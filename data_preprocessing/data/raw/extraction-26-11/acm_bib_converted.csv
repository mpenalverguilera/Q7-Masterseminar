DOI,Document title,Abstract
10.1145/3649158.3657034,BlueSky: How to Raise a Robot - A Case for Neuro-Symbolic AI in Constrained Task Planning for Humanoid Assistive Robots,"Humanoid robots will be able to assist humans in their daily life, in particular due to their versatile action capabilities. However, while these robots need a certain degree of autonomy to learn and explore, they also should respect various constraints, for access control and beyond. We explore the novel field of incorporating privacy, security, and access control constraints with robot task planning approaches. We report preliminary results on the classical symbolic approach, deep-learned neural networks, and modern ideas using large language models as knowledge base. From analyzing their trade-offs, we conclude that a hybrid approach is necessary, and thereby present a new use case for the emerging field of neuro-symbolic artificial intelligence."
10.1145/3772077,LUMEN: Enhancing IoT System Observability with Multi-Agent Large Language Models and Knowledge Graphs,"The rapid expansion of Internet of Things (IoT) systems has transformed industries through real-time monitoring and automation, generating vast and heterogeneous data streams. As IoT networks expand, the increasing volume and diversity of data, spanning real-time telemetry, device logs, and historical records, complicate the management of IoT systems, including system monitoring, analysis, and reasoning. To address this challenge, we introduce LUMEN (Large Language Models as Unified Multi-Agent Systems for IoT ENhancement), a novel approach combining multi-agent Large Language Models (LLMs), knowledge graphs, and heterogeneous databases to enable cognitive digital twins for IoT observability. LUMEN models IoT systems as knowledge graphs, capturing device relationships and metadata while monitoring data is stored in time-series or object databases. Specialized LLM-based agents collaborate dynamically to analyze IoT systems and explain the findings in natural language, generating and executing analysis code when necessary. Integrated with off-the-shelf network monitoring tools, LUMEN facilitates semantic reasoning and human-in-the-loop collaboration, delivering adaptive insights across diverse data contexts. Two industrial case studies demonstrate the ability of LUMEN to automate analysis workflows, enhance system adaptability, and provide interpretable analytics. This work advances IoT observability by integrating LLMs, semantic intelligence, and explainable analytics into a scalable and adaptive solution using a multi-agent architecture for complex IoT systems."
10.14778/3750601.3750611,"SagaLLM: Context Management, Validation, and Transaction Guarantees for Multi-Agent LLM Planning","This paper introduces SagaLLM, a structured multi-agent architecture designed to address four foundational limitations of current LLM-based planning systems: unreliable self-validation, context loss, lack of transactional safeguards, and insufficient inter-agent coordination. While recent frameworks leverage LLMs for task decomposition and multi-agent communication, they often fail to ensure consistency, rollback, or constraint satisfaction across distributed workflows. SagaLLM bridges this gap by integrating the Saga transactional pattern with persistent memory, automated compensation, and independent validation agents. It leverages LLMs' generative reasoning to automate key tasks traditionally requiring hand-coded coordination logic, including state tracking, dependency analysis, log schema generation, and recovery orchestration. Although SagaLLM relaxes strict ACID guarantees, it ensures workflow-wide consistency and recovery through modular checkpointing and compensable execution. Empirical evaluations across planning domains demonstrate that standalone LLMs frequently violate interdependent constraints or fail to recover from disruptions. In contrast, SagaLLM achieves significant improvements in consistency, validation accuracy, and adaptive coordination under uncertainty—establishing a robust foundation for real-world, scalable LLM-based multi-agent systems."
10.1145/3769111,Conformal Temporal Logic Planning using Large Language Models,"This paper addresses temporal logic task planning problems for mobile robots. We consider missions that require accomplishing multiple high-level sub-tasks, expressed in natural language (NL), in a temporal and logical order. To formally define the mission, we treat these sub-tasks as atomic predicates in a Linear Temporal Logic (LTL) formula. We refer to this task specification framework as LTL-NL. Our goal is to design plans, defined as sequences of robot actions, accomplishing LTL-NL tasks. This action planning problem cannot be solved directly by existing LTL planners due to the NL nature of atomic predicates. Therefore, we propose HERACLEs, a hierarchical neuro-symbolic planner that relies on a novel integration of (i) existing symbolic planners generating high-level task plans determining the order at which the NL sub-tasks should be accomplished; (ii) pre-trained Large Language Models (LLMs) to design sequences of robot actions for each sub-task in these task plans; and (iii) conformal prediction acting as a formal interface between (i) and (ii) and managing uncertainties due to LLM imperfections. We show, both theoretically and empirically, that HERACLEs can achieve user-defined mission success rates. We demonstrate the efficiency of HERACLEs through comparative numerical experiments against recent LLM-based planners as well as hardware experiments on mobile manipulation tasks. Finally, we present examples demonstrating that our approach enhances user-friendliness compared to conventional symbolic approaches."
10.1145/3691620.3695336,Towards LLM-augmented multiagent systems for agile software engineering,"A cognitive multi-agent ecosystem designed for efficient software engineering using Agile methodologies can significantly improve software development processes. Key components include the integration of Multi-Agent Systems (MAS) and Large Language Models (LLMs), utilizing Dynamic Context techniques for agent profiling, and Theory of Mind to enhance collaboration. The CogniSim Ecosystem analyzes problems, proposes solutions, constructs and validates plans, and coordinates specialized agents playing roles such as developers, executors, quality checkers, and methodology reviewers. These agents produce documentation, models, and diagrams (e.g., UML) while adhering to predefined quality and performance measures. The ecosystem also simulates the impact of various team configurations on problem-solving effectiveness, helping organizations identify optimal team structures. Case studies and simulations demonstrate its practical applications."
10.1145/3760269.3760299,Outdoor Multi-UAV Collaborative Task Planning System Based on Multi-Agent and Improved PPO Algorithm,"Aiming at the problem of task collaboration and path planning for multi-agent drones in unknown environments, this paper proposes a multi-agent collaborative planning architecture that integrates a large language model (LLM) and a multimodal (MM) perception network, which is used for executing the multi-agent tasks in outdoor environments. This paper innovatively proposes an improved Proximal Policy Optimization (PPO) algorithm for path planning. Through a structured reward function and a joint strategy sharing mechanism, the path planning among multiple drones were efficiently achieved. The system in this paper innovatively proposes a loop intelligent control process called UTTUT (User Instruction, Task Graph Generation, Task Allocation, UAV Feedback, and Task Graph Updating), as well as a  ({P}^3)  (Perception, Planning, Prompt) factor graph model. Theoretically analyzes the interpretability of large model collaborative task planning. The Doubao large language model is introduced as the central control unit, and the Grounding DINO perception model is deployed at the drone end. By combining RGBD, semantic information, and asynchronous scheduling task factors, the perception and positioning of targets in complex scenes are realized. In addition, this paper compares the performances of different large model collaborative frameworks and gets the optimal large model control scheme results. Simulations are carried out on different platforms to verify the superiority of the framework proposed in this paper."
10.1145/3698587.3701359,ClinicalAgent: Clinical Trial Multi-Agent System with Large Language Model-based Reasoning,"Large Language Models (LLMs) and multi-agent systems have shown impressive capabilities in natural language tasks but face challenges in clinical trial applications, primarily due to limited access to external knowledge. Recognizing the potential of advanced clinical trial tools that aggregate and predict based on the latest medical data, we propose an integrated solution to enhance their accessibility and utility. We introduce Clinical Agent System (ClinicalAgent), a clinical multi-agent system designed for clinical trial tasks, leveraging GPT-4, multi-agent architectures, LEAST-TO-MOST, and ReAct reasoning technology. This integration not only boosts LLM performance in clinical contexts but also introduces novel functionalities. The proposed method achieves competitive predictive performance in clinical trial outcome prediction (0.7908 PR-AUC), obtaining a 0.3326 improvement over the standard prompt Method. Publicly available code can be found at https://github.com/LeoYML/clinical-agent."
10.1145/3746059.3747681,StorySage: Conversational Autobiography Writing Powered by a Multi-Agent Framework,"Every individual carries a unique and personal life story shaped by their memories and experiences. However, these memories are often scattered and difficult to organize into a coherent narrative—a challenge that defines the task of autobiography writing. Existing conversational writing assistants tend to rely on generic user interactions and pre-defined guidelines, making it difficult for these systems to capture personal memories and develop a complete biography over time. We introduce StorySage, a user-driven software system designed to meet the needs of a diverse group of users that supports a flexible conversation and a structured approach to autobiography writing. Powered by a multi-agent framework composed of an Interviewer, Session Scribe, Planner, Section Writer, and Session Coordinator, our system iteratively collects user memories, updates their autobiography, and plans for future conversations. In experimental simulations, StorySage demonstrates its ability to navigate multiple sessions and capture user memories across many conversations. User studies (N = 28) highlight how StorySage maintains improved conversational flow, narrative completeness, and higher user satisfaction when compared to a baseline. In summary, StorySage contributes both a novel architecture for autobiography writing and insights into how multi-agent systems can enhance human-AI creative partnerships."
10.1145/3760658.3760664,Gap-Guided Evolutionary Deep Reinforcement Learning for Hierarchical Navigation in Structured Dynamic Environments,"Multi-agent collision avoidance—where an ego-robot must navigate from a start pose to a goal pose while avoiding both static obstacles and dynamic agents—is a longstanding challenge in motion planning. Recently, reinforcement learning (RL) has been explored for this task, but most RL-based solutions address simplified scenarios, often omitting complex static obstacles and focusing primarily on dynamic agent avoidance. Consequently, these approaches are unsuitable for structured environments such as mazes or indoor layouts with significant static geometry. To address this limitation, we integrate a multi-agent collision avoidance policy—specifically the GPU-accelerated Asynchronous Advantage Actor-Critic for Collision Avoidance (Evolution GA3C-CADRL) [4]—within a hierarchical navigation framework. Our method incorporates a local waypoint planner that leverages global navigation plans and real-time sensor data to generate short-term waypoints, ensuring clear paths devoid of static obstacles between the agent and the next target. This architecture effectively mitigates the original model’s inability to handle static constraints. The full system integrates global planning, perception-informed gap-based waypoint generation, and deep RL for local control. We empirically evaluate our hierarchical planner across five structured environments and demonstrate that the integrated waypoint + RL approach consistently reduces collision rates and improves goal-reaching success compared to the standalone RL model. Results show substantial improvements in both navigation robustness and success rate under realistic, complex scenarios."
10.1145/3703323.3704277,MEQA - A Multi-modal Interactive Enterprise Query Answering System using Multi-Agent LLM,"This paper introduces a new architecture for multi-agent systems designed to support query answering over secure enterprise data. The system uses a modular approach to natural language understanding and task execution, utilizing specialized agents for query processing. Our system features a Multi-Agent Block that consists of agents for general inquiries, Text2SQL, visualization, and information consolidation. These agents work together to handle complex queries. The Answer Generation component then integrates these results into coherent responses. We demonstrate our system’s efficiency using a complex query processed by a Text2SQL agent. In this scenario, the agent interacts with multiple endpoints, including an enterprise database and LLM endpoints, while employing techniques like RISE (Recursive Introspection for Results Improvements) and STaR (Self-Taught Reasoner) to enhance reasoning. Additionally, we use an open-source utility, LLMLingua, to compress prompts and reduce computational overhead. Our approach shows strong performance across various retrieval tasks, offering a significant step toward more intuitive and efficient data interaction, with the potential to transform how organizations utilize large language models, multiple agents, and data assets."
10.1145/3712003,"LLM-Based Multi-Agent Systems for Software Engineering: Literature Review, Vision, and the Road Ahead","Integrating Large Language Models (LLMs) into autonomous agents marks a significant shift in the research landscape by offering cognitive abilities that are competitive with human planning and reasoning. This article explores the transformative potential of integrating Large Language Models into Multi-Agent (LMA) systems for addressing complex challenges in software engineering (SE). By leveraging the collaborative and specialized abilities of multiple agents, LMA systems enable autonomous problem-solving, improve robustness, and provide scalable solutions for managing the complexity of real-world software projects. In this article, we conduct a systematic review of recent primary studies to map the current landscape of LMA applications across various stages of the software development lifecycle (SDLC). To illustrate current capabilities and limitations, we perform two case studies to demonstrate the effectiveness of state-of-the-art LMA frameworks. Additionally, we identify critical research gaps and propose a comprehensive research agenda focused on enhancing individual agent capabilities and optimizing agent synergy. Our work outlines a forward-looking vision for developing fully autonomous, scalable, and trustworthy LMA systems, laying the foundation for the evolution of Software Engineering 2.0."
10.1145/3744333.3747807,Enhancing Passenger Trust Toward Cooperative Autonomous Vehicles Using Simulated Augmented Reality Displays,"Adoption of Fully Autonomous Vehicles (FAVs) depends on trust, which is defined as confidence in a vehicle’s dependability, safety, and predictability. In cooperative driving scenarios, trust must exceed ego vehicles to include other autonomous vehicles and their coordination. This is challenged by unexpected multi-agent interactions, diminishing human control, and limited system transparency. We hypothesize that enhancing transparency by providing information about ego vehicle, other cooperative vehicles, and road conditions can foster trust. This is achieved by visualizing vehicle-to-everything (V2X) information via augmented reality (AR) interfaces. To test this in a safe environment, we conducted a within-subjects experiment in a Virtual Reality (VR) driving simulator with AR overlays. Participants experienced three interface concepts: (A) no transparency, (B) system-level transparency (ego vehicle intentions only), and (C) environment-level transparency (cooperation intentions, planned paths, and infrastructure). Results show that environment-level transparency, despite the higher cognitive workload, enhanced trust in both ego and cooperating FAVs."
10.1145/3768292.3770383,AuditAgent: Expert-Guided Multi-Agent Reasoning for Cross-Document Fraudulent Evidence Discovery,"Financial fraud detection in real-world scenarios presents significant challenges due to the subtlety and dispersion of evidence across complex, multi-year financial disclosures. In this work, we introduce a novel multi-agent reasoning framework AuditAgent, enhanced with auditing domain expertise, for fine-grained evidence chain localization in financial fraud cases. Leveraging an expert-annotated dataset constructed from enforcement documents and financial reports released by the China Securities Regulatory Commission, our approach integrates subject-level risk priors, a hybrid retrieval strategy, and specialized agent modules to efficiently identify and aggregate cross-report evidence. Extensive experiments demonstrate that our method substantially outperforms General-Purpose Agent paradigm in both recall and interpretability, establishing a new benchmark for automated, transparent financial forensics. Our results highlight the value of domain-specific reasoning and dataset construction for advancing robust financial fraud detection in practical, real-world regulatory applications."
10.5555/3635637.3662921,NovelGym: A Flexible Ecosystem for Hybrid Planning and Learning Agents Designed for Open Worlds,"As AI agents leave the lab and venture into the real world as autonomous vehicles, delivery robots, and cooking robots, it is increasingly necessary to design and comprehensively evaluate algorithms that tackle the ""open-world''. To this end, we introduce NovelGym, a flexible and adaptable ecosystem designed to simulate gridworld environments, serving as a robust platform for benchmarking reinforcement learning (RL) and hybrid planning and learning agents in open-world contexts. The modular architecture of NovelGym facilitates rapid creation and modification of task environments, including multi-agent scenarios, with multiple environment transformations, thus providing a dynamic testbed for researchers to develop open-world AI agents."
10.1145/3715709,Thinking Fast and Slow in Human and Machine Intelligence,"When working to build machines that have a form of intelligence, it is natural to be inspired by human intelligence. Of course, humans are very different from machines, in their embodiment and myriad other ways. Humans exploit their bodies to experience the world, create an internal model of it, and use this model to reason, learn, and make contextual and informed decisions. Machines lack the same embodiment, but often have access to both more memory and more computing power. Despite these crucial disanalogies, it is still useful to leverage our knowledge of how the human mind reasons and makes decisions to design and build machines that demonstrate behaviors similar to that of a human. In this article, we present a novel AI architecture, Slow and Fast AI (SOFAI), that is inspired by the “thinking fast and slow” cognitive theory of human decision making. SOFAI is a multi-agent architecture that employs both “fast” and “slow” solvers underneath a metacognitive agent that is able to both choose among a set of solvers as well as reflect on and learn from past experience. Experimental results on the behavior of two instances of the SOFAI architecture show that, compared to using just one of the two decision modalities, SOFAI is markedly better in terms of decision quality, resource consumption, and efficiency.Modeling AI systems on dual-process theories of human cognition can improve their ability to flexibly handle diverse tasks."
10.1145/3768292.3770387,"Large Language Model Agents for Investment Management: Foundations, Benchmarks, and Research Frontiers","Recent advances in Large Language Models (LLMs) have triggered a new wave of intelligent financial agents capable of complex reasoning, tool use, and autonomous decision-making. This survey presents a comprehensive review of LLM-based agents in the context of investment and trading, focusing on applications such as portfolio optimization, risk management, information retrieval, and automated strategy generation. We systematically categorize the literature by use case and architectural innovations including multi-agent collaborations, reflection mechanisms, and tool-augmented pipelines. Additionally, we review emerging evaluation frameworks and benchmark datasets tailored to finance-specific agent tasks. The survey identifies current trends, technical limitations, and open challenges related to robustness, explainability, and real-world deployment. We conclude with emerging directions for building more capable, adaptive, and trustworthy financial AI agents aligned with the demands of modern investment ecosystems."
10.5555/3635637.3663063,Attention-based Priority Learning for Limited Time Multi-Agent Path Finding,"Solving large-scale Multi-Agent Path Finding (MAPF) within a limited time remains an open challenge, despite its importance for many robotic applications. Recent learning-based methods scale better than conventional ones, but remain suboptimal and often exhibit low success rates within a limited time on large-scale instances. These limitations often stem from their black-box nature. In this study, we propose a hybrid approach that incorporates prioritized planning with learning-based methods to explicitly address these challenges. We formulate prioritized planning as a Markov Decision Process and introduce a reinforcement learning-based prioritized planning paradigm. In doing so, we develop a novel Synthetic Score-based Attention Network (S2AN) to learn conflict/blocking relationships among agents, and deliver blocking-free priorities. By integrating priority mechanisms and leveraging a new attention-based neural network for enhanced multi-agent cooperative strategies, our method enhances solution completeness while trading off scalability and maintains linear time complexity, thus offering a robust avenue for large-scale MAPF tasks. Comparisons demonstrate its superiority over current learning-based methods in terms of solution quality, completeness, and reachability within limited time constraints, especially in large-scale scenarios. Moreover, an extensive set of numerical results reveals superior completeness compared to restricted-time Priority-Based Search (PBS) and Priority Inheritance with Backtracking (PIBT) in medium to large-scale obstacle-dense scenarios."
10.1145/3774946,MemIndex: Agentic Event-based Distributed Memory Management for Multi-agent Systems,"Interactive applications are latency-sensitive systems that enable dynamic responses to user inputs in domains such as robotics, industrial automation, and autonomous control. These applications require efficient application protocols for communication, with the pub/sub model being one of the most promising approaches. However, existing pub/sub systems are architecturally constrained, particularly by limited memory capacity and inefficiencies in dynamic environments. Addressing these challenges requires effective distributed memory management, yet this aspect has received limited attention in existing research. This paper addresses the gap by proposing MemIndex, an adaptive and autonomous distributed memory-management framework with an intent-indexed bipartite graph architecture. It is designed for an LM-based multi-agent pub/sub systems, enabling agents to autonomously negotiate memory operations in real time through dynamic index spaces for efficient reasoning. We evaluate our proposed MemIndex using diverse models against two baselines. Experimental results show MemIndex outperforms both baselines across storage, retrieval, update, and deletion operations, achieving average reductions of about 34\% and 56\% in elapsed time, 57\% and 75\% in CPU utilization, 23\% and 76\% in memory usage. Scalability tests further demonstrate that MemIndex maintains low end-to-end delay as submissions and agents grow, confirming that its negotiation-driven offloading enables efficient distributed memory management in interactive applications."
10.5555/3709347.3744035,The Next Level of Long-Term Agent Autonomy -- Proactively Acquiring Knowledge and Abilities,"For an artificial agent operating long-term under real-world conditions it is not enough to be able to act on orders given by the human. Even being able to act proactively (anticipatory, self-initiated) does not suffice. The reason roots in the unrealistic assumption that the proactive agent from the start and always knows everything it needs to know and has all the abilities it requires. We argue that the agent has to be able to proactively learn new knowledge and abilities according to how the dynamic environment evolves. We identify challenges and directions towards proactive learning. Our focus is on formal methods which lend themselves to doing the necessary reasoning but also give suggestions how these might be integrated with machine learning. The ideas envisioned in this paper can advance (M)AS (Multi-Agent Systems) research and have the potential to enhance collaborations of hybrid human-AI systems."
10.1145/3731715.3733393,MMCNav: MLLM-empowered Multi-agent Collaboration for Outdoor Visual Language Navigation,"Navigating through real-world environments, such as urban street views, poses a significant challenge for agents searching for a clear path to the destination based on environmental information. Although existing methods leveraging large language models (LLMs) have demonstrated remarkable achievements, they often struggle to tackle scenarios that require complex visual understanding. Inspired by the classical perception-cognition-action feedback loop in cognitive neuroscience, we present a multimodal large language models (MLLMs) empowered multi-agent collaborative outdoor navigation system that significantly enhances the capability to accomplish outdoor navigation tasks by extending a single agent into multiple cooperative agents. Each agent assumes a specific role in this system and collaborates to perform their respective tasks effectively. The system begins with agents interpreting human-written navigation instructions into detailed plans. At each step of the plan, agents analyze and caption the multimodal scenarios to improve their understanding of the environment. Then agents determine the search direction based on observational captions and historical decisions. At the end of the navigation, agents adopt the map of the search process to perform a two-stage reflection for error correction. Comprehensive experiments and analyses conducted on two outdoor navigation datasets demonstrate the superiority of our approach, outperforming previous methods in terms of performance. The repository of this project is available at https://github.com/zzhaesc/MMCNav."
10.5555/3635637.3663023,Design Patterns for Explainable Agents (XAg),"The ability to explain the behaviour of the AI systems is a key aspect of building trust, especially for autonomous agent systems - how does one trust an agent whose behaviour can not be explained? In this work, we advocate the use of design patterns for developing explainable-by-design agents (XAg), to ensure explainability is an integral feature of agent systems rather than an ""add-on"" feature. We present TriQPAN (Trigger, Query, Process, Action and Notify), a design pattern for XAg. TriQPAN can be used to explain behaviours of any agent architecture and we show how this can be done to explain decisions such as why the agent chose to pursue a particular goal, why or why didn't the agent choose a particular plan to achieve a goal, and so on. We term these queries as direct queries. Our framework also supports temporal correlation queries such as asking a search and rescue drone, ""which locations did you visit and why?"". We implemented TriQPAN in the SARL agent language, built-in to the goal reasoning engine, affording developers XAg with minimal overhead. The implementation will be made available for public use. We describe that implementation and apply it to two case studies illustrating the explanations produced, in practice."
10.5555/3709347.3743808,"Planning, Scheduling, and Execution on the Moon: The CADRE Technology Demonstration Mission","NASA's Cooperative Autonomous Distributed Robotic Exploration (CADRE) mission, slated for flight to the Moon's Reiner Gamma region in 2025/2026, is designed to demonstrate multi-agent autonomous exploration of the Lunar surface and sub-surface. A team of three robots and a base station will autonomously explore a region near the lander, collecting the data required for 3D reconstruction of the surface with no human input; and then autonomously perform distributed sensing with multi-static ground penetrating radars (GPR), driving in formation while performing coordinated radar soundings to create a map of the subsurface. At the core of CADRE's software architecture is a novel autonomous, distributed planning, scheduling, and execution (PS&amp;E) system. The system coordinates the robots' activities, planning and executing tasks that require multiple robots' participation while ensuring that each individual robot's thermal and power resources stay within prescribed bounds, and respecting ground-prescribed sleep-wake cycles. The system uses a centralized-planning, distributed-execution paradigm, and a leader election mechanism ensures robustness to failures of individual agents. In this paper, we describe the architecture of CADRE's PS&amp;E system; discuss its design rationale; and report on verification and validation (V&amp;V) testing of the system on CADRE's hardware in preparation for deployment on the Moon."
10.1145/3766882.3767169,AgentSight: System-Level Observability for AI Agents Using eBPF,"Modern software infrastructure increasingly relies on LLM agents for development and maintenance, such as Claude Code and Gemini-cli. However, these AI agents differ fundamentally from traditional deterministic software, posing a significant challenge to conventional monitoring and debugging. This creates a critical semantic gap: existing tools observe either an agent's high-level intent (via LLM prompts) or its low-level actions (e.g., system calls), but cannot correlate these two views. This blindness makes it difficult to distinguish between benign operations, malicious attacks, and costly failures. We introduce AgentSight, an AgentOps observability framework that bridges this semantic gap using a hybrid approach. Our approach, boundary tracing, monitors agents from outside their application code at stable system interfaces using eBPF. AgentSight intercepts TLS-encrypted LLM traffic to extract semantic intent, monitors kernel events to observe system-wide effects, and causally correlates these two streams across process boundaries using a real-time engine and secondary LLM analysis. This instrumentation-free technique is framework-agnostic, resilient to rapid API changes, and incurs less than 3\% performance overhead. Our evaluation shows AgentSight detects prompt injection attacks, identifies resource-wasting reasoning loops, and reveals hidden coordination bottlenecks in multi-agent systems. AgentSight is released as an open-source project at https://github.com/eunomia-bpf/agentsight."
10.1145/3708657.3708691,Heterogeneous Resource Allocation in LEO Networks: A Federated Multi-Agent Deep Reinforcement Learning Method,"With the continuous development of satellite technology, satellite edge computing is garnering unprecedented attention as a crucial component of 6G. However, the heterogeneous network architecture and resource distribution of future 6G networks present huge challenges for effective and reasonable resource allocation for diverse task requirements. This paper proposes a heterogeneous resource allocation strategy to address these needs in future LEO networks. By employing a multi-agent deep reinforcement learning method based on federated learning, the proposed strategy can achieve self-learning, self-updating and be adaptive to different resource requirements of various tasks. Simulation results demonstrate that the proposed method exhibits superior performance in task completion and overall energy consumption across different resource environments compared to benchmark algorithms."
10.1145/3746027.3755425,From Model Diagram to Code: A Benchmark Dataset and Multi-Agent Framework,"Model Diagram-to-Code Generation aims to translate model diagrams from research papers into implementation code that reconstructs the model's architecture. This task plays a crucial role in accelerating scientific workflows and enhancing the efficiency of industrial model deployment. While recent studies have explored various Image-to-Code Generation tasks using Multimodal Large Language Models (MLLMs), these efforts have primarily focused on reconstructing the visual appearance depicted in input images, leaving this task largely underexplored. The complex structural elements and implicit relationships in model diagrams present greater challenges for MLLMs, particularly in terms of visual reasoning and semantic interpretation. To support this task, we introduce MDCDataset, a dataset designed to evaluate the ability of MLLMs to generate code from model diagrams. It comprises 1,008 instances spanning 16 research domains, each with a model diagram, structured textual content, and the ground-truth code implementation. Furthermore, to address the inherent challenges of this task, we propose MDCAgent, a collaborative multi-agent framework composed of Parsing, Generation, and Check Agents. These agents work in coordination to analyze, extract, and verify complex elements and implicit relationships within model diagrams, thereby enhancing the visual architecture-aware reasoning capabilities of MLLMs. Our extensive experiments confirm the effectiveness of the framework."
10.1145/3746027.3754761,HM-RAG: Hierarchical Multi-Agent Multimodal Retrieval Augmented Generation,"While Retrieval-Augmented Generation (RAG) augments Large Language Models (LLMs) with external knowledge, conventional single-agent RAG remains fundamentally limited in resolving complex queries demanding coordinated reasoning across heterogeneous data ecosystems. We present HM-RAG, a novel Hierarchical Multi-agent Multimodal RAG framework that pioneers collaborative intelligence for dynamic knowledge synthesis across structured, unstructured, and graph-based data. The framework is composed of a three-tiered architecture with specialized agents: a Decomposition Agent that dissects complex queries into contextually coherent sub-tasks via semantic-aware query rewriting and schema-guided context augmentation; Multi-source Retrieval Agents that carry out parallel, modality-specific retrieval using plug-and-play modules designed for vector, graph, and web-based databases; and a Decision Agent that uses consistency voting to integrate multi-source answers and resolve discrepancies in retrieval results through Expert Model Refinement. This architecture attains comprehensive query understanding by combining textual, graph-relational, and web-derived evidence, resulting in a remarkable 12.95\% improvement in answer accuracy and a 3.56\% boost in question classification accuracy over baseline RAG systems on the ScienceQA and CrisisMMD benchmarks. Notably, HM-RAG establishes state-of-the-art results in zero-shot settings on both datasets. Its modular architecture ensures seamless integration of new data modalities while maintaining strict data governance, marking a significant advancement in addressing the critical challenges of multimodal reasoning and knowledge synthesis in RAG systems."
10.1145/3607720.3607796,"Tweets similarity classification based on Machine Learning Algorithms, TF-IDF and the Dynamic Case Based Reasoning","The research on the field of Twitter sentiment analysis, which aims to extract users’ sentiments through their public opinion about a given topic, has been increased and grown rapidly across a broad range of disciplines in the last decade. In this article, we propose a hybrid approach for Tweets similarity classification Based on Dynamic Case Based Reasoning approach, machine learning algorithms and Multi-Agent System. Our approach proposes a multi-agent adaptive system for Tweets similarity classification. It combines the Dynamic Case-Based Reasoning approach with the scientific measurement of keyword weight (Term Frequency- Inverse Document Frequency, TF-IDF). It consists of gathering and pre-processing tweets about a given topic and use a feature extraction to extract useful features. Machine Learning algorithms are then used for similarity content-based classification. Our approach is general and can be used to follow users’ tweets traces to predict their sentiments and provide them with an individualized content. In this study, Covid-19 tweets have been taken as an example."
10.1145/3676536.3698389,Thinking and Moving: An Efficient Computing Approach for Integrated Task and Motion Planning in Cooperative Embodied AI Systems,"Cooperative embodied AI systems, where multiple agents collaborate to accomplish complex, long-horizon tasks, show significant promise for real-world applications. These systems integrate perception, cognition, and action through integrated task and motion planning (TAMP), leveraging the advanced reasoning and communication capabilities of large language models (LLMs). However, their efficiency is often hindered by challenges such as high computational latency and redundant communication, largely due to the reliance on LLMs for sequential planning decisions.In this paper, we aim to identify the inherent characteristics and optimization opportunities in cooperative embodied AI systems. We first present a cognitive-inspired modular framework encompassing perception, memory, communication, planning, and execution. We then conduct a detailed profiling analysis of two state-of-the-art cooperative embodied systems, revealing the significance of each module and identifying critical bottlenecks such as redundant message pre-generation and excessive LLM usage in decision-making processes. Based on these insights, we propose several model- and system-level optimizations, including a planning-first communication strategy, selective multi-agent communication, and planning-guided multi-step execution. Evaluated across long-horizon cooperative tasks, these optimizations reduce the frequency of LLM inference runs, achieving an average 3.93\texttimes{} speedup in end-to-end task execution. Finally, we discuss the challenges and potential directions for embodied AI computing, to enhance system flexibility, efficiency, and scalability."
10.1145/3716553.3750771,A Multifaceted Multi-Agent Framework for Zero-Shot Emotion Analysis and Recognition of Symbolic Music,"This paper presents the first attempt at zero-shot music emotion recognition (MER) to map musical pieces, represented in symbolic formats (e.g., ABC notation), onto the valence-arousal space. Conventional MER approaches typically train an end-to-end deep neural network (DNN). However, the performance of such supervised methods is limited due to the multifaceted and ambiguous nature of music emotions, compounded by the scarcity of MER datasets. To address this, we leverage knowledge transfer from large language models (LLMs) pre-trained on vast text and symbolic data. We hypothesize that LLMs possess capabilities in low-level music description and high-level emotion reasoning (not necessarily in a musical context). Accordingly, we propose a multi-agent framework that performs zero-shot MER by associating objective musical attributes (harmony, melody, rhythm, and structure) with subjective attributes (valence and arousal). Our system employs a hierarchical architecture comprising (i) musical element descriptors, (ii) chain-of-thought emotion analysts, and (iii) comprehensive predictors. Knowledge injection and zero-shot prompting are utilized to mitigate inherent model biases. Evaluations on the EMOPIA dataset demonstrate that our system, built on the Gemini-2.0-Flash backbone, significantly outperforms baseline LLM models, including ultra-large models and mixture-of-experts (MoE) systems, and performs comparably to fully supervised or fine-tuned models."
10.5555/3463952.3464093,Active Perception within BDI Agents Reasoning Cycle,"In multi-agent systems the main process responsible for obtaining information about the environment is perception, generally this process is performed passively regardless the agent's intentional state. However, especially when inserted in the real world, a frequent problem is that agents have partial perception of the environment, failing to perceive some relevant information. To circumvent this problem, a solution is to actively take actions to perceive what is of interest to the agent, for example, in a computer vision system, the camera can be repositioned to have a better view of an object. This work aims to develop an active perception model integrated with the reasoning cycle of BDI agents. Experiments are performed using BDI agents with ROS to command unmanned aerial vehicles to analyze the benefits and impacts of using cognitive agents with active perception to program robot intelligence."
10.1145/3746252.3761057,On Verifiable Legal Reasoning: A Multi-Agent Framework with Formalized Knowledge Representations,"Legal reasoning requires both precise interpretation of statutory language and consistent application of complex rules, presenting significant challenges for AI systems. This paper introduces a modular multi-agent framework that decomposes legal reasoning into distinct knowledge acquisition and application stages. In the first stage, specialized agents extract legal concepts and formalize rules to create verifiable intermediate representations of statutes. The second stage applies this knowledge to specific cases through three steps: analyzing queries to map case facts onto the ontology schema, performing symbolic inference to derive logically entailed conclusions, and generating final answers using a programmatic implementation that operationalizes the ontological knowledge. This bridging of natural language understanding with symbolic reasoning provides explicit and verifiable inspection points, significantly enhancing transparency compared to end-to-end approaches. Evaluation on statutory tax calculation tasks demonstrates substantial improvements, with foundational models achieving 76.4\% accuracy compared to 18.8\% baseline performance, effectively narrowing the performance gap between reasoning and foundational models. These findings suggest that modular architectures with formalized knowledge representations can make sophisticated legal reasoning more accessible through computationally efficient models while enhancing consistency and explainability in AI legal reasoning, establishing a foundation for future research into more transparent, trustworthy, and effective AI systems for legal domain."
10.1145/3665331,Generating and Evaluating Data of Daily Activities with an Autonomous Agent in a Virtual Smart Home,"Training machine learning models to identify human behavior is a difficult yet essential task to develop autonomous and adaptive systems such as smart homes. These models require large and diversified amounts of labeled data to be trained effectively. Due to the high variety of home environments and occupant behaviors, collecting datasets that are representative of all possible homes is a major challenge. In addition, privacy and cost are major hurdles to collect real home data. To avoid these difficulties, one solution consists of training these models using purely synthetic data, which can be generated through the simulation of home and their occupants. Two challenges arise from this approach: designing a methodology with a simulation able to generate credible simulated data and evaluating this credibility. In this article, we explain the methodology used to generate diversified synthetic data of daily activities, through the combination of an agent model to simulate an occupant and a simulated 3D house enriched with sensors and effectors to produce such data. We demonstrate the credibility of the generated synthetic data by comparing their efficacy for training human context understanding models against the efficacy generated by real data. To achieve this, we replicate a real dataset collection setting with our smart home simulator. The occupant is replaced by an autonomous agent following the same experimental protocol used for the real dataset collection. This agent is a BDI-based model enhanced with a scheduler designed to offer a balance between control and autonomy. This balance is useful in synthetic data generation since strong constraints can be imposed on the agent to simulate desired situations while allowing autonomous behaviors outside these constraints to generate diversified data. In our case, the constraints are those imposed during the real dataset collection that we want to replicate. The simulated sensors and effectors were configured to react to the agent’s behaviors similarly to the real ones. We experimentally show that data generated from this simulation are valuable for two human context understanding tasks: current human activity recognition and future human activity prediction. In particular, we show that models trained solely with simulated data can give reasonable predictions about real situations occurring in the original dataset. We also report experimental results regarding statistical analysis and C2ST to assess the credibility of generated data. We discuss the generality of our approach for evaluating the credibility of simulated data from their use as training data."
10.5555/3535850.3535992,Socially Supervised Representation Learning: The Role of Subjectivity in Learning Efficient Representations,"Despite its rise as a prominent solution to the data inefficiency of today's machine learning models, self-supervised learning has yet to be studied from a purely multi-agent perspective. In this work, we propose that aligning internal subjective representations, which naturally arise in a multi-agent setup where agents receive partial observations of the same underlying environmental state, can lead to more data-efficient representations. We propose that multi-agent environments, where agents do not have access to the observations of others but can communicate within a limited range, guarantees a common context that can be leveraged in individual representation learning. The reason is that subjective observations necessarily refer to the same subset of the underlying environmental states and that communication about these states can freely offer a supervised signal. To highlight the importance of communication, we refer to our setting associally supervised representation learning. We present a minimal architecture comprised of a population of autoencoders, where we define loss functions, capturing different aspects of effective communication, and examine their effect on the learned representations. We show that our proposed architecture allows the emergence of aligned representations. The subjectivity introduced by presenting agents with distinct perspectives of the environment state contributes to learning abstract representations that outperform those learned by a single autoencoder and a population of autoencoders, presented with identical perspectives of the environment state. Altogether, our results demonstrate how communication from subjective perspectives can lead to the acquisition of more abstract representations in multi-agent systems, opening promising perspectives for future research at the intersection of representation learning and emergent communication."
10.1145/3706598.3713913,Jupybara: Operationalizing a Design Space for Actionable Data Analysis and Storytelling with LLMs,"Mining and conveying actionable insights from complex data is a key challenge of exploratory data analysis (EDA) and storytelling. To address this challenge, we present a design space for actionable EDA and storytelling. Synthesizing theory and expert interviews, we highlight how semantic precision, rhetorical persuasion, and pragmatic relevance underpin effective EDA and storytelling. We also show how this design space subsumes common challenges in actionable EDA and storytelling, such as identifying appropriate analytical strategies and leveraging relevant domain knowledge. Building on the potential of LLMs to generate coherent narratives with commonsense reasoning, we contribute Jupybara, an AI-enabled assistant for actionable EDA and storytelling implemented as a Jupyter Notebook extension. Jupybara employs two strategies—design-space-aware prompting and multi-agent architectures—to operationalize our design space. An expert evaluation confirms Jupybara’s usability, steerability, explainability, and reparability, as well as the effectiveness of our strategies in operationalizing the design space framework with LLMs."
10.1145/3757110.3757143,Application of Self-Play Deep Reinforcement Learning in Task Planning for UAV Swarms under Capacity Constraints,"This paper develops an Adaptive Staircase-based Policy Space Response Oracle (ASP) architecture that uses a self-play deep reinforcement learning (DRL) method to solve the problem of planning tasks for UAV swarms in urban logistics and post-disaster rescue situations when there isn't enough time and resources. We show that UAV swarm path planning may be optimized across different scales by combining a two-player meta-game structure with adversarial instance creation and developing a staircase curriculum learning mechanism. The framework lets you learn from small amounts of pre-training (10 to 100 inspection points) and apply that knowledge to larger applications (200 to 1000 inspection points). The results of the experiments indicate that the ASP-based method works better than traditional Policy Optimization for Multi-Agent (POMO) algorithms. It cuts the average solution time by 41\% and the total flight distance by 55.6\% in tasks with a thousand nodes. This paper offers a systematic engineering approach for dynamic task planning in UAV swarms, overcoming the problem of balancing exploration and exploitation in complicated state spaces and proving that it can be used in a variety of situations."
10.1145/3771555,VUI Testing of VPA Apps via Behavior Model-Enhanced LLM Agents,"With the increasing adoption of smart speakers, Virtual Personal Assistant (VPA) applications have become integral to daily life, enabling users to access news, entertainment, and smart device control through Voice User Interfaces (VUI). However, many VPA apps suffer from quality issues, such as unexpected terminations and failures to process common user commands, highlighting the urgent need for systematic and efficient VUI testing. Existing chatbot-style and model-based testing approaches lack global and semantic awareness, resulting in ineffective test case generation and inefficient state exploration.To address these challenges, we introduce Elevate, a model-enhanced, LLM-driven VPA testing framework that employs a multi-agent architecture to enhance VUI behavior testing. Elevate comprises three specialized LLM agents—Observer, Generator, and Planner—that collaboratively perform state extraction, test case generation, and guided state exploration. Additionally, a deterministic finite automaton (DFA)-based behavior model is designed to abstract app behavior and provide structured guidance to LLM agents, enhancing testing performance. Elevate also incorporates a feedback mechanism that refines testing strategies based on observed behaviors, ensuring continuous improvement.Implemented using GPT-4-Turbo and DeepSeek-R1, Elevate has been evaluated on problem detection, sentence/semantic coverage, and large-scale testing. Experimental results show that Elevate outperforms state-of-the-art methods (Vitas and LLM-based chatbots), detecting at least 18 and 37 more problems, respectively, and achieving over 10\% and 30\% higher state coverage. In a large-scale evaluation on 4,000 Alexa skills, Elevate further demonstrated 15\% higher coverage than Vitas, confirming its effectiveness, scalability, and potential for widespread application in VUI testing."
10.5555/3635637.3663033,Modeling Cognitive Biases in Decision-theoretic Planning for Active Cyber Deception,"This paper presents an approach to modeling and exploiting cognitive biases of cyber attackers in planning for active deception. Sophisticated cyber attacks are primarily orchestrated by human actors. Hence, we focus on the human aspect of the attacker's decision-making process. Humans deviate from rational decision-making due to various cognitive biases. Here, we focus on fundamental attribution error (FAE) and confirmation bias and their role in cyber deception because these biases contribute to humans being deceived. We use the decision-theoretic planning framework of finitely-nested factored I-POMDP (I-POMDPχ), which allows us to explicitly model FAE in multi-agent settings and build cognitive models of the attackers. We show how these biases impact their beliefs as they act and obtain more information about the environment and the adversary. The tractability of the I-POMDPχ also allows for modeling agents at a higher strategy level where the optimal policy relies on induction and exploitation of these biases. Hence, we also present an I-POMDPχ-based rational defender agent that can model the attacker's beliefs under the influence of FAE and confirmation bias from a higher strategic level, and exploit them. Our experiments in simulated interactions show that the I-POMDPχ-based defender agent can induce FAE in an attacker to distort the attacker's beliefs. Consequently, the defender agent can exploit the attacker's cognitive biases to extend the duration of the attack to facilitate the attacker's intent recognition in a controlled environment. Our work provides a general decision-theoretic formulation of FAE and confirmation bias, and demonstrates its role in planning for agent-based active cyber deception."
10.1145/3564121.3564817,Tutorial: Neuro-symbolic AI for Mental Healthcare,"Artificial Intelligence (AI) systems for mental healthcare (MHCare) have been ever-growing after realizing the importance of early interventions for patients with chronic mental health (MH) conditions. Social media (SocMedia) emerged as the go-to platform for supporting patients seeking MHCare. The creation of peer-support groups without social stigma has resulted in patients transitioning from clinical settings to SocMedia supported interactions for quick help. Researchers started exploring SocMedia content in search of cues that showcase correlation or causation between different MH conditions to design better interventional strategies. User-level Classification-based AI systems were designed to leverage diverse SocMedia data from various MH conditions, to predict MH conditions. Subsequently, researchers created classification schemes to measure the severity of each MH condition. Such ad-hoc schemes, engineered features, and models not only require a large amount of data but fail to allow clinically acceptable and explainable reasoning over the outcomes. To improve Neural-AI for MHCare, infusion of clinical symbolic knowledge that clinicans use in decision making is required. An impactful use case of Neural-AI systems in MH is conversational systems. These systems require coordination between classification and generation to facilitate humanistic conversation in conversational agents (CA). Current CAs with deep language models lack factual correctness, medical relevance, and safety in their generations, which intertwine with unexplainable statistical classification techniques. This lecture-style tutorial will demonstrate our investigations into Neuro-symbolic methods of infusing clinical knowledge to improve the outcomes of Neural-AI systems to improve interventions for MHCare:(a) We will discuss the use of diverse clinical knowledge in creating specialized datasets to train Neural-AI systems effectively. (b) Patients with cardiovascular disease express MH symptoms differently based on gender differences. We will show that knowledge-infused Neural-AI systems can identify gender-specific MH symptoms in such patients. (c) We will describe strategies for infusing clinical process knowledge as heuristics and constraints to improve language models in generating relevant questions and responses."
10.1145/3632410.3632430,DSDF: Coordinated look-ahead strategy in multi-agent reinforcement learning with noisy agents,"Existing methods of Multi-Agent Reinforcement learning, involving Centralized Training and Decentralized execution, attempt to train the agents towards learning a pattern of coordinated actions to arrive at optimal joint policy. However, during the execution phase, if some of the agents degrade and perform noisy actions (not the same actions suggested by policy) to varying degrees, the above methods provide poor coordination. In this paper, we show how such random noise in agents, which could be a result of the degradation or aging of robots, can add to the uncertainty in coordination and thereby contribute to unsatisfactory global rewards. In such a scenario, the agents which are in accordance with the policy have to understand the behavior and limitations of the noisy agents while the noisy agents have to plan in cognizance of their limitations. In our proposed method, Deep Stochastic Discount Factor (DSDF), based on the degree of degradation the algorithm tunes the discount factor for each agent uniquely, thereby altering the global planning of the agents. Moreover, given the degree of degradation in some agents is expected to change over time, our method provides a framework under which such changes can be incrementally addressed without extensive retraining. Results on benchmark environments show the efficacy of the DSDF approach when compared with existing approaches."
10.5555/3535850.3535998,Epistemic Reasoning in Jason,"This paper presents an extension to the Jason BDI language to allow qualitative reasoning under uncertainty. We demonstrate the need for such an extension using a challenge from the 2019 Multi-Agent Programming Contest (MAPC), namely localization for navigation. Given the ability to qualitatively reason about what the agent knows and what it considers possible (or impossible), these challenges become easier to express, reason about, and act upon in a Jason program.Through the use of epistemic logic and the epistemic reasoner in Hintikka's World, our extension allows agents to express epistemic queries; specifically, utilizing the class of single-agent S5 epistemic models to model-check queries about the agent's uncertainty. This paper also provides an evaluation of the overall performance and scalability of the extension's implementation to show how it impacts the agent's reasoning time; from the evaluation results, we use the official 2019 MAPC time constraints to examine the performance tradeoffs of using the presented extension to model and reason about uncertainty."
10.1145/3583133.3596302,Quantum Enhancements for AlphaZero,"Reinforcement learning algorithms including AlphaZero are powerful artificial intelligence (AI) algorithms, but are known to be resource intensive and unable to train within a reasonable budget. Speeding up learning would be valuable to further expand application areas for real world problems. In this paper, we investigate two quantum computing methods to enhance AlphaZero, with the goal of speeding up training. We evaluate the results by playing the board game Othello, an adversarial multi-agent turn based game similar to the game Go. First, parameterized quantum circuits (PQC) have been shown to train hybrid quantum-classical reinforcement learning agents in standard benchmark environments. With this inspiration, we replace the classical neural network with a PQC quantum neural network (QNN) in the AlphaZero architecture. Second, tensor-network quantum circuits have been used to extract important features for convolutional neural networks (CNNs) in image classification tasks. Using this as inspiration, we use a tree tensor network (TTN) to extract features from the Othello game board, generating a new set of feature vectors for a classical neural network to estimate the policy and value. Results show both novel methods converge to master the game and achieve the same level of play compared to the classical AlphaZero agent."
10.5555/3463952.3464044,Deep Implicit Coordination Graphs for Multi-agent Reinforcement Learning,"Multi-agent reinforcement learning (MARL) requires coordination to efficiently solve certain tasks. Fully centralized control is often infeasible in such domains due to the size of joint action spaces. Coordination graph based formalization allows reasoning about the joint action based on the structure of interactions. However,they often require domain expertise in their design. This paper introduces the deep implicit coordination graph (DICG) architecture for such scenarios. DICG consists of a module for inferring the dynamic coordination graph structure which is then used by a graph neural network based module to learn to implicitly reason about the joint actions or values. DICG allows learning the tradeoff between full centralization and decentralization via standard actor-critic methods to significantly improve coordination for domains with large number of agents. We apply DICG to both centralized-training-centralized-execution and centralized-training-decentralized-execution regimes. We demonstrate that DICG solves the relative over generalization pathology in predatory-prey tasks as well as outperforms various MARL baselines on the challenging StarCraft II Multi-agent Challenge (SMAC) and traffic junction environments."
10.5555/3709347.3743782,Generalised BDI Planning,"Agent interpreters based on the Beliefs, Desires, and Intentions (BDI) model traditionally perform means-ends reasoning using plan libraries composed of reactive planning rules. However, the design of such rules often imposes a heavy knowledge engineering burden on a designer, and trades off flexibility for runtime efficiency. This use of planning rules originates from the limitations of planning technology at the time of the first BDI implementations. While these limitations have gradually been overcome by the integration of various types of planning into existing BDI theories, the corresponding interpreters remain fundamentally plan-library based. In this paper, we develop a novel BDI agent architecture driven by generalised planning as means-ends reasoning, in a radical departure from existing architectures. This architecture has two key properties. First, it more closely resembles the foundations of BDI logic and reasoning. Second, it offers substantial gains in efficiency in comparison with an architecture driven by classical planning."
10.1109/TNET.2023.3289172,Ensuring Threshold AoI for UAV-Assisted Mobile Crowdsensing by Multi-Agent Deep Reinforcement Learning With Transformer,"Unmanned aerial vehicle (UAV) crowdsensing (UCS) is an emerging data collection paradigm to provide reliable and high quality urban sensing services, with age-of-information (AoI) requirement to measure data freshness in real-time applications. In this paper, we explicitly consider the case to ensure that the attained AoI always stay within a specific threshold. The goal is to maximize the total amount of collected data from diverse Point-of-Interests (PoIs) while minimizing AoI and AoI threshold violation ratio under limited energy supplement. To this end, we propose a decentralized multi-agent deep reinforcement learning framework called “DRL-UCS(&lt;inline-formula&gt; &lt;tex-math notation=""LaTeX""&gt;$text {AoI}_{th}$ &lt;/tex-math&gt;&lt;/inline-formula&gt;)” for multi-UAV trajectory planning, which consists of a novel transformer-enhanced distributed architecture and an adaptive intrinsic reward mechanism for spatial cooperation and exploration. Extensive results and trajectory visualization on two real-world datasets in Beijing and San Francisco show that, DRL-UCS(&lt;inline-formula&gt; &lt;tex-math notation=""LaTeX""&gt;$text {AoI}_{th}$ &lt;/tex-math&gt;&lt;/inline-formula&gt;) consistently outperforms all nine baselines when varying the number of UAVs, AoI threshold and generated data amount in a timeslot."
10.5555/3709347.3744089,SmartPilot:Agent-Based CoPilot for Intelligent Manufacturing,"In the dynamic landscape of Industry 4.0, achieving efficiency, precision, and adaptability is essential for optimizing manufacturing operations. SmartPilot is a neurosymbolic and agent-based CoPilot designed to enhance real-time decision-making capabilities in manufacturing. The system addresses three key challenges: anomaly prediction, production forecasting, and domain-specific question answering through an agent-based framework. SmartPilot leverages multimodal data and a compact architecture optimized for edge devices. This paper highlights its innovative combination of agent-based design and neurosymbolic reasoning to enable contextual decision-making in complex environments. The demonstration video, datasets, and supplementary materials are available at https://github.com/ChathurangiShyalika/SmartPilot."
10.1145/3469213.3470712,Design and Realization of Distance Intelligent Learning System Based on Bayesian Network Training,"Modern long-distance teaching utilizes the advantages of Internet information technology, making it not only comparable to traditional teaching in certain typical indicators, but also able to integrate with relevant educational technology, and develop new teaching models that cannot be supported by traditional teaching environments. However, judging from the current situation, most of the distance teaching systems have shortcomings in design. They only digitize the existing teaching models and existing teaching materials and move them to the Internet, which makes the system lacks intelligence and adaptability. It is difficult to provide personalized learning guidance for students' learning differences, and the quality of distance teaching cannot be well guaranteed. This paper proposes an intelligent teaching model based on Bayesian network and multi-agent technology. The teaching model can be different from person to person to formulate and implement guidance strategies, actively collect the most interesting information for learners through the intelligent agent proxy server, and automatically generate various questions and exercises. At the same time, the model uses agent communication protocol to process information through reasonable planning and adjustment of learning content and progress, and allows users to browse. The system can predict user needs, actively formulate learning plans, adjust learning progress, and diagnose learning progress. Problems and errors make them more in line with the learner's knowledge base and cognitive characteristics. Therefore, the teaching model has a certain pertinence and forward-looking."
10.1145/3770857,A BDI Task-oriented Agent in Belief Space,"Building conversational agents to help humans in domain-specific tasks is challenging since the agent needs to understand the natural language and act over it while accessing domain expert knowledge. Modern natural language processing techniques led to an expansion of conversational agents, with recent pretrained language models achieving increasingly accurate language recognition results using ever-larger open datasets. However, the black-box nature of such pretrained language models obscures the agent's reasoning and its motivations when responding, leading to unexplained dialogues. In this work, we develop a belief-desire-intention (BDI) agent as a task-oriented dialogue system to introduce mental attitudes similar to humans describing their behavior during a dialogue. We compare the BDI model with pipeline task-oriented dialogue system architecture by leveraging existing components from dialogue systems and developing the agent's intention selection as a dialogue policy. We show that combining traditional agent modelling approaches, such as BDI, with more recent learning techniques can result in efficient and scrutable dialogue systems."
10.5555/3535850.3535884,Optimizing Multi-Agent Coordination via Hierarchical Graph Probabilistic Recursive Reasoning,"Multi-agent reinforcement learning (MARL) requires coordination by some means of interaction between agents to efficiently solve tasks. Interaction graphs allow reasoning about joint actions based on the local structure of interactions, but they disregard the potential impact of an agent's action on its neighbors' behaviors, which could rapidly alter in dynamic settings. In this paper, we thus present a novel perspective on opponent modeling in domains with only local interactions using (level-1) Graph Probabilistic Recursive Reasoning (GrPR2). Unlike previous work on recursive reasoning, each agent iteratively best-responds to other agents' policies over all possible local interactions. Agents' policies are approximated via a variational Bayes scheme for capturing their uncertainties, and we prove that an induced variant of Q-learning converges under self-play when there exists only one Nash equilibrium. In cooperative settings, we further devise a variational lower bound on the likelihood of each agent's optimality. Opposed to other models, optimizing the resulting objective prevents each agent from attaining an unrealistic modelling of others, and yields an exact tabular Q-iteration method that holds convergence guarantees. Then, we deepen the recursion to level-k via Cognitive Hierarchy GrPR2 (GrPR2-CH), which lets each level-k player best-respond to a mixture of strictly lower levels in the hierarchy. We prove that: (1) level-3 reasoning is the optimal hierarchical level, maximizing each agent's expected return; and (2) the weak spot of the classical CH models is that 0-level is uniformly distributed, as it may introduce policy bias. Finally, we propose a practical actor-critic scheme, and illustrate that GrPR2-CH outperforms strong MARL baselines in the particle environment."
10.1145/3765618,ROS-BDI robots: an agent-based approach for programming the behaviour of autonomous robots,"The Robotic Operating System (ROS) provides resources that facilitate the development of robots. However, these resources do not provide robots with some features required in complex scenarios, such as goal-oriented behaviour, autonomy, deliberative capabilities, social abilities, and proactivity combined with reactivity. On the other hand, these features are inherent to Belief-Desire-Intention (BDI) agents, whose behaviour results from reasoning over explicit representations of their beliefs (information about the environment), desires (goals to be achieved), and intentions (commitments to those goals). This work addresses the integration between ROS and BDI agents. This integration is addressed both at a conceptual level, where ROS and BDI concepts are aligned, and in a more practical level, where programming tools are presented to program the behaviour of ROS-based robots as BDI agents. The proposal is evaluated through application examples. The results of this work include an integration model and tools to develop these robots."
10.5555/3398761.3398771,Explainable Multi Agent Path Finding,"Multi Agent Path Finding (MAPF) is the problem of planning paths for agents to reach their targets from their start locations, such that the agents do not collide while executing the plan. In safety-critical systems, the plan is typically checked by a human supervisor, who decides on whether to allow its execution. In such cases, we wish to convince the human that the plan is indeed collision free.To this end, we propose an explanation scheme for MAPF, which bases explanations on simplicity of visual verification by human's cognitive process. The scheme decomposes a plan into segments such that within each segment, the paths of the agents are disjoint. Then, we can convince the supervisor that the plan is collision free using a small number of images (dubbed an explanation). In addition, we can measure the simplicity of a plan by the number of segments required for the decomposition. We study the complexity of algorithmic problems that arise by the explanation scheme, as well as the tradeoff between the length (makespan) of a plan and its minimal decomposition. We also provide experimental results of our scheme both in a continuous and in a discrete setting."
10.1145/3461702.3462515,A Multi-Agent Approach to Combine Reasoning and Learning for an Ethical Behavior,"The recent field of Machine Ethics is experiencing rapid growth to answer the societal need for Artificial Intelligence (AI) algorithms imbued with ethical considerations, such as benevolence toward human users and actors. Several approaches already exist for this purpose, mostly either by reasoning over a set of predefined ethical principles (Top-Down), or by learning new principles (Bottom-Up). While both methods have their own advantages and drawbacks, only few works have explored hybrid approaches, such as using symbolic rules to guide the learning process for instance, combining the advantages of each. This paper draws upon existing works to propose a novel hybrid method using symbolic judging agents to evaluate the ethics of learning agents' behaviors, and accordingly improve their ability to ethically behave in dynamic multi-agent environments. Multiple benefits ensue from this separation between judging and learning agents: agents can evolve (or be updated by human designers) separately, benefiting from co-construction processes; judging agents can act as accessible proxies for non-expert human stakeholders or regulators; and finally, multiple points of view (one per judging agent) can be adopted to judge the behavior of the same agent, which produces a richer feedback. Our proposed approach is applied to an energy distribution problem, in the context of a Smart Grid simulator, with continuous and multi-dimensional states and actions. The experiments and results show the ability of learning agents to correctly adapt their behaviors to comply with the judging agents' rules, including when rules evolve over time."
10.1145/3746276.3760471,ZJUT-MM@MUCG Challenge: Agent Network for Multimodal Video Understanding,"This technical report presents an Agent Network architecture for complex multimodal video understanding, developed for the MUCG Video Comprehension scope. The framework is built on the Model Context Protocol (MCP), enabling standardized, provider-agnostic integration of heterogeneous tools. It adopts a three-layer hierarchy: an Orchestrator Agent for task classification and schema injection, a Thinking Agent for reasoning and planning, and multiple Expert Agents for specialized capabilities such as captioning, detection, tracking, zoom-in analysis, optical flow, and depth estimation. Guided by the ReAct cognitive paradigm, the Thinking Agent performs iterative ''Thinking–Acting–Observing'' cycles to decompose tasks, invoke tools, and refine results. An adaptive refinement mechanism further enhances performance through progressive frame sampling and LLM-based self-evaluation, balancing computational efficiency with reasoning quality. This modular and scalable design enables robust handling of diverse long-video tasks and produces benchmark-ready, structured outputs for evaluation. The code is released at https://github.com/wangzheng17/ZJUT-MM-MUCG25."
10.1145/3768292.3771251,Structured Agentic Workflows for Financial Time-Series Modelling with LLMs and Reflective Feedback,"Time-series data is central to decision-making in financial markets, yet building high-performing, interpretable, and auditable models remains a major challenge. While Automated Machine Learning (AutoML) frameworks streamline model development, they often lack adaptability and responsiveness to domain-specific needs and evolving objectives. Concurrently, Large Language Models (LLMs) have enabled agentic systems capable of reasoning, memory management, and dynamic code generation, offering a path toward more flexible workflow automation. In this paper, we introduce TS-Agent, a modular agentic framework designed to automate and enhance time-series modeling workflows for financial applications. The agent formalizes the pipeline as a structured, iterative decision process across three stages: model selection, code refinement, and fine-tuning, guided by contextual reasoning and experimental feedback. Central to our architecture is a planner agent equipped with structured knowledge banks, curated libraries of models and refinement strategies, which guide exploration, while improving interpretability and reducing error propagation. TS-Agent supports adaptive learning, robust debugging, and transparent auditing, key requirements for high-stakes environments such as financial services. Empirical evaluations on diverse financial forecasting and synthetic data generation tasks demonstrate that TS-Agent consistently outperforms state-of-the-art AutoML and agentic baselines, achieving superior accuracy, robustness, and decision traceability."
10.5555/3635637.3662942,BDI Agents in Natural Language Environments,"Developing autonomous agents to deal with real-world problems is challenging, especially when developers are not necessarily specialists in artificial intelligence. This poses two key challenges regarding the interface of the programming with the developer, and the efficiency of the resulting agents. In this paper we tackle both challenges in an efficient agent architecture that leverages recent developments in natural language processing, and the intuitive folk psychology abstraction of the beliefs, desires, intentions (BDI) architecture. The resulting architecture uses existing reinforcement learning techniques to bootstrap the agent's reasoning capabilities while allowing a developer to instruct the agent more directly using natural language as its programming interface. We empirically show the efficiency gains of natural language plans over a pure machine learning approach in the ScienceWorld environment."
10.1145/3765286,TableTalk: Scaffolding Spreadsheet Development with a Language Agent,"Spreadsheet programming is challenging. Programmers use spreadsheet programming knowledge (e.g., formulas) and problem-solving skills to combine actions into complex tasks. Advancements in large language models have introduced language agents that observe, plan, and perform tasks, showing promise for spreadsheet creation. We present TableTalk, a spreadsheet programming agent embodying three design principles—scaffolding, flexibility, and incrementality—derived from studies with seven spreadsheet programmers and 85 Excel templates. TableTalk guides programmers through structured plans based on professional workflows, generating three potential next steps to adapt plans to programmer needs. It uses pre-defined tools to generate spreadsheet components and incrementally build spreadsheets. In a study with 20 programmers, TableTalk produced higher-quality spreadsheets 2.3 times more likely to be preferred than the baseline. It reduced cognitive load and thinking time by 12.6\%. From this, we derive design guidelines for agentic spreadsheet programming tools and discuss implications on spreadsheet programming, end-user programming, AI-assisted programming, and human-agent collaboration."
10.1145/3708319.3734180,MoRTELaban: a Neurosymbolic Framework for Motion Representation and Analysis based on Labanotation and Laban Movement Analysis,"Human motion cannot be fully modeled by subsymbolic representations. While these extract precise hidden patterns in motion data, they are often task-specific and lack a semantic understatement of motion. Symbolic systems that mirror human cognition and explicit expressive processes are necessary for richer motion synthesis and analysis, enabling physical reasoning and expert knowledge encoding. In this work, we propose a neurosymbolic framework that combines Labanotation and Laban Movement Analysis (LMA), originally developed for dance, to represent and analyze human motion symbolically. We expand the existing LabanEditor to support full-body annotation and integrate it with AMASS, Mediapipe, and Kinect inputs through a SMPL-based format. Our system supports automatic annotation for the local functional and expressive aspects of motion, and enables bidirectional conversion between symbols and motion. While still a work in progress, this framework lays the groundwork for explainable, expressive motion modeling that can support human-robot interaction, motion preservation, and psychomotor learning systems."
10.5555/3635637.3663257,Empowering BDI Agents with Generalised Decision-Making,"While research on software agents has long focused on explicit agent communication, there is comparatively less effort on implicit communication between agents via recognising each other's intentions and desires for understanding their decision-making reasoning process. Since most human communication is not explicit, we aim to outline a research agenda to help endow autonomous agents with analogous coordination capabilities. In this paper, we formalise a framework that empowers the decision-making process of BDI agents in adversarial and cooperative environments by casting them as generalised planners using Theory of Mind. Our formalisation uses the fundamental philosophical properties of the BDI model and its reasoning process to outline a broad research agenda in agents' research."
10.5555/3709347.3744038,Grounding Agent Reasoning in Image Schemas: A Neurosymbolic Approach to Embodied Cognition,"Despite advances in embodied AI, agent reasoning systems still struggle to capture the fundamental conceptual structures that humans naturally use to understand and interact with their environment. To address this, we propose a novel framework that bridges embodied cognition theory and agent systems by leveraging a formal characterization of image schemas, which are defined as recurring patterns of sensorimotor experience that structure human cognition. By customizing LLMs to translate natural language descriptions into formal representations based on these sensorimotor patterns, we will be able to create a neurosymbolic system that grounds the agent's understanding in fundamental conceptual structures. We argue that such an approach enhances both efficiency and interpretability while enabling more intuitive human-agent interactions through shared embodied understanding."
10.1145/3708319.3733667,Computational Models of Cognitive and Affective Theory of Mind,"Theory of Mind is described as the capability to attribute mental states to oneself and others, and it can be essential for robots to favor more collaborative, adaptive, and emotionally appropriate behaviors when they are deployed in human-centered environments. In this work, we survey existing methodologies to introduce ToM in Human-Robot Interaction, focusing on two main formalizations: Cognitive ToM, focusing on reasoning about beliefs and intentions in a more task oriented way, and Affective ToM, which requires the agent to recognize and adapt to others’ emotional states. While both approaches have advanced robot adaptability and user engagement, they are often developed in isolation. For this reason, we will discuss the need for integrated models that combine cognitive and affective reasoning, and outline future directions for more socially intelligent and emotionally aware robotic systems."
10.1145/3731599.3767401,Agentic AI vs ML-based Autotuning: A Comparative Study for Loop Reordering Optimization,"High Performance Computing (HPC) applications rely heavily on code optimizations to achieve good performance on modern CPU and GPU architectures. Traditional Machine Learning autotuning approaches have demonstrated success in exploring high-dimensional spaces, but they often require expensive compile-run evaluations and lack adaptability for large HPC applications. The recent advances in Large Language Models (LLMs) and Agentic AI systems raise intriguing questions about the potential of these approaches to address specific optimization methodologies. This work aims to answer an essential question for the HPC community: ""How Agentic AI Systems Compare to Traditional ML Autotuning Techniques?"" To address this question, we present a comparative analysis between a traditional ML-based optimization approach and an Agentic AI system, evaluating their respective capabilities and limitations for loop-level optimization. In addition, we introduced a new Agentic AI system named LoopGen-AI using three different Large Language Models: GPT-4.1, Claude 4.0, and Gemini 2.5. A key finding is that LoopGen-AI achieves competitive performance with only a few program runs, the reasoning logs from the agents revealed that their decisions rely heavily on the combination of semantic understanding of the target kernel with dynamic feedback from the environment, highlighting a promising new dimension in performance tuning. In contrast, ML-based autotuners focus on statistical exploration, and require orders of magnitude more runs to reach peak performance. Additionally, our analysis shows that prompt engineering, particularly using Persona + Context Manager patterns, significantly impacts the effectiveness of Agentic AI. Our results indicate that while Agentic AI systems are not yet a complete replacement for ML-based autotuners, it can effectively complement traditional methods."
10.1145/3746027.3755643,The Eye of Sherlock Holmes: Uncovering User Private Attribute Profiling via Vision-Language Model Agentic Framework,"Our research reveals a new privacy risk associated with the vision language model (VLM) agentic framework: the ability to infer sensitive attributes (e.g., age and health information) and even abstract ones (e.g., personality and social traits) from a set of personal images, which we term ''image private attribute profiling.'' This threat is particularly severe given that modern apps can easily access users' photo albums, and inference from image sets enables models to exploit inter-image relations for more sophisticated profiling. However, two main challenges hinder our understanding of how well VLMs can profile an individual from a few personal photos: (1) the lack of benchmark datasets with multi-image annotations for private attributes, and (2) the limited ability of current multimodal large language models (MLLMs) to infer abstract attributes from large image collections. In this work, we construct PAPI, the largest dataset for studying private attribute profiling in personal images, comprising 2,510 images from 251 individuals with 3,012 annotated privacy attributes. We also propose HolmesEye, a hybrid agentic framework that combines VLMs and LLMs to enhance privacy inference. HolmesEye uses VLMs to extract both intra-image and inter-image information and LLMs to guide the inference process as well as consolidate the results through forensic analysis, overcoming existing limitations in long-context visual reasoning. Experiments reveal that HolmesEye achieves a 10.8\% improvement in average accuracy over state-of-the-art baselines and surpasses human-level performance by 15.0\% in predicting abstract attributes. This work highlights the urgency of addressing privacy risks in image-based profiling and offers both a new dataset and an advanced framework to guide future research in this area."
10.5555/3709347.3743841,Logic of Knowledge and Cognitive Ability,"Along with the convenience brought by the increasing usage of autonomous systems, unexpected accidents happened. These accidents emphasize the need for autonomous systems to possess the ability to recognize potential hazards, effectively communicate these hazards to human operators, and facilitate retrospective analyses. This ability, including recognition, prejudgment, post-analysis, and reasoning, falls within the realm of cognitive ability, which is important in improving the safety and outcomes in the decision-making process of such systems. In this paper, we present a foundational step toward addressing the safety challenges involving the cognitive ability of artificial agents. We study the interplay between knowledge and the cognitive ability of intelligent agents. The main technical result is a sound and complete bimodal logical system that describes the interplay between the knowledge and cognitive ability modalities."
10.5555/3635637.3663048,Enabling BDI Agents to Reason on a Dynamic Action Repertoire in Hypermedia Environments,"Autonomy requires adaptability and persistence in pursuing long-term objectives within evolving contexts. While BDI agents can cope with dynamic and uncertain environments, their adaptability is typically constrained by static action repertoires, known a priori by designers. Through Semantic Web and Web of Things technologies, machine-readable action descriptions can be discovered in hypermedia environments, and updated dynamically to mirror the evolving landscape of actions offered by real-world environments. This paper proposes the integration of action-oriented BDI reasoning with signifiers that reveal information about action possibilities that may appear, disappear, or be modified in a hypermedia environment at any time. We extend the means-end reasoning of BDI agents with a mechanism for resolving signifiers discovered at run time into actions, which enables agents to adjust their decision-making based on action possibilities advertised in the environment. We evaluate our approach through experiments, where Jason agents discover signifiers expressed with available Web ontologies. The results demonstrate that our signifier resolution mechanism enhances action reasoning at run time towards effective goal achievement in dynamic and unknown environments."
10.5555/3709347.3743552,Feature Engineering for Agents: An Adaptive Cognitive Architecture for Interpretable ML Monitoring,"Monitoring Machine Learning (ML) models in production environments is crucial, yet traditional approaches often yield verbose, low-interpretability outputs that hinder effective decision-making. We propose a cognitive architecture for ML monitoring that applies feature engineering principles to agents based on Large Language Models (LLMs), significantly enhancing the interpretability of monitoring outputs. Central to our approach is a Decision Procedure module that simulates feature engineering through three key steps: Refactor, Break Down, and Compile. The Refactor step improves data representation to better capture feature semantics, allowing the LLM to focus on salient aspects of the monitoring data while reducing noise and irrelevant information. Break Down decomposes complex information for detailed analysis, and Compile integrates sub-insights into clear, interpretable outputs. This process leads to a more deterministic planning approach, reducing dependence on LLM-generated planning, which can sometimes be inconsistent and overly general. The combination of feature engineering-driven planning and selective LLM utilization results in a robust decision support system, capable of providing highly interpretable and actionable insights. Experiments using multiple LLMs demonstrate the efficacy of our approach, achieving significantly higher accuracy compared to various baselines across several domains."
10.1145/3746027.3762011,Agent-MER: A Cognitive Agent with Hierarchical Deliberation for Open-Vocabulary Multimodal Emotion Recognition,"This paper focuses on Open-Vocabulary Multimodal Emotion Recognition (OV-MER) and is dedicated to solving the two challenges it faces: concept semantic misalignment and incomplete coverage of fine-grained emotion categories. To address this, we propose a novel cognitive agent framework (Agent-MER), which reframes the OV-MER task as a problem to be solved by an agent that mimics the human cognitive process through knowledge-guided deliberation. We first construct a hierarchical Emotion Tree to serve as the agent's knowledge base. Building on this, we design a Knowledge-Guided Hierarchical Deliberation reasoning process. This process systematically explores the entire emotional landscape through a three-level, coarse-to-fine iterative reasoning process, enabling the identification of a richer and deeper range of emotions. Finally, a Self-Consistent Voting mechanism is employed to aggregate the results from multiple reasoning runs, ensuring the robustness of the final output. Experiments conducted in the MER2025 Challenge demonstrate that our proposed method achieved a top-ranking score of 61.04\%, securing first place and significantly outperforming existing baselines. This work not only provides an effective solution for OV-MER but also opens up new avenues for developing more human-like affective intelligence systems."
10.1145/3717511.3747067,"BEE: Belief-Value-Aligned, Explainable, and Extensible Cognitive Framework for Conversational Agents","Recent advances in large language models have enabled virtual agents to exhibit increasingly believable social behaviors. However, creating social agents that remain consistent with a defined profile and explain their reasoning remains challenging. We introduce a cognitive framework designed to address these gaps. Our framework features a graph-based memory module (concept pool) and a decision-making process inspired by human cognition. The concept pool contains an agent’s beliefs, values, and background stories for context-dependent retrieval. The decision-making process uses the concept pool to produce belief-value aligned responses of the virtual agent and intuitive, human-readable explanations of the reasoning. To evaluate the effectiveness of our framework, we created two virtual agents based on historical figures and compared them to baseline agents. Our evaluation combined quantitative assessments of belief-value alignment with a user study (n=48) examining explainable agency. Results show that our framework exhibits model-agnostic improved belief-value alignment and produces more detailed, relevant, and understandable explanations. By grounding virtual agent behavior in structured memories and cognitive principles, our framework offers a compelling step toward more coherent and socially intelligent virtual agents."
10.5555/3709347.3743564,Azorus: Commitments over Protocols for BDI Agents,"Commitments support flexible interactions between agents by capturing the meaning of their interactions. However, commitment-based reasoning is not adequately supported in agent programming models. We contribute Azorus, a programming model based on declarative specifications centered on commitments and aligned with information protocols. Azorus supports reasoning about goals and commitments and combines modeling of commitments and protocols, thereby uniting three leading declarative approaches to engineering decentralized multiagent systems. Specifically, we realize Azorus over three existing technology suites: (1) Jason, a popular BDI-based programming model; (2) Cupid, a formal language and query-based model for commitments; and (3) BSPL, a language and its associated tools for information protocols, including Jason programming. We implement Azorus and demonstrate how it enables capturing interesting patterns of business logic."
10.1145/3746277.3760412,Multimodal Trait and Emotion Recognition via Agentic AI: An End-to-End Pipeline,"This paper describes an end-to-end, modular, agentic system for inferring personality traits and emotional states based on multimodal interview-style data, when behavioral metadata (response time, body language, speech features, etc.) are made available. The system architecture consisted of a Perception Agent for classifying the emotions, an Inference Agent for estimating Big Five personality traits, and a Dialogue Agent for producing psychologically informed responses. A retrieval-augmented memory module connected the three agents to maintain context and continuity in the dialogue. The agents used two different language model backbones, LLaMA 3.2 1B and Falcon-RW-1B, learning and reasoning within the same processing pipeline while evaluating their performance on a benchmark of 19 annotated queries across a range of emotional states, conversation scenarios, and context. The evaluation assessed processing latency, lexical diversity, and consistency of trait estimation. The key finding for this study was that integrating metadata and modular reasoning leads to more contextually relevant and empathic responses than just prompting the agent. LLaMA produced longer, richer, and more diverse output while Falcon scores a much lower latency with shorter, predictable, and consistent responses. Overall, this study demonstrates that the combination of multimodal affective signals and agentic reasoning can lead to better human–AI interaction. While the work presented here is a proof-of-concept that is constrained by a benchmark experiment, it lays the grounds for scaling response models beyond the types of responses evaluated in this study, introduces more evaluation metrics, and enables more robust personalization features in future dialogue systems."
10.1145/3623385,“Do This Instead”—Robots That Adequately Respond to Corrected Instructions,"Natural language instructions are effective at tasking autonomous robots and for teaching them new knowledge quickly. Yet, human instructors are not perfect and are likely to make mistakes at times and will correct themselves when they notice errors in their own instructions. In this article, we introduce a complete system for robot behaviors to handle such corrections, during both task instruction and action execution. We then demonstrate its operation in an integrated cognitive robotic architecture through spoken language in two tasks: a navigation and retrieval task and a meal assembly task. Verbal corrections occur before, during, and after verbally taught sequences of tasks, demonstrating that the proposed methods enable fast corrections not only of the semantics generated from the instructions but also of overt robot behavior in a manner shown to be reasonable when compared to human behavior and expectations."
10.5555/3382225.3382387,Enhancing diffusion models by embedding cognitive reasoning,"Diffusion models are powerful tools for understanding the spread of diverse content such as information, opinions and ideas through social networks. Although these models have been successfully used to study the spreading dynamics such as viral marketing, there are many real scenarios (e.g. vaccination, evacuation) that require a more complex model. Hence, we propose a new hybrid framework that combines diffusion modelling with cognitive agent modelling. The hybrid, generic framework is grounded on BDI (Belief-Desire-Intention), an advanced, efficient cognitive agent framework. We demonstrate our framework to a wildfire evacuation case study consisting of 5,000 agents. We then compare and analyse the diffusion outcomes of our model against two baseline models, the standard Linear Threshold (LT) model and a slightly modified version of the LT model, across 17 different input configurations. The results show (statistically) significant differences with the baselines for the majority of the configurations, highlighting the need for cognitive agents in diffusion modelling. The framework presented here provides the basis for modelling complex reasoning to capture diffusion phenomena in complex and dynamic social systems."
10.1145/3712672,A Cyber-War Between Bots: Cognitive Attackers are More Challenging for Defenders than Strategic Attackers,"Adversary emulation is commonly used to test cyber-defense performance against known threats to organizations. However, many adversary emulation methods often rely on automated planning and underplay the role of human cognition. Consequently, defenders are often underprepared for human attackers who can think creatively and adapt their strategies. In this article, we propose the design of adversarial cognitive agents that are dynamic, adaptable, and able to learn from experience. These cognitive agents are built based on the theoretical principles of Instance-Based Learning Theory (IBLT) of experiential choice in dynamic tasks, making them more challenging than strategically optimal adversaries for human defenders. Our research offers three main contributions. First, in a simulation experiment, we demonstrate how IBL attacker agents can learn from experience and become as efficient as optimal strategic algorithms against a strategic defender. In a second simulation experiment, the IBL attackers are pitted against an IBL defender, showing that the IBL attacker can be a more challenging adversary for the IBL defender, while the IBL defender can learn to counter carefully crafted optimal attack strategies. To test these observations, we conducted a third experiment, where humans played the role of defenders against both strategic and IBL attackers in an interactive task. The results confirm the predictions of the second simulation experiment: Cognitive attackers are more challenging for human defenders than strategic attackers. These insights contribute to informing future adversary emulation efforts and training of cyber defenders."
10.5555/3721488.3721763,Demonstration of an Open-source ROS 2 Framework and Simulator for Situated Interactive Social Robot,"We introduce an open-source ROS 2 architecture for situated social robots, along with a simulator that allows mixed-reality development and interactions. The architecture is a hybrid symbolic/subsymbolic system that integrates explicit ontology semantics for perception, reasoning, and execution, with LLMs. It features multimodal social perception by leveraging the open source ROS4HRI framework; LLMs (both edge- and cloud-based) to facilitate natural language interaction between the user and system; KnowledgeCore, an open-source knowledge base, to reason about facts in the world; and an intent-based controller to supervise the execution of parallel/sequential tasks and skills. We demonstrate our system architecture with a social robot running the mixed-reality system."
10.1145/3716553.3750759,Using a Secondary Channel to Display the Internal Empathic Resonance of LLM-Driven Agents for Mental Health Support,"Conversational agents are becoming increasingly popular for digital mental health support. However, while empathy is essential for effective emotional support, the unimodal request-response interaction of such systems limits empathic communication. We address this limitation through a secondary channel that displays an agent’s inner reflections, similar to how nonverbal feedback in human interaction conveys cognitive and emotional states. We implemented a chatbot that generates not only conversational responses but also describes internal reasoning and emotional resonance. A user study involving N = 188 participants indicated a statistically significant increase in perceived empathy ( (+14.7\%) ) when the agent’s internal reflections were displayed. Our findings demonstrate a practical method to enhance empathic interaction with LLM-based chatbots in empathy-critical contexts. Additionally, this work opens possibilities for multimodal systems where LLM-generated reflections may serve as input for generating nonverbal feedback."
10.1145/3746027.3755832,CogDDN: A Cognitive Demand-Driven Navigation with Decision Optimization and Dual-Process Thinking,"Mobile robots are increasingly required to navigate and interact within unknown and unstructured environments to meet human demands. Demand-driven navigation (DDN) enables robots to identify and locate objects based on implicit human intent, even when object locations are unknown. However, traditional data-driven DDN methods rely on pre-collected data for model training and decision-making, limiting their generalization capability in unseen scenarios. In this paper, we propose CogDDN, a VLM-based framework that emulates the human cognitive and learning mechanisms by integrating fast and slow thinking systems and selectively identifying key objects essential to fulfilling user demands. CogDDN identifies appropriate target objects by semantically aligning detected objects with the given instructions. Furthermore, it incorporates a dual-process decision-making module, comprising a Heuristic Process for rapid, efficient decisions and an Analytic Process that analyzes past errors, accumulates them in a knowledge base, and continuously improves performance. Chain of Thought (CoT) reasoning strengthens the decision-making process. Extensive closed-loop evaluations on the AI2Thor simulator with the ProcThor dataset show that CogDDN outperforms single-view camera-only methods by 15\%, demonstrating significant improvements in navigation accuracy and adaptability. The project page is available at https://yuehaohuang.github.io/CogDDN/."
10.1145/3746252.3761059,DIVAgent: A Diversified Search Agent that Mimics the Human Search Process,"Search result diversification plays a crucial role in addressing query ambiguity and multi-faceted information needs by reducing redundancy across documents. While previous supervised approaches can achieve superior performance, they require costly, large-scale annotated data. In contrast, unsupervised methods are more flexible and training-free but rely on manually designed ranking functions, often leading to suboptimal performance. Inspired by how humans explore diverse information during real-world searching, we propose a diversified search agent DIVAgent to combine the advantages of supervised and unsupervised methods. DIVAgent introduces LLMs as the ''brain'' to reason over complex and diverse search results and delineate human cognitive processes into a workflow tailored for search result diversification. Our search agent first identifies potential user intents and then analyzes the alignment of each document to the intents via an intent-aware module. To guide the generation of diversified document rankings, we design an intent-guided ranker that explicitly links documents to their dominant intents while performing greedy document selection. Experimental results demonstrate that DIVAgent significantly outperforms existing unsupervised baselines and achieves competitive performance with supervised models, highlighting the promise of LLMs for diversified ranking in realistic search scenarios."
10.1145/3623387,"UHTP: A User-Aware Hierarchical Task Planning Framework for Communication-Free, Mutually-Adaptive Human-Robot Collaboration","Collaborative human-robot task execution approaches require mutual adaptation, allowing both the human and robot partners to take active roles in action selection and role assignment to achieve a single shared goal. Prior works have utilized a leader-follower paradigm in which either agent must follow the actions specified by the other agent. We introduce the User-aware Hierarchical Task Planning (UHTP) framework, a communication-free human-robot collaborative approach for adaptive execution of multi-step tasks that moves beyond the leader-follower paradigm. Specifically, our approach enables the robot to observe the human, perform actions that support the human’s decisions, and actively select actions that maximize the expected efficiency of the collaborative task. In turn, the human chooses actions based on their observation of the task and the robot, without being dictated by a scheduler or the robot. We evaluate UHTP both in simulation and in a human subjects experiment of a collaborative drill assembly task. Our results show that UHTP achieves more efficient task plans and shorter task completion times than non-adaptive baselines across a wide range of human behaviors, that interacting with a UHTP-controlled robot reduces the human’s cognitive workload, and that humans prefer to work with our adaptive robot over a fixed-policy alternative."
10.1145/3746059.3747789,Cooperative Design Optimization through Natural Language Interaction,"Designing successful interactions requires identifying optimal design parameters. To do so, designers often conduct iterative user testing and exploratory trial-and-error. This involves balancing multiple objectives in a high-dimensional space, making the process time-consuming and cognitively demanding. System-led optimization methods, such as those based on Bayesian optimization, can determine for designers which parameters to test next. However, they offer limited opportunities for designers to intervene in the optimization process, negatively impacting the designer’s experience. We propose a design optimization framework that enables natural language interactions between designers and the optimization system, facilitating cooperative design optimization. This is achieved by integrating system-led optimization methods with Large Language Models (LLMs), allowing designers to intervene in the optimization process and better understand the system’s reasoning. Experimental results show that our method provides higher user agency than a system-led method and shows promising optimization performance compared to manual design. It also matches the performance of an existing cooperative method with lower cognitive load."
10.1145/3757887.3763009,Epistemic vs. Counterfactual Fairness in Allocation of Resources,"Resource allocation is fundamental to a variety of societal decision-making settings, ranging from the distribution of charitable donations to assigning limited public housing among interested families. A central challenge in this context is ensuring fair outcomes, which often requires balancing conflicting preferences of various stakeholders. While extensive research has been conducted on theoretical and algorithmic solutions within the fair division framework, much of this work neglects the subjective perception of fairness by individuals. This study focuses on the fairness notion of envy-freeness (EF), which ensures that no agent prefers the allocation of another agent according to their own preferences. While the existence of exact EF allocations may not always be feasible, various approximate relaxations, such as counterfactual and epistemic EF, have been proposed. Through a series of experiments with human participants, we compare perceptions of fairness between three widely studied counterfactual and epistemic relaxations of EF. Our findings indicate that allocations based on epistemic EF are perceived as fairer than those based on counterfactual relaxations. Additionally, we examine a variety of factors, including scale, balance of outcomes, and cognitive effort involved in evaluating fairness and their role in the complexity of reasoning across treatments."
10.1145/3764921.3770147,Experiential geosimulation,"We introduce experiential geosimulation as a medium for co-exploring embodied behavioral geography, physical locomotion and sensorimotor control, and spatial vision and perception. Methodologically, this convergence is approached through interconnection of high-fidelity geographic automata systems, running in virtual geographic environments within virtual reality head-mounted displays, while spatial telematics and neural activity are collected through eye tracking on a single-board computer and encephalography (EEG) is processed from a scalp-mounted brain-computer interface. Data exchange between these diverse geographic information systems allows for the creation of synthetic simulation scenarios that can evoke realistic locomotion and task behavior from real, physically involved human users. Here, we show that the system also entices people's realistic neural activity, which can provide insight into users' experiences as navigation, agency, spatial vision, landmark salience, non-verbal communications, and cognitive where/what reasoning."
10.1145/3757566,"Co-Writing with AI, on Human Terms: Aligning Research with User Demands Across the Writing Process","As generative AI tools like ChatGPT become integral to everyday writing, critical questions arise about how to preserve writers' sense of agency and ownership when using these tools. Yet, a systematic understanding of how AI assistance affects different aspects of the writing process-and how this shapes writers' agency-remains underexplored. To address this gap, we conducted a systematic review of 109 HCI papers using the PRISMA approach. From this literature, we identify four overarching design strategies for AI writing support-structured guidance, guided exploration, active co-writing, and critical feedback-mapped across the four key cognitive processes in writing: planning, translating, reviewing, and monitoring. We complement this analysis with interviews of 15 writers across diverse domains. Our findings reveal that writers' desired levels of AI intervention vary across the writing process: content-focused writers (e.g., academics) prioritize ownership during planning, while form-focused writers (e.g., creatives) value control over translating and reviewing. Writers' preferences are also shaped by contextual goals, values, and notions of originality and authorship. By examining when ownership matters, what writers want to own, and how AI interactions shape agency, we surface both alignment and gaps between research and user needs. Our findings offer actionable design guidance for developing human-centered writing tools for co-writing with AI, on human terms."
10.1145/3411764.3445109,Disagree? You Must be a Bot! How Beliefs Shape Twitter Profile Perceptions,"In this paper, we investigate the human ability to distinguish political social bots from humans on Twitter. Following motivated reasoning theory from social and cognitive psychology, our central hypothesis is that especially those accounts which are opinion-incongruent are perceived as social bot accounts when the account is ambiguous about its nature. We also hypothesize that credibility ratings mediate this relationship. We asked N = 151 participants to evaluate 24 Twitter accounts and decide whether the accounts were humans or social bots. Findings support our motivated reasoning hypothesis for a sub-group of Twitter users (those who are more familiar with Twitter): Accounts that are opinion-incongruent are evaluated as relatively more bot-like than accounts that are opinion-congruent. Moreover, it does not matter whether the account is clearly social bot or human or ambiguous about its nature. This was mediated by perceived credibility in the sense that congruent profiles were evaluated to be more credible resulting in lower perceptions as bots."
10.1145/3733155.3733211,Indoor Turn-By-Turn Navigation Assistance for Robotic Rollators,"Navigating indoor environments poses significant challenges for individuals with mobility and cognitive impairments, impacting their independence and quality of life. While robotic rollators have shown potential in providing mobility assistance, existing systems often rely on static navigation approaches that lack a capacity to dynamically adapt to path changes and unforeseen deviations. This paper addresses this gap by introducing a dynamic turn-by-turn navigation system designed to provide real-time, user-centered guidance. The system aims to enhance spatial orientation and wayfinding through online dynamic planning, addressing critical limitations of current solutions. We present results from user trials in a simulated environment, which show its potential to improve mobility. Possible areas of improvement are also discussed, paving the way for more effective assistive technologies in real-world settings."
10.1145/3677052.3698597,"FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning","Financial intelligence generation from vast data sources has typically relied on traditional methods of knowledge-graph construction or database engineering. Recently, fine-tuned financial domain-specific Large Language Models (LLMs), have emerged. While these advancements are promising, limitations such as high inference costs, hallucinations, and the complexity of concurrently analyzing high-dimensional financial data, emerge. This motivates our invention FISHNET (Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert swarming, and Task planning), an agentic architecture that accomplishes highly complex analytical tasks for more than 98,000 regulatory filings that vary immensely in terms of semantics, data hierarchy, or format. FISHNET shows remarkable performance for financial insight generation (61.8\% success rate over 5.0\% Routing, 45.6\% RAG R-Precision). We conduct rigorous ablations to empirically prove the success of FISHNET, each agent’s importance, and the optimized performance of assembling all agents. Our modular architecture can be leveraged for a myriad of use-cases, enabling scalability, flexibility, and data integrity that are critical for financial tasks."
10.1145/3701716.3717565,CubeRobot: Grounding Language in Rubik's Cube Manipulation via Vision-Language Model,"Proving Rubik's Cube theorems at the high level represents a notable milestone in human-level spatial imagination and logic thinking and reasoning. Traditional Rubik's Cube robots, relying on complex vision systems and fixed algorithms, often struggle to adapt to complex and dynamic scenarios. To overcome this limitation, we introduce CubeRobot, a novel vision-language model (VLM) tailored for solving 3x3 Rubik's Cubes, empowering embodied agents with multimodal understanding and execution capabilities. We used the CubeCoT image dataset, which contains multiple-level tasks (43 subtasks in total) that humans are unable to handle, encompassing various cube states. We incorporate a dual-loop VisionCoT architecture and Memory Stream, a paradigm for extracting task-related features from VLM-generated planning queries, thus enabling CubeRobot to independent planning, decision-making, reflection and separate management of high- and low-level Rubik's Cube tasks. Furthermore, in low-level Rubik's Cube restoration tasks, CubeRobot achieved a high accuracy rate of 100\%, similar to 100\% in medium-level tasks, and achieved an accuracy rate of 80\% in high-level tasks."
10.1145/3746027.3755537,GraphVideoAgent: Enhancing Long-form Video Understanding with Entity Relation Graphs,"Long-form video understanding (LVU) addresses the challenge of answering complex questions over extended video length, where informative cues are sparse and easily overwhelmed by redundant content. To tackle this, it requires selecting a small set of question-relevant keyframes and reasoning over long-range, temporally dispersed visual evidence. However, current methods typically extract frame-level features with limited temporal context and store them in sequential memory structures. As a result, they struggle to capture the evolving relations among entities and fail to maintain identity consistency when entities temporarily leave and later reappear in the video. These limitations prevent accurate keyframe localization and coherent reasoning.In this paper, we propose GraphVideoAgent, a novel agent-based LVU framework that integrates a dynamic entity relation graph with a large language model (LLM)-based multi-round reasoning. Our framework emulates human cognitive strategies by iteratively retrieving keyframes and explicitly tracking both temporal and semantic interactions among entities. Our GraphVideoAgent iteratively reflects on question cues and visual observations, while the graph memory maintains a structured representation of evolving entity states and their causal relations. This design enables accurate keyframe selection, effective reasoning over sparse visual evidence, and interpretable prediction. Extensive experiments on two LVU benchmarks, EgoSchema and NExT-QA, demonstrate that GraphVideoAgent achieves state-of-the-art performance while using only 8.2 and 8.1 frames on average, significantly improving both accuracy and efficiency."
10.5555/3635637.3662884,Fast and Slow Goal Recognition,"Goal recognition is a crucial aspect of understanding the intentions and objectives of agents by observing some of their actions. The most prominent approaches to goal recognition can be divided into two main categories: (1) trustworthy systems, which exploit automated reasoning for computing plans compatible with the observed actions, and (2) swifter systems, which try to quickly infer goals, often overlooking complex cognitive processes, and have no formal guarantees of their results. This paper introduces a novel approach inspired by the dual process theory, which integrates these two techniques. A dual-process model is proposed, leveraging fast, experience-based recognition for immediate goal identification, and slow, deliberate analysis for deeper understanding. Machine learning techniques and classical planning techniques are employed to obtain this dual-process system. Experimental evaluations demonstrate the effectiveness of the approach, reducing the amount of resources required to compute a solution (e.g., time to find a goal), while at the same time enhancing accuracy and robustness, especially in more complex scenarios."
10.1145/3555776.3577657,Modeling a Conversational Agent using BDI Framework,"Building conversational agents to help humans in domain-specific tasks is challenging since the agent needs to understand the natural language and act over it while accessing domain expert knowledge. Modern natural language processing techniques led to an expansion of conversational agents, with recent pretrained language models achieving increasingly accurate language recognition results using ever-larger open datasets. However, the black-box nature of such pretrained language models obscures the agent's reasoning and its motivations when responding, leading to unexplained dialogues. We develop a belief-desire-intention (BDI) agent as a task-oriented dialogue system to introduce mental attitudes similar to humans describing their behavior during a dialogue. We compare the resulting model with a pipeline dialogue model by leveraging existing components from dialogue systems and developing the agent's intention selection as a dialogue policy. We show that combining traditional agent modelling approaches, such as BDI, with more recent learning techniques can result in efficient and scrutable dialogue systems."
10.5555/3709347.3743563,Human-Agent Coordination in Games under Incomplete Information via Multi-Step Intent,"Strategic coordination between autonomous agents and human partners under incomplete information can be modeled as turn-based cooperative games. We extend a turn-based game under incomplete information, the shared-control game, to allow players to take multiple actions per turn rather than a single action. The extension enables the use of multi-step intent, which we hypothesize will improve performance in long-horizon tasks. To synthesize cooperative policies for the agent in this extended game, we propose an approach featuring a memory module for a running probabilistic belief of the environment dynamics and an online planning algorithm called IntentMCTS. This algorithm strategically selects the next action by leveraging any communicated multi-step intent via reward augmentation while considering the current belief. Agent-to-agent simulations in the Gnomes at Night testbed demonstrate that IntentMCTS requires fewer steps and control switches than baseline methods. A human-agent user study corroborates these findings, showing an 18.52\% higher success rate compared to the heuristic baseline and a 5.56\% improvement over the single-step prior work. Participants also report lower cognitive load, frustration, and higher satisfaction with the IntentMCTS agent partner."
10.1145/3733155.3733196,Assistive Robots for Older Adults: A Human-Robot Interaction Study,"The progressive population ageing is rapidly transforming our societies. Assistive robots become an opportunity to favour the ageing in place allowing elderlies to remain in the home environment while increasing safety, healthy lifestyles, and remote monitoring for facilitating early intervention in an emergency. The present pilot work aims to compare two different human-robot interactions based on both usability and user-experience standardized scales and semi-structured interviews administered to a group of 10 elderly people to identify the factors affecting technology acceptance. The use of two different robots based on touch screen (Temi) and oral communication (Ohmni) equipped with specific sensors is investigated in four different scenarios with both clinical and social purposes: cognitive stimulation, nutritional control, physiological parameters monitoring, and entertainment. The study's findings report that the initial distrust in innovative and unusual technologies may be reduced by approaching them in a controlled environment. However, the perception of the usefulness and usability of robots, and more generally of technology, is also influenced by the personal nature of the user and the reason for use. Indeed, robots appear to be a threat to older adults’ independence, especially those who stay fit and behave independently. Concerning the robots’ interaction modes, most users preferred a combined interaction based on both vocal and written communication to make up for hearing or visual problems. Moreover, a robot exhibiting both a static and dynamic mode was preferred. However, further studies should be devoted to the optimization of the adopted technologies considering the users’ feedback for improved adaptivity and technology acceptance."
10.5555/3709347.3743817,Gricean Norms as a Basis for Effective Collaboration,"Effective human-AI collaboration hinges not only on the AI agent's ability to follow explicit instructions but also on its capacity to navigate ambiguity, incompleteness, invalidity, and irrelevance in communication. Gricean conversational and inference norms facilitate collaboration by aligning unclear instructions with cooperative principles. We propose a normative framework that integrates Gricean norms and cognitive frameworks---common ground, relevance theory, and theory of mind---into large language model (LLM) based agents. The normative framework adopts the Gricean maxims of quantity, quality, relation, and manner, along with inference, as Gricean norms to interpret unclear instructions, which are: ambiguous, incomplete, invalid, or irrelevant. Within this framework, we introduce Lamoids, GPT-4 powered agents designed to collaborate with humans. To assess the influence of Gricean norms in human-AI collaboration, we evaluate two versions of a Lamoid: one with norms and one without. In our experiments, a Lamoid collaborates with a human to achieve shared goals in a grid world (Doors, Keys, and Gems) by interpreting both clear and unclear natural language instructions. Our results reveal that the Lamoid with Gricean norms achieves higher task accuracy and generates clearer, more accurate, and contextually relevant responses than the Lamoid without norms. This improvement stems from the normative framework, which enhances the agent's pragmatic reasoning, fostering effective human-AI collaboration and enabling context-aware communication in LLM-based agents."
10.1145/3527928,Neurophysiological and Behavioral Differences in Human-Multiagent Tasks: An EEG Network Perspective,"Effective human-multiagent teams will incorporate the cognitive skills of the human with the autonomous capabilities of the multiagent group to maximize task performance. However, producing a seamless fusion requires a greater understanding of the human’s cognitive state as it reacts to uncertainties in both the task environment and agent dynamics. This study examines external behaviors in concert with neurophysiological measures acquired via electroencephalography (EEG) to probe the interactions between cognitive processes, behaviors, and performance in a human-multiagent team task. We show that changes in the α (8–12 Hz) and θ (4–8 Hz) bands of EEG indicate a higher burden on the cognitive resources associated with visual-spatial reasoning required to estimate a more complex kinematic state of robotic agents. These results are reinforced by complementary behavioral shifts in gaze and pilot inputs. Additionally, higher-performing participants tend to engage more actively in the task by utilizing greater amounts of visual-spatial reasoning. Finally, we show that features based on EEG dynamic-network-metrics provide discriminative information that distinguishes gaze behaviors associated with the attention process."
10.1145/3712285.3759887,STELLAR: Storage Tuning Engine Leveraging LLM Autonomous Reasoning for High Performance Parallel File Systems,"I/O performance is crucial to efficiency in data-intensive scientific computing; but tuning large-scale storage systems is complex, costly, and notoriously manpower-intensive, making it inaccessible for most domain scientists. To address this problem, we propose STELLAR, an autonomous tuner for high-performance parallel file systems. Our evaluations show that STELLAR almost always selects near-optimal configurations for the parallel file systems within the first five attempts, even for previously unseen applications. STELLAR’s human-like efficiency is fundamentally different from existing autotuning methods, which often require hundreds of thousands of iterations to converge. STELLAR achieves this through autonomous end-to-end agentic tuning. Powered by large language models (LLMs), STELLAR is capable of (1) accurately extracting tunable parameters from software manuals, (2) analyzing I/O trace logs generated by applications, (3) selecting initial tuning strategies, (4) rerunning applications on real systems and collecting I/O performance feedback, (5) adjusting tuning strategies and repeating the tuning cycle, and (6) reflecting on and summarizing tuning experiences into reusable knowledge for future optimizations. STELLAR integrates retrieval-augmented generation (RAG), external tool execution, LLM-based reasoning, and a multiagent design to stabilize reasoning and combat hallucinations. We evaluate how each of these components impacts optimization outcomes, thus providing insight into the design of similar systems for other optimization problems. STELLAR’s architecture and empirical validation open new avenues for tackling complex system optimization challenges, especially those characterized by vast search spaces and high exploration costs. Its highly efficient autonomous tuning will broaden access to I/O performance optimizations for domain scientists with minimal additional resource investment."
10.1145/3528228.3528407,Digital mentor: towards a conversational bot to identify hypotheses for software startups,"Software startups develop innovative, software-intensive product and services. This context leads to uncertainty regarding the software they are building. Experimentation, a process of testing hypotheses about the product, helps these companies to reduce uncertainty through different evidence-based approaches. The first step in experimentation is to identify the hypotheses to be tested. HyMap is a technique where a facilitator helps a software startup founder to draw a cognitive map representing her understanding of the context and, based on that, create hypotheses about the software to be built. In this paper, we present the Digital Mentor, an working-in-progress conversational bot to help creating a HyMap without the need of a human facilitator. We report the proposed solution consisting of a web application with the backend of a natural language understanding system, the current state of development, the challenges we faced so far and the next steps we plan to move forward."
10.1145/3526109,Human-Robot Scaffolding: An Architecture to Foster Problem-solving Skills,"In order to give assertive support, robots need to understand the cognitive and emotional characteristics of learners while in the learning process. Also, if the task involves handling capacity, robots must have similar skills. Three concepts were explored to control the cognitive and emotional robot’s behavior: the psychological flow theory, the scaffolding pedagogic strategy, and the multiagents-software paradigm. Based on these concepts, the Human-Robot Scaffolding architecture was designed. It is divided into five blocks. First, the sensory block recognizes body gestures, speech, and task state. Second, the beliefs block estimates the skills and emotional state of learners. Third, the desires block validates the goals the robot can reach; the goals are grouped in skills development, emotional control, cognitive control, challenge control, life signals, and immediate support. Fourth, the intentions block, based on the goals competition strategy, selects the goal that the robot will perform. Finally, the action-planner block regulates the robot’s movements according to the robot’s emotions. The validation procedure was done with 53 learners ranging between 10 and 13 years old who study in public and private schools. Based on the research achievements, the robot fosters learning the Mean-Ends Analysis strategy and the solution of a problem. A video fragment that summarizes the research process is available in ."
10.1145/3510822,FAtiMA Toolkit: Toward an Accessible Tool for the Development of Socio-emotional Agents,"More than a decade has passed since the development of FearNot!, an application designed to help children deal with bullying through role-playing with virtual characters. It was also the application that led to the creation of FAtiMA, an affective agent architecture for creating autonomous characters that can evoke empathic responses. In this article, we describe the FAtiMA Toolkit, a collection of open-source tools that is designed to help researchers, game developers, and roboticists incorporate a computational model of emotion and decision-making in their work. The toolkit was developed with the goal of making FAtiMA more accessible, easier to incorporate into different projects, and more flexible in its capabilities for human-agent interaction, based upon the experience gathered over the years across different virtual environments and human-robot interaction scenarios. As a result, this work makes several different contributions to the field of Agent-Based Architectures. More precisely, the FAtiMA Toolkit’s library-based design allows developers to easily integrate it with other frameworks, its meta-cognitive model affords different internal reasoners and affective components, and its explicit dialogue structure gives control to the author even within highly complex scenarios. To demonstrate the use of the FAtiMA Toolkit, several different use cases where the toolkit was successfully applied are described and discussed."
10.1145/3639856.3639879,CONRAD: Cognitive Intent Driven 5G Network Slice Planning and Design,"The emergence of 5G allows the network to be sliced to meet multiple service requirements. However, current design systems are policy-driven, which limits the ability to redesign the 5G network adaptively for requirements or traffic patterns. In this paper, we propose Conrad, an autonomous and intent-driven framework that can allocate resources efficiently to meet 5G slice requirements. Via the use of a cognitive intent handling engine, the requirements are transformed to goals that may be solved using machine reasoning techniques. Four agents are registered for forecasting, design planning, evaluation and actuation to enable dynamic re-design of the 5G slices. Exploiting automated planning techniques, proposals are provided to optimally provision the network slice resources. This process is demonstrated over a radio access network (RAN) slicing use case with intents on average expected throughput."
10.1145/3715761,Integrating Large Language Models and Reinforcement Learning for Non-linear Reasoning,"Large Language Models (LLMs) were shown to struggle with long-term planning, which may be caused by the limited way in which they explore the space of possible solutions. We propose an architecture where a Reinforcement Learning (RL) Agent guides an LLM's space exploration: (1) the Agent has access to domain-specific information, and can therefore make decisions about the quality of candidate solutions based on specific and relevant metrics, which were not explicitly considered by the LLM's training objective; (2) the LLM can focus on generating immediate next steps, without the need for long-term planning. We allow non-linear reasoning by exploring alternative paths and backtracking. We evaluate this architecture on the program equivalence task, and compare it against Chain of Thought (CoT) and Tree of Thoughts (ToT). We assess both the downstream task, denoting the binary classification, and the intermediate reasoning steps. Our approach compares positively against CoT and ToT."
10.5555/3463952.3464007,Explaining BDI Agent Behaviour through Dialogue,"BDI agents act in response to external inputs and their internal plan library. Understanding the root cause of BDI agent action is often difficult, and in this paper we present a dialogue based approach for explaining the behaviour of a BDI agent. We consider two dialogue participants who may have different views regarding the beliefs, plans and external events which drove agent action (encoded via traces). These participants make utterances which incrementally reveal their traces to each other, allowing them to identify divergences in the traces, or to conclude that their traces agree. In practice, we envision a human taking on the role of a dialogue participant, with the BDI agent itself acting as the other participant. The dialogue then facilitates explanation, understanding and debugging of BDI agent behaviour. After presenting our formalism and its properties, we describe our implementation of the system and provide an example of its use in a simple scenario."
10.5555/3535850.3535953,Preference-Based Goal Refinement in BDI Agents,"Computational agents based on the BDI framework typically rely on abstract plans and plan refinement to reach a degree of autonomy in dynamic environments: agents are provided with the ability to selecthow-to achieve their goals by choosing from a set of options. In this work we focus on a related, yet under-studied feature:abstract goals. These constructs refer to the ability of agents to adopt goals that are not fully grounded at the moment of invocation, refining them only when and where needed: the ability to selectwhat-to (concretely) achieve at run-time. We present a preference-based approach to goal refinement, defining preferences based on extendedCeteris Paribus Networks (CP-Nets) for an AgentSpeak(L)-like agent programming language, and mapping the established CP-Nets logic and algorithms to guide the goal refinement step. As a technical contribution, we present an implementation of this method that solely uses a Prolog-like inference engine of the agent's belief-base to reason about preferences, thus minimally affecting the decision-making mechanisms hard-coded in the agent framework."
10.1145/3659061,Generating Pattern-Based Conventions for Predictable Planning in Human–Robot Collaboration,"For humans to effectively work with robots, they must be able to predict the actions and behaviors of their robot teammates rather than merely react to them. While there are existing techniques enabling robots to adapt to human behavior, there is a demonstrated need for methods that explicitly improve humans’ ability to understand and predict robot behavior at multi-task timescales. In this work, we propose a method leveraging the innate human propensity for pattern recognition in order to improve team dynamics in human–robot teams and to make robots more predictable to the humans that work with them. Patterns are a cognitive tool that humans use and rely on often, and the human brain is in many ways primed for pattern recognition and usage. We propose pattern-aware convention-setting for teaming (PACT), an entropy-based algorithm that identifies and imposes appropriate patterns over a robot’s planner or policy over long time horizons. These patterns are autonomously generated and chosen via an algorithmic process that considers human-perceptible features and characteristics derived from the tasks to be completed, and as such, produces behavior that is easier for humans to identify and predict. Our evaluation shows that PACT contributes to significant improvements in team dynamics and teammate perceptions of the robot, as compared to robots that utilize traditionally ‘optimal’ plans and robots utilizing unoptimized patterns."
10.1109/ICONS62911.2024.00052,Mimicking Associative Learning of Rats via a Neuromorphic Robot in Open Field Maze Using Spatial Cell Models,"Data-driven Artificial Intelligence (AI) approaches have exhibited remarkable prowess across various cognitive tasks using extensive training data. However, the reliance on large datasets and neural networks presents challenges such as high-power consumption and limited adaptability, particularly in SWaP-constrained applications like planetary exploration. To address these issues, we propose enhancing the autonomous capabilities of intelligent robots by emulating the associative learning observed in animals. Associative learning enables animals to adapt to their environment by memorizing concurrent events. By replicating this mechanism, neuromorphic robots can navigate dynamic environments autonomously, learning from interactions to optimize performance. This paper explores the emulation of associative learning in rodents using neuromorphic robots within open-field maze environments, leveraging insights from spatial cells such as place and grid cells. By integrating these models, we aim to enable online associative learning for spatial tasks in real-time scenarios, bridging the gap between biological spatial cognition and robotics for advancements in autonomous systems."
10.5555/3535850.3535964,BOID*: Autonomous Goal Deliberation through Abduction,"The original BOID [5] is a cognitive architecture that unifies Belief, Obligation, Intention and Desire rules to calculate which actions should an agent undertake next. In the current paper, we adapt the original BOID with an aim to model autonomous agency. The new BOID* architecture is able to capture anticipation that we believe to be one of the hallmarks of autonomous agency. We focus on developing algorithms for anticipatory reasoning through a new BOID* goal deliberation component. The key method that BOID* introduces is abductive reasoning as a way to represent motivational attitudes, such as desires and obligations. As a result of deliberation via abduction, BOID* specifies intention revision procedures that connect motivational and informational attitudes. The BOID* is a part of the project to build autonomous AI models that make explicit the reasoning behind adopting future goals, prioritizing selected goals and forming intentions."
10.5555/3635637.3662854,Willy Wonka Mechanisms,"Bounded rationality in mechanism design aims to ensure incentive-compatibility for agents who are cognitively limited. These agents lack the contingent reasoning skills that traditional mechanism design assumes, and depending on how these cognitive limitations are modelled this alters the class of incentive-compatible mechanisms. In this work we design mechanisms without any ''obvious'' manipulations for several auction settings that aim to either maximise revenue or minimise the compensation paid to the agents. A mechanism without obvious manipulations is said to be not obviously manipulable (NOM), and assumes agents act truthfully as long as the maximum and minimum utilities from doing so are no worse than the maximum and minimum utilities from lying, with the extremes taken over all possible actions of the other agents. We exploit the definition of NOM by introducing the concept of golden tickets and wooden spoons, which designate bid profiles ensuring the mechanism's incentive-compatibility for each agent. We then characterise these ''Willy Wonka'' mechanisms, and by carefully choosing the golden tickets and wooden spoons we use this to design revenue-maximising auctions and frugal procurement auctions."
10.1145/3696410.3714765,Division-of-Thoughts: Harnessing Hybrid Language Model Synergy for Efficient On-Device Agents,"The rapid expansion of web content has made on-device AI assistants indispensable for helping users manage the increasing complexity of online tasks. The emergent reasoning ability in large language models offer a promising path for next-generation on-device AI agents. However, deploying full-scale Large Language Models (LLMs) on resource-limited local devices is challenging. In this paper, we propose <u>D</u>ivision-<u>o</u> f-<u>T</u>houghts (DoT), a collaborative reasoning framework leveraging the synergy between locally deployed Smaller-scale Language Models (SLMs) and cloud-based LLMs. DoT leverages a Task Decomposer to elicit the inherent planning abilities in language models to decompose user queries into smaller sub-tasks, which allows hybrid language models to fully exploit their respective strengths. Besides, DoT employs a Task Scheduler to analyze the pair-wise dependency of sub-tasks and create a dependency graph, facilitating parallel reasoning of sub-tasks and the identification of key steps. To allocate the appropriate model based on the difficulty of sub-tasks, DoT leverages a Plug-and-Play Adapter, which is an additional task head attached to the SLM that does not alter the SLM's parameters. To boost adapter's task allocation capability, we propose a self-reinforced training method that relies solely on task execution feedback. Extensive experiments on various benchmarks demonstrate that our DoT significantly reduces LLM costs while maintaining competitive reasoning accuracy. Specifically, DoT reduces the average reasoning time and API costs by 66.12\% and 83.57\%, while achieving comparable reasoning accuracy with the best baseline methods."
10.1145/3723498.3723702,Evaluating Large Language Models through Communication Games: An Agent-Based Framework Using Werewolf in Unity,"In this study, we explore the reasoning capabilities of Large Language Models (LLMs) within the context of the social communication game Werewolf, aiming to evaluate their performance in managing complex system states commonly found in computer games. Our agent architecture gathers data, refines them into detailed information, and plans actions based on this knowledge. To demonstrate the feasibility of using LLM based agents in computer games, we developed a simulation and evaluation tool using the Unity game engine. This software enables users to experiment with various LLMs and agent architectures and to measure model performance within the application.For evaluation, we tested three models: GPT-3.5 Turbo, Mistral-7B-OpenOrca, and Nous-Hermes-Llama2-13B. The results show that even smaller models can perform reasonably well in Werewolf. However, their error rate is significantly higher, highlighting the need for additional software modules or fine-tuning to improve their accuracy."
10.5555/3712729.3712829,Planning a Material Replenishment through Autonomous Mobile Robot in an Assembly Plant Using a Hybrid Simulation Approach,"This paper focuses on planning the implementation of an autonomous mobile robot in an existing material replenishment system of an assembly plant using a hybrid simulation approach. In this research, we aim to identify proper strategies for the number of containers or payloads the robot should carry per shift under different scenarios using Agent-Based Modeling and Discrete Event Simulation. Our primary objective is to minimize the number of shifts a mobile robot should travel for replenishment while keeping idle time low across all stations and ensuring timely material replenishment. The results show that choosing which strategy to use for the implementation of the autonomous navigating robot depends on the maximum number of containers it can carry and the utilization of payload space. While this paper focuses on Tiger Motors Assembly line at Auburn University, its applications could be extended to similar assembly plants equipped with a similar material replenishment system."
10.1145/3665939.3665963,CopycHats: Question Sequencing with Artificial Agents,"Schema Matching, the task of finding correspondences among attributes of different schemata, plays an important role in data integration. The task has been extensively researched, leading to the development of multiple algorithmic approaches, many of which incorporate humans to some extent, by performing the matching, validating algorithmic solutions, or generating reliable ground truth for algorithms to be trained against. Human matching is a temporal process, in which previous decisions and ongoing cognitive processes influence future behavior. Therefore, planning a human matching task necessitates careful consideration, for example, the ordering of questions posed to the matcher. Various strategies exist for optimally choosing the sequence of matching questions and evaluating them may be limited by notable inherent human limitations. In this work, we propose to leverage Large Language Models (LLMs) to create artificial agents that emulate human agents in order to evaluate question sequencing strategies. We offer an alternative to traditional human-based evaluations, which overcome those limitations. We test our suggested evaluation framework and discuss the similarities and differences between artificial and human agents in the context of schema matching evaluation."
10.1145/3701716.3715247,"Meta-Agent-Workflow: Streamlining Tool Usage in LLMs through Workflow Construction, Retrieval, and Refinement","Large language models (LLMs) have recently shown significant advancements and are increasingly used as key components in automated agents for various web-based tasks. Typically, this agentization is achieved by carefully prompting LLMs to guide their behavior in using tools for specific tasks. However, this approach can be limited by the complexity of tasks and the inherent capabilities of LLMs. To enhance task-specific performance, a pre-defined workflow approach can be employed, reducing repetitive and error-prone planning for particular tasks. This workflow-driven process is especially well-suited for industrial applications, where task-specific agents can be easily configured using visual interfaces supported by various open-source platforms. In this paper, we introduce a novel framework called Meta-Agent-Workflowto create, retrieve, and refine agent workflows. Experiments on ToolBench demonstrate that our framework effectively transforms LLM tool-reasoning processes into task-specific workflows, retrieves workflows for different tasks based on various queries, and updates them based on execution feedback. We also open-source our code and follow the workflow architecture of an open-source agent platform (e.g., Dify) to facilitate further industrial and community use. The Meta-Agent-Workflow will be open-sourced in https://github.com/testlbin/meta_agent_workflows."
10.1145/3749893.3749973,Empathic Growth: Designing Human-Plant Interaction through Artistic Exploration,"This paper presents Empathic Growth, an inter-species interactive art installation that explores plant perception from a more-than-human perspective. Grounded in Jakob von Uexk\""{u}ll’s concept of Umwelt, the installation recognizes plants as active participants with their own perceptual worlds. By visualizing the biosignals of both humans and plants in a shared environment, Empathic Growth creates a visualized space of shared perception, encouraging participants to reflect on plant agency and fostering empathy between species. The installation exhibition revealed that participants developed a greater awareness of plant perception and a deeper empathy for plant life, encouraging a rethinking of human-plant relationships. Through three iterative exhibitions, Empathic Growth evolved from an initial experiment exploring emotional symbiosis between humans and plants into a real-time interactive hybrid perception interface, ultimately into digital hybrid forms as an agent-based artificial life with collective behaviors. This process realized an exploration of the interaction of human-plant empathy and the digital artificial life of growth."
10.5555/3545946.3598760,Feedback-Guided Intention Scheduling for BDI Agents,"Intelligent agents, like those based on the popular BDI agent paradigm, typically pursue multiple goals in parallel. An intention scheduler is required to reason about the possible interactions between the agent's intentions to maximize some utility. An important consideration when scheduling intentions is the user's preferences over the goals and the ways in which the goals are achieved. These preferences are generally unknown in advance, time-consuming to elicit, hard to model, and difficult to incorporate into an intention scheduler. In this paper, we present a Monte Carlo Tree Search based intention scheduler (pref-MCTS) that is able to learn the user's preferences over intention schedules via low-burden comparative-type queries. It incorporates the learned preferences in guiding the search, leading to execution policies that are optimized towards the user's preferences and expectations. We evaluate our approach using an artificial oracle that shows that pref-MCTS improves over state-of-the-art baselines, even when provided with a limited number of preference queries and noisy labels. We also conducted a user study and showed that pref-MCTS is able to learn user preferences and generate schedules that are preferred by the users in real-time."
10.1145/3730824,Learning to Assemble with Alternative Plans,"We present a reinforcement learning framework for constructing assemblies composed of rigid parts, which are commonly seen in many historical masonry buildings and bridges. Traditional construction methods for such structures often depend on dense scaffolding to stabilize their intermediate assembly steps, making the process both labor-intensive and time-consuming. This work utilizes multiple robots to collaboratively assemble structures, offering temporary support by holding parts in place without additional scaffolding. Precomputing the robotic assembly process to ensure structural stability involves a time-consuming offline process due to the combinatorial nature of its search space. However, the precomputed assembly plans may get disrupted during real-world execution due to unforeseen changes, such as setup modifications or delays in part delivery. Recomputing these plans using traditional offline methods results in significant project delays. Therefore, we propose a reinforcement learning-based approach in which a neural network is trained to efficiently generate alternative assembly plans for a given structure online, enabling adaptation to external changes. To enable effective and efficient training, we introduce three key innovations: a GPU-based stability simulator for parallelizing simulations, a novel curriculum-based training scheme to address sparse rewards during training, and a new graph neural network architecture for efficiently encoding assembly geometry. We validate our approach by training reinforcement learning agents on various assemblies and evaluating their performance on unseen assembly tasks. Furthermore, we demonstrate the effectiveness of our framework in planning multi-robot assembly processes, effectively handling disruptions in both simulation and physical environments."
10.1145/3603269.3604860,EBB: Reliable and Evolvable Express Backbone Network in Meta,"We present the design, implementation, evaluation, deployment and production experiences of EBB (Express BackBone), a private WAN (Wide Area Network) connecting Meta's global data centers (DCs). Initiated in 2015, EBB now carries 100\% of DC-DC traffic, witnessing remarkable growth over the years. A key design aspect of EBB is its multi-plane architecture, facilitating seamless deployment of a new control plane while ensuring operational simplicity. This architecture allows for efficient failure mitigation, standard maintenance, and capacity expansion by draining one or two planes without impacting service level objectives (SLOs). Another critical design decision is the hybrid model, combining distributed control agents and a central controller. EBB's centralized traffic engineering utilizes an MPLS-TE based solution to allocate paths periodically for different traffic classes based on service requirements, while its distributed control agents enable fast local failure recovery by pre-installing pre-computed backup paths in the data plane. We delve into our eight-year production experience, highlighting the successful deployment of multiple generations of EBB."
10.1145/3670998,Interpersonal Communication Interconnection in Media Convergence Metaverse,"The metaverse aims to provide immersive virtual worlds connecting with the physical world. To enable real-time interpersonal communications between users across the globe, the metaverse places high demands on network performance, including low latency, high bandwidth, and fast network speeds. This paper proposes a novel Media Convergence Metaverse Network (MCMN) framework to address these challenges. Specifically, the META controller serves as MCMN's logically centralized control plane, responsible for holistic orchestration across edge sites and end-to-end path computation between metaverse users. We develop a model-free deep reinforcement learning-based metaverse traffic optimization algorithm that learns to route flows while satisfying the Quality of Service (QoS) boundaries. The network slicing engine leverages artificial intelligence and machine learning to create isolated, customized virtual networks tailored for metaverse traffic dynamics on demand. It employs unsupervised and reinforcement learning techniques using network telemetry from the META controller to understand application traffic patterns and train cognitive slicer agents to make quality of service -aware decisions accordingly. Optimized delivery of diverse concurrent media types necessitates routing intelligence to meet distinct requirements while mitigating clashes over a shared infrastructure. Media-aware routing enhances traditional shortest-path approaches by combining topological metrics with workflow sensitivities. We realize an edge-assisted rendering fabric to offload complex processing from bandwidth-constrained endpoints while retaining visual realism. Extensive simulations demonstrate MCMN's superior performance compared to conventional networking paradigms. MCMN shows great promise to enable seamless interconnectivity and ultra-high fidelity communications to unlock the true potential of the metaverse."
10.5555/3648699.3649067,LapGym: an open source framework for reinforcement learning in robot-assisted laparoscopic surgery,"Recent advances in reinforcement learning (RL) have increased the promise of introducing cognitive assistance and automation to robot-assisted laparoscopic surgery (RALS). However, progress in algorithms and methods depends on the availability of standardized learning environments that represent skills relevant to RALS. We present LapGym, a framework for building RL environments for RALS that models the challenges posed by surgical tasks, and sofa_env, a diverse suite of 12 environments. Motivated by surgical training, these environments are organized into 4 tracks: Spatial Reasoning, Deformable Object Manipulation \& Grasping, Dissection, and Thread Manipulation. Each environment is highly parametrizable for increasing difficulty, resulting in a high performance ceiling for new algorithms. We use Proximal Policy Optimization (PPO) to establish a baseline for model-free RL algorithms, investigating the effect of several environment parameters on task difficulty. Finally, we show that many environments and parameter configurations reect well-known, open problems in RL research, allowing researchers to continue exploring these fundamental problems in a surgical context. We aim to provide a challenging, standard environment suite for further development of RL for RALS, ultimately helping to realize the full potential of cognitive surgical robotics. LapGym is publicly accessible through GitHub (https://github.com/ScheiklP/lap_gym)."
10.1145/3514254,MetaCogs: Mitigating Executive Dysfunction via Agent-based Modeling for Metacognitive Strategy Development,"Executive functions (EF) are a collection of cognitive domains governing task initiation, motor planning, attention, and goal-oriented action. Difficulties with EF have marked impacts on adaptive living skills, learning outcomes, and quality of life for people with cognitive and psychosocial disabilities, as well as the broader population. While there is considerable research interest in EF training intervention for disabled populations, very few studies explore metacognitive intervention for people with cognitive disabilities. Metacognition comprises conscious beliefs and strategies around task management and goal setting. Metacognitive awareness has been shown to mediate the effects of executive function on self-regulated learning. Metacognitive interventions have also shown promise in general education, military training, and medical practice. We present a virtual reality experience deploying agent-based modeling to support explicit metacognitive strategy instruction for undergraduate students of all neurotypes. Our results support that explicit instructional material explaining executive function and metacognition in relation to problem-solving experiences influenced participant self-concept and awareness of personal traits and cognitive processes."
10.1145/3746252.3760995,STARec: An Efficient Agent Framework for Recommender Systems via Autonomous Deliberate Reasoning,"While modern recommender systems are instrumental in navigating information abundance, they remain fundamentally limited by static user modeling and reactive decision-making paradigms. Current large language model (LLM)-based agents inherit these shortcomings through their overreliance on heuristic pattern matching, yielding recommendations prone to shallow correlation bias, limited causal inference, and brittleness in sparse-data scenarios. We introduce STARec, a slow-thinking augmented agent framework that endows recommender systems with autonomous deliberative reasoning capabilities. Each user is modeled as an agent with parallel cognitions: fast response for immediate interactions and slow reasoning that performs chain-of-thought rationales. To cultivate intrinsic slow thinking, we develop anchored reinforcement training-a two-stage paradigm combining structured knowledge distillation from advanced reasoning models with preference-aligned reward shaping. This hybrid approach scaffolds agents in acquiring foundational capabilities (preference summarization, rationale generation) while enabling dynamic policy adaptation through simulated feedback loops. Experiments on MovieLens 1M and Amazon CDs benchmarks demonstrate that STARec achieves substantial performance gains compared with state-of-the-art baselines, despite using only 0.4\% of the full training data."
10.1145/3461615.3485413,Get Together in the Middle-earth: a First Step Towards Hybrid Intelligence Systems,"In the last decade, the number of computer systems using AI has increased dramatically. To date, indeed, AI is present in almost all the aspects of the human everyday life. This resulted in the attempt of scholars in Computer Science to endow machines with human-like socio-cognitive skills and/or human-like embodiment to try to improve interactions. Such an approach, however, highlights several crucial issues related to the substantial differences between fine-grained human skills and what machines can do and learn. So, although being expensive and sophisticated tools, machines tend to be “idiots savants”. Hybrid Intelligence (HI) is aimed to tackle this issue by proposing, as Akata and colleagues say, “systems that operate as mixed teams, where humans and machines cooperate synergistically, proactively, and purposefully to achieve shared goals”. To our knowledge, however, HI is at a very early exploratory stage, and few concrete solutions to deal with it exist. In this position paper we introduce and briefly describe “Middle-Earth”, a conceptual and experimental ground to study HI. Moreover, we present a first prototype of a software platform based on immersive VR environments, on which we plan to carry out in the future the first pioneering experiments on teams of humans and/or AI-driven agents getting together in Middle Earth to perform collaborative tasks."
10.1145/3627611.3627616,Engaging Cities: From Urban Space to Media Interface,"Technology in this millennium has evolved to become a conduit for communication, creative expression and knowledge transmission. Central to this is the designer's agentic role in mediating the percolation of the digital into the built environment to produce new and transformative experiences incorporating mixed reality. Through discussing two speculative projects, this paper poses the question of what instigative role media might play in efforts to boost spatial ambience and social agency. The first reimagines an AR media architecture experience: by expanding the scope of screen media to include touch media and mobile media, handheld devices fulfil a fresh function, to re-center the urban experience alongside encouraging multidimensional user interaction. Meanwhile, a virtually mediated tour conceived to explore interactions between media and architecture, user agency and behavior, redefines an appreciation for the mimetic. While VR is unable to replicate the randomness and complexity of real-world experience, the sensorial richness of the lived environment and in-person interactions, insights can still be gleaned by how people navigate in cities, even in a simulated environment. These examples reconfirm how our relationship with urban space has been irrevocably altered by digital affordance, through interpretation, interactions and interventions. They open up a dialogue on other alternatives to traditional notions and practices of media architecture. Given the proliferation of digital and online tools and platforms, it stands to reason that now is the opportune time to enskill and empower designers to seize control of the technological ensemble, and exploit what the digital affords, to interpret new and meaningful uses."
10.1145/3377049.3377133,Design and Implementation of Smart Cyclone Separator Vacuum Cleaner Bot Driven by Renewable Energy,"People are facing many difficulties with dust particles in every step of life which sometimes may become the passive reason behind death. Nowadays, new gadgets and devices are bringing innovative solutions to make problems simplified and effortless in our daily life. So, the innovation of an autonomous dust sweeper bot can make cleaning tasks effortless and user-friendly. For the last few years, self-directed cleaners have taken major attention by providing customer satisfaction because of its usefulness in helping humans by minimizing physical effort in day to day cleaning purposes. Consequently, a new type of vacuum cleaner bot is implemented by using local resources which can solve the dust problem automatically. One of the additional features of this vacuum cleaner bot is its running capability using a hybrid plugin/solar energy. This bot can repeatedly keep clean places like industries, hospitals, and universities. This bot follows a predetermined line in automatic mode or can be controlled by a joystick. This structure also can detect obstacles on its following path to avoid accidents. It has the charging capability using solar radiation or can be charged from the mains during cloudy days. It collects dust by its cyclone separator vacuum cleaner \& cleaning brush, which is designed for the first time by our team. This bot is designed to run on ultra-low power (only 80 W), whereas the lowest power of a conventional vacuum cleaner in the market is around 1800W.Finally, we can say that this renewable energy-driven smart cyclone separator vacuum cleaner bot is the finest bot that can solve the dust problem by itself. It has far-reaching potential to be the best commercial product in the cleaning era with the assurance of a healthy environment."
10.1145/3746027.3754542,InteractGuide: LLM-Enhanced Multimodal Reasoning for User-Centric Interaction Recommendations in AR-HRI Authoring,"Augmented Reality (AR) enhances Human-Robot Interaction (HRI) by offering diverse interaction methods. However, existing systems often fail to resolve the conflict between a user's implicit preferences and physical ergonomics, leading to suboptimal experiences. We introduce InteractGuide, a novel framework that, for the first time, uses a Large Language Model (LLM) as a central reasoning engine to dynamically balance these competing factors. Our system translates physiological signals into a symbolic ''Preference Memory'' that the LLM reasons over, alongside real-time ergonomic and contextual data, to provide personalized interaction recommendations. A 29-participant study confirms our architecture improves efficiency and experience compared to single-factor approaches, showing the potential of LLMs as reasoning engines for complex AR-HRI. This work presents a validated end-to-end architecture for user-centric interaction adaptation, demonstrating the potential of LLMs as reasoning engines in complex AR-HRI systems."
10.5555/3523760.3523794,Mind the Machines: Applying Implicit Measures of Mind Perception in Social Robotics,"Beyond conscious beliefs and goals, automatic cognitive processes shape our social encounters, and interactions with complex machines like social robots are no exception. With this in mind, it is surprising that research in human-robot interaction (HRI) almost exclusively uses explicit measures, such as subjective ratings and questionnaires, to assess human attitudes towards robots - seemingly ignoring the importance of implicit measures. This is particularly true for research focusing on the question whether or not humans are willing to attribute complex mental states (i.e.,mind perception ), such asagency (i.e., the capacity to plan and act) andexperience (i.e., the capacity to sense and feel), to robotic agents. In the current study, we (i) created the mind perception implicit association test (MP-IAT) to examine subconscious attributions of mental capacities to agents of different degrees of human-likeness (here: human vs. humanoid robot), and (ii) compared the outcomes of the MP-IAT to explicit mind perception ratings of the same agents. Results indicate that (i) already at the subconscious level, robots are associated with lower levels of agency and experience compared to humans, and that (ii) implicit and explicit measures of mind perception are not significantly correlated. This suggests that mind perception (i) has an implicit component that can be measured using implicit tests like the IAT and (ii) might be difficult to modulate via design or experimental procedures due to its fast-acting, automatic nature."
10.1145/3481585,"A Cloud-based Robot System for Long-term Interaction: Principles, Implementation, Lessons Learned","Making the transition to long-term interaction with social-robot systems has been identified as one of the main challenges in human-robot interaction. This article identifies four design principles to address this challenge and applies them in a real-world implementation: cloud-based robot control, a modular design, one common knowledge base for all applications, and hybrid artificial intelligence for decision making and reasoning. The control architecture for this robot includes a common Knowledge-base (ontologies), Data-base, “Hybrid Artificial Brain” (dialogue manager, action selection and explainable AI), Activities Centre (Timeline, Quiz, Break and Sort, Memory, Tip of the Day,  ( ldots  ) ), Embodied Conversational Agent (ECA, i.e., robot and avatar), and Dashboards (for authoring and monitoring the interaction). Further, the ECA is integrated with an expandable set of (mobile) health applications. The resulting system is a Personal Assistant for a healthy Lifestyle (PAL), which supports diabetic children with self-management and educates them on health-related issues (48 children, aged 6–14, recruited via hospitals in the Netherlands and in Italy). It is capable of autonomous interaction “in the wild” for prolonged periods of time without the need for a “Wizard-of-Oz” (up until 6 months online). PAL is an exemplary system that provides personalised, stable and diverse, long-term human-robot interaction."
10.1145/3712255.3734367,Evolvability in Rule-Making: A Self-Amendment Game Among LLM Agents,"We introduce the Self-Amendment Game, a simulation framework where Large Language Model (LLM) agents iteratively propose, vote on, and revise the very rules that govern them. Inspired by the self-modifying game Nomic, this system enables agents to operate within a fully amendable environment in which institutional constraints are themselves subject to change. Using leading LLMs, we examine two agent strategies: ""Add"" agents that focus on introducing new rules, and ""Modify"" agents that refine existing ones. Add agents tend to generate denser but less stable rule systems, with rapid point accumulation and high leadership turnover. Modify agents foster greater stability, with fewer but more consistent leaders. Analyzing the semantic structure of proposals, we find that varied justification styles often lead to instability, while coherence in reasoning promotes rule adoption. Our findings highlight a crucial trade-off between innovation and governance stability, offering a foundation for studying adaptive, self-governing systems involving both artificial agents and hybrid human-AI institutions."
10.1145/3513091,Assured Mission Adaptation of UAVs,"The design of systems that can change their behaviour to account for scenarios that were not foreseen at design time remains an open challenge. In this article, we propose an approach for adaptation of mobile robot missions that is not constrained to a predefined set of mission evolutions. We implement an adaptive software architecture and show how controller synthesis can be used both to guarantee correct transitioning from the old to the new mission goals with runtime architectural reconfiguration to include new software actuators and sensors if necessary. The architecture brings together architectural concepts that are commonplace in robotics such as temporal planning, discrete, hybrid and continuous control layers together with architectural concepts from adaptive systems such as runtime models and runtime synthesis. We validate the architecture flying several missions taken from the robotic literature for different real and simulated UAVs."
10.1145/3762657,Grasp-HGN: Grasping the Unexpected,"For transradial amputees, robotic prosthetic hands promise to regain the capability to perform daily living activities. To advance next-generation prosthetic hand control design, it is crucial to address current shortcomings in robustness to out of lab artifacts, and generalizability to new environments. Due to the fixed number of object to interact with in existing datasets, contrasted with the virtually infinite variety of objects encountered in the real world, current grasp models perform poorly on unseen objects, negatively affecting users’ independence and quality of life.To address this: (i) we define semantic projection, the ability of a model to generalize to unseen object types and show that conventional models like YOLO, despite 80\% training accuracy, drop to 15\% on unseen objects. (ii) We propose Grasp-LLaVA, a Grasp Vision Language Model enabling human-like reasoning to infer the suitable grasp type estimate based on the object’s physical characteristics resulting in a significant 50.2\% accuracy over unseen object types compared to 36.7\% accuracy of an SOTA grasp estimation model.Lastly, to bridge the performance-latency gap, we propose Hybrid Grasp Network (HGN), an edge-cloud deployment infrastructure enabling fast grasp estimation on edge and accurate cloud inference as a fail-safe, effectively expanding the latency vs. accuracy Pareto. HGN with confidence calibration (DC) enables dynamic switching between edge and cloud models, improving semantic projection accuracy by 5.6\% (to 42.3\%) with 3.5\texttimes{} speedup over the unseen object types. Over a real-world sample mix, it reaches 86\% average accuracy (12.2\% gain over edge-only), and 2.2\texttimes{} faster inference than Grasp-LLaVA alone."
10.1145/3610068,How Time Pressure in Different Phases of Decision-Making Influences Human-AI Collaboration,"Human cognitive and decision-making abilities depreciate under pressure, motivating the emergence of artificial intelligence (AI) systems as decision support tools to assist people in performing tasks under stress. In this work, we study human decision-making behavior and task performance under time pressure---induced from limitedinitial observation time (time to perform the task before providing an initial response without AI input) andfinal decision time (time to weigh an AI's suggestion before reaching a collective human-AI team answer)---for spatial reasoning and count estimation tasks. Our results show that, while the impact of initial observation time on AI-assisted decision-making was dependent on task nature, participants were more likely to follow AI suggestions when they were provided with longer final decision time; moreover, although participants generally tended to adhere to their initial responses, they had more agency when they were more logically engaged in a task. Our results offer a nuanced understanding of human-AI collaboration under time pressure in different phases of the decision-making process."
10.1145/3746027.3758167,MindFuse: Towards GenAI Explainability in Marketing Strategy Co-Creation,"The future of digital marketing lies in the convergence of human creativity and generative AI, where insight, strategy, and storytelling are co-authored by intelligent systems. We present MindFuse, a brave new explainable generative AI framework designed to act as a strategic partner in the marketing process. Unlike conventional LLM applications that stop at content generation, MindFuse fuses CTR-based content AI-guided co-creation with large language models to extract, interpret, and iterate on communication narratives grounded in real advertising data. MindFuse operates across the full marketing lifecycle: from distilling content pillars and customer personas from competitor campaigns to recommending in-flight optimizations based on live performance telemetry. It uses attention-based explainability to diagnose ad effectiveness and guide content iteration, while aligning messaging with strategic goals through dynamic narrative construction and storytelling. We introduce a new paradigm in GenAI for marketing, where LLMs not only generate content but reason through it, adapt campaigns in real time, and learn from audience engagement patterns. Our results, validated in agency deployments, demonstrate up to 12\texttimes{} efficiency gains, setting the stage for future integration with empirical audience data (e.g., GWI, Nielsen) and full-funnel attribution modeling. MindFuse redefines AI not just as a tool, but as a collaborative agent in the creative and strategic fabric of modern marketing. In the end of the paper, we also provide a forward-looking forecast on how platforms like MindFuse and Google DeepMind's ACAI are likely to shape the future of marketing agencies. These systems will not only reset client expectations toward greater transparency, speed, and personalization, but will also redefine the skillsets demanded from the new generation of marketers. As hybrid agencies emerge-blending creative storytelling with data science and AI engineering-the competitive landscape will increasingly hinge on talent. In this new environment, professionals will be expected to pair human imagination with technical fluency, while agencies will need to reinvent themselves as AI facilitators and curators of brand authenticity amidst the ongoing talent war led by platforms such as Meta."
10.1145/3746252.3761363,Parse-LLM: A Prior-Free LLM Parser for Unknown System Logs,"Log parsing extracts structured information from unstructured logs and serves as a fundamental pre-processing step for various log-based analytics and monitoring tasks. Recent advances have leveraged Large Language Models (LLMs) to handle log format complexities and enhance parsing performance. However, these methods heavily rely on labeled data, which is often scarce in rapidly evolving industrial systems, limiting their applicability in real-world scenarios. Moreover, the sheer volume of logs results in slow parsing and high computational costs, further hindering the deployment of LLM-based log parsing systems. To address these issues, we propose Parse-LLM, an unsupervised end-to-end log parsing framework based on LLMs Specifically, we first developed a Log Decomposer Agent that leverages Chain-of-Thought (CoT) reasoning and callable tools, enabling the LLM to autonomously separate log headers from content. Next, we introduce the Hybrid Log Partition module, which segments logs by balancing commonalities and differences. Finally, we developed a novel Variation-aware Log Parsing module that allows the LLM to harness additional supervisory signals through comparative analysis of similar logs. Comprehensive experiments conducted on large-scale public datasets show that Parse-LLM outperforms state-of-the-art log parsers in an unsupervised setting, offering an effective and scalable solution for the practical application of unsupervised log parsing."
10.5555/3709347.3744045,Responsible Autonomy for Hybrid Intelligence,"In hybrid intelligence (HI) systems, artificial intelligence (AI) agents and humans work together to solve complex tasks. In these interactions, each agent is expected to work autonomously and be responsible for their actions. By capturing consent as a regulation of actions in a normative environment (such as a HI system), an agent can determine an appropriate action within the normative environment, and reason on the moral and ethical requirements and effects of the action. Current consent representations do not allow agents to reason on normative actions, which limit agent autonomy. We are developing a representation of consent that captures the nuances of consent from human-human interaction, and expresses them computationally to allow the AI agent to responsibly practice autonomy in a HI system. In future work, the proposed representation will be evaluated against human intuitions about consent, and compared to current consent representations to ensure a robust and domain-agnostic formalisation. Further research includes developing a consent representation that can manage multi-party consent and shared resources, specifying accounts for consent violations to determine culpability, and exploring a developmental approach to norm representation and management for greater perceived agent responsibility and autonomy in a HI system."
10.1145/3588432.3591510,Acting as Inverse Inverse Planning,"Great storytellers know how to take us on a journey. They direct characters to act—not necessarily in the most rational way—but rather in a way that leads to interesting situations, and ultimately creates an impactful experience for audience members looking on. If audience experience is what matters most, then can we help artists and animators directly craft such experiences, independent of the concrete character actions needed to evoke those experiences? In this paper, we offer a novel computational framework for such tools. Our key idea is to optimize animations with respect to simulated audience members’ experiences. To simulate the audience, we borrow an established principle from cognitive science: that human social intuition can be modeled as “inverse planning,” the task of inferring an agent’s (hidden) goals from its (observed) actions. Building on this model, we treat storytelling as “inverse inverse planning,” the task of choosing actions to manipulate an inverse planner’s inferences. Our framework is grounded in literary theory, naturally capturing many storytelling elements from first principles. We give a series of examples to demonstrate this, with supporting evidence from human subject studies."
10.1145/3539608,Social Relationship Analysis Using State-of-the-art Embeddings,"Detection of human relationships from their interactions on social media is a challenging problem with a wide range of applications in different areas, like targeted marketing, cyber-crime, fraud, defense, planning, and human resource, to name a few. All previous work in this area has only dealt with the most basic types of relationships. The proposed approach goes beyond the previous work to efficiently handle the hierarchy of social relationships. This article introduces a novel technique named Quantifiable Social Relationship (QSR) analysis for quantifying social relationships to analyze relationships between agents from their textual conversations. QSR uses cross-disciplinary techniques from computational linguistics and cognitive psychology to identify relationships. QSR utilizes sentiment and behavioral styles displayed in the conversations for mapping them onto level II relationship categories. Then, for identifying the level III relationship categories, QSR uses level II relationships, sentiments, interactions, and word embeddings as key features. QSR employs natural language processing techniques for feature engineering and state-of-the-art embeddings generated by word2vec, global vectors (glove), and bidirectional encoder representations from transformers (bert). QSR combines the intrinsic conversational features with word embeddings for classifying relationships. QSR achieves an accuracy of up to 89\% for classifying relationship subtypes. The evaluation shows that QSR can accurately identify the hierarchical relationships between agents by extracting intrinsic and extrinsic features from textual conversations between agents."
10.1145/3488241,Stop Ignoring Me! On Fighting the Trivialization of Social Robots in Public Spaces,"Service and social robot in public scenarios will face various tasks in future applications, such as guiding people or admonishing them to provide assistance or convey social norms. Robots in public spaces might also incorporate roles of authority figures who might admonish people (e.g., security or guard robots). However, recent investigations showed that people ignore the admonishment of robots. Thus, in this work, we are looking at the reasons why people might ignore robots based on the Cognitive Dissonance Theory (CDT). We present the results of two consecutive field observations where a robot admonishes participants (i.e., pedestrians in a shopping mall) and requests them to stop using a smartphone while walking, which is considered an unmoral behavior. In the first field observation, we approached 160 participants over four days and conducted semi-structured interviews with 19 of them. Approximately half of the people ignored the robot, and half of them followed the instructions. Our interview results show that people who ignore the robot indeed use trivialization as a cognitive dissonance reduction strategy to justify ignoring the robot. Based on our analysis of the results, we developed a counter-trivialization strategy that anticipates this dissonance reduction strategy. We admonished 167 participants in our second field observation over four days, and our results show that significantly fewer people ignore the instructions of the robot when the robot uses a counter-trivialization strategy."
10.1145/3767624.3767637,Radish Harvester Path Planning Based on Improved U-Net Algorithm,"Accurate recognition of crop rows is important for agricultural robot path planning and navigation. The traditional U-Net model suffers from mask discontinuity and edge blurring when recognizing crop rows in complex field environments, which seriously affects the accuracy and stability of path planning. To solve this problem, an improved U-Net algorithm (HSA-Unet) based on the Hybrid Spatial Attention mechanism (HSA) is proposed for enhancing the coherence and structural robustness of the crop row mask in the radish harvester path planning task. Meanwhile, a radish row image dataset containing eight typical changing scenarios, such as different light conditions, weed interference, and row breakage, was constructed to comprehensively evaluate the model's adaptability in the complex field environment. In addition, the centerline of the crop rows for the model prediction mask was determined by the triangular scanning method, and an End-of-Row (EOR) detection method combining continuous frame detection and odometer constraints was designed to achieve reliable identification of the end of the radish rows and automatic triggering of row change signals. The results of systematic experiments conducted on the Gazebo simulation platform show that HSA-Unet achieves an average IoU of 35.65\% in the turnip row segmentation task, which is better than the 27.08\% of the traditional U-Net, and the stability of mask prediction is significantly enhanced. Meanwhile, the mobile platform achieves a path planning quality score of 0.86 under different initial yaw angles (±20°), demonstrating good heading adaptive capability and dynamic path adjustment. The proposed method provides effective and robust technical support for deploying agricultural robots in complex field environments. It has potential generalization value in other crop row recognition tasks."
10.1145/3654439,The IDEA of Us: An Identity-Aware Architecture for Autonomous Systems,"Autonomous systems, such as drones and rescue robots, are increasingly used during emergencies. They deliver services and provide situational awareness that facilitate emergency management and response. To do so, they need to interact and cooperate with humans in their environment. Human behaviour is uncertain and complex, so it can be difficult to reason about it formally. In this article, we propose IDEA: an adaptive software architecture that enables cooperation between humans and autonomous systems, by leveraging the social identity approach. This approach establishes that group membership drives human behaviour. Identity and group membership are crucial during emergencies, as they influence cooperation among survivors. IDEA systems infer the social identity of surrounding humans, thereby establishing their group membership. By reasoning about groups, we limit the number of cooperation strategies the system needs to explore. IDEA systems select a strategy from the equilibrium analysis of game-theoretic models that represent interactions between group members and the IDEA system. We demonstrate our approach using a search-and-rescue scenario, in which an IDEA rescue robot optimises evacuation by collaborating with survivors. Using an empirically validated agent-based model, we show that the deployment of the IDEA system can reduce median evacuation time by 13.6\%."
10.5555/3466184.3466303,Unified DEVS-based platform for modeling and simulation of hybrid control systems,"Recent robotic research has led to different architectural approaches that support enactment of automatically synthesized discrete event controllers from user specifications over low-level continuous variable controllers. Simulation of these hybrid control approaches to robotics can be a useful validation tool for robot users and architecture designers, but presents the key challenge of working with discrete and continuous representations of the robot, its environment and its mission plans. In this work we address this challenge showcasing a unified DEVS-based hybrid simulation platform. We model and simulate the hybrid robotic software architecture of a fixed-wing UAV, including the full stack of controllers involved: discrete, hybrid and continuous. We validate the approach experimentally on a typical UAV mapping mission and show that with our unified approach we are able to achieve simulation speed-ups up to one order of magnitude above our previous Software In The Loop simulation setup."
10.1145/3604571.3604572,Empathy-Driven Innovation: Analysis of Five User-Centered Design Thinking Case Studies,"Design Thinking (DT) is widely used to drive innovation in companies. DT consists of five phases: empathy, define, ideation, prototype, and test. However, companies often skip the empathy process and go directly to the ideation phase. It is because empathy cannot immediately solve problems, is time- and resource-consuming, and is hindered by the cognitive bias that companies believe they already know what users or customers want. This article presents the process of empathy in five cases of Design Thinking (DT) projects in Indonesia carried out by postgraduate students who have worked in the companies for years. The projects discussed are a bank's marketing plan for ultra-micro entrepreneurs, the development of an online community platform by a software development company, the creation of tourist attractions in a forest area by the government tourism agency, the creation of an online ecosystem for the footwear industry by the government, and the development of a digital e-contract by a state-owned enterprise. We conducted a comparative case study analysis to examine the empathy process in meeting user needs and achieving innovation in these projects. This article argues that optimizing the empathic process in DT can lead to innovation. However, this empathic phase should continue through the ideation, prototyping, and testing phases. An individual who works in a company can initiate and carry out this empathy process. Nevertheless, the following phases require the support and involvement of all stakeholders in the company."
10.1145/3757232.3757240,Deep Rooted Connections: Cultivating Human-Plant-Computer Interaction Across Cultures and Technologies,"Human-Plant-Computer Interaction (HPCI) is an emerging interdisciplinary field that explores the integration of humans, plants, and computational technologies to create innovative, sustainable, and meaningful interactions. This paper presents a thematic-historical review of HPCI, tracing its roots across diverse domains such as bioelectrical engineering, agriculture, art, architecture, and robotics. It also highlights its evolution into modern applications like virtual environments, tangible interfaces, and extended reality. The review reveals HPCI’s broad scope, cultural and technological foundations, and capacity to address global challenges, particularly sustainability. While North America, Europe, and Asia – especially Japan – dominate the research landscape, contributions from Africa and South America remain limited. This gap underscores the need for a more inclusive approach incorporating diverse cultural and ecological knowledge. This paper identifies key milestones, trends, and interdisciplinary overlaps by examining the field’s progression, offering insights into HPCI’s potential to enrich human-nature relationships. The paper advocates for a broader definition of HPCI that accommodates regional perspectives and promotes collaboration across disciplines. Future directions include visualizing HPCI’s geographical and temporal evolution, exploring researchers’ motivations, and fostering contributions from underrepresented regions. These efforts can help ensure that HPCI addresses pressing global sustainability issues and represents the diverse voices and contexts essential for its growth. This review aims to inspire a more inclusive, globally relevant HPCI research community and advance sustainable innovation at the intersection of technology, ecology, and culture."
10.1145/3652628.3652828,Robot trajectory optimization design based on hybrid ant colony algorithm,"This thesis investigates the innovative integration and application of algorithms of hybrid ant colony algorithm in solving intelligent robot path optimization problems. Among the many branches of intelligent robots, the path planning problem is a particularly important one, and with the development of science and technology and the wide application of intelligent robots, the design of robot trajectory optimization is facing new challenges. The native ant colony algorithm is easy to fall into the local optimal solution in dealing with the problem of robot path planning. Through algorithm analysis, a hybrid ant colony algorithm is proposed. When integrating genetic algorithm and incorporating crossover and mutation factors into the hybrid ant colony algorithm, it not only enhances the diversity of the population, but also speeds up the convergence speed of the algorithm and improves the quality of the optimal solution. The case study shows that the combination of ant colony algorithm and genetic algorithm effectively avoids the problems of instability and poor robustness of the traditional ant colony algorithm, and a more efficient and stable path planning solution can be obtained, which further improves the working effect of the intelligent robot."
10.1145/3377812.3381398,Towards DO-178C certification of adaptive learning UAV agents designed with a cognitive architecture,"Adaptive and Learning Agents (ALAs) bring computational intelligence to their Cyber Physical host systems to adapt to novel situations encountered in their complex operational environment. They do so by learning from their experience to improve their performance. RTCA DO-178C specifies a stringent certification process for airborne software which represents several challenges when applied to an ALA in regards of functional completeness, functional correctness, testability and adaptability. This research claims that it is possible to certify an Adaptive Learning Unmanned Aerial Vehicle (UAV) Agent designed as per a Cognitive Architecture with current DO-178C certification process when leveraging a qualified tool (DO-330), Model-Based Development and Verification (DO-331) and Formal Methods (DO-333). The research consists in developing, as a case study, an ALA embedded in a UAV aimed at neutralizing rogue UAVs in the vicinity of civil airports and test it in the field. This article is the plan to complete, by end 2022, a dissertation currently in its confirmation phase."
10.1145/3461702.3462520,Alienation in the AI-Driven Workplace,"This paper asks whether explanations of one's workplace and economic institutions are valuable in and of themselves. In doing so, it departs from much of the explainability literature in law, computer science, philosophy, and the social sciences, which examine the instrumental values that explainable AI has: explainable systems increase accountability and user trust, or reduce the risk of harm due to increased robustness. Think, however, of how you might feel if you went to your local administrative agency to apply for some benefit, or you were handed down a decision by a judge in a court. Let's stipulate that you know that the decision was just, even though neither the civil servant nor the judge explain to you why the decision was made, and you don't know the relevant rules; you just brought all the information you had about yourself, and hoped for the best. Is such a decision process defective? I argue that such a decision process is defective because it prevents individuals from accessing the normative explanations that are necessary to form an appropriate practical orientation towards their social world. A practical orientation is a reflective stance towards one's social world, which is expressed in one's actions and draws on one's cognitive architecture that allows one to navigate the various social practices and institutions. A practical orientation can range from rejection to silent endorsement, and is the sort of attitude for which there are the right kind of reasons, based in the world's normative character. It also determines how one fills out one's role obligations, and, more broadly, guides one's actions in the relevant institution: a teacher in the American South during the time of enforced racial segregation, for example, might choose where to teach on the basis of her rejection of the segregation of education. To form an appropriate practical orientation, one must have an understanding of the social world's normative character, which required a normative explanation And, since we spend so much of our lives at work and are constrained by economic institutions, we must understand their structure and how they function."
10.1145/3746059.3747722,Creating General User Models from Computer Use,"Human-computer interaction has long imagined technology that understands us—from our preferences and habits, to the timing and purpose of our everyday actions. Yet current user models remain fragmented, narrowly tailored to specific applications, and incapable of the flexible, cross-context reasoning required to fulfill these visions. This paper presents an architecture for a general user model (GUM) that learns about you by observing any interaction you have with your computer. The GUM takes as input any unstructured observation of a user (e.g., device screenshots) and constructs confidence-weighted natural language propositions that capture that user’s behavior, knowledge, beliefs, and preferences. GUMs can infer that a user is preparing for a wedding they’re attending from a message thread with a friend. Or recognize that a user is struggling with a collaborator’s feedback on a draft paper by observing multiple stalled edits and a switch to reading related work. GUMs introduce an architecture that infers new propositions about a user from multimodal observations, retrieves related propositions for context, and continuously revises existing propositions. To illustrate the breadth of applications that GUMs enable, we demonstrate how they augment chat-based assistants with contextual understanding, manage OS notifications to surface important information only when needed, and enable interactive agents that adapt to user preferences across applications. We also instantiate a new class of proactive assistants (Gumbos) that discover and execute useful suggestions on a user’s behalf based on their GUM. In our evaluations, we find that GUMs make calibrated and accurate inferences about users, and that assistants built on GUMs proactively identify and perform actions of meaningful value that users wouldn’t think to request explicitly. Altogether, GUMs introduce new methods that leverage large multimodal models to understand unstructured user context, enabling both long-standing visions of HCI and entirely new interactive systems that anticipate user needs."
10.1145/3536167,Personal Space in Human-Robot Interaction at Work: Effect of Room Size and Working Memory Load,"A recent literature review on personal space in human-robot interaction identified a research gap for the influence of contextual factors. At the same time, psychological research on interpersonal distancing and theoretical considerations based on compensatory control models suggest the importance of considering these factors in robot path planning. To address this gap, we tested the effect of room size and working memory load on participants’ comfort distance toward an approaching robot. In a preregistered 3 \texttimes{} 2 within-subject design, N = 72 participants were approached by a mobile manufacturing robot in a corridor with varying room size and with and without a cognitive secondary task. As dependent variables, comfort distance, arousal, and perceived control were measured. While room size and working memory load had no significant direct effect on comfort distance, participants felt higher arousal and lower control in smaller rooms and in conditions with high working memory load, which in turn caused larger comfort distances (indirect effect). With experience, comfort distances decreased. Based on the indirect effects, future studies should test the effect of more extreme manipulations on comfort distances. Robots should adapt their path planning by keeping larger distances toward human workers in stressful environments to avoid discomfort."
10.1145/3768740.3768800,Master-Slave Robot Collaborative Control Strategy Research Based on Multi-Source Data Fusion and Dynamic Target Recognition,"Master-slave robotic collaborative systems face technical challenges in multi-source information processing and real-time target recognition in complex dynamic environments. To address the limitations of traditional single-sensor data and insufficient target recognition accuracy, a master-slave robot cooperative control strategy based on multi-source data fusion and dynamic target recognition is proposed. The strategy employs a data fusion algorithm combining Extended Kalman Filter and Particle Filter to effectively integrate information from LiDAR, RGB-D cameras, and IMU sensors. A dynamic target recognition model based on YOLOv5 is constructed, incorporating the DeepSORT tracking algorithm to achieve real-time target tracking and state prediction. A hierarchical cooperative control architecture based on Contract Net Protocol is designed, where the master robot undertakes global task planning and resource scheduling, while slave robots execute local path planning and precise operation control. Experimental results demonstrate that the control strategy achieves a target recognition accuracy of 94.2\%, improves collaborative operation efficiency by 32.4\%, and reduces system response time to 120ms, significantly outperforming other methods, providing an effective solution for multi-robot collaborative operations in intelligent manufacturing environments."
10.1145/3768292.3770347,ProtoHedge: Interpretable Hedging with Market Prototypes,"Deep hedging has emerged as a powerful framework for financial risk management, capable of learning effective hedging strategies in the presence of market frictions. However, its reliance on black-box neural networks creates a critical barrier to adoption, limiting trust, auditability, and regulatory compliance. In this work, we address this challenge by introducing a transparent alternative to the black-box Deep Hedging paradigm. Instead of relying on an opaque architecture, our model learns a finite set of representative market states, or “prototypes”. Hedging decisions are then made via a transparent, similarity-based mechanism: the agent’s action is a weighted average of learned actions associated with each prototype. We call our specific implementation of this framework ProtoHedge. The reasoning approach makes every decision traceable to understandable market scenarios. We conduct extensive experiments in both classical Black-Scholes and more realistic stochastic volatility environments. Our results demonstrate that this interpretability is achieved with minimal impact of less than 0.40\% on hedging performance, as our model’s hedging effectiveness is comparable to that of the original black-box deep hedging agent. This work shows that transparency and performance are not mutually exclusive, paving the way for more trustworthy automated risk management systems."
10.1145/3680530.3695442,Eye of Flora: Encountering Nature through the Mixed Reality Lens of Plant-Environment Interactions,"This paper presents a hybrid plants-driven mixed reality (MR) system, Eye of Flora, which re-engages humans with nature from a more-than-human perspective. Eye of Flora integrates plants into digital twin systems by merging plant electrophysiology with 3D reconstruction technologies. Utilizing AI to analyze their biosignals, digital plant agents can now participate in digital environments and share their unseen biological responses to various environmental factors through aesthetic particle systems. This approach challenges anthropocentric digital ecosystems by incorporating ecological awareness through a multispecies perspective, promoting a holistic view of human-nature relationships and fostering symbiotic coexistence in the digital age."
10.1145/3766918.3766948,Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework,"With the proliferation of Large Language Models (LLMs), the detection of misinformation has become increasingly important and complex. This research proposes an innovative verifiable misinformation detection LLM agent that goes beyond traditional true/false binary judgments. The agent actively verifies claims through dynamic interaction with diverse web sources, assesses information source credibility, synthesizes evidence, and provides a complete verifiable reasoning process. Our designed agent architecture includes three core tools: precise web search tool, source credibility assessment tool and numerical claim verification tool. These tools enable the agent to execute multi-step verification strategies, maintain evidence logs, and form comprehensive assessment conclusions. We evaluate using standard misinformation datasets such as FakeNewsNet, comparing with traditional machine learning models and LLMs. Evaluation metrics include standard classification metrics, quality assessment of reasoning processes, and robustness testing against rewritten content. Experimental results show that our agent outperforms baseline methods in misinformation detection accuracy, reasoning transparency, and resistance to information rewriting, providing a new paradigm for trustworthy AI-assisted fact-checking."
10.1145/3696673.3723065,Academic Advising Chatbot Powered with AI Agent,"Academic advising plays a crucial role in fostering student success. However, challenges such as limited advisor availability can hinder effective support. Generative AI, particularly AI-powered chatbots, offers the potential to enhance student advising in higher education by providing personalized guidance. These technologies help college students find the information and resources needed to create degree plans aligned with their academic goals. This research introduces ARGObot, an intelligent advising system that facilitates student navigation of university policies through automated interpretation of the student handbook as its primary knowledge base. ARGObot enhances accessibility to critical academic policies and procedures, supporting incoming students' success through personalized guidance. Our system integrates a multifunctional agent enhanced by a Large Language Model (LLM). The architecture employs multiple external tools to enhance its capabilities: a Retrieval-Augmented Generation (RAG) system accesses verified university sources; email integration facilitates Human-in-the-Loop (HITL) interaction; and a web search function expands the system's knowledge base beyond predefined constraints. This approach enables the system to provide contextually relevant and verified responses to various student queries. This architecture evolved from our initial implementation based on Gemini 1 Pro, which revealed significant limitations due to its lack of agent-based functionality, resulting in hallucination issues and irrelevant responses. Subsequent evaluation demonstrated that our enhanced version, integrating GPT-4 with the text-embedding-ada-002 model, achieved superior performance across all metrics. This paper also presents a comparative analysis of both implementations, highlighting the architectural improvements and their impact on system performance."
10.5555/3709347.3743788,Personality-Driven Decision Making in LLM-Based Autonomous Agents,"The embedding of Large Language Models (LLMs) into autonomous agents is a rapidly developing field which enables dynamic, configurable behaviours without the need for extensive domain-specific training. In our previous work, we introduced SANDMAN, a Deceptive Agent architecture leveraging the Five-Factor OCEAN personality model, demonstrating that personality induction significantly influences agent task planning. Building on these findings, this study presents a novel method for measuring and evaluating how induced personality traits affect task selection processes-specifically planning, scheduling, and decision-making-in LLM-based agents. Our results reveal distinct task-selection patterns aligned with induced OCEAN attributes, underscoring the feasibility of designing highly plausible Deceptive Agents for proactive cyber defense strategies."
10.1145/3679409.3679473,Design and Research of Octahedral Linkage Mobile Robot,"In the face of complex terrain, the performance of robots with single motion mode is poor. This paper proposes a mobile robot based on the Sarrus mechanism and octahedral structure of spatial closed chain linkage based on the current research status. After planning of rolling modes, wheeled mode and hybrid mode, the mobile robot can be operated to gain the mobility of traversal movement by specified control method. When facing ordinary road surface and terrains, the robot achieves excellent adaptability to different environment compared with conventional mobile robot."
10.1145/3387940.3391501,MSABot: A Chatbot Framework for Assisting in the Development and Operation of Microservice-Based Systems,"Microservice architecture (MSA) has become a popular architectural style. The main advantages of MSA include modularization and scalability. However, the development and maintenance of Microservice-based systems are more complex than traditional monolithic architecture. This research plans to develop a novel Chatbot system, referred to as MSABot (Microservice Architecture Bot), to assist in the development and operation of Microservice-based systems by using Chatbots. MSABot integrates a variety of tools to allow users to understand the current status of Microservice development and operation, and to push the information of system errors or risks to users. For the operators who take over the maintenance of Microservices, MSABot also allows them to quickly understand the overall service architecture and the operation status of each service. Besides, we invited multiple users who are familiar with the technology of Microservice or ChapOps to evaluate MSABot. The results of the survey show that more than 90\% of the respondents believe that MSABot can adequately support the development and maintenance of Microservice-based systems."
10.1145/3491102.3501992,Rediscovering Affordance: A Reinforcement Learning Perspective,"Affordance refers to the perception of possible actions allowed by an object. Despite its relevance to human–computer interaction, no existing theory explains the mechanisms that underpin affordance-formation; that is, how affordances are discovered and adapted via interaction. We propose an integrative theory of affordance-formation based on the theory of reinforcement learning in cognitive sciences. The key assumption is that users learn to associate promising motor actions to percepts via experience when reinforcement signals (success/failure) are present. They also learn to categorize actions (e.g., “rotating” a dial), giving them the ability to name and reason about affordance. Upon encountering novel widgets, their ability to generalize these actions determines their ability to perceive affordances. We implement this theory in a virtual robot model, which demonstrates human-like adaptation of affordance in interactive widgets tasks. While its predictions align with trends in human data, humans are able to adapt affordances faster, suggesting the existence of additional mechanisms."
10.1145/3711896.3737141,Swarm Intelligence in Geo-Localization: A Multi-Agent Large Vision-Language Model Collaborative Framework,"Visual geo-localization demands in-depth knowledge and advanced reasoning skills to associate images with precise real-world geo-graphic locations. Existing image database retrieval methods are limited by the impracticality of storing sufficient visual records of global landmarks. Recently, Large Vision-Language Models (LVLMs) have demonstrated the capability of geo-localization through Visual Question Answering (VQA), enabling a solution that does not require external geo-tagged image records. However, the performance of a single LVLM is still limited by its intrinsic knowledge and reasoning capabilities. To address these challenges, we introduce smileGeo, a novel visual geo-localization framework that leverages multiple Internet-enabled LVLM agents operating within an agent-based architecture. By facilitating inter-agent communication, smileGeo integrates the inherent knowledge of these agents with additional retrieved information, enhancing the ability to effectively localize images. Furthermore, our framework incorporates a dynamic learning strategy that optimizes agent communication, reducing redundant interactions and enhancing overall system efficiency. To validate the effectiveness of the proposed framework, we conducted experiments on three different datasets, and the results show that our approach significantly outperforms current state-of-the-art methods. The source code is available at https://github.com/Applied-Machine-Learning-Lab/smileGeo."
10.5555/3463952.3464115,Intention Progression using Quantitative Summary Information,"A key problem for Belief-Desire-Intention (BDI) agents is intention progression, i.e., which plans should be selected and how the execution of these plans should be interleaved so as to achieve the agent's goals. Monte-Carlo Tree Search (MCTS) has been shown to be a promising approach to the intention progression problem, out-performing other approaches in the literature. However, MCTS relies on runtime simulation of possible interleavings of the plans in each intention, which may be computationally costly. In this paper, we introduce the notion of quantitative summary information which can be used to estimate the likelihood of conflicts between an agent's intentions. We show how offline simulation can be used to precompute quantitative summary information prior to execution of the agent's program, and how the precomputed summary information can be used at runtime to guide the expansion of the MCTS search tree and avoid unnecessary runtime simulation. We compare the performance of our approach with standard MCTS in a range of scenarios of increasing difficulty. The results suggest our approach can significantly improve the efficiency of MCTS in terms of the number of runtime simulations performed."
10.1145/3460210.3493585,Cutting Events: Towards Autonomous Plan Adaption by Robotic Agents through Image-Schematic Event Segmentation,"Autonomous robots struggle with plan adaption in uncertain and changing environments. Although modern robots can make popcorn and pancakes, they are incapable of performing such tasks in unknown settings and unable to adapt action plans if ingredients or tools are missing. Humans are continuously aware of their surroundings. For robotic agents, real-time state updating is time-consuming and other methods for failure handling are required. Taking inspiration from human cognition, we propose a plan adaption method based on event segmentation of the image-schematic states of subtasks within action descriptors. For this, we reuse action plans of the robotic architecture CRAM and ontologically model the involved objects and image-schematic states of the action descriptor cutting. Our evaluation uses a robot simulation of the task of cutting bread and demonstrates that the system can reason about possible solutions to unexpected failures regarding tool use."
10.1145/3424953.3426510,Analyzing the socioenactive dimensions of creative learning environments with preschool children,"Several published papers discuss how to encourage creativity in the classroom. An emerging concept is creative learning, which attempts to understand, experiment, and define methodologies and learning environments designed to promote creativity. Enaction theorists, a new thread of cognitive science, understand that cognition and creativity always emerge through real-time interaction with the environment and other agents in that environment. Socioenactive systems are extensions to the enactive system concept, bringing attention to socio-cultural values in the dynamic coupling of the human (through the body senses) and technology. This work aims to explore and understand the creative process of preschool children during their interaction with a tangible programming environment (TaPrEC+mBot) that allows programming of a robot car by arranging wooden blocks. The analysis draws on the physical, digital, and social dimensions of socioenactive systems. The results show that the children felt especially involved through their bodies and engaged in the activity of creating their own programming scenario. They also suggest that the children's reasoning and behavior seem to be connected or influenced by their body movements and their physical, social and digital experience and interaction with the tangible programming environment."
10.1145/3759355.3759371,Simulating Attachment Behavior in Mobile Robots Through Toy Following Tasks,"This paper presents a behaviorally inspired toy-following mobile robot system designed to simulate attachment-driven behavior, taking conceptual motivation from the Strange Situation Test (SST) used in canine psychology. The system integrates a top-down vision approach using a Basler a2A1920-160ucBAS camera, where a YOLOv11 object detection model—trained on a custom dataset with two classes (robot and toy)—is used to localize both entities in real time. A homography-based camera calibration process maps fisheye image coordinates to world positions, which are processed in a ROS-based architecture. Path planning is performed using the Improved RRT* with Reduced Random Map Size (IRRT*-RRMS) algorithm, while motion control combines Vector Field Histogram (VFH) for obstacle avoidance with a Pure Pursuit controller for trajectory tracking. The system was implemented on a TurtleBot3 Waffle Pi and evaluated in a 4.32 \texttimes{} 2.88-meter indoor environment with manually moved toy targets. Experimental results demonstrate high tracking accuracy and a strong success rate, confirming the system’s effectiveness in simulating real-time pursuit behavior under the attachment model. The proposed approach provides a foundation for future research in emotionally responsive robotics and animal-inspired human–robot interaction."
10.1145/3686015.3689365,Mycorrhizal Fungi and Plant Symbiosis for Energy Harvesting in the Internet of Plants,"Biological entities in nature have developed sophisticated communication methods over millennia to facilitate cooperation. Among these entities, plants are some of the most intricate communicators. They interact with each other through various communication modalities, creating networks that enable the exchange of information and nutrients. In this paper, we explore this collective behavior and its components. We then introduce the concept of agent plants, outlining their architecture and detailing the tasks of each unit. Additionally, we investigate the mycorrhizal fungi-plant symbiosis to extract glucose for energy harvesting. We propose an architecture that converts the chemical energy stored in these glucose molecules into electrical energy. We conduct comprehensive analyses of the proposed architecture to validate its effectiveness."
10.1145/3565287.3617637,Toward a Better Understanding of the Emotional Dynamics of Negotiation with Large Language Models,"Current approaches to building negotiation agents rely either on model-based techniques that explicitly implement key principles of negotiation or model-free techniques leveraging algorithms developed via training on large amounts of human-generated text. We bridge these two approaches by combining a model-based approach with large language models for natural language understanding and generation. We find large language models perform well at recognizing dialogue acts and an opponent's emotions; perform reasonably well at recognizing opponents' preferences in the negotiation; and perform worse at understanding opponent offers. We also perform a qualitative comparison of the capabilities of our hybrid approach with a model-free method and find our hybrid agent provides safeguards against hallucinations and guarantees more control over aspects of negotiation such as emotional expressions, information sharing, and concession strategies."
10.1145/3760269.3760353,ABCM: Agent-Based Complexity Management Method for Intelligent Manufacturing,"Modern intelligent manufacturing systems are inherently complex, driven by product variety, dynamic scheduling, and intricate interactions among humans, machines, and materials. This complexity presents significant challenges for production planning, control, and decision-making. To address these issues, we propose ABCM (Agent-Based Complexity Management), a novel method that integrates system dynamics simulation with a large language model (LLM)-based agent framework. ABCM utilizes PySD to simulate manufacturing processes and extract structured model outputs, which are analyzed through a suite of modular tools registered within a LangChain agent. These tools enable the computation of descriptive statistics, dynamic performance indicators, and complexity metrics—including entropy, rise time, overshoot, and integral errors—thus allowing for automated, data-driven complexity assessment. The agent autonomously interprets simulation results, identifies performance bottlenecks, and offers optimization recommendations. A case study demonstrates the practical application of ABCM in managing production variability and enhancing system responsiveness. The modular and extensible architecture supports scalable deployment in diverse intelligent manufacturing scenarios, contributing to improved adaptability, efficiency, and complexity control."
10.5555/3535850.3535914,Intention-Aware Navigation in Crowds with Extended-Space POMDP Planning,"This paper presents a hybrid online Partially Observable Markov Decision Process (POMDP) planning system that addresses the problem of autonomous navigation in the presence of multi-modal uncertainty introduced by other agents in the environment. As a particular example, we consider the problem of autonomous navigation in dense crowds of pedestrians and among obstacles. Popular approaches to this problem first generate a path using a complete planner (e.g., Hybrid A*) with ad-hoc assumptions about uncertainty, then use online tree-based POMDP solvers to reason about uncertainty with control over a limited aspect of the problem (i.e. speed along the path). We present a more capable and responsive real-time approach enabling the POMDP planner to control more degrees of freedom (e.g., both speed AND heading) to achieve more flexible and efficient solutions. This modification greatly extends the region of the state space that the POMDP planner must reason over, significantly increasing the importance of finding effective roll-out policies within the limited computational budget that real time control affords. Our key insight is to use multi-query motion planning techniques (e.g., Probabilistic Roadmaps or Fast Marching Method) as priors for rapidly generating efficient roll-out policies for every state that the POMDP planning tree might reach during its limited horizon search. Our proposed approach generates trajectories that are safe and significantly more efficient than the previous approach, even in densely crowded dynamic environments with long planning horizons."
10.1145/3652628.3652670,Multi-Constraint Flexible Job Scheduling Algorithm Based on DDQN: A Deep Reinforcement Learning Algorithm for Solving Practical Job Scheduling Problems,"As an important part of intelligent manufacturing, reasonable scheduling of production planning is very important for reducing costs and increasing efficiency. This paper considers that the current algorithms related to intelligent scheduling do not consider the actual constraints enough, and the solution efficiency cannot satisfy the application requirements. Considering the actual industrial production and a variety of practical constraints including employee attendance time and machine start-up time, this paper proposes a deep reinforcement learning algorithm. The goal of this research is to minimize the total production cost including product processing costs, employee overtime costs, order back-order costs, finished and semi-finished product inventory costs. In this paper, the intelligent scheduling problem is modeled as a Markov decision-making process, and the agent selects and executes actions according to the state at each decision-making stage. In this paper, the Double DQN neural network architecture is built. Seven features are extracted from the scheduling environment to form a feature vector representation state, and six composite scheduling rules are designed to form an action set considering the optimization goal. A reward function closely related to the goal is designed. Numerical experiments show that the quality of the solution set obtained by the reinforcement learning algorithm is better than or similar to that of the genetic algorithm, and the solution speed is significantly better than that of other algorithms, which proves the effectiveness and feasibility of the proposed algorithm."
10.1145/3610419.3610475,Redundantly Actuated Hybrid Kinematic setup for high Manipulability,"Robot workspace and Manipulability analysis are essential for choosing the most optimum robot and planning the Toolpath for a particular task. Standard industrial robots can be modified to increase their workspace and overall Manipulability by moving their base on a predetermined optimum track, thus, increasing their overall effectivity. Hybrid robot kinematic chains can benefit from both the properties of having a serial and parallel chain, giving maneuverability and dexterity, along with good accuracy and rigidity. This paper aims to find the advantages of moving such a hybrid system on a curved track by comparing the Manipulability plots in the reachable workspace. The track can be optimized per the user’s demand for the lower limit of Manipulability, which may vary as per the task the machine has to perform."
10.1145/3745238.3745531,"A Survey of Multi-AI Agent Collaboration: Theories, Technologies and Applications","As an important application of large language model(LLM), artificial intelligence agent(AI Agent) have the ability to autonomously perceive, understand, plan, memory, act, and use tools. It can automate complex tasks and effectively empower various business scenarios. Single AI Agent flexible and diverse deployment, multi-AI Agent innovative interaction and collaboration, multi-AI Agent collaboration improves the autonomy of the intelligent system by integrating the capabilities of single AI Agent. This paper provides an overview of multi-AI Agent from four aspects. Firstly, the core capabilities of AI Agent were outlined, and multi-AI Agent collaboration was introduced and its characteristics were analyzed. Secondly, the theoretical basis, key technologies, and scenario applications of multi-AI Agent collaboration were discussed, and the mechanism, architecture design, communication protocol, reinforcement learning, security and trustworthiness of multi-AI Agent collaboration were deeply studied. Thirdly, the advantages and disadvantages of multi-AI Agent collaboration in technology, application, and security directions were summarized, and frontier research and innovation directions were provided. Finally, a summary and outlook were made on the high-quality development of multi-AI Agent collaboration."
10.1145/3657054.3657119,Digital Government Ecosystem: Adaptive Architecture for Digital and ICT Investment Decision Making,"Agencies, while operating in the federated digital government ecosystem, need to make significant investments in digital and information and communication technology (ICT) for providing services to people and businesses. A whole-of-government adaptive architecture driven approach seems appropriate for supporting common language and consistent digital and ICT investment decision making. It enables adaptive planning and implementation with a view to make an optimal use of public funds and aligned with the strategic direction and priorities in digital and ICT investments. However, the challenge is how to establish the adaptive architecture for supporting digital and ICT investment decision making in the complex and federated digital government ecosystem. This paper proposes the adaptive enterprise architecture (AEA) meta-framework for digital ecosystems, as a lens, to systematically integrate the Australian Government Architecture (AGA), and Digital and ICT Oversight Investment Framework (IOF) in establishing the adaptive architecture for assisting digital and ICT investment decisions within complex digital government ecosystems. The proposed approach is demonstrated and evaluated with the help of an example scenario for an Australian digital government service. The results of this study indicate that the adaptive architecture driven approach involving AGA and IOF seems useful for architecting and supporting complex digital and ICT investment decision making to deliver the holistic outcomes of data and digital government strategy objectives."
10.5555/3643142.3643315,Investigating Production Yield Effect on Inventory Control through a Hybrid Simulation Approach,"Production Planning and Control (PPC) plays a key role in stabilizing and improving manufacturing processes under external and internal uncertainties by providing transparency in the whole system. This study focuses on PPC with internal uncertainties such as losses of work-in-process products during a contact lens manufacturing process. Although such losses are expected, the yield rates are uncertain and vary at different production stages. A hybrid agent-based simulation (ABS) and discrete-event simulation (DES) approach was utilized to resemble the underlying dynamics of the manufacturing system with uncertain yield rates. The results of the simulation experiments demonstrated that a simple average yield approach for production planning would cause potential backlogs and extra holding costs for the excess inventory. The proposed hybrid simulation could be used to support the decision-making process on a weekly basis to help a production planning team make a schedule that would improve efficiency and customer satisfaction."
10.1145/3613904.3642465,The Adaptive Architectural Layout: How the Control of a Semi-Autonomous Mobile Robotic Partition was Shared to Mediate the Environmental Demands and Resources of an Open-Plan Office,"A typical open-plan office layout is unable to optimally host multiple collocated work activities, personal needs, and situational events, as its space exerts a range of environmental demands on workers in terms of maintaining their acoustic, visual or privacy comfort. As we hypothesise that these demands could be coped by optimising the environmental resources of the architectural layout, we deployed a mobile robotic partition that autonomously manoeuvres between predetermined locations. During a five-weeks in-the-wild study within a real-world open-plan office, we studied how 13 workers adopted four distinct adaptation strategies when sharing the spatiotemporal control of the robotic partition. Based on their logged and self-reported reasoning, we present six initiation regulating factors that determine the appropriateness of each adaptation strategy. This study thus contributes to how future human-building interaction could autonomously improve the experience, comfort, performance, and even the health and wellbeing of multiple workers that share the same workplace."
10.1145/3744464.3744491,Design of Robot Single Conveyor Double Sided Multi Layer Handling and Stacking Control System,"The robot handling and palletizing control system is widely used in industries such as box packaging processing and logistics. The handling and palletizing control system can assist packaging production lines in achieving rapid handling and palletizing of boxes, facilitating subsequent transportation and processing of boxes. At present, the handling and palletizing control system is mainly aimed at the application of unidirectional palletizing layout in single conveyor production lines. The efficiency of handling and palletizing is low, and its control algorithm is complex, with many repeated trajectories, which makes it difficult to speed up the system operation and has a significant impact on the production and processing output of box bodies. Using robotstudio software, a control system for single conveyor line handling and double-sided multi-layer palletizing based on robot control is designed to meet the needs of real production line box handling and palletizing. By building a structured handling and palletizing control algorithm architecture, simplifying the layout of handling and palletizing workstations, optimizing the handling and palletizing process, the efficiency of robot motion trajectory planning is improved, and problems such as low intelligence level, low production efficiency, and cumbersome robot operation trajectory of handling and palletizing production lines are solved."
10.1145/3543507.3583380,Response-act Guided Reinforced Dialogue Generation for Mental Health Counseling,"Virtual Mental Health Assistants (VMHAs) have become a prevalent method for receiving mental health counseling in the digital healthcare space. An assistive counseling conversation commences with natural open-ended topics to familiarize the client with the environment and later converges into more fine-grained domain-specific topics. Unlike other conversational systems, which are categorized as open-domain or task-oriented systems, VMHAs possess a hybrid conversational flow. These counseling bots need to comprehend various aspects of the conversation, such as dialogue-acts, intents, etc., to engage the client in an effective and appropriate conversation. Although the surge in digital health research highlights applications of many general-purpose response generation systems, they are barely suitable in the mental health domain – the prime reason is the lack of understanding in the mental health counseling conversation. Moreover, in general, dialogue-act guided response generators are either limited to a template-based paradigm or lack appropriate semantics in dialogue generation. To this end, we propose READER – a REsponse-Act guided reinforced Dialogue genERation model for the mental health counseling conversations. READER is built on transformer to jointly predict a potential dialogue-act dt + 1 for the next utterance (aka response-act) and to generate an appropriate response (ut + 1). Through the transformer-reinforcement-learning (TRL) with Proximal Policy Optimization (PPO), we guide the response generator to abide by dt + 1 and ensure the semantic richness of the responses via BERTScore in our reward computation. We evaluate READER on HOPE, a benchmark counseling conversation dataset and observe that it outperforms several baselines across several evaluation metrics – METEOR, ROUGE, and BERTScore."
10.1145/3564121.3564125,A Hybrid Planning System for Smart Charging of Electric Fleets,"Electric vehicle (EV) fleets are well suited for last-mile deliveries both from sustainability and operational cost perspectives. To ensure economic parity with non-EV options, even captive chargers for EV fleets need to be managed intelligently. Specifically, the EVs needs to be adequately charged for their entire delivery runs while handling reduced time flexibility between runs; limited number of chargers; and deviations from the planned schedule. Existing works either solve smaller instances of this problem optimally, or larger instances with significant sub-optimality. In addition, they typically consider either day-ahead or real-time planning in isolation. We complement existing works with a hybrid approach that first identifies a day-ahead plan for assigning EVs to chargers; and then uses online replanning to handle any deviations in real-time. For the day-ahead planning, we use a learning agent (LA) that learns to assign EVs to chargers over several problem instances. Because the agent solves a given instance during its testing phase, it achieves scale in problem size with limited sub-optimality. For the online replanning, we use a greedy heuristic that dynamically refines the day-ahead plan to handle delays in EV arrivals. We evaluate our approach using representative datasets. As baselines for the LA, we use an exact mixed-integer linear program (MILP) (greedy heuristic) for small (large) problem instances. As baselines for the replanning, we use no-planning and no-replanning. Our experiments show that LA performs better (8.5-14\%) than greedy heuristic in large problem instances, while being reasonably close (&lt; 22\%) to the optimal in smaller instances. For online replanning, our approach performs about 7-20\% better than no-planning and no-replanning for a range of delay profiles."
10.1145/3512917,"""I Just Can't Help But Smile Sometimes"": Collaborative Self-Management of Depression","Depression is a challenging condition that requires individuals to manage their moods and emotions over time. Within CSCW, there has been an interest in understanding how individuals seek and share support on social media and in online communities. However, less attention has been paid to how collaboration as an aspect of self-management of depression unfolds in people's daily lives. In this paper, we explore the collaborative self-management work of 28 individuals managing depression who live in the United States. Data collection included remote semi-structured interviews with an associated cognitive mapping exercise. Our findings describe who participants turn to for day-to-day collaborative support, how collaborative activities are enacted (across both mood-focused and preventative support practices), and where these often technology-mediated interactions occur across text, phone, video, and picture-based channels. We discuss collaborative self-management in the depression support context, including key characteristics: agency, reciprocity, time, and interaction. We also present a four-step model of how the process occurs over time (awareness, planning, interaction, and reflection). We conclude by discussing how technology ecosystems support individuals' collaborative self-management."
10.1145/3548608.3559184,Research on position and attitude control method of planar motion of 5-DOF hybrid robot,"In the agriculture industry, scholars are increasingly paying attention to the advantages of hybrid robots and applying them in agricultural production. Agricultural products such as tree trunks or fruit stems is formed by growth. When the hybrid robot is working, It is easier to obtain the ideal end pose of the hybrid robot by describing the pose relationship of the robot end relative to the work object than the robot end relative to the world coordinate system. In order to realize the continuous motion control of the hybrid robot with a specified relative attitude relative to a certain plane in space, a method to realized planar motion based on 2SPU+U+RRR type five-degree-of-freedom hybrid robot position and attitude control is proposed. First, the trajectory of the task is discretized, according to the required posture, and the position and attitude matrix of each position on the trajectory is derived. Then through the inverse solution of the kinematic model, the five-degree-of-freedom hybrid robot is completely decoupled. The pose of the robot end is calculated to realize the plane motion control of the robot with a specified pose in Cartesian space according to the kinematic model of the hybrid robot based on the mechanism equivalent principle. Finally, the pose control method of the robot is tested. The experimental results show that the control method can realize the accurate planar motion control of the specified pose in Cartesian space during the repeated planar motion of the 2SPU+U+RRR type 5-DOF hybrid robot. This paper provides a five-degree-of-freedom hybrid robot theoretical model for the position and attitude synchronous motion control of arbitrary plane in Cartesian space."
10.1145/3680127.3680211,A Generic Architecture for the Digitization of Government Procurement Processes,"The implementation of government information systems has been a means to improve social, political, and economic conditions and the quality of life of its citizens. However, the systems of the governments are very different and even within a country there are distinctions between the federal, state, local and agency levels according to their specific context and capabilities. Among the governmental systems, electronic procurement is critical as they are related to a significant part of public spending. The purpose of this paper is to describe an assessment of the current state of digitization of procurement processes of innovative governments to deduce components of a common architecture from their best practices experiences that can be utilized for benchmark evaluation. This study employed an Action Design Research approach to identify, stakeholders, processes, system applications, technological components, and standards of a generic architecture for e-procurement. As a result, it was possible to deduce from countries implemented cases and validate through an organization benchmarking action case a generic architecture with four main system components: (1) e-planning of government procurement, (2) e-selection of suppliers, and (3) e-provisioning of goods and services from suppliers (4) e-services to citizens. The most developed component in government cases is e-selection, however, further developments should be carried out in e-planning and e-provisioning, mainly the integration with e-services. This work demonstrates how management research can create references for digital transformation. As a practical implication, the architectural model provides professionals with a tool for benchmark assessments, for decision-make on the evolution of functionalities and system requirements for government e-procurement."
10.1145/3610579.3611082,Explaining Unsolvability of Planning Problems in Hybrid Systems with Model Reconciliation,"A recent problem of interest in Explainable AI Planning is that of explaining the unsolvability of planning problems. Though there has been a lot of research on generating explanations of solutions to planning problems, explaining the absence of solutions remains a largely open and understudied problem. Model reconciliation has been a popular approach for generating explanations for such problems in recent literature, which involves an AI agent and a human planner, who have different models of the planning domain and each explains to the other the differences they have in their domain representations and attempt to arrive at a consensus. More often than not, it is assumed that the AI agent has a correct and complete view of the domain, of which the human only has a partial view. Through reconciliation, the human domain is updated to be consistent with what the AI agent has. Most of the works in this direction are targeted toward classical planning problems on domains represented typically as discrete state transition systems or variants. In this paper, we provide an approach towards model reconciliation for planning problems in hybrid systems represented as a mix of discrete and continuous domains. We assume that the agent has a complete model of the environment, while the human has a partial or erroneous model and expects a plan for the planning problem when there is none. The explanation problem is presented as a process of continuous reconciliation between these two entities (agent and human) to make the human domain consistent with that of the agent. To this effect, we use a mix of graph traversal and path analysis, along with Linear programming to carry out the reconciliation process. In particular, we use the concept of Irreducible Infeasible Sets (IIS) to generate explanations. Experimental results on 2 representative hybrid domains show the efficacy of our approach."
10.1145/3759928.3759967,BiLSTM-Based Climate and Agricultural Supply Chain Resilience Modeling Using Time Series Forecasting in Ghana,"This study proposes a Bidirectional Long Short-Term Memory (BiLSTM) neural network to formulate a deep learning framework that predicts climate variables and measures the resilience of Ghana’s agricultural supply chain. The model uses past data from the Ghana Meteorological Agency to forecast future temperatures, rainfall, and a composite resilience index made up of crop yield, transport delay, labor availability, market price volatility, and storage capacity. The model architecture includes regularization methods like Batch Normalization, Gaussian Noise, and Layer Normalization. It then uses multi-output dense layers for tasks that need to make predictions at the same time. The model performed well in predicting the resilience index, with a Root Mean Squared Error (RMSE) of 0.0819, a Mean Absolute Error (MAE) of 0.0687, and a R2 score of 0.0697. The proposed BiLSTM model outperformed the persistent baseline naive model. Predictions of raw climate variables weren’t very accurate because they are naturally unstable. However, the resilience index, which is a smoothed composite metric, was predicted with more consistency. These results show that BiLSTM-based models could help with climate-resilient agricultural planning and decision-making in places like Northern Ghana, where there isn’t a lot of data and the climate is unreliable."
10.1145/3717413.3717418,Utilizing Autonomous Airport Parking Facilities as Virtual Power Plants to Provide Frequency Containment Reserve,"With the rise of inverter-based renewables, grid stability is increasingly strained. Electric vehicles (EVs) offer unique potential in enhancing this stability through intelligent (dis-)charging control; by aggregation, they can provide significant balancing services to network operators. To exploit this opportunity, airport parking is particularly well suited due to the large number of vehicles with predictable departure times. By using the novel Automated Valet Charging (AVC) technology, parking facilities can optimally schedule EVs---autonomously maneuvering cars to and from charge points and connecting them robotically. We propose using AVC-capable parking facilities as virtual power plants (VPPs), providing fast-acting frequency containment reserve (FCR). This study's key contributions are: 1) presenting the AVC VPP concept and formalizing its two core optimization tasks, 2) developing a modular co-simulation architecture for comprehensive evaluation, 3) performing preliminary experiments, to assess feasibility and to identify simulation challenges, and 4) outlining strategic recommendations for practical AVC VPP implementation. The results suggest the concept's potential in utilizing airport EV parking for FCR, promising additional revenue for parking operators without sacrificing customer satisfaction. However, for conclusive assessment, extended simulation models are necessary. Furthermore, prequalification emerges as a significant obstacle to profitable real-world applications. Ultimately, AVC VPPs may help with transforming EVs from being a burden on the grid to a valuable asset."
10.1145/3708597.3708615,Curriculum Reinforcement Learning with Hybrid Exploration Strategies for 2D Maze Path Planning: Simulated Strategies for Microrobot Navigation in Constrained Environments,"This paper presents a reinforcement learning (RL) framework designed to solve 2D maze path planning problems within simulated environments, with potential applications in microrobot navigation in constrained settings. The primary challenge addressed is the efficient training of an RL agent to navigate mazes ranging from simple 17x17 grids to complex 263x263 grids. Our approach integrates curriculum learning to increase the complexity of mazes during training gradually and employs hybrid exploration strategies to balance exploration and exploitation effectively. Although the experiments were conducted in a simulated environment, the methods developed hold significant promise for real-world microrobot applications. We benchmarked our RL framework, which is built on a Deep Q-Network (DQN), against traditional pathfinding algorithms such as Breadth-First Search (BFS), A-star, and Rapidly-exploring Random Trees (RRT). We trained our model on the subset of the ‘Curriculum - Lost in Maze Dataset,’ consisting of 3.1 million maze images, demonstrating the model's ability to generalize and efficiently solve unseen mazes. The model achieved an average loss of 12.67 across all maze sizes and adapted to new ones with an average time of 21.69. The proposed methodology results in significant improvements, with a 16.54\% increase in success rate and a 51.49\% improvement in path efficiency compared to the average of the two baseline methods. Our proposed approach potentially contributes to microrobot manipulation, where precise path planning is crucial for avoiding obstacles in real-time within a vision-based control system limited to a monocular top view by the optical microscope [1], [2], [3]."
10.5555/3721488.3721623,Capabilities2 for ROS2: Advanced Skill-Based Control for Human-Robot Interaction,"In the early days of the Open Source Robotics Foundation, a lesser-known project aimed to design an ''app-able robot'', leading to the creation of the ''Capabilities'' package for the Robot Operating System. Over a decade later, formulating robot capabilities remains a significant technical hurdle in bringing robots from the lab into everyday life. This paper introduces Capabilities2, a successor to the original Capabilities package, now reimagined for ROS2. Capabilities2 enhances the original design by enabling advancements in skill-based control techniques and offering a more efficient, extensible framework for defining and utilising robot capabilities. We delve into its application in new real-world scenarios, with a particular focus on human-robot interactions and the deployment of collaborative mobile robots in human-centric environments. Capabilities2 addresses challenges in implementing intuitive, collaborative robots by introducing an abstracted database handler, an object-relational mapping for capability models, and a plugin architecture for capability execution. These features support dynamic capability representation, runtime adaptability, and integration with modern AI techniques for skill-based task planning. By providing a standardised yet flexible framework, Capabilities2 reduces the integration effort required to develop top-level controls for real-world scenarios, facilitating rapid development and deployment. Our contributions include the reimplementation of the Capabilities package in ROS2, enhancements to support contemporary robotic applications, and demonstrations of new use cases enabled by Capabilities2. We believe that Capabilities2 significantly advances the field of robotics by equipping developers with tools to create more capable, adaptable, and interactive robots. Capabilities2 is available at https://github.com/CollaborativeRoboticsLab/capabilities2"
10.1145/3411764.3445540,”Naked and on Fire”: Examining Player Agency Experiences in Narrative-Focused Gameplay,"Player agency is central to interactive narrative and games. While previous work focuses on analyzing player perception of agency through various lenses and phenomena, like meaningful choice and expectations, it is largely theoretical. Few user studies within games explore how players reason about and judge their own agency within interactive narratives. We present an interview study where participants rated their agency experiences within narrative-focused games and described their reasoning. The analysis suggests that agency perception depends on multiple factors beyond meaningful choice, such as social investment and genre-conventions. Participants described varying preferences and value judgements for different factors, indicating that individual differences have a deep impact on agency perception in narrative-focused gameplay. We discuss the implications of these cognitive variables on design, how they can be leveraged with other factors, and how our findings can help future work enhance and measure player agency, within interactive narrative and beyond."
10.1145/3653081.3653145,Smart operation and maintenance management and application of wind farms,"It has become a trend to use artificial intelligence, big data, cloud/edge computing and other technologies to improve power generation efficiency and supervision capabilities to achieve ""new energy +"". This article follows the principles of ""few people on duty, situation-based maintenance, and digital operation and maintenance"" to build an intelligent site and platform of ""remote centralized operation + regional maintenance + smart site"". Real-time detection, analysis, diagnosis, and operation optimization of new energy power plants. Additionally, this paper proposes AnoGAN, a hybrid model that combines generative adversarial networks (GANs) and variational autoencoders (VAEs) for anomaly detection. It generates normal data and detects anomalies through generated data errors, contributing to the intelligent operation and maintenance of wind farms. The wheeled robot replaces manual tasks in critical areas and embodies the integration of advanced anomaly detection technology with practical robotic solutions for efficient power infrastructure maintenance."
10.1145/3565287.3617610,Towards extreme network KPIs with programmability in 6G,"6G's superpower must be simplicity, which should not be viewed as a constraint, but rather as the organic outcome of using the most advanced technologies at our disposal. Programmability in the data plane, cloud-native features like automatic scaling and failover, transparent acceleration of both network functions and applications and AI-driven optimizations are already present. We only need to integrate these different innovations into a consistent architecture and offer a simple yet powerful solution for the very different applications that would use future mobile networks. The application space is getting more and more heterogeneous, e.g., legacy Internet-based services still using the good old TCP protocol, future media services relying on multipath transport - always utilizing the best available connection, or control applications of robots or drones requiring extreme low and stable latency. The different applications will require very different Key Performance Indicators (KPIs) from the network. In this paper, we present a novel architecture called DESIRE6G (D6G) architecture that aims to fulfill these requirements by integrating the key technological innovations mentioned above. Besides supporting the diverse KPIs of future applications, the novel architecture should also simplify the mobile network itself by promoting modularity and service-based network function selection which can replace traditional control plane centric solutions, e.g., for handover."
10.1145/3434074.3446911,Who Wants to Grant Robots Rights?,"The robot rights debate has thus far proceeded without any reliable data concerning the public opinion about robots and the rights they should have. We have administered an online survey (n = 200) that investigates layman's attitudes towards granting particular rights to robots. Furthermore, we have asked them for what reasons they are willing to grant them those rights. Finally, we have administered general perceptions of robots regarding appearance, capacities, and traits. Results show that rights can be divided in sociopolitical and computing dimensions, and reasons into cognition and compassion dimensions. People generally have a positive view on robot interaction capacities. Attitudes towards robot rights depend on age and experience as well as on the cognitive and affective capacities people believe robots will ever possess. Our results suggest that the robot rights debate stands to benefit greatly from a common understanding of the capacity potentials of future robots."
10.1145/3444369,Developing Conversational Agents for Use in Criminal Investigations,"The adoption of artificial intelligence (AI) systems in environments that involve high risk and high consequence decision-making is severely hampered by critical design issues. These issues include system transparency and brittleness, where transparency relates to (i) the explainability of results and (ii) the ability of a user to inspect and verify system goals and constraints; and brittleness, (iii) the ability of a system to adapt to new user demands. Transparency is a particular concern for criminal intelligence analysis, where there are significant ethical and trust issues that arise when algorithmic and system processes are not adequately understood by a user. This prevents adoption of potentially useful technologies in policing environments. In this article, we present a novel approach to designing a conversational agent (CA) AI system for intelligence analysis that tackles these issues. We discuss the results and implications of three different studies; a Cognitive Task Analysis to understand analyst thinking when retrieving information in an investigation, Emergent Themes Analysis to understand the explanation needs of different system components, and an interactive experiment with a prototype conversational agent. Our prototype conversational agent, named Pan, demonstrates transparency provision and mitigates brittleness by evolving new CA intentions. We encode interactions with the CA with human factors principles for situation recognition and use interactive visual analytics to support analyst reasoning. Our approach enables complex AI systems, such as Pan, to be used in sensitive environments, and our research has broader application than the use case discussed."
10.5555/3523760.3523782,"Why do We Follow Robots? An Experimental Investigation of Conformity with Robot, Human, and Hybrid Majorities","Individuals tend to conform to a majority for reasons of peer pressure (normative conformity) and insecurity (informational conformity). It is important to investigate the reasons for social phenomena such as conformity in order to better understand processes in hybrid teams (i.e., teams which consist of humans and robots). Research has yielded conflicting results on conformity with robot and hybrid majorities, and the reasons for conformity remain unclear. We conducted a within-subject online experiment (n = 103) to compare the reasons for conformity under three conditions: human, robot, and hybrid majorities. Results indicate that subjects conformed most often with hybrid majorities, while they conformed least often with robot majorities. Normative conformity influenced conformity with human majorities, but informational conformity did not. Informational conformity influenced conformity with robot majorities, but normative conformity did not. Both types of conformity affected conformity with hybrid majorities. Our results provide a possible explanation for the heterogeneous findings on conformity in HRI"
10.1145/3764587,Contract Embeddings for Layered Control Architectures,"The design of complex cyber-physical system architectures is often hierarchical. System specifications are mapped to an implementation layer via a stepwise refinement process involving multiple intermediate layers. These layers may capture different functionalities, and the orchestration of a variety of heterogeneous techniques suited to each layer may be required to achieve the overall design objectives. Due to their heterogeneity, ensuring traceability and verifiability of such architectures is a challenging problem. In this article, we present a correct-by-construction methodology for designing heterogeneous layered architectures. We capture the specifications at each layer with assume-guarantee contracts, a specification paradigm which can encompass a variety of modeling formalisms. We then use the notion of contract embeddings to define specification refinement, rigorously and traceably mapping specifications across layers modeled with heterogeneous formalisms. We instantiate our methodology on the design of layered control architectures (LCAs), resulting in a novel approach that can verifiably orchestrate domain-specific techniques to satisfy both global planning and local safety requirements. In the context of LCAs, we derive necessary conditions for correct specification refinement and results for compositional realization of control safety specifications. We illustrate our design methodology on a motivating example and a case study derived from robotic mission planning and control."
10.1145/3625156.3625189,Efficient Mobile Robot Navigation with D* Lite and Bellman Ford Hybrid Algorithm,"Robotics is a challenging area which is highly employed in various fields, including industry, logistics, healthcare, and transportation. They need effective and reliable path planning algorithms to navigate in complicated and dynamic situations. Due to its effectiveness and optimality, the hybridized algorithm has recently become a well-liked approach for resolving path planning issues in robotics. In this article, the D* Lite algorithm's implementation was done using Bellman ford Shortest Path Algorithm to achieve improved path quality and their performance assessment was done using different 2D maps. The theoretical foundation of the algorithm, its simulation implementation, and practical findings proving its efficiency regarding computing time, path distance and various other metrics are all presented in this article. It has been verified through both theoretical and empirical results that the novel hybrid technique can enhance the efficiency and effectiveness of the D*Lite. Simulation results are very much effective as D* lite implementation includes bellman ford algorithm for achieving nearly 25\% reduced computation time as well as 36\% improved optimal path length."
10.1145/3448734.3450793,An Efficient RRT-based Framework for Planning Short and Smooth Alige.x Robot Motion,"Autonomous navigation is a crucial technology for the automatic operation of mobile robots, in which path planning is the core part. In a complicated and dynamic environment, planning efficiency is crucial. In this paper, we propose a hybrid path planning scheme for a differentially driven wheeled robot with dynamical constraints by combining global path planning and local hierarchical architectures in a complex dynamic environment. In path planning under the hybrid structure, first, we generate a global path based on the adaptive goal-directed RRT algorithm. This way can achieve Efficiency. Local path planning uses the DWA with PID controller instead of the cost function for real-time motion control. A seamless interface between the global and local path planning mechanisms is designed to contribute to the whole hybrid path planning scheme. Finally, the experimental results on the grid map prove the potency and feasibility of our method."
10.1145/3649329.3658250,DeepRIoT: Continuous Integration and Deployment of Robotic-IoT Applications,"We present DeepRIoT, a continuous integration and continuous deployment (CI/CD) based architecture that accelerates the learning and deployment of a Robotic-IoT system trained from deep reinforcement learning (RL). We adopted a multi-stage approach that agilely trains a multi-objective RL controller in the simulator. We then collected traces from the real robot to optimize its plant model, and used transfer learning to adapt the controller to the updated model. We automated our framework through CI/CD pipelines, and finally, with low cost, succeeded in deploying our controller in a real F1tenth car that is able to reach the goal and avoid collision from a virtual car through mixed reality."
10.5555/3712729.3712749,Incorporating the Com-B Model for Behavior Change into an Agent-Based Model of Smoking Behaviors: An Object-Oriented Design,"Modeling trajectories in cigarette smoking prevalence, initiation and quitting for populations and subgroups of populations is important for policy planning and evaluation. This paper proposes an agent-based model (ABM) design for simulating the smoking behaviors of a population using the Capability, Opportunity, Motivation - Behavior (COM-B) model. Capability, Opportunity and Motivation are modeled as latent composite attributes which are composed of observable factors associated with smoking behaviors. Three forms of the COM-B model are proposed to explain the transitions between smoking behaviors: initiating regular smoking uptake, making a quit attempt and quitting successfully. The ABM design follows object-oriented principles and extends an existing generic software architecture for mechanism-based modeling. The potential of the model to assess the impact of smoking policies is illustrated and discussed."
10.1145/3411764.3445124,Empowering Dyads of Older Adults With Mild Cognitive Impairment And Their Care Partners Using Conversational Agents,"Conversational agents (CAs) such as Google Home or Alexa offer empowering opportunities for dyads composed of older adults with mild cognitive impairment (MCI) and their care partners. CAs support coordination and planning between the two, and can amplify the support that the care partner needs to provide. In this study, we observed how ten such dyads interacted with a Google Home over 10 weeks. We logged and analyzed 3,878 total interactions, interviewed the dyads to better understand their experiences, and also surveyed their individual preferences and priorities for automated assistance in the home. We found that CAs empowered both the people who had MCI, and their care partners. We observed that the utility of the CA in the day-to-day lives of users largely depended on how much the care partner scaffolded promising functionality, setting it up and contextualizing it for specific needs and desires."
10.1145/3745778.3766664,Frustration-driven Snap-through in Snapology,"We propose a transformable modular system based on Snapology, a modular origami assembled with prismatic foldable modules connected by foldable hinges. Our Snapology system specifically employs rhombic and regular triangular modules, with all creases constrained to a single fold direction (valley or mountain). The key finding lies in exploiting geometric frustration — the inability of the system to satisfy all geometric constraints simultaneously — to achieve rapid transformation from planar to three-dimensional (3D) configurations through snapping motion. The transformation principle is programmable by controlling the activation of out-of-plane fold hinges incident on a single vertex, enabling two distinct motions: smooth motion and snapping motion. We develop kinematic models to analyze configuration spaces and elucidate the underlying transformation principles. Computational modeling and prototype fabrication validate the predicted snapping behaviors. Design explorations demonstrate various system configurations that achieve programmable 2D-to-3D transformations through controlled snapping motion. This work establishes a new paradigm for frustration-driven modular origami design, with applications in programmable matter, soft robotics, and adaptive architectural systems."
10.1145/3469127,Struggling to Keep Tabs on Capstone Projects: A Chatbot to Tackle Student Procrastination,"Capstone projects usually represent the most significant academic endeavor with which students have been involved. Time management tends to be one of the hurdles. On top, University students are prone to procrastinatory behavior. Inexperience and procrastination team up for students failing to meet deadlines. Supervisors strive to help. Yet heavy workloads frequently prevent tutors from continuous involvement. This article looks into the extent to which conversational agents (a.k.a. chatbots) can tackle procrastination in single-student capstone projects. Specifically, chatbot enablers put in play include (1) alerts, (2) advice, (3) automatic rescheduling, (4) motivational messages, and (5) reference to previous capstone projects. Informed by Cognitive Behavioural Theory, these enablers are framed within the three phases involved in self-regulation misalignment: pre-actional, actional, and post-actional. To motivate this research, we first analyzed 77 capstone-project reports. We found that students’ Gantt charts (1) fail to acknowledge review meetings (70\%) and milestones (100\%) and (2) suffer deviations from the initial planned effort (16.28\%). On these grounds, we develop GanttBot, a Telegram chatbot that is configured from the student’s Gantt diagram. GanttBot reminds students about close landmarks, it informs tutors when intervention might be required, and it learns from previous projects about common pitfalls, advising students accordingly. For evaluation purposes, course 17/18 acts as the control group ( N=28 ) while course 18/19 acts as the treatment group ( N=25  students). Using “overdue days” as the proxy for procrastination, results indicate that course 17/18 accounted for an average of 19 days of delay (SD = 5), whereas these days go down to 10 for the intervention group in course 18/19 (SD = 4). GanttBot is available for public usage as a Telegram chatbot."
10.5555/3463952.3463967,Reason Explanation for Encouraging Behaviour Change Intention,"The demand for intelligent virtual advisors in our rapidly advancing world is rising and, consequently, the need for understanding the reasoning process to answer why a particular piece of advice is provided to the user is directly increasing. Personalized explanation is regarded as a reliable way to improve the user's understanding and trust in the virtual advisor. So far, cognitive explainable agents utilize reason explanation by referring to their own mental state (beliefs and goals) to explain their own behaviour. However, when the explainable agent plays the role of a virtual advisor and recommends a behaviour for the human to perform, it is best to refer to the user's mental state, rather than the agent's mental state, to form a reason explanation. In this paper, we are developing an explainable virtual advisor (XVA) that communicates with the user to elicit the user's beliefs and goals and then tailors its advice and explains it according to the user's mental state. We tested the proposed XVA with university students where the XVA provides tips to reduce the students' study stress. We measured the impact of receiving three different patterns of tailored explanations (belief-based, goal-based, and belief&amp;goal-based explanation) in terms of the students' intentions to change their behaviours. The results showed that the intention to change is not only related to the explanation pattern but also to the user context, the relationship built with the agent, the type of behaviour recommended and the user's current intention to do the behaviour."
10.1145/3501409.3501622,Research on Improved Hybrid Polynomial Interpolation Algorithm for Rail Inspection Robot,"In order to ensure the track stability when the rail inspection robot automatically tracks the moving target and reduce the amplitude of angular velocity and angular acceleration, it is necessary to study the trajectory planning strategy. Aiming at the problem that the amplitude of angular velocity and angular acceleration of 3-5-3 hybrid polynomial interpolation algorithm is too high, a 3-3-5 hybrid polynomial interpolation trajectory planning method is proposed. Firstly, the D-H (Denavit-Hartenberg) model of the rail inspection robot is used to compute its kinematics equation. Secondly, according to the constraints of motion curve (angle, angular velocity, angular acceleration continuous), kinematics constraints are obtained and interpolation points are determined. Thirdly, the coefficient expression of the hybrid polynomial interpolation algorithm is solved by substituting kinematics constraints and interpolation points into the formula of the 3-3-5 hybrid polynomial interpolation algorithm. Finally, the 3-3-5 hybrid polynomial interpolation algorithm is simulated in MATLAB. The results show that the 3-3-5 hybrid polynomial interpolation algorithm can effectively reduce the amplitude of the angular velocity and angular acceleration, reduce the jerk of the motor, and improve the overall motion performance of the inspection robot."
10.1145/3689933.3690834,Automated APT Defense Using Reinforcement Learning and Attack Graph Risk-based Situation Awareness,"Advanced Persistent Threats pose significant risks to communication and infrastructure systems. While both heuristic and reinforcement learning have been applied to address this challenge, current approaches rely on fixed assumptions or use simplistic state representations and reward functions, compromising adaptability and accuracy. In this paper, we propose a novel intelligent agent system that enhances security against APTs by leveraging MulVAL attack graphs and quantitative risk assessment. Our approach translates complex MulVAL attack graph states into a compact RL state representation, enabling efficient learning in dynamic network environments. We integrate quantitative attack graph-based risk assessment into the RL framework, employing a hybrid reward function that incorporates residual risk, risk reduction, control efficacy, and cost. This risk-based approach provides enhanced context and situation awareness to the RL agent, facilitating more informed long-term decision-making. Using both Q-learning and Proximal Policy Optimization algorithms, we train and evaluate our system on an emulated industrial control system environment under realistic APT attacks. Experimental results demonstrate the significant benefits of our risk-based approach in guiding RL agents. Compared to non-risk configurations, our method shows improved success rates in APT mitigation, reduced control costs, which imply better long-term strategic planning."
10.1145/3728725.3728759,A Guided-learning Network for Brain Tumor Segmentation with Missing Modalities,"Accurate segmentation of brain tumors is essential for clinical assessment and treatment planning, as it leverages multiple MRI modalities to provide complementary diagnostic information. However, missing modalities are frequently en- countered in clinical practice due to factors such as image degradation, artifacts, protocol inconsistencies, or patient con- traindications to contrast agents. While certain unified models are designed to accommodate various missing modality scenarios, their performance declines markedly when multiple modalities are absent, particularly in cases where only a single modality is available. To tackle this challenge, we introduce a Guided- learning Network that leverages dynamic FFT filters. This network trains multiple specialized models designed for different missing modality scenarios, achieving outstanding performance. The architecture comprises two distinct learning paths: one dedicated to capturing multimodal information and another focused on generating modality-specific representations for the missing modality. A guided-learning strategy connects these two paths. Initially, the multimodal path is trained and its parameters are locked, enabling the missing modality path to learn under its guidance. The training process incorporates several key com- ponents: adversarial learning to align high-level features across paths, frequency-domain adaptive filtering using dynamic FFT filters to extract global features, and mutual information transfer to ensure critical information is retained even when modality data is missing. Experiments conducted on the BraTS2018 dataset demonstrate that our model outperforms comparable state-of- the-art methods in all missing modality cases."
10.1145/3375790,Exploring the Role of Common Model of Cognition in Designing Adaptive Coaching Interactions for Health Behavior Change,"Our research aims to develop intelligent collaborative agents that are human-aware: They can model, learn, and reason about their human partner’s physiological, cognitive, and affective states. In this article, we study how adaptive coaching interactions can be designed to help people develop sustainable healthy behaviors. We leverage the common model of cognition (CMC) [31] as a framework for unifying several behavior change theories that are known to be useful in human–human coaching. We motivate a set of interactive system desiderata based on the CMC-based view of behavior change. Then, we propose PARCoach, an interactive system that addresses the desiderata. PARCoach helps a trainee pick a relevant health goal, set an implementation intention, and track their behavior. During this process, the trainee identifies a specific goal-directed behavior as well as the situational context in which they will perform it. PARCCoach uses this information to send notifications to the trainee, reminding them of their chosen behavior and the context. We report the results from a 4-week deployment with 60 participants. Our results support the CMC-based view of behavior change and demonstrate that the desiderata for proposed interactive system design is useful in producing behavior change."
10.1145/3583131.3590459,Using a Variational Autoencoder to Learn Valid Search Spaces of Safely Monitored Autonomous Robots for Last-Mile Delivery,"The use of autonomous robots for delivery of goods to customers is an exciting new way to provide a reliable and sustainable service. However, in the real world, autonomous robots still require human supervision for safety reasons. We tackle the real-world problem of optimizing autonomous robot timings to maximize deliveries, while ensuring that there are never too many robots running simultaneously so that they can be monitored safely. We assess the use of a recent hybrid machine-learning-optimization approach COIL (constrained optimization in learned latent space) and compare it with a baseline genetic algorithm for the purposes of exploring variations of this problem. We also investigate new methods for improving the speed and efficiency of COIL. We show that only COIL can find valid solutions where appropriate numbers of robots run simultaneously for all problem variations tested. We also show that when COIL has learned its latent representation, it can optimize 10\% faster than the GA, making it a good choice for daily re-optimization of robots where delivery requests for each day are allocated to robots while maintaining safe numbers of robots running at once."
10.1145/3598151.3598191,A Hierarchical Autonomous Exploration Algorithm for Large-scale and Complex Environments with Mobile Robot,"In order to solve the problem of low exploration efficiency caused by repeatedly backtracking the frontiers in large and complex environments, a hierarchical autonomous exploration algorithm is proposed. Firstly, based on the robot's static model to judge the environment's traversability, which allows robots to explore complex 3D environments. Following that, a hybrid strategy is used to filter out frontiers within a local planning horizon, thus complete exploration of the local area is achieved by solving the traveling salesman problem (TSP). Finally, the sparse global topology map generates transfer paths between sub-areas, transferring the robot to another sub-area to resume exploration. Compared to the RRT autonomous exploration algorithm and the GBP autonomous exploration algorithm, the method in this work reduces the exploration path by more than 13.8\% and the exploration time by more than 23.7\%. The results show that the proposed algorithm significantly improves the autonomous exploration efficiency of mobile robots in large and complex environments."
10.1145/3396851.3402365,Prospective Experiment for Reinforcement Learning on Demand Response in a Social Game Framework,"Improving demand response can help optimize renewable energy use and might be possible using current tools in machine learning. We propose an experiment to test the development of Reinforcement Learning (RL) agents to learn to vary a daily grid price signal to optimize behavioral energy shift in office workers. We describe our application of Batch Constrained Q Learning and Soft Actor Critic (SAC) as RL agents and Social Cognitive Theory, LSTM networks, and linear regression as planning models. We report limited success within simulation with SAC and linear regression. Finally, we propose an experiment timeline for consideration."
10.1145/3586183.3606763,Generative Agents: Interactive Simulacra of Human Behavior,"Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents: computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent’s experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty-five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behaviors. For example, starting with only a single user-specified notion that one agent wants to throw a Valentine’s Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture—observation, planning, and reflection—each contribute critically to the believability of agent behavior. By fusing large language models with computational interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior."
10.1145/3707292.3707383,A Survey of Theory Foundation and Key Technology in Large Models,"The training and reasoning technology of large models continues to go deeper and more practical, and the model performance continues to hit new highs, driving the emergence of intelligent native applications and laying a solid technical foundation for new applications, new services, and new formats. This paper focuses on the technical capabilities and development directions of large models, introduces the theory foundation research of large models in detail, including scaling laws, intrinsic task subspace, low-rank decomposition optimization theory, effective model complexity theory and alignment theory foundation; it conducts in-depth research on key technology of large models such as the neural network architecture, chain of thought(CoT), multimodal fusion technology, retrieval-augmented generation(RAG) and large language model (LLM) based agent, sorts out the iteration of technology and innovative research results; it discusses technical challenges such as the professionalism, authenticity, controllability, and credibility of large models, pointing out the key technical points of innovative research; finally, it summarizes and looks forward to the high-quality development of large models."
10.5555/3545946.3598838,Value Inference in Sociotechnical Systems,"As artificial agents become increasingly embedded in our society, we must ensure that their behavior aligns with human values. Value alignment entails value inference, the process of identifying values and reasoning about how humans prioritize values. We introduce a holistic framework that connects the technical (AI) components necessary for value inference. Subsequently, we discuss how hybrid intelligence-the synergy of human and artificial intelligence---is instrumental to the success of value inference. Finally, we illustrate how value inference both poses significant challenges and provides novel opportunities for multiagent systems research."
10.1145/3610419.3610435,Mathematical modeling and control of Biomimetic Autonomous Underwater Vehicle (BAUV) based on flapping propulsion,"Bioinspired underwater vehicles which mimic motion from flapping gait of marine fishes can benefit from the flight efficiency and silent maneuver in aquatic environments. However, there is a very limited amount of research which focuses on mapping the flapping fin propulsion to model the complete dynamics of the bioinspired robot. Multiple parameters like amplitude of motion, flapping frequency and initial angle of attack affect the overall motion dynamics. In this work, the propulsive thrust generated from the undulating fin structure is numerically investigated by computational fluid dynamics (CFD) study. Further, this non-linear thrust map is used to formulate the mathematical model of the proposed biomimetic autonomous underwater vehicle (BAUV). To validate the trajectory tracking performance of the proposed system in 2D planar maneuver, coupled dynamics of the underactuated vehicle (with one caudal, and two dorsal fins) is derived and hybrid control strategy is implemented. Trajectory tracking control of the proposed structure is also studied which is challenging because of the oscillatory motions of the fins. For a L-shaped trajectory of edge length 200m, the proposed BAUV with a span-length of 2.5 m is capable to render the desired trajectory with permissible error of 0.2 m, maximum flapping frequency of 0.6 Hz and dorsal fin deflection of 25 degrees which verify the accuracy of the proposed BAUV model."
10.1145/3623263.3623359,Reinforcement learning for scaffold-free construction of spanning structures,"In construction robotics, a conventional design-to-fabrication workflow starts with designing a structure, followed by task and robotic motion planning, and ultimately, fabrication. However, this approach can prove unsuccessful, as we may only discover the infeasibility of a design at the final stages of the process. This can result in rework and a considerable waste of time and resources. To overcome this challenge, we propose a design method based on reinforcement learning (RL) where the agent makes decisions at every step of the sequential assembly of the structure while considering assembly’s stability. In this way, we take the construction constraints into consideration at the design stage. The research particularly focuses on the design of spanning structures that multiple robot arms can construct without the need for scaffolding. A series of experiments were conducted using both a centralized and a decentralized learning setup. Our results show that while the decentralized setup was successful in constructing smaller structures, only the centralized setup allowed active collaboration between robot arms, resulting in structures with larger spans. To validate our approach, we fabricated two of the designed structures with two collaborating robot arms, which confirmed the feasibility of these designs. In summary, the proposed method opens exciting possibilities for generating innovative designs that push the boundaries of architectural creativity while simultaneously fulfilling fabrication-related constraints."
10.5555/3635637.3663074,Pragmatic Instruction Following and Goal Assistance via Cooperative Language-Guided Inverse Planning,"People often give instructions whose meaning is ambiguous without further context, expecting that their actions or goals will disambiguate their intentions. How can we build assistive agents that follow such instructions in a flexible, context-sensitive manner? This paper introduces cooperative language-guided inverse plan search (CLIPS), a Bayesian agent architecture for pragmatic instruction following and goal assistance. Our agent assists a human by modeling them as a cooperative planner who communicates joint plans to the assistant, then performs multimodal Bayesian inference over the human's goal from actions and language, using large language models (LLMs) to evaluate the likelihood of an instruction given a hypothesized plan. Given this posterior, our assistant acts to minimize expected goal achievement cost, enabling it to pragmatically follow ambiguous instructions and provide effective assistance even when uncertain about the goal. We evaluate these capabilities in two cooperative planning domains (Doors, Keys \&amp; Gems and VirtualHome), finding that CLIPS significantly outperforms GPT-4V, LLM-based literal instruction following and unimodal inverse planning in both accuracy and helpfulness, while closely matching the inferences and assistive judgments provided by human raters."
10.1145/3383652.3423893,Spontaneous Facial Behavior Revolves Around Neutral Facial Displays,"With forty-six Action Units (AUs) forming the building blocks in the Facial Action Coding System (FACS), millions of facial configurations can be formed. Most research has focused on a subset of combinations to determine the link between facial configurations and emotions. Despite the value of this research for psychological and computational reasons, it is not clear what the most common combinations of AUs are to form the most commonly expressed facial configurations. We used three diverse corpora with human coded facial action units for a computational analysis. The analysis demonstrated that the largest portion of facial behavior consists of the absence of AU activations, yielding only one specific facial configuration, that of the neutral face. These results are important for cognitive scientists, computer graphics designers and virtual human developers alike. They suggest that only a relatively small number of AU combinations are initially needed for the creation of natural facial behavior in Embodied Conversational Agents (ECAs)."
10.1145/3725783.3764388,Between Promise and Pain: The Reality of Automating Failure Analysis in Microservices with LLMs,"Large Language Models (LLMs) are increasingly explored as general-purpose assistants for infrastructure operations, helping automate tasks like querying data, analyzing logs, and suggesting fixes. In this paper, we consider the more general and ambitious problem of fully automating root cause analysis (RCA) in microservice systems, where LLMs must collect information, reason about it, and interact with the environment to detect, localize and resolve issues. Anecdotal evidence offers useful insights and partial solutions, but the broader challenge remains unresolved. We systematically evaluate multiple LLM agent architectures across a range of incident scenarios. We study how different tool-augmented agents perform, and shed light on common failure modes, including hallucinated reasoning paths and inefficient use of context. Our findings reveal both the promise and the limitations of current approaches, and point to concrete directions for more robust and effective use of LLMs in this domain."
10.1145/3387939.3391591,Software architecture and task plan co-adaptation for mobile service robots,"Self-adaptive systems increasingly need to reason about and adapt both structural and behavioral system aspects, such as in mobile service robots, which must reason about missions that they need to achieve and the architecture of the software executing them. Deciding how to best adapt these systems to run time changes is challenging because it entails considering mutual dependencies between the software architecture that the system is running and the outcome of plans for completing tasks, while also considering multiple trade-offs and uncertainties. Considering all these aspects in planning for adaptation often yields large solution spaces which cannot be adequately explored at run time. We address this challenge by proposing a planning approach able to consider the impact of mutual dependencies between software architecture and task planning on the satisfaction of mission goals. The approach is able to reason quantitatively about the outcome of adaptation decisions handling both the reconfiguration of the system's architecture and adaptation of task plans under uncertainty and in a rich trade-off space. Our results show: (i) feasibility of run-time decision-making for self-adaptation in an otherwise intractable solution space by dividing-and-conquering adaptation into architecture reconfiguration and task planning sub-problems, and (ii) improved quality of adaptation decisions with respect to decision making that does not consider dependencies between architecture and task planning."
10.1145/3686592.3686595,Enhancing spatially-disaggregated simulations with large language models,"We present our experience integrating large language models (LLMs) and simulation engines to enhance spatially-disaggregated simulation, taking advantage of the spatial knowledge and spatial reasoning capabilities of LLMs. The examples illustrate LLM integration with different variations of compartmental epidemiological models, including agent-based models (ABM) in the context of modeling COVID-19 infection spread in a school setting, and LLM integration with a system dynamics model which supports a serious game focused on strategies for responding to disease outbreaks at the county level. We present the architecture of the integrated LLM-simulation system, demonstrate the initial results, and discuss the challenges of the current approach, related to LLM's understanding of spatial information and spatial relationships, their reasoning capabilities, and model performance and scalability."
10.1145/3715669.3727346,Low-Power Hierarchical Network: Pervasive Eye-Tracking on Smart Eyewear,"Pervasive eye-tracking technology for eyewear devices represents a major advancement in wearable computing, enabling intuitive interaction and improving accessibility. However, the low-power constraints of these devices present a significant challenge in balancing accuracy with limited computational capacity. This study focuses on developing and evaluating algorithms for a low-power wearable infrared eye-tracking system conceived to work 24/7. The system includes a custom-built prototype that integrates infrared LEDs and photodiodes, strategically positioned on smart eyewear to estimate gaze direction. A humanoid robot, Ami Desktop, was utilized to create a controlled and robust dataset. Two deep learning architectures were investigated: a Multi-Layer Perceptron (MLP) and a tailored Hierarchical Neural Network (HNN). Variants of these models incorporating dimensionality reduction techniques were implemented to optimize performance and efficiency for low-power microcontrollers. The results demonstrate the superior accuracy and reasonable computational demands of the HNN models, highlighting their potential for continuous, real-time and portable eye-tracking applications."
10.1145/3748304,Large Language Models for Information Retrieval: A Survey,"As a primary means of information acquisition, information retrieval (IR) systems, such as search engines, have integrated themselves into our daily lives. These systems also serve as components of dialogue, question-answering, and recommender systems. The trajectory of IR has evolved dynamically from its origins in term-based methods to its integration with advanced neural models. While the neural models excel at capturing complex contextual signals and semantic nuances, they still face challenges such as data scarcity, interpretability, and the generation of contextually plausible yet potentially inaccurate responses. This evolution requires a combination of traditional methods (such as term-based sparse retrieval methods with rapid response) and modern neural architectures (such as language models with powerful language understanding capacity). Meanwhile, the emergence of large language models (LLMs) has revolutionized natural language processing due to their remarkable language understanding, generation, and reasoning abilities. Consequently, recent research has sought to leverage LLMs to improve IR systems. Given the rapid evolution of this research trajectory, it is necessary to consolidate existing methodologies and provide nuanced insights through a comprehensive overview. In this survey, we delve into the confluence of LLMs and IR systems, including crucial aspects such as query rewriters, retrievers, rerankers, readers, and search agents."
10.1145/3643834.3661519,"Designing Plant-Driven Actuators for Robots to Grow, Age, and Decay","Designing plant-driven actuators presents an opportunity to create new types of devices that grow, age, and decay, such as robots that embody these qualities in their physical structure. Plant-robot hybrids that grow and decay incorporate unpredictable and gradual transformations inherent across living organisms and suggest an alternative to the design principles of immediacy, responsiveness, control, accuracy, and durability commonly found in robotic design. To explore this, we present a design space of primitives for plant-driven robotic actuators. Proof-of-concept prototypes illustrate how concepts like slow change, slow movement, decay, and destruction can be incorporated into robotic forms. We describe the design considerations required for building plant-driven actuators for robots, including experimental findings regarding the mechanical properties of plant forces. Finally, we speculate on the potential benefits of plant-robot hybrids to interactive domains such as robotics."
10.1145/3514094.3534182,Piecemeal Knowledge Acquisition for Computational Normative Reasoning,"We present a hybrid approach to knowledge acquisition and representation for machine ethics---or more generally, computational normative reasoning. Building on recent research in artificial intelligence and law, our approach is modeled on the familiar practice of decision-making under precedential constraint in the common law. We first provide a formal characterization of this practice, showing how a body of normative information can be constructed in a way that is piecemeal, distributed, and responsive to particular circumstances. We then discuss two possible applications: first, a robot childminder, and second, moral judgment in a bioethical domain."
10.1145/3319502.3374832,When Humans Aren't Optimal: Robots that Collaborate with Risk-Aware Humans,"In order to collaborate safely and efficiently, robots need to anticipate how their human partners will behave. Some of today's robots model humans as if they were also robots, and assume users are always optimal. Other robots account for human limitations, and relax this assumption so that the human is noisily rational. Both of these models make sense when the human receives deterministic rewards: i.e., gaining either $100 or $130 with certainty. But in real-world scenarios, rewards are rarely deterministic. Instead, we must make choices subject to risk and uncertainty-and in these settings, humans exhibit a cognitive bias towards suboptimal behavior. For example, when deciding between gaining $100 with certainty or $130 only 80\% of the time, people tend to make the risk-averse choice-even though it leads to a lower expected gain! In this paper, we adopt a well-known Risk-Aware human model from behavioral economics called Cumulative Prospect Theory and enable robots to leverage this model during human-robot interaction (HRI). In our user studies, we offer supporting evidence that the Risk-Aware model more accurately predicts suboptimal human behavior. We find that this increased modeling accuracy results in safer and more efficient human-robot collaboration. Overall, we extend existing rational human models so that collaborative robots can anticipate and plan around suboptimal human behavior during HRI."
10.1145/3526071.3527520,Software architecture for deformable linear object manipulation: a shape manipulation case study,"Deformable linear object manipulation is challenging due to their high dimensional configuration space and their underactuated nature when manipulated by a robotic gripper. Due to the complexity of the task, robotic manipulation relies on sensors and computationally demanding models, which end up in multiple different software components interacting with each other. Research in deformable object manipulation usually focuses on modeling, planning or control, without focusing on a software architecture. This paper presents a novel software architecture for deformable linear object manipulation. The software architecture includes components for deformable linear object manipulation, namely perception-, observation-, robot control-, planning-, communication- and decision component. On top of these components, a layered software architecture consisting of a decision layer, a skill layer and a functional layer is presented The proposed concept aims to be a blueprint for a unified software architecture satisfying the requirements of robotic systems to achieve deformable linear object manipulation. The validation of the software architecture is done in a case study of an autonomous shape manipulation task, where one robot and a stereo camera shape a deformable linear object to a predefined desired shape. This use case is inspired by an automated cable routing process, which today in the industry is still mainly handled manually and therefore offers a vast potential for automation."
10.1145/3319502.3374779,Decision-Making for Bidirectional Communication in Sequential Human-Robot Collaborative Tasks,"Communication is critical to collaboration; however, too much of it can degrade performance. Motivated by the need for effective use of a robot's communication modalities, in this work, we present a computational framework that decides if, when, and what to communicate during human-robot collaboration. The framework, titled CommPlan, consists of a model specification process and an execution-time POMDP planner. To address the challenge of collecting interaction data, the model specification process is hybrid : where part of the model is learned from data, while the remainder is manually specified. Given the model, the robot's decision-making is performed computationally during interaction and under partial observability of human's mental states. We implement CommPlan for a shared workspace task, in which the robot has multiple communication options and needs to reason within a short time. Through experiments with human participants, we confirm that CommPlan results in the effective use of communication capabilities and improves human-robot collaboration."
10.1145/3614321.3614356,Enterprise architecture adoption in government: a public value perspective,"Substantial research has been conducted to investigate the value that Enterprise Architecture (EA) can generate for organizations. However, there is also a need to empirically explore the mechanisms involved in creating this value. Against this backdrop, this paper aims to answer the research question: “Which mechanisms contribute to generating value through using Enterprise Architecture in government?” The research was conducted through a survey administered to Swedish government organizations, directed by a public value framework. The data analysis was conducted using descriptive statistics and an inductive analysis of open-text answers. The findings reveal values associated with the use of EA in government and corresponding value-generating mechanisms. Core activities in the municipalities consist of establishing digital value chains where values are generated for citizens and the internal administration. National agencies engage more in creating strategic value through intrinsic enhancements enabled via EA to establish organizational commonalities. Our findings informed a conceptual framework, which encompasses organizing principles, core EA activities, and applications. This research contributes to the literature on the use of EA in government by highlighting EA activities related to the strategic orientation of organizational operations and enablers for deriving valuable results from these activities. Our framework, informed by theories of public value and results from practice, provides a roadmap for public managers to plan and operationalize their architectural work. By doing so, we contribute to establishing an important link between research on EA in the public sector and public value theory. We conclude the paper with suggesting additional research on two identified research gaps: 1. Using EA for participatory processes, 2. Further investigation of evaluation practices."
10.5555/3398761.3398896,Human-Centered Decision Support for Agenda Scheduling,"Over the course of a day, people often attend many appointments, like meetings or doctor's appointments, with time and location constraints, as well as perform other tasks like stopping by the grocery store with only location constraints. Optimally scheduling the day's agenda typically requires a high cognitive load, where people reason about all their constraints at once. An agent that aids a person in scheduling the day's agenda can potentially reduce the stress associated with scheduling but must be able to 1) perform fast updates and 2) produce new agendas that can be readily understood by the people they are helping. In order to understand how people reason about agenda changes, we first performed a study where participants are asked to perform a series of scheduling tasks and captured their update strategy both subjectively (self-reporting) and objectively (by tracking their reasoning). Our results that show that people use spatial cues and meeting time information to reduce the rescheduling task to a more reasonable size. We then present a novel heuristic for adding tasks to agendas that targets rescheduling to clusters of appointments that are spatio-temporally near the new task.We show that this heuristic approach always finds the optimal solution, while greatly reducing rescheduling time, and performs rescheduling in a way that is similar to our participants' strategies."
10.1145/3760622.3760647,Machine Learning-based Feature Evaluation of the Factors Affecting the Effective Infrastructure Project Implementation,"Numerous factors affect how well infrastructure projects are implemented in different agencies and organizations, therefore identifying the important factors requires a data-driven approach. This study uses neural network simulations to examine the relative impact of various components using a feature evaluation based on machine learning. Neural network simulations yielded high predictive accuracy, with correlation coefficients (R) ranging from 0.97294 to 0.99084 and mean squared errors (MSE) between 0.014255 and 0.024731, validating the robustness of the model. Results indicate that the absence of a Project Procurement Management Plan (PPMP) and Annual Procurement Plan preparation is the most critical parameter in implementation requirements. In fund management, interagency funds not taken up in trust accounts emerged as the most influential factor, highlighting potential financial inefficiencies. Architectural \&amp; Engineering (A&amp;E) and Administration \&amp; Supervision (A&amp;S) expense allocations were found to be the primary determinants in the budget allocation category. For procurement of equipment, supplies, materials, and services, the absence of lease-to-own agreements significantly impacts cost-effective resource acquisition. Additionally, deviations from audit guidelines in rental fee disbursements pose financial accountability risks in the authority to charge fees for equipment rental. These results highlight the necessity of better financial supervision, procurement planning, and regulatory compliance to increase the efficiency and transparency of infrastructure projects, offering policymakers and agency administrators practical insights."
10.5555/3635637.3662981,2D-Ptr: 2D Array Pointer Network for Solving the Heterogeneous Capacitated Vehicle Routing Problem,"The heterogeneous capacitated vehicle routing problem (HCVRP) aims to optimize the routes of heterogeneous vehicles with capacity constraints to serve a set of customers with demands. Existing learning-based methods for solving HCVRP have the problem of weak generalization ability, which means that well-trained model cannot adapt well to new scenarios with different vehicle or customer numbers. To address this issue, by modeling the simultaneous decision-making of multiple agents as a sequence of consecutive actions in real time, we propose a pointer network extension model, which includes a static encoder and a dynamic encoder to map the current situation to node embeddings and vehicle embeddings, respectively. For each element in the consecutive actions sequence, the decoder of our model uses the probability distribution obtained from node embeddings and vehicle embeddings as a 2D array pointer to select a tuple from the combinations of vehicles and nodes (customers and depot). We call this architecture a 2D Array Pointer network (2D-Ptr). Instead of planning paths based on the priority order of vehicles, 2D-Ptr plans paths based on the priority order of actions. In addition, 2D-Ptr consists of a series of carefully designed attention modules, entitling the model to be generalizable in the scenarios where additional vehicles (or customers) are introduced or existing vehicles (or customers) are removed. We empirically test 2D-Ptr and show its capability for producing near-optimal solutions through cooperative actions. 2D-Ptr delivers competitive performance against the state-of-the-art baselines, and can solve arbitrary instances of the HCVRP without requiring re-training."
10.1145/3547578.3547592,A Real-time Smooth Lifting Path Planning for Tower Crane Based on TD3 with Discrete-Continuous Hybrid Action Space,"Smoothness and rapidity are two important performance indexes for crane lifting path planning. Traditionally, cranes are modeled as multi-freedom robots and use robot path planning algorithms to plan path in continuous space. However, the paths planned by these methods are not smooth enough to operate. In addition, presently, most of proposed lifting path planning algorithms focus on static environments, requiring accurate environmental information to build maps, which is too computation expensive to meet the requirement of real-time path planning. In this paper, we propose a deep reinforcement learning-based lifting path planning algorithm for hybrid action spaces. The network structure is developed based on TD3. A new reward function is designed and hindsight experience replay is used to solve the reward sparsity problem in long distance path planning. The planning path is smooth and can achieve real-time path planning in unknown environments. The result of simulation experiments demonstrates the effectiveness of the proposed approach."
10.1145/3520304.3534022,"GUI-based, efficient genetic programming for Unity3D","Unity3D is a game development environment that could be co-opted for agent-based machine learning research. We present a GUI-driven, and efficient Genetic Programming (GP) system for this purpose. Our system, ABL-Unity3D, addresses challenges entailed in co-opting Unity3D: making the simulator serve agent learning rather than humans playing a game, lowering fitness evaluation time to make learning computationally feasible, and interfacing GP with an AI Planner to support hybrid algorithms that could improve performance. We achieve this through development of a GUI using the Unity3D editor's programmable interface, and performance optimizations. These optimizations result in at least a 3x speed up. We describe ABL-Unity3D by explaining how to use it for an example experiment using GP and AI Planning."
10.1145/3664647.3681657,StableMoFusion: Towards Robust and Efficient Diffusion-based Motion Generation Framework,"Thanks to the powerful generative capacity of diffusion models, recent years have witnessed rapid progress in human motion generation. Existing diffusion-based methods employ disparate network architectures and training strategies. The effect of the design of each component is still unclear. In addition, the iterative denoising process consumes considerable computational overhead, which is prohibitive for real-time scenarios such as virtual characters and humanoid robots. For this reason, we first conduct a comprehensive investigation into network architectures, training strategies, and inference process. Based on the profound analysis, we tailor each component for efficient high-quality human motion generation. Despite the promising performance, the tailored model still suffers from foot skating which is an ubiquitous issue in diffusion-based solutions. To eliminate footskate, we identify foot-ground contact and correct foot motions along the denoising process. By organically combining these well-designed components together, we present StableMoFusion, a robust and efficient framework for human motion generation. Extensive experimental results show that our StableMoFusion performs favorably against current state-of-the-art methods."
10.1145/3704919,Model-checking Strategic Abilities in Information-sharing Systems,"We introduce a subclass of concurrent game structures (CGS) with imperfect information in which agents are endowed with private data-sharing capabilities. Importantly, our CGSs are such that it is still decidable to model-check these CGSs against a relevant fragment of ATL. These systems can be thought as a generalization of architectures allowing information forks, that is, cases where strategic abilities lead to certain agents outside a coalition privately sharing information with selected agents inside that coalition. Moreover, in our case, in the initial states of the system, we allow information forks from agents outside a given set  (A)  to agents inside this group (A) . For this reason, together with the fact that the communication in our models underpins a specialized form of broadcast, we call our formalism  (A)  -cast systems. To underline, the fragment of ATL for which we show the model-checking problem to be decidable over  (A) -cast is a large and significant one; it expresses coalitions over agents in any subset of the set  (A) . Indeed, as we show, our systems and this ATL fragments can encode security problems that are notoriously hard to express faithfully: terrorist-fraud attacks in identity schemes."
10.1145/3478586.3478625,Development of Modular Library for Rapid Prototyping of Planar Hybrid Linkages using Computer Aided Design: Design of a modular library using CAD for prototyping of different planer hybrid linkages via additive manufacturing techniques.,"The paper targets to develop a modular library for prototyping planar hybrid linkages using additive manufacturing, while suggesting an optimized selection of printing conditions, layering direction, and clearances. A safe range for pure tensile load has been estimated using FEM simulation to confirm usability in prototyping. Three modules have been designed to produce active, passive, and joint locking functionalities in the revolute joints and the fourth connectivity module helps to achieve the connectivity in between revolute joints of different linkages. It has been shown by developing the prototype for two different complex planer hybrid manipulators as examples, that these modules work as tools for the designer to design a customized manipulator. CAD modelling has been used for preparing a complete manipulator structure which, using AM, can be given the physical form.In the design and manufacturing of robotic manipulators, incorporating modular libraries makes the design customizable as well as makes the process easier. With this approach, the user follows a drag and drop approach to customize a design using an already available set of modular components fulfilling different purposes. Further work will demonstrate the technique by preparing models some randomly selected linkages based upon the designed modules."
10.1145/3592102,A Temporal Coherent Topology Optimization Approach for Assembly Planning of Bespoke Frame Structures,"We present a computational framework for planning the assembly sequence of bespoke frame structures. Frame structures are one of the most commonly used structural systems in modern architecture, providing resistance to gravitational and external loads. Building frame structures requires traversing through several partially built states. If the assembly sequence is planned poorly, these partial assemblies can exhibit substantial deformation due to self-weight, slowing down or jeopardizing the assembly process. Finding a good assembly sequence that minimizes intermediate deformations is an interesting yet challenging combinatorial problem that is usually solved by heuristic search algorithms. In this paper, we propose a new optimization-based approach that models sequence planning using a series of topology optimization problems. Our key insight is that enforcing temporal coherent constraints in the topology optimization can lead to sub-structures with small deformations while staying consistent with each other to form an assembly sequence. We benchmark our algorithm on a large data set and show improvements in both performance and computational time over greedy search algorithms. In addition, we demonstrate that our algorithm can be extended to handle assembly with static or dynamic supports. We further validate our approach by generating a series of results in multiple scales, including a real-world prototype with a mixed reality assistant using our computed sequence and a simulated example demonstrating a multi-robot assembly application."
10.1145/3512290.3528728,A multi-objective evolutionary algorithm with new reproduction and decomposition mechanisms for the multi-point dynamic aggregation problem,"An emerging optimisation problem from real-world applications, named the multi-point dynamic aggregation (MPDA) problem, has become an active research of the multi-robot system. This paper focuses on a multi-objective MPDA (MO-MPDA) problem which is to design execution plans of robots for minimising the cost of used robots and maximising the efficiency of task execution. The MOMPDA problem has the issues of conflicting objectives, redundant representation, and variable-length encoding, posing extra challenges to address the MO-MPDA problem effectively. Combining the ∊-constraint method and decomposition mechanisms, a novel multi-objective evolutionary algorithm is proposed. The proposed algorithm selects the efficiency objective as the main objective and converts the cost objective as constraints. Thus, the multi-objective problem is decomposed into a series of scalar constrained optimisation subproblems by assigning each subproblem with an upper bound constraint. All the subproblems are optimised and evolved simultaneously with the transferring knowledge from other sub-problems to solve the MO-MPDA problem parallelly and efficiently. Besides, considering the characteristics of parent individuals, this paper designs a hybrid reproduction mechanism to transmit effective information to offspring individuals for tackling the encoding redundancy and varying-length. Experimental results show that the proposed algorithm significantly outperforms the state-of-the-art algorithms in terms of most-used metrics."
10.1145/3598151.3598174,A Collision-free Path Planning Algorithm for Industrial Robots with Adaptive Search Mechanism,"In path planning for industrial robots, collision avoidance is a critical constraint. This paper studies the problem of collision-free motion planning for a spraying robot, i.e., obtaining a series of joint configurations along a given spraying waypoint that satisfies the collision constraints and satisfy the kinematics of the robot. Aiming at this problem, a collision-free motion optimization algorithm based on the adaptive search is proposed in this paper. First, a boundary volume hierarchy (BVH) of the robot and environment is quickly generated based on the GPU parallel architecture. Second, the redundancy of spray incidence angles is used to search for feasible spray incidence angle directions in the redundant space and update the robot's BVHs for collision detection. In addition, during the optimization iterations, the size of the search space is adaptively reduced according to the number of collision failures in the previous iterations to avoid falling into a local optimum. Finally, the effectiveness of the proposed algorithm is verified by simulation on a six-degrees-of-freedom robot performing a spraying task."
10.1145/3459104.3459125,Development of a Hybrid Control Algorithm Based on Neural Networks for Mobile Autonomous Robot Navigation,"A control algorithm based on adaptive neural networks is developed to control the navigation of a mobile autonomous ground-based explorer robot. A simulation was performed in the Matlab program to verify the operation of the algorithm, where the set of proximity sensors used by the robot for the detection and evasion of obstacles was simulated.The algorithm was developed using three neural network architectures: Adaline-type linear adaptive network, Perceptron neural network, and Feedforward neural network. The mathematical study of each of the adaptive neural network architectures proposed for the recognition of training patterns, corresponding to wall following patterns was carried out; their comparison was made and based on the results of the simulation, the one that showed the best output responses was selected to form part of the algorithm.This algorithm is in charged of the main tasks of obstacle avoidance and the target searching, generating as control outputs: the angle of rotation of the robot concerning its current position and its forward speed, to solve the problem of high difficulty concave obstacles encountered in the robot's path to the target. This is a hybrid algorithm, made up of a local path planning algorithm, in charge of obstacle wall fallowing and a global path planning algorithm, in charge of finding the final objective.This work focused on solving the problem of evasion of high difficulty concave obstacles, formed by curves in the form of a loop, also called dead-end traps, in which a situation of local minimum is presented. In this work different types of obstacles were simulated, being able to create almost any shape; the algorithm was tested with obstacles created from arrays of bars or lines forming simple corners, with obstacles such as U-shaped, snail-shaped, labyrinth-shaped, among other complicated shapes.The developed algorithm autonomously generates an obstacle-free navigation path, with a speed control of the robot, during the entire movement until reaching the final target.Besides, the simulation shows that the designed algorithm works adequately to solve the problem of concave obstacles, and compared with results of other mobile robot navigation techniques such as potential fields, diffuse controller-based techniques, and techniques based on rule learning (pure neural network); that in general, they present great limitations to solve the type of problem posed, difficult concave-type obstacles, remaining stuck in local minima or entering into infinite cycles with no exit, without reaching the final target; therefore, the robustness of the developed algorithm is shown."
10.1145/3448734.3450894,Kinematics Analysis of Anti-Terrorism Robot with Rigid-Flexible Parallel Closed Loop Linkage Mechanism,"The flexible linkage and parallel mechanism is gradually introduced to the structural design of various types of the robots. For anti-terrorism robot, this article put forward a kind of rigid-flexible hybrid parallel close looped linkage mechanism. Firstly, the plane rigid-flexible hybrid close looped system model is established. On this basis, dynamic model is established by using Lagrange and assumed mode methods. Finally, the model which has been developed was simulated, and it was compared and analyzed with the rigid system. The results show that the rules of the energy variation of the new model are similar to general rigid system. Therefore it can be applied to the same applicable situation. Under external force, the change curve of kinetic energy of rigid-flexible system is gentler. It has a more significant characteristic of smoothening impact and is more applicative where there is more impact as a result."
10.1145/3594806.3596534,Voice-Based Conversational Agents and Knowledge Graphs for Improving News Search in Assisted Living,"As the healthcare sector faces major challenges, such as aging populations, staff shortages, and common chronic diseases, delivering high-quality care to individuals has become very difficult. Conversational agents have shown to be a promising technology to alleviate some of these issues. In the form of digital health assistants, they have the potential to improve the everyday life of the elderly and chronically ill people. This includes, for example, medication reminders, routine checks, or social chit-chat. In addition, conversational agents can satisfy the fundamental need of having access to information about daily news or local events, which enables individuals to stay informed and connected with the world around them. However, finding relevant news sources and navigating the plethora of online news articles can be overwhelming, particularly for those with limited technological literacy or health-related impairments. To address this challenge, we propose an innovative solution that combines knowledge graphs and conversational agents for news search in assisted living. By leveraging graph databases to semantically structure news data and implementing an intuitive voice-based interface, our system can help care-dependent people easily discover relevant news articles and give personalized recommendations. We explain our design choices, provide a system architecture, share insights of an initial user test, and give an outlook on planned future work."
10.1145/3638530.3664116,Improving Efficiency of Evolving Robot Designs via Self-Adaptive Learning Cycles and an Asynchronous Architecture,"Algorithmic frameworks for the joint optimisation of a robot's design and controller often utilise a learning loop nested within an evolutionary algorithm to refine the controller associated with a newly generated robot design. Intuitively, it is reasonable to assume that the length of the learning period required is directly related to the complexity of the new design. Therefore, we propose a novel self-adaptive criterion that modifies the learning budget for each individual robot based on setting a target for the progress to be achieved during learning. This stopping criterion can lead to wide variance in learning times per robot evaluated. Research in other domains where variable evaluation time is also observed has suggested that asynchronous architectures are preferable in this situation, leading to improved objective performance and efficiency. We conduct a systematic comparison of synchronous and asynchronous architectures using the new learning stopping criterion in a joint optimisation task, showing that a judicious choice of target learning progress used in conjunction with an asynchronous framework provides considerably better results in terms of fitness and computational efficiency than a synchronous framework --- in the latter, the choice of target learning progress has no significant influence."
10.1145/3477314.3507270,Rating consistency is consistently underrated: an exploratory analysis of movie-tag rating inconsistency,"Content-based and hybrid recommender systems rely on item-tag ratings to make recommendations. An example of an item-tag rating is the degree to which the tag ""comedy"" applies to the movie ""Back to the Future (1985)"". Ratings are often generated by human annotators who can be inconsistent with one another. However, many recommender systems take item-tag ratings at face value, assuming them all to be equally valid. In this paper, we investigate the inconsistency of item-tag ratings together with contextual factors that could affect consistency in the movie domain. We conducted semi-structured interviews to identify potential reasons for rating inconsistency. Next, we used these reasons to design a survey, which we ran on Amazon Mechanical Turk. We collected 6,070 ratings from 665 annotators across 142 movies and 80 tags. Our analysis shows that ~45\% of ratings are inconsistent with the mode rating for a given movie-tag pair. We found that the single most important factor for rating inconsistency is the annotator's perceived ease of rating, suggesting that annotators are at least tacitly aware of the quality of their own ratings. We also found that subjective tags (e.g. ""funny"", ""boring"") are more inconsistent than objective tags (e.g. ""robots"", ""aliens""), and are associated with lower tag familiarity and lower perceived ease of rating."
10.1145/3503795,Enabling Morally Sensitive Robotic Clarification Requests,"The design of current natural language-oriented robot architectures enables certain architectural components to circumvent moral reasoning capabilities. One example of this is reflexive generation of clarification requests as soon as referential ambiguity is detected in a human utterance. As shown in previous research, this can lead robots to (1) miscommunicate their moral dispositions and (2) weaken human perception or application of moral norms within their current context. We present a solution to these problems by performing moral reasoning on each potential disambiguation of an ambiguous human utterance and responding accordingly, rather than immediately and naively requesting clarification. We implement our solution in the Distributed Integrated Cognition Affect and Reflection robot architecture, which, to our knowledge, is the only current robot architecture with both moral reasoning and clarification request generation capabilities. We then evaluate our method with a human subjects experiment, the results of which indicate that our approach successfully ameliorates the two identified concerns."
10.5555/3546258.3546359,LocalGAN: modeling local distributions for adversarial response generation,"This paper presents a new methodology for modeling the local semantic distribution of responses to a given query in the human-conversation corpus, and on this basis, explores a specified adversarial learning mechanism for training Neural Response Generation (NRG) models to build conversational agents. Our investigation begins with the thorough discussions upon the objective function of general Generative Adversarial Nets (GAN) architectures, and the training instability problem is proved to be highly relative with the special local distributions of conversational corpora. Consequently, an energy function is employed to estimate the status of a local area restricted by the query and its responses in the semantic space, and the mathematical approximation of this energy-based distribution is finally found. Building on this foundation, a local distribution oriented objective is proposed and combined with the original objective, working as a hybrid loss for the adversarial training of response generation models, named as LocalGAN. Our experimental results demonstrate that the reasonable local distribution modeling of the query-response corpus is of great importance to adversarial NRG, and our proposed LocalGAN is promising for improving both the training stability and the quality of generated results."
10.1145/3586996,CNN-based Robust Sound Source Localization with SRP-PHAT for the Extreme Edge,"Robust sound source localization for environments with noise and reverberation are increasingly exploiting deep neural networks fed with various acoustic features. Yet, state-of-the-art research mainly focuses on optimizing algorithmic accuracy, resulting in huge models preventing edge-device deployment. The edge, however, urges for real-time low-footprint acoustic reasoning for applications such as hearing aids and robot interactions. Hence, we set off from a robust CNN-based model using SRP-PHAT features, Cross3D&nbsp;[16], to pursue an efficient yet compact model architecture for the extreme edge. For both the SRP feature representation and neural network, we propose respectively our scalable LC-SRP-Edge and Cross3D-Edge algorithms which are optimized towards lower hardware overhead. LC-SRP-Edge halves the complexity and on-chip memory overhead for the sinc interpolation compared to the original LC-SRP&nbsp;[19]. Over multiple SRP resolution cases, Cross3D-Edge saves 10.32\%~73.71\% computational complexity and 59.77\%~94.66\% neural network weights against the Cross3D baseline. In terms of the accuracy-efficiency tradeoff, the most balanced version (EM) requires only 127.1 MFLOPS computation, 3.71 MByte/s bandwidth, and 0.821 MByte on-chip memory in total, while still retaining competitiveness in state-of-the-art accuracy comparisons. It achieves 8.59&nbsp;ms/frame end-to-end latency on a Rasberry Pi 4B, which is 7.26\texttimes{} faster than the corresponding baseline."
10.1145/3610661.3617514,Design of Generative Multimodal AI Agents to Enable Persons with Learning Disability,"The recent advances in Multimodal AI \&amp; Generative AI open doors to the possibilities of solving key challenges for Persons with Learning Disability. To assist individuals facing difficulty in visual or auditory perception, this paper designs \&amp; develops a multimodal AI agent using recent advances in the field. We aim to solve the challenge of enabling persons with Visual or Auditory Processing Disorders to learn \&amp; communicate. We do this by exploring a design that allows the transformation of information across visual and language modalities. This design can be realized with the recent advances in Generative Multimodal AI. Based on each individual's needs, the AI agent dynamically adapts the Human Computer interaction model. For instance, for a child with Visual Processing Disorder (VPD), given the child's hindered ability to make sense of information taken in through the eyes, the Multimodal AI agent transforms any visual information into auditory user interaction. In another instance, for a person with Central Auditory Processing Disorder (CAPD), given the hindrance in the individual's ability to analyze information taken in through the ears, the AI dynamically translates any speech modality into visual cues. Thus the AI agent adapts dynamically to the strengths and abilities of the individual. To enable students with VPD to learn, the design allows the student to ask questions about an image. This design is realized as a Visual Question Answering task in Vision Language Transformer models. We explore interactive multimodal conversations with Few shot Learning and In-Context Instruction Tuning of Multimodal Large Language Models to address difficulty in visual reasoning. To enable persons with CAPD to learn, the design translates audio lectures into visual cues. This visual cue consists of a combination of words using speech recognition and Large Language Models based re-phrasing to simpler words, cross-modal retrieval of images to address auditory memory challenges, and AI-generated images. To identify the strengths of each child, we also explore Multimodal embedding based Multimodal latent space arithmetic to link AI across senses. To effectively integrate the proposed design into the mainstream, we explore a universal design based inclusive approach to extend the use case to create AI assistants for assisting children with different learning styles such as visual learners or auditory learners. To enable future research on the proposed design, we explore an architecture to compose a pipeline of AI models, and to connect with external systems via plugin connectors. We implement lab scale prototypes of this design and present a demo on the project webpage at https://sites.google.com/view/multimodallearningdisability."
10.5555/3522802.3522882,Systemic characteristics to support hybrid simulation modeling,"Hybrid simulation (HS) is a modeling approach based on combining System Dynamics, Discrete Event Simulation, and/or Agent Based Simulation into a single model. There have been many benefits identified for utilization HS for planning and decision-making across many sectors. However, the lead time and skills requirements for developing HS models is usually greater than single methodology models. This position paper proposes that in order to improve and speed up the development of HS models, the decision to hybridize should be taken at the earliest possible point, i.e. when investigating the system and defining the problem. To this end, five system based characteristics have been proposed as decision points that help modelers to make such decisions. The paper concludes by suggesting a number of research avenues to follow for further improvements, whilst highlighting further challenges related to the availability of skills and tools for developing HS models."
10.1145/3638529.3654013,Towards Multi-Morphology Controllers with Diversity and Knowledge Distillation,"Finding controllers that perform well across multiple morphologies is an important milestone for large-scale robotics, in line with recent advances via foundation models in other areas of machine learning. However, the challenges of learning a single controller to control multiple morphologies make the 'one robot one task' paradigm dominant in the field. To alleviate these challenges, we present a pipeline that: (1) leverages Quality Diversity algorithms like MAP-Elites to create a dataset of many single-task/single-morphology teacher controllers, then (2) distills those diverse controllers into a single multi-morphology controller that performs well across many different body plans by mimicking the sensory-action patterns of the teacher controllers via supervised learning. The distilled controller scales well with the number of teachers/morphologies and shows emergent properties. It generalizes to unseen morphologies in a zero-shot manner, providing robustness to morphological perturbations and instant damage recovery. Lastly, the distilled controller is also independent of the teacher controllers - we can distill the teacher's knowledge into any controller model, making our approach synergistic with architectural improvements and existing training algorithms for teacher controllers."
10.5555/3716662.3716760,A Model- and Data-Agnostic Debiasing System for Achieving Equalized Odds,"As reliance on Machine Learning (ML) systems in real-world decision-making processes grows, ensuring these systems are free of bias against sensitive demographic groups is of increasing importance. Existing techniques for automatically debiasing ML models generally require access to either the models' internal architectures, the models' training datasets, or both. In this paper we outline the reasons why such requirements are disadvantageous, and present an alternative novel debiasing system that is both data- and model-agnostic. We implement this system as a Reinforcement Learning Agent and through extensive experiments show that we can debias a variety of target ML model architectures over three benchmark datasets. Our results show performance comparable to data- and/or model-gnostic state-of-the-art debiasers."
10.1145/3469410.3469419,Plant(e)tecture: Towards a Multispecies Media Architecture Framework for amplifying Plant Agencies,"More-than-human media architecture is gaining increased attention as a response to the planet's environmental emergency and in turn allowing us to envision a more desirable future compared to tech-utopian smart cities. New types of digital technologies have emerged into the human mindscape, and with that a new potential for bridging human understanding and multispecies geographies. Emphasising the agency of plants, this paper attempts to answer the following research questions: how can twenty-first-century media technologies, such as media architecture, be used to better incorporate plant/flora perspectives? This paper begins by providing a review of multispecies ontology, exploration of plant agency and how media architecture can visualise and amplify plant agency based on Whitehead's Process Philosophy, Mark Hansen's Feed-Forward concept and Feenberg's technical agency framework. Hortum Machina B, terra0, and Elowan are explored as three examples of Plant(e)tecture where the multispecies actors “plants'' are coupled with technologies and analysed for agency and autonomy. Synthesising the three case studies, the paper discusses the role of media architecture in (i) enabling plant agency; (ii) engaging multispecies actors in autonomous decision-making, and; (iii) the creation of technology to amplify the agency of plants in a design process that transcends human sensibilities. The paper closes on the prospect of the multispecies-techno agency framework to enable human designers, makers, decision-makers and thinkers to move beyond human-centric determinism prevalent in media architecture. The framework offers new ways of thinking of the purpose of technical agency in multispecies assemblages."
10.1145/3550356.3559090,A tool for the automation of efficient multi-robot choreography planning and execution,"In the automotive industry, the design, modeling, and planning of multi-robot cells are manual error-prone, and time-expensive tasks. A recent work investigated, using reactive synthesis, approaches to automate robot task planning, and execution. In this paper, we present a tool that realizes a model-at-runtime approach. The tool is integrated with a robot simulation tool, to automate efficient multi-robot choreography planning, and execution. We illustrate the tool using a multi-robot spot welding cell, inspired from an industrial case. Given a virtual model of the production cell, and user constraints definition, the tool can derive a specification for the reactive synthesis. The tool integrates the synthesized controller with the production cell execution, and in real time, optimizes the strategies by considering the uncertainties. The system can select among several correct, and safe actions, the optimal action using AI-based planning techniques, such as the Monte Carlo Tree Search (MCTS) algorithm. We showcase our tool, illustrate its implementation architecture, including how it can support robot experts for automated planning and execution of production cells."
10.1145/3512943,Human-AI Collaboration for UX Evaluation: Effects of Explanation and Synchronization,"Analyzing usability test videos is arduous. Although recent research showed the promise of AI in assisting with such tasks, it remains largely unknown how AI should be designed to facilitate effective collaboration between user experience (UX) evaluators and AI. Inspired by the concepts of agency and work context in human and AI collaboration literature, we studied two corresponding design factors for AI-assisted UX evaluation: explanations and synchronization. Explanations allow AI to further inform humans how it identifies UX problems from a usability test session; synchronization refers to the two ways humans and AI collaborate: synchronously and asynchronously. We iteratively designed a tool-AI Assistant-with four versions of UIs corresponding to the two levels of explanations (with/without) and synchronization (sync/async). By adopting a hybrid wizard-of-oz approach to simulating an AI with reasonable performance, we conducted a mixed-method study with 24 UX evaluators identifying UX problems from usability test videos using AI Assistant. Our quantitative and qualitative results show that AI with explanations, regardless of being presented synchronously or asynchronously, provided better support for UX evaluators' analysis and was perceived more positively; when without explanations, synchronous AI better improved UX evaluators' performance and engagement compared to the asynchronous AI. Lastly, we present the design implications for AI-assisted UX evaluation and facilitating more effective human-AI collaboration."
10.1145/3503161.3548281,Target-Driven Structured Transformer Planner for Vision-Language Navigation,"Vision-language navigation is the task of directing an embodied agent to navigate in 3D scenes with natural language instructions. For the agent, inferring the long-term navigation target from visual-linguistic clues is crucial for reliable path planning, which, however, has rarely been studied before in literature. In this article, we propose a Target-Driven Structured Transformer Planner (TD-STP) for long-horizon goal-guided and room layout-aware navigation. Specifically, we devise an Imaginary Scene Tokenization mechanism for explicit estimation of the long-term target (even located in unexplored environments). In addition, we design a Structured Transformer Planner which elegantly incorporates the explored room layout into a neural attention architecture for structured and global planning. Experimental results demonstrate that our TD-STP substantially improves previous best methods' success rate by 2\% and 5\% on the test set of R2R and REVERIE benchmarks, respectively. Our code is available at https://github.com/YushengZhao/TD-STP."
10.1145/3648536.3648545,A Multi-Robot Architecture Framework for Effective Robot Teammates in Mixed-Initiative Teams,"Effective robotic teammates should be able to interact with humans in natural language about all task aspects, keep track of task and team states to coordinate their actions, and handle unexpected events autonomously. In this paper, we introduce a multi-robot architectural framework for effective robot teammates that allows robots to learn new tasks on the fly and monitor task execution to be able to detect unexpected faults and events. It enables robots to generate recovery plans, assess their effectiveness, and engage with human teammates in problem solving dialogues. We demonstrate the capabilities and operation of the framework in a complex mixed-initiative human-robot medical assembly and delivery task."
10.1145/3503161.3547886,Dilated Context Integrated Network with Cross-Modal Consensus for Temporal Emotion Localization in Videos,"Understanding human emotions is a crucial ability for intelligent robots to provide better human-robot interactions. The existing works are limited to trimmed video-level emotion classification, failing to locate the temporal window corresponding to the emotion. In this paper, we introduce a new task, named Temporal Emotion Localization in videos (TEL), which aims to detect human emotions and localize their corresponding temporal boundaries in untrimmed videos with aligned subtitles. TEL presents three unique challenges compared to temporal action localization: 1) The emotions have extremely varied temporal dynamics; 2) The emotion cues are embedded in both appearances and complex plots; 3) The fine-grained temporal annotations are complicated and labor-intensive. To address the first two challenges, we propose a novel dilated context integrated network with a coarse-fine two-stream architecture. The coarse stream captures varied temporal dynamics by modeling multi-granularity temporal contexts. The fine stream achieves complex plots understanding by reasoning the dependency between the multi-granularity temporal contexts from the coarse stream and adaptively integrates them into fine-grained video segment features. To address the third challenge, we introduce a cross-modal consensus learning paradigm, which leverages the inherent semantic consensus between the aligned video and subtitle to achieve weakly-supervised learning. We contribute a new testing set with 3,000 manually-annotated temporal boundaries so that future research on the TEL problem can be quantitatively evaluated. Extensive experiments show the effectiveness of our approach on temporal emotion localization. The repository of this work is at https://github.com/YYJMJC/TemporalEmotion-Localization-in-Videos."
10.1145/3587259.3627561,Knowledge-enhanced Agents for Interactive Text Games,"Communication via natural language is a key aspect of machine intelligence, and it requires computational models to learn and reason about world concepts, with varying levels of supervision. Significant progress has been made on fully-supervised non-interactive tasks, such as question-answering and procedural text understanding. Yet, various sequential interactive tasks, as in text-based games, have revealed limitations of existing approaches in terms of coherence, contextual awareness, and their ability to learn effectively from the environment. In this paper, we propose a knowledge-injection framework for improved functional grounding of agents in text-based games. Specifically, we consider two forms of domain knowledge that we inject into learning-based agents: memory of previous correct actions and affordances of relevant objects in the environment. Our framework supports two representative model classes: reinforcement learning agents and language model agents. Furthermore, we devise multiple injection strategies for the above domain knowledge types and agent architectures, including injection via knowledge graphs and augmentation of the existing input encoding strategies. We experiment with four models on the 10 tasks in the ScienceWorld&nbsp;text-based game environment, to illustrate the impact of knowledge injection on various model configurations and challenging task settings. Our findings provide crucial insights into the interplay between task properties, model architectures, and domain knowledge for interactive contexts."
10.5555/3581644.3581718,Real Time Local Re-Routing to Limit Queuing Delay Exploiting SRv6 and Extensible In-Band Processing,"In this paper we introduce QLR, a per-router control agent that aims at reducing the occupancy of the local buffers by performing re-routing operations. The Segment Routing architecture is exploited to manage the uncoordinated selection of rerouting performed by different nodes, thus avoiding the creation of routing loops, while the Extensible In-band Processing is used to allow the network nodes to have a detailed and updated view of the wide network status. Data and control plane programmability are considered to define a prototype implementation of QLR that allows for the execution of a preliminary performance evaluation and proof-of-concept. From the conducted experiments has emerged that QLR can effectively reduce the maximum queue occupancy and end-to-end delay up to 43\% and 63\%, respectively."
10.1109/MICRO56248.2022.00065,AgilePkgC: An Agile System Idle State Architecture for Energy Proportional Datacenter Servers,"Modern user-facing applications deployed in data-centers use a distributed system architecture that exacerbates the latency requirements of their constituent microservices (30--250μs). Existing CPU power-saving techniques degrade the performance of these applications due to the long transition latency (order of 100μs) to wake up from a deep CPU idle state (C-state). For this reason, server vendors recommend only enabling shallow core C-states (e.g., CC1) for idle CPU cores, thus preventing the system from entering deep package C-states (e.g., PC6) when all CPU cores are idle. This choice, however, impairs server energy proportionality since power-hungry resources (e.g., IOs, uncore, DRAM) remain active even when there is no active core to use them. As we show, it is common for all cores to be idle due to the low average utilization (e.g., 5 -- 20\%) of datacenter servers running user-facing applications.We propose to reap this opportunity with AgilePkgC (APC), a new package C-state architecture that improves the energy proportionality of server processors running latency-critical applications. APC implements PC1A (package C1 agile), a new deep package C-state that a system can enter once all cores are in a shallow C-state (i.e., CC1) and has a nanosecond-scale transition latency. PC1A is based on four key techniques. First, a hardware-based agile power management unit (APMU) rapidly detects when all cores enter a shallow core C-state (CC1) and triggers the system-level power savings control flow. Second, an IO Standby Mode (IOSM) places IO interfaces (e.g., PCIe, DMI, UPI, DRAM) in shallow (nanosecond-scale transition latency) low-power modes. Third, a CLM Retention (CLMR) mode rapidly reduces the CLM (Cache-and-home-agent, Last-level-cache, and Mesh network-on-chip) domain's voltage to its retention level, drastically reducing its power consumption. Fourth, APC keeps all system PLLs active in PC1A to allow nanosecond-scale exit latency by avoiding PLL re-locking overhead.Combining these techniques enables significant power savings while requiring less than 200ns transition latency, &gt;250\texttimes{} faster than existing deep package C-states (e.g., PC6), making PC1A practical for datacenter servers. Our evaluation based on an Intel Skylake-based server shows that APC reduces the energy consumption of Memcached by up to 41\% (25\% on average) with &lt;0.1\% performance degradation. APC provides similar benefits for other representative workloads."
10.1145/3526071.3527515,Towards flexible runtime monitoring support for ROS-based applications,"Robotic systems are becoming common in different domains and for various purposes, such as unmanned aerial vehicles performing search and rescue operations, or robots operating in manufacturing plants. Such systems are characterized by close interactions, or even collaborations, between hardware and machinery on the one hand, and humans on the other. Furthermore, as Cyber-Physical Systems (CPS) in general and robotic applications in particular typically operate in an emergent environment, unanticipated events may occur during their operation, making the need for runtime monitoring support a crucial yet often time-consuming task. Runtime monitoring typically requires establishing support for collecting data, aggregating and transporting the data to a monitoring framework for persistence and further processing, and finally, performing checks of functional and non-functional properties. In this paper, we present our initial efforts towards a flexible monitoring framework for ROS-based systems. We report on challenges for establishing runtime monitoring support and present our preliminary architecture that aims to significantly reduce the setup and maintenance effort when creating monitors and establishing constraint checks."
10.1145/3532105.3535018,BlueSky: Combining Task Planning and Activity-Centric Access Control for Assistive Humanoid Robots,"In the not too distant future, assistive humanoid robots will provide versatile assistance for coping with everyday life. In their interactions with humans, not only safety, but also security and privacy issues need to be considered. In this Blue Sky paper, we therefore argue that it is time to bring task planning and execution as a well-established field of robotics with access and usage control in the field of security and privacy closer together. In particular, the recently proposed activity-based view on access and usage control provides a promising approach to bridge the gap between these two perspectives. We argue that humanoid robots provide for specific challenges due to their task-universality and their use in both, private and public spaces. Furthermore, they are socially connected to various parties and require policy creation at runtime due to learning. We contribute first attempts on the architecture and enforcement layer as well as on joint modeling, and discuss challenges and a research roadmap also for the policy and objectives layer. We conclude that the underlying combination of decentralized systems' and smart environments' research aspects provides for a rich source of challenges that need to be addressed on the road to deployment."
10.1145/3689218.3689233,The Application of the LSTM Neural Networks on the Hydrology Forecast,"In this research, we utilize the Long Short-Term Memory (LSTM) neural networks to forecast water flows at various reservoir sites. Utilizing historical meteorological data, we forecast the flow volumes for the following 30 hours based on the data from the first 15 hours. Our approach involves data preprocessing, feature engineering, model training and performance evaluation. Results indicate promising accuracy in flow prediction across multiple sites. Accurate streamflow forecasting is essential for effective water resource management and flood resilience planning. Traditional numerical models often face limitations in computational efficiency and inability to fully capture the complex, nonlinear dynamics of hydrological systems. With the recent advancements in deep learning, particularly Long Short-Term Memory (LSTM) networks, there is an opportunity to enhance streamflow predictions. This paper explores the application of LSTM networks for hourly streamflow forecasting at multiple catchments in the United States. Leveraging extensive, near-real-time hydrological and meteorological data from agencies such as the U.S. Geological Survey (USGS), the study develops an LSTM-based model to predict water flow. The model integrates historical data on temperature, precipitation, and flow measurements, and is trained to forecast streamflow at hourly intervals. Results demonstrate that the LSTM model effectively captures temporal dependencies, outperforming traditional methods. This study highlights the potential of LSTM networks to provide accurate and computationally efficient streamflow predictions, contributing to improved water management and flood forecasting capabilities. Future research directions include the incorporation of additional features and the exploration of advanced neural network architectures to further enhance prediction performance."
10.5555/3535850.3535982,Using Deep Learning to Bootstrap Abstractions for Hierarchical Robot Planning,"This paper addresses the problem of learning abstractions that boost robot planning performance while providing strong guarantees of reliability. Although state-of-the-art hierarchical robot planning algorithms allow robots to efficiently compute long-horizon motion plans for achieving user desired tasks, these methods typically rely upon environment-dependent state and action abstractions that need to be hand-designed by experts.We present a new approach for bootstrapping the entire hierarchical planning process. This allows us to compute abstract states and actions for new environments automatically using the critical regions predicted by a deep neural network with an auto-generated robot-specific architecture. We show that the learned abstractions can be used with a novel multi-source bi-directional hierarchical robot planning algorithm that is sound and probabilistically complete. An extensive empirical evaluation on twenty different settings using holonomic and non-holonomic robots shows that (a) our learned abstractions provide the information necessary for efficient multi-source hierarchical planning; and that (b) this approach of learning, abstractions, and planning outperforms state-of-the-art baselines by nearly a factor of ten in terms of planning time on test environments not seen during training."
10.1145/3551902.3551962,Service Mesh Patterns,"As the benefits and applicability of microservice architectures become better understood by the software industry, and this architecture becomes increasingly more adopted for building stable, independent and scalable cloud applications, a new set of concerns have alerted developers regarding communication between the different microservices. A service mesh tries to address this issue by creating a clear separation of concerns between application logic and the infrastructure needed for the communication between the different services. This is accomplished by abstracting the cross-cutting concerns related with communication out of the internal services making it possible to be reused by the different services. Existing literature describes a service mesh pattern and a sidecar pattern. This paper leans on these patterns and proposes six patterns found by observing the, what is commonly called, good practices. The six patterns are service mesh, shared communication library, node agent, sidecar, service mesh team and control plane per cluster."
10.5555/3398761.3399115,Competence-Aware Systems for Long-Term Autonomy,"Recent years have seen a push towards deploying fully autonomous robots in large, complex domains such as autonomous driving, space exploration, and service robots. However, legal, ethical, or technical constraints have limited the extent of these systems' employable autonomy. In order to successfully achieve their intended goals, these systems must utilize assistance from humans to compensate for their limitations. For such systems to be successful over the course of a long-term deployment, they must both be cognizant of their own competence and have the ability to improve this competence over time in a safe way. Motivated by practical concerns faced in industry, this thesis provides a formal model for such a human-agent system to reason about its own competence and aims in future work to provide effective ways of safely improving the competence of the system over the course of its deployment."
10.1145/3452296.3472902,Network planning with deep reinforcement learning,"Network planning is critical to the performance, reliability and cost of web services. This problem is typically formulated as an Integer Linear Programming (ILP) problem. Today's practice relies on hand-tuned heuristics from human experts to address the scalability challenge of ILP solvers.In this paper, we propose NeuroPlan, a deep reinforcement learning (RL) approach to solve the network planning problem. This problem involves multi-step decision making and cost minimization, which can be naturally cast as a deep RL problem. We develop two important domain-specific techniques. First, we use a graph neural network (GNN) and a novel domain-specific node-link transformation for state encoding, in order to handle the dynamic nature of the evolving network topology during planning decision making. Second, we leverage a two-stage hybrid approach that first uses deep RL to prune the search space and then uses an ILP solver to find the optimal solution. This approach resembles today's practice, but avoids human experts with an RL agent in the first stage. Evaluation on real topologies and setups from large production networks demonstrates that NeuroPlan scales to large topologies beyond the capability of ILP solvers, and reduces the cost by up to 17\% compared to hand-tuned heuristics."
10.1145/3376067.3376068,Pulmonary Tuberculosis Detection Using Deep Learning Convolutional Neural Networks,"Tuberculosis (TB) is classified as one of the top ten reasons for death from an infectious agent. This paper is to investigate the accuracy of two methods to detect Pulmonary Tuberculosis based on the patient chest X-ray images using Convolutional Neural Networks (CNN). Various image preprocessing methods are tested to find the combination that yields the highest accuracy. Moreover, a hybrid approach using the original statistical computer-aided detection method combined with Neural Networks was also investigated. Simulations have been carried out based on 406 normal images \&amp; 394 abnormal images. The simulations show that a cropped region of interest coupled with contrast enhancement yields excellent results. When further enhancing the images with the hybrid method even better results are achieved."
10.1145/3638209.3638213,Innovative Urban Design Simulation: Utilizing Agent-Based Modelling through Reinforcement Learning,"Data-driven design for cities is improving the quality of everyday life of citizens and optimizes the usage of resources. A new aspect is artificial intelligence, which Smart Cities could greatly benefit from. A central problem for urban designers is the unavailability of data to make relevant decisions. Agent-based simulations enable a view of the dynamic properties of the urban system, generating data in its course. However, the simulation must remain sufficiently simple to remain in the realm of computability. The research question of this paper is: How can we make agents behave more realistically to analyze citizens’ mobility behavior? To solve this problem, we first created a simulated virtual environment, where agents can move freely in a small part of a city, the harbor area in Hamburg, Germany. We assumed that happiness is a crucial motivating factor for the movement of citizens. A survey of 130 citizens provided the weights that govern the simulated environment and the happiness score assignation of places. As an AI method, we then used Reinforcement Learning as a general model and Q-learning as an algorithm to generate a baseline. Through randomly traversing the model environment a baseline was created. We are in the process of enhancing Reinforcement Learning with a Deep Q-Network to make the actors learn. Early experiments show a significant improvement over a tabular Q-learning approach. This paper contributes to the literature of urban planning, and data-driven architectural design. The main contribution is replacing the inefficient search for a global maximum of the happiness function, with an efficient local solution global maximum. This has implications for further research in the generation of synthetic data through simulations."
10.1145/3428300,Koord: a language for programming and verifying distributed robotics application,"A robot’s code needs to sense the environment, control the hardware, and communicate with other robots. Current programming languages do not provide suitable abstractions that are independent of hardware platforms. Currently, developing robot applications requires detailed knowledge of signal processing, control, path planning, network protocols, and various platform-specific details. Further, porting applications across hardware platforms remains tedious. We present Koord—a domain specific language for distributed robotics—which abstracts platform-specific functions for sensing, communication, and low-level control. Koord makes the platform-independent control and coordination code portable and modularly verifiable. Koord raises the level of abstraction in programming by providing distributed shared memory for coordination and port interfaces for sensing and control. We have developed the formal executable semantics of Koord in the K framework. With this symbolic execution engine, we can identify assumptions (proof obligations) needed for gaining high assurance from Koord applications. We illustrate the power of Koord through three applications: formation flight, distributed delivery, and distributed mapping. We also use the three applications to demonstrate how platform-independent proof obligations can be discharged using the Koord Prover while platform-specific proof obligations can be checked by verifying the obligations using physics-based models and hybrid verification tools."
10.5555/3400397.3400507,Hybrid system modeling approach for the depiction of the energy consumption in production simulations,"In many industrial manufacturing companies, energy has become a major cost factor. Energy aspects are included in the decision-making system of production planning and control to reduce manufacturing costs. For this priority, the simulation of production processes requires not only the consideration of logistical and technical production factors but also the integration of time-dependent energy flows which are continuous in nature. A hybrid simulation, using a continuous approach to depict the energy demand of production processes in combination with a discrete approach to map the material flows and logistic processes, shows the complex interactions between material flow and energy usage in production closer to reality. This paper presents a hybrid simulation approach combining System Dynamics, Discrete-Event and Agent-Based Simulation for energy efficiency analysis in production, considering the energy consumption in the context of planning and scheduling operations and applying it to a use-case scenario of mechanical processing of die-cast parts."
10.1145/3508072.3508114,Atmospheric Temperature Prediction across Nigeria using Artificial Neural Network,"Atmospheric temperature is one of the dominating atmospheric parameters that impact on the propagation of radio waves through the troposphere. Adequate knowledge of the atmospheric temperature of an environment is therefore essential for radio wave propagation planning. In this study, thirty-four (34)-year (1981-2014) atmospheric temperature data of 10 selected weather stations across the climatic zones of Nigeria, obtained from the Nigerian Meteorological Agency (NIMET) through the data bank of the West African Science Service Centre on Climate Change and Adaptive Land Use (WASCAL) of the Federal University of Technology Minna, Nigeria was used in Artificial Neural Network (ANN) for the prediction of mean monthly atmospheric temperature. The ANN architecture comprised of 2 inputs (the climatic zones and the corresponding month for the mean monthly atmospheric temperature), 1 hidden layer and 1 output (atmospheric temperature). Levenberg-Marquardt algorithm was used with 9 different pairs of activation functions formed from 3 activation functions (logsig, purelin and tansig). The number of neurons in the hidden layer was varied from 33-39 with an increasing steps of 2 (33, 35, 37 and 39). The network architecture of 2-37-1 (2 inputs, 37 neurons in the hidden layer and 1 output), with tansig/tansig pair of activation functions had the least mean square error value of 2.2280, and was used for the prediction process. The computed correlation values for measured and predicted atmospheric temperature ranged from 0.9733 to 0.8787, depicting strong positive correlation and good accuracy of the developed model. Comparisons of the measured and the ANN predicted atmospheric temperature across selected stations in the climatic zones of Nigeria, showed that the developed model can effectively predict mean monthly atmospheric temperature, using month and climatic zone as input parameters."
10.1145/3551708.3556203,MIXED REALITY MEDIA TECHNOLOGIES AS A CATALYST FOR ARCHITECTURAL AGENCY,"Though incredible strides have been made in the adoption of mixed reality technologies in the past decade, the reality is that they have often remained inaccessible for a variety of reasons including expense and expertise. While both the costs and learning curves of these technologies have flattened in recent years, they remain an esoteric component in contemporary pedagogy. This is fundamentally due to the lack of curricular and extracurricular application. This presentation demonstrates the effective adoption of virtual and augmented reality technologies in Canada's largest undergraduate accredited architecture program that has given agency to students in their academic design work and more noteworthy, their extracurricular initiatives. Through a comprehensive case study of a student project showcased at the recent international Winter Stations design exhibition, this paper demonstrates the effective inculcation, integration, and application of mixed reality tools in empowering students to bring their design ideas to built reality. The integration of innovative mixed reality technologies is no longer hampered by technological accessibility; it is mired by curricular inertia and dogma. The promise of breaking through conventional pedagogical frameworks with innovative technologies is reinforced and highlighted in this experiential learning precedent."
10.1145/3459996,Tactile Perception for Teleoperated Robotic Exploration within Granular Media,"The sense of touch is essential for locating buried objects when vision-based approaches are limited. We present an approach for tactile perception when sensorized robot fingertips are used to directly interact with granular media particles in teleoperated systems. We evaluate the effects of linear and nonlinear classifier model architectures and three tactile sensor modalities (vibration, internal fluid pressure, fingerpad deformation) on the accuracy of estimates of fingertip contact state. We propose an architecture called the Sparse-Fusion Recurrent Neural Network (SF-RNN) in which sparse features are autonomously extracted prior to fusing multimodal tactile data in a fully connected RNN input layer. The multimodal SF-RNN model achieved 98.7\% test accuracy and was robust to modest variations in granular media type and particle size, fingertip orientation, fingertip speed, and object location. Fingerpad deformation was the most informative modality for haptic exploration within granular media while vibration and internal fluid pressure provided additional information with appropriate signal processing. We introduce a real-time visualization of tactile percepts for remote exploration by constructing a belief map that combines probabilistic contact state estimates and fingertip location. The belief map visualizes the probability of an object being buried in the search region and could be used for planning."
10.1145/3412370,Finding the Largest Successful Coalition under the Strict Goal Preferences of Agents,"Coalition formation has been a fundamental form of resource cooperation for achieving joint goals in multiagent systems. Most existing studies still focus on the traditional assumption that an agent has to contribute its resources to all the goals, even if the agent is not interested in the goal at all. In this article, a natural extension of the traditional coalitional resource games (CRGs) is studied from both theoretical and empirical perspectives, in which each agent has uncompromising, personalized preferences over goals. Specifically, a new CRGs model with agents’ strict preferences for goals is presented, in which an agent is willing to contribute its resources only to the goals that are in its own interest set. The computational complexity of the basic decision problems surrounding the successful coalition is reinvestigated. The results suggest that these problems in such a strict preference way are complex and intractable. To find the largest successful coalition for possible computation reduction or potential parallel processing, a flow-network–based exhaust algorithm, called FNetEA, is proposed to achieve the optimal solution. Then, to solve the problem more efficiently, a hybrid algorithm, named 2D-HA, is developed to find the approximately optimal solution on the basis of genetic algorithm, two-dimensional (2D) solution representation, and a heuristic for solution repairs. Through extensive experiments, the 2D-HA algorithm exhibits the prominent ability to provide reassurances that the optimal solution could be found within a reasonable period of time, even in a super-large-scale space."
10.5555/3545946.3598826,Intelligent Onboard Routing in Stochastic Dynamic Environments using Transformers,"Autonomous marine agents find extensive applications in environmental data collection, naval security, and exploration of harsh ocean regions. As intelligent agents, they must perform onboard routing, collect data about their surroundings and update their route to minimize mission travel time, energy, or data collection. While Markov Decision Processes (MDPs) and Reinforcement Learning (RL) are often used for path planning, they are computationally expensive for onboard routing as they need in-mission re-planning. In the present paper, we develop a novel, deep learning method based on the decision transformers for optimal path planning and onboard routing of autonomous marine agents. The transformer architectures convert the RL-based optimal path planning problem into a supervised learning problem via sequence modeling. Before the mission, during the offline planning phase, the environment is first modeled as a stochastic dynamic ocean flow with dynamically orthogonal flow equations. A training dataset for the transformer model is created by solving the stochastic dynamically orthogonal Hamilton-Jacobi level set partial differential equations or a dynamic programming solution for MDPs. These paths are then processed to obtain sequences of states, actions and returns for our transformer models, where the agent's state is typically its spatio-temporal coordinate and other collectible data. We propose and analyze multiple state modeling choices against the agent's state estimation capabilities and scenarios with multiple target locations. We demonstrate that (i) a trained agent learns to infer the surrounding flow and perform optimal onboard routing when the agent's state estimation is accurate,(ii) specifying the target locations (in case of multiple targets) as a part of the state enables a trained agent to route itself to the correct destination, and (iii) a trained agent is robust to limited noise in state transitions and is capable of reaching target locations in completely new flow scenarios. We extensively showcase end-to-end planning and onboard routing in various canonical and idealized ocean flow scenarios. We analyze the predictions of the transformer models and explain the inner mechanics of learning through a novel visualization of self-attention of actions and states on the trajectories."
10.1109/TNET.2022.3149293,Defending Trace-Back Attack in 3D Wireless Internet of Things,"With the development of 5G, it is unsurprising that most of the smart devices in the Internet of Things (IoT) will be wirelessly connected with each other in the near future. This kind of lightweight, scalable and green network architecture will be well-received. In a wide variety of IoT application scenarios, sensor nodes deployed in a local space, such as a multistory building, automatically form a distributed 3D wireless IoT and it can be employed to collect and analyze environmental information. Source-location privacy protection is of great importance in these networks and however, most existing schemes focus on only planar distributed networks which are not suitable for the 3D networks. In this paper, we consider a novel trace-back attack for 3D wireless IoT and then design a source-location privacy protection scheme, named DMR-3D, to defend this kind of novel attacks. In DMR-3D, the source node first selects a set of virtual locations to indirectly choose a set of agent nodes based on the cold start sphere structure and the ellipsoid communication pipeline. Then, a sophisticated mechanism is designed based on both the connected graph and Multiple Delaunay Triangulation (MDT) structure of the network to deliver packets from the source node to the destination node via these agent nodes in a relay manner. Analysis and simulation results illustrate that the proposed scheme can effectively protect source-location privacy with a moderate increment of path stretch, time delay and data transmission amount."
10.1145/3434490,Discrete-Event Modeling and Simulation of Diffusion Processes in Multiplex Networks,"A variety of phenomena (such as the spread of diseases, pollution in rivers, etc.) can be studied as diffusion processes over networks (i.e., the diffusion of the phenomenon over a set of interconnected entities). This research introduces a method to study such diffusion processes in multiplex dynamic networks. We use a formal Modeling and Simulation methodology (in our case, DEVS, Discrete-Event System Specification). We use DEVS formal models to integrate models defined using Agent-Based Modeling and Network Theory. We present (1) an Architecture to study Diffusion Processes in Multiplex dynamic networks (ADPM) and (2) a systematic Process to define, implement, and simulate diffusion processes over such networks. We show a theoretical definition and a concrete implementation of ADPM. We show how to use ADPM and the process in a case study based on a real nuclear emergency plan; this illustrates the application of the process, the architecture, and the developed software. Different scenarios are studied as Diffusion Processes to demonstrate the usability of ADPM."
10.1145/3392858,C-Reference: Improving 2D to 3D Object Pose Estimation Accuracy via Crowdsourced Joint Object Estimation,"Converting widely-available 2D images and videos, captured using an RGB camera, to 3D can help accelerate the training of machine learning systems in spatial reasoning domains ranging from in-home assistive robots to augmented reality to autonomous vehicles. However, automating this task is challenging because it requires not only accurately estimating object location and orientation, but also requires knowing currently unknown camera properties (e.g., focal length). A scalable way to combat this problem is to leverage people's spatial understanding of scenes by crowdsourcing visual annotations of 3D object properties. Unfortunately, getting people to directly estimate 3D properties reliably is difficult due to the limitations of image resolution, human motor accuracy, and people's 3D perception (i.e., humans do not ""see"" depth like a laser range finder). In this paper, we propose a crowd-machine hybrid approach that jointly uses crowds' approximate measurements of multiple in-scene objects to estimate the 3D state of a single target object. Our approach can generate accurate estimates of the target object by combining heterogeneous knowledge from multiple contributors regarding various different objects that share a spatial relationship with the target object. We evaluate our joint object estimation approach with 363 crowd workers and show that our method can reduce errors in the target object's 3D location estimation by over 40\%, while requiring only $35$\% as much human time. Our work introduces a novel way to enable groups of people with different perspectives and knowledge to achieve more accurate collective performance on challenging visual annotation tasks."
10.1145/3388218.3388225,Multiple Waypoint Mobile Robot Path Planning Using Neighborhood Search Genetic Algorithms,"In this paper, we present a Neighborhood Search Genetic Algorithms (NSGAs) for mobile robot path planning. GAs have been used successfully in a variety of path planning problem because they can search the space of all possible paths and provide the optimal one. The convergence process of GAs might be lengthy compared to traditional search techniques that depend on local search methods. We propose a hybrid approach that allows GAs to combine both the advantages of GAs and local search algorithms. GAs will create a multiple waypoint path allowing a mobile robot to navigate through static obstacles and finding the optimal path in order to approach the target location without collision. The proposed NSGAs has been examined over four different path planning case studies with varying complexity. The performance of the enhanced GA has been compared with A-star algorithm (A*) standard GA, particle swarm optimization (PSO) algorithm. The obtained results show that the proposed approach is able to get good results compared to other algorithms."
10.5555/3463952.3464034,Grid-to-Graph: Flexible Spatial Relational Inductive Biases for Reinforcement Learning,"Although reinforcement learning has been successfully applied in many domains in recent years, we still lack agents that can systematically generalize. While relational inductive biases that fit a task can improve generalization of RL agents, these biases are commonly hard-coded directly in the agent's neural architecture. In this work, we show that we can incorporate relational inductive biases, encoded in the form of relational graphs, into agents. Based on this insight, we propose Grid-to-Graph (GTG), a mapping from grid structures to relational graphs that carry useful spatial relational inductive biases when processed through a Relational Graph Convolution Network (R-GCN). We show that, with GTG, R-GCNs generalize better both in terms of in-distribution and out-of-distribution compared to baselines based on Convolutional Neural Networks and Neural Logic Machines on challenging procedurally generated environments and MinAtar. Furthermore, we show that GTG produces agents that can jointly reason over observations and environment dynamics encoded in knowledge bases."
10.1145/3503510,A Workflow Architecture for Cloud-based Distributed Simulation,"Distributed Simulation has still to be adopted significantly by the wider simulation community. Reasons for this might be that distributed simulation applications are difficult to develop and access to multiple computing resources are required. Cloud computing offers low-cost on-demand computing resources. Developing applications that can use cloud computing can be also complex, particularly those that can run on different clouds. Cloud-based Distributed Simulation (CBDS) is potentially attractive, as it may solve the computing resources issue as well as other cloud benefits, such as convenient network access. However, as possibly shown by the lack of sustainable approaches in the literature, the combination of cloud and distributed simulation may be far too complex to develop a general approach. E-Infrastructures have emerged as large-scale distributed systems that support high-performance computing in various scientific fields. Workflow Management Systems (WMS) have been created to simplify the use of these e-Infrastructures. There are many examples of where both technologies have been extended to use cloud computing. This article therefore presents our investigation into the potential of using these technologies for CBDS in the above context and the WORkflow architecture for cLoud-based Distributed Simulation (WORLDS), our contribution to CBDS. We present an implementation of WORLDS using the CloudSME Simulation Platform that combines the WS-PGRADE/gUSE WMS with the CloudBroker Platform as a Service. The approach is demonstrated with a case study using an agent-based distributed simulation of an Emergency Medical Service in REPAST and the Portico HLA RTI on the Amazon EC2 cloud."
10.1145/3352593.3352673,Computation of Singularity Free Region and Design Optimisation of a Four-Degrees-of-Freedom Hybrid Arm,"This paper presents a method for the dimensional design of a spatial hybrid manipulator, namely, a four-degrees-of-freedom robotic arm. The design aims at finding the link parameters of the arm in such a manner that it possesses a singularity-free region that is bigger than a specified volume, in the shape of a cylinder. It is also required that the static performance of the manipulator, over this region, is better than a specified nominal level, quantified in terms of the actuator torques required to carry a fixed payload. The design problem is posed as a bi-objective optimisation problem, and solved using a GA-based optimiser code, namely, NSGA-II. The method is demonstrated via a numerical example. The Pareto-optimal solutions are obtained in a reasonable time, and the design achieves the required targets, thus demonstrating its efficacy."
10.1145/3404555.3404639,Urban Driving Based on Condition Imitation Learning and Multi-Period Information Fusion,"In recent years, autonomous driving has become a hot topic, especially in the complex urban road environment. The visual algorithm is the most used scheme for autonomous driving. The traditional condition imitation learning adopts the end-to-end deep learning network. But it lacks interpretability, and the ability of feature extraction and expression of network is limited. There are still some problems in the local planning and detail implementation. To solve these problems, we propose to use the deep residual network architecture and add the dual attention module to learn driving skills, which are closer to human beings. To further improve the detailed feature extraction ability of the network, the deeper residual network architecture is used. To adaptively integrate the global context long-range dependence of the image in the spatial and feature dimensions, the dual attention module is adopted to improve the ability of network expression. At the same time, in order to make full use of the multi-period attribute information of the camera image itself, we redesign the network architecture, extract, integrate the three-way temporal information features and the high-level semantics, and increase the interpretability of the temporal information of the model. This method is tested on the CARLA simulator. The experimental results show that compared with the benchmark algorithm, it achieves better driving effect. Deeper feature extraction and multi-period information fusion can effectively improve the driving ability and driving completion of the agent."
10.1145/3427773.3427863,Augmenting Reinforcement Learning with a Planning Model for Optimizing Energy Demand Response,"While reinforcement learning (RL) on humans has shown incredible promise, it often suffers from a scarcity of data and few steps. In instances like these, a planning model of human behavior may greatly help. We present an experimental setup for the development and testing of an Soft Actor Critic (SAC) V2 RL architecture for several different neural architectures for planning models: an autoML optimized LSTM, an OLS, and a baseline model. We present the effects of including a planning model in agent learning within a simulation of the office, currently reporting a limited success with the LSTM."
10.1145/3400302.3415759,DaDu series: fast and efficient robot accelerators,"Research on accelerators for robotics is increasing. This article introduces the kinematics, motion planning and collision detection algorithms and our accelerators in robotics, and then analyzes their advantages, disadvantages and bottlenecks. In view of the shortcomings of the existing accelerators, this paper will show a series accelerators named ""DaDu"" that we have proposed. For kinematics, we have proposed Dadu [1] to accelerate the inverse kinematics algorithm, which achieves 1700x speedup than the CPU implementation, 30x speedup than the GPU implementation, and 776x higher energy efficiency than the GPU implementation. For motion planning, we have proposed Dadu-P [2] to accelerate the PRM algorithm. It can get 26.5x speedup than an existing CPU-based approach for collision detection. Furthermore, with an incremental approach, the performance of motion planning can further be improved by 10x while the solution quality is degraded by 10\% only. For the collision detection algorithm in motion planning, the proposed accelerator Dadu-CD [3] elaborates the in-memory processing architecture, achieving at least 5x speedup than Dadu-P in the total planning time and 9.55x lower energy consumption than Dadu-P."
10.1145/3412841.3441942,The interplay of a conversational ontology and AI planning for health dialogue management,"Health dialogue systems are required to respect some special requirements such as predictability and reliability. While knowledge based approaches still seem to be the most appropriate for these systems, the automated generation of reliable policies remains an open problem. This work proposes an approach that integrates a conversational ontology (Convology) and Artificial Intelligence planning with the aim of automating the generation of a dialogue manager capable of handling goal-oriented dialogues for the health domain. The resulting dialogue manager is aimed to be integrated into a suitable architecture that provides the natural language components. We illustrate our approach by describing how it has been implemented into PuffBot, a multi-turn goal-oriented conversational agent for supporting patients affected by asthma."
10.1145/3352593.3352665,Effect of Cable Co-sharing on the Workspace of a cable-Driven Serial Chain Manipulator,"Serial chain robotic architectures can be actuated by cables attached to the links at desired positions to achieve the desired range of motion. There are possible applications for such mechanisms where low moving inertia is required. One of the challenges in the design of cable-driven mechanisms is to identify the regions where cables remain in tension. However, routing of the cables through multiple links i.e., cable co-sharing, alters the performance characteristics of the manipulator. This paper discusses the effect of cable co-sharing on the workspace of serial chain systems. Further, changes to be made in architecture to facilitate co-sharing is discussed. A planar 2 link cable-driven serial chain manipulator is considered for the analysis to present the advantages offered by co-sharing architecture in designing a compact system."
10.5555/3400397.3400437,STTAR: a simheuristics-enabled scheme for multi-stakeholder coordination of aircraft turnaround operations,"Aircraft turnaround operations involve all services to an aircraft (e.g. passenger boarding/disembarking, re-fuelling, deicing) between its arrival and immediately following departure. The aircraft, parked at its stand, witnesses a number of service providers move around it to perform their duties. These companies run substantially independent operations, working for different airlines/flights within a confined area where many resources, including physical space itself, have inescapably to be shared. Inter-dependencies among service providers abound, and knock-on effects at disrupted times are rife. Coordination from the side of the airport operator is difficult. We envisage a tactical robust scheme whereby ground handlers and the airport operator cooperate, albeit indirectly, in the development of plans for the next day that are less likely to be impacted by at least the more frequent operational disruptions. The scheme is based on a simheuristic approach which integrates ad-hoc heuristics with a hybrid simulation model (agent-based/discrete-event)."
10.5555/3437539.3437619,Dadu-CD: fast and efficient processing-in-memory accelerator for collision detection,"Collision detection is a fundamental task in motion planning of robotics. Typically, the performance of collision detection is the bottleneck of an entire motion planning, and so does the energy consumption. Several hardware accelerators have been proposed for collision detection, which achieves higher performance and energy efficiency than general-purpose CPUs and GPUs. However, existing accelerators are still facing the limited memory bandwidth bottleneck, due to the large data volume required by the parallel processing cores and the limited DRAM bandwidth. In this work, we propose a novel collision detection accelerator by employing the processing-in-memory technique. We elaborate the in-memory processing architecture to fully utilize the internal bandwidth of DRAM banks. To make the algorithm and hardware suitable for in-memory processing to be highly efficient, a set of innovative software and hardware techniques are also proposed. Compared with a state-of-the-art ASIC-based collision detection accelerator, both performance and energy efficiency of our accelerator are significantly improved."
10.1145/3433996.3434027,The Planning and Construction of Healthcare Big Data Platform,"Healthcare Big Data Platform is the important content in the process of medical information industry. To a certain extent, it represents the overall level of the regional informatization. It is also a data exchange and sharing platform connecting the basic systems of local various medical and health institutions, and it is also the base and carrier to integrate the regional information system. This paper introduces the local regional medical informatization construction, planning architecture, data center construction mode and technical realization methods. Through this project, the informatization level of basic health agencies and all hospitals will have been greatly improved. It can provide more convenient and high-quality medical service for patients, alleviates ""difficulty and expensive"" problem effectively."
10.1145/3457682.3457759,Multi-Perspective Reasoning Transformers,"Machine Reading Comprehension is defined as the ability of machines to read and understand unstructured text and answer questions about it. It is considered as a challenging task with wide range of enterprise applications. Wide range of natural language understanding and reasoning tasks are found embedded within machine reading comprehension datasets. This requires effective models with robust relational reasoning capabilities to answer complex questions. Reasoning in natural language is a long-term machine-learning goal and is critically needed for building intelligent agents. However, most papers heavily depend on underlying language modeling and thus pay little to no attention on creating effective reasoning models. This paper proposes a modified transformer architecture that effectively combines soft and hard attention to create multi-perspective reasoning model capable of tackling wide range of reasoning tasks. An attention mechanism that highlights the relational significance of input signals is considered as well. The result from this study shows performance gain as compared to its counterpart the transformer network on bAbI dataset, a natural language reasoning tasks."
10.1145/3369759,Parallel Data Distribution Management on Shared-memory Multiprocessors,"The problem of identifying intersections between two sets of d-dimensional axis-parallel rectangles appears frequently in the context of agent-based simulation studies. For this reason, the High Level Architecture (HLA) specification—a standard framework for interoperability among simulators—includes a Data Distribution Management (DDM) service whose responsibility is to report all intersections between a set of subscription and update regions. The algorithms at the core of the DDM service are CPU-intensive, and could greatly benefit from the large computing power of modern multi-core processors. In this article, we propose two parallel solutions to the DDM problem that can operate effectively on shared-memory multiprocessors. The first solution is based on a data structure (the interval tree) that allows concurrent computation of intersections between subscription and update regions. The second solution is based on a novel parallel extension of the Sort Based Matching algorithm, whose sequential version is considered among the most efficient solutions to the DDM problem. Extensive experimental evaluation of the proposed algorithms confirm their effectiveness on taking advantage of multiple execution units in a shared-memory architecture."
10.5555/3378680.3378739,Language-capable robots may inadvertently weaken human moral norms,"Previous research in moral psychology and human-robot interaction has shown that technology shapes human morality, and research in human-robot interaction has shown that humans naturally perceive robots as moral agents. Accordingly, we propose that language-capable autonomous robots are uniquely positioned among technologies to significantly impact human morality. We therefore argue that it is imperative that language-capable robots behave according to human moral norms and communicate in such a way that their intention to adhere to those norms is clear. Unfortunately, the design of current natural language oriented robot architectures enables certain architectural components to circumvent or preempt those architectures' moral reasoning capabilities. In this paper, we show how this may occur, using clarification request generation in current dialog systems as a motivating example. Furthermore, we present experimental evidence that the types of behavior exhibited by current approaches to clarification request generation can cause robots to (1) miscommunicate their moral intentions and (2) weaken humans' perceptions of moral norms within the current context. This work strengthens previous preliminary findings, and does so within an experimental paradigm that provides increased external and ecological validity over earlier approaches."
10.1145/3485114.3485122,The new analog: A protocol for linking design and construction intent with algorithmic planning for robotic assembly of complex structures,"Construction robotics are increasingly popular in the architectural fabrication community due to their accuracy and flexibility. Because of their high degree of motion freedom, these tools are able to assemble complex structures with irregular designs, which advances architectural aesthetics and structural performance. However, automated task and motion planning (TAMP) for a robot to assemble non-repetitive objects can be challenging due to (1) a non-repetitive assembly pattern (2) the need for a continuous robotic motion throughout a sequence of movement (3) a congested construction scene and (4) occasional robot configuration constraints due to taught positions. Recent work has already begun to address these challenges for repetitive assembly processes, where the robot repeats a pattern of primitive behaviors (e.g. brick stacking or spatial extrusion). Yet, there are many assembly processes that can benefit from a non-repetitive pattern. For example, processes can change tools on an element-by-element level to accommodate a wider range of geometry. Our work is motivated by the necessity of robotic modeling and planning for a recently published timber assembly process which utilizes distributed robotic clamps to press together interlocking joints. In addition to pick-and-place operations, the robot needs to move numerous tools within the construction scene, similar to a tool-change operation. In order to facilitate an agile process for architectural design, construction process design, and TAMP, we introduce a flowchart-based specification language which allows various designers to describe their design and construction intent and knowledge. A compiler can then translate the assembly description, sequence, process flowchart, and robotic setup into a plan skeleton. Additionally, we present a linear and a non-linear solving algorithm that can solve the plan skeleton for a full sequence of robot motions. This algorithm can be customized to take into account designer intuition, which can speed up the planning process. We provide a comparison of the two algorithms using the timber assembly process as our case study. We validate our results by robotically executing and constructing a large-scale real-world timber structure. Finally, we demonstrate the flexibility of our flowchart by showing how custom assembly actions are modeled in our case study. We also demonstrate how other recently published robotic assembly processes can be formulated using our flowcharts to demonstrate generalizability."
10.1145/3384544.3384595,IoT Soil Moisture Monitoring and Irrigation System Development,"Agriculture is vital in human evolution and was the first activity to be emphasized ever since the beginning of time. With the population growing constantly, there are inventions of new means in the production of food to cater for those demands. Improvement in a variety of technologies is one of such effort conducted for the cause. Robotics or chemical technologies may not be the only improvements that could be exercised. Internet of Things (IoT) technology is one of an application widely used currently. The study aims to establish a less manpower plantation in smart city with the use of IoT technology to improve the crop cultivation. In preliminary, a wireless soil moisture monitoring and irrigation system was developed. The system aims to monitor the moisture and properties of soil for plants. At the same time, with a self-sufficient and self-organized irrigation system based on the water-control algorithm. The developed system covered the three layers in IoT architecture: perception layer, network layer and application layer. In perception layer, a microcontroller, soil moisture sensors and solenoid valves acted as the sensors, transducers and actuators. Wireless networking technology (WiFi) was used as the communication for data transmitting and receiving. Through the developed application, humidity and irrigation volume were collected, recorded and analyzed. These preliminary results help in visualizing the concept of a less manpower plantation in smart city."
10.1145/3472813.3473197,"The Contemporary Issues in Medico-Social, Sanitary Protection of Mother and Child; Health Care Facilities, Awareness and Management of Primary Health Care Services in Nigeria","This study is focused on contemporaneous longer-term acute issues for mother child under five. It is an expository work targeted to uncover lack of access to Primary Health Care Services (PHCS) which has consistently posed serious health risks in Nigerian society, especially in rural areas, where health facilities are largely inadequate or absent in extreme cases. COVID-19 has played an important role in disclosing lapses of health facilities in most countries around the world and Nigeria is not an exception. Therefore, it takes cognizance of the mother and child health, pre and post antenatal well-being. Previous studies examination indicated that about one in every six children dies before age five in Nigeria. This suggests that improved access to adequate health care holds great potential for improved child survival. However, there has not been an enough systematic attempt to examine the effects of these barriers to health care on under-five mortality in Nigerian rural areas. This study is designed to address this knowledge gap. Method and materials: Online survey monkey tool (OSMT) aims to collect data and measure accuracy performance for proper feedback was employed. A structured questionnaire was used to send across 107 pregnant women in some rural areas in Nigeria for a period of one month and 2 weeks and they responded through emails, Facebook etc. due to Covid-19 protocol and restrictions. A total of 67 persons responded. Their feedback was processed, analyzed and presented in graphics. Objective: To ascertain the health situation of mother and child in Nigerian rural communities and the other prevalence factors influencing access to primary health care services. Results and discussion- We found 95.52\% respondents align with the fact that health of the mothers and children is a public health priority, 79.10\% agreed that progress in newborn health does not require expansive technology. 83.82\% subscribed to the idea that an urgent need is required t develop effective ways to organizing continuity of care during those first weeks after birth etc. Conclusion: Findings of this study stressed the need for improved access to adequate health care in rural areas through the elimination of barriers to access and education awareness. This study would enable health agencies and planners in the country to achieve a significant reduction in childhood and mother mortality in the long run."
10.5555/3400397.3400605,A distributed agent-based framework for a constellation of drones in a military operation,"A seamless communication capability is important in military operations. Likewise, enhanced security, increased capacity, and robust communication mechanisms are vital for humanitarian and disaster-response operations. Often, a system of wide-band satellites is employed for real-time exchange of information and over-the-horizon control, but the communications are prone to denial of service (DoS) attacks, and delayed redeployment. Hence, a swarm of drones could be deployed in mission-critical operations in times of urgency for a secured and robust distributed-intercommunication which is essential for survivability and successful completion of missions. In this paper, a distributed-agent-based framework for secure and reliable information exchange between drones in a constellation is proposed. The framework comprises a mechanism for path planning simulation and estimation, a flexible network architecture for improved client-server(C/S) and peer-to-peer (P2P) connectivity, as well as agents for identity authentications and secure communications. The framework has been simulated and verified with results showing promise."
10.1145/3373017.3373028,A Short Survey of Pre-trained Language Models for Conversational AI-A New Age in NLP,"Building a dialogue system that can communicate naturally with humans is a challenging yet interesting problem of agent-based computing. The rapid growth in this area is usually hindered by the long-standing problem of data scarcity as these systems are expected to learn syntax, grammar, decision making, and reasoning from insufficient amounts of task-specific dataset. The recently introduced pre-trained language models have the potential to address the issue of data scarcity and bring considerable advantages by generating contextualized word embeddings. These models are considered counterpart of ImageNet in NLP and have demonstrated to capture different facets of language such as hierarchical relations, long-term dependency, and sentiment. In this short survey paper, we discuss the recent progress made in the field of pre-trained language models. We also deliberate that how the strengths of these language models can be leveraged in designing more engaging and more eloquent conversational agents. This paper, therefore, intends to establish whether these pre-trained models can overcome the challenges pertinent to dialogue systems, and how their architecture could be exploited in order to overcome these challenges. Open challenges in the field of dialogue systems have also been deliberated."
10.1145/3449639.3459301,An efficient computational approach for automatic itinerary planning on web servers,"The automatic itinerary planning service requires to generate multiple-day schedules automatically under user-specified POIs and constraints. Knowing as an NP-Hard optimization problem, the task is commonly solved by (meta-)heuristic algorithms such as the genetic algorithms (GAs). However, considering the concurrent requests received by a web server in practice, the time efficiency of the existing itinerary planners can be rather unsatisfactory. To address the issue, this paper proposes a computational approach that hybridizing a GA with the reinforcement learning (RL) technology. The benefit is that we no longer need to re-execute the GA for each new request arrived. Instead, the approach keeps the historical solutions in track and maintains a RL agent to sequentially decide how to handle each new request. Experimental results show that the proposed approach is able to stably provide high-quality solutions, while greatly reducing the average time overhead of the web server."
10.1145/3453892.3461332,Benchmarking Force Control Algorithms,"Force control is nowadays a mature technology and it is becoming more and more common in robotic applications. A specific and significant example are robotic devices for rehabilitation. Despite this, an effective standardized and comprehensive method to assess force control performance does not exist. Defining the performance of a force-controlled system is not a trivial task, and one of the reasons is that performance does not only depend on the dynamics of the robot, but also on the dynamics of the environment, which are usually uncertain and time-varying. Exerting a force on a soft environment is different from exerting a force on a rigid environment. Indeed, the same force-controlled robot can have different force responses in different environments. This paper proposes a methodology to standardize the benchmarking of force control algorithms applied to different actuation architectures and considering a wide set of possible environments and disturbances, defined by the application of interest."
10.1145/3359852.3359907,Biomimicry and Art: transductions with biology,"This article discusses the concept of Biomimicry [2], which has been applyed in many fields, from nanotechnology to robotics. It is appearing in smart materials and machinic intelligence, for diverse purposes, being inspired by natural processes and organisms. The main application of Biomimicry has been to produce artifacts and ideas from what we know that nature has already done. While the mimesis has been removed from the vocabulary of Art, the works of some artists are still full of possibilities to discuss under the concept of Biomimetics. Many artists have dedicated themselves to the development of works using the poiesis of hybridization and mimicry. How close is the approach of Biomimetics? As examples, are brought Walmor Corr\^{e}a, Patr\'{\i}cia Piccinini, Liu Xue, Alessandro Boezio, Joan Fontcoberta and Pere Formiguera. This discussion is the starting point for my project ""VIRIDIUM"", in which Im developing some semiautonomous and translucent robots, printed in 3D. The poetic is the capacity that nature has of hybridizing and evolving, spontaneously, as well as being hybridized by genetic manipulation. I propose the development of objects / beings that do not exist in the nature but refer and simulate behaviors of those who inhabit the world, in different kingdoms of Nature. I describe the first stage of the project, which focuse the Plantae kingdom (also known as Metaphyta). Besides the Biomimicry (Biomimetics) concepts I bring the concept of Artification [3][16], as a possible model of understanding the poetic process, both in ""VIRIDIUM"" and in the works of the artists chosen."
10.5555/3437539.3437794,Enabling containerized computing and orchestration of ROS-based robotic SW applications on cloud-server-edge architectures: late breaking results,"We present a toolchain based on Docker and KubeEdge that enables containerization and orchestration of ROS-based robotic SW applications on heterogeneous and hierarchical HW architectures. The toolchain allows for verification of functional and real-time constraints through HW-in-the-loop simulation, and for automatic mapping exploration of the SW across Cloud-Server-Edge architectures. We present the results obtained for the deployment of a real case of study composed by an ORB-SLAM application combined to local/global planners with obstacle avoidance for a mobile robot navigation."
10.1145/3426425.3426942,Behavior trees in action: a study of robotics applications,"Autonomous robots combine a variety of skills to form increasingly complex behaviors called missions. While the skills are often programmed at a relatively low level of abstraction, their coordination is architecturally separated and often expressed in higher-level languages or frameworks. Recently, the language of Behavior Trees gained attention among roboticists for this reason. Originally designed for computer games to model autonomous actors, Behavior Trees offer an extensible tree-based representation of missions. However, even though, several implementations of the language are in use, little is known about its usage and scope in the real world. How do behavior trees relate to traditional languages for describing behavior? How are behavior tree concepts used in applications? What are the benefits of using them?  We present a study of the key language concepts in Behavior Trees and their use in real-world robotic applications. We identify behavior tree languages and compare their semantics to the most well-known behavior modeling languages: state and activity diagrams. We mine open source repositories for robotics applications that use the language and analyze this usage. We find that Behavior Trees are a pragmatic language, not fully specified, allowing projects to extend it even for just one model. Behavior trees clearly resemble the models-at-runtime paradigm. We contribute a dataset of real-world behavior models, hoping to inspire the community to use and further develop this language, associated tools, and analysis techniques."
10.1109/TCBB.2019.2896908,Active Vision and Surface Reconstruction for 3D Plant Shoot Modelling,"Plant phenotyping is the quantitative description of a plant's physiological, biochemical, and anatomical status which can be used in trait selection and helps to provide mechanisms to link underlying genetics with yield. Here, an active vision- based pipeline is presented which aims to contribute to reducing the bottleneck associated with phenotyping of architectural traits. The pipeline provides a fully automated response to photometric data acquisition and the recovery of three-dimensional (3D) models of plants without the dependency of botanical expertise, whilst ensuring a non-intrusive and non-destructive approach. Access to complete and accurate 3D models of plants supports computation of a wide variety of structural measurements. An Active Vision Cell (AVC) consisting of a camera-mounted robot arm plus combined software interface and a novel surface reconstruction algorithm is proposed. This pipeline provides a robust, flexible, and accurate method for automating the 3D reconstruction of plants. The reconstruction algorithm can reduce noise and provides a promising and extendable framework for high throughput phenotyping, improving current state-of-the-art methods. Furthermore, the pipeline can be applied to any plant species or form due to the application of an active vision framework combined with the automatic selection of key parameters for surface reconstruction."
10.1145/3411564.3411656,Web Accessibility Evolution in the Brazilian Government,"The Brazilian Federal Government has published many pieces of legislation to assure the rights of people with disabilities with respect to both architectural and digital accessibility. Unfortunately, studies conducted in 2015 and 2017 have shown that the web portals of many federal agencies, including those with ministry status, failed to fully comply with the current legislation in many aspects. The aim of this paper is to re-evaluate the web portals of the Brazilian Federal Ministries to assess how much they evolved since 2015 concerning their compliance with the Brazilian Accessibility Model (e-MAG); usage of the Digital Government Identity; publication of the Circumstantial Report and Accessibility Work Plan; and usage of recommended Content Management Systems. The results of our evaluation show that compliance with the e-MAG standard with ratings based on the different types of guidelines violated slightly improved, but the number of instances of violations of guidelines significantly dropped; the usage of the Digital Government Identity has increased satisfactorily as well as the usage of recommended tools for developing and maintaining web portals; and only few web portals published the Circumstantial Report and Accessibility Work Plan."
10.1145/3356998.3365765,Path optimization of integrating crowd model and reinforcement learning,"Exit choice and path planning are critical in emergency decision-making. Traditional research focuses on the shortest path, which is not sensitive to environmental factors such as the crowd congestion, obstacles distribution, air pollution, etc. To solve the path optimization problem, a behavior agent model is developed and integrated in the large-scale crowd simulation. The Q-Learning algorithm is applied to adjust the agent behavior. Considering the architectural space key exits and doors as network nodes, the paper presents combining dynamic crowd model and reinforcement learning strategy. The strategy with high training efficiency considering obstacles setup, crowd movement, and exits environment, the learning agent interacts dynamically with surrounding environment, and learns the shortest time path to exit. Simulation utilizes social force model for occupant movement, avoiding collisions with other occupants and obstacles. The path optimization is verified with the pedestrian library of Anylogic."
10.1145/3366423.3382668,Architectures for Autonomy: Towards an Equitable Web of Data in the Age of AI,"Today, the Web connects over half the world's population, many of whom use it to stay connected to a multiplicity of vital digital public and private services, impacting every aspect of their lives. Access to the Web and underlying Internet is seen as essential for all—even a fundamental human right [7]. However, many contend that the power structure on large swaths of the Web has become inverted; they argue that instead of being run for and by users, it has been made to serve the platforms themselves, and the powerful actors that sponsor such platforms to run targeted advertising on their behalf. In such an ad-driven platform ecosystem, users, including their beliefs, data, and attention, have become traded commodities [13].There is concern that the emergence of powerful data analytics and AI techniques threaten to further entrench the power of these same platforms, by putting the control of powerful and valuable new capabilities in their hands rather than the users who produce the data [10]. The fear is that it is giving rise to data and AI monopolies [2,6]. Individuals have no long-term control or agency over their personal data or many of the decisions made using it.This may be one reason we are witnessing a so called Renaissance of Ethics - a plethora of initiatives and activities that call out the range of threats to individual autonomy, self-determination and privacy, the lack of transparency and accountability, a concern around bias and fairness, equity and access in our data driven ecosystem. This keynote will argue as the remaining half of the world's population comes online, we need digital infrastructures that will promote a plurality of methods of data sovereignty and governance instead of imposing a ’single policy fits-all’ platform governance model, which has strained and undermined the ability for governments to protect and support their citizens digital rights.This is an opportunity to re-imagine and re-architect elements of the Web, data, algorithms and institutions so as to ensure a more equitable distribution of these new digital potentialities. Based on our existing research we have been developing methods and tech-nologies pertaining to the following core principles: informational self-determination and autonomy, balanced and equitable access to AI and data, accountability and redress of AI/algorithmic decisions, and new models of ethical participation and contribution.The technology that underpins the modern web has seen exponential rates of change that have continuously improved the capabilities of the processors, memory and communications upon which it depends. This has enabled huge amounts of data to be linked and stored as well as providing for increasing use of AI. A variety of projects will be described where we sought to unlock the potential of this increasingly powerful infrastructure [1, 4, 5, 9]. The lessons learnt through various efforts to develop the Seman-tic Web [8] and the insights gained through the release of open data at scale will be reviewed [11]. We will review our attempts to understand how the blending of humans, algorithms and data at scale results in social machines whose emergent properties results in behaviour and problem solving which any of the individual elements would not have been able to achieve [12]. Understanding these emergent properties of the web was one of the motivating factors behind the establishment of Web Science [3]. We will briefly review the prospects for Web Science.The importance of data as infrastructure to enable wide spread innovation, accountability and trusted reproducible science will be stressed. Recent work will be described that seeks to promote an equitable and balanced Web environment in which privacy can be upheld and better mutualities realised. Developments in technical and institutional architectures that could underpin an Ethical Web of data will be outlined."
