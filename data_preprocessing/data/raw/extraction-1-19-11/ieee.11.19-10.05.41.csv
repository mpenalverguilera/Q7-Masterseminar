"Source title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"A Self-Adaptive Multi-Agent System Approach for Collaborative Mobile Learning","D. G. de la Iglesia; J. F. Calderón; D. Weyns; M. Milrad; M. Nussbaum","Media Technology, Linnaeus University, Växjö, Kronoberg, Sweden; Departamento de Ciencia de la Computacion, Escuela de Ingeniera PUC, Santiago, RM, Chile; Department of Computer Science, Linnaeus University, DFM, Småland, Sweden; Center for Learning and Knowledge Technologies (CeLeKT), Linnaeus University, Vaxjo, Kronoberg, Sweden; Departamento de Ciencia de la Computacion, Escuela de Ingeniera PUC, RM, Chile",IEEE Transactions on Learning Technologies,"20 May 2017","2015","8","2","158","172","Mobile technologies have emerged as facilitators in the learning process, extending traditional classroom activities. However, engineering mobile learning applications for outdoor usage poses severe challenges. The requirements of these applications are challenging, as many different aspects need to be catered, such as resource access and sharing, communication between peers, group management, activity flow, etc. Robustness is particularly important for learning scenarios to guarantee undisturbed and smooth user experiences, pushing the technological aspects in the background. Despite significant research in the field of mobile learning, very few efforts have focused on collaborative mobile learning requirements from a software engineering perspective. This paper focuses on aspects of the software architecture, aiming to address the challenges related to resource sharing in collaborative mobile learning activities. This includes elements such as autonomy for personal interactive learning, richness for large group collaborative learning (indoor and outdoor), as well as robustness of the learning system. Additionally, we present self-adaptation as a solution to mitigate risks of resource unavailability and organization failures that arise from environment and system dynamism. Our evaluation provides indications regarding the system correctness with respect to resource sharing and collaboration concerns, and offers qualitative evidence of self-adaptation benefits for collaborative mobile learning applications.","1939-1382","","10.1109/TLT.2014.2367493","Center for Research on Educa-tional Policy and Practice(grant numbers:CIE01-CONICYT); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6948376","Mobile Learning;Software Architecture;Multi-Agent Systems;Self-Adaptation;Mobile learning;software architecture;multi-agent systems;self-adaptation","Mobile communication;Collaboration;Mobile handsets;Software;Robustness;Computer architecture;Performance evaluation","","28","","45","IEEE","5 Nov 2014","","","IEEE","IEEE Journals"
"A Novel Multi-Agent Parallel-Critic Network Architecture for Cooperative-Competitive Reinforcement Learning","Y. Sun; J. Lai; L. Cao; X. Chen; Z. Xu; Y. Xu","Command and Control Engineering College, Army Engineering University of PLA, Nanjing, China; Command and Control Engineering College, Army Engineering University of PLA, Nanjing, China; Command and Control Engineering College, Army Engineering University of PLA, Nanjing, China; Command and Control Engineering College, Army Engineering University of PLA, Nanjing, China; Command and Control Engineering College, Army Engineering University of PLA, Nanjing, China; The PLA Unit 31102, Nanjing, China",IEEE Access,"31 Jul 2020","2020","8","","135605","135616","Multi-agent deep reinforcement learning (MDRL) is an emerging research hotspot and application direction in the field of machine learning and artificial intelligence. MDRL covers many algorithms, rules and frameworks, it is currently researched in swarm system, energy allocation optimization, stocking analysis, sequential social dilemma, and with extremely bright future. In this paper, a parallel-critic method based on classic MDRL algorithm MADDPG is proposed to alleviate the training instability problem in cooperative-competitive multi-agent environment. Furthermore, a policy smoothing technique is introduced to our proposed method to decrease the variance of learning policies. The suggested method is evaluated in three different scenarios of authoritative multi-agent particle environment (MPE). Multiple statistical data of experimental results show that our method significantly improves the training stability and performance compared to vanilla MADDPG.","2169-3536","","10.1109/ACCESS.2020.3011670","National Natural Science Foundation of China(grant numbers:61806221); Advanced research fund of equipment development department(grant numbers:61421010318); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9146854","Multi-agent system;deep reinforcement learning;parallel-critic architecture;training stability","Training;Task analysis;Machine learning;Stability analysis;Games;Network architecture;Learning (artificial intelligence)","","12","","45","CCBY","24 Jul 2020","","","IEEE","IEEE Journals"
"Rational Coordination in Cognitive Agents: A Decision-Theoretic Approach Using ERMM","N. Mazhar; M. Kausar","Department of Software Engineering, Foundation University Islamabad, Islamabad, Pakistan; Department of Software Engineering, Foundation University Islamabad, Islamabad, Pakistan",IEEE Access,"1 Sep 2023","2023","11","","92628","92646","Over the years, research in multi-agent systems has become increasingly popular. Agents evolve by interacting with their environment and must communicate with other agents in order to do various cooperative tasks. The research aims to provide efficient coordination among cooperative cognitive agents in unpredictable multi-agent situations. Xiang’s rational agent model addresses scenarios when no social conventions or predefined communication protocols exist for the agents’ interaction and then makes decisions by recursive modeling. We address the deficiencies of the loosely coupled framework and the problem of mispredictions in Xiang’s architecture. The solution is based on Lawniczak’s Architecture for generic cognitive agents and an enhanced model of Xiang’s Recursive Modeling Method for coordinated decision-making in multi-agent situations. We instruct the cognitive agent to learn about other agents from past mispredictions and then consider its best choice. The feedback module is incorporated so agents can learn to maximize their joint expected reward. The model filters the mispredictions and evaluates the error rate. We compare the enhanced method with the Recursive Modeling Method. The results show that mispredictions are corrected from 33% to 10.9% and errors in perception are reduced from 22% to 0.097%, as the system progresses. Overall, the approach demonstrates superior performance. It significantly lowers the rate of mispredictions about other agents’ actions and takes 30% to 42% less time and 55.4 % fewer moves than RMM.","2169-3536","","10.1109/ACCESS.2023.3309417","Foundation University, Islamabad; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10232974","Cognitive agent;multi-agent system;recursive reasoning;agent reasoning;agent-oriented methodologies;loosely coupled framework;decision making;MAS communication;agent coordination;recursive modeling method","Decision making;Multi-agent systems;Computational modeling;Target tracking;Computer architecture;Cognition;Task analysis;Recursive estimation;Agent-based modeling","","","","45","CCBYNCND","28 Aug 2023","","","IEEE","IEEE Journals"
"Development of Deep-Learning-Based Autonomous Agents for Low-Speed Maneuvering in Unity","R. Berta; L. Lazzaroni; A. Capello; M. Cossu; L. Forneris; A. Pighetti; F. Bellotti","Electrical, Electronics and Telecommunication Engineering and Naval Architecture Department (DITEN), University of Genoa, Genoa, Italy; Electrical, Electronics and Telecommunication Engineering and Naval Architecture Department (DITEN), University of Genoa, Genoa, Italy; Electrical, Electronics and Telecommunication Engineering and Naval Architecture Department (DITEN), University of Genoa, Genoa, Italy; Electrical, Electronics and Telecommunication Engineering and Naval Architecture Department (DITEN), University of Genoa, Genoa, Italy; Electrical, Electronics and Telecommunication Engineering and Naval Architecture Department (DITEN), University of Genoa, Genoa, Italy; Electrical, Electronics and Telecommunication Engineering and Naval Architecture Department (DITEN), University of Genoa, Genoa, Italy; Electrical, Electronics and Telecommunication Engineering and Naval Architecture Department (DITEN), University of Genoa, Genoa, Italy",Journal of Intelligent and Connected Vehicles,"26 Sep 2024","2024","7","3","229","244","This study provides a systematic analysis of the resource-consuming training of deep reinforcement-learning (DRL) agents for simulated low-speed automated driving (AD). In Unity, this study established two case studies: garage parking and navigating an obstacle-dense area. Our analysis involves training a path-planning agent with real-time-only sensor information. This study addresses research questions insufficiently covered in the literature, exploring curriculum learning (CL), agent generalization (knowledge transfer), computation distribution (CPU vs. GPU), and mapless navigation. CL proved necessary for the garage scenario and beneficial for obstacle avoidance. It involved adjustments at different stages, including terminal conditions, environment complexity, and reward function hyperparameters, guided by their evolution in multiple training attempts. Fine-tuning the simulation tick and decision period parameters was crucial for effective training. The abstraction of high-level concepts (e.g., obstacle avoidance) necessitates training the agent in sufficiently complex environments in terms of the number of obstacles. While blogs and forums discuss training machine learning models in Unity, a lack of scientific articles on DRL agents for AD persists. However, since agent development requires considerable training time and difficult procedures, there is a growing need to support such research through scientific means. In addition to our findings, we contribute to the R&D community by providing our environment with open sources.","2399-9802","","10.26599/JICV.2023.9210039","CRF; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10695161","automated driving;autonomous agents;deep reinforcement learning;curriculum learning;modeling and simulation","Training;Systematics;Connected vehicles;Navigation;Graphics processing units;Machine learning;Complexity theory","","10","","87","","26 Sep 2024","","","TUP","TUP Journals"
"A Multi-Layered AI-Driven Cybersecurity Architecture: Integrating Entropy Analytics, Fuzzy Reasoning, Game Theory, and Multi-Agent Reinforcement Learning for Adaptive Threat Defense","E. F. Siddiqui; M. Haleem; S. F. Ahmad; A. Salhi; A. T. Zamani; N. Varish","Department of Computer Science, Era University, Lucknow, Uttar Pradesh, India; Department of Computer Science, Era University, Lucknow, Uttar Pradesh, India; Department of Artificial Intelligence and Data Science, GITAM (Deemed to be) University, Hyderabad Campus, Hyderabad, Telangana, India; Department of Information Systems, College of Computer and Information Sciences, Princess Nourah bint Abdulrahman University, P.O. Box 84428, Riyadh, Saudi Arabia; Department of Computer Science, Faculty of Science, Northern Border University, Arar, Saudi Arabia; Department of Computer Science and Engineering, GITAM (Deemed to be) University, Hyderabad Campus, Hyderabad, Telangana, India",IEEE Access,"3 Oct 2025","2025","13","","170235","170257","In the face of increasingly sophisticated cyberattacks, including adaptive adversaries and stealthy anomalies, key features of defense mechanisms should be effective, interpretable, and theoretically rooted. Conventional intrusion detection systems are typically based on a single-paradigm machine learning model which can be effective (because it is optimized for conditions), but fail in generalizability and falling back on an explanation of its prediction. This paper outlines a multi-layered AI-enabled cyber defense framework that integrates entropy analytics, fuzzy inference, game-theoretic defense, and multi-agent reinforcement learning (MARL) inside a closed-loop adaptive architecture. In its simplest form, the novelty of the paper is that, four functional paradigms - uncertainty quantification, interpretability, strategic adversarial thinking, and live policy adaptation - are placed into a single coherent system. The framework operates as sequential and feedback salients - entropy analytics quantify the uncertainty in are states, fuzzy inference end maps the uncertainty into qualitative decision rules, game theory shapes defender - attacker towards equilibrium strategies, and MARL dynamically updates those strategies for convergence and long term adaptation. The empirical work on appropriate benchmark intrusion detection datasets consistently outperformed baseline systems including the DDN, Fed-ID, AG-IDS, DL-FL systems producing a 6-12% increase in detection accuracy, lower false positive rates from non-intrusions, and a faster convergence, with adversarial examples across multiple epochs. Also, practical case studies reveal a level of improved explainability in threat classification and anomaly detection, which equates to practical interpretability for security analysts from the framework. The major contributions of the work are threefold: 1) an integrated multi-layered AI-based cybersecurity framework, 2) theoretical robustness results in bounded adversarial models, and 3) performance and interpretability form the systematic empirical evaluations over multiple datasets.","2169-3536","","10.1109/ACCESS.2025.3610526","Princess Nourah bint Abdulrahman University Researchers Supporting Project(grant numbers:PNURSP2025R909); Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11165264","Adversarial cybersecurity;entropy-based detection;fuzzy inference;game-theoretic defense;multi-agent reinforcement learning","Security;Artificial intelligence;Accuracy;Computer crime;Computer security;Reinforcement learning;Fuzzy logic;Entropy;Adaptation models;Real-time systems","","","","64","CCBY","16 Sep 2025","","","IEEE","IEEE Journals"
"Federated Reinforcement Learning Acceleration Method for Precise Control of Multiple Devices","H. -K. Lim; J. -B. Kim; I. Ullah; J. -S. Heo; Y. -H. Han","Department of Interdisciplinary Program in Creative Engineering, Korea University of Technology and Education, Cheonan, South Korea; Department of Computer Science Engineering, Korea University of Technology and Education, Cheonan, South Korea; Advanced Technology Research Center, Korea University of Technology and Education, Cheonan, South Korea; Department of Interdisciplinary Program in Creative Engineering, Korea University of Technology and Education, Cheonan, South Korea; Department of Computer Science Engineering, Korea University of Technology and Education, Cheonan, South Korea",IEEE Access,"27 May 2021","2021","9","","76296","76306","Nowadays, Reinforcement Learning (RL) is applied to various real-world tasks and attracts much attention in the fields of games, robotics, and autonomous driving. It is very challenging and devices overwhelming to directly apply RL to real-world environments. Due to the reality gap simulated environment does not match perfectly to the real-world scenario and additional learning cannot be performed. Therefore, an efficient approach is required for RL to find an optimal control policy and get better learning efficacy. In this paper, we propose federated reinforcement learning based on multi agent environment which applying a new federation policy. The new federation policy allows multi agents to perform learning and share their learning experiences with each other e.g., gradient and model parameters to increase their learning level. The Actor-Critic PPO algorithm is used with four types of RL simulation environments, OpenAI Gym's CartPole, MoutainCar, Acrobot, and Pendulum. In addition, we did real experiments with multiple Rotary Inverted Pendulum (RIP) to evaluate and compare the learning efficiency of the proposed scheme with both environments.","2169-3536","","10.1109/ACCESS.2021.3083087","Basic Science Research Program through the National Research Foundation of Korea (NRF) by the Ministry of Education(grant numbers:2018R1A6A1A03025526,NRF- 2020R1A6A3A13073735); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9439484","Federated reinforcement learning;multi-agent;transfer learning;gradient sharing","Reinforcement learning;Transfer learning;Training;Performance evaluation;Games;Systems architecture;Servers","","19","","33","CCBY","24 May 2021","","","IEEE","IEEE Journals"
"Herbguard: An Ensemble Deep Learning Framework With Efficientnet and Vision Transformers for Fine-Grained Classification of Medicinal and Poisonous Plants","A. Baskota; S. Ghimire; A. Ghimire; P. Baskaran","School of Computer Science and Engineering (SCOPE), Vellore Institute of Technology, Vellore, Tamil Nadu, India; School of Computer Science and Engineering (SCOPE), Vellore Institute of Technology, Vellore, Tamil Nadu, India; School of Computer Science and Engineering (SCOPE), Vellore Institute of Technology, Vellore, Tamil Nadu, India; School of Computer Science and Engineering (SCOPE), Vellore Institute of Technology, Vellore, Tamil Nadu, India",IEEE Access,"23 Oct 2025","2025","13","","179333","179350","Classifying whether a plant is herbal or poisonous is a significant challenge for trekkers, hikers, and nature enthusiasts, particularly in remote areas where several unfamiliar plant species are encountered. Consumption or even close contact with some poisonous plant species may lead to serious health risks, highlighting the need for an intelligent and real-time classification system. In this study, we propose an approach based on deep-learning to classify plants into several species under herbal and poisonous categories. The system employs Convolutional Neural Network (CNN) based EfficientNetV2-S, designed for local feature extraction, trained on segmented images, and transformer-based ViT-Tiny, capable of capturing global dependencies in images, fine-tuned on unsegmented raw images. Both models are trained using a two-stage fine-tuning strategy with label smoothing, MixUp, and CutMix augmentations. Preprocessing steps include CLAHE-based contrast enhancement, HSV masking and GrabCut segmentation, that are applied to training images to focus on relevant plant regions. The models are evaluated on 48 different plant species, consisting of 40 herbal and 8 poisonous species, ultimately achieving species-level accuracies of 95.86% (EfficientNet) and 96.69% (ViT) on the validation dataset. A soft-voting ensemble of the two models further improves species-level accuracy to 97.10% upon validation and 98.43% upon testing, while category-level accuracy remains consistently above 99.7% for all the models. These results demonstrate that combining convolutional and transformer-based approaches leads to a robust, highly accurate classification system that is capable of distinguishing varieties of medicinal and poisonous plants, offering a practical tool for safe trekking, biodiversity monitoring, and herbal medicine research.","2169-3536","","10.1109/ACCESS.2025.3622382","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11205506","Plant classification;herbal and poisonous plants;deep learning;convolutional neural network (CNN);EfficientNet;vision transformer;image segmentation;data augmentation;soft-voting ensemble","Accuracy;Transformers;Convolutional neural networks;Feature extraction;Medicinal plants;Biological system modeling;Image segmentation;Deep learning;Computer vision;Computational modeling","","","","23","CCBYNCND","16 Oct 2025","","","IEEE","IEEE Journals"
"Strategic Implementation of Super-Agents in Heterogeneous Multi-Agent Training for Advanced Military Simulation Adaptability","H. O. Altun; H. Furkan Ceran; K. Kutay Metın; T. Erol; E. Fişne","Institute for Data Science and Artificial Intelligence, Boğaziçi University, Istanbul, Türkiye; HAVELSAN, Çankaya, Ankara, Türkiye; HAVELSAN, Çankaya, Ankara, Türkiye; HAVELSAN, Çankaya, Ankara, Türkiye; Institute for Data Science and Artificial Intelligence, Boğaziçi University, Istanbul, Türkiye",IEEE Access,"6 Jun 2025","2025","13","","96544","96563","This study focuses on the application of reinforcement learning in tactical military simulation environments involving heterogeneous multi-agent systems. Optimizing Heterogeneous Multi-Agent Training (HMAT) through scenario-specific adjustments to the Proximal Policy Optimization (PPO) algorithm, we tackle the complexity of tactical simulations. Utilizing an advanced simulation platform, a diverse range of Reinforcement Learning (RL) agents are rigorously trained across various combat scenarios. A ‘super-agent’, an Artificial Intelligence (AI) orchestrator for multi-agent systems, marks a significant advancement in collaborative AI, enhancing operational performance. Comparative analysis highlights the strengths of both traditional RL approaches and HMAT in a unified computational framework. While independent learning agents excel in predictable environments with fast training capabilities, HMAT stands out in dynamic scenarios for its adaptability and superior performance. The integration of HMAT with ‘super-agents’ is shown to markedly improve the fidelity and adaptive capacity of military simulations. Experimental results demonstrate that our fine-tuned super-agent framework achieves up to 92% mission success rate, outperforming scenario-specific baselines by 15–20% in complex Suppression of Enemy Air Defenses (SEAD) and air-to-ground tasks.These enhancements have far-reaching implications, potentially revolutionizing strategic military training and operational planning and underscoring AI’s critical role in modern defense strategies.","2169-3536","","10.1109/ACCESS.2025.3573419","HAVELSAN’s Education Technologies Department; Forces in Virtual Environments Machine Learning (FIVE-ML) project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11015435","Advanced combat simulations;AI-driven tactical decision making;heterogeneous multi-agent systems;military simulation training;reinforcement learning;proximal policy optimization;super-agents and tactical scenario analysis","Training;Artificial intelligence;Scalability;Adaptation models;Decision making;Complexity theory;Multi-agent systems;Military computing;Heuristic algorithms;Computer architecture","","","","46","CCBYNCND","26 May 2025","","","IEEE","IEEE Journals"
"UAV cooperative air combat maneuver decision based on multi-agent reinforcement learning","Z. Jiandong; Y. Qiming; S. Guoqing; L. Yi; W. Yong","School of Electronics and Information, Northwestern Polytechnical University, Xi'an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi'an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi'an, China; Shenyang Aircraft Design Institute, Shenyang, China; School of Electronics and Information, Northwestern Polytechnical University, Xi'an, China",Journal of Systems Engineering and Electronics,"12 Jan 2022","2021","32","6","1421","1438","In order to improve the autonomous ability of unmanned aerial vehicles (UAV) to implement air combat mission, many artificial intelligence-based autonomous air combat maneuver decision-making studies have been carried out, but these studies are often aimed at individual decision-making in 1v1 scenarios which rarely happen in actual air combat. Based on the research of the 1v1 autonomous air combat maneuver decision, this paper builds a multi-UAV cooperative air combat maneuver decision model based on multi-agent reinforcement learning. Firstly, a bidirectional recurrent neural network (BRNN) is used to achieve communication between UAV individuals, and the multi-UAV cooperative air combat maneuver decision model under the actor-critic architecture is established. Secondly, through combining with target allocation and air combat situation assessment, the tactical goal of the formation is merged with the reinforcement learning goal of every UAV, and a cooperative tactical maneuver policy is generated. The simulation results prove that the multi-UAV cooperative air combat maneuver decision model established in this paper can obtain the cooperative maneuver policy through reinforcement learning, the cooperative maneuver policy can guide UAVs to obtain the overall situational advantage and defeat the opponents under tactical cooperation.","1004-4132","","10.23919/JSEE.2021.000121","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9679711","decision-making;air combat maneuver;cooperative air combat;reinforcement learning;recurrent neural network","Atmospheric modeling;Reinforcement learning;Autonomous aerial vehicles;Weapons;Recurrent neural networks;Decision making;Target tracking","","82","","","","12 Jan 2022","","","BIAI","BIAI Journals"
"Multi-UAV Path Planning for Wireless Data Harvesting With Deep Reinforcement Learning","H. Bayerlein; M. Theile; M. Caccamo; D. Gesbert","Communication Systems Department, EURECOM, Sophia Antipolis, France; TUM Department of Mechanical Engineering, Technical University of Munich, Munich, Germany; TUM Department of Mechanical Engineering, Technical University of Munich, Munich, Germany; Communication Systems Department, EURECOM, Sophia Antipolis, France",IEEE Open Journal of the Communications Society,"2 Jun 2021","2021","2","","1171","1187","Harvesting data from distributed Internet of Things (IoT) devices with multiple autonomous unmanned aerial vehicles (UAVs) is a challenging problem requiring flexible path planning methods. We propose a multi-agent reinforcement learning (MARL) approach that, in contrast to previous work, can adapt to profound changes in the scenario parameters defining the data harvesting mission, such as the number of deployed UAVs, number, position and data amount of IoT devices, or the maximum flying time, without the need to perform expensive recomputations or relearn control policies. We formulate the path planning problem for a cooperative, non-communicating, and homogeneous team of UAVs tasked with maximizing collected data from distributed IoT sensor nodes subject to flying time and collision avoidance constraints. The path planning problem is translated into a decentralized partially observable Markov decision process (Dec-POMDP), which we solve through a deep reinforcement learning (DRL) approach, approximating the optimal UAV control policy without prior knowledge of the challenging wireless channel characteristics in dense urban environments. By exploiting a combination of centered global and local map representations of the environment that are fed into convolutional layers of the agents, we show that our proposed network architecture enables the agents to cooperate effectively by carefully dividing the data collection task among themselves, adapt to large complex environments and state spaces, and make movement decisions that balance data collection goals, flight-time efficiency, and navigation constraints. Finally, learning a control policy that generalizes over the scenario parameter space enables us to analyze the influence of individual parameters on collection performance and provide some intuition about system-level benefits.","2644-125X","","10.1109/OJCOMS.2021.3081996","French government, through the 3IA Côte d’Azur Project(grant numbers:ANR-19-P3IA-0002); TSN CARNOT Institute(grant numbers:Robots4IoT); German Federal Ministry of Education and Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9437338","Internet of Things (IoT);map-based planning;multi-agent reinforcement learning (MARL);trajectory planning;unmanned aerial vehicle (UAV)","Path planning;Robot sensing systems;Training;Data collection;Wireless communication;Task analysis;Navigation","","146","","37","CCBY","20 May 2021","","","IEEE","IEEE Journals"
"Robust Model Selection for Plant Leaf Image Recognition Based on Evolutionary Ant Colony Optimization With Learning Rate Schedule","T. Chompookham; S. Phiphitphatphaisit; E. Okafor; O. Surinta","Department of Information Technology, Faculty of Informatics, Multi-Agent Intelligent Simulation Laboratory (MISL) Research Unit, Mahasarakham University, Mahasarakham, Thailand; Department of Information System, Faculty of Business Administration and Information Technology, Rajamangala University of Technology, Khonkaen Campus, Khon Kaen, Thailand; SDAIA-KFUPM Joint Research Center for Artificial Intelligence, King Fahd University of Petroleum and Minerals, Dhahran, Saudi Arabia; Department of Information Technology, Faculty of Informatics, Multi-Agent Intelligent Simulation Laboratory (MISL) Research Unit, Mahasarakham University, Mahasarakham, Thailand",IEEE Access,"24 Sep 2024","2024","12","","132369","132389","Selecting optimal deep learning models is often a time-consuming process. To address this challenge, we propose a novel variant of the ant colony optimization (ACO) algorithm. This approach is designed to enhance model selection across various deep learning architectures, with a particular focus on leaf classification tasks. We introduce a new ACO technique specifically tailored for selecting robust models within convolutional neural networks (CNNs). These models are then integrated into an ensemble learning framework known as ensemble CNNs. A distinguishing feature of our proposed evolutionary ACO algorithm is its ability to consistently identify a set of robust CNN models in each iteration. This capability is facilitated by an innovative fitness function and an adaptive learning rate schedule embedded within the ACO algorithm, which optimizes pheromone distribution. Unlike the original ACO algorithm, which consistently selects the same CNN model, our evolutionary approach enables the dynamic discovery of new CNN models. To validate our method, we conducted experiments on two plant leaf datasets: Mulberry and Turkey-plant. Our comparison with existing methods, specifically the ant colony system (ACS) and the max-min ant system (MMAS), demonstrated that the MMAS algorithm outperformed the ACS algorithm. Furthermore, we explored three ensemble learning techniques: unweighted average, weighted average, and cost-sensitive learning. The weighted average method emerged as the most effective ensemble approach, with its parameters determined through a grid search process. The results indicate that the evolutionary ACO algorithm not only facilitates the selection of robust deep learning models but also achieves superior performance compared to the original ACO algorithm when applied to the Mulberry leaf and Turkey-plant datasets.","2169-3536","","10.1109/ACCESS.2024.3457753","Mahasarakham University(grant numbers:6717011/2567); National Science and Technology Development Agency to Provide Government Scholarships in Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10677001","Model selection;ensemble learning;ensemble convolutional neural networks;metaheuristics;ant colony optimization;learning rate schedule","Convolutional neural networks;Feature extraction;Accuracy;Computational modeling;Adaptation models;Ensemble learning;Image recognition","","3","","96","CCBYNCND","11 Sep 2024","","","IEEE","IEEE Journals"
"Access Point Clustering in Cell-Free Massive MIMO Using Conventional and Federated Multi-Agent Reinforcement Learning","B. Banerjee; R. C. Elliott; W. A. Krzymieñ; M. Medra","Department of Electrical and Computer Engineering, University of Alberta, Edmonton, AB, Canada; Department of Electrical and Computer Engineering, University of Alberta, Edmonton, AB, Canada; Department of Electrical and Computer Engineering, University of Alberta, Edmonton, AB, Canada; Huawei Technologies Canada Company Ltd., Ottawa, ON, Canada",IEEE Transactions on Machine Learning in Communications and Networking,"3 Jul 2023","2023","1","","107","123","Cell-free massive multiple-input multiple-output (MIMO) systems consist of geographically-distributed multi-antenna access points (APs) that form a virtual massive MIMO array. To make the network arbitrarily scalable in size, each user should be served by the best possible personalized user-centric cluster of nearby APs. Unfortunately, determining that cluster is a combinatorially-complex problem made even harder when the users are in motion. Therefore, in this work, we develop a multi-agent reinforcement learning (MARL) algorithm for AP selection and clustering. Each AP is an agent in the MARL algorithm and it is trained to near-optimally select for itself which users to serve. Conventional MARL algorithms require a centralized reward system to train the agents, and the agents’ neural network weights tend to strongly depend on their locations during training. To counteract these problems, we also consider a federated MARL framework. Simulation results demonstrate both our conventional and federated MARL algorithms outperform existing published AP selection algorithms, and also provide performance comparable to the case of all APs serving all users. The results also show the conventional algorithm has somewhat superior performance in the environment it was trained in, but the federated algorithm transfers its learning to changed environments much better, with very little performance loss.","2831-316X","","10.1109/TMLCN.2023.3283228","Huawei Technologies Canada Company Ltd.; the Natural Sciences and Engineering Research Council (NSERC) of Canada; the 2022 IEEE International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10144362","Access point clustering;cell-free massive MIMO;centralized critic;decentralized actors;federated reinforcement learning;multi-agent reinforcement learning;user association","Massive MIMO;Clustering algorithms;Antenna arrays;Reinforcement learning;Matching pursuit algorithms;Antennas;Precoding","","21","","77","CCBY","5 Jun 2023","","","IEEE","IEEE Journals"
"Robust Defensive Cyber Agent for Multi-Adversary Defense","M. O. Farooq","Department of Computer Science, Munster Technological University Cork, Cork, Ireland",IEEE Transactions on Machine Learning in Communications and Networking,"12 Sep 2025","2025","3","","1030","1049","Modern cyber environments are becoming increasingly complex and distributed, often organized into multiple interconnected subnets and nodes. Even relatively small-scale networks can exhibit significant security challenges due to their dynamic topologies and the diversity of potential attack vectors. In modern cyber environments, human-led defense alone is insufficient due to delayed response times, cognitive overload, and limited availability of skilled personnel, particularly in remote or resource-constrained settings. These challenges are intensified by the growing diversity of cyber threats, including adaptive and machine learning-based attacks, which demand rapid and intelligent responses. Addressing this, we propose a reinforcement learning (RL)-based framework that integrates eXtreme Gradient Boosting (XGBoost) and transformer architectures to develop robust, generalizable defensive agents. The proposed agents are evaluated against both baseline defenders trained to counter specific adversaries and hierarchical generic agents representing the current state-of-the-art. Experimental results demonstrate that the RL-XGBoost (integration of RL and XGBoost) agent consistently achieves superior performance in terms of defense accuracy and efficiency across varied adversarial strategies and network configurations. Notably, in scenarios involving changes to network topology, both RL-Transformer (RL combined with transformer architectures) and RL-XGBoost agents exhibit strong adaptability and resilience, outperforming specialized blue agents and hierarchical agents in performance consistency. In particular, the RL-Transformer variant (RL-BERT) demonstrates exceptional robustness when attacker entry points are altered, effectively capturing long-range dependencies and temporal patterns through its self-attention mechanism. Overall, these findings highlight the RL-XGBoost model’s potential as a scalable and intelligent solution for multi-adversary defense in dynamic and heterogeneous cyber environments.","2831-316X","","10.1109/TMLCN.2025.3605855","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11150430","Autonomous cyber operations;cyber security;defensive blue agent;machine learning;transformers;XGBoost","Transformers;Human-machine systems;Machine learning;Training;Adaptation models;Reinforcement learning;Computer architecture;Boosting;Optimization;Network topology","","1","","20","CCBYNCND","3 Sep 2025","","","IEEE","IEEE Journals"
"A Distributed Assignment Method for Dynamic Traffic Assignment Using Heterogeneous-Adviser Based Multi-Agent Reinforcement Learning","Z. Pan; Z. Qu; Y. Chen; H. Li; X. Wang","School of Transportation, Jilin University, Changchun, China; School of Transportation, Jilin University, Changchun, China; School of Transportation, Jilin University, Changchun, China; School of Transportation, Jilin University, Changchun, China; School of Transportation, Jilin University, Changchun, China",IEEE Access,"28 Aug 2020","2020","8","","154237","154255","The Dynamic Traffic Assignment (DTA) is one of the important measures to alleviate urban network traffic congestion. The congestions are usually caused by stochastic traffic demands, which are generally unassignable from time dimension in the real-world but are assumed to be assignable in existing DTA methods (i.e. real-time travel demands). In this paper, a distributed DTA method for preventing urban network traffic congestion caused by stochastic real-time travel demands by improving Multi-Agent Reinforcement Learning (MARL). A team structure, which consists of decision-makers and advisers, is designed to learn parallelly in realistic DTA tasks. To reduce the size of the solution space adaptively, the dynamic critical values advised by adviser agents are adopted as constraints for the strategy space of decision-makers (i.e. main agents). A collaborative heterogeneous-adviser mechanism is designed to avoid deviation of guidance. To enhance the adaptability of DTA to the changeable external environment, the mixed strategy concept is introduced to improve the decision-making process of main agents. The respective mapping mechanisms are designed to define adaptive learning rates to improve the sensitivity of MARL. The Sioux Falls (SF) network is established as a test platform via a Dynamic Network Loading (DNL). The effectiveness of the suggested DTA method is assessed through numerical simulations SF network. Under the influence of the scenario with stochastic real-time travel demands, the results show that the proposed method outperforms in terms of the throughput of the network and the individual average travel time among the overall network. Additionally, the ability of the proposed method in response to the external environment rapidly has also been demonstrated. Adopting the suggested method can improve the state of the art to assign stochastic real-time travel demands dynamically and to avoid potential traffic congestion fundamentally.","2169-3536","","10.1109/ACCESS.2020.3018267","National Natural Science Foundation of China(grant numbers:51705196); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9172059","Dynamic traffic assignment;intelligent transportation system;multi-agent system;reinforcement learning;multi-agent reinforcement learning;numerical simulation","Real-time systems;Reinforcement learning;Stochastic processes;Convergence;Load modeling;Computer architecture;Decision making","","9","","72","CCBY","20 Aug 2020","","","IEEE","IEEE Journals"
"Deep Reinforcement Learning Versus Evolution Strategies: A Comparative Survey","A. Y. Majid; S. Saaybi; V. Francois-Lavet; R. V. Prasad; C. Verhoeven","Department of Microelectronics, Delft University of Technology, Delft, The Netherlands; Department of Software Technology, Delft University of Technology, Delft, The Netherlands; Department of Computer Science, Vrije Universiteit Amsterdam, Amsterdam, The Netherlands; Department of Software Technology, Delft University of Technology, Delft, The Netherlands; Department of Microelectronics, Delft University of Technology, Delft, The Netherlands",IEEE Transactions on Neural Networks and Learning Systems,"3 Sep 2024","2024","35","9","11939","11957","Deep reinforcement learning (DRL) and evolution strategies (ESs) have surpassed human-level control in many sequential decision-making problems, yet many open challenges still exist. To get insights into the strengths and weaknesses of DRL versus ESs, an analysis of their respective capabilities and limitations is provided. After presenting their fundamental concepts and algorithms, a comparison is provided on key aspects, such as scalability, exploration, adaptation to dynamic environments, and multiagent learning. Current research challenges are also discussed, including sample efficiency, exploration versus exploitation, dealing with sparse rewards, and learning to plan. Then, the benefits of hybrid algorithms that combine DRL and ESs are highlighted.","2162-2388","","10.1109/TNNLS.2023.3264540","Cognizant Technology Solutions through the Internet of Swarms Project; Rijksdienst voor Ondernemend Nederland under PPS O&I; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10114063","Deep reinforcement learning (DRL);evolution strategies (ESs);exploration;meta-learning;multiagent;parallelism","Q-learning;Deep learning;Games;Evolution (biology);Scalability;Robots;Optimization","","41","","194","CCBY","2 May 2023","","","IEEE","IEEE Journals"
"Adaptive Throughput Optimization in Multi-Rate IEEE 802.11 WLANs via Multi-Agent Deep Reinforcement Learning","M. -C. Chou; C. -F. Hung; C. -Y. Huang; C. -H. Ke","Department of Computer Science and Information Engineering, National Quemoy University, Kinmen, Taiwan; Department of Computer Science and Information Engineering, National Taiwan University of Science and Technology, Taipei City, Taiwan; Department of Electronic and Computer Engineering, National Taiwan University of Science and Technology, Taipei City, Taiwan; Department of Computer Science and Information Engineering, National Quemoy University, Kinmen, Taiwan",IEEE Open Journal of the Communications Society,"8 Jul 2025","2025","6","","5384","5394","As wireless networks become increasingly important in modern society, their application scenarios are becoming more diverse and complex. However, the heterogeneity of nodes and transmission conditions presents significant challenges to existing wireless strategies and traditional centralized AI methods, making it difficult to meet user demands for network throughput. This paper proposes a distributed architecture based on multi-agent reinforcement learning combined with deep reinforcement learning. Agents are deployed on individual transmission nodes, enabling distributed observation and autonomous decision-making, while the access point provides feedback derived from the network performance resulting from their individual decisions. By experimentally comparing centralized and distributed architectures in multi-rate environments, this paper analyzes trade-offs in scalability and network performance. Additional experiments conducted under dynamic network conditions with node mobility and static scenarios involving a larger number of coexisting nodes further validate the system’s robustness and adaptability. The analysis of training loss trends shows that although the distributed architecture incurs a higher training cost, it achieves improved throughput. In particular, the distributed method outperforms the centralized method by nearly 30% when the number of nodes is relatively small, and maintains a 5–10% performance advantage as the network continues to scale.","2644-125X","","10.1109/OJCOMS.2025.3580886","National Science and Technology Council (NSTC), Taiwan(grant numbers:112-2221-E-011-059-MY3,112-2221-E-507-002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11039654","IEEE 802.11 multi-rate wireless networks;throughput maximization;deep reinforcement learning;multi-agent","Throughput;Wireless networks;Computer architecture;Training;Optimization;IEEE 802.11ax Standard;Reinforcement learning;Heuristic algorithms;Decision making;Wireless sensor networks","","","","20","CCBY","18 Jun 2025","","","IEEE","IEEE Journals"
"A Low-Cost Q-Learning-Based Approach to Handle Continuous Space Problems for Decentralized Multi-Agent Robot Navigation in Cluttered Environments","V. B. Ajabshir; M. S. Guzel; E. Bostanci","Computer Engineering Department, Ankara University, Ankara, Turkey; Computer Engineering Department, Ankara University, Ankara, Turkey; Computer Engineering Department, Ankara University, Ankara, Turkey",IEEE Access,"6 Apr 2022","2022","10","","35287","35301","This paper addresses the problem of navigating decentralized multi-agent systems in partially cluttered environments and proposes a new machine-learning-based approach to solve it. On the basis of this approach, a new robust and flexible Q-learning-based model is proposed to handle a continuous space problem. As in reinforcement learning (RL) algorithms, Q-learning does not require a model of the environment. Additionally, Q-Learning (QL) has the advantages of being fast and easy to design. However, one disadvantage of QL is that it needs a massive amount of memory, and it grows exponentially with each extra feature introduced to the state space. In this research, we introduce an agent-level decentralized collision avoidance low-cost model for solving a continuous space problem in partially cluttered environments, followed by introducing a method to merge non-overlapping QL features in order to reduce its size significantly by about 70% and make it possible to solve more complicated scenarios with the same memory size. Additionally, another method is proposed for minimizing the sensory data that is used by the controller. A combination of these methods is able to handle swarm navigation low memory cost with at least18 number of robots. These methods can also be adapted for deep q-learning architectures so as to increase their approximation performance and also decrease their learning time process. Experiments reveal that the proposed method also achieves a high degree of accuracy for multi-agent systems in complex scenarios.","2169-3536","","10.1109/ACCESS.2022.3163393","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9745030","Adaptive algorithm;continuous space problem;multi-agent systems;Q-learning","Robot kinematics;Navigation;Q-learning;Robot sensing systems;Multi-agent systems;Swarm robotics;Task analysis","","5","","55","CCBY","30 Mar 2022","","","IEEE","IEEE Journals"
"Toward Causal Representation Learning","B. Schölkopf; F. Locatello; S. Bauer; N. R. Ke; N. Kalchbrenner; A. Goyal; Y. Bengio","Max Planck Institute for Intelligent Systems, Tübingen, Germany; Max Planck Institute for Intelligent Systems, Tübingen, Germany; Max Planck Institute for Intelligent Systems, Tübingen, Germany; Mila, Montreal, QC, Canada; Google Research Amsterdam, The Netherlands; Mila, Montreal, QC, Canada; Mila, Montreal, QC, Canada",Proceedings of the IEEE,"30 Apr 2021","2021","109","5","612","634","The two fields of machine learning and graphical causality arose and are developed separately. However, there is, now, cross-pollination and increasing interest in both fields to benefit from the advances of the other. In this article, we review fundamental concepts of causal inference and relate them to crucial open problems of machine learning, including transfer and generalization, thereby assaying how causality can contribute to modern machine learning research. This also applies in the opposite direction: we note that most work in causality starts from the premise that the causal variables are given. A central problem for AI and causality is, thus, causal representation learning, that is, the discovery of high-level causal variables from low-level observations. Finally, we delineate some implications of causality for machine learning and propose key research areas at the intersection of both communities.","1558-2256","","10.1109/JPROC.2021.3058954","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9363924","Artificial intelligence;causality;deep learning;representation learning","Mathematical model;Machine learning;Data models;Differential equations;Inference algorithms;Training data;Adaptation models;Artificial intelligence;Representation learning","","665","","282","CCBY","26 Feb 2021","","","IEEE","IEEE Journals"
"Cooperative Multi-Agent Deep Reinforcement Learning for Resource Management in Full Flexible VHTS Systems","F. G. Ortiz-Gomez; D. Tarchi; R. Martínez; A. Vanelli-Coralli; M. A. Salas-Natera; S. Landeros-Ayala","Universidad Politécnica de Madrid, Madrid, Spain; Department of Electrical, Electronic and Information Engineering, University of Bologna, Bologna, Italy; Universidad Politécnica de Madrid, Madrid, Spain; Department of Electrical, Electronic and Information Engineering, University of Bologna, Bologna, Italy; Universidad Politécnica de Madrid, Madrid, Spain; Agencia Espacial Mexicana, Mexico City, Mexico",IEEE Transactions on Cognitive Communications and Networking,"8 Mar 2022","2022","8","1","335","349","Very high throughput satellite (VHTS) systems are expected to have a huge increase in traffic demand in the near future. Nevertheless, this increase will not be uniform over the entire service area due to the non-uniform distribution of users and changes in traffic demand during the day. This problem is addressed by using flexible payload architectures, which allow the allocation of payload resources flexibly to meet the traffic demand of each beam, leading to dynamic resource management (DRM) approaches. However, DRM adds significant complexity to VHTS systems, so in this paper we discuss the use of one reinforcement learning (RL) algorithm and two deep reinforcement learning (DRL) algorithms to manage the resources available in flexible payload architectures for DRM. These algorithms are Q-Learning (QL), Deep Q-Learning (DQL) and Double Deep Q-Learning (DDQL) which are compared based on their performance, complexity and added latency. On the other hand, this work demonstrates the superiority a cooperative multiagent (CMA) decentralized distribution has over a single agent (SA).","2332-7731","","10.1109/TCCN.2021.3087586","Spanish Government, Ministerio de Economía, Industria y Competitividad through the National Program of Research, Development and Innovation within the FUTURE-RADIO project(grant numbers:TEC2017-85529-C3-1-R); Ph.D. scholarship provided by Universidad Politécnica de Madrid; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9448341","Bandwidth allocation;beamwidth allocation;power allocation;deep reinforcement learning;deep learning;dynamic resource management;flexible payload;multi-beam;cooperative multi-agent","Resource management;Payloads;Bandwidth;Satellite broadcasting;Reinforcement learning;Satellites;Color","","27","","39","CCBY","8 Jun 2021","","","IEEE","IEEE Journals"
"Toward an Automated Learning Control Architecture for Cyber-Physical Manufacturing Systems","I. Kovalenko; J. Moyne; M. Bi; E. C. Balta; W. Ma; Y. Qamsane; X. Zhu; Z. M. Mao; D. M. Tilbury; K. Barton","Department of Mechanical Engineering and Industrial & Manufacturing Engineering, Pennsylvania State University, University Park, PA, USA; Department of Mechanical Engineering, University of Michigan, Ann Arbor, MI, USA; Robotics Institute, University of Michigan, Ann Arbor, MI, USA; Automatic Control Laboratory, ETH Zürich, Zurich, Switzerland; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA; Siemens Technology, Production Automation Engineering, Charlotte, NC, USA; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA; Department of Mechanical Engineering, University of Michigan, Ann Arbor, MI, USA; Department of Mechanical Engineering, University of Michigan, Ann Arbor, MI, USA",IEEE Access,"18 Apr 2022","2022","10","","38755","38773","Manufacturers are constantly looking to enhance the performance of their manufacturing systems by improving their ability to address disruptions and disturbances, while reducing cost and maximizing quantity and quality. Even though innovative mechanisms for adaptability and flexibility continuously contribute to the smart manufacturing evolutionary process, they generally stop short of providing a capability for coordinated on-line learning. This is especially true when that learning requires exploration outside of established operational boundaries or uses artificial intelligence (as opposed to purely human intelligence) as part of the dynamic implementation of learning. In this work, we provide a vision for the development of an automated learning control architecture to extend the adaptability and flexibility capabilities of manufacturing systems. As part of this vision, we describe a set of requirements and objectives that, if addressed, provide an environment to allow distributed and automated learning across the manufacturing ecosystem. We then provide an example communication and control architecture that meets these requirements and objectives by gathering information, building a dynamic knowledge base, distributing intelligence, making decisions, and adapting the control commands sent to the equipment and people across the manufacturing ecosystem. The example architecture leverages both centralized and distributed control strategies and the ability to switch between the strategies to gather and learn from information in the system. Example case studies are provided illustrating how this architecture can be used to improve manufacturing system performance.","2169-3536","","10.1109/ACCESS.2022.3165551","National Science Foundation (NSF)(grant numbers:NSF-1544678); National Institute of Standards and Technology (NIST) Award(grant numbers:70NANB19H090); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9751037","Smart manufacturing;system-level control;industrial automation;cyber-physical systems;adaptation and learning;multi-agent systems","Manufacturing systems;Manufacturing;Computer architecture;Boundary conditions;Decision making;Decentralized control;Market research","","23","","89","CCBY","7 Apr 2022","","","IEEE","IEEE Journals"
"Application of Traffic Light Control in Oversaturated Urban Network Using Multi-Agent Deep Reinforcement Learning","E. Ei Mon; H. Ochiai; C. Aswakul","Department of Electrical Engineering, Faculty of Engineering, Wireless Network and Future Internet Research Unit, Chulalongkorn University, Bangkok, Thailand; Information and Communication Engineering, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Electrical Engineering, Faculty of Engineering, Wireless Network and Future Internet Research Unit, Chulalongkorn University, Bangkok, Thailand",IEEE Access,"14 Jun 2024","2024","12","","82384","82395","Adaptive traffic signal control techniques have been developed in numerous studies to increase traffic flow efficiency. Using traffic signals to design an adaptive traffic management system is ideal for reducing traffic congestion. Reinforcement learning is a branch of current approaches that try to learn a policy function through a trial-and-error process and maximize the reward through properly adjusted interaction with the learning agent’s environment. We propose a traffic signal control architecture for an oversaturated urban network using Deep Q-Network. We have enhanced the learning process by incorporating diverse state information through upstream and downstream detailed traffic states. We conduct experiments on the Simulation of Urban MObility, an open-source traffic simulator that supports large-scale traffic signal control.","2169-3536","","10.1109/ACCESS.2024.3397495","Second Century Fund (C2F) at Chulalongkorn University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10521498","Multi-agent;oversaturated traffic;reinforcement learning;simulation of urban mobility;traffic signal control","Roads;Q-learning;Traffic congestion;Deep reinforcement learning;Aerospace electronics;Traffic control;Urban areas","","8","","34","CCBYNCND","6 May 2024","","","IEEE","IEEE Journals"
"Model-Based Graph Reinforcement Learning for Inductive Traffic Signal Control","F. -X. Devailly; D. Larocque; L. Charlin","Department of Decision Sciences, HEC Montreal, Montreal, QC, Canada; Department of Decision Sciences, HEC Montreal, Montreal, QC, Canada; Department of Decision Sciences, HEC Montreal, Montreal, QC, Canada",IEEE Open Journal of Intelligent Transportation Systems,"24 Apr 2024","2024","5","","238","250","We introduce MuJAM, an adaptive traffic signal control method which leverages model-based reinforcement learning to 1) extend recent generalization efforts (to road network architectures and traffic distributions) further by allowing a generalization to the controllers’ constraints (cyclic and acyclic policies), 2) improve performance and data efficiency over related model-free approaches, and 3) enable explicit coordination at scale for the first time. In a zero-shot transfer setting involving both road networks and traffic settings never experienced during training, and in a larger transfer experiment involving the control of 3,971 traffic signal controllers in Manhattan, we show that MuJAM, using both cyclic and acyclic constraints, outperforms domain-specific baselines as well as a recent transferable approach.","2687-7813","","10.1109/OJITS.2024.3376583","Natural Sciences and Engineering Research Council (NSERC), Fonds de Recherche du Québec: Nature et Technologies (FRQNT); Fondation HEC Montréal; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10470423","Adaptive traffic signal control;transfer learning;multi-agent reinforcement learning;joint action modeling;model-based reinforcement learning;graph neural networks","Training;Road traffic;Adaptation models;Scalability;Reinforcement learning;Planning;Intelligent transportation systems;Adaptive control;Signal integrity;Transfer learning;Multi-agent systems;Graph neural networks","","10","","55","CCBY","12 Mar 2024","","","IEEE","IEEE Journals"
"Explaining a Deep Reinforcement Learning (DRL)-Based Automated Driving Agent in Highway Simulations","F. Bellotti; L. Lazzaroni; A. Capello; M. Cossu; A. De Gloria; R. Berta","Electronics and Telecommunication Engineering and Naval Architecture Department, University of Genoa, Genoa, Electrical, Italy; Electronics and Telecommunication Engineering and Naval Architecture Department, University of Genoa, Genoa, Electrical, Italy; Electronics and Telecommunication Engineering and Naval Architecture Department, University of Genoa, Genoa, Electrical, Italy; Electronics and Telecommunication Engineering and Naval Architecture Department, University of Genoa, Genoa, Electrical, Italy; Electronics and Telecommunication Engineering and Naval Architecture Department, University of Genoa, Genoa, Electrical, Italy; Electronics and Telecommunication Engineering and Naval Architecture Department, University of Genoa, Genoa, Electrical, Italy",IEEE Access,"27 Mar 2023","2023","11","","28522","28550","As deep learning models have become increasingly complex, it is critical to understand their decision-making, particularly in safety-relevant applications. In order to support a quantitative interpretation of an autonomous agent trained through Deep Reinforcement Learning (DRL) in the highway-env simulation environment, we propose a framework featuring three types of views for analyzing data: (i) episode timeline, (ii) frame by frame, and (iii) aggregated statistical analysis, also including heatmaps for a better spatial understanding. Our methodology allowed a novel, consistent description of the behavior of the agent. The main motivator for the taken action is typically the longitudinal distance from the second-closest and, to a lower extent, third-closest vehicle. In the overtakes, also the agent’s position in lanes becomes relevant. The analysis identified interesting patterns and an issue in the last frames of an episode, when the agent is unable to overtake the last two vehicles, arguably because of the lack of reference vehicles ahead. We observed a clear differentiation between attention and SHAP values (estimating the importance of each feature for each decision), reflecting the architecture of the neural network, where the first layer implements the attention mechanism, while the deeper ones make the actual decision. Attention focuses on the proximity of the ego, while the decision is taken on a wider horizon, denoting a valuable anticipation capability. To support research, the proposed framework is released as open source.","2169-3536","","10.1109/ACCESS.2023.3259544","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10077125","Automated driving;deep Q learning;explainable AI;highway simulation environment;reinforcement learning","Road transportation;Computational modeling;Behavioral sciences;Predictive models;Computer architecture;Deep learning;Trajectory;Autonomous driving;Reinforcement learning;Simulation;Road traffic","","22","","62","CCBY","20 Mar 2023","","","IEEE","IEEE Journals"
"F-CBR: An Architecture for Federated Case-Based Reasoning","A. Jaiswal; K. Y. Yigzaw; P. Öztürk","Department of Computer Science, Norwegian University of Science and Technology (NTNU), Trondheim, Norway; Norwegian Centre for E-health Research, Tromsø, Norway; Department of Computer Science, Norwegian University of Science and Technology (NTNU), Trondheim, Norway",IEEE Access,"21 Jul 2022","2022","10","","75458","75471","Case-based reasoning (CBR) is a problem-solving methodology in artificial intelligence that attempts to solve new problems using past experiences known as cases. Experiences collected in a single case base from an institution or geographical region are seldom sufficient to solve diverse problems, especially in rare situations. Additionally, many institutions do not promote peer-to-peer (p2p) communication or encourage data sharing through such networks to retain autonomy. The paper proposes a federated CBR (F-CBR) architecture to address these challenges. F-CBR enables solving new problems based on similar cases from multiple autonomous CBR systems without p2p communication. We also designed an algorithm to minimize (irrelevant or unsolicited) data sharing in an F-CBR system. We extend the F-CBR design to support institutions with organizational or geographical hierarchies. The F-CBR architecture was implemented and evaluated on two public datasets and a private real-world (non-specific musculoskeletal disorder patient) dataset. The findings demonstrate that the retrieval quality of F-CBR systems is comparable to or better than a single CBR system that persists all the cases on a centralized case base. F-CBR systems address data privacy by incorporating the data minimization principle. We foresee F-CBR as a viable real-world design that can aid in federating legacy CBR systems with minimal or no changes. The CBR systems used in this study are shared on GitHub to support reproducibility.","2169-3536","","10.1109/ACCESS.2022.3188808","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9815866","Case-based reasoning;data minimization;data privacy;data silos;decision support systems;federated architecture;federated case-based reasoning","Cognition;Artificial intelligence;Data privacy;Privacy;Collaborative work;Regulation;Peer-to-peer computing","","10","","49","CCBY","6 Jul 2022","","","IEEE","IEEE Journals"
"Intelligent Parent Change to Improve 6TiSCH Network Transmission Using Multi-Agent Q-Learning","D. Zakiyal Fawwaz; S. -H. Chung","Department of Information Convergence Engineering, Pusan National University, Busan, South Korea; Department of Information Convergence Engineering, Pusan National University, Busan, South Korea",IEEE Access,"1 Aug 2024","2024","12","","102862","102879","The 6TiSCH (IPv6 over the TSCH mode of IEEE 802.15.4e) architecture for wireless sensor networks merges the time-slotted channel hopping (TSCH) at the medium access control (MAC) layer with the routing protocols tailored for low-power and lossy networks (RPL). However, research often neglects the incorporation between TSCH MAC and RPL. Standard RPL strategies rely on an objective function (OF) using the expected transmission count (ETX) metric, which does not adequately reflect the traffic dynamics. Moreover, RPL’s hysteresis function employs a static threshold to control parent change decisions. This static setting disregarded the diverse traffic patterns within the network, leading to unnecessary parent node changes and preventing the node from selecting a better parent. To overcome these shortcomings, we introduce 3 advancements to standard RPL. First, an adaptive parent-changing mechanism based on cooperative Q-learning. Second, a cell usage and traffic load aware objective function. Third, an improved initial transmission cell allocation. Those methods are collectively termed ACI-RPL. We evaluated the performance of the proposed method through simulations using the 6TiSCH simulator and real-hardware tests on the FIT IoT-Lab testbed with OpenWSN firmware. The experiment result indicates that ACI-RPL performs better than the benchmark algorithms. In comparison to the standard RPL, ACI-RPL improves the packet delivery ratio and the total received packets by 12% and 17%, respectively. Additionally, ACI-RPL reduces energy consumption and latency by 23% and 9%.","2169-3536","","10.1109/ACCESS.2024.3433589","Institute of Information & communications Technology Planning & Evaluation (IITP) under the Artificial Intelligence Convergence Innovation Human Resources Development(grant numbers:IITP-2024-RS-2023-00254177); Korea Government (MSIT); MSIT (Ministry of Science and ICT), Korea, under the ITRC (Information Technology Research Center) support program(grant numbers:IITP-2024-RS-2023-00260098); IITP (Institute for Information & Communications Technology Planning & Evaluation); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10609377","6TiSCH;RPL;objective function;wireless sensor network;multi-agent Q-learning","Computer architecture;Microprocessors;Routing protocols;Measurement;Schedules;Resource management;Linear programming;Multi-agent systems;Q-learning","","1","","51","CCBYNCND","25 Jul 2024","","","IEEE","IEEE Journals"
"SABlockFL: a blockchain-based smart agent system architecture and its application in federated learning","Z. Zhang; T. Yang; Y. Liu","Software College, Northeastern University, Shenyang, China; Software College, Northeastern University, Shenyang, China; Software College, Northeastern University, Shenyang, China",International Journal of Crowd Science,"11 Jul 2022","2020","4","2","133","147","Purpose – The purpose of this work is to bridge FL and blockchain technology through designing a blockchain-based smart agent system architecture and applying in FL. and blockchain technology through designing a blockchain-based smart agent system architecture and applying in FL. FL is an emerging collaborative machine learning technique that trains a model across multiple devices or servers holding private data samples without exchanging their data. The locally trained results are aggregated by a centralized server in a privacy-preserving way. However, there is an assumption where the centralized server is trustworthy, which is impractical. Fortunately, blockchain technology has opened a new era of data exchange among trustless strangers because of its decentralized architecture and cryptography-supported techniques. Design/methodology/approach – In this study, the author proposes a novel design of a smart agent inspired by the smart contract concept. Specifically, based on the proposed smart agent, a fully decentralized, privacy-preserving and fair deep learning blockchain-FL framework is designed, where the agent network is consistent with the blockchain network and each smart agent is a participant in the FL task. During the whole training process, both the data and the model are not at the risk of leakage. Findings – A demonstration of the proposed architecture is designed to train a neural network. Finally, the implementation of the proposed architecture is conducted in the Ethereum development, showing the effectiveness and applicability of the design. Originality/value – The author aims to investigate the feasibility and practicality of linking the three areas together, namely, multi-agent system, FL and blockchain. A blockchain-FL framework, which is based on a smart agent system, has been proposed. The author has made several contributions to the state-of-the-art. First of all, a concrete design of a smart agent model is proposed, inspired by the smart contract concept in blockchain. The smart agent is autonomous and is able to disseminate, verify the information and execute the supported protocols. Based on the proposed smart agent model, a new architecture composed by these agents is formed, which is a blockchain network. Then, a fully decentralized, privacy-preserving and smart agent blockchain-FL framework has been proposed, where a smart agent acts as both a peer in a blockchain network and a participant in a FL task at the same time. Finally, a demonstration to train an artificial neural network is implemented to prove the effectiveness of the proposed framework.","2398-7294","","10.1108/IJCS-12-2019-0037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9826687","Blockchain;Federated learning;Smart agent","Training;Deep learning;Smart contracts;Systems architecture;Collaborative work;Data models;Blockchains","","16","","34","","11 Jul 2022","","","TUP","TUP Journals"
"A Memory Driven Self-learning Combat Agent Architecture in a 3D Virtual Environment","T. Zhang; Y. Wei; H. Fang","School of Automation, Beijing Institution of Technology, Beijing, China; School of Astronautics, Beijing Institution of Technology, Beijing, China; School of Automation, Beijing Institution of Technology, Beijing, China",Journal of Web Engineering,"25 Aug 2025","2025","24","5","687","712","Agent behavior modeling in 3D virtual environments is a critical challenge in artificial intelligence and military simulation. While rule-based methods (e.g., finite state machines) are widely used, their limitations in adaptability and development efficiency hinder their application in dynamic combat scenarios. To address this, a memory-driven self-learning agent (MDSLA) architecture is proposed, integrating visual, auditory, and game features to simulate human-like battlefield decision-making. The architecture employs an asynchronous advantage actor-critic (A3C) framework to enhance training efficiency and incorporates a memory module for processing historical perception data. Experimental validation in the Vizdoom environment demonstrates that MDSLA outperforms traditional rule-based methods and mainstream reinforcement learning algorithms in convergence speed and combat effectiveness. Furthermore, a parallel simulation mechanism is implemented via high-speed middleware, enabling seamless deployment of the model on both Vizdoom and a high-precision simulation platform (HPSP). Results from HPSP experiments show a 33% reduction in task execution time and a 24.1% improvement in lethality compared to finite state machine-driven agents. This work provides a scalable framework for developing intelligent combat agents with enhanced adaptability and realism in 3D virtual environments.","1544-5976","","10.13052/jwe1540-9589.2451","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11135462","Agent modelling;memory-driven architecture;reinforcement learning;military simulation;3D virtual environment","Training;Solid modeling;Adaptation models;Three-dimensional displays;Decision making;Virtual environments;Automata;Reinforcement learning;Intelligent agents;Middleware","","","","38","","25 Aug 2025","","","River Publishers","River Publishers Journals"
"Hierarchical Reinforcement Learning for Submarine Torpedo Countermeasures and Evasive Manoeuvres","B. Kang; W. Yun","LIG Nex1, Seongnam-si, South Korea; LIG Nex1, Seongnam-si, South Korea",IEEE Access,"22 Nov 2024","2024","12","","170620","170631","Modern naval warfare environment is becoming increasingly complex, with acoustic-based torpedoes being the most significant threat to submarines. It is essential to develop advanced technologies to enhance submarine survival rates. In this paper, we propose a hierarchical multi-agent reinforcement learning scheme and a realistic underwater simulation environment for optimal submarine torpedo countermeasures and evasive manoeuvres. Our hierarchical model consists of high-level and low-level agents. The high-level agent decides on decoy launches, while the low-level agent executes specific torpedo countermeasures and evasive manoeuvres. We implement underwater simulation environment based on a 6-DOF motion model to realistically simulate underwater object movements and use PID control for accurate and stable physics. This database is used for active and passive SONAR detection of torpedoes and submarines, enhancing the realism of the acoustic environment. We designed 4-level metrics to systematically analyze model performance in static and dynamic environments with single and multiple torpedo scenarios. Also, we propose a new training methodology to address delayed and sparse reward problems by considering submarine manoeuvring characteristics. Experimental results show that our proposed hierarchical architecture demonstrates competitive performance, achieving a survival rate of 89.07% even in the most complex dynamic environment. We demonstrate improved submarine torpedo countermeasures and evasive manoeuvre performance through stable training in complex underwater environments.","2169-3536","","10.1109/ACCESS.2024.3487152","Korean Research Institute for defense Technology planning and advancement (KRIT) grant funded by the Korean Government Defense Acquisition Program Administration(grant numbers:KRIT-CT-22-023-03, 2022); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10737084","Hierarchical reinforcement learning;submarine torpedo countermeasures;evasive manoeuvres;underwater simulation environment","Underwater vehicles;Reinforcement learning;Training;Missiles;Vehicle dynamics;6-DOF;Salinity (geophysical);Accuracy;Vectors;Q-learning","","2","","39","CCBYNCND","28 Oct 2024","","","IEEE","IEEE Journals"
"Multi-Agent Transformer Networks With Graph Attention","W. Jin; H. Lee","Department of Computer Engineering, Kwangwoon University, Seoul, South Korea; Department of Computer Engineering, Kwangwoon University, Seoul, South Korea",IEEE Access,"10 Oct 2024","2024","12","","144982","144991","In addressing multi-agent reinforcement learning (MARL) challenges, Multi-Agent Transformer (MAT) has demonstrated a number of notable successes. In various benchmarks, MAT consistently showed a strong performance. A key observation in the latest MAT frameworks is MARL modeling with sequence modeling (SM) to represent the inter-agent relationships by self-attention mechanisms. This study applies graph-based modeling to represent the inter-agent relationships present in agent interactions to improve performance. To this end, we introduce the so-called MAT-GAT model, which leverages Graph Attention Networks (GAT) to allow for individualized consideration of interactions between agents. This enables MAT to pay more attention to information relative to inter-agent interactions within a cooperative MARL environment. To evaluate the performance of MAT-GAT, we conducted a series of benchmark tests across three different levels of StarCraft Multi-Agent Challenge (SMAC) tasks and the MuJoCo Half-cheetah task. The test results indicate that MAT-GAT outperforms both the original MAT and state-of-the-art baselines such as QMIX, particularly in complex environments. This demonstrates MAT-GAT’s improved performance with respect to its representation capabilities and learning.","2169-3536","","10.1109/ACCESS.2024.3447056","Ministry of Science and Information and Communication Technology (MSIT), under the National Program for Excellence in Software (SW) Supervised by the Institute for Information & Communication Technology Planning & Evaluation (IITP)(grant numbers:2017-0-00096); Research Grant of Kwangwoon University in 2024; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10643073","Multi-agent;reinforcement learning;transformer;GAT;SMAC;MuJoCo","Transformers;Reinforcement learning;Games;Task analysis;Scalability;Decoding;Observability;Multi-agent systems","","1","","60","CCBYNCND","21 Aug 2024","","","IEEE","IEEE Journals"
"Combined Multi-Agent and Centralized Resource Allocation in Cloud Radio Access Networks","R. T. Rodoshi; R. A. Nazib; C. Chun; W. Choi","Department of Computer Science, George Mason University, Fairfax, VA, USA; Department of Computer Science, George Mason University, Fairfax, VA, USA; Department of Computer Engineering, Chosun University, Gwangju, Republic of Korea; School of Computer Science and Engineering, Chung-Ang University, Seoul, Republic of Korea",IEEE Access,"7 May 2025","2025","13","","79098","79106","The fifth generation (5G) mobile network is designed to facilitate high data rates with massive connectivity with the benefit of small cell technology. The cloud radio access network (C-RAN) is a promising mobile network architecture that can meet the ever-increasing resource demand of a growing number of users. In C-RAN, base station functionalities are separated into baseband units (BBUs) and remote radio heads (RRHs), with BBUs centralized and virtualized via cloud computing. However, this architecture introduces new challenges in efficiently allocating resources to dynamic users. This paper aims to design a resource allocation scheme that improves system efficiency and satisfies dynamic user demands in C-RAN. We propose a hybrid resource allocation approach that combines centralized control and multi-agent-based decision-making. The centralized controller, located within the BBU pool, collaborates with virtual base stations (VBSs) acting as multi-agent system (MAS) agents. The resource allocation solution is derived by jointly considering the real-time resource requests from agents and the historical demand estimates generated by the centralized controller. Through simulation-based evaluation, we compare our proposed scheme with conventional random and fixed resource allocation methods. The results demonstrate improved performance in terms of resource utilization, reduced unfulfilled demand, and fairness among VBS agents. The proposed combined resource allocation strategy effectively meets dynamic user requirements while maintaining system efficiency in C-RAN. Our work highlights the importance of integrating historical demand trends with real-time agent requests for improved long-term resource planning.","2169-3536","","10.1109/ACCESS.2025.3566389","“Technology Commercialization Collaboration Platform Construction” Project of the INNOPOLIS Foundation(grant numbers:1711177250); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10982217","Cloud radio access network;multi-agent system;resource allocation","Resource management;Dynamic scheduling;Computer architecture;Cloud radio access networks;Base stations;Multi-agent systems;Quality of service;Network architecture;Microprocessors;Market research","","","","15","CCBY","2 May 2025","","","IEEE","IEEE Journals"
"Quantum Deep Q-Learning with Distributed Prioritized Experience Replay","S. Y. -C. Chen","Wells Fargo, New York, NY, USA",2023 IEEE International Conference on Quantum Computing and Engineering (QCE),"30 Nov 2023","2023","02","","31","35","This paper introduces the QDQN-DPER framework to enhance the efficiency of quantum reinforcement learning (QRL) in solving sequential decision tasks. The framework incorporates prioritized experience replay, asynchronous training and novel matrix loss into the training algorithm to reduce the high sampling complexities. Numerical simulations demonstrate that QDQN-DPER outperforms the baseline distributed quantum Q-learning with the same model architecture. The proposed framework holds potential for more complex tasks while maintaining training efficiency.","","979-8-3503-4323-6","10.1109/QCE57702.2023.10180","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10313818","Quantum machine learning;Reinforcement learning;Quantum neural networks","Training;Quantum computing;Q-learning;Computational modeling;Neural networks;Computer architecture;Parallel processing","","9","","46","","30 Nov 2023","","","IEEE","IEEE Conferences"
"End-to-End Autonomous Driving in CARLA: A Survey","Y. A. Ozaibi; M. Dulva Hina; A. Ramdane-Cherif","ECE Paris School of Engineering, Paris, France; ECE Paris School of Engineering, Paris, France; LISV Laboratory, Université de Versailles Paris-Saclay, Vélizy-Villacoublay, France",IEEE Access,"17 Oct 2024","2024","12","","146866","146900","Autonomous Driving (AD) has evolved significantly since its beginnings in the 1980s, with continuous advancements driven by both industry and academia. Traditional AD systems break down the driving task into smaller modules—such as perception, localization, planning, and control– and optimizes them independently. In contrast, end-to-end models use neural networks to map sensory inputs directly to vehicle controls, optimizing the entire driving process as a single task. Recent advancements in deep learning have driven increased interest in end-to-end models, which is the central focus of this review. In this survey, we discuss how CARLA-based state-of-the-art implementations address various issues encountered in end-to-end autonomous driving through various model inputs, outputs, architectures, and training paradigms. To provide a comprehensive overview, we additionally include a concise summary of these methods in a single large table. Finally, we present evaluations and discussions of the methods, and suggest future avenues to tackle current challenges faced by end-to-end models.","2169-3536","","10.1109/ACCESS.2024.3473611","École centrale d’électronique (ECE) Paris Engineering School, Laboratoire d’Ingénierie des Systèmes de Versailles (LISV), Université de Versailles—Paris-Saclay; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10704612","Autonomous driving;autonomous vehicles;end-to-end models;deep learning;motion planning;CARLA","Autonomous vehicles;Surveys;Benchmark testing;Reviews;Reinforcement learning;Trajectory;Pipelines;Location awareness;Imitation learning;Autonomous driving;Deep learning;Motion planning","","3","","182","CCBYNCND","3 Oct 2024","","","IEEE","IEEE Journals"
"AI-Augmented DevSecOps Pipelines for Secure and Scalable Service-Oriented Architectures in Cloud-Native Systems","A. Mittal","University of the Cumberlands, USA",2025 IEEE International Conference on Service-Oriented System Engineering (SOSE),"26 Aug 2025","2025","","","79","84","Cloud-native architectures face escalating security challenges that traditional approaches cannot address at scale. This paper presents an AI-augmented DevSecOps framework integrating machine learning models into security pipelines for realtime threat detection and automated response. The framework achieves 95% attack detection rates with sub-2 second latency at 10 k events/sec. Key contributions include LSTM-based threat detection embedded in CI/CD workflows, adaptive model training with 98% accuracy retention over 6 months, and complete opensource implementation. Experimental validation across multiple attack scenarios demonstrates effectiveness while maintaining operational efficiency in hybrid Kubernetes-serverless environments.","2642-6587","979-8-3315-8911-0","10.1109/SOSE67019.2025.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11126136","cloud-native security;devsecops;machine learning;microservices;kubernetes;anomaly detection;ci/cd pipelines","Training;Adaptation models;Service-oriented systems engineering;Pipelines;Microservice architectures;Machine learning;Threat assessment;Security;Faces;Anomaly detection","","","","15","CCBY","26 Aug 2025","","","IEEE","IEEE Conferences"
"Exploring and Exploiting Conditioning of Reinforcement Learning Agents","A. Asadulaev; I. Kuznetsov; G. Stein; A. Filchenkov","Machine Learning Laboratory, ITMO University, Saint-Petersburg, Russia; Machine Learning Laboratory, ITMO University, Saint-Petersburg, Russia; Machine Learning Laboratory, ITMO University, Saint-Petersburg, Russia; Machine Learning Laboratory, ITMO University, Saint-Petersburg, Russia",IEEE Access,"3 Dec 2020","2020","8","","211951","211960","The outcome of Jacobian singular values regularization was studied for supervised learning problems. In supervised learning settings for linear and nonlinear networks, Jacobian regularization allows for faster learning. It also was shown that Jacobian conditioning regularization can help to avoid the “mode-collapse” problem in Generative Adversarial Networks. In this paper, we try to answer the following question: Can information about policy network Jacobian conditioning help to shape a more stable and general policy of reinforcement learning agents? To answer this question, we conduct a study of Jacobian conditioning behavior during policy optimization. We analyze the behavior of the agent conditioning on different policies under the different sets of hyperparameters and study a correspondence between the conditioning and the ratio of achieved rewards. Based on these observations, we propose a conditioning regularization technique. We apply it to Trust Region Policy Optimization and Proximal Policy Optimization (PPO) algorithms and compare their performance on 8 continuous control tasks. Models with the proposed regularization outperformed other models on most of the tasks. Also, we showed that the regularization improves the agent’s generalization by comparing the PPO performance on CoinRun environments. Also, we propose an algorithm that uses the condition number of the agent to form a robust policy, which we call Jacobian Policy Optimization (JPO). It directly estimates the condition number of an agent’s Jacobian and changes the policy trend. We compare it with PPO on several continuous control tasks in PyBullet environments and the proposed algorithm provides a more stable and efficient reward growth on a range of agents.","2169-3536","","10.1109/ACCESS.2020.3037276","Russian Ministry of Science and Higher Education(grant numbers:2.8866.2017/8.9); Research and Development(grant numbers:619416); Russian Science Foundation through Deep reinforced algorithms for solving the routing problem with dynamically changing topology and graph properties(grant numbers:20-19-00700); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9256259","Reinforcement learning;neural networks;policy optimization;generalization;regularization;conditioning","Jacobian matrices;Shape;Supervised learning;Reinforcement learning;Computer architecture;Approximation algorithms;Task analysis","","6","","31","CCBY","11 Nov 2020","","","IEEE","IEEE Journals"
"A Systematic State-of-the-Art Analysis of Multi-Agent Intrusion Detection","I. A. Saeed; A. Selamat; M. F. Rohani; O. Krejcar; J. A. Chaudhry","School of Computing, Faculty of Engineering, Universiti Teknologi Malaysia UTM, Skudai, Malaysia; School of Computing, Faculty of Engineering, Universiti Teknologi Malaysia UTM, Skudai, Malaysia; School of Computing, Faculty of Engineering, Universiti Teknologi Malaysia UTM, Skudai, Malaysia; Center for Basic and Applied Research, Faculty of Informatics and Management, University of Hradec Kralove, Hradec Kralove, Czech Republic; Duja Inc., Perth, WA, Australia",IEEE Access,"9 Oct 2020","2020","8","","180184","180209","Multi-agent architectures have been successful in attaining considerable attention among computer security researchers. This is so, because of their demonstrated capabilities such as autonomy, embedded intelligence, learning and self-growing knowledge-base, high scalability, fault tolerance, and automatic parallelism. These characteristics have made this technology a de facto standard for developing ambient security systems to meet the open and dynamic nature of today's online communities. Although multi-agent architectures are increasingly studied in the area of computer security, there is still not enough empirical evidence on their performance in intrusions and attacks detection. The aim of this paper is to report the systematic literature review conducted in the context of specific research questions, to investigate multi-agent IDS architectures to highlight the issues that affect their performance in terms of detection accuracy and response time. We used pertinent keywords and terms to search and retrieve the most recent research studies, on multi-agent IDS architectures, from the major research databases and digital libraries such as SCOPUS, Springer, and IEEE Explore. The search processes resulted in a number of studies; among them, there were journal articles, book chapters, conference papers, dissertations, and theses. The obtained studies were assessed and filtered out, and finally, there were over 71 studies chosen to answer the research questions. The results of this study have shown that multi-agent architectures include several advantages that can help in the development of ambient IDS. However, it has been found that there are several issues in the current multi-agent IDS architectures that may degrade the accuracy and response time of intrusions and attacks detection. Based on our findings, the issues of multi-agent IDS architectures include limitations in the techniques, mechanisms, and schemes used for multi-agent IDS adaptation and learning, load balancing, scalability, fault-tolerance, and high communication overhead. It has also been found that new measurement metrics are required for evaluating multi-agent IDS architectures.","2169-3536","","10.1109/ACCESS.2020.3027463","Universiti Teknologi Malaysia (UTM) through Research University(grant numbers:Vot-20H04); Malaysia Research University Network (MRUN)(grant numbers:Vot 4L876); Fundamental Research Grant Scheme (FRGS) through Ministry of Education Malaysia for the Completion of the Research(grant numbers:Vot 5F073); SPEV Project, University of Hradec Kralove, FIM, Czech Republic (2020); Ph.D. Student Sebastien Mambou in for Consultations Regarding Application Aspects; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9207913","Multi-agent;IDS architectures;intrusion detection;attacks;review;malware;cyberphysical system","Computer architecture;Intrusion detection;Systematics;Bibliographies;Computer networks;Computer security","","11","","107","CCBY","28 Sep 2020","","","IEEE","IEEE Journals"
"Communication-Aware Graph Neural Network for Multi-Agent Reinforcement Learning","Y. Choi; P. Di Marco; P. Park","Department of Radio and Information Communications Engineering, Chungnam National University, Daejeon, South Korea; Department of Information Engineering, Computer Science and Mathematics, University of L’Aquila, L’Aquila, Italy; Department of Radio and Information Communications Engineering, Chungnam National University, Daejeon, South Korea",IEEE Access,"3 Apr 2025","2025","13","","55832","55840","Multi-agent reinforcement learning (MARL) requires effective communication strategies to solve complex control tasks over uncertain communication channels. This paper explores a communication-aware graph neural network (GNN) approach for MARL, where the interactions between agents are modeled as a dynamic directed graph that explicitly considers time-varying lossy links. We integrate communication aspects into MARL by combining the self-attention-based coordination graph and a graph convolution with zero-input compensation to migrate the information losses over multi-hop networks. We evaluate our approach on two challenging tasks: the predator-prey and the coverage problems. We show 1) the operational benefits of communication-aware GNN with sensing range, node density, and task complexity, 2) the robust performance of the proposed scheme to support the graph convolution over various ranges of packet loss probabilities of links, and 3) the effectiveness of the residual connection of the GNN model on the overall performance and the communication architecture.","2169-3536","","10.1109/ACCESS.2025.3554736","National Research Foundation (NRF)(grant numbers:RS-2023-00241471); European Union—NextGenerationEU, Mission 4, Component 1, through Italian Ministry of University and Research (MUR) National Innovation Ecosystem(grant numbers:ECS00000041–VITALITY–CUP E13C22001060006); Italian National Recovery and Resilience Plan (NRRP) of NextGenerationEU, a partnership on “Telecommunications of the Future” [PE00000001–program “RESearch and innovation on future Telecommunications systems and networks, to make Italy more smART (RESTART)”, Structural Project 6G WIreless NETworks (6GWINET), Cascade Call SuPporting restARt spoKe 3 reSearch (SPARKS)](grant numbers:CUP D43C22003080001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10942368","Coordination;graph attention;graph neural network;lossy link;multi-agent system","Convolution;Graph neural networks;Reinforcement learning;Multi-agent systems;Message passing;Vectors;Packet loss;Nickel;Hands;Aggregates","","","","27","CCBY","26 Mar 2025","","","IEEE","IEEE Journals"
"Optimal Frequency Reuse and Power Control in Multi-UAV Wireless Networks: Hierarchical Multi-Agent Reinforcement Learning Perspective","S. Lee; S. Lim; S. H. Chae; B. C. Jung; C. Y. Park; H. Lee","School of Electronic and Electrical Engineering, Hankyong National University, Anseong, South Korea; School of Electronic and Electrical Engineering, Hankyong National University, Anseong, South Korea; Department of Electronics Engineering, Tech University of Korea, Siheung-si, South Korea; Department of Electronics Engineering, Chungnam National University, Daejeon, South Korea; Agency for Defense Development, Daejeon, South Korea; School of Electronic and Electrical Engineering, Hankyong National University, Anseong, South Korea",IEEE Access,"19 Apr 2022","2022","10","","39555","39565","To overcome the problems caused by the limited battery lifetime in multiple-unmanned aerial vehicle (UAV) wireless networks, we propose a hierarchical multi-agent reinforcement learning (RL) framework to maximize the energy efficiency (EE) of UAVs by finding the optimal frequency reuse factor and transmit power. The proposed algorithm consists of distributed inner-loop RL for transmit power control of the UAV terminal (UT) and centralized outer-loop RL for finding the optimal frequency reuse factor. Specifically, the proposed algorithm adjusts these two factors jointly to effectively mitigate intercell interference and reduce undesired transmit power consumption in multi-UAV wireless networks. We show that, for this reason, the proposed algorithm outperforms conventional algorithms, such as a random action algorithm with a fixed frequency reuse factor and a hierarchical multi-agent Q-learning algorithm with binary transmit power controls. Furthermore, even in the environment where UTs are continuously moving based on the mixed mobility model, we show that the proposed algorithm can find the best reward when compared to conventional algorithms.","2169-3536","","10.1109/ACCESS.2022.3166179","Agency for Defense Development, Republic of Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9754590","Unmanned aerial vehicle;optimal frequency reuse;transmit power control;energy efficiency;hierarchical multi-agent Q-learning;multi-UAV wireless network","Frequency conversion;Computer architecture;Time-frequency analysis;Microprocessors;Wireless networks;Q-learning;Autonomous aerial vehicles","","11","","19","CCBY","11 Apr 2022","","","IEEE","IEEE Journals"
"Energy-Aware MARL for Coordinated Data Collection in Multi-AUV Systems","A. Wibisono; H. -K. Song; B. M. Lee","Department of Intelligent Mechatronics Engineering, Sejong University, Seoul, South Korea; Department of Convergence Engineering for Intelligent Drone, Sejong University, Seoul, South Korea; Department of Intelligent Mechatronics Engineering, Sejong University, Seoul, South Korea",IEEE Access,"9 Sep 2025","2025","13","","155835","155854","As the demand for adaptive and autonomous smart ocean systems continues to grow, multi-agent control strategies based on reinforcement learning for Autonomous Underwater Vehicles (AUVs) play a vital role in supporting data collection in challenging deep-sea environments. Unlike previous surveys, this paper presents a comprehensive review of Multi-Agent Reinforcement Learning (MARL) approaches with a specific emphasis on energy efficiency and inter-AUV coordination. We examine various MARL algorithms and their applications in real-world scenarios such as buffer overflow prevention, avoidance of Flight eXceedance (FX) violations, and adaptive path planning. As a supporting illustration, we include a case study based on the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm to demonstrate how coordinated policies can be formed under energy-constrained and partially observable scenarios. Additional experiments using MAPPO and MODDPG show that MODDPG excels in energy efficiency with low overflow, while MAPPO yields moderate rewards but lacks training stability. These results provide a conceptual foundation for validating energy-efficient reward strategies based on decentralized coordination. Scope note: the case study we included is a form of limited validation to complement the survey, not a new algorithmic contribution. Therefore, the experimental findings should be read as supporting the narrative (rather than as a claim of being the state-of-the-art method in this field). We also acknowledge that the simulation used is still limited to an idealistic 2D grid environment and does not fully represent real ocean dynamics. Therefore, we plan to extend it to a 3D particle-based or Computational Fluid Dynamics (CFD) framework, along with integration of ocean environmental data from historical sources such as NOAA, JAMSTEC, and Copernicus Marine. Major challenges such as non-stationarity in agent interactions, limitations of acoustic communication, and the simulation-to-reality gap are also discussed. Future research directions include Meta-Reinforcement Learning (Meta-RL), adaptive role assignment based on energy utility, large-scale decentralized MARL architectures, and training based on realistic ocean scenarios. This review and the supporting experiments are expected to serve as a strategic foundation for the development of efficient, robust, and scalable multi-agent AUV systems for future marine missions.","2169-3536","","10.1109/ACCESS.2025.3606016","Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education(grant numbers:NRF-2020R1A6A1A03038540); Korean Government through the Ministry of Science and ICT (MSIT), South Korea(grant numbers:NRF-2023R1A2C1002656); ICT Challenge and Advanced Network of HRD Program through MSIT(grant numbers:IITP-2025-RS-2022-00156345); Institute of Information and Communications Technology Planning and Evaluation (IITP)-Information Technology Research Center (ITRC) grant funded by Korean Government (MSIT)(grant numbers:IITP-2025-RS-2024-00437494); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11151265","Autonomous underwater vehicle (AUV);multi-agent reinforcement learning (MARL);energy-efficient navigation;buffer overflow;flight eXceedance (FX);multi-agent deep deterministic policy gradient (MADDPG);computational fluid dynamics (CFD);meta-reinforcement learning (Meta-RL)","Sensors;Energy efficiency;Data collection;Oceans;Reviews;Surveys;Observability;Navigation;Batteries;Vehicle dynamics","","1","","115","CCBY","4 Sep 2025","","","IEEE","IEEE Journals"
"Knowledge- and Model-Driven Deep Reinforcement Learning for Efficient Federated Edge Learning: Single- and Multi-Agent Frameworks","Y. Li; L. Zhao; T. Wang; L. Ding; F. Yang","Department of Electronic Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL, USA; Department of Electronic Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Electronic Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Electronic Engineering, Shanghai Jiao Tong University, Shanghai, China",IEEE Transactions on Machine Learning in Communications and Networking,"24 Feb 2025","2025","3","","332","352","In this paper, we investigate federated learning (FL) efficiency improvement in practical edge computing systems, where edge workers have non-independent and identically distributed (non-IID) local data, as well as dynamic and heterogeneous computing and communication capabilities. We consider a general FL algorithm with configurable parameters, including the number of local iterations, mini-batch sizes, step sizes, aggregation weights, and quantization parameters, and provide a rigorous convergence analysis. We formulate a joint optimization problem for FL worker selection and algorithm parameter configuration to minimize the final test loss subject to time and energy constraints. The resulting problem is a complicated stochastic sequential decision-making problem with an implicit objective function and unknown transition probabilities. To address these challenges, we propose knowledge/model-driven single-agent and multi-agent deep reinforcement learning (DRL) frameworks. We transform the primal problem into a Markov decision process (MDP) for the single-agent DRL framework and a decentralized partially-observable Markov decision process (Dec-POMDP) for the multi-agent DRL framework. We develop efficient single-agent and multi-agent asynchronous advantage actor-critic (A3C) approaches to solve the MDP and Dec-POMDP, respectively. In both frameworks, we design a knowledge-based reward to facilitate effective DRL and propose a model-based stochastic policy to tackle the mixed discrete-continuous actions and large action spaces. To reduce the computational complexities of policy learning and execution, we introduce a segmented actor-critic architecture for the single-agent DRL and a distributed actor-critic architecture for the multi-agent DRL. Numerical results demonstrate the effectiveness and advantages of the proposed frameworks in enhancing FL efficiency.","2831-316X","","10.1109/TMLCN.2025.3534754","Shanghai Key Laboratory Funding(grant numbers:(STCSM 22DZ2229005)); Program for Professor of Special Appointment (Eastern Scholar) at Shanghai Institutions of Higher Learning; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10854500","Federated learning;edge computing;worker selection;algorithm parameter configuration;deep reinforcement learning;multi-agent reinforcement learning","Accuracy;Energy consumption;Quantization (signal);Delay effects;Servers;Convergence;Computational modeling;Edge computing;Stochastic processes;Markov decision processes","","2","","57","CCBY","27 Jan 2025","","","IEEE","IEEE Journals"
"Performance Evaluation of Reinforcement Learning-Based Intrusion Detection Systems","I. A. Saeed; A. Selamat; F. Rohani; O. Krejcar","Faculty of Computing & Media and Games Center of Excellence (MagicX), Universiti Teknologi Malaysia, Johor Bahru, Malaysia; Faculty of Computing & Media and Games Center of Excellence (MagicX), Universiti Teknologi Malaysia, Johor Bahru, Malaysia; Faculty of Computing & Media and Games Center of Excellence (MagicX), Universiti Teknologi Malaysia, Johor Bahru, Malaysia; University of Hradec Kralove, Rokitanskeho 62, Hradec Kralove, Czech Republic",IEEE Access,"","2025","PP","99","1","1","Reinforcement Learning (RL) offers an innovative approach to Intrusion Detection Systems (IDSs) by enabling agents to autonomously learn through dynamic interactions within network environments, without relying on pre-recorded datasets. Through RL, agents evaluate action values—rewards and penalties at each time step, aiming to converge toward optimal policies that enhance intrusion detection effectiveness. However, achieving reliable convergence in real-time environments remains uncertain, potentially impacting overall detection performance. This paper examines two prominent RL-based IDS architectures: a single-agent model and a game-theoretic multi-agent model, both employing the Deep Q-Network (DQN) algorithm, to highlight the challenges associated with convergence in real-time environments. Using OMNeT++ simulation, a semi-realistic network environment was implemented to test the performance of both architectures. Key performance metrics including accumulated Q-values, loss, epsilon decay, detection accuracy, and precision were analyzed to evaluate the two models. The findings reveal that both the single-agent and game-theoretic multi-agent architectures exhibit unstable convergence, leading to reduced detection accuracy and precision. The observed metrics highlight areas for improvement and underscore the challenges that must be addressed to achieve optimal real-time intrusion detection using reinforcement learning.","2169-3536","","10.1109/ACCESS.2025.3628626","Universiti Teknologi Malaysia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11247829","Cyber-attack;Network Security;Reinforcement Learning;RL;Deep Learning;MARL;Multi-Agent;DQN;Simulation;OMNET++","Convergence;Scalability;Accuracy;Reinforcement learning;Real-time systems;Intrusion detection;Decision making;Computer architecture;Training;Stability analysis","","","","","CCBY","13 Nov 2025","","","IEEE","IEEE Early Access Articles"
"Multi-Agent Reinforcement Learning With Cross-Layered Adaptive Wireless Video Streaming for Road Traffic Monitoring","A. M. Htut; H. Ochiai; C. Aswakul","Department of Electrical Engineering, Faculty of Engineering, Wireless Network and Future Internet Research Unit, Chulalongkorn University, Bangkok, Thailand; Department of Information and Communication Engineering, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Electrical Engineering, Faculty of Engineering, Wireless Network and Future Internet Research Unit, Chulalongkorn University, Bangkok, Thailand",IEEE Access,"8 Aug 2025","2025","13","","137155","137178","This paper presents the design and implementation of a multi-agent reinforcement learning framework for adaptive wireless image sequence streaming in road traffic monitoring systems. This work extends previous research that utilizes Apache Kafka for real-time wireless image transmission. To promote cooperation and fairness among agents, a multi-agent architecture with independent learners employing a social welfare function as a joint reward is implemented. The learning agents are trained and evaluated under various scenarios, and their performance is compared to a baseline without learning agents. Experimental results show that, after sufficient training, the proposed approach outperforms the baseline by 3.98% to 31.55% in joint reward. An emulated software-defined wireless mesh network is built with Mininet-WiFi to test the scalability and convergence time. This study highlights the potential of multi-agent reinforcement learning for improving adaptive wireless image streaming in road traffic monitoring, with significant implications for future research and real-world applications.","2169-3536","","10.1109/ACCESS.2025.3593616","Wireless Network and Future Internet Research Unit of Chulalongkorn University and Asi@Connect’s Data-Centric IoT-Cloud Service Platform for Smart Communities (IoTcloudServe@TEIN) Project; Second Century Fund (C2F), Chulalongkorn University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11098873","Apache Kafka;near real-time image sequence streaming;multi-agent reinforcement learning;road traffic monitoring system;software-defined wireless mesh network","Wireless communication;Adaptive systems;Road traffic;Monitoring;Wireless mesh networks;Routing;Real-time systems;Image sequences;Image restoration;Ad hoc networks","","","","43","CCBY","29 Jul 2025","","","IEEE","IEEE Journals"
"Leveraging the Learning Curve: Reusing Existing Architectural Patterns to Design and Implement MAS","A. Casals; A. A. F. Brandão","Escola Politécnica, USP, São Paulo, Brazil; Escola Politécnica, USP, São Paulo, Brazil",IEEE Access,"18 Mar 2025","2025","13","","45809","45825","Recent advancements in AI have led to the development of specialized systems related to multi-agent systems (MAS). However, the inherently collaborative nature of agents is often overlooked, and many of these specialized systems are used as components by other AI systems. From a software engineering perspective, this context can benefit from aligning the architectural characteristics of distributed systems with the inherently distributed nature of MAS. We propose that introducing a minimal set of agent-related concepts into the Distributed Systems (DS) domain can improve the engineering of modern MAS by leveraging techniques from DS engineering with established agent theory. In this study, we recapitulated the common origins of MAS and DS by drawing architectural parallels to establish a unified engineering approach. We then defined a minimal set of agent concepts to perform two practical studies on leveraging MAS development. First, we incorporated these concepts into a DS architectural pattern to design a distributed MAS. We then used these concepts in a graduate course to teach MAS engineering to students with no prior knowledge of agent theory. The learning outcomes from both courses included successful MAS implementation using DS tools and techniques. Although more than two-thirds of these students had no practical experience in developing distributed systems, the average final grade in both courses was above 80%, thus validating our approach. Finally, we discuss how this study supports the development of advanced systems using modern AI techniques consistently with established agent-related research while leveraging established DS techniques and concepts.","2169-3536","","10.1109/ACCESS.2025.3546526","Coordenação de Aperfeiçoamento de Pessoal de Nível Superior–Brazil (CAPES)(grant numbers:001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10906495","Architectural patterns;distributed systems;multi-agent systems;entity-component-systems","Computer architecture;Problem-solving;Knowledge engineering;Organizations;Collaboration;Semantic Web;Multi-agent systems;Systems architecture;Focusing;Distributed databases","","","","94","CCBY","27 Feb 2025","","","IEEE","IEEE Journals"
"Integrating Local Motion Planning and Robust Decentralized Fault-Tolerant Tracking Control for Search and Rescue Task of Hybrid UAVs and Biped Robots Team System","B. -S. Chen; T. -W. Hung","Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan",IEEE Access,"15 May 2023","2023","11","","45888","45909","In this study, we integrate a local motion planning and robust  $H_{\infty} $  decentralized observer-based feedforward reference tracking fault-tolerant control (FTC) of a hybrid UAVs and biped robots team system (URTS) for the purpose of search and rescue (S&R). A system architecture of performing S&R tasks for each agent in URTS is proposed to explain how to integrate reference trajectory planning and tracking control in URTS for S&R usage. In order to optimally allocate tasks to each agent in URTS, a task allocate problem is investigated. In order to optimally plan a path for each agent in URTS to reach these allocated task locations, a path planning problem is formulated. To deal with complex S&R terrain, we decompose the path planning problem into three steps, i.e., (i) global path planning, (ii) behavior decision and (iii) local motion planning. Through such decomposition, some roadmap-based path planning algorithms can be applied to the global path planning of agents in URTS. By the behavior decision, we can decide what behavior to follow the global path according to the terrain environment. Next, we focus on the local motion planning problem of flying behavior for UAV and walking behavior for robot, and then the tracking control problem for UAVs and robots in the hybrid team system. By a proposed novel feedforward linearization control scheme, the robust  $H_{\infty} $  decentralized observer-based feedforward reference tracking FTC design is significantly simplified for each agent in URTS. A novel smoothing signal model of fault signal is embedded to achieve the active FTC through observer estimation. Then, the design of the robust  $H_{\infty} $  decentralized observer-based feedforward reference tracking FTC strategy is transformed into a linear matrix inequality (LMI) -constrained optimization problem of each agent. With the help of MATLAB LMI Toolbox, the robust  $H_{\infty} $  decentralized observer-based feedforward reference tracking FTC design problem of each UAV and robot in URTS is effectively solved. Finally, the simulation results are used to demonstrate the integration of local motion planning with the S&R tasks of hybrid URTS and to verify the effectiveness of the proposed robust  $H_{\infty} $  decentralized observer-based feedforward reference tracking FTC method of hybrid URTS under the external disturbance and the actuator and sensor fault.","2169-3536","","10.1109/ACCESS.2023.3273787","Ministry of Science and Technology of Taiwan(grant numbers:MOST 108-2221-E-007-099-MY3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10120943","Biped robot;fault-tolerant control;heterogeneous multi-agent system;robust H∞ control;S&R;smoothing signal model;UAV;hybrid UAVs-UGVs team system","Task analysis;Path planning;Robots;Behavioral sciences;Tracking;Motion planning;Feedforward systems;Multi-agent systems","","6","","34","CCBY","8 May 2023","","","IEEE","IEEE Journals"
"A2PC: Augmented Advantage Pointer-Critic Model for Low Latency on Mobile IoT With Edge Computing","R. Carvalho; F. Al-Tam; N. Correia","Center for Electronic, Optoelectronic and Telecommunications (CEOT), University of Algarve, Faro, Portugal; ELM-Research, Riyadh, Saudi Arabia; Faculty of Science and Technology, Center for Electronic, Optoelectronic and Telecommunications (CEOT), University of Algarve, Faro, Portugal",IEEE Transactions on Machine Learning in Communications and Networking,"13 Dec 2024","2025","3","","1","16","As a growing trend, edge computing infrastructures are starting to be integrated with Internet of Things (IoT) systems to facilitate time-critical applications. These systems often require the processing of data with limited usefulness in time, so the edge becomes vital in the development of such reactive IoT applications with real-time requirements. Although different architectural designs will always have advantages and disadvantages, mobile gateways appear to be particularly relevant in enabling this integration with the edge, particularly in the context of wide area networks with occasional data generation. In these scenarios, mobility planning is necessary, as aspects of the technology need to be aligned with the temporal needs of an application. The nature of this planning problem makes cutting-edge deep reinforcement learning (DRL) techniques useful in solving pertinent issues, such as having to deal with multiple dimensions in the action space while aiming for optimum levels of system performance. This article presents a novel scalable DRL model that incorporates a pointer-network (Ptr-Net) and an actor-critic algorithm to handle complex action spaces. The model synchronously determines the gateway location and visit time. Ultimately, the gateways are able to attain high-quality trajectory planning with reduced latency.","2831-316X","","10.1109/TMLCN.2024.3501217","Foundation for Science and Technology (FCT) from Portugal with the Center for Electronic, Optoelectronic and Telecommunications (CEOT’s) through CEOT BASE(grant numbers:UIDB/00631/2020); CEOT PROGRAMÁTICO Project(grant numbers:UIDP/00631/2020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10755120","Action branching;Internet of Things;IoT;long-range wide-area network;LoRaWAN;mobility;pointer networks;reinforcement learning","Logic gates;LoRaWAN;Internet of Things;Planning;Machine learning;Data collection;Computer architecture;Proposals;Optimization;Trajectory planning","","","","59","CCBY","18 Nov 2024","","","IEEE","IEEE Journals"
"Graph Learning in Robotics: A Survey","F. Pistilli; G. Averta","Department of Control and Computer Engineer, Polytechnic of Turin, Turin, Italy; Department of Control and Computer Engineer, Polytechnic of Turin, Turin, Italy",IEEE Access,"19 Oct 2023","2023","11","","112664","112681","Deep neural networks for graphs have emerged as a powerful tool for learning on complex non-euclidean data, which is becoming increasingly common for a variety of different applications. Yet, although their potential has been widely recognised in the machine learning community, graph learning is largely unexplored for downstream tasks such as robotics applications. To fully unlock their potential, hence, we propose a review of graph neural architectures from a robotics perspective. The paper covers the fundamentals of graph-based models, including their architecture, training procedures, and applications. It also discusses recent advancements and challenges that arise in applied settings, related for example to the integration of perception, decision-making, and control. Finally, the paper provides an extensive review of various robotic applications that benefit from learning on graph structures, such as bodies and contacts modelling, robotic manipulation, action recognition, fleet motion planning, and many more. This survey aims to provide readers with a thorough understanding of the capabilities and limitations of graph neural architectures in robotics, and to highlight potential avenues for future research.","2169-3536","","10.1109/ACCESS.2023.3323220","Future Artificial Intelligence Research (FAIR); European Union Next-GenerationEU [PIANO NAZIONALE DI RIPRESA E RESILIENZA (PNRR)—MISSIONE 4 COMPONENTE 2, INVESTIMENTO 1.3-D.D. 1555 11/10/2022](grant numbers:PE00000013); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10274715","Graph neural networks;robotics;deep learning;human-machine interaction","Robots;Convolutional neural networks;Task analysis;Laplace equations;Solid modeling;Data models;Surveys;Graph neural networks;Deep learning;Human computer interaction","","12","","155","CCBYNCND","9 Oct 2023","","","IEEE","IEEE Journals"
"An Efficient Hardware Implementation of Reinforcement Learning: The Q-Learning Algorithm","S. Spanò; G. C. Cardarilli; L. Di Nunzio; R. Fazzolari; D. Giardino; M. Matta; A. Nannarelli; M. Re","Department of Electronic Engineering, University of Rome “Tor Vergata,”, Rome, Italy; Department of Electronic Engineering, University of Rome “Tor Vergata,”, Rome, Italy; Department of Electronic Engineering, University of Rome “Tor Vergata,”, Rome, Italy; Department of Electronic Engineering, University of Rome “Tor Vergata,”, Rome, Italy; Department of Electronic Engineering, University of Rome “Tor Vergata,”, Rome, Italy; Department of Electronic Engineering, University of Rome “Tor Vergata,”, Rome, Italy; Department of Applied Mathematics and Computer Science, Danmarks Tekniske Universitet, 2800, Denmark; Department of Electronic Engineering, University of Rome “Tor Vergata,”, Rome, Italy",IEEE Access,"31 Dec 2019","2019","7","","186340","186351","In this paper we propose an efficient hardware architecture that implements the Q-Learning algorithm, suitable for real-time applications. Its main features are low-power, high throughput and limited hardware resources. We also propose a technique based on approximated multipliers to reduce the hardware complexity of the algorithm. We implemented the design on a Xilinx Zynq Ultrascale+ MPSoC ZCU106 Evaluation Kit. The implementation results are evaluated in terms of hardware resources, throughput and power consumption. The architecture is compared to the state of the art of Q-Learning hardware accelerators presented in the literature obtaining better results in speed, power and hardware resources. Experiments using different sizes for the Q-Matrix and different wordlengths for the fixed point arithmetic are presented. With a Q-Matrix of size 8 × 4 (8 bit data) we achieved a throughput of 222 MSPS (Mega Samples Per Second) and a dynamic power consumption of 37 mW, while with a Q-Matrix of size 256 × 16 (32 bit data) we achieved a throughput of 93 MSPS and a power consumption 611 mW. Due to the small amount of hardware resources required by the accelerator, our system is suitable for multi-agent IoT applications. Moreover, the architecture can be used to implement the SARSA (State-Action-Reward-StateAction) Reinforcement Learning algorithm with minor modifications.","2169-3536","","10.1109/ACCESS.2019.2961174","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8937555","Artificial intelligence;hardware accelerator;machine learning;Q-learning;reinforcement learning;SARSA;FPGA;ASIC;IoT;multi-agent","Hardware;Random access memory;Computer architecture;Field programmable gate arrays;Throughput;Approximation algorithms;Power demand","","84","","39","CCBY","20 Dec 2019","","","IEEE","IEEE Journals"
"Designing a Classifier for Active Fire Detection From Multispectral Satellite Imagery Using Neural Architecture Search","A. Cassimon; P. Reiter; S. Mercelis; K. Mets","IDLab—Faculty of Applied Engineering, University of Antwerp—imec, Antwerpen, Belgium; IDLab—Faculty of Applied Engineering, University of Antwerp—imec, Antwerpen, Belgium; IDLab—Faculty of Applied Engineering, University of Antwerp—imec, Antwerpen, Belgium; IDLab—Faculty of Applied Engineering, University of Antwerp—imec, Antwerpen, Belgium",IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,"22 Apr 2025","2025","18","","10204","10224","Wildfires are becoming increasingly devastating, and detecting them early is essential to containing them. Deep learning-based wildfire detection systems have increased in complexity dramatically in recent years, and in order to manage this added complexity, techniques have been proposed to automate the design of neural network architectures. Such techniques are usually referred to as neural architecture search (NAS). This article showcases the use of a reinforcement learning-based neural architecture search (NAS) agent to design a small neural network to perform active fire detection on multispectral satellite imagery. Specifically, we aim to automatically design a neural network that can determine if a single multispectral pixel is a part of a fire, and do so within the constraints of a low earth orbit nanosatellite with a limited power budget, to facilitate on-board processing of sensor data. A regression model that predicts the F1 score obtained by a particular architecture following quantization is used as a reward function. This model is trained on the classification performance statistics of a sample of neural network architectures. Besides the F1 score, we also include the total number of parameters in our reward function to limit the size of the designed model. Finally, we deployed the best neural network to the Google Coral Micro Dev Board and evaluated its inference latency and power consumption. This neural network consists of 1716 parameters, takes on average 984 $\mu$s to inference, and consumes around 800 mW to perform inference. These results show that our approach can be applied to new problems.","2151-1535","","10.1109/JSTARS.2025.3556550","Fonds Wetenschappelijk Onderzoek(grant numbers:1SC8821N); Vlaamse regering; Mastering Onboard Vision Intelligence and Quality; European Union NextGenerationEU; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10946665","Active fire detection;AutoML;deep learning;multispectral imaging;neural architecture search (NAS)","Neural networks;Computer architecture;Satellite images;Reinforcement learning;Training;Benchmark testing;Neural architecture search;Wildfires;Small satellites;Predictive models","","1","","74","CCBY","1 Apr 2025","","","IEEE","IEEE Journals"
"USV Port Oil Spill Cleanup Using Hybrid Multi-Destination RL-CPP","O. Elmakis; A. Degani","Technion Autonomous Systems Program, Technion—Israel Institute of Technology, Haifa, Israel; Technion Autonomous Systems Program, Technion—Israel Institute of Technology, Haifa, Israel",IEEE Access,"7 Nov 2023","2023","11","","122722","122735","Human activities are the principal contributors to oil pollution in marine ecosystems, thereby causing severe ecological damage. The high volume of vessel traffic operating in these areas contributes to the rapid contamination of the marine ecosystem, leading to frequent oil spill events, particularly near ports where congestion is prevalent. Addressing this issue today necessitates the involvement of numerous skilled personnel committed to the task. This team undertakes the repetitive and tedious work of surveying the area, detecting spills, and employing various techniques to address each oil slick. The emergence of Unmanned Surface Vehicle (USV) technology has introduced a promising alternative capable of alleviating the process of continuous monitoring and cleaning operations in proximal shoreline areas. This paper addresses the problem of USV cleaning operations near the port. The proposed method synthesizes a hierarchical architecture that integrates traditional global path planning for multi-destination oil spills, along with coverage path planning based on reinforcement learning, to adapt to dynamically changing oil spills. This combined architecture results in a comprehensive solution, allowing navigation within the port’s vicinity to address each occurrence of oil pollution. To evaluate the effectiveness of this approach, we conducted an elaborate simulation designed to replicate port activities. The findings of this paper indicate a significant reduction in pollution levels due to USV operation and underscore the ability to acquire complex policies for dynamic coverage planning through the use of a reinforcement learning framework.","2169-3536","","10.1109/ACCESS.2023.3327559","Technion Autonomous Systems Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10295460","Autonomous agents;marine navigation;oil pollution;path planning;reinforcement learning","Path planning;Seaports;Monitoring;Reinforcement learning;Autonomous agents;Marine navigation;Offshore installations;Oil pollution;Reinforcement learning","","2","","34","CCBYNCND","25 Oct 2023","","","IEEE","IEEE Journals"
"Emotion-Related Pedagogical Agent: A Systematic Literature Review","A. I. Septiana; K. Mutijarsa; B. L. Putro; Y. Rosmansyah","School of Electrical Engineering and Informatics, Bandung Institute of Technology, Bandung, Indonesia; School of Electrical Engineering and Informatics, Bandung Institute of Technology, Bandung, Indonesia; Faculty of Mathematics and Science Education, Indonesia University of Education, Bandung, Indonesia; School of Electrical Engineering and Informatics, Bandung Institute of Technology, Bandung, Indonesia",IEEE Access,"13 Mar 2024","2024","12","","36645","36656","Pedagogical agent is a software agent that provides guidance, feedback, or intervention to learners in digital environments. It has the potential to address issues in computer-based learning, particularly online learning, which often neglects affective aspects, such as the emotions of its users. Most systematic literature reviews (SLR) on pedagogical agent have focused on their visual design, types of feedback, and other empirical elements. However, what underlies these agents’ ability to provide interventions personalized to learner’s emotions has not been examined. So, this SLR explores how pedagogical agent has addressed learner’s emotional needs. The study’s research questions include: 1) To what extent does research exist on models, frameworks, or architectures for pedagogical agent, especially those related to emotions? 2) How are pedagogical agent represented, what types of interventions do they use, and how do they affect learner’s emotions? 3) What kinds of inputs are used to activate the pedagogical agent’s functions? This SLR applied the Kitchenham method to select reference sources from 2013 to 2023 and was indexed by Scopus in the Q1 to Q4 range. Our review revealed the absence of a specific model for mapping out interventions tailored to the learner’s emotional needs. Most existing pedagogical agent provide learning interventions that are less adaptive and personalized based on the learner’s emotional state and are applied to asynchronous learning systems such as e-learning. There are still very few pedagogical agents that use real-time input technology by utilizing artificial intelligence to recognize learner’s emotion to trigger an adaptive and personalized intervention.","2169-3536","","10.1109/ACCESS.2024.3374376","School of Electrical Engineering and Informatics, Bandung Institute of Technology (ITB); and; Department of Software Engineering, Indonesia University of Education (UPI), Cibiru Regional Campus, Indonesia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10462142","Pedagogical agent;learning intervention;emotion;education;learner","Bibliographies;Chatbots;Adaptation models;Systematics;Reviews;Games;Scientific publishing;Emotion recognition;Electronic learning;Software agents","","4","","73","CCBYNCND","7 Mar 2024","","","IEEE","IEEE Journals"
"Active Inference Integrated With Imitation Learning for Autonomous Driving","S. Nozari; A. Krayani; P. Marin-Plaza; L. Marcenaro; D. M. Gómez; C. Regazzoni","Department of Engineering and Naval Architecture (DITEN), University of Genoa, Genoa, Italy; Department of Engineering and Naval Architecture (DITEN), University of Genoa, Genoa, Italy; Department of Systems Engineering and Automation, Carlos III University of Madrid, Madrid, Spain; Department of Engineering and Naval Architecture (DITEN), University of Genoa, Genoa, Italy; Department of Systems Engineering and Automation, Carlos III University of Madrid, Madrid, Spain; Department of Engineering and Naval Architecture (DITEN), University of Genoa, Genoa, Italy",IEEE Access,"13 May 2022","2022","10","","49738","49756","Classical imitation learning methods suffer substantially from the learning hierarchical policies when the imitative agent faces an unobserved state by the expert agent. To address these drawbacks, we propose an online active learning through active inference approach that encodes the expert’s demonstrations based on observation-action to improve the learner’s future motion prediction. For this purpose, we provide a switching Dynamic Bayesian Network based on the dynamic interaction between the expert agent and another object in its surrounding as a reference model, which we exploit to initialize an incremental probabilistic learning model. This learning model grows and matures based on the free-energy formulation and message passing of active inference dynamically at discrete and continuous levels in an online active learning phase. In this scheme, generalized states of the learning world are represented as distance-vector, where it is the learner’s observation concerning its interaction with a moving object. Considering the distance vector entail intentions, it enables action prediction evaluation in a prospective sense. We illustrate these points using simulations of driving intelligent agents. The learning agent is trained by using long-term predictions from the generative learning model to reproduce the expert’s motion while learning how to select a suitable action through new experiences. Our results affirm that a Dynamic Bayesian optimal approach provides a principled framework and outperforms conventional reinforcement learning methods. Furthermore, it endorses the general formulation of action prediction as active inference.","2169-3536","","10.1109/ACCESS.2022.3172712","Spanish Government(grant numbers:PID2019-104793RB-C31,RTI2018-096036-B-C21); Comunidad de Madrid(grant numbers:SEGVAUTO-4.0-CM P2018/EMT-4362); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9768830","Imitation learning;active inference;dynamic Bayesian network;autonomous driving","Dynamics;Probabilistic logic;Task analysis;Bayes methods;Vehicle dynamics;Iron;Reinforcement learning","","10","","64","CCBY","4 May 2022","","","IEEE","IEEE Journals"
"A New Efficient Method for Refining the Reinforcement Learning Algorithm to Train Deep Q Agents for Reaching a Consensus in P2P Networks","A. A. Mallouh; Z. Qawaqneh; O. Abuzaghleh; A. Al-Rababa’A","Computer Science Department, Manhattan College, Riverdale, NY, USA; Department of Computing Sciences, State University of New York Brockport, Brockport, NY, USA; Department of Computer Information Science, Higher Colleges of Technology, Dubai, United Arab Emirates; Computer Science Department, The World Islamic Science and Education University, Amman, Jordan",IEEE Access,"24 Apr 2023","2023","11","","38665","38679","The usage of distributed Peer-to-Peer (P2P) networks has been growing steadily for a reasonable period. Various applications rely on the infrastructure of P2P networks, where nodes communicate to accomplish a task without the need for a central authority. One of the significant challenges in P2P networks is the ability of the network nodes to reach a consensus on a shared item; the challenge increases as time passes. Thus, this work proposes a new effective method for tweaking the Deep Reinforcement Learning (DRL) algorithm to train Deep Q Network (DQN) learning agents to reach a consensus among the P2P nodes. We propose various hierarchies of deep agents to address this crucial challenge in P2P networks. DRL is utilized to build and train agents; more precisely, DQN learning agents are constructed and trained. Two scenarios are proposed and evaluated. In the first scenario, one DQN agent is trained to find the consensus between the network nodes. In the second scenario, three hierarchies with different numbers of layers of agents are proposed and evaluated. In both scenarios, the P2P network used is a blockchain network. The best result was obtained using the third hierarchy of the second scenario; the overall accuracy of the model is 87.8%.","2169-3536","","10.1109/ACCESS.2023.3268283","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10105270","Blockchain;consensus;deep reinforcement learning;DQN;P2P","Blockchains;Training;Q-learning;Peer-to-peer computing;Games;Behavioral sciences;Distribution networks;Deep learning;Reinforcement learning","","","","34","CCBYNCND","19 Apr 2023","","","IEEE","IEEE Journals"
"An implementation architecture for crowd network simulations","J. Zou; K. Wang; H. Sun","School of Computer and Control Engineering, Yantai University, Yantai, China; School of Computer and Control Engineering, Yantai University, Yantai, China; School of Computer and Control Engineering, Yantai University, Yantai, China",International Journal of Crowd Science,"11 Jul 2022","2020","4","2","189","207","Purpose – Crowd network systems have been deemed as a promising mode of modern service industry and future economic society, and taking crowd network as the research object and exploring its operation mechanism and laws is of great significance for realizing the effective governance of the government and the rapid development of economy, avoiding social chaos and mutation. Because crowd network is a large-scale, dynamic and diversified online deep interconnection, its most results cannot be observed in real world, and it cannot be carried out in accordance with traditional way, simulation is of great importance to put forward related research. To solve above problems, this paper aims to propose a simulation architecture based on the characteristics of crowd network and to verify the feasibility of this architecture through a simulation example. Design/methodology/approach – This paper adopts a data-driven architecture by deeply analyzing existing large-scale simulation architectures and proposes a novel reflective memory-based architecture for crowd network simulations. In this paper, the architecture is analyzed from three aspects: implementation framework, functional architecture and implementation architecture. The proposed architecture adopts a general structure to decouple related work in a harmonious way and gets support for reflection storage by connecting to different devices via reflection memory card. Several toolkits for system implementation are designed and connected by data-driven files (DDF), and these XML files constitute a persistent storage layer. To improve the credibility of simulations, VV&A (verification, validation and accreditation) is introduced into the architecture to verify the accuracy of simulation system executions. Findings – Implementation framework introduces the scenes, methods and toolkits involved in the whole simulation architecture construction process. Functional architecture adopts a general structure to decouple related work in a harmonious way. In the implementation architecture, several toolkits for system implementation are designed, which are connected by DDF, and these XML files constitute a persistent storage layer. Crowd network simulations obtain the support of reflective memory by connecting the reflective memory cards on different devices and connect the interfaces of relevant simulation software to complete the corresponding function call. Meanwhile, to improve the credibility of simulations, VV&A is introduced into the architecture to verify the accuracy of simulation system executions. Originality/value – This paper proposes a novel reflective memory-based architecture for crowd network simulations. Reflective memory is adopted as share memory within given simulation execution in this architecture; communication efficiency and capability have greatly improved by this share memory-based architecture. This paper adopts a data-driven architecture; the architecture mainly relies on XML files to drive the entire simulation process, and XML files have strong readability and do not need special software to read.","2398-7294","","10.1108/IJCS-11-2019-0034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9826689","Crowd network;Large-scale simulation;Simulation architecture","Analytical models;Memory management;Memory architecture;Sociology;XML;Computer architecture;Software","","2","","10","","11 Jul 2022","","","TUP","TUP Journals"
"OPACA: Toward an Open, Language- and Platform-Independent API for Containerized Agents","B. Acar; T. Küster; O. F. Kupke; R. K. Strehlow; M. G. Augusto; F. Sivrikaya; S. Albayrak","Chair of Agent Technology, Technische Universität Berlin, Berlin, Germany; GT-ARC gGmbH, Berlin, Germany; GT-ARC gGmbH, Berlin, Germany; GT-ARC gGmbH, Berlin, Germany; Chair of Agent Technology, Technische Universität Berlin, Berlin, Germany; GT-ARC gGmbH, Berlin, Germany; Chair of Agent Technology, Technische Universität Berlin, Berlin, Germany",IEEE Access,"22 Jan 2024","2024","12","","10012","10022","While multi-agent frameworks can provide many advanced features, they often suffer from not being able to seamlessly interact with the outside world, e.g., with web-services or other multi-agent frameworks. This may be one factor that hinders a broader application of multi-agent systems in production systems. A possible solution to this problem is the combination of multi-agent systems with the concepts of micro-services and containerization, providing language-agnostic open interfaces, as well as encapsulation and modularity. In this paper, we propose an API and reference implementation that can be employed by multi-agent systems based on different languages and frameworks. Each agent component is encapsulated in a container and is accessed through its parent runtime platform, which takes care of aspects such as authentication, input validation, monitoring and other infrastructure tasks. Multiple runtime platforms can then be connected to form systems of distributed, heterogeneous multi-agent societies.","2169-3536","","10.1109/ACCESS.2024.3353613","KI-Anwendungen (Go-KI) project (Offenes Innovationslabor KI zur Förderung gemeinwohlorientierter KI-Anwendungen); German Federal Ministry of Labour and Social Affairs (BMAS)(grant numbers:DKI.00.00032.21); German Research Foundation and the Open Access Publication Fund of TU Berlin; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10398198","Multi-agent systems;microservices;Kubernetes;Docker;API","Microservice architectures;Multi-agent systems;Task analysis;Software;Artificial intelligence;Industries;Programming","","2","","33","CCBYNCND","12 Jan 2024","","","IEEE","IEEE Journals"
"Agentic Reasoning for Social Event Extrapolation: Integrating Knowledge Graphs and Language Models","A. Narasimhan Sampath; A. Thakur; S. Krishnan","University of North Carolina at Charlotte, Charlotte, NC, USA; Saint Francis High School, Mountain View, CA, USA; University of North Carolina at Charlotte, Charlotte, NC, USA",IEEE Access,"8 Oct 2025","2025","13","","172096","172110","Accurate prediction of socio-political events is a longstanding challenge with profound implications for risk management, policy planning, and international relations. Traditional machine learning approaches, such as graph neural networks and recurrent neural networks, have achieved notable progress but often struggle to integrate rich textual context and provide interpretable reasoning. Recent advances in large language models (LLMs) have demonstrated unprecedented capabilities across diverse tasks, including text generation, code synthesis, and complex multimodal reasoning, making them promising candidates for event prediction in dynamic, data-rich environments. This research presents an agentic reasoning framework combining temporal knowledge graphs, large language models (LLMs), and a modular tool-based architecture to address event extrapolation in complex, real-world settings. The methodology integrates agent-based reasoning, iterative tool invocation, and explicit validation mechanisms to ensure logical consistency and transparency in predictions. Experiments on country-specific subsets of the POLECAT dataset employ multiple LLM architectures and multiple evaluation metrics, including Hit@k, MRR, F1-scores and Prediction Entropy. Comparative analyses demonstrate that the agentic framework achieves robust predictive performance and interpretability, complementing fine-tuned LLM baselines. Furthermore, the ethical implications of deploying AI in social computing are addressed, including bias, transparency, and accountability. This study advances event prediction by demonstrating how agentic LLMs, equipped with explicit reasoning and validation, provide scalable and ethically grounded solutions for complex social event extrapolation.","2169-3536","","10.1109/ACCESS.2025.3612015","DOD Department of the Army (DA)(grant numbers:W911NF2410189); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11173644","Agentic workflows;event extrapolation;prediction;large language models (LLMs);reasoning;temporal knowledge graphs (TKGs)","Cognition;Knowledge graphs;Forecasting;Extrapolation;Predictive models;Large language models;Time series analysis;Retrieval augmented generation;History;Computer architecture","","","","52","CCBY","19 Sep 2025","","","IEEE","IEEE Journals"
"A Novel On-Demand Charging Strategy Based on Swarm Reinforcement Learning in WRSNs","Z. Wei; M. Li; Z. Wei; L. Cheng; Z. Lyu; F. Liu","School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China",IEEE Access,"13 May 2020","2020","8","","84258","84271","The charging issue in Wireless Rechargeable Sensor Networks (WRSNs) is a popular research problem. With the help of wireless energy transfer technology, electrical energy can be transfer from Wireless Charging Equipment (WCE) to the sensor nodes, providing a new paradigm to prolong the network lifetime. Existing research usually takes the periodical and deterministic charging approach, but ignore the limited energy of the WCE and the influences of non-deterministic factors such as topological changes and node failures, making them unsuitable for real networks. In this study, we aim to minimize the number of dead sensor nodes while maximizing energy utilization of WCE under the limited energy of the WCE. Furthermore, the Swarm Reinforcement Learning (SRL) method is firstly introduced to achieve the autonomous planning ability of WCE. Moreover, to solve the problem of insufficient search in existing SRL algorithm, we improve the SRL by firefly algorithm. And a novel charging algorithm, named Swarm Reinforcement Learning based on Firefly Algorithm (SRL-FA), is proposed for the on-demand charging architecture. To evaluate the performance of the proposed algorithm, SRL-FA is compared with the existing swarm reinforcement learning algorithms and classic on-demand charging algorithms in two network scenarios. The Extensive simulation shows that the proposed algorithm can achieve promising performance in energy utilization of WCE, charging success rate and other performance metrics.","2169-3536","","10.1109/ACCESS.2020.2992127","National Key Research Development Program of China(grant numbers:2018YFC0604404); Key Research and Development Project in Anhui Province, China(grant numbers:201904a07020030); Fundamental Research Funds for the Central Universities, China(grant numbers:PA2019GDPK0079); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9085330","Wireless rechargeable sensor networks;on-demand charging algorithm;swarm reinforcement learning;firefly algorithm","Reinforcement learning;Robot sensing systems;Wireless sensor networks;Path planning;Wireless communication;Planning;Energy harvesting","","11","","32","CCBY","4 May 2020","","","IEEE","IEEE Journals"
"Buyers Collusion in Incentivized Forwarding Networks: A Multi-Agent Reinforcement Learning Study","M. Ibrahim; S. Ekin; A. Imran","Department of Engineering Technology, Texas A&M University, College Station, TX, USA; Department of Engineering Technology, Texas A&M University, College Station, TX, USA; James Watt School of Engineering, University of Glasgow, Glasgow, U.K.",IEEE Transactions on Machine Learning in Communications and Networking,"19 Feb 2024","2024","2","","240","260","We present the issue of monetarily incentivized forwarding in a multi-hop mesh network architecture from an economic perspective. It is anticipated that credit-incentivized forwarding and relaying will be a simple method of exchanging transmission power and spectrum for connectivity. However, gateways and forwarding nodes, like any other free market, may create an oligopolistic market for the users they serve. In this study, a coalition scheme between buyers aims to address price control by gateways or nodes closer to gateways. In a Stackelberg competition game, buyer agents (users) and sellers (gateways) make decisions using reinforcement learning (RL), with decentralized Deep Q-Networks to buy and sell forwarding resources. We allow communication links between the buyers with a limited messaging space, without defining a collusion mechanism. The idea is to demonstrate that through messaging, and RL tacit collusion can emerge between agents in a decentralized setup. The multi-agent reinforcement learning (MARL) system is presented and analyzed from a machine-learning perspective. Moreover, MARL dynamics are discussed via mean field analysis to better understand divergence causes and make implementation recommendations for such systems. Finally, the simulation results show the results of coordination among the users.","2831-316X","","10.1109/TMLCN.2024.3365420","U.S. Department of Energy, Office of Science, Office of Advanced Scientific Computing Research(grant numbers:DE-SC0023957); U.S. National Science Foundation(grant numbers:2323300,1923669); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10433203","Multi-agent;reinforcement learning;IoT;incentivized forwarding","Games;Logic gates;Distributed ledger;Behavioral sciences;Costs;Spread spectrum communication;Markov processes","","3","","85","CCBY","12 Feb 2024","","","IEEE","IEEE Journals"
"Explaining Intelligent Agent’s Future Motion on Basis of Vocabulary Learning With Human Goal Inference","Y. Fukuchi; M. Osawa; H. Yamakawa; M. Imai","National Institute of Informatics, Tokyo, Japan; College of Humanities and Sciences, Nihon University, Tokyo, Japan; Whole Brain Architecture Initiative, Tokyo, Japan; Faculty of Science and Technology, Keio University, Kanagawa, Japan",IEEE Access,"26 May 2022","2022","10","","54336","54347","Intelligent agents (IAs) that use machine learning for decision-making often lack the explainability about what they are going to do, which makes human-IA collaboration challenging. However, previous methods of explaining IA behavior require IA developers to predefine vocabulary that expresses motion, which is problematic as IA decision-making becomes complex. This paper proposes Manifestor, a method for explaining an IA’s future motion with autonomous vocabulary learning. With Manifestor, an IA can learn vocabulary from a person’s instructions about how the IA should act. A notable contribution of this paper is that we formalized the communication gap between a person and IA in the vocabulary-learning phase, that is, the IA’s goal may be different from what the person wants the IA to achieve, and the IA needs to infer the latter to judge whether a motion matches that person’s instruction. We evaluated Manifestor by investigating whether people can accurately predict an IA’s future motion with explanations generated with Manifestor. We compared Manifestor’s vocabulary with that from optimal acquired in a situation in which the communication-gap problem did not exist and that from ablation, which was learned with a false assumption that an IA and person shared a goal. The experimental results revealed that vocabulary learned with Manifestor improved people’s prediction accuracy as much as with optimal, while ablation failed, suggesting that Manifestor can enable an IA to properly learn vocabulary from people’s instructions even if a communication gap exists.","2169-3536","","10.1109/ACCESS.2022.3176104","Core Research for Evolutionary Science and Technology, Japan Science and Technology Agency (JST CREST), Japan(grant numbers:JPMJCR19A1); Research Grant of Keio Leading-edge Laboratory of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9777698","Explainable AI;human–agent interaction;intelligent agent;deep reinforcement learning","Human factors;Decision making;Behavioral sciences;Machine learning;Intelligent agents;Reinforcement learning;Vocabulary","","2","","47","CCBY","18 May 2022","","","IEEE","IEEE Journals"
"dropCyclic: Snapshot Ensemble Convolutional Neural Network Based on a New Learning Rate Schedule for Land Use Classification","S. Noppitak; O. Surinta","Department of Information Technology, Faculty of Informatics, Multi-Agent Intelligent Simulation Laboratory (MISL), Mahasarakham University, Mahasarakham, Thailand; Department of Information Technology, Faculty of Informatics, Multi-Agent Intelligent Simulation Laboratory (MISL), Mahasarakham University, Mahasarakham, Thailand",IEEE Access,"13 Jun 2022","2022","10","","60725","60737","The ensemble learning method is a necessary process that provides robustness and is more accurate than the single model. The snapshot ensemble convolutional neural network (CNN) has been successful and widely used in many domains, such as image classification, fault diagnosis, and plant image classification. The advantage of the snapshot ensemble CNN is that it combines the cyclic learning rate schedule in the algorithm to snap the best model in each cycle. In this research, we proposed the dropCyclic learning rate schedule, which is a step decay to decrease the learning rate value in every learning epoch. The dropCyclic can reduce the learning rate and find the new local minimum in the subsequent cycle. We evaluated the snapshot ensemble CNN method based on three learning rate schedules: cyclic cosine annealing, max-min cyclic cosine learning rate scheduler, and dropCyclic then using three backbone CNN architectures: MobileNetV2, VGG16, and VGG19. The snapshot ensemble CNN methods were tested on three aerial image datasets: UCM, AID, and EcoCropsAID. The proposed dropCyclic learning rate schedule outperformed the other learning rate schedules on the UCM dataset and obtained high accuracy on the AID and EcoCropsAID datasets. We also compared the proposed dropCyclic learning rate schedule with other existing methods. The results show that the dropCyclic method achieved higher classification accuracy compared with other existing methods.","2169-3536","","10.1109/ACCESS.2022.3180844","Mahasarakham University(grant numbers:6508011/2565); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9791446","Snapshot ensemble convolutional neural network;ensemble learning;convolutional neural network;learning rate schedule;land use classification;aerial image","Convolutional neural networks;Training;Schedules;Learning systems;Machine learning;Bagging;Satellites","","10","","43","CCBY","8 Jun 2022","","","IEEE","IEEE Journals"
"A Generalist Reinforcement Learning Agent for Compressing Convolutional Neural Networks","G. Gonzalez-Sahagun; S. E. Conant-Pablos; J. C. Ortiz-Bayliss; J. M. Cruz-Duarte","School of Engineering and Sciences, Tecnológico de Monterrey, Monterrey, Nuevo Leon, Mexico; School of Engineering and Sciences, Tecnológico de Monterrey, Monterrey, Nuevo Leon, Mexico; School of Engineering and Sciences, Tecnológico de Monterrey, Monterrey, Nuevo Leon, Mexico; School of Engineering and Sciences, Tecnológico de Monterrey, Monterrey, Nuevo Leon, Mexico",IEEE Access,"15 Apr 2024","2024","12","","51100","51114","Over the years, researchers have proposed multiple approaches to reduce the number of parameters Deep Learning models have. Due to the complexity of compressing models, some authors have opted to train Reinforcement Learning agents that learn how to compress a particular model without losing considerable accuracy. Nonetheless, training an agent for each model can be time-consuming. We propose a methodology for training a generalist agent capable of compressing other convolutional neural networks that it was not trained to compress. Our generalist agent uses feature maps to select which compression technique to apply to convolutional and dense layers. Since the shape of the feature maps is reduced as it goes deeper into the network, we implemented a Dueling Deep Q-Network with a Region of Interest layer, allowing it to generate features of a fixed size for feature maps of various heights and widths. Our generalist agent trained to compress two LeNet models, one trained with fashion MNIST and the other with Kuzushiji-MNIST, compressed the same architecture trained on MNIST to less than 15% of its original size with an accuracy loss of less than 2.5%.","2169-3536","","10.1109/ACCESS.2024.3385857","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494337","Computer vision;deep learning;model compression;model optimization;reinforcement learning","Computational modeling;Image coding;Training;Reinforcement learning;Kernel;Stochastic processes;Shape","","1","","45","CCBY","8 Apr 2024","","","IEEE","IEEE Journals"
"Driven by Data or Derived Through Physics? A Review of Hybrid Physics Guided Machine Learning Techniques With Cyber-Physical System (CPS) Focus","R. Rai; C. K. Sahu","Department of Mechanical and Aerospace Engineering, Manufacturing and Design Lab (MADLab), University at Buffalo, Buffalo, USA; Department of Mechanical and Aerospace Engineering, Manufacturing and Design Lab (MADLab), University at Buffalo, Buffalo, USA",IEEE Access,"23 Apr 2020","2020","8","","71050","71073","A multitude of cyber-physical system (CPS) applications, including design, control, diagnosis, prognostics, and a host of other problems, are predicated on the assumption of model availability. There are mainly two approaches to modeling: Physics/Equation based modeling (Model-Based, MB) and Machine Learning (ML). Recently, there is a growing consensus that ML methodologies relying on data need to be coupled with prior scientific knowledge (or physics, MB) for modeling CPS. We refer to the paradigm that combines MB approaches with ML as hybrid learning methods. Hybrid modeling (HB) methods is a growing field within both the ML and scientific communities, and are recognized as an important emerging but nascent area of research. Recently, several works have attempted to merge MB and ML models for the complete exploitation of their combined potential. However, the research literature is scattered and unorganized. So, we make a meticulous and systematic attempt at organizing and standardizing the methods of combining ML and MB models. In addition to that, we outline five metrics for the comprehensive evaluation of hybrid models. Finally, we conclude by shedding some light on the challenges of hybrid models, which we, as a research community, should focus on for harnessing the full potential of hybrid models. An additional feature of this survey is that the hybrid modeling work has been discussed with a focus on modeling cyber-physical systems.","2169-3536","","10.1109/ACCESS.2020.2987324","Defense Advanced Research Projects Agency (DARPA)(grant numbers:HR0011-18-9-0037); Naval Surface Warfare Center (NSWC) NEEC(grant numbers:N00174-19-0025); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9064519","Cyber-physical systems;deep learning;deep neural networks;hybrid models;model-based;machine learning;physics guided;physics informed;physics prior;theory guided","Mathematical model;Physics;Computational modeling;Machine learning;Data models;Cyber-physical systems;Sensors","","212","","272","CCBY","13 Apr 2020","","","IEEE","IEEE Journals"
"Optimization of Multi-Agent Scheduling Based on MA-ID3QN for the Riveting and Welding Work Cell","J. Zheng; Y. Zhang; Y. Gao; Z. Chen; Y. Gao; C. Zhou; X. Zhou","School of Information Engineering, Wuhan University of Technology, Wuhan, Hubei, China; School of Information Engineering, Wuhan University of Technology, Wuhan, Hubei, China; School of Information Engineering, Wuhan University of Technology, Wuhan, Hubei, China; School of Information Engineering, Wuhan University of Technology, Wuhan, Hubei, China; School of Information Engineering, Wuhan University of Technology, Wuhan, Hubei, China; School of Information Engineering, Wuhan University of Technology, Wuhan, Hubei, China; School of Information Engineering, Wuhan University of Technology, Wuhan, Hubei, China",IEEE Access,"5 Sep 2025","2025","13","","153171","153188","In industrial manufacturing, multi-agent scheduling is one of the key technologies for improving production efficiency. Due to the complexity of multi-agent systems and the interference between tasks, achieving efficient task scheduling is faced with significant challenges. To solve this problem, this paper introduces the dueling double deep Q-network (D3QN) into the multi-robot scheduling scenario of a riveting and welding work cell for the first time. Considering the characteristics of this scenario, an improved D3QN is proposed, which is designed as a multi-agent independent dueling double deep Q-network algorithm (MA-ID3QN) based on a multi-agent cooperation mechanism. In this approach, robots in the work cell are treated as independent agents, with decentralized training and decentralized execution to accommodate varying robot numbers. Meanwhile, several mechanisms are employed to enhance the algorithm’s performance. Furthermore, a digital twin-based riveting and welding work cell platform is constructed for validation. First, the MA-ID3QN algorithm generates a scheduling strategy based on the state of the physical space of the riveting and welding work cell. Then, the scheduling strategy is verified on the digital twin platform. Finally, comparative experiments are conducted to validate the effectiveness of the proposed method. The experimental results demonstrate that the MA-ID3QN-based agent scheduling method exhibits better reliability, higher efficiency, and stronger generalization capability in multi-agent task scheduling. This approach improves the efficiency of the riveting and welding work cell and reduces the time required for welding tasks in mass production scenarios. Moreover, it has promising application prospects in industrial robot scheduling.","2169-3536","","10.1109/ACCESS.2025.3604143","National Key Research and Development Program of China “The Study on Load-Bearing and Moving Support Exoskeleton Robot Key Technology and Typical Application”(grant numbers:2017YFB1300502); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11145045","Multi-agent scheduling;MA-ID3QN;digital twin;riveting and welding work cell","Job shop scheduling;Welding;Dynamic scheduling;Computer architecture;Robots;Reinforcement learning;Scheduling;Microprocessors;Scalability;Heuristic algorithms","","","","39","CCBYNCND","29 Aug 2025","","","IEEE","IEEE Journals"
"An Improved Acceleration Method Based on Multi-Agent System for AGVs Conflict-Free Path Planning in Automated Terminals","K. Guo; J. Zhu; L. Shen","Institute of Logistics Science and Engineering, Shanghai Maritime University, Shanghai, China; Institute of Logistics Science and Engineering, Shanghai Maritime University, Shanghai, China; Institute of Logistics Science and Engineering, Shanghai Maritime University, Shanghai, China",IEEE Access,"6 Jan 2021","2021","9","","3326","3338","Aiming at the problem that the increasing number of automated guided vehicles (AGVs) will lead to more frequent conflicts between AGVs. In this paper, a conflict-free path planning model for multi-AGV is established, aiming to minimize the blocking rate of AGVs between the quay crane and the yard crane, considering the travel speed, operation time, and conflict distance of AGVs. An architecture of AGV's system based on Multi-Agent System (MAS) is designed, the improved interactive protocol based on blackboard model is used as the communication method of AGV, the improved acceleration control method is combined with the AGV priority determination method based on time cost as the negotiation strategy of AGV, the improved Dijkstra algorithm calculates the conflict-free path of each AGV. By comparing the acceleration control method based on MAS with the speed control method based on MAS and the task priority control method, the effectiveness of this method for solving multiple AGVs conflict-free path planning in automated terminals is verified.","2169-3536","","10.1109/ACCESS.2020.3047916","Shanghai Pujiang Program(grant numbers:16PJC043); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9311130","Automated terminals;multi-AGV;multi-agent system (MAS);improved acceleration control method;conflict-free","Path planning;Cranes;Task analysis;Acceleration;Multi-agent systems;Job shop scheduling;Containers","","29","","31","CCBY","30 Dec 2020","","","IEEE","IEEE Journals"
"Leveraging Transfer Learning in Deep Reinforcement Learning for Solving Combinatorial Optimization Problems Under Uncertainty","F. Ezzahra Achamrah","Sheffield University Management School, The University of Sheffield, Sheffield, U.K.",IEEE Access,"9 Dec 2024","2024","12","","181477","181497","In recent years, addressing the inherent uncertainties within Combinatorial Optimization Problems (COPs) reveals the limitations of traditional optimization methods. Although these methods are often effective in deterministic settings, they may lack flexibility and adaptability to navigate the uncertain nature of real-world COP/s. Deep Reinforcement Learning (DRL) has emerged as a promising approach for dynamic decision-making within these complex environments. Yet, the application of DRL in solving COP/s highlights key limitations for the generalization process across various problem instances without extensive retraining and customization for each new variant, leading to notable computational costs and inefficiencies. To address these challenges, this paper introduces a novel framework that combines the adaptability and learning capabilities of DRL with the efficiency of Transfer Learning (TL) and Neural Architecture Search. This framework enables the leveraging of knowledge gained from solving COP/s to enhance the solving of different but related COP/s, thereby eliminating the necessity for retraining models from scratch for each new problem variant to be solved. The framework was evaluated on over 1,500 benchmark instances across 10 stochastic and deterministic variants of the vehicle routing problem. Across extensive experiments, the approach consistently improves solution quality and computational efficiency. On average, it achieves at least a 5% improvement in solution quality and a 20% reduction in CPU time compared to state-of-the-art methods, with some variants showing even more substantial gains. For large-scale instances over 200 customers, the TL process requires only 10-15% of the time needed to train models from scratch, while maintaining solution quality, laying the groundwork for future research in this area.","2169-3536","","10.1109/ACCESS.2024.3505678","Grantham Centre for Sustainable Futures(grant numbers:X/008802-16-60); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10766597","Combinatorial optimization problems;uncertainty;deep reinforcement learning;transfer learning;vehicle routing problem","Optimization;Deep reinforcement learning;Uncertainty;Transfer learning;Heuristic algorithms;Adaptation models;Stochastic processes;Computational modeling;Vehicle dynamics;Routing","","2","","74","CCBY","25 Nov 2024","","","IEEE","IEEE Journals"
"Multi-Agent Reinforcement Learning Based Cooperative Content Caching for Mobile Edge Networks","W. Jiang; G. Feng; S. Qin; Y. Liu","National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, China; National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, China; National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, China; National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, China",IEEE Access,"22 May 2019","2019","7","","61856","61867","To address the drastic growth of data traffic dominated by streaming of video-on-demand files, mobile edge caching/computing (MEC) can be exploited to develop intelligent content caching at mobile network edges to alleviate redundant traffic and improve content delivery efficiency. Under the MEC architecture, content providers (CPs) can deploy popular video files at MEC servers to improve users’ quality of experience (QoE). Designing an efficient content caching policy is crucial for CPs due to the content dynamics, unknown spatial-temporal traffic demands, and limited service capacity. The knowledge of users’ preference is very useful and important for efficient content caching, yet often unavailable in advance. Under this circumstance, machine learning can be used to learn the users’ preference based on historical demand information and decide the video files to be cached at the MEC servers. In this paper, we propose a multi-agent reinforcement learning (MARL)-based cooperative content caching policy for the MEC architecture when the users’ preference is unknown and only the historical content demands can be observed. We formulate the cooperative content caching problem as a multi-agent multi-armed bandit problem and propose a MARL-based algorithm to solve the problem. The simulation experiments are conducted based on a real dataset from MovieLens and the numerical results show that the proposed MARL-based cooperative content caching scheme can significantly reduce content downloading latency and improve content cache hit rate when compared with other popular caching schemes.","2169-3536","","10.1109/ACCESS.2019.2916314","National Natural Science Foundation of China(grant numbers:61631004,61871099); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8713465","Caching;cooperative;mobile edge caching;multi-agent reinforcement learning","Servers;Quality of experience;Reinforcement learning;Streaming media;Cooperative caching;Computational modeling;Numerical models","","74","","34","OAPA","13 May 2019","","","IEEE","IEEE Journals"
"TC-Driver: A Trajectory Conditioned Reinforcement Learning Approach to Zero-Shot Autonomous Racing","E. Ghignone; N. Baumann; M. Magno","ETH Zurich, Switzerland; ETH Zurich, Switzerland; ETH Zurich, Switzerland",Field Robotics,"25 Feb 2025","2023","3","","637","651","Autonomous racing is becoming popular for academic and industry researchers as a test for general autonomous driving by pushing perception, planning, and control algorithms to their limits. While traditional control methods such as model predictive control are capable of generating an optimal control sequence at the edge of the vehicles' physical controllability, these methods are sensitive to the accuracy of the modeling parameters, such as tire modeling coefficients. As model mismatch is inevitable in reality, the heuristic nature of Reinforcement Learning (RL) offers a viable approach to modeling robustness. This paper presents TC-Driver, an RL approach for robust control in autonomous racing. In particular, the TC-Driver agent is conditioned by a trajectory generated by any arbitrary traditional high-level trajectory planner. The proposed TC-Driver architecture addresses the tire parameter modeling inaccuracies by exploiting the learning capabilities of RL while utilizing the reliability of traditional planning methods in a hybrid fashion. We train the agent under varying tire conditions, allowing it to generalize to different model parameters, aiming to increase the racing capabilities of the system in practice. Experimental results demonstrate that the proposed hybrid RL architecture of the TC-Driver improves the generalization robustness of autonomous racing agents when compared to a previous state-of-the-art end-to-end-based architecture. Namely, the proposed controller yields a 29-fold improvement in crash ratio when facing model mismatch and can zero-shot transfer its behavior on unseen tracks which present completely new features, while the end-to-end baseline fails. When deployed on a physical system, the proposed architecture demonstrates zero-shot Sim2Real capabilities that outperform end-to-end agents 10-fold in terms of crash ratio while exhibiting similar driving characteristics in reality as in simulation.","2771-3989","","10.55417/fr.2023020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10876052","autonomous racing;reinforcement learning;control;wheeled robots;embedded control","Trajectory;Tires;Training;Computer architecture;Accidents;Reinforcement learning;Standards;Planning;Hardware;Computational modeling","","3","","","CCBY","25 Feb 2025","","","FRPS","FRPS Journals"
"Deployment of Unmanned Aerial Vehicles in Next-Generation Wireless Communication Network Using Multi-Agent Reinforcement Learning","R. Sharma; S. Raj Chopra; A. Gupta; R. Kaur; S. Tanwar; G. Pau; G. Sharma; F. Alqahtani; A. Tolba","School of Electronics and Electrical Engineering, Lovely Professional University, Phagwara, Punjab, India; School of Electronics and Electrical Engineering, Lovely Professional University, Phagwara, Punjab, India; School of Electronics and Electrical Engineering, Lovely Professional University, Phagwara, Punjab, India; Department of Electronics Technology, Guru Nanak Dev University, Amritsar, Punjab, India; Department of Computer Science and Engineering, Institute of Technology, Nirma University, Ahmedabad, Gujarat, India; Faculty of Engineering and Architecture, Kore University of Enna, Enna, Italy; Department of Electrical Engineering Technology, University of Johannesburg, Johannesburg 2006, South Africa; Department of Software Engineering, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia; Department of Computer Science, Community College, King Saud University, Riyadh, Saudi Arabia",IEEE Access,"21 May 2024","2024","12","","69517","69538","To address the challenges posed by a large number of disaster-waiver-affected users and the complexities of scaling centralized algorithms for rapidly restoring emergency communication services, the paper proposes a distributed intent-based optimization architecture based on multi-agent reinforcement learning. This approach aims to mitigate service discrepancies and dynamics among users. In the network feature layer, a distributed K-sums clustering algorithm considers variations in user services. Each UAV base station autonomously and minimally adjusts the local network structure based on user requirements. It selects user features from the cluster center as input states for the multi-agent reinforcement learning neural network. In the trajectory regulation layer, the paper introduces a multi-agent maximum entropy reinforcement learning (MASAC) algorithm. The UAV base station, acting as an intelligent node, governs its flight trajectory within the framework of “distributed training – distributed execution.” The paper incorporates techniques such as integrated learning and curriculum learning to enhance training stability and convergence speed. Simulation results demonstrate the effectiveness of our distributed K-sums clustering algorithm in terms of load efficiency and cluster balance, outperforming the traditional K-means algorithm. Additionally, the UAV base station trajectory control algorithm based on MASAC significantly reduces communication interruptions, enhances network spectral efficiency, and surpasses existing reinforcement learning methods.","2169-3536","","10.1109/ACCESS.2024.3401016","Researchers Supporting Project through King Saud University, Riyadh, Saudi Arabia(grant numbers:RSPD2024R681); Università degli Studi di Enna Kore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10530332","Unmanned aerial vehicles;disaster;integrated learning;spectral efficiency","Autonomous aerial vehicles;Base stations;Optimization;Trajectory;Clustering algorithms;Disasters;Heuristic algorithms;Disaster management;Spectral analysis","","2","","27","CCBYNCND","14 May 2024","","","IEEE","IEEE Journals"
"Multi-Agent Reinforcement Learning With Action Masking for UAV-Enabled Mobile Communications","D. Rizvi; D. Boyle","Dyson School of Design Engineering, Imperial College London, London, U.K.; Dyson School of Design Engineering, Imperial College London, London, U.K.",IEEE Transactions on Machine Learning in Communications and Networking,"30 Dec 2024","2025","3","","117","132","Unmanned Aerial Vehicles (UAVs) are increasingly used as aerial base stations to provide ad hoc communications infrastructure. Building upon prior research efforts which consider either static nodes, 2D trajectories or single UAV systems, this paper focuses on the use of multiple UAVs for providing wireless communication to mobile users in the absence of terrestrial communications infrastructure. In particular, we jointly optimize UAV 3D trajectory and NOMA power allocation to maximize system throughput. Firstly, a weighted K-means-based clustering algorithm establishes UAV-user associations at regular intervals. Then the efficacy of training a novel Shared Deep Q-Network (SDQN) with action masking is explored. Unlike training each UAV separately using DQN, the SDQN reduces training time by using the experiences of multiple UAVs instead of a single agent. We also show that SDQN can be used to train a multi-agent system with differing action spaces. Simulation results confirm that: 1) training a shared DQN outperforms a conventional DQN in terms of maximum system throughput (+20%) and training time (-10%); 2) it can converge for agents with different action spaces, yielding a 9% increase in throughput compared to Mutual DQN algorithm; and 3) combining NOMA with an SDQN architecture enables the network to achieve a better sum rate compared with existing baseline schemes.","2831-316X","","10.1109/TMLCN.2024.3521876","Commonwealth Scholarship Commission, U.K.; Communications Hub for Empowering Distributed ClouD Computing Applications and Research; Engineering and Physical Sciences Research Council(grant numbers:EP/Y037421/1,EP/X040518/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10812765","Aerial networks;non-orthogonal multiple access;multi-agent reinforcement learning;invalid action masking","Autonomous aerial vehicles;NOMA;Trajectory;Throughput;Three-dimensional displays;Resource management;Ad hoc networks;Training;Clustering algorithms;Base stations","","4","","58","CCBY","23 Dec 2024","","","IEEE","IEEE Journals"
"Knowledge Transfer in Deep Reinforcement Learning via an RL-Specific GAN-Based Correspondence Function","M. Ruman; T. V. Guy","Department of Adaptive Systems, Institute of Information Theory and Automation, Czech Academy of Sciences, Prague, Czech Republic; Department of Adaptive Systems, Institute of Information Theory and Automation, Czech Academy of Sciences, Prague, Czech Republic",IEEE Access,"3 Dec 2024","2024","12","","177204","177218","Deep reinforcement learning has demonstrated superhuman performance in complex decision-making tasks, but it struggles with generalization and knowledge reuse—key aspects of true intelligence. This article introduces a novel approach that modifies Cycle Generative Adversarial Networks specifically for reinforcement learning, enabling effective one-to-one knowledge transfer between two tasks. Our method enhances the loss function with two new components: model loss, which captures dynamic relationships between source and target tasks, and Q-loss, which identifies states significantly influencing the target decision policy. Tested on the 2-D Atari game Pong, our method achieved 100% knowledge transfer in identical tasks and either 100% knowledge transfer or a 30% reduction in training time for a rotated task, depending on the network architecture. In contrast, using standard Generative Adversarial Networks or Cycle Generative Adversarial Networks led to worse performance than training from scratch in the majority of cases. The results demonstrate that the proposed method ensured enhanced knowledge generalization in deep reinforcement learning.","2169-3536","","10.1109/ACCESS.2024.3497589","Joint Ústav teorie informace a automatizace (UTIA)-Provozně ekonomická fakulta (PEFT) Laboratory TALISMAN; European Cooperation in Science and Technology through COST Action(grant numbers:CA21169); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10752398","Deep learning;Markov decision process;reinforcement learning;transfer learning;knowledge transfer","Training;Decision making;Games;Network architecture;Generative adversarial networks;Deep reinforcement learning;Knowledge transfer;Standards","","","","43","CCBYNCND","13 Nov 2024","","","IEEE","IEEE Journals"
"DDoS Traffic Control Using Transfer Learning DQN With Structure Information","S. -M. Xia; L. Zhang; W. Bai; X. -Y. Zhou; Z. -S. Pan","College of Command and Information System, PLA Army Engineering University, Nanjing, China; College of Command and Information System, PLA Army Engineering University, Nanjing, China; College of Command and Information System, PLA Army Engineering University, Nanjing, China; College of Command and Information System, PLA Army Engineering University, Nanjing, China; College of Command and Information System, PLA Army Engineering University, Nanjing, China",IEEE Access,"1 Jul 2019","2019","7","","81481","81493","A DDoS attack is one of the most serious threats to the current Internet. The Router throttling is a popular method to response against DDoS attacks. Currently, coordinated team learning (CTL) has adopted tile coding for continuous state representation and strategy learning. It is suitable for this distributed challenge but lacks robustness. Our first contribution is that we adapt deep network as function approximation for continuous state representation, as a deep reinforcement learning approach is robust in many different Atari games with a little modification of the learning architecture. Furthermore, current multiagent router throttling methods only consider traffic-reading information. Therefore, for a homogeneous team scenario, all agents can share parameters with the same deep network. However, for heterogeneous team scenarios, if all agents still share one deep network, the learning policy may not be sufficiently ideal. Our second contribution is that we add team structure information so that all agents can still share one deep network. However, deep reinforcement learning is a considerably time-consuming task. Transfer learning is an appropriate method because learning policy in a simple scenario allows us to transfer the policy to other different and even complex scenarios. For transfer learning regarding the DDoS control problem, we propose a progressive transfer learning approach, which is our third contribution. Therefore, we can learn a better policy with less time consumption. Moreover, with progressive transfer learning, we can promote our method in a more complex environment. The experimental results validate that our three contributions truly achieve better performance than the existing methods.","2169-3536","","10.1109/ACCESS.2019.2923993","National Key Research Development Program of China(grant numbers:2017YFB0802800); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8742593","Distributed denial of service;router throttling;deep network;team structure information;multiagent reinforcement learning;progressive transfer learning","Computer crime;Servers;Reinforcement learning;Task analysis;Games;Encoding;Aggregates","","5","","50","CCBY","20 Jun 2019","","","IEEE","IEEE Journals"
"DNN Task Assignment in UAV Networks: A Generative AI Enhanced Multiagent Reinforcement Learning Approach","X. Tang; Q. Chen; W. Weng; B. Liao; J. Wang; X. Cao; X. Li","Guangxi University Key Laboratory of Intelligent Networking and Scenario System (School of Information and Communication), Guilin University of Electronic Technology, Guilin, China; School of Architecture and Transportation Engineering, Guilin University of Electronic Technology, Guilin, China; Guangxi University Key Laboratory of Intelligent Networking and Scenario System (School of Information and Communication), Guilin University of Electronic Technology, Guilin, China; Guangxi University Key Laboratory of Intelligent Networking and Scenario System (School of Information and Communication), Guilin University of Electronic Technology, Guilin, China; College of Computing and Data Science, Nanyang Technological University, Jurong West, Singapore; School of Electronic and Information Engineering and the Key Laboratory of Advanced Technology of Near Space Information System, Ministry of Industry and Information Technology of China, Beihang University, Beijing, China; Guangxi University Key Laboratory of Intelligent Networking and Scenario System (School of Information and Communication), Guilin University of Electronic Technology, Guilin, China",IEEE Internet of Things Journal,"8 May 2025","2025","12","10","13340","13352","uncrewed aerial vehicles (UAVs) offer high mobility and flexible deployment capabilities, making them ideal for Internet of Things (IoT) applications. However, the substantial amount of data generated by various applications within the existing low-altitude network requires processing through deep neural networks (DNN) on UAVs, which is challenging due to their limited computational resources. To address this issue, we propose a two-stage optimization method for flight path planning and task allocation based on a mother-child UAV swarm system. In the first stage, we employ a greedy algorithm to solve the path planning problem by considering the task size of the target area to be inspected and the shortest flight path as constraints. The goal is to minimize both the flight path of the UAV and the overall cost of the system. In the second stage, we introduce a novel DNN task assignment algorithm that combines multiagent deep deterministic policy gradient (MADDPG) and generative diffusion models (GDMs), named GDM-MADDPG. This algorithm takes advantage of the reverse denoising process of GDM to replace the actor network in MADDPG. It enables UAVs to generate specific DNN task assignment actions based on agents’ observations in a dynamic environment, thereby improving the efficiency of task assignment and overall system performance. The simulation results demonstrate that our algorithm outperforms the benchmarks in terms of path planning, Age of Information (AoI), task completion rate, and system utility, demonstrating its effectiveness.","2327-4662","","10.1109/JIOT.2025.3541715","National Natural Science Foundation of China(grant numbers:U22A2054); Guangxi Natural Science Foundation of China(grant numbers:2025GXNSFAA069687); Graduate Study Abroad Program of Guilin University of Electronic Technology(grant numbers:GDYX2024001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10884737","Deep neural network;generative artificial intelligence (AI);mobile edge computing;multiagent reinforcement learning (MARL);path planning;task assignment;uncrewed aerial vehicle (UAV) network","Autonomous aerial vehicles;Collaboration;Artificial neural networks;Internet of Things;Computational modeling;Servers;Heuristic algorithms;Cloud computing;Real-time systems;Energy consumption","","5","","51","CCBY","13 Feb 2025","","","IEEE","IEEE Journals"
"Risk-Aware Reinforcement Learning Framework for User-Centric O-RAN","S. Khan Kasi; F. Ahmed Khan; S. Ekin; A. Imran","AI4Networks Research Center, School of Electrical and Computer Engineering, The University of Oklahoma, Norman, OK, USA; AI4Networks Research Center, School of Electrical and Computer Engineering, The University of Oklahoma, Norman, OK, USA; School of Electrical and Computer Engineering, Texas A&M University, College Station, TX, USA; AI4Networks Research Center, School of Electrical and Computer Engineering, The University of Oklahoma, Norman, OK, USA",IEEE Transactions on Machine Learning in Communications and Networking,"30 Jan 2025","2025","3","","195","214","The evolution of Open Radio Access Networks (O-RAN) presents an opportunity to enhance network performance by enabling dynamic orchestration of configuration and optimization parameters (COPs) through online learning methods. However, leveraging this potential requires overcoming the limitations of traditional cell-centric RAN architectures, which lack the necessary flexibility. On the other hand, despite their recent popularity, the practical deployment of online learning frameworks, such as Deep Reinforcement Learning (DRL)-based COP optimization solutions, remains limited due to their risk of deteriorating network performance during the exploration phase. In this article, we propose and analyze a novel risk-aware DRL framework for user-centric RAN (UC-RAN), which offers both the architectural flexibility and COP optimization to exploit this flexibility. We investigate and identify UC-RAN COPs that can be optimized via a soft actor-critic algorithm implementable as an O-RAN application (rApp) to jointly maximize latency satisfaction, reliability satisfaction, area spectral efficiency, and energy efficiency. We use the offline learning on UC-RAN to reliably accelerate DRL training, thus minimizing the risk of DRL deteriorating cellular network performance. Results show that our proposed solution approaches near-optimal performance in just a few hundred iterations with a decrease in risk score by a factor of ten.","2831-316X","","10.1109/TMLCN.2025.3534139","National Science Foundation(grant numbers:1923669,2323300); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10852269","User-centric;O-RAN;reinforcement learning;risk-aware;6G and beyond","Optimization;Open RAN;Training;Cellular networks;Computer architecture;Reliability;Convergence;Resource management;Energy efficiency;Quality of service","","2","","38","CCBY","24 Jan 2025","","","IEEE","IEEE Journals"
"Online Decentralized Multi-Agents Meta-Learning With Byzantine Resiliency","O. T. Odeyomi; B. Ude; K. Roy","Department of Computer Science, North Carolina Agricultural and Technical State University, Greensboro, NC, USA; Department of Computer Science, North Carolina Agricultural and Technical State University, Greensboro, NC, USA; Department of Computer Science, North Carolina Agricultural and Technical State University, Greensboro, NC, USA",IEEE Access,"11 Jul 2023","2023","11","","68286","68300","Meta-learning is a learning-to-learn paradigm that leverages past learning experiences for quick adaptation to new learning tasks. It has a wide application, such as in few-shot learning, reinforcement learning, neural architecture search, federated learning, etc. It has been extended to the online learning setting where task data distribution arrives sequentially. This provides continuous lifelong learning. However, in the online meta-learning setting, a single agent has to learn many varieties of related tasks. Yet, a single agent is limited to its local task data and must collaborate with neighboring agents to improve its learning performance. Therefore, online decentralized meta-learning algorithms are designed to allow an agent to collaborate with neighboring agents in order to improve learning performance. Despite their advantages, online decentralized meta-learning algorithms are susceptible to Byzantine attacks caused by the diffusion of poisonous information from unidentifiable Byzantine agents in the network. This is a serious problem where normal agents are unable to learn and convergence to the global meta-initializer is thwarted. State-of-the-art algorithms, such as BRIDGE, designed to provide robustness against Byzantine attacks are slow and cannot work in online learning settings. Therefore, we propose an online decentralized meta-learning algorithm that works with two Byzantine-resilient aggregation techniques, which are modified coordinate-wise screening and centerpoint aggregation. The proposed algorithm provides faster convergence speed and guarantees both resiliency and continuous lifelong learning. Our simulation results show that the proposed algorithm performs better than state-of-the-art algorithms.","2169-3536","","10.1109/ACCESS.2023.3291677","Department of Computer Science, North Carolina Agricultural and Technical State University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10171341","Byzantine attacks;decentralized networks;diffusion learning;meta-learning;online learning;regret","Metalearning;Task analysis;Resilience;Convergence;Computational modeling;Computational efficiency;Learning systems;Metalearning;Online services","","5","","73","CCBY","3 Jul 2023","","","IEEE","IEEE Journals"
"Differentiable Quantum Architecture Search in Asynchronous Quantum Reinforcement Learning","S. Y. -C. Chen","Wells Fargo, New York, NY, USA",2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"10 Jan 2025","2024","01","","1516","1524","The emergence of quantum reinforcement learning (QRL) is propelled by advancements in quantum computing (QC) and machine learning (ML), particularly through quantum neural networks (QNN) built on variational quantum circuits (VQC). These advancements have proven successful in addressing sequential decision-making tasks. However, constructing effective QRL models demands significant expertise due to challenges in designing quantum circuit architectures, including data encoding and parameterized circuits, which profoundly influence model performance. In this paper, we propose addressing this challenge with differentiable quantum architecture search (DiffQAS), enabling trainable circuit parameters and structure weights using gradient-based optimization. Furthermore, we enhance training efficiency through asynchronous reinforcement learning (RL) methods facilitating parallel training. Through numerical simulations, we demonstrate that our proposed DiffQAS-QRL approach achieves performance comparable to manually-crafted circuit architectures across considered environments, showcasing stability across diverse scenarios. This methodology offers a pathway for designing QRL models without extensive quantum knowledge, ensuring robust performance and fostering broader application of QRL.","","979-8-3315-4137-8","10.1109/QCE60285.2024.00178","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821463","Quantum machine learning;Quantum neural networks;Reinforcement learning;Variational quantum circuits","Training;Computational modeling;Computer architecture;Reinforcement learning;Numerical simulation;Data models;Numerical models;Integrated circuit modeling;Quantum circuit;Testing","","9","","69","CCBYNCND","10 Jan 2025","","","IEEE","IEEE Conferences"
"An Integrated Framework of Two-Stream Deep Learning Models Optimal Information Fusion for Fruits Disease Recognition","U. Zahra; M. A. Khan; M. Alhaisoni; A. Alasiry; M. Marzougui; A. Masood","Department of Computer Science, HITEC University, Taxila, Pakistan; Department of Computer Science, HITEC University, Taxila, Pakistan; Department of Computer Sciences, College of Computer and Information Sciences, Princess Nourah Bint Abdul Rahman University, Riyadh, Saudi Arabia; College of Computer Science, King Khalid University, Abha, Saudi Arabia; College of Computer Science, King Khalid University, Abha, Saudi Arabia; Department of Physics, Norwegian University of Science and Technology, Trondheim, Norway",IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,"17 Jan 2024","2024","17","","3038","3052","Diseases impact the rates of production of many agricultural goods. These diseases require detection, which is difficult to do manually. Therefore, the creation of some automated illness detection systems is urgently required. Deep learning showed significant success in the area of precision agriculture for the recognition of plant disease. Compared with the traditional techniques, the deep learning architecture automatically extracts deep features from the deeper layer. In this work, we proposed a new automated method for classifying apple and grapefruit leaf disease recognition utilizing two-stream deep learning architecture. The proposed framework entails several steps. The first phase is picture contrast enhancement, which combines the information from DnCNN and top–bottom hat filtering to create a better image. Then, the augmentation process uses horizontal and vertical flips to increase the dataset's original size. The Inception-ResNet-V2 deep learning model is then adjusted and trained using deep transfer learning on the expanded dataset. After being extracted from the training model, the best features are chosen using two techniques—an entropy-based strategy and tree growth optimization. Finally, a new effective method combines the chosen features, and machine learning classifiers are used to complete the classification. On the augmented dataset, the proposed framework correctly classified apple and leaf diseases with the accuracy rates of 99.4% and 99.9%, respectively.","2151-1535","","10.1109/JSTARS.2023.3339297","Deanship of Scientific Research, King Khalid University; large group Research Project(grant numbers:RGP2/249/44); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10342713","Apple disease;contrast enhancement;deep learning (DL);denoising network;entropy;feature fusion;grape disease;tree growth algorithm","Diseases;Feature extraction;Deep learning;Computational modeling;Optimization;Pipelines;Plant diseases","","25","","67","CCBYNCND","5 Dec 2023","","","IEEE","IEEE Journals"
"A Multiagent Meta-Based Task Offloading Strategy for Mobile-Edge Computing","W. Ding; F. Luo; C. Gu; Z. Dai; H. Lu","Faculty of School of Information Science and Engineering, East China University of Science and Technology, Shanghai, China; Faculty of School of Information Science and Engineering, East China University of Science and Technology, Shanghai, China; Faculty of School of Information Science and Engineering, East China University of Science and Technology, Shanghai, China; Faculty of School of Information Science and Engineering, East China University of Science and Technology, Shanghai, China; Faculty of School of Information Science and Engineering, East China University of Science and Technology, Shanghai, China",IEEE Transactions on Cognitive and Developmental Systems,"2 Feb 2024","2024","16","1","100","114","Task offloading in mobile-edge computing (MEC) improves the efficacy of mobile devices (MDs) in terms of computing performance, data storage, and energy consumption by offloading computational tasks to edge servers. Efficient task offloading can leverage MEC technology to reduce task processing latency and energy consumption. By integrating the reasoning ability and machine intelligence of the cognitive computing architecture, such as SOAR and ACT-R, reinforcement learning (RL) algorithms have been applied to resolve the task offloading in MEC. To solve the problem that conventional deep RL (DRL) algorithms cannot adapt to dynamic environments, this article proposed a task offloading scheduling strategy which combined multiagent RL and meta-learning. In order to make the two actions of charging time and offloading strategy fully considered at the same time, we implemented a learning network of two agents on an MD. To efficiently train the policy network, we proposed a first-order approximation method based on the clipped surrogate objective. Finally, the experiments are designed with a variety of the number of subtasks, transmission rate, and edge server performance, and the results show that the MRL-based strategy has the overwhelming overall performance and can be quickly applied in various environments with good stability and generalization.","2379-8939","","10.1109/TCDS.2023.3246107","Shanghai Sailing Program(grant numbers:20YF1410900); National Natural Science Foundation(grant numbers:62276097); Project on Shanghai Science and Technology Innovation Action Plan(grant numbers:22ZR1416500,20dz1201400); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10048492","Deep reinforcement learning (DRL);edge task offloading;meta-learning;multiagent","Energy consumption;Computational modeling;Deep reinforcement learning;Multi-agent systems;Multi-access edge computing;Metalearning;Algorithm design and analysis","","17","","39","CCBY","17 Feb 2023","","","IEEE","IEEE Journals"
"A Generalist Reinforcement Learning Agent for Compressing Multiple Convolutional Networks Using Singular Value Decomposition","G. Gonzalez-Sahagun; S. E. Conant-Pablos; J. Carlos Ortiz-Bayliss; J. M. Cruz-Duarte","School of Engineering and Sciences, Tecnologico de Monterrey, Monterrey, Nuevo Leon, Mexico; School of Engineering and Sciences, Tecnologico de Monterrey, Monterrey, Nuevo Leon, Mexico; School of Engineering and Sciences, Tecnologico de Monterrey, Monterrey, Nuevo Leon, Mexico; School of Engineering and Sciences, Tecnologico de Monterrey, Monterrey, Nuevo Leon, Mexico",IEEE Access,"1 Oct 2024","2024","12","","136131","136147","Deep learning models have gained popularity in the last decade for computer vision tasks. Although these models are widely used, they process data in cloud services due to requiring large amounts of memory unavailable on consumer devices. Multiple techniques have been proposed to reduce the memory needed for these models. Nonetheless, finding the best method to compress each model can be a time-consuming process as the parameters of these techniques significantly affect the results. We propose a methodology for training a reinforcement learning model that exploits similarities between models to select how to compress other models it has not seen before. By reusing the generalist agent and exploiting the similarities, searching for how to compress a new model can be avoided. The agent receives a set of feature maps and compresses a model by choosing the percentage of singular values to use in a low-rank factorization of the weights of each layer. We chose the feature maps by generating an embedding for all the images and selecting the most representative image of each class. Our agent trained to compress two models, the first trained using fashion MNIST, whereas the second, using Kuzushiji-MNIST, reduced a model trained on MNIST to 15% of its original size with minimal accuracy loss. Reusing the generalist agent permitted us to skip 4.6 days of searching for a solution for MNIST.","2169-3536","","10.1109/ACCESS.2024.3457863","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10677015","Computer vision;deep learning;model compression;model optimization;reinforcement learning;singular value decomposition;low-rank factorization","Computational modeling;Image coding;Training;Data models;Filters;Reinforcement learning;Sparse matrices;Computer vision;Deep learning;Singular value decomposition","","","","44","CCBY","11 Sep 2024","","","IEEE","IEEE Journals"
"Enhancing the Uplink of Cell-Free Massive MIMO Through Prioritized Sampling and Personalized Federated Deep Reinforcement Learning","C. F. Mendoza; M. Kaneko; M. Rupp; S. Schwarz","Institute of Telecommunications, Christian Doppler Laboratory for Digital Twin Assisted AI for Sustainable Radio Access Networks, Technische Universität Wien, Vienna, Austria; Information Systems Architecture Science Research Division, National Institute of Informatics, Tokyo, Japan; Institute of Telecommunications, Technische Universität Wien, Vienna, Austria; Institute of Telecommunications, Technische Universität Wien, Vienna, Austria",IEEE Transactions on Cognitive Communications and Networking,"","2025","PP","99","1","1","Effective power control is key to solving the inter-user interference problem that degrades performance in cell-free massive multiple-input multiple-output (MIMO) systems. Motivated by its ability to operate online and model-free, without relying on training datasets, we leverage deep reinforcement learning (DRL) for uplink power control, aiming to maximize the guaranteed rate. We propose a fully centralized single-agent framework and two distributed schemes that employ several agents for improved scalability, leveraging prioritized experience replay to enable fast adaptation to the dynamic changes of the wireless environment. We investigate the performance of two multi-agent system architectures: (1) centralized training, decentralized execution (CTDE), where each agent forwards its RL experience to a central trainer, and (2) personalized federated learning (FedPer), where the training is performed locally at each agent, and only the base layer of the local deep neural network (DNN) model is forwarded periodically for aggregation at a server. We focus on the realistic scenario of dynamic device (de-)activation, combined with user mobility. Numerical evaluations demonstrate that the proposed FedPer with prioritized sampling achieves near-optimal rate and power performance while incurring the least amount of communication overhead.","2332-7731","","10.1109/TCCN.2025.3561289","Christian Doppler Forschungsgesellschaft; National Institute of Informatics; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10966452","cell-free massive MIMO;power control;deep reinforcement learning;personalized federated learning;prioritized experience replay","Power control;Uplink;Training;Massive MIMO;Resource management;Optimization;Artificial neural networks;Convergence;Interference;Scalability","","","","","CCBY","16 Apr 2025","","","IEEE","IEEE Early Access Articles"
"Energy-Efficient IoT Sensor Calibration With Deep Reinforcement Learning","A. Ashiquzzaman; H. Lee; T. -W. Um; J. Kim","School of Electronics and Computer Engineering, Chonnam National University, Gwangju, South Korea; Human IT Convergence Research Center, Korea Electronics Technology Institute, Seoul, South Korea; Department of Cyber Security, College of Science and Technology, Duksung Women’s University, Seoul, South Korea; School of Electronics and Computer Engineering, Chonnam National University, Gwangju, South Korea",IEEE Access,"2 Jun 2020","2020","8","","97045","97055","The modern development of ultra-durable and energy-efficient IoT based communication sensors has much application in modern telecommunication and networking sectors. Sensor calibration to reduce power usage is beneficial to minimizing energy consumption in sensors as well as improve the efficiency of devices. Reinforcement learning (RL) has been received much attention from researchers and now widely applied in many study fields to achieve intelligent automation. Though various types of sensors have been widely used in the field of IoT, rare researches were conducted in resource optimizing. In this novel research, a new style of power conservation has been explored with the help of RL to make a new generation of IoT devices with calibrated power sources to maximize resource utilization. A closed grid multiple power source based control for sensor resource utilization has been introduced. Our proposed model using Deep Q learning (DQN) enables IoT sensors to maximize its resource utilization. This research focuses solely on the energy-efficient sensor calibration and simulation results show promising performance of the proposed method.","2169-3536","","10.1109/ACCESS.2020.2992853","National Research Foundation of Korea (NRF) grant funded by the Korean Government (MSIT)(grant numbers:2018R1A2B2003774); Information Technology Research Center (ITRC); IITP (Institute for Information & Communications Technology Planning & Evaluation)(grant numbers:IITP-2020-2016-0-00314); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9087857","Algorithm design and analysis;optimization;computational and artificial intelligence;battery management systems;simulation;electronic design automation and methodology;deeplearning;reinforcement learning","Deep learning;Reinforcement learning;Resource management;Neural networks;Machine learning algorithms;Calibration","","21","","36","CCBY","6 May 2020","","","IEEE","IEEE Journals"
"Dynamic Adaptation in an Intelligent Multi-Tutoring System: A Multi-Agent Approach","Z. Rida; B. Hadhoum; E. Mourad; M. Mustapha","Faculty of Sciences, Ibn Zohr University, Agadir, Morocco; Le Havre Normandy University, Le Havre, France; Faculty of Sciences, Ibn Zohr University, Agadir, Morocco; Faculty of Sciences, Ibn Zohr University, Agadir, Morocco",IEEE Access,"21 Jul 2025","2025","13","","124587","124601","Online learning provides new educational opportunities but continues to face high dropout rates compared to traditional classroom settings. To address this issue, we propose IMTS (Intelligent Multi-Tutoring System), an intelligent tutoring system that integrates both multi-tutoring and multidisciplinary capabilities. IMTS synergistically integrates automated tutoring (intelligent agents) and human tutoring (teachers and peers) to deliver personalized support to learners. The proposed architecture is based on a multi-agent system (MAS) that dynamically adapts pedagogical interventions according to the learners’ profiles and needs. By analysing learning progress in real time, the system continuously adjusts its recommendations and guides the student toward the most appropriate support (educational resources, peer interaction, or teacher intervention). IMTS was developed using the JADE platform and integrated into a customized Learning Management System (LMS). An experiment conducted with students demonstrated notably improved academic performance (e.g., a 20% relative score gain compared to control), increased engagement, and significantly reduced dropout rates (e.g., halved). These findings suggest that IMTS represents a significant advancement in online education by enabling more interactive, responsive, and personalised tutoring.","2169-3536","","10.1109/ACCESS.2025.3576651","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11024187","Dynamic adaptation;intelligent tutoring system;multi;agent system;multi-tutoring;peer tutoring","Organizations;Education;XML;Real-time systems;Multi-agent systems;Decision making;Synchronization;Probabilistic logic;Learning management systems;Hands","","1","","21","CCBY","4 Jun 2025","","","IEEE","IEEE Journals"
"Observation of Collaborative Activities in a Game-Based Learning Platform","J. -C. Marty; T. Carron","Laboratoire SysCom, Bâtiment Mont-Blanc, Domaine Scientifique Technolac, Université de Savoie, Le Bourget-du-lac, France; Laboratoire SysCom, Bâtiment Mont-Blanc, Domaine Scientifique Technolac, Université de Savoie, Le Bourget-du-lac, France",IEEE Transactions on Learning Technologies,"10 Mar 2011","2011","4","1","98","110","The work reported here takes place in the educational domain. Learning with Computer-Based Learning Environments changes habits, especially for teachers. In this paper, we wish to demonstrate through examples how learning sessions set up in a Game-Based Learning environment may be regulated by the teacher thanks to observation facilities. Providing teachers with feedback (via observation) on the ongoing activity is thus central to being aware of what is happening in the classroom, in order to react in an appropriate way and to adapt a given pedagogical scenario. The first part deals with the observation of a learning environment, based on traces left by users in their collaborative activities. The information existing in these traces is rich but the quantity of traces is huge and very often incomplete. Furthermore, the information is not always at the right level of abstraction. That is why we explain the observation process, the assets of a multisource approach and the need for visualization linked to the traces. The second part of the paper focuses on our view of learning games illustrated through the “pedagogical dungeon,” a game-based environment that we have developed. In the third part, we illustrate these concepts in the pedagogical dungeon equipped for observation and with the capacity for collaboration in certain activities. Finally, the feedback about the experiments presented is discussed at the end of the paper.","1939-1382","","10.1109/TLT.2011.1","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5703066","Learning games;trace;indicator;observation facilities;regulation and collaborative learning tools.","Collaboration;Visualization;Data visualization;Software;Games;Electronic learning;Computer architecture","","29","","47","IEEE","28 Jan 2011","","","IEEE","IEEE Journals"
"Deep Reinforcement Learning for Dynamic Extravehicular Maintenance Policy in Space Stations","Y. Li; K. Liu; S. Zhang; J. Cui; X. Li; B. Wang","China Astronautics Standards Institute, Beijing, China; China Astronautics Standards Institute, Beijing, China; China Astronautics Standards Institute, Beijing, China; China Astronautics Standards Institute, Beijing, China; China Astronautics Standards Institute, Beijing, China; Beijing Institute of Technology School of Aerospace Engineering, Beijing, China",IEEE Access,"","2025","PP","99","1","1","The long-term and stable operation of space station is fundamental for advancing scientific research and technology validation, which elevates efficient and safe extravehicular maintenance to a critical priority. This article introduces a novel multi-agent deep reinforcement learning to autonomously manage the complexities of maintenance tasks in the space environment. The proposed model utilizes Deep Q-Networks (DQN) to effectively handle dynamic risk constraints and adapt in real-time to volatile conditions, such as orbital debris and system failures. Its architecture integrates a hierarchical layer of strategic planning agents, which allocate tasks and resources, with a reactive layer of execution agents that perform on-site operations. This dual-layer system is continuously informed by sophisticated models that simulate critical state transitions, including progressive device degradation, emergent environmental hazards, and the vital metric of astronaut stamina decay. Consequently, the framework generates optimal maintenance policies that rigorously maximize cost-efficiency and safety despite stringent constraints, including severely limited spare parts, restricted extravehicular activity durations, and unpredictable external risks. The model’s superiority is demonstrated to significantly reduce operational costs, minimize astronaut exposure to risk, and provide rapid, intelligent responses to stochastic component failures. This ensures the sustainability and success of long-duration space missions.","2169-3536","","10.1109/ACCESS.2025.3633735","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11251048","Deep Q-network;deep reinforcement learning;extravehicular maintenance;space stations","Maintenance;Space stations;Space vehicles;Degradation;Deep reinforcement learning;Safety;Uncertainty;Space missions;Multi-agent systems;Robot kinematics","","","","","CCBY","17 Nov 2025","","","IEEE","IEEE Early Access Articles"
"Model-Free Reinforcement Learning in Microgrid Control: A Review","F. Batincan Gurbuz; A. Karaki; A. Karaki; S. Demirbas; S. Bayhan","Department of Electrical-Electronic Engineering, Technology Faculty, Gazi University, Ankara, Türkiye; College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar; Qatar Environment and Energy Research Institute, Hamad Bin Khalifa University, Doha, Qatar; Department of Electrical-Electronic Engineering, Technology Faculty, Gazi University, Ankara, Türkiye; Department of Electrical-Electronic Engineering, Technology Faculty, Gazi University, Ankara, Türkiye",IEEE Access,"18 Sep 2025","2025","13","","161762","161778","The global shift toward distributed energy resources (DERs) has accelerated the deployment of microgrids (MGs), introducing unprecedented control challenges that traditional strategies often struggle to address. Model-free reinforcement learning (MFRL) has emerged as a promising paradigm for adaptive, intelligent control without the need for explicit system modeling. This paper presents a comprehensive review of MFRL applications in MG control, proposing a systematic taxonomy that classifies existing approaches by control hierarchy, architectural configuration, operational modes, and action spaces. We analyze critical design considerations—including reward function shaping, exploration strategies, and computational requirements—that influence practical deployment. Furthermore, we systematically evaluate key MFRL algorithms and map their suitability across primary, secondary, and tertiary control levels. By examining recent applications, we highlight that MFRL has reached considerable maturity across all control hierarchies, revealing clear trends: continuous-action methods excel in real-time primary control, distributed schemes enhance scalability in secondary coordination, and multi-agent frameworks enable complex tertiary-level optimization. Finally, the review identifies persistent implementation challenges and offers practical guidance for algorithm selection and deployment strategies in modern MG systems. This review aims to serve both researchers and practitioners seeking to deploy MFRL in modern MG systems.","2169-3536","","10.1109/ACCESS.2025.3609317","Qatar National Library; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11162524","Hierarchical control;model-free;microgrids;Q-learning;reinforcement learning","Reviews;Microgrids;Power system stability;Stability analysis;Q-learning;Optimization;Distributed power generation;Convergence;Computer architecture;Aerospace electronics","","","","95","CCBYNCND","12 Sep 2025","","","IEEE","IEEE Journals"
"Comprehensive overview of multi-agent systems for controlling smart grids","O. P. Mahela; M. Khosravy; N. Gupta; B. Khan; H. H. Alhelou; R. Mahla; N. Patel; P. Siano","Power System Planning Division, Rajasthan Rajya Vidyut Prasaran Nigam Ltd., Jaipur, India; Media Integrated Communication Laboratory, Osaka University, Osaka, Japan; Computer Science and Engineering Department, Oakland University, Rochester, NY, USA; Department of Electrical and Computer Engineering, Hawassa University, Hawassa, Ethiopia; Faculty of Mechanical and Electrical Engineering, Tishreen University, Latakia, Syria; Department of Electrical Engineering, National Institute of Technology, Kurukshetra, Kurukshetra, India; Computer Science and Engineering Department, Oakland University, Rochester, NY, USA; Department of Management & Innovation Systems, University of Salerno, Salerno, Italy",CSEE Journal of Power and Energy Systems,"24 Jan 2022","2022","8","1","115","131","Agents are intelligent entities that act flexibly and autonomously and make wise decisions based on their intelligence and experience. A multi-agent system (MAS) contains multiple, intelligent, and interconnected collaborating agents for solving a problem beyond the ability of a single agent. A smart grid (SG) combines advanced intelligent systems, control techniques, and sensing methods with an existing utility power network. For controlling smart grids, various control systems with different architectures have already been developed. MAS-based control of power system operations has been shown to overcome the limitations of time required for analysis, relaying, and protection; transmission switching; communication protocols; and management of plant control. These systems provide an alternative for fast and accurate power network control. This paper provides a comprehensive overview of MASs used for the control of smart grids. The paper provides a wide-spectrum view of the status of smart grids, MAS-based control techniques and their implementation for the control of smart grids. Use of MASs in the control of various aspects of smart grids—including the management of energy, marketing energy, pricing, scheduling energy, reliability, network security, fault handling capability, communication between agents, SG-electrical vehicles, SG-building energy systems, and soft grids—have been critically reviewed. More than a hundred publications on the topic of MAS-based control of smart grids have been critically examined, classified, and arranged for fast reference.","2096-0042","","10.17775/CSEEJPES.2020.03390","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9299490","Coordinated control;multi-agent systems;renewable energy sources;smart energy infrastructure;smart grid","Smart grids;Standards;Control systems;Protocols;Power system dynamics;Reliability;Economics","","44","","","","21 Dec 2020","","","CSEE","CSEE Journals"
"Transmission Control in NB-IoT With Model-Based Reinforcement Learning","J. J. Alcaraz; F. Losilla; F. -J. Gonzalez-Castaño","Department of Information and Communication Technologies, Technical University of Cartagena, Cartagena, Spain; Department of Information and Communication Technologies, Technical University of Cartagena, Cartagena, Spain; Telematics Engineering Department, Universidad de Vigo, Vigo, Spain",IEEE Access,"15 Jun 2023","2023","11","","57991","58005","In Narrowband Internet of Things (NB-IoT), the control of uplink transmissions is a complex task involving device scheduling, resource allocation in the carrier, and the configuration of link-adaptation parameters. Existing heuristic proposals partially address the problem, but reinforcement learning (RL) seems to be the most effective approach a priori, given its success in similar control problems. However, the low sample efficiency of conventional (model-free) RL algorithms is an important limitation for their deployment in real systems. During their initial learning stages, RL agents need to explore the policy space selecting actions that are, in general, highly ineffective. In an NB-IoT access network this implies a disproportionate increase in transmission delays. In this paper, we make two contributions to enable the adoption of RL in NB-IoT: first, we present a multi-agent architecture based on the principle of task division. Second, we propose a new model-based RL algorithm for link adaptation characterized by its high sample efficiency. The combination of these two strategies results in an algorithm that, during the learning phase, is able to maintain the transmission delay in the order of hundreds of milliseconds, whereas model-free RL algorithms cause delays of up to several seconds. This allows our approach to be deployed, without prior training, in an operating NB-IoT network and learn to control it efficiently without degrading its performance.","2169-3536","","10.1109/ACCESS.2023.3284990","Xunta de Galicia (Spain)(grant numbers:ED481B-2022-019); MCIN/AEI/10.13039/501100011033(grant numbers:PID2020-116329GB-C21); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10147823","Narrowband Internet of Things (NB-IoT);reinforcement learning;NPUSCH;uplink scheduling;link adaptation","Uplink;Delays;Resource management;Downlink;Task analysis;Narrowband;Time-frequency analysis","","5","","42","CCBYNCND","9 Jun 2023","","","IEEE","IEEE Journals"
"Deep Reinforcement Learning Enabled Self-Configurable Networks-on-Chip for High-Performance and Energy-Efficient Computing Systems","M. F. Reza","Department of Mathematics and Computer Science, Eastern Illinois University, Charleston, IL, USA",IEEE Access,"24 Jun 2022","2022","10","","65339","65354","Network-on-Chips (NoC) has been the superior interconnect fabric for multi/many-core on-chip systems because of its scalability and parallelism. On-chip network resources can be dynamically configured to improve the energy efficiency and performance of NoC. However, large and complex design space in heterogeneous NoC architectures becomes difficult to explore within a reasonable time for optimal trade-offs of energy and performance. Furthermore, reactive resource management is not effective in preventing problems, such as thermal hotspots, from happening in adaptive systems. Therefore, we propose machine learning (ML) techniques to provide proactive solutions within an instant in NoC-based computing systems. We present a deep reinforcement learning (deep RL) technique to configure voltage/frequency levels of NoC routers and links for both high performance and energy efficiency while meeting the global energy budget constraint. Distributed RL agents technique has been proposed, where an RL agent configures a NoC router and associated links intelligently based on system utilization and application demands. Additionally, neural networks are used to approximate the actions of distributed RL agents. Simulations results for NoC sizes ranging from 16 to 256 cores under real applications and synthetic traffic show that the proposed self-configurable and scalable approach, on average, improves energy-delay product (EDP) by 30-40% (up to 80%) and by 8% (up to 17%) compared to existing non-ML and ML based solutions, respectively.","2169-3536","","10.1109/ACCESS.2022.3182500","Department of Mathematics and Computer Science at the Eastern Illinois University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794707","Network-on-chip (NoC);multicore architecture;mancore processor;machine learning (ML);reinforcement learning (RL);distributed RL;deep reinforcement learning (Deep RL);Q-learning;neural networks (NNs);self-configurable;energy-efficiency;high-performance","System-on-chip;Reinforcement learning;Task analysis;Artificial neural networks;Optimization;Computer architecture;Voltage","","9","","53","CCBY","13 Jun 2022","","","IEEE","IEEE Journals"
"An Agent-Based Framework for Policy Simulation: Modeling Heterogeneous Behaviors With Modified Sigmoid Function and Evolutionary Training","S. Yu","Fraunhofer Institute for Systems and Innovation Research, Karlsruhe, Germany",IEEE Transactions on Computational Social Systems,"2 Aug 2023","2023","10","4","1901","1913","This article proposes an agent-based policy simulation framework that can be applied to the cases satisfying: 1) the agents try to maximize some intertemporal preference and 2) the impacts of different factors on agents’ behavioral tendency are monotonic. By combining the simulation and optimization methods, this framework balances the flexibility and validity of agent-based models (ABMs): the sigmoid function is modified and used to model agents’ decision-making rules, and the evolutionary training method is used to calibrate agents’ behavioral parameters. Based on an example for the emission trading scheme, the application of the framework is presented and evaluated in detail.","2329-924X","","10.1109/TCSS.2022.3196737","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9857838","Agent-based model (ABM);evolutionary training;flexibility and validity;policy simulation framework;sigmoid function","Behavioral sciences;Biological system modeling;Adaptation models;Training;Decision making;Calibration;Atmospheric modeling","","8","","69","CCBY","16 Aug 2022","","","IEEE","IEEE Journals"
"A Modular Execution Architecture for Robust Multi-Robot Planning and Acting in Trans-Media Environments","V. D. L. Rochefoucauld; P. Ratsamee; S. Lacroix; F. Ingrand; Y. Uranishi","LAAS-CNRS, INSA, University of Toulouse, Toulouse, France; Department of Mechanical Engineering, Faculty of Engineering Science, Kansai University, Osaka, Japan; LAAS-CNRS, INSA, University of Toulouse, Toulouse, France; LAAS-CNRS, INSA, University of Toulouse, Toulouse, France; Cybermedia Education Division, D3 Center, The University of Osaka, Osaka, Japan",IEEE Access,"4 Nov 2025","2025","13","","186208","186230","In complex missions involving heterogeneous multi-robot teams, especially in trans-media systems that operate across environments such as air and water, robust execution frameworks must ensure both temporal coherence and resilience to uncertainty. These challenges stem from the need to manage dynamic mode transitions, closely linked inter-agent actions, and execution-time failures. This paper introduces the Adaptive and Modular Architecture (AMA) Execution and Planning components. AMA-Exec is a distributed execution framework designed to enable coherent, fault-tolerant mission execution in such conditions. AMA-Exec uses the plans produced by AMA-Plan, a PDDL-based planning framework. AMA-Exec incorporates Simple Temporal Networks (STNs) to facilitate temporal reasoning; modular Behavior Trees (BTs) to enable distributed execution; and runtime monitoring mechanisms to categorize failures, propagate delays, and execute partial replanning. In contrast to centralized, monolithic systems, AMA-Exec organizes execution around collaborative robot teams and leverages real-time feedback to maintain synchronization and temporal alignment under disturbances. We validate the framework on simulated trans-media missions, encompassing concurrent actions and a range of failure scenarios. Findings indicate enhanced execution continuity, applicability to more complex missions, and robust failure recovery in comparison to baseline methodologies. AMA-Exec modularity and generalizability render it suitable for a wide range of applications, including environmental monitoring, distributed exploration, and search-and-rescue operations.","2169-3536","","10.1109/ACCESS.2025.3625646","Joint Doctoral Program between LAAS-CNRS/INSA Toulouse and Osaka University, with Institutional Support from both Institutions; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11218220","Multi-robot systems;trans-media robots;execution monitoring;automated planning;temporal coordination;behavior trees","Planning;Robots;Robot kinematics;Runtime;Synchronization;Robustness;Delays;Multi-robot systems;Cognition;Uncertainty","","","","51","CCBY","27 Oct 2025","","","IEEE","IEEE Journals"
"A Survey on Deep Reinforcement Learning for Data Processing and Analytics","Q. Cai; C. Cui; Y. Xiong; W. Wang; Z. Xie; M. Zhang","National University of Singapore, Singapore; National University of Singapore, Singapore; National University of Singapore, Singapore; National University of Singapore, Singapore; Zhejiang University and Institute of Computing Innovation, Zhejiang University, Hangzhou, Zhejiang, China; Beijing Institute of Techonology, Beijing, China",IEEE Transactions on Knowledge and Data Engineering,"3 Apr 2023","2023","35","5","4446","4465","Data processing and analytics are fundamental and pervasive. Algorithms play a vital role in data processing and analytics where many algorithm designs have incorporated heuristics and general rules from human knowledge and experience to improve their effectiveness. Recently, reinforcement learning, deep reinforcement learning (DRL) in particular, is increasingly explored and exploited in many areas because it can learn better strategies in complicated environments it is interacting with than statically designed algorithms. Motivated by this trend, we provide a comprehensive review of recent works focusing on utilizing DRL to improve data processing and analytics. First, we present an introduction to key concepts, theories, and methods in DRL. Next, we discuss DRL deployment on database systems, facilitating data processing and analytics in various aspects, including data organization, scheduling, tuning, and indexing. Then, we survey the application of DRL in data processing and analytics, ranging from data preparation, natural language processing to healthcare, fintech, etc. Finally, we discuss important open challenges and future research directions of using DRL in data processing and analytics.","1558-2191","","10.1109/TKDE.2022.3155196","National Key Research and Development Program of China(grant numbers:2020YFB1708100); Singapore Ministry of Education Academic Research Fund Tier 3(grant numbers:MOE2017-T3-1-007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9723570","Deep reinforcement learning;data processing and analytics;database;system optimization","Data processing;Reinforcement learning;Query processing;Optimization;Costs;Tuning;Medical services","","24","","126","CCBYNCND","1 Mar 2022","","","IEEE","IEEE Journals"
"Improving the Computational Efficiency of the Unit Commitment Problem in Hydrothermal Systems by Using Multi-Agent Deep Reinforcement Learning","P. Guerra; E. Gil; V. H. Hinojosa","Department of Electrical Engineering, Universidad Técnica Federico Santa María, Valparaíso, Chile; Department of Electrical Engineering, Universidad Técnica Federico Santa María, Valparaíso, Chile; Department of Electrical Engineering, Universidad Técnica Federico Santa María, Valparaíso, Chile",IEEE Access,"18 Apr 2024","2024","12","","53266","53276","In power systems with a significant hydroelectric component, instances of the Unit Commitment (UC) problem may be much more computationally intensive due to the longer decision horizons and the additional hydro constraints. Therefore, this paper presents a methodology to reduce the solution space to accelerate 168-hour-ahead UC formulated as a Mixed-Integer Linear Program (MILP). First, an offline model maps environment observations to actions in a Multi-Agent Deep Reinforcement Learning (MADRL) model. This mapping uses historical power system operation data to determine the on/off status of specific generation units. Then, the online model uses the binary variable solutions obtained by the offline model to solve a UC problem with a reduced solution space. The Multi-Agent approach allows each agent, based on Artificial Neural Networks (ANN) with a Temporal Convolutional Network (TCN) architecture, to group units that are located in the same region. A shared cumulative reward function is used to adjust simultaneously the different ANN weights during the learning phase. The effectiveness of our method is demonstrated using real operational data of the Chilean National Electricity System, achieving statistically significant lower computation times and a negligible error that is within the integrality gap of the solver.","2169-3536","","10.1109/ACCESS.2024.3383442","Chilean National Agency for Research and Development (ANID)(grant numbers:Basal FB0008,Fondecyt 1231892); Universidad Técnica Federico Santa María, Chile(grant numbers:USM PI_LIR_2022_03); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10486892","Artificial neural networks;multi-agent deep reinforcement learning;unit commitment;variable reduction","Power systems;Optimization;Electricity;Training;ISO;Generators;Feature extraction","","1","","32","CCBYNCND","1 Apr 2024","","","IEEE","IEEE Journals"
"Towards Open and Expandable Cognitive AI Architectures for Large-Scale Multi-Agent Human-Robot Collaborative Learning","G. T. Papadopoulos; M. Antona; C. Stephanidis","Foundation for Research and Technology - Hellas (FORTH), Institute of Computer Science (ICS), Greece; Foundation for Research and Technology - Hellas (FORTH), Institute of Computer Science (ICS), Greece; Foundation for Research and Technology - Hellas (FORTH), Institute of Computer Science (ICS), Greece",IEEE Access,"24 May 2021","2021","9","","73890","73909","Learning from Demonstration (LfD) constitutes one of the most robust methodologies for constructing efficient cognitive robotic systems. Despite the large body of research works already reported, current key technological challenges include those of multi-agent learning and long-term autonomy. Towards this direction, a novel cognitive architecture for multi-agent LfD robotic learning is introduced in this paper, targeting to enable the reliable deployment of open, scalable and expandable robotic systems in large-scale and complex environments. In particular, the designed architecture capitalizes on the recent advances in the Artificial Intelligence (AI) (and especially the Deep Learning (DL)) field, by establishing a Federated Learning (FL)-based framework for incarnating a multi-human multi-robot collaborative learning environment. The fundamental conceptualization relies on employing multiple AI-empowered cognitive processes (implementing various robotic tasks) that operate at the edge nodes of a network of robotic platforms, while global AI models (underpinning the aforementioned robotic tasks) are collectively created and shared among the network, by elegantly combining information from a large number of human-robot interaction instances. Regarding pivotal novelties, the designed cognitive architecture a) introduces a new FL-based formalism that extends the conventional LfD learning paradigm to support large-scale multi-agent operational settings, b) elaborates previous FL-based self-learning robotic schemes so as to incorporate the human in the learning loop and c) consolidates the fundamental principles of FL with additional sophisticated AI-enabled learning methodologies for modelling the multi-level inter-dependencies among the robotic tasks. The applicability of the proposed framework is explained using an example of a real-world industrial case study (subject to ongoing research activities) for agile production-based Critical Raw Materials (CRM) recovery.","2169-3536","","10.1109/ACCESS.2021.3080517","ICS-FORTH internal Research and Technological Development (RTD) Programme ’Ambient Intelligence and Smart Environments; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9431107","Learning from demonstration;human-robot interaction;artificial intelligence;federated learning","Robots;Task analysis;Collaborative work;Service robots;Hidden Markov models;Robot sensing systems;Human-robot interaction","","27","","88","CCBY","14 May 2021","","","IEEE","IEEE Journals"
"A Reinforcement-Learning Based Approach for Designing High-Voltage SiC MOSFET Guard Rings","T. S. Rawat; C. -L. Hung; Y. -K. Hsiao; W. -C. Yu; S. Elangovan; W. -T. Lin; Y. -R. Lin; K. -L. Yang; N. -Y. Jan; Y. -H. Li; H. -C. Kuo","Semiconductor Research Center, Hon Hai Research Institute (HHRI), Foxconn, Taiwan; Semiconductor Research Center, Hon Hai Research Institute (HHRI), Foxconn, Taiwan; Semiconductor Research Center, Hon Hai Research Institute (HHRI), Foxconn, Taiwan; Semiconductor Research Center, Hon Hai Research Institute (HHRI), Foxconn, Taiwan; Semiconductor Research Center, Hon Hai Research Institute (HHRI), Foxconn, Taiwan; Semiconductor Research Center, Hon Hai Research Institute (HHRI), Foxconn, Taiwan; AI Research Center, Hon Hai Research Institute (HHRI), Foxconn, Taiwan; AI Research Center, Hon Hai Research Institute (HHRI), Foxconn, Taiwan; AI Research Center, Hon Hai Research Institute (HHRI), Foxconn, Taiwan; AI Research Center, Hon Hai Research Institute (HHRI), Foxconn, Taiwan; Semiconductor Research Center, Hon Hai Research Institute (HHRI), Foxconn, Taiwan",IEEE Open Journal of Power Electronics,"13 Dec 2024","2024","5","","1853","1861","For high-power silicon carbide (SiC) devices, breakdown voltage analysis is an important parameter, especially for guard ring design. This work explores the implementation of machine learning on SiC guard ring parameters such as ion implanted dose and energy. In this work, the reinforcement learning method has been successfully implemented on the 1.7 kV SiC guard ring device TCAD simulated data for the prediction of parameters. Our work has predicted the parameters successfully for the 2.5 kV guard ring design. For training, proximal policy optimization (PPO) and advantage actor-critic (A2C) RL agents were deployed. The network architecture was kept at “auto” with 3 hidden layers of 128 neurons in each layer. Our method is practically feasible and easily implemented as compared to other works, and has been shown in this paper. By using the limited design parameters of the 1.7 kV guard ring device, the trained agent has successfully predicted the design parameters for the 2.5 kV guard ring device, which has been confirmed using TCAD simulations. This work is more accurate, practical, and result-oriented, and we believe that this can significantly minimize the computational cost as compared to the standalone TCAD simulations. Also, this implementation of ML on TCAD data can substantially accelerate the design exploration for the power devices and ultimately lower product-to-market time.","2644-1314","","10.1109/OJPEL.2024.3496865","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10752388","Breakdown voltage;machine learning;power device;reinforcement learning;SiC guard ring design","Training;Technological innovation;Silicon carbide;Computational modeling;Scalability;Neurons;Network architecture;Reliability engineering;Robustness;Optimization","","3","","40","CCBYNCND","13 Nov 2024","","","IEEE","IEEE Journals"
"Massively High-Throughput Reinforcement Learning for Classic Control on GPUs","X. Sha; T. Lan","School of Civil and Transportation Engineering, Southeast University Chengxian College, Nanjing, Jiangsu, China; Salesforce AI Research, Palo Alto, CA, USA",IEEE Access,"29 Aug 2024","2024","12","","117737","117744","This study presents a novel massively high-throughput reinforcement learning (RL) framework specifically designed for addressing classic control problems, leveraging our proposed architecture and algorithms optimized for efficient concurrent computations on GPUs. Our research demonstrates the effectiveness of our methods in efficiently training RL agents across various classic control problems, encompassing both discrete and continuous domains, while achieving rapid and stable performance up to 10K concurrent environment instances. Furthermore, we observe that RL exploration with a large number of parallel instances significantly enhances the stability of updating a shared model. For instance, we show that the stability of Deep Deterministic Policy Gradient (DDPG) training can be achieved without requiring experience replay, as evidenced in our study.","2169-3536","","10.1109/ACCESS.2024.3441242","Research and Development Fund for Young Teachers of Southeast University Chengxian College(grant numbers:Z0057); Jiangsu Provincial University Philosophy and Social Science Research Project(grant numbers:2022SJYB0707); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10632139","Classic control;GPU acceleration;high-throughput;reinforcement learning","Graphics processing units;Reinforcement learning;Training;Instruction sets;Computer architecture;Trajectory;Throughput;Control systems","","2","","28","CCBYNCND","9 Aug 2024","","","IEEE","IEEE Journals"
"CPS-Agent Oriented Construction and Implementation For Cyber Physical Systems","Y. Hu; X. Zhou","School of Computer Science and Engineering, Northwestern Polytechnical University, Xi’an, China; School of Computer Science and Engineering, Northwestern Polytechnical University, Xi’an, China",IEEE Access,"25 Oct 2018","2018","6","","57631","57642","Cyber-physical systems (CPSs) have attracted many researchers in areas as diverse as aerospace, manufacturing, transportation, and so on. However, modeling methodologies and tools for autonomous objects in CPS are still lacking. In this paper, the CPS-Agent is proposed to model objects with consideration of temporal-spatial traits and interaction with physical environment. It is formulated by a fivetuple. Furthermore, considering that no universal methodology of coordination strategy formulation could be used to guide researchers, we present a role-based strategy formulation to make work patterns of CPS-Agents more clear. In terms of network communication among CPS-Agents, a set of communicative primitives is tailored based on the FIPA-ACL specification. Afterward, to guide engineers in designing systems according to their application requirements in the area of CPS, we design templates and a novel visual support tool for generating C++ files automatically corresponding to customized CPS-Agents, coordination strategies, and coordination groups. Finally, the complete development process based on our methodologies and tool is illustrated by an instance of a car team.","2169-3536","","10.1109/ACCESS.2018.2873751","National Natural Science Foundation of China(grant numbers:61751208,61502394); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8485798","Cyber physical system;modeling;support tool;CPS-agent;code generation","Tools;Task analysis;Java;Software agents;Visualization;Automobiles","","9","","29","OAPA","8 Oct 2018","","","IEEE","IEEE Journals"
"Reinforcement Learning for Building Energy Optimization Through Controlling of Central HVAC System","J. Hao; D. W. Gao; J. J. Zhang","Department of Electrical and Computer Engineering, University of Denver, Denver, CO, USA; Department of Electrical and Computer Engineering, University of Denver, Denver, CO, USA; School of Electrical Engineering and Automation, Wuhan University, Wuhan, China",IEEE Open Access Journal of Power and Energy,"8 Oct 2020","2020","7","","320","328","This paper presents a novel methodology to control HVAC system and minimize energy cost on the premise of satisfying power system constraints. A multi-agent architecture based on game theory and reinforcement learning is developed so as to reduce the cost and computational complexity of the microgrid. The multi-agent architecture comprising agents, state variables, action variables, reward function and cost game is formulated. The paper fills the gap between multi-agent HVAC systems control and power system optimization and planning. The results and analysis indicate that the proposed algorithm is beneficial to deal with the problem of “curse of dimensionality” for multi-agent microgrid HVAC system control and speed up learning of unknown power system conditions.","2687-7910","","10.1109/OAJPE.2020.3023916","U.S. National Science Foundation(grant numbers:1711951); Key Technologies Research and Development Program of Tianjin City(grant numbers:17ZXRGGX00170); Corporate Research and Development Program of State Grid of China(grant numbers:SGZJDK00DYJS1900232); Science and Technology Program of Central China Branch of State Grid Corporation of China(grant numbers:521400180005); National Key Research and Development Program of China(grant numbers:SQ2018AAA010127); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9195858","Game theory;reinforcement learning;multi-agent system;HVAC control;cost minimization","Control systems;Buildings;Open Access;Tin;Microgrids","","26","","30","CCBY","14 Sep 2020","","","IEEE","IEEE Journals"
"Visual Explanation With Action Query Transformer in Deep Reinforcement Learning and Visual Feedback via Augmented Reality","H. Itaya; W. Yin; T. Hirakawa; T. Yamashita; H. Fujiyoshi; K. Sugiura","Chubu University, Kasugai-shi, Aichi, Japan; Department of Robotics, Chubu University, Kasugai-shi, Aichi, Japan; Center for Mathematical Science and Artificial Intelligence, Chubu University, Kasugai-shi, Aichi, Japan; Department of Computer Science, Chubu University, Kasugai-shi, Aichi, Japan; Department of Robotics, Chubu University, Kasugai-shi, Aichi, Japan; Department of Computer Science, Keio University, Yokohama, Kanagawa, Japan",IEEE Access,"3 Apr 2025","2025","13","","56338","56354","Deep Reinforcement Learning (DRL) agents possess powerful control capabilities and have potential applications in robotics and other fields. However, the closed box properties of DRL agent models still make it difficult to interpret their decision-making processes. One research area that addresses this challenge is eXplainable Reinforcement Learning (XRL). Conventional visual explanation methods in XRL focus only on the rationale behind a single selected action and are insufficient for a more comprehensive analysis of an agent’s decision making. In addition, visualizing attention only as an image is problematic in real-world environments such as robotics because it does not clearly map attention to physical space, limiting user understanding. To overcome these limitations, we propose Action Q-Transformer (AQT), an XRL method that uses a transformer encoder-decoder architecture with action information as a query. In this way, AQT calculates explicit attentions for each action that an agent may select, resulting in a DRL agent model that is easier to interpret. Furthermore, we introduce a visual feedback method using augmented reality (AR) to project these attentions directly into the physical environment. Through experiments on the Atari 2600 video game strategy task and a robot control task in an indoor environment, we demonstrate that AQT can analyze agent decision making in detail. Also, user evaluation in a robot task confirms that AR-based visual feedback effectively improves the understanding of the agent’s behavior.","2169-3536","","10.1109/ACCESS.2025.3554493","New Energy and Industrial Technology Development Organization (NEDO)(grant numbers:JPNP20006); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10938565","Explainable AI;deep reinforcement learning;augmented reality;video games;robot control","Transformers;Visualization;Robots;Decision making;Deep reinforcement learning;Computational modeling;Video games;Robot control;Augmented reality;Real-time systems","","","","54","CCBY","25 Mar 2025","","","IEEE","IEEE Journals"
"Deep Reinforcement Learning-Based Asymmetric Convolutional Autoencoder for Intrusion Detection","Y. Dai; X. Qian; C. Yang","School of Electronic Information and Artificial Intelligence, Yibin Vocational & Technical College, Yibin, China; College of Digital Economy, Yibin Industry Polytechnic College, Yibin, China; School of Changning County Vocational and Technical School, Yibin, China",Journal of ICT Standardization,"18 Jun 2025","2025","13","1","67","92","In recent years, intrusion detection systems (IDSs) have become a critical component of network security, due to the growing number and complexity of cyber-attacks. Traditional IDS methods, including signature-based and anomaly-based detection, often struggle with the high-dimensional and imbalanced nature of network traffic, leading to suboptimal performance. Moreover, many existing models fail to efficiently handle the diverse and complex attack types. In response to these challenges, we propose a novel deep learning-based IDS framework that leverages a deep asymmetric convolutional autoencoder (DACA) architecture. Our model combines advanced techniques for feature extraction, dimensionality reduction, and anomaly detection into a single cohesive framework. The DACA model is designed to effectively capture complex patterns and subtle anomalies in network traffic while significantly reducing computational complexity. By employing this architecture, we achieve superior detection accuracy across various types of attacks even in imbalanced datasets. Experimental results demonstrate that our approach surpasses several state-of-the-art methods, including HCM-SVM, D1-IDDS, and GNN -IDS, achieving high accuracy, precision, recall, and F1-score on benchmark datasets such as NSL-KDD and UNSW-NB15. The results emphasize how effectively our model identifies complex and varied attack patterns. In conclusion, the proposed IDS model offers a promising solution to the limitations of current detection systems, with significant improvements in performance and efficiency. This approach contributes to advancing the development of robust and scalable network security solutions.","2246-0853","","10.13052/jicts2245-800X.1314","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11042904","Intrusion detection system;asymmetric convolutional autoencoder;network security;attack detection;feature extraction","Training;Accuracy;Computational modeling;Autoencoders;Intrusion detection;Computer architecture;Telecommunication traffic;Network security;Semisupervised learning;Real-time systems","","","","53","","18 Jun 2025","","","River Publishers","River Publishers Journals"
"Dynamic Fusion of LSTM Predictions Using Reinforcement Learning-Based GOWLA for Human Activity Recognition","H. K. Fatlawi; A. Kiss","Center of Information Technology Research and Development, University of Kufa, Najaf, Iraq; Department of Information Systems, Eötvös Loránd University, Budapest, Hungary",IEEE Access,"20 Jun 2025","2025","13","","104779","104790","Human Activity Recognition (HAR) contributes significantly to vital areas in healthcare, IoT, and smart monitoring applications. Generally, the current models rely on deep learning and traditional machine learning techniques such as LSTM and SVM. However, these methods face considerable challenges, such as imbalanced data distribution, weak adaptation of weights to temporal changes, and a decline in classification performance in rare activities. In this paper, we propose a new method based on dynamic reinforcement learning to update GOWLA weights, which is entitled Dynamic RL-GOWLA. In this method, the LSTM outputs are combined using Weighted Logarithmic Averaging with a reinforcement learning agent for dynamically updating the weights based on the model’s performance in each training iteration. Experiments on WISDM database show that the proposed method outperforms traditional models such as LSTM, SVM, Bayesian Classifier, RNN, and CNN, achieving a F1-score of 96.58%. This approach improves the adaptability of models to imbalanced data, making it a promising solution for tasks that require accurate classification of dynamic human activities.","2169-3536","","10.1109/ACCESS.2025.3579926","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11036747","Human activity recognition;reinforcement learning;deep learning;ordered weighted averaging","Human activity recognition;Open wireless architecture;Long short term memory;Reinforcement learning;Feature extraction;Computational modeling;Sensors;Solid modeling;Deep learning;Data models","","","","51","CCBY","16 Jun 2025","","","IEEE","IEEE Journals"
"Distributed Intelligence in Wireless Networks","X. Liu; J. Yu; Y. Liu; Y. Gao; T. Mahmoodi; S. Lambotharan; D. H. -K. Tsang","Institute for Digital Technologies, Loughborough University London, London, U.K; Internet of Things Thrust, The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, Guangdong, China; School of Electronic Engineering and Computer Science, Queen Mary University of London, London, U.K; School of Computer Science, Fudan University, Shanghai, China; Department of Engineering, King's College London, London, U.K; Institute for Digital Technologies, Loughborough University London, London, U.K; Internet of Things Thrust, The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, Guangdong, China",IEEE Open Journal of the Communications Society,"26 Apr 2023","2023","4","","1001","1039","The cloud-based solutions are becoming inefficient due to considerably large time delays, high power consumption, and security and privacy concerns caused by billions of connected wireless devices and typically zillions of bytes of data they produce at the network edge. A blend of edge computing and Artificial Intelligence (AI) techniques could optimally shift the resourceful computation servers closer to the network edge, which provides the support for advanced AI applications (e.g., video/audio surveillance and personal recommendation system) by enabling intelligent decision making on computing at the point of data generation as and when it is needed, and distributed Machine Learning (ML) with its potential to avoid the transmission of the large dataset and possible compromise of privacy that may exist in cloud-based centralized learning. Besides, the deployment of AI techniques to redesign end-to-end communication is attracting attention to improve communication performance. Therefore, the interaction of AI and wireless communications generates a new concept, named native AI wireless networks. In this paper, we conduct a comprehensive overview of recent advances in distributed intelligence in wireless networks under the umbrella of native AI wireless networks, with a focus on the design of distributed learning architectures for heterogeneous networks, on AI-enabled edge computing, on the communication-efficient technologies to support distributed learning, and on the AI-empowered end-to-end communications. We highlight the advantages of hybrid distributed learning architectures compared to state-of-the-art distributed learning techniques. We summarize the challenges of existing research contributions in distributed intelligence in wireless networks and identify potential future opportunities.","2644-125X","","10.1109/OJCOMS.2023.3265425","Engineering and Physical Sciences Research Council (EPSRC)(grant numbers:EP/R006385/1,EP/X012301/1,EP/R00711X/2); Guangzhou Municipal Science and Technology Project(grant numbers:2023A03J0011); Guangdong Provincial Key Laboratory of Integrated Communications, Sensing and Computation for Ubiquitous Internet of Things;; U.K. Government Funded Project under the Future Open Networks Research Challenge sponsored by the Department of Science Innovation and Technology; Royal Society(grant numbers:IEC01112); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10100930","Distributed intelligence;distributed machine learning;edge computing;end-to-end communications;federated learning;split learning","Artificial intelligence;Wireless networks;Data models;Computational modeling;Servers;Training;Distance learning","","21","","232","CCBY","12 Apr 2023","","","IEEE","IEEE Journals"
"Sim-to-Real Transfer of Deep Reinforcement Learning Agents for Online Coverage Path Planning","A. Jonnarth; O. Johansson; J. Zhao; M. Felsberg","Manta Systems, Linköping, Sweden; Department of Electrical Engineering, Linköping University, Linköping, Sweden; Department of Information and Communication Engineering, Dalian University of Technology, Dalian, China; Department of Electrical Engineering, Linköping University, Linköping, Sweden",IEEE Access,"24 Jun 2025","2025","13","","106883","106905","Coverage path planning (CPP) is the problem of finding a path that covers the entire free space of a confined area, with applications ranging from robotic lawn mowing to search-and-rescue. While for known environments, offline methods can find provably complete paths, and in some cases optimal solutions, unknown environments need to be planned online during mapping. We investigate the suitability of continuous-space reinforcement learning (RL) for this challenging problem, and propose a computationally feasible egocentric map representation based on frontiers, as well as a novel reward term based on total variation to promote complete coverage. Compared to existing classical methods, this approach allows for a flexible path space, and enables the agent to adapt to specific environment characteristics. Meanwhile, the deployment of RL models on real robot systems is difficult. Training from scratch may be infeasible due to slow convergence times, while transferring from simulation to reality, i.e. sim-to-real transfer, is a key challenge in itself. We bridge the sim-to-real gap through a semi-virtual environment, including a real robot and real-time aspects, while utilizing a simulated sensor and obstacles to enable environment randomization and automated episode resetting. We investigate what level of fine-tuning is needed for adapting to a realistic setting. Through extensive experiments, we show that our approach surpasses the performance of both previous RL-based approaches and highly specialized methods across multiple CPP variations in simulation. Meanwhile, our method successfully transfers to a real robot. Our code implementation can be found online (Link to code repository: https://github.com/arvijj/rl-cpp).","2169-3536","","10.1109/ACCESS.2025.3581035","Wallenberg AI, Autonomous Systems and Software Program (WASP); Knut and Alice Wallenberg (KAW) Foundation; Vinnova Project, Human-Centered Autonomous Regional Airport(grant numbers:Dnr 2022-02678); Strategic Research Environment, Excellence Center at Linköping-Lund in Information Technology (ELLIIT); Swedish Government; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11039829","Coverage path planning;end-to-end learning;exploration;online;real-time;reinforcement learning;robotics;sim-to-real transfer;total variation","Robots;Training;Robot sensing systems;Path planning;Real-time systems;Adaptation models;Data models;Sensors;Network architecture;Delays","","1","","61","CCBY","18 Jun 2025","","","IEEE","IEEE Journals"
"Network Resource Allocation Strategy Based on Deep Reinforcement Learning","S. Zhang; C. Wang; J. Zhang; Y. Duan; X. You; P. Zhang","State Grid Shandong Electric Power Research Institute, Jinan, China; College of Computer Science and Technology, China University of Petroleum (East China), Qingdao, China; College of Computer Science and Technology, China University of Petroleum (East China), Qingdao, China; College of Computer Science and Technology, China University of Petroleum (East China), Qingdao, China; State Grid Shandong Electric Power Research Institute, Jinan, China; College of Computer Science and Technology, China University of Petroleum (East China), Qingdao, China",IEEE Open Journal of the Computer Society,"1 Jul 2020","2020","1","","86","94","The traditional Internet has encountered a bottleneck in allocating network resources for emerging technology needs. Network virtualization (NV) technology as a future network architecture, the virtual network embedding (VNE) algorithm it supports shows great potential in solving resource allocation problems. Combined with the efficient machine learning (ML) algorithm, a neural network model close to the substrate network environment is constructed to train the reinforcement learning agent. This paper proposes a two-stage VNE algorithm based on deep reinforcement learning (DRL) (TS-DRL-VNE) for the problem that the mapping result of existing heuristic algorithm is easy to converge to the local optimal solution. For the problem that the existing VNE algorithm based on ML often ignores the importance of substrate network representation and training mode, a DRL VNE algorithm based on full attribute matrix (FAM-DRL-VNE) is proposed. In view of the problem that the existing VNE algorithm often ignores the underlying resource changes between virtual network requests, a DRL VNE algorithm based on matrix perturbation theory (MPT-DRL-VNE) is proposed. Experimental results show that the above algorithm is superior to other algorithms.","2644-1268","","10.1109/OJCS.2020.3000330","Major Scientific and Technological Projects(grant numbers:ZD2019-183-006); The Fundamental Research Funds(grant numbers:20CX05017A,18CX02139A); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9109671","Resource allocation;network virtualization;virtual network embedding;machine learning","Substrates;Resource management;Reinforcement learning;Bandwidth;Machine learning algorithms;Internet;Neural networks","","16","","42","CCBY","5 Jun 2020","","","IEEE","IEEE Journals"
"Crossing the Reality Gap: A Survey on Sim-to-Real Transferability of Robot Controllers in Reinforcement Learning","E. Salvato; G. Fenu; E. Medvet; F. A. Pellegrino","Department of Engineering and Architecture, University of Trieste, Trieste, Italy; Department of Engineering and Architecture, University of Trieste, Trieste, Italy; Department of Engineering and Architecture, University of Trieste, Trieste, Italy; Department of Engineering and Architecture, University of Trieste, Trieste, Italy",IEEE Access,"19 Nov 2021","2021","9","","153171","153187","The growing demand for robots able to act autonomously in complex scenarios has widely accelerated the introduction of Reinforcement Learning (RL) in robots control applications. However, the trial and error intrinsic nature of RL may result in long training time on real robots and, moreover, it may lead to dangerous outcomes. While simulators are useful tools to accelerate RL training and to ensure safety, they often are provided only with an approximated model of robot dynamics and of its interaction with the surrounding environment, thus resulting in what is called the reality gap (RG): a mismatch of simulated and real control-law performances caused by the inaccurate representation of the real environment in simulation. The most undesirable result occurs when the controller learnt in simulation fails the task on the real robot, thus resulting in an unsuccessful sim-to-real transfer. The goal of the present survey is threefold: (1) to identify the main approaches to face the RG problem in the context of robot control with RL, (2) to point out their shortcomings, and (3) to outline new potential research areas.","2169-3536","","10.1109/ACCESS.2021.3126658","Italian Ministry for Research in the framework of the 2017 Program for Research Projects of National Interest (PRIN)(grant numbers:2017YKXYXJ); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9606868","Reality gap;reinforcement learning;robotics;sim-to-real","Task analysis;Reinforcement learning;Training;Robot control;Process control;Faces","","123","","121","CCBY","8 Nov 2021","","","IEEE","IEEE Journals"
"Converging Technologies for Safety Planning and Inspection Information System of Portable Firefighting Equipment","N. Khan; D. Lee; C. Baek; C. -S. Park","School of Architecture and Building Sciences, Chung-Ang University, Seoul, South Korea; School of Architecture and Building Sciences, Chung-Ang University, Seoul, South Korea; School of Architecture and Building Sciences, Chung-Ang University, Seoul, South Korea; School of Architecture and Building Sciences, Chung-Ang University, Seoul, South Korea",IEEE Access,"2 Dec 2020","2020","8","","211173","211188","Many construction workers are getting injured or killed in fires and explosion accidents each year. The workers are prone to severe fatal accidents due to unavailability of permanent firefighting system in many construction sites, thus they typically rely on portable firefighting equipment (PFE) to minimize fire damage. Many occupational health and safety agencies have developed safety regulations for PFE installation and monitoring in construction. However, in the traditional construction fire safety management process, the installation spots for PFE's are visually identified in a 2D floor plan and then top-down supervisory approach is used to inspect the active availability of the PFE's. Such manually operated conventional methods of PFE installation and monitoring are expensive, prone to manipulation, and do not provide sufficient motivation for voluntarily following fire safety policies. Therefore, this research study develops a fire safety rule-based PFE installation approach and proposes an alternative method for shifting the top-down inspection approach to the bottom-up voluntarily approach for convenient, transparent, and automated safety inspection information delivery. To validate the bottom-up approach concept, a visual language algorithm is initially developed for PFE installation planning system (PFE-IPS) in BIM, followed by an optical character recognition (OCR) and blockchain -based android application for safety inspection information system (SIIS). This article also presents two case studies to evaluate the feasibility and practicality of the developed systems. The proposed approach out-turn reduces the safety manager's manual efforts and burdens of government safety auditors while enhancing efficiency and reliability.","2169-3536","","10.1109/ACCESS.2020.3039512","Chung-Ang University Research Scholarship Grants in 2020; National Research Foundation of Korea (NRF) grant funded by the Korean Government Ministry of Science and ICT (MSIP)(grant numbers:NRF-2019R1A2B5B02070721); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9265272","Fire safety rule;visual languages;BIM;optical character recognition (OCR);blockchain;portable firefighting equipment (PFE)","Safety;Inspection;Planning;Blockchain;Accidents;Optical character recognition software;Monitoring","","14","","57","CCBY","20 Nov 2020","","","IEEE","IEEE Journals"
"A Spatiotemporal Agent for Robust Multimodal Registration","Z. Luo; X. Wang; X. Wu; Y. Yin; K. Cao; Q. Song; J. Hu","Department of Computer Science, Chengdu University of Information Technology, Chengdu, China; CuraCloud Corporation, Seattle, USA; Department of Computer Science, Chengdu University of Information Technology, Chengdu, China; CuraCloud Corporation, Seattle, USA; CuraCloud Corporation, Seattle, USA; CuraCloud Corporation, Seattle, USA; Department of Computer Science, Chengdu University of Information Technology, Chengdu, China",IEEE Access,"1 May 2020","2020","8","","75347","75358","Multimodal image registration is a crucial step for a variety of medical applications to provide complementary information from the combination of various data sources. Conventional image registration methods aim at finding a suited similarity metric as well as a descriptive image feature, which is quite challenging due to the high diversity of tissue appearance across modalities. In this paper, we present a novel approach to register images via an asynchronously trained reinforcement learning agent automatically. Within this approach, convolutional gated recurrent units (ConvGRU) is incorporated after stacked convolutional layers to extract both spatial and temporal features of the neighboring frames and implicitly learn the similarity metric. Moreover, we propose a customized reward function driven by fixed points error (FPE) to guide the agent to the correct registration direction. A Monte Carlo rollout strategy is also leveraged to perform a look-ahead inference to the elimination of jitter in the test stage. Evaluation is performed on paired CT and MR images from patients diagnosed as nasopharyngeal carcinoma. The results demonstrate that our method achieves state-of-the-art performance in medical image registration.","2169-3536","","10.1109/ACCESS.2020.2989150","National Natural Science Foundation of China(grant numbers:61602065); Scientific Research Foundation of the Education Department of Sichuan Province(grant numbers:17ZA0062); Chengdu University of Information and Technology (CUIT) Foundation for Leaders of Disciplines in Science(grant numbers:J201608); Scientific Research Foundation of CUIT(grant numbers:KYTZ201610); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9075173","Medical image;reinforcement learning;multimodal registration;actor-critic;convolutional GRU","Image registration;Feature extraction;Machine learning;Measurement;Learning (artificial intelligence);Biomedical imaging;Task analysis","","3","","36","CCBY","21 Apr 2020","","","IEEE","IEEE Journals"
"Word-Based POMDP Dialog Management via Hybrid Learning","S. Lei; X. Wang; C. Yuan","Center for Intelligence of Science and Technology, Beijing University of Posts and Telecommunications, Beijing, China; Center for Intelligence of Science and Technology, Beijing University of Posts and Telecommunications, Beijing, China; Center for Intelligence of Science and Technology, Beijing University of Posts and Telecommunications, Beijing, China",IEEE Access,"3 Apr 2019","2019","7","","39236","39243","Dialog management plays an important role in the task-oriented dialog system. Most of the previous works divide dialog management into state tracker and action selector. The two parts are modeled separately and implemented in a pipelined way, which suffers from the problem of error accumulation, and the feedback signal from action selector cannot be propagated to state tracker and natural language understanding module. This paper proposes a word-based partially observable Markov decision processes' dialog management that integrates natural language understanding, state tracker, and action selector into an end-to-end architecture. Our proposed dialog management takes the words from user utterances as inputs and then produces optimal action as well as slot values of natural language understanding which are necessary for response generation. To this end, we propose a hybrid learning method, which integrates reinforcement learning and supervised learning, to optimize the action selector and slot filler jointly. In addition, we develop a high-return prioritized experience replay to speed up the convergence of the training process. The experimental results show that the proposed dialog management outperforms four strong baselines in a series of different dialog tasks. A human user's evaluation also shows the same results. The high-return prioritized experience replay accelerates the convergence effectively, especially in the scenario in which the proposed dialog management works on more complex tasks.","2169-3536","","10.1109/ACCESS.2019.2903863","National Natural Science Foundation of China(grant numbers:61273365); NSSFC(grant numbers:2016ZDA055); 111 Project(grant numbers:B08004); Beijing Advanced Innovation Center for Imaging Technology, Engineering Research Center of Information Networks of MOE, China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8664102","Recurrent neural networks;multi-layer neural network;supervised learning;reinforcement learning;dialog management;task-oriented dialog system;partially observable Markov decision processes","Task analysis;Training;Supervised learning;Pipelines;Convergence;Natural languages;Markov processes","","1","","28","OAPA","10 Mar 2019","","","IEEE","IEEE Journals"
"CommonPower: A Framework for Safe Data-Driven Smart Grid Control","M. Eichelbeck; H. Markgraf; M. Althoff","School of Computation, Information and Technology, Technical University of Munich, Germany; School of Computation, Information and Technology, Technical University of Munich, Germany; School of Computation, Information and Technology, Technical University of Munich, Germany",IEEE Transactions on Smart Grid,"","2025","PP","99","1","1","The growing complexity of power system management has led to an increased interest in reinforcement learning (RL). To validate their effectiveness, RL algorithms have to be evaluated across multiple case studies. Case study design is an arduous task requiring the consideration of many aspects, among them the influence of available forecasts and the level of decentralization in the control structure. Furthermore, vanilla RL controllers cannot themselves ensure the satisfaction of system constraints, which makes devising a safeguarding mechanism a necessary task for every case study before deploying the system. To address these shortcomings, we introduce the Python tool CommonPower, the first general framework for the modeling and simulation of power system management tailored towards machine learning. Its modular architecture enables users to focus on specific elements without having to implement a simulation environment. Another unique contribution of CommonPower is the automatic synthesis of model predictive controllers and safeguards. Beyond offering a unified interface for single-agent RL, multi-agent RL, and optimal control, CommonPower includes a training pipeline for machine-learning-based forecasters as well as a flexible mechanism for incorporating feedback of safeguards into the learning updates of RL controllers.","1949-3061","","10.1109/TSG.2025.3616402","Deutsche Forschungsgemeinschaft(grant numbers:458030766); Bayerische Forschungsstiftung(grant numbers:AZ-1473-20); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11186797","Safe reinforcement learning;energy management;model predictive control;multi-agent systems;forecast uncertainties","Libraries;Predictive models;Power systems;Optimal control;Microgrids;Decentralized control;Adaptation models;Trajectory;Smart grids;Safety","","","","","CCBY","1 Oct 2025","","","IEEE","IEEE Early Access Articles"
"An Energy Efficient EdgeAI Autoencoder Accelerator for Reinforcement Learning","N. K. Manjunath; A. Shiri; M. Hosseini; B. Prakash; N. R. Waytowich; T. Mohsenin","Department of Computer Science and Electrical Engineering, University of Maryland, Baltimore, MD, USA; Department of Computer Science and Electrical Engineering, University of Maryland, Baltimore, MD, USA; Department of Computer Science and Electrical Engineering, University of Maryland, Baltimore, MD, USA; Department of Computer Science and Electrical Engineering, University of Maryland, Baltimore, MD, USA; U.S. Army Research Laboratory, Aberdeen, MD, USA; Department of Computer Science and Electrical Engineering, University of Maryland, Baltimore, MD, USA",IEEE Open Journal of Circuits and Systems,"25 Jan 2021","2021","2","","182","195","In EdgeAI embedded devices that exploit reinforcement learning (RL), it is essential to reduce the number of actions taken by the agent in the real world and minimize the compute-intensive policies learning process. Convolutional autoencoders (AEs) has demonstrated great improvement for speeding up the policy learning time when attached to the RL agent, by compressing the high dimensional input data into a small latent representation for feeding the RL agent. Despite reducing the policy learning time, AE adds a significant computational and memory complexity to the model which contributes to the increase in the total computation and the model size. In this article, we propose a model for speeding up the policy learning process of RL agent with the use of AE neural networks, which engages binary and ternary precision to address the high complexity overhead without deteriorating the policy that an RL agent learns. Binary Neural Networks (BNNs) and Ternary Neural Networks (TNNs) compress weights into 1 and 2 bits representations, which result in significant compression of the model size and memory as well as simplifying multiply-accumulate (MAC) operations. We evaluate the performance of our model in three RL environments including DonkeyCar, Miniworld sidewalk, and Miniworld Object Pickup, which emulate various real-world applications with different levels of complexity. With proper hyperparameter optimization and architecture exploration, TNN models achieve near the same average reward, Peak Signal to Noise Ratio (PSNR) and Mean Squared Error (MSE) performance as the full-precision model while reducing the model size by 10x compared to full-precision and 3x compared to BNNs. However, in BNN models the average reward drops up to 12% - 25% compared to the full-precision even after increasing its model size by 4x. We designed and implemented a scalable hardware accelerator which is configurable in terms of the number of processing elements (PEs) and memory data width to achieve the best power, performance, and energy efficiency trade-off for EdgeAI embedded devices. The proposed hardware implemented on Artix-7 FPGA dissipates 250 μJ energy while meeting 30 frames per second (FPS) throughput requirements. The hardware is configurable to reach an efficiency of over 1 TOP/J on FPGA implementation. The proposed hardware accelerator is synthesized and placed-and-routed in 14 nm FinFET ASIC technology which brings down the power dissipation to 3.9 μJ and maximum throughput of 1,250 FPS. Compared to the state of the art TNN implementations on the same target platform, our hardware is 5x and 4.4x (2.2x if technology scaled) more energy efficient on FPGA and ASIC, respectively.","2644-1225","","10.1109/OJCAS.2020.3043737","U.S. Army Research Laboratory through Cooperative Agreement(grant numbers:W911NF-10-2-0022); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9335309","Reinforcement learning;autonomous systems;autoencoder;binary neural networks (BNNs);ternary neural networks (TNNs);EdgeAI;energy efficiency;FPGA;ASIC","Computational modeling;Neural networks;Reinforcement learning;Hardware;Energy efficiency;Complexity theory;Field programmable gate arrays","","10","","43","CCBY","25 Jan 2021","","","IEEE","IEEE Journals"
"A Sample Aggregation Approach to Experiences Replay of Dyna-Q Learning","H. Shi; S. Yang; K. -S. Hwang; J. Chen; M. Hu; H. Zhang","School of Computer Science, Northwestern Polytechnical University, Xi’an, China; Department of software, Twentieth Research Institute of China Electronic Technology Group Corporation, Xi’an, China; Department of Electrical Engineering, National Sun Yat-Sen University, Kaohsiung, Taiwan; School of Computer Science, Northwestern Polytechnical University, Xi’an, China; School of Electronics Engineering and Computer Science, Peking University, Beijing, China; Department of software, Twentieth Research Institute of China Electronic Technology Group Corporation, Xi’an, China",IEEE Access,"23 Jul 2018","2018","6","","37173","37184","In a complex environment, the learning efficiency of reinforcement learning methods always decreases due to large-scale or continuous spaces problems, which can cause the well-known curse of dimensionality. To deal with this problem and enhance learning efficiency, this paper introduces an aggregation method by using framework of sample aggregation based on Chinese restaurant process (CRP), named FSA-CRP, to cluster experiential samples, which is represented by quadruples of the current state, action, next state, and the obtained reward. In addition, the proposed algorithm applies a similarity estimation method, the MinHash method, to calculate the similarity between samples. Moreover, to improve the learning efficiency, the experience sharing Dyna learning algorithm based on samples/clusters prediction method is proposed. While an agent learns the value function of the current state, it acquires clustering results, the value functions of the sample merge with the original as the updated value function of the cluster. In indirect learning (planning) for the Dyna-Q, a learning agent looks for the most likely branches of the constructed FSA-CRP model to raise up learning efficiency. The most likely branches will be selected by an improved action/sample selection algorithm. The algorithm applies the probability that the sample appears in the cluster to select simulated experiences for indirect learning. To verify the validity and applicability of the proposed method, experiments are conducted on a simulated maze and a cart-pole system. The results demonstrate that the proposed method can effectively accelerate the learning process.","2169-3536","","10.1109/ACCESS.2018.2847048","National Key Research and Development Program of China(grant numbers:2017YFB1001900); Aeronautical Science Foundation of China(grant numbers:2016ZC53022); Fundamental Research Funds for the Central Universities(grant numbers:2018026); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8383982","Dyna-Q;Minhash;Chinese restaurant process;FSA-CRP model;prediction","Planning;Prediction algorithms;Learning (artificial intelligence);Computer architecture;Computational complexity;Sensors;Heuristic algorithms","","10","","31","OAPA","13 Jun 2018","","","IEEE","IEEE Journals"
"A Centralized Strategy for Multi-Agent Exploration","F. Gul; A. Mir; I. Mir; S. Mir; T. U. Islaam; L. Abualigah; A. Forestiero","Department of Electrical Engineering, Aerospace and Aviation Campus KAMRA, Air University, Attock, Pakistan; Faculty of Engineering and IT, University of Technology Sydney, Ultimo, NSW, Australia; Department of Electrical Engineering, Aerospace and Aviation Campus KAMRA, Air University, Attock, Pakistan; Electrical Department, Fast National University of Computer and Emerging Sciences, Peshawar, Pakistan; School of Aerospace and Mechanical Engineering, College of Aeronautical Engineering, NUST, Islamabad, Pakistan; Hourani Center for Applied Scientific Research, Al-Ahliyya Amman University, Amman, Jordan; School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia",IEEE Access,"9 Dec 2022","2022","10","","126871","126884","This paper introduces recently developed Aquila Optimization Algorithm specifically configured for Multi-Robot space exploration. The proposed hybrid framework “Coordinated Multi-Robot Exploration Aquila Optimizer” (CME-AO) is a unique combination of both deterministic Coordinated Multi-robot Exploration (CME) and a swarm based methodology, known as Aquila Optimizer (AO). A novel parallel communication protocol is also embedded to improve multi-robot space exploration process while simultaneously minimizing both the computation complexity and time. This ensures acquisition of a optimal collision-free path in a barrier-filled environment via generating a finite map. The architecture starts by determining the cost and utility values of neighbouring cells around the robot using deterministic CME. Aquila Optimization technique is then incorporated to increase the overall solution accuracy. Numerous simulations under different environmental conditions were then performed to validate the effectiveness of the proposed algorithm. Algorithm consistency aspects in achieving the expected results (area explored rate and time) is demonstrated through statistical means. A perspective analysis is then performed by comparing the performance of the CME-AO algorithm with latest state of art contemporary algorithms namely conventional CME and CME-WO (CME Whale Optimizer). The comparison duly accommodates all pertinent aspects such as % area explored, number of failed runs, and time taken for map exploration for different environments. Results indicate that the proposed algorithm presents two distinct advantages over the other conventional state of the art CME based techniques a) enhanced map exploration in cluttered environment and b) significantly reduced computation complexity and execution time, with almost no fail runs. This makes the suggested methodology particularly suitable for on-board utilization in an obstacle-cluttered environment, where other techniques either fails (stuck locally) or takes longer exploration time.","2169-3536","","10.1109/ACCESS.2022.3218653","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9933766","Robotics;multiple agent system;space exploration;artificial intelligence;optimization algorithms;autonomous systems","Multi-agent systems;Robot kinematics;Planning;Optimization;Path planning;Collision avoidance;Robot sensing systems;Artificial intelligence;Autonomous systems","","41","","67","CCBY","1 Nov 2022","","","IEEE","IEEE Journals"
"A Custom Reinforcement Learning Environment for Hybrid Renewable Energy Systems: Design and Implementation","D. F. G. Filho; M. A. Moret; E. G. S. Nascimento","Stricto Sensu Department, SENAI CIMATEC University, Salvador, Bahia, Brazil; Stricto Sensu Department, SENAI CIMATEC University, Salvador, Bahia, Brazil; Stricto Sensu Department, SENAI CIMATEC University, Salvador, Bahia, Brazil",IEEE Access,"1 Aug 2025","2025","13","","133984","133993","We present HybridEnergyEnv, an open-source, Gym-style simulation environment designed for reinforcement learning (RL) research in hybrid renewable energy systems (HRES) combining wind, solar, and battery storage. The environment incorporates realistic component models, including intermittent renewable generation profiles, a synthetic electricity price signal inversely correlated with renewable availability, and a detailed Battery Energy Storage System (BESS) model accounting for state-of-charge (SoC) dynamics, self-discharge, efficiency losses, thermal derating, and rainflow-based capacity degradation. To validate the framework, we evaluate three dispatch strategies implemented with algorithms available in the Stable-Baselines3 (SB3) library: Proximal Policy Optimization (PPO), Advantage Actor-Critic (A2C), and Double Deep Q-Network (DDQN). Results show that DRL-based policies increase operational revenue by up to 10.05% and reduce curtailment by up to 84.60% compared to the no-storage baseline. Additionally, DDQN achieves the longest episode durations and highest rewards during training, indicating greater stability under strict curtailment constraints. We describe the environment architecture, component models, and API, demonstrating the potential of HybridEnergyEnv as a high-fidelity, extensible platform for the development of intelligent, degradation-aware dispatch strategies in modern power systems.","2169-3536","","10.1109/ACCESS.2025.3593064","Eletrobras Chesf–Northeast Operations through the Public Call for Research and Development(grant numbers:02/2017); Brazilian Electricity Regulatory Agency (ANEEL, Brazil) Base(grant numbers:PD-00048-0217); SENAI CIMATEC University(grant numbers:308963/2022-9); Erick G. Sperandio Nascimento was supported by the National Council for Scientific and Technological Development (CNPq) Technological Development Fellowship(grant numbers:308963/2022-9); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11097283","OpenAI gym environment;deep reinforcement learning;hybrid renewable energy;wind energy;solar energy;battery energy storage system;PPO;A2C;DDQN","Renewable energy sources;Degradation;Biological system modeling;Batteries;Wind forecasting;Thermal degradation;Power system dynamics;Hybrid power systems;Load modeling;Computer architecture","","","","24","CCBY","28 Jul 2025","","","IEEE","IEEE Journals"
"A Reinforced Active Learning Algorithm for Semantic Segmentation in Complex Imaging","U. A. Usmani; J. Watada; J. Jaafar; I. A. Aziz; A. Roy","Department of Computer and Information Science, Faculty of Science and IT, Universiti Teknologi PETRONAS (UTP), Seri Iskandar, Perak, Malaysia; Production and Systems, Graduate School of Information, Waseda University, Kitakyushu, Japan; Department of Computer and Information Science, Faculty of Science and IT, Universiti Teknologi PETRONAS (UTP), Seri Iskandar, Perak, Malaysia; Department of Computer and Information Science, Faculty of Science and IT, Universiti Teknologi PETRONAS (UTP), Seri Iskandar, Perak, Malaysia; Department of Computer Science, School of Information Technology, Monash University Malaysia, Subang Jaya, Selangor, Malaysia",IEEE Access,"30 Dec 2021","2021","9","","168415","168432","Semantic segmentation annotation helps train computer vision based Artificial Intelligence models where each image pixel is assigned to a specific object class. The model developers try to identify the features helpful for determining the objects of interest by using various supervised deep learning techniques. However, this is a difficult task due to the complexity of object structures. Two difficulties arise in the current approaches for semantic segmentation. The pixel-wise label approach is costly to obtain and is time consuming. Second, the datasets taken for the semantic segmentation task are not balanced since certain classes are present more than the others. This biases the model performance to the most represented ones. We propose a new reinforced active learning strategy based on a deep reinforcement learning algorithm. This work presents a modified Deep  $Q$  Learning formulation for active learning. An agent learns the strategy of selecting a subset of small image regions, which are more knowledgeable than the whole set of images from an unlabeled data pool. The decision on the area of selection is dependent on the assumptions and segmentation model uncertainties taken for training purposes. We use the CamVid and RGB indoor test scenes dataset to evaluate the proof of concept. Our results infer that our approach demands more labels from under-represented groups than the baselines, thus enhancing their efficiency and mitigating the class imbalance. Our method’s performance is superior to the conventional deep learning models in detecting 8 out of 11 classes on the Camvid road segmentation scene dataset. It achieves an accuracy of 90.56%, a mIoU score of 87.17%, and a BF score of 93.14%. On the SUNRGB indoor scenes dataset, it gives an accuracy of around 75.82% and a BF score of 77.25%, thus outperforming the current state-of-the-art methods.","2169-3536","","10.1109/ACCESS.2021.3136647","Yayasan Universiti Teknologi Petronas Prestigious Scholarship (YUTP) under Universiti Teknologi Petronas with cost centre(grant numbers:015LC0-281); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9656121","Reinforcement learning;deep query networks;active learning;semantic segmentation","Deep learning;Training;Image segmentation;Uncertainty;Q-learning;Computational modeling;Roads","","31","","80","CCBY","20 Dec 2021","","","IEEE","IEEE Journals"
"User-Centric Satellite Handover for Multiple Traffic Profiles Using Deep Q-Learning","N. Badini; M. Jaber; M. Marchese; F. Patrone","Department of Electrical, Electronics and Telecommunications Engineering, and Naval Architecture (DITEN), University of Genoa, Genoa, Italy; Department of Electrical, Electronics and Telecommunications Engineering, and Naval Architecture (DITEN), University of Genoa, Genoa, Italy; Department of Electrical, Electronics and Telecommunications Engineering, and Naval Architecture (DITEN), University of Genoa, Genoa, Italy; Department of Electrical, Electronics and Telecommunications Engineering, and Naval Architecture (DITEN), University of Genoa, Genoa, Italy",IEEE Transactions on Aerospace and Electronic Systems,"5 Dec 2024","2024","60","6","8591","8604","Multiple low Earth orbit (LEO) satellites have recently been launched in constellations to ensure direct Internet access to users anywhere and at any time. Due to the high-speed mobility of LEO satellites, users undergo multiple handovers (HOs) during their service time, which has a negative impact on users' quality of service (QoS) if occurred in high frequency. Moreover, next-generation communication technologies are designed to support a wide spectrum of applications, including artificial intelligence, virtual reality, and Internet of Things. Thus, differentiating user equipments (UEs) with different and varying traffic profiles (TP) has become necessary due to each application's unique performance requirements. However, LEO satellites have limited onboard resources and the launched constellations ensure that each UE will be covered by more than one LEO satellite at any given moment, making it challenging to select the optimal satellite at any given time to assure the optimum QoS. Therefore, a satellite HO strategy has to effectively use the few available satellite resources and prevent network congestion while respecting the various resource requirements per TP. To address all the above requirements, we propose a user-centric multiagent deep Q-network satellite HO strategy, which is the first in the state of the art to address the variety and diversity of UEs' performance requirements and generated traffic statistics. Our method showcases a significant achievement of approximately 60% reduction in HO rate and around 91% reduction in blocking rate compared to conventional single-criterion approaches.","1557-9603","","10.1109/TAES.2024.3434771","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10613436","Deep neural network (DNN);deep Q-learning (DQL);distributed satellite handover (HO);multiagent reinforcement learning (MARL);satellite–terrestrial integrated network (STIN) simulator","Satellites;Low earth orbit satellites;Satellite broadcasting;Quality of service;Handover;Aerospace and electronic systems;Optimization","","8","","38","CCBY","29 Jul 2024","","","IEEE","IEEE Journals"
"Reinforcement Learning Based Fault-Tolerant Routing Algorithm for Mesh Based NoC and Its FPGA Implementation","S. Jagadheesh; P. V. Bhanu; J. Soumya; L. R. Cenkeramaddi","Department of Electrical and Electronics Engineering, Birla Institute of Technology and Science-Pilani, Hyderabad Campus, Hyderabad, Telangana, India; Department of Electrical and Electronics Engineering, Birla Institute of Technology and Science-Pilani, Hyderabad Campus, Hyderabad, Telangana, India; Department of Electrical and Electronics Engineering, Birla Institute of Technology and Science-Pilani, Hyderabad Campus, Hyderabad, Telangana, India; Department of Information and Communication Technology, University of Agder (UiA), Grimstad, Kristiansand, Norway",IEEE Access,"2 May 2022","2022","10","","44724","44737","Network-on-Chip (NoC) has emerged as the most promising on-chip interconnection framework in Multi-Processor System-on-Chips (MPSoCs) due to its efficiency and scalability. In the deep sub-micron level, NoCs are vulnerable to faults, which leads to the failure of network components such as links and routers. Failures in NoC components diminish system efficiency and reliability. This paper proposes a Reinforcement Learning based Fault-Tolerant Routing (RL-FTR) algorithm to tackle the routing issues caused by link and router faults in the mesh-based NoC architecture. The efficiency of the proposed RL-FTR algorithm is examined using System-C based cycle-accurate NoC simulator. Simulations are carried out by increasing the number of links and router faults in various sizes of mesh. Followed by simulations, real-time functioning of the proposed RL-FTR algorithm is observed using the FPGA implementation. Results of the simulation and hardware shows that the proposed RL-FTR algorithm provides an optimal routing path from the source router to the destination router.","2169-3536","","10.1109/ACCESS.2022.3168992","Indo-Norwegian Collaboration in Autonomous Cyber-Physical Systems (INCAPS) of the INTPART International Partnerships for Excellent Education, Research and Innovation Program from the Research Council of Norway(grant numbers:287918); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9760423","Fault-tolerance;FPGA;network-on-chip;reinforcement learning;routing","Routing;Topology;Fault tolerant systems;Fault tolerance;Heuristic algorithms;Machine learning algorithms;Field programmable gate arrays","","17","","30","CCBY","20 Apr 2022","","","IEEE","IEEE Journals"
"Constrained Environment Optimization for Prioritized Multi-Agent Navigation","Z. Gao; A. Prorok","Department of Computer Science and Technology, University of Cambridge, Cambridge, U.K.; Department of Computer Science and Technology, University of Cambridge, Cambridge, U.K.",IEEE Open Journal of Control Systems,"6 Oct 2023","2023","2","","337","355","Traditional approaches for multi-agent navigation consider the environment as a fixed constraint, despite the obvious influence of spatial constraints on agents' performance. Yet hand-designing conducive environments is inefficient and potentially expensive. The goal of this article is to consider the obstacle layout of the environment as a decision variable in a system-level optimization problem. In other words, we aim to find an automated solution that optimizes the obstacle layout to improve the performance of multi-agent navigation, under a variety of realistic constraints. Towards this end, we propose novel problems of unprioritized and prioritized environment optimization, where the former considers agents unbiasedly and the latter incorporates agent priorities into optimization. We show, through formal proofs, under which conditions the environment can change to guarantee completeness (i.e., all agents reach goals), and analyze the role of agent priorities in the environment optimization. We proceed to impose constraints on the environment optimization that correspond to real-world restrictions on obstacle changes, and formulate it mathematically as a constrained stochastic optimization problem. Since the relationship between agents, environment and performance is challenging to model, we leverage reinforcement learning to develop a model-free solution and a primal-dual mechanism to handle constraints. Distinct information processing architectures are integrated for various implementation scenarios, including online/offline optimization and discrete/continuous environment. Numerical results corroborate the theory and demonstrate the validity and adaptability of our approach.","2694-085X","","10.1109/OJCSYS.2023.3316090","European Research Council(grant numbers:949940); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10251921","Constrained optimization;environment optimization;multi-agent systems;navigation","Optimization;Navigation;Trajectory;Multi-agent systems;Layout;Robot sensing systems","","4","","53","CCBY","15 Sep 2023","","","IEEE","IEEE Journals"
"Feature Selection for Malware Detection Based on Reinforcement Learning","Z. Fang; J. Wang; J. Geng; X. Kan","College of Computer Science, Sichuan University, Chengdu, China; College of Computer Science, Sichuan University, Chengdu, China; College of Computer Science, Sichuan University, Chengdu, China; College of Computer Science, Sichuan University, Chengdu, China",IEEE Access,"12 Dec 2019","2019","7","","176177","176187","Machine learning based malware detection has been proved great success in the past few years. Most of the conventional methods are based on supervised learning, which relies on static features with labels. While selecting static features requires both human expertise and labor. New selections, which fix features from a wide range, are handcrafted by careful manual experimentation or modified from existing methods. Despite their success, the static features are still hard to be determined. In this paper, a Deep Q-learning based Feature Selection Architecture (DQFSA) is introduced to cover the deficiencies of traditional methods. The proposed architecture automatically selects a small set of highly differentiated features for malware detection task without human intervention. DQFSA trains an agent through Q-learning to maximize the expected accuracy of the classifiers on a validation dataset by sequentially interacting with the features space. The agent, based on an  $\epsilon $ -greedy exploration strategy and experience replay, explores a large but finite space of possible actions and iteratively discovers selections with improved performance on the learning task. Actions are a set of reasonable choices, which indicate whether a feature is chosen or not. Extensive experimental results indicate that the proposed DQFSA outperforms existing baseline approaches for feature selection on malware detection with minimum features, improves the generalization performance of the learning model and reduces human intervention. More specifically, the proposed architecture’s underlying representation is robust enough for re-calibrating models to other domains of information security.","2169-3536","","10.1109/ACCESS.2019.2957429","National Basic Research Program of China (973 Program)(grant numbers:2019QY1404,2018YFB0804503); National Natural Science Foundation of China(grant numbers:U1836103); Technology Research and Development Program of Sichuan, China(grant numbers:2017GZDZX0002,19ZDZX0024); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920059","Feature selection;malware detection;deep reinforcement learning;Q-learning","Feature extraction;Malware;Task analysis;Learning (artificial intelligence);Computer architecture;Training;Machine learning","","41","","31","CCBY","3 Dec 2019","","","IEEE","IEEE Journals"
"Reinforcement Learning Based EV Charging Management Systems–A Review","H. M. Abdullah; A. Gastli; L. Ben-Brahim","Electrical Engineering Department, College of Engineering, Qatar University, Doha, Qatar; Electrical Engineering Department, College of Engineering, Qatar University, Doha, Qatar; Electrical Engineering Department, College of Engineering, Qatar University, Doha, Qatar",IEEE Access,"18 Mar 2021","2021","9","","41506","41531","To mitigate global warming and energy shortage, integration of renewable energy generation sources, energy storage systems, and plug-in electric vehicles (PEVs) have been introduced in recent years. The application of electric vehicles (EV) in the smart grid has shown a significant option to reduce carbon emission. However, due to the limited battery capacity, managing the charging and discharging process of EV as a distributed power supply is a challenging task. Moreover, the unpredictable nature of renewable energy generation, uncertainties of plug-in electric vehicles associated parameters, energy prices, and the time-varying load create new challenges for the researchers and industries to maintain a stable operation of the power system. The EV battery charging management system plays a main role in coordinating the charging and discharging mechanism to efficiently realize a secure, efficient, and reliable power system. More recently, there has been an increasing interest in data-driven approaches in EV charging modeling. Consequently, researchers are looking to deploy model-free approaches for solving the EV charging management with uncertainties. Among many existing model-free approaches, Reinforcement Learning (RL) has been widely used for EV charging management. Unlike other machine learning approaches, the RL technique is based on maximizing the cumulative reward. This article reviews the existing literature related to the RL-based framework, objectives, and architecture for the charging coordination strategies of electric vehicles in the power systems. In addition, the review paper presents a detailed comparative analysis of the techniques used for achieving different charging coordination objectives while satisfying multiple constraints. This article also focuses on the application of RL in EV coordination for research and development of the cutting-edge optimized energy management system (EMS), which are applicable for EV charging.","2169-3536","","10.1109/ACCESS.2021.3064354","Qatar National Library; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9371688","Artificial intelligence;electric vehicles;machine learning;management;smart grids","Electric vehicle charging;Uncertainty;Batteries;Reinforcement learning;Vehicle-to-grid;Optimization;Load modeling;Global warming","","159","","120","CCBY","8 Mar 2021","","","IEEE","IEEE Journals"
"Overview of Intelligent Online Banking System Based on HERCULES Architecture","G. Luo; W. Li; Y. Peng","Intelligent Information Processing Laboratory, School of Computer, Fudan University, Shanghai, China; School of Computer, Fudan University, Shanghai, China; Intelligent Information Processing Laboratory, School of Computer, Guangxi Teachers Education University, Nanning, China",IEEE Access,"16 Jun 2020","2020","8","","107685","107699","The online banking transaction system is the application system with the most complex business, the most demanded, and frequent version updates in the software engineering application system. The existing online banking business sub-module is intelligent and faces major challenges in security. Traditional online banking systems cannot meet this capability. This article combines machine learning and online banking business module design to implement a business agent online banking system based on a new architecture. The article first proposes new features and new challenges of the online banking system, discusses the technical problems solved by the intelligent online banking system, and analyzes HERCULES Architecture business intelligent machine learning algorithm model, smart deposits and white-collar loans and other core processes, and then designed and implemented an intelligent online banking system business model, focusing on the issues of the intelligent online banking system, soft load balancing implementation and transaction security, through business implementation The effectiveness of the proposed business agent is verified. The actual use results show that the intelligent online banking of the HERCULES architecture has greatly improved the intelligence and security of the traditional online banking system. Finally, we summarize and analyze the value and innovation of the intelligent online banking system, and look forward to the shortcomings of the system.","2169-3536","","10.1109/ACCESS.2020.2997079","Intelligent Information Processing Laboratory, School of Computer, Fudan University, Shanghai, China; company in Shanghai; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9099293","HERCULES architecture;machine learning;hot release;smart deposits;white-collar loans;load balancing","Online banking;Business;Security;Computer architecture;Machine learning;Machine learning algorithms","","11","","32","CCBY","25 May 2020","","","IEEE","IEEE Journals"
"Multi-agent system application in accordance with game theory in bi-directional coordination network model","J. Zhang; G. Wang; S. Yue; Y. Song; J. Liu; X. Yao","College of Electronics and Information Engineering, Air Force Engineering University, Xi'an, China; College of Air Missile Defense, Air Force Engineering University, Xi'an, China; College of Air Missile Defense, Air Force Engineering University, Xi'an, China; College of Air Missile Defense, Air Force Engineering University, Xi'an, China; College of Air Missile Defense, Air Force Engineering University, Xi'an, China; College of Air Missile Defense, Air Force Engineering University, Xi'an, China",Journal of Systems Engineering and Electronics,"30 Apr 2020","2020","31","2","279","289","The multi-agent system is the optimal solution to complex intelligent problems. In accordance with the game theory, the concept of loyalty is introduced to analyze the relationship between agents' individual income and global benefits and build the logical architecture of the multi-agent system. Besides, to verify the feasibility of the method, the cyclic neural network is optimized, the bi-directional coordination network is built as the training network for deep learning, and specific training scenes are simulated as the training background. After a certain number of training iterations, the model can learn simple strategies autonomously. Also, as the training time increases, the complexity of learning strategies rises gradually. Strategies such as obstacle avoidance, firepower distribution and collaborative cover are adopted to demonstrate the achievability of the model. The model is verified to be realizable by the examples of obstacle avoidance, fire distribution and cooperative cover. Under the same resource background, the model exhibits better convergence than other deep learning training networks, and it is not easy to fall into the local endless loop. Furthermore, the ability of the learning strategy is stronger than that of the training model based on rules, which is of great practical values.","1004-4132","","10.23919/JSEE.2020.000006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9082307","loyalty;game theory;bi-directional coordination network;multi-agent system;learning strategy","Task analysis;Training;Games;Game theory;Bidirectional control;Multi-agent systems;Modeling","","11","","","","30 Apr 2020","","","BIAI","BIAI Journals"
"Immune multi-agent model using vaccine for cooperative air-defense system of systems for surface warship formation based on danger theory","J. Wang; X. Zhao; B. Xu; W. Wang; Z. Niu","School of Electronic & Information, Northwestern Polytechnical University, Xi'an 710072, China; Department of Missile, Dalian Naval Academy, Dalian 116018, China; School of Electronic & Information, Northwestern Polytechnical University, Xi'an 710072, China; Institute of Operational Software and Simulation, Dalian Naval Academy, Dalian 116018, China; Department of Equipment, Unit 92896 of the PLA Navy, Dalian 116018, China; Department of Naval Gun, Dalian Naval Academy, Dalian 116018, China; Department of Information Operations, Dalian Naval Academy, Dalian 116018, China",Journal of Systems Engineering and Electronics,"5 Mar 2014","2013","24","6","946","953","Aiming at the problem on cooperative air-defense of surface warship formation, this paper maps the cooperative air-defense system of systems (SoS) for surface warship formation (CASoSSWF) to the biological immune system (BIS) according to the similarity of the defense mechanism and characteristics between the CASoSSWF and the BIS, and then designs the models of components and the architecture for a monitoring agent, a regulating agent, a killer agent, a pre-warning agent and a communicating agent by making use of the theories and methods of the artificial immune system, the multi-agent system (MAS), the vaccine and the danger theory (DT). Moreover a new immune multi-agent model using vaccine based on DT (IMMUVBDT) for the cooperative air-defense SoS is advanced. The immune response and immune mechanism of the CASoSSWF are analyzed. The model has a capability of memory, evolution, commendable dynamic environment adaptability and self-learning, and embodies adequately the cooperative air-defense mechanism for the CA-SoSSWF. Therefore it shows a novel idea for the CASoSSWF which can provide conception models for a surface warship formation operation simulation system.","1004-4132","","10.1109/JSEE.2013.00111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6756016","immune multi-agent model (IMM);vaccine;surface warship formation;cooperative air-defense system of systems (CASoS);danger theory (DT)","Atmospheric modeling;Defense systems;Detectors;Multi-agent systems;Military communication","","6","","","","5 Mar 2014","","","BIAI","BIAI Journals"
"Gait Balance and Acceleration of a Biped Robot Based on Q-Learning","J. -L. Lin; K. -S. Hwang; W. -C. Jiang; Y. -J. Chen","Department of Information Management, Shih Hsin University, Taipei, Taiwan; Department of Electrical Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan; Department of Electrical Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan; Department of Electrical Engineering, National Chung Cheng University, Chiayi, Taiwan",IEEE Access,"20 May 2017","2016","4","","2439","2449","This paper presents a method for the biped dynamic walking and balance control using reinforcement learning, which learns dynamic walking without a priori knowledge about the dynamic model. The learning architecture developed is aimed to solve complex control problems in robotic actuation control by mapping the action space from a discretized domain to a continuous one. It employs the discrete actions to construct a policy for continuous action. The architecture allows for the scaling of the dimensionality of the state space and cardinality of the action set that represents new knowledge, or new requirements for a desired task. The balance learning method utilizing the motion of robot arm and leg to shift the zero moment point on the soles of a robot can maintain the biped robot in a static stable state. This balanced algorithm is applied to biped walking on a flat surface and a seesaw and is making the biped’s walks more stable. The simulation shows that the proposed method can allow the robot to learn to improve its behavior in terms of walking speed. Finally, the methods are implemented on a physical biped robot to demonstrate the feasibility and effectiveness of the proposed learning scheme.","2169-3536","","10.1109/ACCESS.2016.2570255","Most Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7471433","Reinforcement Learning;Biped Robot;Continuous Action Space;Zero Moment Point;Reinforcement learning;biped robot;continuous action space;zero moment point","Robots;Legged locomotion;Reinforcement learning;Learning systems;Artificial intelligence;Balance control;Dynamic modelds;Zero moment point","","39","","24","OAPA","18 May 2016","","","IEEE","IEEE Journals"
"A Reinforcement Learning Approach to Military Simulations in Command: Modern Operations","A. Dimitriu; T. V. Michaletzky; V. Remeli; V. R. Tihanyi","Széchenyi István University, Győr, Hungary; Széchenyi István University, Győr, Hungary; Széchenyi István University, Győr, Hungary; Széchenyi István University, Győr, Hungary",IEEE Access,"5 Jun 2024","2024","12","","77501","77513","This paper presents a Reinforcement Learning (RL) framework for Command: Modern Operations (CMO), an advanced Real Time Strategy (RTS) game that simulates military operations. CMO challenges players to navigate tactical, operational, and strategic decision-making, involving the management of multiple units, effective resource allocation, and concurrent action assignment. The primary objective of this research is automating and enhancing military decision-making, utilizing the capabilities of RL. To achieve this goal, a parameterized Proximal Policy Optimization (PPO) agent with a unique architecture has been developed, specifically designed to address the unique challenges presented by CMO. By adapting and extending methodologies from achievements in the domain, such as AlphaStar and OpenAI Five, the agent showcases the potential of RL in military simulations. Our model can handle a wide range of scenarios presented in CMO, marking a significant step towards the integration of Artificial Intelligence (AI) with military studies and practices. This research establishes the groundwork for future explorations in applying AI to defense and strategic analysis.","2169-3536","","10.1109/ACCESS.2024.3406148","Ministry of Culture and Innovation of Hungary from the National Research, Development and Innovation Fund, through the “Nemzeti Laboratóriumok pályázati program” Funding Scheme(grant numbers:2022-2.1.1-NL-2022-00012); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10540085","Reinforcement learning;military simulations;tactical and strategic AI;military decision making;command modern operations","Games;Training;Complexity theory;Artificial intelligence;Transformers;Weapons;Decision making;Reinforcement learning;Command and control systems;Military communication","","6","","31","CCBYNCND","27 May 2024","","","IEEE","IEEE Journals"
"New Approaches for Network Topology Optimization Using Deep Reinforcement Learning and Graph Neural Network","M. Ali; F. Duchesne; G. Dahman; F. Gagnon; D. Naboulsi","École de Technologie Supérieure, Montreal, QC, Canada; École de Technologie Supérieure, Montreal, QC, Canada; École de Technologie Supérieure, Montreal, QC, Canada; École de Technologie Supérieure, Montreal, QC, Canada; École de Technologie Supérieure, Montreal, QC, Canada",IEEE Access,"20 May 2025","2025","13","","85447","85460","The exponential growth in Internet-connected devices has escalated the demand for optimized network topologies to ensure high performance. Traditional optimization methods often fall short in scalability and adaptability when it comes to network topology planning. In this paper, we address the challenge of transforming mesh topologies into tree topologies for wireless networks, with the objective of maximizing throughput. We propose two new methods: Path Selection with Rejection Strategy (PSRS), which leverages Message-Passing Neural Networks (MPNN), and Dual-Agent Tree Topology Exploration (DATTE), which employs Graph Attention Networks (GAT). These schemes integrate Deep Reinforcement Learning (DRL) and Graph Neural Networks (GNNs) to construct efficient tree topologies with the goal of maximizing the minimum throughput of the wireless network. Experimental results validate the scalability and performance gains of the proposed approaches, highlighting their potential for real-world applications.","2169-3536","","10.1109/ACCESS.2025.3569236","Mitacs/Ultra Intelligence and Communications(grant numbers:IT25839); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11000124","Deep reinforcement learning;graph neural networks;proximal policy optimization;tree topology;wireless network","Network topology;Topology;Optimization;Throughput;Graph neural networks;Wireless networks;Scalability;Planning;Deep reinforcement learning;Computer architecture","","","","48","CCBY","12 May 2025","","","IEEE","IEEE Journals"
"An Organizational Structure and Self-Adaptive Mechanism for Holonic Multi-Agent Systems","M. Wang; Q. Li; Y. Lin","School of Computer Science and Technology, Xidian University, Xi’an, China; School of Computer Science and Technology, Xidian University, Xi’an, China; School of Computer Science and Technology, Xidian University, Xi’an, China",IEEE Access,"14 Aug 2020","2020","8","","145128","145148","A holonic multi-agent system combines the concept of a holon with a multi-agent system; this combination has been proven to be an effective way to build a complex system. Great progress has been made in this area, but previous studies are fragmented and lack of a task-based perspective to model different systems in the real world. Therefore, this article proposes a formalistic model for HMAS from a task-based perspective. Not only the static organizational structure is designed, but also the dynamic running mechanism, including the self-adaptive mechanism and the task assignment mechanism based on the proposed holonic structure, are also discussed. Finally, a case study is provided to verify the self-adaptive mechanism. The experimental results show that our proposed DHMAS has the ability to adapt to the changing environment, and performs better in terms of the success rate and the response time when the system is heavily loaded.","2169-3536","","10.1109/ACCESS.2020.3014694","National Natural Science Foundation of China(grant numbers:61972300,61902288,61672401,61373045); Pre-Research Project of the Thirteenth Five-Year-Plan of China(grant numbers:315***10101,315**0102); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9160943","Holonic multi-agent system;multi-agent system;organizational structure;self-adaptive mechanism;task-based perspective","Task analysis;Multi-agent systems;Software systems;Complex systems;Organizations;Computer architecture;Adaptation models","","3","","35","CCBY","6 Aug 2020","","","IEEE","IEEE Journals"
"Exploring Neural Architecture Search Space via Deep Deterministic Sampling","K. G. Mills; M. Salameh; D. Niu; F. X. Han; S. S. C. Rezaei; H. Yao; W. Lu; S. Lian; S. Jui","Department of Electrical and Computer Engineering, University of Alberta, Edmonton, AB, Canada; Huawei Technologies Canada Company Ltd., Edmonton, AB, Canada; Department of Electrical and Computer Engineering, University of Alberta, Edmonton, AB, Canada; Huawei Technologies Canada Company Ltd., Edmonton, AB, Canada; Huawei Technologies Canada Company Ltd., Edmonton, AB, Canada; Huawei Technologies Canada Company Ltd., Edmonton, AB, Canada; Huawei Technologies Canada Company Ltd., Edmonton, AB, Canada; Huawei Kirin Solution, Shanghai, China; Huawei Kirin Solution, Shanghai, China",IEEE Access,"12 Aug 2021","2021","9","","110962","110974","Recent developments in Neural Architecture Search (NAS) resort to training the supernet of a predefined search space with weight sharing to speed up architecture evaluation. These include random search schemes, as well as various schemes based on optimization or reinforcement learning, in particular policy gradient, that aim to optimize a parametric architecture distribution and the shared model weights simultaneously. In this paper, we focus on efficiently exploring the important region of a neural architecture search space with reinforcement learning. We propose Deep Deterministic Architecture Sampling (DDAS) based on deep deterministic policy gradient and the actor-critic framework, to selectively sample important architectures in the supernet for training. Through balancing exploitation and exploration, DDAS is designed to combat the disadvantages of prior random supernet warm-up schemes and optimization schemes. Gradient-based NAS approaches require the execution of multiple short experiments in order to combat the random stochastic nature of gradient descent, while still only producing a single architecture. Contrary to this approach, DDAS employs a reinforcement learning-based agent and focuses on discovering a Pareto frontier containing many architectures over the course of a single experiment requiring 1 GPU day. Experimental results for CIFAR-10 and CIFAR-100 on the DARTS search space show that DDAS can depict in a single search, the accuracy-FLOPs (or model size) Pareto frontier, which outperforms random sampling and search. With a test accuracy of 97.27%, the best architecture found on CIFAR-10 outperforms the original second-order DARTS while using 600M fewer parameters. Additionally, DDAS finds an architecture capable of achieving 82.00% test accuracy on CIFAR-100 while using only 3.14M parameters and outperforming GDAS.","2169-3536","","10.1109/ACCESS.2021.3101975","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9503404","Neural architecture search;reinforcement learning;differentiable optimization","Computer architecture;Optimization;Training;Reinforcement learning;Search problems;Stochastic processes;Graphics processing units","","7","","38","CCBY","2 Aug 2021","","","IEEE","IEEE Journals"
"Distributed Collaborative Complete Coverage Path Planning Based on Hybrid Strategy","J. Zhang; X. Du; Q. Dong; B. Xin","School of Automation, Beijing Institute of Technology, Beijing, China; School of Automation, Beijing Institute of Technology, Beijing, China; School of Automation, Beijing Institute of Technology, Beijing, China; School of Automation, Beijing Institute of Technology, Beijing, China",Journal of Systems Engineering and Electronics,"14 May 2024","2024","35","2","463","472","Collaborative coverage path planning (CCPP) refers to obtaining the shortest paths passing over all places except obstacles in a certain area or space. A multi-unmanned aerial vehicle (UAV) collaborative CCPP algorithm is proposed for the urban rescue search or military search in outdoor environment. Due to flexible control of small UAVs, it can be considered that all UAVs fly at the same altitude, that is, they perform search tasks on a two-dimensional plane. Based on the agents' motion characteristics and environmental information, a mathematical model of CCPP problem is established. The minimum time for UAVs to complete the CCPP is the objective function, and complete coverage constraint, no-fly constraint, collision avoidance constraint, and communication constraint are considered. Four motion strategies and two communication strategies are designed. Then a distributed CCPP algorithm is designed based on hybrid strategies. Simulation results compared with pattern-based genetic algorithm (PBGA) and random search method show that the proposed method has stronger real-time performance and better scalability and can complete the complete CCPP task more efficiently and stably.","1004-4132","","10.23919/JSEE.2023.000118","National Natural Science Foundation of China(grant numbers:61903036,61822304); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10272321","multi-agent cooperation;unmanned aerial vehicles (UAV);distributed algorithm;complete coverage path planning (CCPP)","Autonomous aerial vehicles;Task analysis;Path planning;Lenses;Collaboration;Simulation;Search methods","","4","","22","","4 Oct 2023","","","BIAI","BIAI Journals"
"A Framework for Enhancing the Operational Phase of Traffic Management Plans","L. A. García; V. R. Tomás","Department of Computer Science and Engineering, Universitat Jaume I, Castellón de la Plana, Spain; Department of Computer Science and Engineering, Universitat Jaume I, Castellón de la Plana, Spain",IEEE Access,"18 Nov 2020","2020","8","","204483","204493","Road traffic emergencies are dangerous and unexpected situations that require immediate actions by the authorities. These actions involve to attend to the people who have been affected by the emergency and to minimize its consequences. A Traffic Management Plan (TMP) is a set of pre-defined measures and actions designed to produce an effective and efficient use of available resources in order to deal with a specific road incident. The operational phase of a TMP involves the coordination of several independent agencies (road managers, traffic police, firemen, etc.). These agencies must provide the resources required by the TMP in the deployment of the measures and actions. In this paper, a new framework to support the TMP operational phase is presented. This framework models each agency as an intelligent agent and it uses a reverse combinatorial distributed auction as the core component of a negotiation process. The goal of this negotiation process is to obtain a common agreement on the best possible allocation of resources taking into account the role, competencies and interest of the involved agencies. The framework has been implemented in a real scenario with real data. The tests developed have demonstrated that the system is able to manage the resources in terms of the execution time and the quality of the provided solutions.","2169-3536","","10.1109/ACCESS.2020.3036492","project Study and Analysis from a Connected Framework for the Autonomous and Dynamic of Alternative Road Traffic Itineraries funded by Universitat Jaume I; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9250493","Intelligent transport systems;multiagent systems;negotiation protocols","Roads;Accidents;Resource management;Current measurement;Protocols;Law enforcement;Cost accounting","","3","","32","CCBY","6 Nov 2020","","","IEEE","IEEE Journals"
"Automatic Spoken Language Acquisition Based on Observation and Dialogue","R. Komatsu; S. Gao; W. Hou; M. Zhang; T. Tanaka; K. Toyoda; Y. Kimura; K. Hino; Y. Iwamoto; K. Mori; T. Okamoto; T. Shinozaki","Tokyo Institute of Technology, Meguro, Tokyo, Japan; Tokyo Institute of Technology, Meguro, Tokyo, Japan; Tokyo Institute of Technology, Meguro, Tokyo, Japan; Tokyo Institute of Technology, Meguro, Tokyo, Japan; Tokyo Institute of Technology, Meguro, Tokyo, Japan; Tokyo Institute of Technology, Meguro, Tokyo, Japan; Tokyo Institute of Technology, Meguro, Tokyo, Japan; Tokyo Institute of Technology, Meguro, Tokyo, Japan; Tokyo Institute of Technology, Meguro, Tokyo, Japan; Tokyo Institute of Technology, Meguro, Tokyo, Japan; National Institute of Information and Communications Technology, Koganei, Tokyo, Japan; Tokyo Institute of Technology, Meguro, Tokyo, Japan",IEEE Journal of Selected Topics in Signal Processing,"18 Oct 2022","2022","16","6","1480","1492","Human babies are born without knowledge of any specific language. They acquire language directly from observation and dialogue without being limited by the availability of labeled data. We propose spoken language acquisition agents that simulate the process. Such an ability requires multiple types of learning, including 1) word discovery, 2) symbol grounding, 3) message generation, and 4) pronunciation generation. Several studies have targeted one or combined learning types to elucidate human intelligence and aimed to equip spoken dialogue systems with human-like flexible language learning ability. However, their language ability was partially lacking some of the components. Our agents are the first to integrate them all. Our key concept is to design an architecture to integrate unsupervised, self-supervised, and reinforcement learning to utilize clues naturally existing in raw sensory signals and drive the learning based on the agent’s intrinsic motivation. Experimental results show agents successfully acquire spoken language from scratch by interacting with an environment to act by speaking. Our proposed focusing mechanism significantly improves learning efficiency. We also demonstrate that our agents can learn neural vocoder and the concept of logical negation as a part of language acquisition.","1941-0484","","10.1109/JSTSP.2022.3189279","Toray Science Foundation; JSPS KAKENHI(grant numbers:JP22K12069); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9817627","Autonomous agent;reinforcement learning;self-supervised learning;spoken language acquisition;unsupervised learning","Vocabulary;Speech recognition;Self-supervised learning;Reinforcement learning;Autonomous agents;Unsupervised learning","","2","","53","CCBY","7 Jul 2022","","","IEEE","IEEE Journals"
"Cooperative Reinforcement Learning for Energy Management in Multi-Hop Networks With Energy Harvesting","H. Dutta; A. K. Bhuyan; S. Biswas","Electrical and Computer Engineering Department, Michigan State University, East Lansing, USA; Electrical and Computer Engineering Department, Michigan State University, East Lansing, USA; Electrical and Computer Engineering Department, Michigan State University, East Lansing, USA",IEEE Transactions on Green Communications and Networking,"","2025","PP","99","1","1","This paper proposes a Reinforcement Learning (RL) framework for joint transmit-sleep scheduling for multi-hops wireless sensor and IoT networks with energy harvesting. The goal of the framework is to learn situation-specific scheduling policies for reducing energy expenditure, while maintaining network performance in terms of packet delivery ratio and end-to-end delay. The proposed system uses a cooperative RL approach where two learning agents, deployed per node, jointly learn transmit and sleep scheduling strategies to manage network energy budgets. The RL framework also uses a localized learning confidence parameter sharing strategy that allows the nodes to ignore unreliable RL observations. This makes the system scalable for network topologies where the source and destination nodes are separated by many numbers of hops. The learning module is decentralized in that learning is independently carried out at the sensor/IoT nodes without relying on a central learning coordinator. Decentralized learning makes the system computationally efficient, and also avoids energy and communication bandwidth overhead usually imposed by a central coordinator. With simulation studies, the proposed learning-driven protocol is tested and compared against existing known MAC sleep schedulers. The proposed mechanism is validated for different scenarios with heterogeneous topologies, traffic, and energy harvesting conditions.","2473-2400","","10.1109/TGCN.2025.3544073","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10896715","Energy-harvesting;Sleep Scheduling;Transmission Scheduling;Reinforcement Learning;Cooperative Learning","Network topology;Topology;Processor scheduling;Job shop scheduling;Reinforcement learning;Batteries;Wireless sensor networks;Stars;Dynamic scheduling;Computer architecture","","1","","","CCBY","20 Feb 2025","","","IEEE","IEEE Early Access Articles"
"CASOA: An Architecture for Agent-Based Manufacturing System in the Context of Industry 4.0","H. Tang; D. Li; S. Wang; Z. Dong","School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China; School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China; School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China; School of Automation Science and Engineering, South China University of Technology, Guangzhou, China",IEEE Access,"19 Mar 2018","2018","6","","12746","12754","The fourth industrial revolution involves the advanced topics, such as industrial Internet of Things, cyber-physical system and smart manufacturing that address increasing demands for mass customized manufacturing. The agent-based manufacturing is a highly distributed control paradigm that can cope with these challenges well. This paper gives an overview of agent-based architectures for manufacturing systems. Besides, a cloud-assisted self-organized architecture is presented by comprising smart agents and cloud to communicate and negotiate through networks. Ontological representations of knowledge base are constructed to provide the information basis for decision-making of agents, which enables dynamic reconfiguration among agents in a collaborative way to achieve agility and flexibility. Furthermore, the agents' interaction behavior is modeled to structure the agents hierarchically to reduce the complexity, because the interactions among agents in distributed system are difficult to understand and predict. The experimental results show that the presented architecture can be easily deployed to build smart manufacturing system and can improve the adaptiveness and robustness of the manufacturing system when dealing with mixed multi-product tasks.","2169-3536","","10.1109/ACCESS.2017.2758160","National Natural Science Foundation of China(grant numbers:51605168); Natural Science Foundation of Guangdong Province(grant numbers:2015A030308002); Science and Technology Planning Project of Guangdong Province(grant numbers:2015B010917001); Fundamental Research Funds for the Central Universities(grant numbers:2017MS016); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8053743","Multi-agent system;industry 4.0;ontology;smart manufacturing","Ontologies;Knowledge based systems;Job shop scheduling;Machining;Manufacturing systems","","75","","23","OAPA","29 Sep 2017","","","IEEE","IEEE Journals"
"Control Systems for Low-Inertia Power Grids: A Survey on Virtual Power Plants","D. E. Ochoa; F. Galarza-Jimenez; F. Wilches-Bernal; D. A. Schoenwald; J. I. Poveda","Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical, Computer and Energy Engineering, University of Colorado, Boulder, CO, USA; Sandia National Laboratories, Albuquerque, NM, USA; Sandia National Laboratories, Albuquerque, NM, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA",IEEE Access,"6 Mar 2023","2023","11","","20560","20581","Virtual Power Plants (VPPs) have emerged as a modern real-time energy management architecture that seeks to synergistically coordinate an aggregation of renewable and non-renewable generation systems to overcome some of the fundamental limitations of traditional power grids dominated by synchronous machines. In this survey paper, we review the different existing and emerging feedback control mechanisms and architectures used for the real-time operation of VPPs. In contrast to other works that have mostly focused on the optimal dispatch and economical aspects of VPPs in the hourly and daily time scales, in this paper we focus on the dynamic nature of the system during the faster sub-hourly time scales. The virtual (i.e., software-based) component of a VPP, combined with the power plant (i.e., physics-based) components of the power grid, make VPPs prominent examples of cyber-physical systems, where both continuous-time and discrete-time dynamics play critical roles in the stability and transient properties of the system. We elaborate on this interpretation of VPPs as hybrid dynamical systems, and we further discuss open research problems and potential research directions in feedback control systems that could contribute to the safe development and deployment of autonomous VPPs.","2169-3536","","10.1109/ACCESS.2023.3249151","U.S. Department of Energy’s (DOE) National Nuclear Security Administration(grant numbers:DE-NA0003525); Grid Modernization Laboratory Consortium (GMLC) Program; National Science Foundation(grant numbers:CAREER ECCS 2305756); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10054041","Smart grids;renewable energy;virtual power plant;feedback control;multi-agent hybrid dynamical systems","Power system dynamics;Renewable energy sources;Power grids;Heuristic algorithms;Power system stability;Feedback control;Virtual power plants","","41","","314","CCBYNCND","27 Feb 2023","","","IEEE","IEEE Journals"
"ICRAN: Intelligent Control for Self-Driving RAN Based on Deep Reinforcement Learning","A. H. Ahmed; A. Elmokashfi","Center for Resilient Networks and Applications, Simula Metropolitan Center for Digital Engineering, Oslo, Norway; Center for Resilient Networks and Applications, Oslo Metropolitan University, Oslo, Norway",IEEE Transactions on Network and Service Management,"12 Oct 2022","2022","19","3","2751","2766","Mobile networks are increasingly expected to support use cases with diverse performance expectations at a very high level of reliability. These expectations imply the need for approaches that timely detect and correct performance problems. However, current approaches often focus on optimizing a single performance metric. Here, we aim to address this gap by proposing a novel control framework that maximizes radio resources utilization and minimizes performance degradation in the most challenging part of cellular architecture that is the radio access network (RAN). We devise a method called Intelligent Control for Self-driving RAN (ICRAN) which involves two deep reinforcement learning based approaches that control the RAN in a centralized and a distributed way, respectively. ICRAN defines a dual-objective optimization goals that are achieved through a set of diverse control actions. Using extensive discrete event simulations, we confirm that ICRAN succeeds in achieving its design goals, showing a greater edge over competing approaches. We believe that ICRAN is implementable and can serve as an important point on the way to realizing self-driving mobile networks.","1932-4537","","10.1109/TNSM.2022.3191746","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9831432","Self-driving network;slicing;RAN;resource allocation;performance optimization;deep reinforcement learning;ns-3 simulation;DDPG","Resource management;Reinforcement learning;Base stations;Software;Reliability;Optimization;Cloud computing","","7","","55","CCBY","18 Jul 2022","","","IEEE","IEEE Journals"
"Training Agents With Interactive Reinforcement Learning and Contextual Affordances","F. Cruz; S. Magg; C. Weber; S. Wermter","Knowledge Technology Group, Department of Informatics, University of Hamburg, Hamburg, Germany; Knowledge Technology Group, Department of Informatics, University of Hamburg, Hamburg, Germany; Knowledge Technology Group, Department of Informatics, University of Hamburg, Hamburg, Germany; Knowledge Technology Group, Department of Informatics, University of Hamburg, Hamburg, Germany",IEEE Transactions on Cognitive and Developmental Systems,"20 May 2017","2016","8","4","271","284","In the future, robots will be used more extensively as assistants in home scenarios and must be able to acquire expertise from trainers by learning through crossmodal interaction. One promising approach is interactive reinforcement learning (IRL) where an external trainer advises an apprentice on actions to speed up the learning process. In this paper we present an IRL approach for the domestic task of cleaning a table and compare three different learning methods using simulated robots: 1) reinforcement learning (RL); 2) RL with contextual affordances to avoid failed states; and 3) the previously trained robot serving as a trainer to a second apprentice robot. We then demonstrate that the use of IRL leads to different performance with various levels of interaction and consistency of feedback. Our results show that the simulated robot completes the task with RL, although working slowly and with a low rate of success. With RL and contextual affordances fewer actions are needed and can reach higher rates of success. For good performance with IRL it is essential to consider the level of consistency of feedback since inconsistencies can cause considerable delay in the learning process. In general, we demonstrate that interactive feedback provides an advantage for the robot in most of the learning cases.","2379-8939","","10.1109/TCDS.2016.2543839","Universidad Central de Chile; Comisión Nacional de Investigación Científica y Tecnológica Scholarship(grant numbers:5043); German Research Foundation DFG; Hamburg Landesforschungsförderungsprojekt CROSS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7458195","Contextual affordances;developmental robotics;domestic cleaning scenario;interactive reinforcement learning (IRL);policy shaping","Learning (artificial intelligence);Service robots;Cognitive robotics;Psychology;Training","","72","","58","CCBY","22 Apr 2016","","","IEEE","IEEE Journals"
"Optimization of a Cluster-Based Energy Management System Using Deep Reinforcement Learning Without Affecting Prosumer Comfort: V2X Technologies and Peer-to-Peer Energy Trading","M. Yavuz; Ö. C. Kivanç","Department of Electrical and Electronics Engineering, Istanbul Okan University, İstanbul, Turkey; Department of Electrical and Electronics Engineering, Istanbul Okan University, İstanbul, Turkey",IEEE Access,"5 Mar 2024","2024","12","","31551","31575","The concept of Prosumer has enabled consumers to actively participate in Peer-to-Peer (P2P) energy trading, particularly as Renewable Energy Source (RES)s and Electric Vehicle (EV)s have become more accessible and cost-effective. In addition to the P2P energy trading, prosumers benefit from the relatively high energy capacity of EVs through the integration of Vehicle-to-X (V2X) technologies, such as Vehicle-to-Home (V2H), Vehicle-to-Load (V2L), and Vehicle-to-Grid (V2G). Optimization of an Energy Management System (EMS) is required to allocate the required energy efficiently within the cluster, due to the complex pricing and energy exchange mechanism of P2P energy trading and multiple EVs with V2X technologies. In this paper, Deep Reinforcement Learning (DRL) based EMS optimization method is proposed to optimize the pricing and energy exchanging mechanisms of the P2P energy trading without affecting the comfort of prosumers. The proposed EMS is applied to a small-scale cluster-based environment, including multiple (6) prosumers, P2P energy trading with novel hybrid pricing and energy exchanging mechanisms, and V2X technologies (V2H, V2L, and V2G) to reduce the overall energy costs and increase the Self-Sufficiency Ratio (SSR)s. Multi Double Deep Q-Network (DDQN) agents based DRL algorithm is implemented and the environment is formulated as a Markov Decision Process (MDP) to optimize the decision-making process. Numerical results show that the proposed EMS reduces the overall energy costs by 19.18%, increases the SSRs by 9.39%, and achieves an overall 65.87% SSR. Additionally, numerical results indicates that model-free DRL, such as DDQN agent based Deep Q-Network (DQN) Reinforcement Learning (RL) algorithm, promise to eliminate the energy management complexities with multiple uncertainties.","2169-3536","","10.1109/ACCESS.2024.3370922","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10452350","Energy management system;peer-to-peer energy trading;vehicle-to-home;multi-agent reinforcement learning;deep reinforcement learning;smart grids","Costs;Optimization;Energy management;Vehicle-to-grid;Clustering algorithms;Heuristic algorithms;Vehicle-to-everything;Peer-to-peer computing;Energy exchange;Reinforcement learning;Deep reinforcement learning;Smart grids","","15","","143","CCBYNCND","27 Feb 2024","","","IEEE","IEEE Journals"
"RLOps: Development Life-Cycle of Reinforcement Learning Aided Open RAN","P. Li; J. Thomas; X. Wang; A. Khalil; A. Ahmad; R. Inacio; S. Kapoor; A. Parekh; A. Doufexi; A. Shojaeifard; R. J. Piechocki","Department of Electrical and Electronic Engineering, University of Bristol, Bristol, U.K; Department of Electrical and Electronic Engineering, University of Bristol, Bristol, U.K; Department of Electrical and Electronic Engineering, University of Bristol, Bristol, U.K; Department of Electrical and Electronic Engineering, University of Bristol, Bristol, U.K; Vilicom U.K. Ltd., Reading, U.K; Vilicom U.K. Ltd., Reading, U.K; Applied Research, Suffolk, U.K; Applied Research, Suffolk, U.K; Department of Electrical and Electronic Engineering, University of Bristol, Bristol, U.K; InterDigital Communications Inc., Wilmington, DE, USA; Department of Electrical and Electronic Engineering, University of Bristol, Bristol, U.K",IEEE Access,"7 Nov 2022","2022","10","","113808","113826","Radio access network (RAN) technologies continue to evolve, with Open RAN gaining the most recent momentum. In the O-RAN specifications, the RAN intelligent controllers (RICs) are software-defined orchestration and automation functions for the intelligent management of RAN. This article introduces principles for machine learning (ML), in particular, reinforcement learning (RL) applications in the O-RAN stack. Furthermore, we review the state-of-the-art research in wireless networks and cast it onto the RAN framework and the hierarchy of the O-RAN architecture. We provide a taxonomy for the challenges faced by ML/RL models throughout the development life-cycle: from the system specification to production deployment (data acquisition, model design, testing and management, etc.). To address the challenges, we integrate a set of existing MLOps principles with unique characteristics when RL agents are considered. This paper discusses a systematic model development, testing and validation life-cycle, termed: RLOps. We discuss fundamental parts of RLOps, which include: model specification, development, production environment serving, operations monitoring and safety/security. Based on these principles, we propose the best practices for RLOps to achieve an automated and reproducible model development process. At last, a holistic data analytics platform rooted in the O-RAN deployment is designed and implemented, aiming to embrace and fulfil the aforementioned principles and best practices of RLOps.","2169-3536","","10.1109/ACCESS.2022.3217511","Innovate UK/CELTIC-NEXT European collaborative project on AI-enabled Massive MIMO (AIMM); Next-Generation Converged Digital Infrastructure (NG-CDI) Project; BT and Engineering and Physical Sciences Research Council (EPSRC)(grant numbers:EP/R004935/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9931127","O-RAN;machine learning;reinforcement learning;MLOps;RLOps;digital twins;data engineering","Radio access networks;Computer architecture;Reinforcement learning;Task analysis;Adaptation models;3GPP;Biological system modeling","","33","","96","CCBY","26 Oct 2022","","","IEEE","IEEE Journals"
"A Novel Multiagent Collaborative Learning Architecture for Automatic Recognition of Mudstone Rock Facies","S. Tewari; A. Prasad; H. Patel; M. Uddin; T. Al-Shehari; N. A. Alsadhan","Department of Computer Engineering and Applications, GLA University, Mathura, India; Department of Computer Engineering and Applications, GLA University, Mathura, India; Department of Data Science, Gyan Ganga Institute of Technology and Sciences, Jabalpur, India; College of Computing and Information Technology, University of Doha for Science and Technology, Doha, Qatar; Department of Self-Development Skill, Common First Year Deanship, King Saud University, Riyadh, Saudi Arabia; Computer Science Department, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia",IEEE Access,"5 Dec 2024","2024","12","","179144","179163","Recognizing mud rock lithofacies is essential for mapping the subsurface depositional environments and identifying oil and gas-bearing rock formations. Conventional well logs interpretation techniques are slow, costly and require high domain expertise. Machine learning (ML) techniques have been implemented to automate the recognition of lithofacies from the bulk of well logs generated. However, the reservoir heterogeneity and uneven thickness of rock layers result in imbalanced data conditions that make the ML models biased. This study proposes a novel multiagent collaborative learning architecture (MCLA) to handle the imbalanced data problem during the identification of lithofacies. This research investigates four popular data resampling techniques, i.e. oversampling, SMOTE and ADASYN. Also, resampling techniques are combined with nine different ML classifiers, including Decision tree, ExtraTree, Random Forest, Logistic regression, Support vector machine, K-nearest Neighbour, Naïve Bayes and Ensemble methods. Stacking and voting ensembles combine the outcomes of diverse classifiers working as team members in MCLA. ADASYN, in combination with Stacking, has produced impressive results in terms of accuracy (99.41%) along with MCC (0.98) and G-mean (0.98). The proposed MCLA shows an enhancement of 2% in lithofacies accuracy and an approximately 4% increment in reliability compared with the top-performing Extra Tree classifier considered in this study.","2169-3536","","10.1109/ACCESS.2024.3507569","King Saud University, Riyadh, Saudi Arabia, through the Researchers Supporting Project(grant numbers:RSPD2024R846); Qatar National Library QNL; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10769432","Data imbalance;resampling techniques;machine learning;stacked generalization;multiagent collaborative learning","Reservoirs;Data models;Rocks;Support vector machines;Oils;Federated learning;Ensemble learning;Accuracy;Training data;Training","","6","","73","CCBY","27 Nov 2024","","","IEEE","IEEE Journals"
"StomachNet: Optimal Deep Learning Features Fusion for Stomach Abnormalities Classification","M. A. Khan; M. S. Sarfraz; M. Alhaisoni; A. A. Albesher; S. Wang; I. Ashraf","Department of Computer Science, HITEC University, Taxila, Pakistan; Department of Computer Science, National University of Computer and Emerging Sciences at Chiniot–Faisalabad Campus, Chiniot, Pakistan; College of Computer Science and Engineering, University of Ha’il, Ha’il, Saudi Arabia; College of Computing and Informatics, Saudi Electronic University, Riyadh, Saudi Arabia; Department of Mathematics, University of Leicester, Leicester, U.K.; Department of Computer Science, HITEC University, Taxila, Pakistan",IEEE Access,"6 Nov 2020","2020","8","","197969","197981","A fully automated design is proposed in this work employing optimal deep learning features for classifying gastrointestinal infections. Here, three prominent infections– ulcer, bleeding, polyp and a healthy class are considered as class labels. In the initial stage, the contrast is improved by fusing bi-directional histogram equalization with top-hat filtering output. The resultant fusion images are then passed to ResNet101 pre-trained model and trained once again using deep transfer learning. However, there are challenges involved in extracting deep learning features including impertinent information and redundancy. To mitigate this problem, we took advantage of two metaheuristic algorithms– Enhanced Crow Search and Differential Evolution. These algorithms are implemented in parallel to obtain optimal feature vectors. Following this, a maximum correlation-based fusion approach is applied to fuse optimal vectors from the previous step to obtain an enhanced vector. This final vector is given as input to Extreme Learning Machine (ELM) classifier for final classification. The proposed method is evaluated on a combined database. It accomplished an accuracy of 99.46%, which shows significant improvement over preceding techniques and other neural network architectures.","2169-3536","","10.1109/ACCESS.2020.3034217","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9240940","Stomach infections;contrast stretching;deep learning;optimization;fusion","Deep learning;Stomach;Databases;Transfer learning;Termination of employment;Computer architecture;Predictive models;Gastrointestinal tract;Classification algorithms;Biomedical monitoring","","88","","43","CCBY","27 Oct 2020","","","IEEE","IEEE Journals"
"Toward Interactive Music Generation: A Position Paper","S. Dadman; B. A. Bremdal; B. Bang; R. Dalmo","Department of Computer Science, UiT The Arctic University of Norway, Narvik, Norway; Department of Computer Science, UiT The Arctic University of Norway, Narvik, Norway; Department of Computer Science, UiT The Arctic University of Norway, Narvik, Norway; Department of Computer Science, UiT The Arctic University of Norway, Narvik, Norway",IEEE Access,"6 Dec 2022","2022","10","","125679","125695","Music generation using deep learning has received considerable attention in recent years. Researchers have developed various generative models capable of imitating musical conventions, comprehending the musical corpora, and generating new samples based on the learning outcome. Although the samples generated by these models are persuasive, they often lack musical structure and creativity. For instance, a vanilla end-to-end approach, which deals with all levels of music representation at once, does not offer human-level control and interaction during the learning process, leading to constrained results. Indeed, music creation is a recurrent process that follows some principles by a musician, where various musical features are reused or adapted. On the other hand, a musical piece adheres to a musical style, breaking down into precise concepts of timbre style, performance style, composition style, and the coherency between these aspects. Here, we study and analyze the current advances in music generation using deep learning models through different criteria. We discuss the shortcomings and limitations of these models regarding interactivity and adaptability. Finally, we draw the potential future research direction addressing multi-agent systems and reinforcement learning algorithms to alleviate these shortcomings and limitations.","2169-3536","","10.1109/ACCESS.2022.3225689","UiT The Arctic University of Norway Ph.D. Scholarship Program; Norwegian Government; UiT The Arctic University of Norway; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9966445","Deep learning;multi-agent systems;music composition;music creativity;music generation;music information retrieval;neural networks;reinforcement learning","Music;Deep learning;Task analysis;Mathematical models;Computational modeling;Computer architecture;Transformers","","5","","151","CCBY","30 Nov 2022","","","IEEE","IEEE Journals"
"Optimizing Parallel Task Execution for Multi-Agent Mission Planning","B. Miloradović; B. Çürüklü; M. Ekström; A. V. Papadopoulos","Division of Intelligent Future Technologies, Mälardalen University, Västerås, Sweden; Division of Intelligent Future Technologies, Mälardalen University, Västerås, Sweden; Division of Intelligent Future Technologies, Mälardalen University, Västerås, Sweden; Division of Intelligent Future Technologies, Mälardalen University, Västerås, Sweden",IEEE Access,"16 Mar 2023","2023","11","","24367","24381","Multi-agent systems have received a tremendous amount of attention in many areas of research and industry, especially in robotics and computer science. With the increased number of agents in missions, the problem of allocation of tasks to agents arose, and it is one of the most fundamental classes of problems in robotics, formally known as the Multi-Robot Task Allocation (MRTA) problem. MRTA encapsulates numerous problem dimensions, and it aims at providing formulations and solutions to various problem configurations, i.e., complex multi-agent missions. One dimension of the MRTA problem has not caught much of the research attention. In particular, problem configurations including Multi-Task (MT) robots have been neglected. However, the increase in computational power, in robotic systems, has allowed the utilization of parallel task execution. This in turn had the benefit of allowing the creation of more complex robotic missions; however, it came at the cost of increased problem complexity. Our contribution to the aforementioned domain can be grouped into three categories. First, we model the problem using two different approaches, Integer Linear Programming and Constraint Programming. With these models, we aim at filling the gap in the literature related to the formal definition of MT robot problem configuration. Second, we introduce the distinction between physical and virtual tasks and their mutual relationship in terms of parallel task execution. This distinction allows the modeling of a wider range of missions while exploiting possible parallel task execution. Finally, we provide a comprehensive performance analysis of both models, by implementing and validating them in CPLEX and CP Optimizer on the set of problems. Each problem consists of the same set of test instances gradually increasing in complexity, while the percentage of virtual tasks in each problem is different. The analysis of the results includes exploration of the scalability of both models and solvers, the effect of virtual tasks on the solvers’ performance, and overall solution quality.","2169-3536","","10.1109/ACCESS.2023.3254900","Swedish Research Council (VR), through the Project Pervasive Self-Optimizing Computing Infrastructure (PSI); Knowledge Foundation (KKS), through the Project Dependable Platforms for Autonomous Systems and Control (DPAC) and Project Federated Choreography of an Integrated Embedded Systems Software Architecture (FIESTA); European Commission, through the Project Aggregated Farming in the Cloud (AFarCloud); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10064332","Multi-agent mission planning;multi-robot task allocation;parallel task execution;integer linear programming;constraint programming","Task analysis;Robots;Planning;Taxonomy;Resource management;Complexity theory;Analytical models","","9","","32","CCBY","9 Mar 2023","","","IEEE","IEEE Journals"
"Reinforcement Learning-Driven Intelligent Monitoring for Data Integrity in Smart Electricity Fee Channels","X. Zheng; S. Du; J. Ye; H. Hong; Y. Shen; X. Qian; X. Lin","State Grid Fujian Marketing Service Center (Metering Center and Integrated Capital Center), Fujian, China; State Grid Fujian Marketing Service Center (Metering Center and Integrated Capital Center), Fujian, China; State Grid Fujian Marketing Service Center (Metering Center and Integrated Capital Center), Fujian, China; State Grid Fujian Marketing Service Center (Metering Center and Integrated Capital Center), Fujian, China; State Grid Fujian Marketing Service Center (Metering Center and Integrated Capital Center), Fujian, China; State Grid Fujian Marketing Service Center (Metering Center and Integrated Capital Center), Fujian, China; State Grid Fujian Marketing Service Center (Metering Center and Integrated Capital Center), Fujian, China",Journal of Web Engineering,"17 Nov 2025","2025","24","7","1103","1132","Ensuring data integrity in Web-based electricity fee channels is increasingly challenging due to dynamic energy data, complex topologies, and the rigidity of static monitoring mechanisms. This paper introduces a novel RL-driven monitoring framework, embedded in a modular, standards-compliant Web architecture, that autonomously detects and mitigates data integrity issues in real time. The proposed framework integrates a deep Q-learning agent with semantic metadata pipelines and RESTful microservices to dynamically adjust detection thresholds, refine anomaly classification policies, and incorporate human feedback into its learning loop. Unlike conventional rule-based systems, the RL agent continuously refines its decision policy through real-time interaction with dynamic data streams and operator feedback. Extensive experiments conducted on emulated smart grid datasets demonstrate the system's practical benefits: a 20% absolute increase in anomaly detection accuracy (from 75% to 95%), a 53% reduction in false positive rate (from 15% to 7%), and a stable average detection latency of 240 ms, all without human-in-the-loop reconfiguration. The RL agent also demonstrates stable convergence and linear scalability, making it well-suited for growing smart grid infrastructures. The system also incorporates a Web-native dashboard that visualizes time-aligned energy consumption and anomaly events while enabling real-time operator feedback, which further optimizes the learning trajectory. These results highlight the feasibility and effectiveness of embedding adaptive, self-optimizing learning agents directly into Web-based infrastructure to ensure long-term data integrity, transparency, and operational resilience. The proposed framework contributes to advancing intelligent Web engineering practices and lays the groundwork for scalable, autonomous monitoring solutions across a wide range of data-intensive infrastructure domains.","1544-5976","","10.13052/jwe1540-9589.2474","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11251115","Web-based monitoring;reinforcement learning;anomaly detection;data integrity;smart energy systems;adaptive Web applications","Adaptive systems;Data integrity;Electricity;Scalability;Real-time systems;Human in the loop;Smart grids;Monitoring;Anomaly detection;Resilience","","","","24","","17 Nov 2025","","","River Publishers","River Publishers Journals"
"Dif-MAML: Decentralized Multi-Agent Meta-Learning","M. Kayaalp; S. Vlaski; A. H. Sayed","Adaptive Systems Laboratory, École Polytechnique Fédérale de Lausanne, Lausanne, Switzerland; Department of Electrical and Electronic Engineering, Imperial College London, London, U.K.; Adaptive Systems Laboratory, École Polytechnique Fédérale de Lausanne, Lausanne, Switzerland",IEEE Open Journal of Signal Processing,"4 Feb 2022","2022","3","","71","93","The objective of meta-learning is to exploit knowledge obtained from observed tasks to improve adaptation to unseen tasks. Meta-learners are able to generalize better when they are trained with a larger number of observed tasks and with a larger amount of data per task. Given the amount of resources that are needed, it is generally difficult to expect the tasks, their respective data, and the necessary computational capacity to be available at a single central location. It is more natural to encounter situations where these resources are spread across several agents connected by some graph topology. The formalism of meta-learning is actually well-suited for this decentralized setting, where the learner benefits from information and computational power spread across the agents. Motivated by this observation, we propose a cooperative fully-decentralized multi-agent meta-learning algorithm, referred to as Diffusion-based MAML or Dif-MAML. Decentralized optimization algorithms are superior to centralized implementations in terms of scalability, robustness, avoidance of communication bottlenecks, and privacy guarantees. The work provides a detailed theoretical analysis to show that the proposed strategy allows a collection of agents to attain agreement at a linear rate and to converge to a stationary point of the aggregate MAML objective even in non-convex environments. Simulation results illustrate the theoretical findings and the superior performance relative to the traditional non-cooperative setting.","2644-1322","","10.1109/OJSP.2021.3140000","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669064","Decentralized optimization;diffusion algorithm;distributed learning;learning to learn;meta-learning;multi-agent systems;networked agents","Task analysis;Adaptation models;Data models;Signal processing algorithms;Signal processing;Optimization;Biological system modeling","","25","","52","CCBY","4 Jan 2022","","","IEEE","IEEE Journals"
"NeBula: TEAM CoSTAR's Robotic Autonomy Solution that Won Phase II of DARPA Subterranean Challenge","A. Agha; K. Otsu; B. Morrell; D. D. Fan; R. Thakker; A. Santamaria-Navarro; S. -K. Kim; A. Bouman; X. Lei; J. Edlund; M. F. Ginting; K. Ebadi; M. Anderson; T. Pailevanian; E. Terry; M. Wolf; A. Tagliabue; T. S. Vaquero; M. Palieri; S. Tepsuporn; Y. Chang; A. Kalantari; F. Chavez; B. Lopez; N. Funabiki; G. Miles; T. Touma; A. Buscicchio; J. Tordesillas; N. Alatur; J. Nash; W. Walsh; S. Jung; H. Lee; C. Kanellakis; J. Mayo; S. Harper; M. Kaufmann; A. Dixit; G. J. Correa; C. Lee; J. Gao; G. Merewether; J. Maldonado-Contreras; G. Salhotra; M. S. Da Silva; B. Ramtoula; S. Fakoorian; A. Hatteland; T. Kim; T. Bartlett; A. Stephens; L. Kim; C. Bergh; E. Heiden; T. Lew; A. Cauligi; T. Heywood; A. Kramer; H. A. Leopold; H. Melikyan; H. C. Choi; S. Daftry; O. Toupet; I. Wee; A. Thakur; M. Feras; G. Beltrame; G. Nikolakopoulos; D. Shim; L. Carlone; J. Burdick","NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; Institut de Robòtica i Informàtica Industrial, CSIC-UPC; NASA Jet Propulsion Laboratory, California Institute of Technology; California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; Massachusetts Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; Polytechnic University of Bari; NASA Jet Propulsion Laboratory, California Institute of Technology; Massachusetts Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; Polytechnic University of Bari; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NA; NA; Luleå University of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; California Institute of Technology; University of California, Riverside; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; University of Colorado Boulder; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; University of Colorado Boulder; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; Ecole Polytechnique de Montréal; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NA; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; NA; NASA Jet Propulsion Laboratory, California Institute of Technology; NASA Jet Propulsion Laboratory, California Institute of Technology; Korea Advanced Institute of Science and Technology; Luleå University of Technology; NA; Massachusetts Institute of Technology; California Institute of Technology",Field Robotics,"25 Feb 2025","2022","2","","1432","1506","This paper presents and discusses algorithms, hardware, and software architecture developed by the TEAM CoSTAR (Collaborative SubTerranean Autonomous Robots), competing in the DARPA Subterranean Challenge. Specifically, it presents the techniques utilized within the Tunnel (2019) and Urban (2020) competitions, where CoSTAR achieved second and first place, respectively. We also discuss CoSTAR's demonstrations in Martian-analog surface and subsurface (lava tubes) exploration. The paper introduces our autonomy solution, referred to as NeBula (Networked Belief-aware Perceptual Autonomy). NeBula is an uncertainty-aware framework that aims at enabling resilient and modular autonomy solutions by performing reasoning and decision making in the belief space (space of probability distributions over the robot and world states). We discuss various components of the NeBula framework, including (i) geometric and semantic environment mapping, (ii) a multi-modal positioning system, (iii) traversability analysis and local planning, (iv) global motion planning and exploration behavior, (v) risk-aware mission planning, (vi) networking and decentralized reasoning, and (vii) learning-enabled adaptation. We discuss the performance of NeBula on several robot types (e.g., wheeled, legged, flying), in various environments. We discuss the specific results and lessons learned from fielding this solution in the challenging courses of the DARPA Subterranean Challenge competition.","2771-3989","","10.55417/fr.2022047","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10878389","aerial robotics;exploration;extreme environments;GPS-denied operation;mapping;motion planning;subterranean robotics;legged robots;teleoperation;wheeled robots","Robots;Planning;Legged locomotion;Robot kinematics;Sensors;Hardware;Three-dimensional displays;Space exploration;Semantics;Propulsion","","13","","","CCBY","25 Feb 2025","","","FRPS","FRPS Journals"
"Cooperation Emergence of Manufacturing Services in Cloud Manufacturing With Agent-Based Modeling and Simulating","P. Lou; J. Hu; C. Zhu; J. Yan; L. Yuan","School of Information Engineering, Wuhan University of Technology, Wuhan, China; School of Information Engineering, Wuhan University of Technology, Wuhan, China; School of Information Engineering, Wuhan University of Technology, Wuhan, China; School of Information Engineering, Wuhan University of Technology, Wuhan, China; School of Information Engineering, Wuhan University of Technology, Wuhan, China",IEEE Access,"12 Feb 2021","2021","9","","24658","24668","With the development of information and network technology, a new type of manufacturing paradigm, known as a service-oriented Cloud Manufacturing (CMfg), is emerged. In the CMfg paradigm, geographically distributed various manufacturing resources authorized by different companies are encapsulated as different manufacturing services (MSs) supported by the enabling technologies, such as cloud computing, Industrial Internet of Things, virtualization technologies, etc. MSs are provided according to the demands of manufacturing tasks (MTs) presented by various customers via the IoT (Internet of Things) in CMfg paradigm. Generally, one MS may complete one MT, but mostly one MT needs more MSs to complete it cooperatively. Furthermore, these MSs are perhaps controlled and managed by different enterprises. As an autonomous entity, each MS generally makes decision in light of its own interests, and their own interests generally have conflicts with the others' and the collective ones. To solve the conflicts through MSs' cooperation is an efficient and low-cost method to maximize both individual and collective interests. Hence, the influences of individual decision-making behaviors on cooperation are explored and discussed in CMfg paradigm. The evolutionary game theory and agent-based modeling and simulating method are employed to model and simulate individual behaviors of MSs during the process of forming the coalition for completing MTs. In addition, the learning mechanism of MSs is discussed in the decision-making process. The simulation results show that decision behaviors of MSs are positively influenced by the information transparency of the CMfg environment and the learning mechanism of MSs effects on the cooperative emergence.","2169-3536","","10.1109/ACCESS.2021.3055587","National Natural Science Foundation of China(grant numbers:52075404); Application Foundation Frontier Special Project of Wuhan Science and Technology Bureau(grant numbers:2020010601012176); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9340180","Cloud manufacturing;public good game;learning automaton;agent-based modeling and simulating","Manufacturing;Games;Game theory;Learning automata;Cloud computing;Analytical models;Computer architecture","","2","","43","CCBY","29 Jan 2021","","","IEEE","IEEE Journals"
"A Secure Trust Method for Multi-Agent System in Smart Grids Using Blockchain","R. Khalid; O. Samuel; N. Javaid; A. Aldegheishem; M. Shafiq; N. Alrajeh","Department of Computer Science, COMSATS University Islamabad, Islamabad, Pakistan; Department of Computer Science, COMSATS University Islamabad, Islamabad, Pakistan; Department of Computer Science, COMSATS University Islamabad, Islamabad, Pakistan; Department of Urban Planning, College of Architecture and Planning, King Saud University, Riyadh, Saudi Arabia; Department of Information and Communication Engineering, Yeungnam University, Gyeongsan, South Korea; Department of Biomedical Technology, College of Applied Medical Sciences, King Saud University, Riyadh, Saudi Arabia",IEEE Access,"23 Apr 2021","2021","9","","59848","59859","This paper proposes a blockchain based trust management method for agents in a multi-agent system (MAS). In this work, three objectives are achieved: trust, cooperation and privacy. The trust of agents depends on the credibility of trust evaluators, which is verified using the proposed methods of trust distortion, consistency and reliability. To enhance the cooperation between agents, a tit-3-for-tat (T3FT) repeated game strategy is developed. The strategy is more forgiving than the existing tit-for-tat (TFT) strategy. It encourages cheating agents to re-establish their trust by cooperating for three consecutive rounds of play. Also, a proof-of-cooperation consensus protocol is proposed to improve agents' cooperation while creating and validating blocks. The privacy of agents is preserved in this work using the publicly verifiable secret sharing mechanism. The proposed methods are implemented using MATLAB R2018a while the MAS is simulated using Java Agent DEvelopment framework (JADE). Simulation results validate the effectiveness of the proposed work. From the simulation results, the proposed trust method outperforms an existing fuzzy logic trust method in terms of detecting the cheating behavior of agents in the system. Besides, the proposed T3FT strategy is effective as compared to the existing tit-for-2-tat and TFT strategies in the literature. Moreover, the security analysis of the proposed method is performed. The analysis shows that the proposed work is safe from bad-mouthing and on-off trust related attacks.","2169-3536","","10.1109/ACCESS.2021.3071431","King Saud University, Riyadh, Saudi Arabia(grant numbers:RSP-2020/295); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9395589","Blockchain;multi-agent system;multi-secret sharing;proof-of-cooperation;repeated game;tit-3-for-tat;urban planning;trust management system","Privacy;Distortion;TV;Trust management;Sensitivity;Reliability;Thin film transistors","","33","","23","CCBY","6 Apr 2021","","","IEEE","IEEE Journals"
"The State of the Art of Emergent Software Systems","A. Shatnawi; E. Faye; B. Rima; Z. A. Shara; A. -D. Seriai","Direction of Research and Innovation, Berger-Levrault, Mauguio, France; Direction of Research and Innovation, Berger-Levrault, Mauguio, France; Direction of Research and Innovation, Berger-Levrault, Mauguio, France; Department of Software Engineering, Jordan University of Science and Technology, Irbid, Jordan; Department of Software Engineering, Jordan University of Science and Technology, Irbid, Jordan",IEEE Access,"1 Mar 2024","2024","12","","31808","31823","Emergent Software Systems (ESSs) are designed to reduce the initial effort in creating autonomous solutions and fully adaptive support systems that can autonomously learn the system’s structure and operating environment without predefined knowledge. These models notably minimize/exclude the involvement of developers in the composition, maintenance, and evolution of software systems. Despite extensive research on self-adaptive systems, systematic reviews focusing specifically on ESSs are lacking. This paper addresses this gap by performing a systematic literature review on ESSs. Our goal is to equip researchers and industry practitioners with a comprehensive view of existing ESSs, enabling them to select approaches that meet their requirements and identify potential research avenues. The research questions are centered around knowing what ESSs are and identifying the set of activities essential for their creation. From an initial collection of 496 papers identified through search engines, 39 papers met our inclusion and exclusion criteria for retention and in-depth analysis. Finally, we build a taxonomy to categorize existing ESS approaches and dissect various ESS definitions to pinpoint their main characteristics. The taxonomy is structured around the goals, processes and usability of ESSs. Our research reveals an emphasis on non-functional adaptation objectives within current ESSs. Despite this focus, the majority of existing ESSs are still in the proof-of-concept phase and have undergone minimal testing in industrial settings. While present ESS investigations largely revolve around areas such as web service computing, internet of things, and cyber-physical systems, we advocate for further exploration of their potential utility in other application domains such as robotics, aerospace, and unmanned vehicles.","2169-3536","","10.1109/ACCESS.2024.3369903","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10445183","Emergent software systems;automatic computing;self-learning;self-adaptation","Software systems;Adaptation models;Usability;Systematics;Monitoring;Maintenance engineering;Computers;Self-supervised learning;Learning systems;Autonomous systems","","1","","51","CCBYNCND","26 Feb 2024","","","IEEE","IEEE Journals"
"Simulation of the Separating Crowd Behavior in a T-Shaped Channel Based on the Social Force Model","Z. Yuan; R. Guo; S. Tang; B. He; L. Bian; Y. Li","Shenzhen Key Laboratory of Spatial Information Smart Sensing and Services, School of Architecture and Urban Planning, Research Institute for Smart Cities, Shenzhen University, Shenzhen, China; Shenzhen Key Laboratory of Spatial Information Smart Sensing and Services, School of Architecture and Urban Planning, Research Institute for Smart Cities, Shenzhen University, Shenzhen, China; Shenzhen Key Laboratory of Spatial Information Smart Sensing and Services, School of Architecture and Urban Planning, Research Institute for Smart Cities, Shenzhen University, Shenzhen, China; Shenzhen Key Laboratory of Spatial Information Smart Sensing and Services, School of Architecture and Urban Planning, Research Institute for Smart Cities, Shenzhen University, Shenzhen, China; Shenzhen Key Laboratory of Spatial Information Smart Sensing and Services, School of Architecture and Urban Planning, Research Institute for Smart Cities, Shenzhen University, Shenzhen, China; Shenzhen Key Laboratory of Spatial Information Smart Sensing and Services, School of Architecture and Urban Planning, Research Institute for Smart Cities, Shenzhen University, Shenzhen, China",IEEE Access,"8 Feb 2019","2019","7","","13668","13682","The separating behavior defines the division of a crowd from a single flow into two distributary flows due to the different pedestrians' destinations. Nevertheless, in the existing literature on pedestrian flow, there is a lack of simulation research on the separating crowd behavior in a T-shaped channel. By conducting a series of controlled experiments, we analyzed the moving trajectories and the spatial and temporal distribution characteristics of pedestrians in the separation process. Based on an analysis of the controlled experiments, we proposed an improved social force model that fully considers the characteristics of pedestrians' swapping locations, and refines the directions of pedestrians' expected speeds in three stages of the pedestrian separation process. During the simulation, we applied the improved model to explore the effects of the pedestrians' swapping locations on the macroscopic phenomena, microscopic individual behavior, and traffic efficiency within a T-shaped channel. The simulation results show that if pedestrians' swapping locations are concentrated in a certain area close to the entrance, the traffic efficiency in the T-shaped channel will be higher than that if the pedestrians' swapping locations are dispersed. Moreover, as the flow rate at the entrance increases, the swapping location becomes more concentrated closer to the entrance, the mean speed increases, and fewer conflicts occur between the pedestrians.","2169-3536","","10.1109/ACCESS.2019.2894345","NSFC (Jilin Science and Technology Development Program)(grant numbers:51278221,51378076,41701187,20170101155JC); National Natural Science Foundation of China(grant numbers:41801392); China Postdoctoral Science Foundation(grant numbers:2018M640821,2018M633133,2018M643150); Open Fund of Key Laboratory of Urban Land Resources Monitoring and Simulation(grant numbers:KF-2018-03-031); Ministry of Land and Resources, Shenzhen, China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8624324","Crowd safety;pedestrian dynamics;swapping location;traffic optimization","Force;Analytical models;Data models;Merging;Legged locomotion;Separation processes;Numerical models","","17","","51","OAPA","23 Jan 2019","","","IEEE","IEEE Journals"
"Transfer Learning Applied to Deep Reinforcement Learning for 6G Resource Management in Intra- and Inter-Slice RAN-Edge Domains","S. Mhatre; F. Adelantado; K. Ramantas; C. Verikoukis","Signal Theory and Communications Department, Universitat Politecnica de Catalunya, Barcelona, Spain; Universitat Oberta de Catalunya (UOC), Barcelona, Spain; Iquadrat Informatica, Barcelona, Spain; Iquadrat Informatica, Barcelona, Spain",IEEE Transactions on Consumer Electronics,"18 Aug 2025","2025","71","2","6659","6672","Leveraging the power of deep reinforcement learning (DRL) and strategic knowledge transfer, our study introduces PIRA-DRL-DTRL, a novel approach to optimizing resource allocation in emerging 6G networks. Central to this research is the innovative application of artificial intelligence (AI) at the network’s edge, enabling efficient management of resources across diverse timeframes while enhancing overall network performance. Implemented within an Open Radio Access Network (O-RAN) architecture, PIRA-DRL-DTRL employs a two-tiered decision-making system to dynamically adapt to varying network demands, ensuring optimal resource allocation for enhanced mobile broadband (eMBB), ultra-reliable low-latency communications (URLLC), and massive machine-type communications (mMTC). Our proposed algorithm achieves significant performance gains, providing a 14.28% and 10.67% improvement in throughput for eMBB slices compared to DRL-only and state-of-the-art (SOTA) methods, respectively. Additionally, it reduces delay by 23.57% and 7.48% compared to baseline and SOTA approaches for eMBB slices. By predicting and adapting to network slice demands, PIRA-DRL-DTRL ensures seamless service delivery. This research lays the groundwork for smarter, more efficient 6G networks capable of meeting the dynamic needs of users and applications.","1558-4127","","10.1109/TCE.2025.3553407","6G-BRICKS(grant numbers:101096954); SUNRISE-6G(grant numbers:101139257); RF-VOLUTION through the Spanish Ministry of Science, Innovation and Universities(grant numbers:PID2021-122247OB-I00); Generalitat de Catalunya(grant numbers:2021 SGR 174); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10935668","6G;O-RAN;radio access network;radio resource management;network slicing;artificial intelligence;machine learning;deep reinforcement learning;transfer learning;intra- and inter-slice scheduling","Resource management;Convergence;Open RAN;Transfer learning;Heuristic algorithms;Quality of service;Artificial intelligence;6G mobile communication;Dynamic scheduling;Training","","4","","29","CCBY","20 Mar 2025","","","IEEE","IEEE Journals"
"Battlefield Target Intelligence System Architecture Modeling and System Optimization","W. Li; Y. Wang; L. Jia; S. Peng; R. He","School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; School of Information and Electronics, Beijing Institute of Technology, Beijing, China",Journal of Systems Engineering and Electronics,"13 Nov 2024","2024","35","5","1190","1210","To address the current problems of poor generality, low real-time, and imperfect information transmission of the battlefield target intelligence system, this paper studies the battlefield target intelligence system from the top-level perspective of multi-service joint warfare. First, an overall planning and analysis method of architecture modeling is proposed with the idea of a bionic analogy for battlefield target intelligence system architecture modeling, which reduces the difficulty of the planning and design process. The method introduces the Department of Defense architecture framework (DoDAF) modeling method, the multi-living agent (MLA) theory modeling method, and other combinations for planning and modeling. A set of rapid planning methods that can be applied to model the architecture of various types of complex systems is formed. Further, the liveness analysis of the battlefield target intelligence system is carried out, and the problems of the existing system are presented from several aspects. And the technical prediction of the development and construction is given, which provides directional ideas for the subsequent research and development of the battlefield target intelligence system. In the end, the proposed architecture model of the battlefield target intelligence system is simulated and verified by applying the colored Petri nets (CPN) simulation software. The analysis demonstrates the reasonable integrity of its logic.","1004-4132","","10.23919/JSEE.2024.000114","National Natural Science Foundation of China(grant numbers:41927801); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10752329","battlefield target intelligence system;architecture modeling;bionic design;system optimization;simulation verification","Analytical models;Biological system modeling;Systems architecture;Computer architecture;Reconnaissance;Big Data;Software;Planning;Logic;Optimization","","","","59","","13 Nov 2024","","","BIAI","BIAI Journals"
"Twin Delayed Deep Deterministic Policy Gradient-Based Target Tracking for Unmanned Aerial Vehicle With Achievement Rewarding and Multistage Training","N. Abo Mosali; S. S. Shamsudin; O. Alfandi; R. Omar; N. Al-Fadhali","Research Center for Unmanned Vehicles, Faculty of Mechanical and Manufacturing Engineering, Universiti Tun Hussein Onn Malaysia, Parit Raja, Batu Pahat, Johor, Malaysia; Research Center for Unmanned Vehicles, Faculty of Mechanical and Manufacturing Engineering, Universiti Tun Hussein Onn Malaysia, Parit Raja, Batu Pahat, Johor, Malaysia; College of Technological Innovation, Zayed University, Abu Dhabi, United Arab Emirates; Faculty of Electrical and Electronic Engineering, Universiti Tun Hussein Onn Malaysia (UTHM), Parit Raja, Johor, Malaysia; Faculty of Electrical and Electronic Engineering, Universiti Tun Hussein Onn Malaysia (UTHM), Parit Raja, Johor, Malaysia",IEEE Access,"7 Mar 2022","2022","10","","23545","23559","Target tracking using an unmanned aerial vehicle (UAV) is a challenging robotic problem. It requires handling a high level of nonlinearity and dynamics. Model-free control effectively handles the uncertain nature of the problem, and reinforcement learning (RL)-based approaches are a good candidate for solving this problem. In this article, the Twin Delayed Deep Deterministic Policy Gradient Algorithm (TD3), as recent and composite architecture of RL, was explored as a tracking agent for the UAV-based target tracking problem. Several improvements on the original TD3 were also performed. First, the proportional-differential controller was used to boost the exploration of the TD3 in training. Second, a novel reward formulation for the UAV-based target tracking enabled a careful combination of the various dynamic variables in the reward functions. This was accomplished by incorporating two exponential functions to limit the effect of velocity and acceleration to prevent the deformation in the policy function approximation. In addition, the concept of multistage training based on the dynamic variables was proposed as an opposing concept to one-stage combinatory training. Third, an enhancement of the rewarding function by including piecewise decomposition was used to enable more stable learning behaviour of the policy and move out from the linear reward to the achievement formula. The training was conducted based on fixed target tracking followed by moving target tracking. The flight testing was conducted based on three types of target trajectories: fixed, square, and blinking. The multistage training achieved the best performance with both exponential and achievement rewarding for the fixed trained agent with the fixed and square moving target and for the combined agent with both exponential and achievement rewarding for a fixed trained agent in the case of a blinking target. With respect to the traditional proportional differential controller, the maximum error reduction rate is 86%. The developed achievement rewarding and the multistage training opens the door to various applications of RL in target tracking.","2169-3536","","10.1109/ACCESS.2022.3154388","Zayed University Cluster(grant numbers:R19046); Universiti Tun Hussein Onn Malaysia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9721287","Navigation;reinforcement learning;target tracking;twin delayed deep deterministic policy gradient;unmanned aerial vehicles","Target tracking;Autonomous aerial vehicles;Training;Vehicle dynamics;Task analysis;Reinforcement learning;Trajectory tracking","","23","","46","CCBY","24 Feb 2022","","","IEEE","IEEE Journals"
"Distributed Optimization for Distribution Grids With Stochastic DER Using Multi-Agent Deep Reinforcement Learning","M. Al-Saffar; P. Musilek","Department of Electrical and Computer Engineering, University of Alberta, Edmonton, AB, Canada; Department of Electrical and Computer Engineering, University of Alberta, Edmonton, AB, Canada",IEEE Access,"30 Apr 2021","2021","9","","63059","63072","This article develops a special decomposition methodology for the traditional optimal power flow which facilitates optimal integration of stochastic distributed energy resources in power distribution systems. The resulting distributed optimal power flow algorithm reduces the computational complexity of the conventional linear programming approach while avoiding the challenges associated with the stochastic nature of the energy resources and loads. It does so using machine learning algorithms employed for two crucial tasks. First, two proposed algorithms, Dynamic Distributed Multi-Microgrid and Monte Carlo Tree Search based Reinforcement Learning, constitute dynamic microgrids of network nodes to confirm the electric power transaction optimality. Second, the optimal distributed energy resources are obtained by the proposed deep reinforcement learning method named Multi Leader-Follower Actors under Centralized Critic. It accelerates conventional linear programming approach by considering a reduced set of resources and their constraints. The proposed method is demonstrated through a real-time balancing electricity market constructed over the IEEE 123-bus system and enhanced using price signals based on distribution locational marginal prices. This application clearly shows the ability of the new approach to effectively coordinate multiple distribution system entities while maintaining system security constraints.","2169-3536","","10.1109/ACCESS.2021.3075247","Canada First Research Excellence Fund (CFREF) under the Future Energy Systems Research Initiative at the University of Alberta; Natural Science and Engineering Research Council (NSERC) of Canada(grant numbers:RGPIN-2017-05866); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9411856","Distributed architecture;distributed optimization;Monte Carlo tree search;multi-agent deep reinforcement learning;optimal power flow","Optimization;Microgrids;Heuristic algorithms;Stochastic processes;Power systems;Real-time systems;Convex functions","","14","","53","CCBY","23 Apr 2021","","","IEEE","IEEE Journals"
"FARANE-Q: Fast Parallel and Pipeline Q-Learning Accelerator for Configurable Reinforcement Learning SoC","N. Sutisna; A. M. R. Ilmy; I. Syafalni; R. Mulyawan; T. Adiono","School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia; School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia; School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia; School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia; School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia",IEEE Access,"3 Jan 2023","2023","11","","144","161","This paper proposes a FAst paRAllel and pipeliNE Q-learning accelerator (FARANE-Q) for a configurable Reinforcement Learning (RL) algorithm implemented in a System on Chip (SoC). The proposed work offers flexibility, configurability, and scalability while maintaining computation speed and accuracy to overcome the challenges of a dynamic environment and increasing complexity. The proposed method includes a Hardware/Software (HW/SW) design methodology for the SoC architecture to achieve flexibility. We also propose joint optimizations on the algorithm, architecture, and implementation to obtain optimum (high efficiency) performance, specifically in energy and area efficiency. Furthermore, we implemented the proposed design in a real-time Zynq Ultra96-V2 FPGA platform to evaluate the functionality with an actual use case of smart navigation. Experimental results confirm that the proposed accelerator FARANE-Q outperforms state-of-the-art works by achieving a throughput of up to 148.55 MSps. It corresponds to the energy efficiency of 1747.64 MSps/W per agent for 32-bit and 2424.33 MSps/W per agent for 16-bit FARANE-Q. Moreover, the proposed 16-bit FARANE-Q outperforms other related works by an improvement of at least  $1.23\times $  in energy efficiency. The designed system also maintains an error accuracy of less than 0.4% with optimized bit precision for more than eight fraction bits. The proposed FARANE-Q also offers a speed up of processing time up to  $1795\times $  compared to embedded SW computation executed on ARM Zynq processor and  $280\times $  of computation of full software executed on i7 processor. Hence, the proposed work has the potential to be used for smart navigation, robotic control, and predictive maintenance.","2169-3536","","10.1109/ACCESS.2022.3232853","Bandung Institute of Technology [Institut Teknologi Bandung (ITB)] Research Program 2021; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10002361","Q-learning;reinforcement learning;HW accelerator;FPGA;SoC","Q-learning;Computer architecture;Field programmable gate arrays;Throughput;Heuristic algorithms;System-on-chip;Pipelines","","15","","45","CCBY","28 Dec 2022","","","IEEE","IEEE Journals"
"Distributed Artificial Intelligence Enabled Aerial-Ground Networks: Architecture, Technologies and Challenges","Z. Xia; J. Du; Y. Ren; Z. Han","Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA",IEEE Access,"11 Oct 2022","2022","10","","105447","105457","Artificial intelligence (AI) provides a promising and novel direction to design future time-varying wireless networks by leading to significantly superior performances compared to conventional methods. In addition, the advanced deployment of unmanned aerial vehicles (UAVs) has boosted extensive novel research results and industrial products in terms of aerial-ground networks. However, with the rapid development of mobile networks and growing requirements for low-latency services, the conventional centralized aerial-ground network has failed to meet the time-varying expectations of mobile users in the dynamic network environment. To cope with the problems, the marriage of the aerial-ground network and innovative AI techniques, i.e., distributed artificial intelligence enabled aerial-ground network (DAIAGN), is proposed in this article, which consists of three vital components: deep reinforcement learning enabled distributed information sharing, edge intelligence enabled distributed security management, and multi-agent reinforcement learning enabled distributed decision making. The functions of the three components are elaborated, and recent related advances are surveyed in detail. A specific case study is also provided with respect to multi-agent reinforcement learning enabled distributed decision making. Furthermore, key challenges and open issues are also discussed to provide some guidances for potential future directions.","2169-3536","","10.1109/ACCESS.2022.3210337","National Key Research and Development Program of China(grant numbers:2020YFD0901000); National Natural Science Foundation of China(grant numbers:61971257,62127801); Young Elite Scientist Sponsorship Program by China Association for Science and Technology (CAST)(grant numbers:2020QNRC001); Project The Verification Platform of Multi-Tier Coverage Communication Network for Oceans through the Peng Cheng Laboratory(grant numbers:LZC0020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9904596","Distributed network;aerial-ground network;artificial intelligence;reinforcement learning;edge intelligence","Access control;Optimization;Information sharing;Reinforcement learning;Artificial intelligence;Distributed decision making;Internet of Things;Edge computing","","8","","33","CCBY","27 Sep 2022","","","IEEE","IEEE Journals"
"Building a General Purpose Pedagogical Agent in a Web-Based Multimedia Clinical Simulation System for Medical Education","Y. -M. Cheng; L. -S. Chen; H. -C. Huang; S. -F. Weng; Y. -G. Chen; C. -H. Lin","Department of Computer Science and Information Engineering, Shu Te University, Kaohsiung, Taiwan; Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan; Institute of Computer and Communication Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan; College of Medicine, National Cheng Kung University, Tainan, Taiwan",IEEE Transactions on Learning Technologies,"11 Sep 2009","2009","2","3","216","225","In medical education, pedagogical agents are widely used by computer learning systems to simulate tutors and/or mimic tutoring interactions, as well as offering just-in-time and adaptive feedback. Although the theoretical aspect of the pedagogical agents has been well-documented in literature, relatively fewer efforts have been made on how a pedagogical agent should be implemented in a real multimedia computerized simulation learning environment. In this paper, we propose a general purpose pedagogical agent architecture and implement it in the multimedia medical simulation Web-based learning system called health information network teaching system (HINTS) to further facilitate students' learning and thereby make the HINTS a more helpful educational tool. Our focus is the design of the general purpose pedagogical architecture and its implementation in a multimedia computerized simulation learning environment. A preliminary students' performance evaluation result is also reported. We analyzed how to evaluate the students' performance and how the hints were given by the pedagogical agent. The system has been installed in the National Cheng Kung University Medical Center, Tainan, Taiwan for trial purposes. Some experiments have been conducted and the results have shown that the pedagogical agent indeed help the students in their learning process.","1939-1382","","10.1109/TLT.2009.18","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4815202","e-Learning for medical education;pedagogical agent;computer-assisted learning;virtual peers;human-computer interaction;learning companions.","Education;Multimedia communication;Computational modeling;Multimedia systems;Laboratories;Medical diagnostic imaging;Data mining","","24","","35","IEEE","17 Apr 2009","","","IEEE","IEEE Journals"
"Deep Fusion Intelligence: Enhancing 5G Security Against Over-the-Air Attacks","M. Amini; G. Asemian; B. Kantarci; C. Ellement; M. Erol-Kantarci","School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada; School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada; School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada; Artificial Intelligence Solutions, thinkRF, Ottawa, ON, Canada; School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada",IEEE Transactions on Machine Learning in Communications and Networking,"31 Jan 2025","2025","3","","263","279","With the increasing deployment of 5G networks, the vulnerability to malicious interference, such as jamming attacks, has become a significant concern. Detecting such attacks is crucial to ensuring the reliability and security of 5G communication systems Specifically in CAVs. This paper proposes a robust jamming detection system addressing challenges posed by impairments, such as Carrier Frequency Offset (CFO) and channel effects. To improve overall detection performance, the proposed approach leverages deep ensemble learning techniques by fusing different features with different sensitivities from the RF domain and Physical layer namely, Primary Synchronization Signal (PSS) and Secondary Synchronization Signal (SSS) cross-correlations in the time and the frequency domain, the energy of the null subcarriers, and the PBCH Error Vector Magnitude (EVM). The ensemble module is optimized for the aggregation method and different learning parameters. Furthermore, to mitigate the false positive and false negative, a systematic approach, termed Temporal Epistemic Decision Aggregator (TEDA) is introduced, which elegantly navigates the time-accuracy tradeoff by seamlessly integrating temporal decisions, thereby enhancing decision reliability. The presented approach is also capable of detecting inter-cell/inter-sector interference, thereby enhancing situational awareness on 5G air interface and RF domain security. Results show that the presented approach achieves the Area Under Curve (AUC) of 0.98, outperforming other compared methods by at least 0.06 (a 6% improvement). The true positive and negative rates are reported as 93.5% and 91.9%, respectively, showcasing strong performance for scenarios with CFO and channel impairments and outperforming the other compared methods by at least 12%. An optimization problem is formulated and solved based on the level of uncertainty observed in the experimental set-up and the optimum TEDA configuration is derived for the target false-alarm and miss-detection probability. Ultimately, the performance of the entire architecture is confirmed through analysis of real 5G signals acquired from a practical testbed, showing strong agreement with the simulation results.","2831-316X","","10.1109/TMLCN.2025.3533427","Natural Sciences and Engineering Research Council of Canada (NSERC) CREATE TRAVERSAL Program; NSERC Discovery Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10851353","5G security;ensemble learning;deep learning;jamming detection;synchronization signals;RF domain","Jamming;5G mobile communication;Radio frequency;Security;Feature extraction;Synchronization;Amplitude modulation;Computer architecture;Accuracy;Wireless networks","","3","","47","CCBYNCND","23 Jan 2025","","","IEEE","IEEE Journals"
"Machine Learning in Network Slicing—A Survey","H. P. Phyu; D. Naboulsi; R. Stanica","Département de Génie Logiciel et des Technologies de l’information, École de Technologie Supérieure, Université du Québec, Montreal, Canada; Département de Génie Logiciel et des Technologies de l’information, École de Technologie Supérieure, Université du Québec, Montreal, Canada; Inria, CITI, INSA Lyon, University of Lyon, Villeurbanne, France",IEEE Access,"25 Apr 2023","2023","11","","39123","39153","5G and beyond networks are expected to support a wide range of services, with highly diverse requirements. Yet, the traditional “one-size-fits-all” network architecture lacks the flexibility to accommodate these services. In this respect, network slicing has been introduced as a promising paradigm for 5G and beyond networks, supporting not only traditional mobile services, but also vertical industries services, with very heterogeneous requirements. Along with its benefits, the practical implementation of network slicing brings a lot of challenges. Thanks to the recent advances in machine learning (ML), some of these challenges have been addressed. In particular, the application of ML approaches is enabling the autonomous management of resources in the network slicing paradigm. Accordingly, this paper presents a comprehensive survey on contributions on ML in network slicing, identifying major categories and sub-categories in the literature. Lessons learned are also presented and open research challenges are discussed, together with potential solutions.","2169-3536","","10.1109/ACCESS.2023.3267985","National Natural Sciences and Engineering Research Council of Canada (NSERC)(grant numbers:RGPIN-2020-06050); Fonds de Recherche du Québec—Nature et Technologies (FRQNT)(grant numbers:FRQNT 2022-NC-297403); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10103689","Network slicing;5G network;machine learning","Network slicing;5G mobile communication;Resource management;Mathematical models;Predictive models;Machine learning;Computer architecture","","45","","212","CCBYNCND","17 Apr 2023","","","IEEE","IEEE Journals"
"Reinforcement Learning for Two-Stage Permutation Flow Shop Scheduling—A Real-World Application in Household Appliance Production","A. Müller; F. Grumbach; F. Kattenstroth","Fraunhofer IOSB-INA, Lemgo, Germany; Center for Applied Data Science (CfADS), Bielefeld University of Applied Sciences, Gütersloh, Germany; Miele & Cie.KG, Gütersloh, Germany",IEEE Access,"25 Jan 2024","2024","12","","11388","11399","Solving production scheduling problems is a difficult and indispensable task for manufacturers with a push-oriented planning approach. In this study, we tackle a novel production scheduling problem from a household appliance production at the company Miele & Cie. KG, namely a two-stage permutation flow shop scheduling problem (PFSSP) with a finite buffer and sequence-dependent setup efforts. The objective is to minimize idle times and setup efforts in lexicographic order. In extensive and realistic data, the identification of exact solutions is not possible due to the combinatorial complexity. Therefore, we developed a reinforcement learning (RL) approach based on the Proximal Policy Optimization (PPO) algorithm that integrates domain knowledge through reward shaping, action masking, and curriculum learning to solve this PFSSP. Benchmarking of our approach with a state-of-the-art genetic algorithm (GA) showed significant superiority. Our work thus provides a successful example of the applicability of RL in real-world production planning, demonstrating not only its practical utility but also showing the technical and methodological integration of the agent with a discrete event simulation (DES). We also conducted experiments to investigate the impact of individual algorithmic elements and a hyperparameter of the reward function on the overall solution.","2169-3536","","10.1109/ACCESS.2024.3355269","Ministry of Economic Affairs, Industry, Climate Action and Energy of the State of North Rhine-Westphalia, Germany, “SUPPORT” Project(grant numbers:005-2111-0026); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10401920","Reinforcement learning;production scheduling;permutation flow shop scheduling problem","Production;Job shop scheduling;Home appliances;Metaheuristics;Benchmark testing;Finite element analysis;Synthetic data","","4","","40","CCBY","17 Jan 2024","","","IEEE","IEEE Journals"
"Neural Networks for Energy-Efficient Self Optimization of eNodeB Antenna Tilt in 5G Mobile Network Environments","M. N. Qureshi; M. K. Shahid; M. I. Tiwana; M. Haddad; I. Ahmed; T. Faisal","Department of Electrical and Computer Engineering, COMSATS University Islamabad, Islamabad, Pakistan; Department of Electrical Engineering, Higher Colleges of Technology, Abu Dhabi, United Arab Emirates; Department of Electrical and Computer Engineering, COMSATS University Islamabad, Islamabad, Pakistan; Department of Electrical Engineering, University of Avignon, Avignon, France; Department of Electrical Engineering, Higher Colleges of Technology, Abu Dhabi, United Arab Emirates; Department of Electrical Engineering, Higher Colleges of Technology, Abu Dhabi, United Arab Emirates",IEEE Access,"16 Jun 2022","2022","10","","61678","61694","In this paper, we present an energy-efficient Self Organizing Network (SON) architecture based on a tunable eNodeB (eNB) antenna tilt design for macrocells in a mobile network environment. This is an imperative element of mobility management in high speed and low latency wireless networks. The SON architecture follows a fully distributed approach with optional network information exchange with neighboring cells and core network. Antenna tilt directly affects its radiation pattern thus changes in eNB antenna tilt can be used to optimize cell coverage and reduce interference in mobile networks. We apply and compare two reinforcement machine learning techniques for optimizing the eNB antenna tilts, i.e., Deep Q-learning using Artificial Neural Network (ANN) and a simple Stochastic Cellular Learning Automata (SCLA). ANN is well known for its ability to learn from a vast number of inputs, while the stochastic learning technique relies on a simple action based probability vector updated based on system feedback. Neighboring cells for any one cell in the network environment are selected based on their separation distance and antenna orientation. We validate the data call performance of the network for edge users as they directly impact the Quality of Service (QoS) in the mobile environment. Our simulated results show that ANN performs better for edge users as compared to SCLA. The model also satisfies the SON requirement of scalability and agility. This work is a follow-up to our earlier work, where we showed that SCLA performs better than Q-learning in a similar network environment and optimizing strategy due to its low complexity, but within the same Q-learning algorithm more input learning parameters gave better performance.","2169-3536","","10.1109/ACCESS.2022.3181595","HCT Research Grant from the Higher Colleges of Technology (HCT), Abu Dhabi, United Arab Emirates(grant numbers:2307); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9792245","5G;antenna tilt;artificial neural networks (ANN);deep Q-learning;energy efficiency;HetNet;self organizing networks;self optimization;stochastic cellular learning automata (SCLA)","Q-learning;Optimization;Antennas;Artificial neural networks;Antenna radiation patterns;5G mobile communication;Interference","","9","","43","CCBY","9 Jun 2022","","","IEEE","IEEE Journals"
"Agent Architecture for Adaptive Behaviors in Autonomous Driving","M. D. Lio; R. Donà; G. P. R. Papini; K. Gurney","Department of Industrial Engineering, University of Trento, Trento, Italy; Department of Industrial Engineering, University of Trento, Trento, Italy; Department of Industrial Engineering, University of Trento, Trento, Italy; Department of Psychology, The University of Sheffield, Sheffield, U.K.",IEEE Access,"1 Sep 2020","2020","8","","154906","154923","Evolution has endowed animals with outstanding adaptive behaviours which are grounded in the organization of their sensorimotor system. This paper uses inspiration from these principles of organization in the design of an artificial agent for autonomous driving. After distilling the relevant principles from biology, their functional role in the implementation of an artificial system are explained. The resulting Agent, developed in an EU H2020 Research and Innovation Action, is used to concretely demonstrate the emergence of adaptive behaviour with a significant level of autonomy. Guidelines to adapt the same principled organization of the sensorimotor system to other agents for driving are also obtained. The demonstration of the system abilities is given with example scenarios and open access simulation tools. Prospective developments concerning learning via mental imagery are finally discussed.","2169-3536","","10.1109/ACCESS.2020.3007018","European Commission through the EU Horizon 2020 Dreams4Cars Research and Innovation Action Project(grant numbers:H2020 731593); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9133080","Adaptive behaviour;affordance competition hypothesis;autonomous driving;explainable artificial intelligence","Trajectory;Organizations;Autonomous vehicles;Brain modeling;Computational modeling;Computer architecture","","18","","52","CCBY","3 Jul 2020","","","IEEE","IEEE Journals"
"Hindsight Goal Ranking on Replay Buffer for Sparse Reward Environment","T. M. Luu; C. D. Yoo","School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",IEEE Access,"8 Apr 2021","2021","9","","51996","52007","This paper proposes a method for prioritizing the replay experience referred to as Hindsight Goal Ranking (HGR) in overcoming the limitation of Hindsight Experience Replay (HER) that generates hindsight goals based on uniform sampling. HGR samples with higher probability on the states visited in an episode with larger temporal difference (TD) error, which is considered as a proxy measure of the amount which the RL agent can learn from an experience. The actual sampling for large TD error is performed in two steps: first, an episode is sampled from the relay buffer according to the average TD error of its experiences, and then, for the sampled episode, the hindsight goal leading to larger TD error is sampled with higher probability from future visited states. The proposed method combined with Deep Deterministic Policy Gradient (DDPG), an off-policy model-free actor-critic algorithm, accelerates learning significantly faster than that without any prioritization on four challenging simulated robotic manipulation tasks. The empirical results show that HGR uses samples more efficiently than previous methods across all tasks.","2169-3536","","10.1109/ACCESS.2021.3069975","Institute for Information & Communications Technology Planning & Evaluation (IITP) grant funded by the Korea Government (MSIT) Development of Framework for Analyzing, Detecting, Mitigating of Bias in AI Model and Training Data(grant numbers:2019-0-01396); BK21 FOUR program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9391700","Hindsight goal ranking;multi-goal reinforcement learning;reinforcement learning;sparse reward;sample efficiency","Task analysis;Training;Robots;Reinforcement learning;Buffer storage;Measurement uncertainty;Computer architecture","","9","","41","CCBY","31 Mar 2021","","","IEEE","IEEE Journals"
"GRAIL: A Goal-Discovering Robotic Architecture for Intrinsically-Motivated Learning","V. G. Santucci; G. Baldassarre; M. Mirolli","School of Computing and Mathematics, University of Plymouth, Plymouth, U.K.; Istituto di Scienze e Tecnologie della Cognizione, Consiglio Nazionale delle Ricerce, Rome, Italy; Istituto di Scienze e Tecnologie della Cognizione, Consiglio Nazionale delle Ricerce, Rome, Italy",IEEE Transactions on Cognitive and Developmental Systems,"20 May 2017","2016","8","3","214","231","In this paper, we present goal-discovering robotic architecture for intrisically-motivated learning (GRAIL), a four-level architecture that is able to autonomously: 1) discover changes in the environment; 2) form representations of the goals corresponding to those changes; 3) select the goal to pursue on the basis of intrinsic motivations (IMs); 4) select suitable computational resources to achieve the selected goal; 5) monitor the achievement of the selected goal; and 6) self-generate a learning signal when the selected goal is successfully achieved. Building on previous research, GRAIL exploits the power of goals and competence-based IMs to autonomously explore the world and learn different skills that allow the robot to modify the environment. To highlight the features of GRAIL, we implement it in a simulated iCub robot and test the system in four different experimental scenarios where the agent has to perform reaching tasks within a 3-D environment.","2379-8939","","10.1109/TCDS.2016.2538961","European Commission under the 7th Framework Programme (FP7/2007- 2013); ICT Challenge 2 Cognitive Systems and Robotics; Project IM-CLeVeR—Intrinsically Motivated Cumulative Learning Versatile Robots(grant numbers:ICT-IP- 231722); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7470616","Autonomous robotics;developmental robotics;goal formation;hierarchical architecture;intrinsic motivations (IMs);reinforcement learning","Computer architecture;Biology;Computational modeling;Three-dimensional displays;Service robots;Buildings","","75","","95","OAPA","18 May 2016","","","IEEE","IEEE Journals"
"Drone Navigation and Target Interception Using Deep Reinforcement Learning: A Cascade Reward Approach","A. A. Darwish; A. Nakhmani","Department of Electrical and Computer Engineering, University of Alabama at Birmingham, Birmingham, AL, USA; Department of Electrical and Computer Engineering, University of Alabama at Birmingham, Birmingham, AL, USA",IEEE Journal of Indoor and Seamless Positioning and Navigation,"13 Dec 2023","2023","1","","130","140","This article proposes an architecture for drone navigation and target interception, utilizing a self-supervised, model-free deep reinforcement learning approach. Unlike the traditional methods relying on complex controllers, our approach uses deep reinforcement learning with cascade rewards, enabling a single drone to navigate obstacles and intercept targets using only a forward-facing depth–RGB camera. This research has significant implications for robotics, as it demonstrates how complex tasks can be tackled using deep reinforcement learning. Our work encompasses three key contributions. First, we tackle the challenge of partial observability when employing nonlinear function approximators for learning stochastic policies. Second, we optimize the task of maximizing the overall expected reward. Finally, we develop a software library for training drones to track and intercept targets. Through our experiments, we demonstrated that our approach, incorporating cascade reward, outperforms state-of-the-art deep Q-network algorithms in terms of learning policies. By leveraging our methodology, drones can successfully navigate complex indoor and outdoor environments and effectively intercept targets based on visual cues.","2832-7322","","10.1109/JISPIN.2023.3334690","Nvidia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10323488","Cascading reward function;drone tracking;dueling double deep   $Q$  -network (DQN);interception;reinforcement learning (RL)","Drones;Navigation;Target tracking;Reinforcement learning;Task analysis;Deep learning;Robots;Mobile robots;Robot vision systems;Deep reinforcement learning","","5","","51","CCBY","20 Nov 2023","","","IEEE","IEEE Journals"
"Renewable Energy Maximization for Pelagic Islands Network of Microgrids Through Battery Swapping Using Deep Reinforcement Learning","M. A. Amin; A. Suleman; M. Waseem; T. Iqbal; S. Aziz; M. T. Faiz; L. Zulfiqar; A. M. Saleh","Department of Electrical, Electronic, Telecommunications Engineering and Naval Architecture, University of Genoa, Genoa, Italy; Rapid Volt (PVT) Ltd., Rajanpur, Punjab, Pakistan; Department of Electronics and Information Engineering, The Hong Kong Polytechnic University, Hung Hom, Hong Kong; Electrical Engineering Department, College of Electrical and Mechanical Engineering, National University of Sciences and Technology (NUST), Islamabad, Pakistan; Department of Electronics and Information Engineering, The Hong Kong Polytechnic University, Hung Hom, Hong Kong; Department of Electronics and Information Engineering, The Hong Kong Polytechnic University, Hung Hom, Hong Kong; Rapid Volt (PVT) Ltd., Rajanpur, Punjab, Pakistan; Electrical Engineering Department, University of Aden, Aden, Yemen",IEEE Access,"18 Aug 2023","2023","11","","86196","86213","The study proposes an energy management system of pelagic islands network microgrids (PINMGs) based on reinforcement learning (RL) under the effect of environmental factors. Furthermore, the day-ahead standard scheduling proposes an energy-sharing framework across islands by presenting a novel method to optimize the use of renewable energy (RE). Energy sharing across islands is critical for powering isolated islands that need electricity owing to a lack of renewable energy supplies to fulfill local demand. A two-stage cooperative multi-agent deep RL solution based on deep Q-learning (DQN) with central RL and island agents (IA) spread over several islands has been presented to tackle this difficulty. Because of its in-depth learning potential, deep RL-based systems effectively train and optimize their behaviors across several epochs compared to other machine learning or traditional methods. As a result, the centralized RL-based problem of scheduling charge battery sharing from resource-rich islands (SI) to load island networks (LIN) was addressed utilizing dueling DQN. Furthermore, due to its precise tracking, the case study compared the accuracy of various DQN approaches and further scheduling based on the dueling DQN. The need for LIN is also stochastic because of variable demand and charging patterns. Hence, the simulation results, including energy scheduling through the ship, are confirmed by optimizing RE consumption via sharing across several islands, and the effectiveness of the proposed method is validated by state and action perturbation to guarantee robustness.","2169-3536","","10.1109/ACCESS.2023.3302895","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10210341","Deep reinforcement learning;pelagic island;microgrids;EMS;renewable energy","Batteries;Marine vehicles;Costs;Renewable energy sources;Microgrids;Generators;Task analysis;Deep learning;Reinforcement learning;Energy management systems","","26","","50","CCBY","7 Aug 2023","","","IEEE","IEEE Journals"
"Multi-Robot Hybrid Coverage Path Planning for 3D Reconstruction of Large Structures","R. Almadhoun; T. Taha; L. Seneviratne; Y. Zweiri","Khalifa University Center for Autonomous Robotic Systems (KUCARS), Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates; Robotics Lab, Dubai Future Foundation (DFF), Dubai, United Arab Emirates; Khalifa University Center for Autonomous Robotic Systems (KUCARS), Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates; Khalifa University Center for Autonomous Robotic Systems (KUCARS), Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates",IEEE Access,"7 Jan 2022","2022","10","","2037","2050","Coverage Path Planning (CPP) is an essential capability for autonomous robots operating in various critical applications such as fire fighting, and inspection. Performing autonomous coverage using a single robot system consumes time and energy. In particular, 3D large structures might contain some complex and occluded areas that shall be scanned rapidly in certain application domains. In this paper, a new Hybrid Coverage Path Planning (HCPP) approach is proposed to explore and cover unknown 3D large structures using a decentralized multi-robot system. The HCPP approach combines a guided Next Best View (NBV) approach with a developed Long Short Term Memory (LSTM) waypoint prediction approach to decrease the CPP exploration time at each iteration and simultaneously achieve high coverage. The hybrid approach is the new ML paradigm which fosters intelligence by balancing between data efficiency and generality allowing the exchange of some CPP parts with a learned model. The HCPP uses a stateful LSTM network architecture which is trained based on collected paths that cover different 3D structures to predict the next viewpoint. This architecture captures the dynamic dependencies of adjacent viewpoints in the long term sequences like the coverage paths. The HCPP switches between these methods triggered by either the number of iterations or an entropy threshold. In the decentralized multi-robot system, the proposed HCPP is embedded in each robot where each one of them shares its global 3D map ensuring robustness. The results performed in a realistic Gazebo robotic simulator confirmed the advantage of the proposed HCPP approach by achieving high coverage on different 3D unknown structures in a shorter time compared to conventional NBV.","2169-3536","","10.1109/ACCESS.2021.3139080","Khalifa University of Science and Technology(grant numbers:RC1-2018-KUCARS); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9664539","Autonomous exploration;multi-robot;coverage planning;LSTM;path prediction;3D reconstruction","Robots;Three-dimensional displays;Long short term memory;Multi-robot systems;Solid modeling;Robot sensing systems;Planning","","17","","50","CCBYNCND","28 Dec 2021","","","IEEE","IEEE Journals"
"Distributed deep reinforcement learning-based resource management for underwater acoustic communication networks","G. Wu; H. Wang; F. Mao; S. Wu","Graduate Student studying in the School of Physics and Information Engineering at Minnan Normal University in Fujian, China; Graduate Student studying in the School of Physics and Information Engineering at Minnan Normal University in Fujian, China; Graduate Student studying in the School of Physics and Information Engineering at Minnan Normal University in Fujian, China; School of Information and Electronic Engineering, Liming Vocational University, Quanzhou 362000, China",IEICE Transactions on Communications,"","2025","PP","99","1","14","This paper investigates the problem of distributed resource management in underwater acoustic communication networks (UACNs) involving multiple transmitters and receivers. In this setting, each transmitter autonomously selects a power allocation strategy based solely on local observations, without reliance on a central controller. Given that the optimization problem incorporating fairness and quality of service (QoS) constraints is non-convex and NP-hard, it is reformulated as a Markov Decision Process (MDP). To address the high complexity of underwater networks and the large state and action spaces, we propose a distributed learning framework based on a multi-agent dueling deep Q-network (MAD3QN). The proposed scheme enables each transmitter to dynamically adjust its transmission power based on local observations by integrating the Jain fairness index, QoS interruption penalty, and energy consumption constraints. Furthermore, by incorporating a dueling network architecture and a neighborhood cooperation mechanism, the learning efficiency is significantly enhanced, leading to a stable and effective resource optimization policy. Simulation results demonstrate that the proposed distributed learning algorithm outperforms existing approaches in terms of convergence speed, network fairness, and communication rate.","1745-1345","","10.23919/transcom.2025EBP3092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11169473","underwater acoustic communication networks;multi-agent dueling deep Q-network;dueling network architecture;neighborhood cooperation mechanism;network fairness","Resource management;Transmitters;Quality of service;Receivers;Mobile nodes;Interference;Underwater acoustics;Signal to noise ratio;Optimization;Energy consumption","","","","","","17 Sep 2025","","","IEICE","IEICE Early Access Articles"
"Reinforcement Learning-Based Voting for Feature Drift-Aware Intrusion Detection: An Incremental Learning Framework","M. A. Shyaa; N. F. Ibrahim; Z. B. Zainol; R. Abdullah; M. Anbar","School of Computer Sciences, Universiti Sains Malaysia (USM), Penang, Malaysia; School of Computer Sciences, Universiti Sains Malaysia (USM), Penang, Malaysia; School of Computer Sciences, Universiti Sains Malaysia (USM), Penang, Malaysia; School of Computer Sciences, Universiti Sains Malaysia (USM), Penang, Malaysia; National Advanced IPv6 Centre (NAv6), Universiti Sains Malaysia (USM), Penang, Malaysia",IEEE Access,"4 Mar 2025","2025","13","","37872","37903","In Intrusion Detection Systems (IDS), stream data classification faces significant challenges due to concept drifts and feature evolution, where traditional methods struggle to maintain accuracy over time. One critical challenge is feature drift, which refers to changes in the relevance of features over time, directly impacting the model’s classification accuracy. This paper introduces the Incremental Feature Drift-Aware Genetic Programming Combiner (IFDA-GPC), which integrates a Voting Enhanced Deep Q-Network Multi-Agent Feature Selection (VE-DQN-MAFS) mechanism to address these challenges. The framework extends the existing IGPC architecture by incorporating dynamic feature selection and employing a multi-agent system with voting-based aggregation. This approach enhances feature selection decisions, especially in cases where agents provide conflicting assessments of feature relevance. By reconciling these variations, the framework ensures consistency and reliability in real-time classification tasks. The framework was evaluated using benchmark datasets, including KDD Cup ’99, CICIDS-2017, HIKARI-2021, and ISCX2012, under both evolving and non-evolving scenarios. Results demonstrate that GPC-KOS-DFS, derived from IFDA-GPC, significantly outperformed existing methods in accuracy, F1-score, recall, and AUC metrics. Notably, it achieved an accuracy of 93% on the CICIDS-2017 dataset, showcasing its effectiveness in handling feature drifts while maintaining high classification performance. These findings establish IFDA-GPC as a robust solution for managing evolving data streams in intrusion detection systems.","2169-3536","","10.1109/ACCESS.2025.3544221","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10896652","Reinforcement learning;feature drift;concept drift;stream data classification;intrusion detection;dynamic feature selection","Feature extraction;Heuristic algorithms;Accuracy;Intrusion detection;Adaptation models;Faces;Genetic programming;Classification algorithms;Tuning;Sensitivity","","1","","46","CCBY","20 Feb 2025","","","IEEE","IEEE Journals"
"Implementation of Decentralized Reinforcement Learning-Based Multi-Quadrotor Flocking","P. Abichandani; C. Speck; D. Bucci; W. Mcintyre; D. Lobo","Department of Electrical and Computer Engineering, Newark College of Engineering (NCE), Robotics and Data Laboratory (RADLab), New Jersey Institute of Technology, Newark, NJ, USA; Lockheed Martin Advanced Technology Laboratories, Cherry Hill, NJ, USA; Lockheed Martin Advanced Technology Laboratories, Cherry Hill, NJ, USA; Department of Electrical and Computer Engineering, Newark College of Engineering (NCE), Robotics and Data Laboratory (RADLab), New Jersey Institute of Technology, Newark, NJ, USA; Department of Electrical and Computer Engineering, Newark College of Engineering (NCE), Robotics and Data Laboratory (RADLab), New Jersey Institute of Technology, Newark, NJ, USA",IEEE Access,"1 Oct 2021","2021","9","","132491","132507","Enabling coordinated motion of multiple quadrotors is an active area of research in the field of small unmanned aerial vehicles (sUAVs). While there are many techniques found in the literature that address the problem, these studies are limited to simulation results and seldom account for wind disturbances. This paper presents the experimental validation of a decentralized planner based on multi-objective reinforcement learning (RL) that achieves waypoint-based flocking (separation, velocity alignment, and cohesion) for multiple quadrotors in the presence of wind gusts. The planner is learned using an object-focused, greatest mass, state-action-reward-state-action (OF-GM-SARSA) approach. The Dryden wind gust model is used to simulate wind gusts during hardware-in-the-loop (HWIL) tests. The hardware and software architecture developed for the multi-quadrotor flocking controller is described in detail. HWIL and outdoor flight tests results show that the trained RL planner can generalize the flocking behaviors learned in training to the real-world flight dynamics of the DJI M100 quadrotor in windy conditions.","2169-3536","","10.1109/ACCESS.2021.3115711","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9548090","Cooperative systems;design for experiments;unmanned aerial vehicles;multi-agent systems;motion planning;supervised learning","Wind;Heuristic algorithms;Atmospheric modeling;Software algorithms;Mathematical models;Birds","","10","","88","CCBY","24 Sep 2021","","","IEEE","IEEE Journals"
"A Framework for Dynamically Meeting Performance Objectives on a Service Mesh","F. S. Samani; R. Stadler","Department of Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden; Department of Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden",IEEE Transactions on Network and Service Management,"19 Dec 2024","2024","21","6","5992","6007","We present a framework for achieving end-to-end management objectives for multiple services that concurrently execute on a service mesh. We apply reinforcement learning (RL) techniques to train an agent that periodically performs control actions to reallocate resources. We develop and evaluate the framework using a laboratory testbed where we run information and computing services on a service mesh, supported by the Istio and Kubernetes platforms. We investigate different management objectives that include end-to-end delay bounds on service requests, throughput objectives, cost-related objectives, and service differentiation. Our framework supports the design of a control agent for a given management objective. The management objective is defined first and then mapped onto available control actions. Several types of control actions can be executed simultaneously, which allows for efficient resource utilization. Second, the framework separates the learning of the system model and the operating region from the learning of the control policy. By first learning the system model and the operating region from testbed traces, we can instantiate a simulator and train the agent for different management objectives. Third, the use of a simulator shortens the training time by orders of magnitude compared with training the agent on the testbed. We evaluate the learned policies on the testbed and show the effectiveness of our approach in several scenarios. In one scenario, we design a controller that achieves the management objectives with 50% less system resources than Kubernetes HPA autoscaling.","1932-4537","","10.1109/TNSM.2024.3434328","Swedish Governmental Agency for Innovation Systems, VINNOVA, through project ANIARA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10612769","Performance management;adaptive resource allocation;microservice;reinforcement learning;operating region","Microservice architectures;Measurement;Training;Reinforcement learning;Delays;Resource management;Throughput","","1","","82","CCBY","26 Jul 2024","","","IEEE","IEEE Journals"
"An End-to-End Curriculum Learning Approach for Autonomous Driving Scenarios","L. Anzalone; P. Barra; S. Barra; A. Castiglione; M. Nappi","Department of Physics and Astronomy (DIFA), University of Bologna, Bologna, Italy; Department of Computer Science, Sapienza University of Rome, Rome, Italy; Department of Electrical and Information Technology Engineering (DIETI), University of Naples “Federico II”, Naples, Italy; Department of Science and Technology (DIST), University of Naples “Parthenope”, Naples, Italy; Department of Computer Science, University of Salerno, Salerno, Italy",IEEE Transactions on Intelligent Transportation Systems,"12 Oct 2022","2022","23","10","19817","19826","In this work, we combine Curriculum Learning with Deep Reinforcement Learning to learn without any prior domain knowledge, an end-to-end competitive driving policy for the CARLA autonomous driving simulator. To our knowledge, we are the first to provide consistent results of our driving policy on all towns available in CARLA. Our approach divides the reinforcement learning phase into multiple stages of increasing difficulty, such that our agent is guided towards learning an increasingly better driving policy. The agent architecture comprises various neural networks that complements the main convolutional backbone, represented by a ShuffleNet V2. Further contributions are given by (i) the proposal of a novel value decomposition scheme for learning the value function in a stable way and (ii) an ad-hoc function for normalizing the growth in size of the gradients. We show both quantitative and qualitative results of the learned driving policy.","1558-0016","","10.1109/TITS.2022.3160673","PRIN 2017 PREVUE: “PRediction of activities and Events by Vision in an Urban Environment,” through the Italian Ministry of Education, University and Research(grant numbers:2017N2RK7K); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9782734","Autonomous driving;CARLA simulator;automotive;deep reinforcement learning;curriculum learning","Autonomous vehicles;Training;Reinforcement learning;Task analysis;Planning;Cameras;Vehicle dynamics","","45","","45","CCBY","26 May 2022","","","IEEE","IEEE Journals"
"Navigating the Landscape of Deep Reinforcement Learning for Power System Stability Control: A Review","M. S. Massaoudi; H. Abu-Rub; A. Ghrayeb","Department of Electrical and Computer Engineering, Texas A&M University at Qatar, Doha, Qatar; Department of Electrical and Computer Engineering, Texas A&M University at Qatar, Doha, Qatar; Department of Electrical and Computer Engineering, Texas A&M University at Qatar, Doha, Qatar",IEEE Access,"5 Dec 2023","2023","11","","134298","134317","The widespread penetration of inverter-based resources has profoundly impacted the electrical stability of power systems (PSs). Deepening grid integration of photovoltaic and wind systems is introducing unforeseen uncertainties for the electricity sector. As a cutting-edge machine learning technology, deep reinforcement learning (DRL) breakthroughs have been in the spotlight over the last few years with potential contributions to PS stability (PSS). The ubiquitous DRL architecture, by learning from the dynamism inherent in PSs, produces near-optimal actions for PSS. This article provides a rigorous review of the latest research efforts focused on DRL to derive PSS policies while accounting for the unique properties of power grids. Furthermore, this paper highlights the theoretical advantages and the key tradeoffs of the emerging DRL techniques as powerful tools for optimal power flow. For all methods outlined, a discussion on their bottlenecks, research challenges, and potential opportunities in large-scale PSS is also presented. This review aims to support research in this area of DRL algorithms to embrace PSS against unseen faults and different PS topologies.","2169-3536","","10.1109/ACCESS.2023.3337118","Qatar National Research Fund [(QNRF) is a member of Qatar Foundation](grant numbers:NPRP12C-33905-SP-213,NPRP12C-33905-SP-220); Qatar National Library; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10329337","Deep reinforcement learning;dynamic security control;electric power systems;power system stability;smart grids","Power system stability;Stability analysis;Uncertainty;Optimization;Smart grids;Heuristic algorithms;Reinforcement learning;Deep learning;Security management","","28","","137","CCBY","27 Nov 2023","","","IEEE","IEEE Journals"
"A Survey on Microservices Trust Models for Open Systems","Z. Lu; D. T. Delaney; D. Lillis","School of Computer Science, University College Dublin, Dublin 4, Ireland; School of Electrical and Electronic Engineering, University College Dublin, Dublin 4, Ireland; School of Computer Science, University College Dublin, Dublin 4, Ireland",IEEE Access,"27 Mar 2023","2023","11","","28840","28855","The microservices architecture (MSA) is a form of distributed systems architecture that has been widely adopted in large-scale software systems in recent years. As with other distributed system architectures, one of the challenges that MSA faces is establishing trust between the microservices, particularly in the context of open systems. The boundaries of open systems are unlimited and unknown, which means that they can be applied to any use case. Microservices can leave or join an open system arbitrarily, without restriction as to ownership or origin, and MSA systems can scale extensively. The organisation of microservices (in terms of the roles they play and the communication links they utilise) can also change in response to changes in the environment in which the system is situated. The management of trust within MSAs is of great importance as the concept of trust is critical to microservices communication, and the operation of an open MSA system is highly reliant on communication between these fine-grained microservices. Thus, a trust model should also be able to manage trust in an open environment. Current trust management solutions, however, are often domain-specific and many are not specifically tailored towards the open system model. This motivates research on trust management in the context of open MSA systems. In this paper, we examine existing microservices trust models, identify the limitations of these models in the context of the principles of open microservices systems, propose a set of qualities for open microservices trust models that emerge from these limitations, and assess selected microservices trust models using the proposed qualities.","2169-3536","","10.1109/ACCESS.2023.3260147","Science Foundation Ireland (SFI) Strategic Partnerships Programme(grant numbers:16/SPP/3296); Origin Enterprises plc; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10077578","Microservices;trust management;service oriented architecture;open systems","Microservice architectures;Open systems;Web services;Trust management;Context modeling;Object oriented modeling;Computer architecture","","8","","72","CCBYNCND","21 Mar 2023","","","IEEE","IEEE Journals"
"Proactive AI-and-RAN Workload Orchestration in O-RAN Architectures for 6G Networks","S. D. A. Shah; M. Hafeez; A. Salama; S. A. R. Zaidi","School of Electronic and Electrical Engineering, University of Leeds, Leeds, U.K.; School of Electronic and Electrical Engineering, University of Leeds, Leeds, U.K.; School of Electronic and Electrical Engineering, University of Leeds, Leeds, U.K.; School of Electronic and Electrical Engineering, University of Leeds, Leeds, U.K.",IEEE Open Journal of the Communications Society,"1 Oct 2025","2025","6","","7939","7954","The vision of AI-RAN convergence, as advocated by the AI-RAN Alliance, aims to unlock a unified 6G platform capable of seamlessly supporting AI and RAN workloads over shared infrastructure. However, the architectural framework and intelligent resource orchestration strategies necessary to realize this vision remain largely unexplored. In this paper, we propose a Converged AI-and-ORAN Architectural (CAORA) framework based on O-RAN specifications, enabling the dynamic coexistence of real-time RAN and computationally intensive AI workloads. We design custom xApps within the Near-Real-Time RAN Intelligent Controller (NRT-RIC) to monitor RAN KPIs and expose radio analytics to an End-to-End (E2E) orchestrator via the recently introduced Y1 interface. The orchestrator incorporates workload forecasting and anomaly detection modules, augmenting a Soft Actor-Critic (SAC) reinforcement learning agent that proactively manages resource allocation, including Multi-Instance GPU (MIG) partitioning. Using real-world 5G traffic traces from Barcelona, our trace-driven simulations demonstrate that CAORA achieves near 99% fulfillment of RAN demands, supports dynamic AI workloads, and maximizes infrastructure utilization even under highly dynamic conditions. Our results reveal that predictive orchestration significantly improves system adaptability, resource efficiency, and service continuity, offering a viable blueprint for future AI-and-RAN converged 6G systems.","2644-125X","","10.1109/OJCOMS.2025.3608700","U.K. Research and Innovation (UKRI), Engineering and Physical Sciences Research Council (EPSRC)(grant numbers:EP/X040518/1,EP/Y037421/1 (CHEDDAR Project)); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11159494","O-RAN;6G;AI;xApp;RIC;SAC","Artificial intelligence;Resource management;Open RAN;Dynamic scheduling;Real-time systems;Monitoring;Computer architecture;6G mobile communication;Graphics processing units;Forecasting","","","","31","CCBY","11 Sep 2025","","","IEEE","IEEE Journals"
"Inter-AGV Scheduling and a Novel Multi-Agent Collaborative Protocol for Intra-AGV Resource Allocation in MEC-Enabled Multi-AGV Scenarios","J. Palomares; E. Carmona-Cejudo; C. Cervelló-Pastor; E. Coronado; H. Chergui; M. Shuaib Siddiqui","Software Networks, i2CAT Foundation, Barcelona, Spain; Software Networks, i2CAT Foundation, Barcelona, Spain; Department of Network Engineering, Universitat Politècnica de Catalunya, Castelldefels, Spain; Software Networks, i2CAT Foundation, Barcelona, Spain; Software Networks, i2CAT Foundation, Barcelona, Spain; Software Networks, i2CAT Foundation, Barcelona, Spain",IEEE Open Journal of the Communications Society,"19 May 2025","2025","6","","4238","4259","In modern novel collaborative multi-Automated Guided Vehicle (AGV) systems, vehicles are responsible for executing both mission-critical process-related operations and purely computational tasks, such as collision avoidance. This work investigates the problem of joint inter-AGV task placement and intra-AGV computational resource allocation in MEC-enabled multi-AGV environments. To address this challenge, a two-step strategy is proposed to maximize the number of scheduled and completed tasks across multiple AGVs while ensuring fair and efficient resource use within each AGV. The problem of inter-AGV task placement is solved by dynamically applying a catalog of deep reinforcement learning (DRL) models for varying numbers of AGVs. Training time for these models is reduced threefold by using datasets from existing optimization solvers. Transfer learning further reduces training times by up to 51%. Second, a multi-agent deep reinforcement learning (MADRL)-based collaborative protocol for dynamic intra- AGV resource allocation (MACP-DRA) is proposed, allowing AGVs to adjust computational resources dynamically. It incorporates a minimum guaranteed share strategy to ensure fair resource distribution while optimizing performance under dynamic workloads. Compared to existing MADRL approaches, MACP-DRA enhances conflict resolution efficiency while maintaining low computational cost. Evaluation results demonstrate that the proposed inter-AGV scheduling strategy approaches optimal performance while achieving a superior trade-off between decision time and task completion rates. Compared to a multi-agent DRL baseline, the proposed MACP-DRA models reduced resource conflicts by 54.9%, task processing delays by 35.7%, and resource underutilization by 9.93%, while maintaining minimal computational and energy consumption overhead.","2644-125X","","10.1109/OJCOMS.2025.3567585","Spanish MINECO and the EU’s – NextGeneration EU, in the framework of the PRTR (Call UNICO I+D 5G 2021)(grant numbers:TSI-063000-2021-9-6GSMART-ICC); EU “NextGenerationEU/PRTR”, MCIN, AEI, Spain(grant numbers:IJC2020-043058-I); CERCA Programme/Generalitat de Catalunya; MCIN/AEI/10.13039/501100011033 (FEDER “a way of making Europe”)(grant numbers:PID2022-142332OA-I00); Horizon Europe through the Project NANCY(grant numbers:101096456); Project COGNIFOG(grant numbers:101092968); MCIN/AEI/10.13039/501100011033(grant numbers:ONOFRE-3 PID2020-112675RB-C43); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10990154","Multi-AGV;Multi-agent collaboration;Scheduling;Resource allocation;MEC","Resource management;Dynamic scheduling;Job shop scheduling;Computational modeling;Adaptation models;Collaboration;Processor scheduling;Optimization;Protocols;Deep reinforcement learning","","2","","54","CCBY","7 May 2025","","","IEEE","IEEE Journals"
"Using Graph Neural Networks in Reinforcement Learning With Application to Monte Carlo Simulations in Power System Reliability Analysis","Ø. R. Solheim; B. Annfelt Høverstad; M. Korpås","Statnett SF, Oslo, Norway; Statnett SF, Oslo, Norway; Department of Electric Energy, Norwegian University of Science and Technology (NTNU), Trondheim, Norway",IEEE Access,"6 Nov 2024","2024","12","","160175","160189","This paper presents a novel method for power system reliability studies that combines graph neural networks with reinforcement learning. Monte Carlo methods are the backbone of probabilistic power system reliability analyses. Recent efforts from the authors indicate that optimal power flow solvers could potentially be replaced with the policies of deep reinforcement learning agents, to obtain significant speedups of Monte Carlo simulations while retaining close to optimal accuracies. However, a limitation of that reinforcement learning approach was that the training of the agent is tightly connected to the specific case being analyzed, and the agent cannot be used as is in new, unseen cases. In this paper, we seek to overcome these issues by representing the state and actions in the power reliability environment by features in a graph, where the adjacency matrix can vary from time step to time step. By combining this with a message-passing graph neural network-based reinforcement agent, we are able to train an agent where the agent model is independent of the power system grid structure. For the actor part of this architecture, we have implemented both a deterministic agent being a variant of the Twin Delayed DDPG-algorithm, and a stochastic agent with similarities to the Soft Actor Critic-algorithm. We show that the agent can solve small extensions of a test case without having seen the new parts of the power system during training. In all of our reliability Monte Carlo simulations using this graph neural network agent, the simulation time is competitive with that based on optimal power flow, while still retaining close to optimal accuracy.","2169-3536","","10.1109/ACCESS.2024.3486354","Norwegian Research Council(grant numbers:310436); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10735201","Reinforcement learning;power systems;graph neural networks;reliability;Monte Carlo simulation","Power system reliability;Power systems;Reliability;Reinforcement learning;Monte Carlo methods;Graph neural networks;Costs;Power system dynamics;Stochastic processes;Generators","","2","","45","CCBYNCND","25 Oct 2024","","","IEEE","IEEE Journals"
"A Trust-Based Agent Learning Model for Service Composition in Mobile Cloud Computing Environments","W. Li; J. Cao; K. Hu; J. Xu; R. Buyya","Qianjiang College, Hangzhou Normal University, Hangzhou, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Qianjiang College, Hangzhou Normal University, Hangzhou, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Cloud Computing and Distributed Systems (CLOUDS) Laboratory, The University of Melbourne, Melbourne, VIC, Australia",IEEE Access,"26 Mar 2019","2019","7","","34207","34226","Mobile cloud computing has the features of resource constraints, openness, and uncertainty which leads to the high uncertainty on its quality of service (QoS) provision and serious security risks. Therefore, when faced with complex service requirements, an efficient and reliable service composition approach is extremely important. In addition, preference learning is also a key factor to improve user experiences. In order to address them, this paper introduces a three-layered trust-enabled service composition model for the mobile cloud computing systems. Based on the fuzzy comprehensive evaluation method, we design a novel and integrated trust management model. Service brokers are equipped with a learning module enabling them to better analyze customers’ service preferences, especially in cases when the details of a service request are not totally disclosed. Because traditional methods cannot totally reflect the autonomous collaboration between the mobile cloud entities, a prototype system based on the multi-agent platform JADE is implemented to evaluate the efficiency of the proposed strategies. The experimental results show that our approach improves the transaction success rate and user satisfaction.","2169-3536","","10.1109/ACCESS.2019.2904081","National Natural Science Foundation of China(grant numbers:61702151,61702320); National Key Research and Development Plan(grant numbers:2018YFB1003800); Department of Education of Zhejiang Province(grant numbers:Y201635438); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8664162","Mobile cloud computing;service composition;trust management;user preference learning;multi-agent technology","Cloud computing;Scheduling;Quality of service;Task analysis;Computational modeling;Processor scheduling;Trust management","","39","","54","OAPA","10 Mar 2019","","","IEEE","IEEE Journals"
"Route Selection for Multi-Hop Cognitive Radio Networks Using Reinforcement Learning: An Experimental Study","A. R. Syed; K. -L. A. Yau; J. Qadir; H. Mohamad; N. Ramli; S. L. Keoh","Faculty of Science and Technology, Sunway University, Selangor, Malaysia; Faculty of Science and Technology, Sunway University, Selangor, Malaysia; Information Technology University, Lahore, Pakistan; Wireless Network and Protocol Research Lab, MIMOS Berhad, Kuala Lumpur, Malaysia; Wireless Network and Protocol Research Lab, MIMOS Berhad, Kuala Lumpur, Malaysia; School of Computing Science, University of Glasgow Singapore, Singapore",IEEE Access,"20 May 2017","2016","4","","6304","6324","Cognitive radio (CR) enables unlicensed users to explore and exploit underutilized licensed channels (or white spaces). While multi-hop CR network has drawn significant research interest in recent years, majority work has been validated through simulation. A key challenge in multi-hop CR network is to select a route with high quality of service (QoS) and lesser number of route breakages. In this paper, we propose three route selection schemes to enhance the network performance of CR networks, and investigate them using a real testbed environment, which consists of universal software radio peripheral and GNU radio units. Two schemes are based on reinforcement learning (RL), while a scheme is based on spectrum leasing (SL). RL is an artificial intelligence technique, whereas SL is a new paradigm that allows communication between licensed and unlicensed users in CR networks. We compare the route selection schemes with an existing route selection scheme in the literature, called highest-channel (HC), in a multi-hop CR network. With respect to the QoS parameters (i.e., throughput, packet delivery ratio, and the number of route breakages), the experimental results show that RL approaches achieve a better performance in comparison with the HC approach, and also achieve close to the performance achieved by the SL approach.","2169-3536","","10.1109/ACCESS.2016.2613122","Malaysian Ministry of Science, Technology and Innovation under Science Fund(grant numbers:01-02-16-SF0027); Malaysian Ministry of Education Fundamental Research Grant Scheme(grant numbers:FRGS/1/2014/ICT03/SYUC/02/2); Small Grant Scheme (Sunway-Lancaster)(grant numbers:SGSSL-FST-CSNS-0114-05,PVM1204); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7575676","Cognitive radio;multi-hop network;route selection;reinforcement learning;spectrum leasing","Spread spectrum communication;Channel estimation;Quality of service;Throughput;Systems architecture;Switches;Learning (artificial intelligence)","","36","","46","OAPA","23 Sep 2016","","","IEEE","IEEE Journals"
"ARCog-NET: An Aerial Robot Cognitive Network Architecture for Swarm Applications Development","G. S. Ramos; F. D. R. Henriques; D. B. Haddad; F. A. A. Andrade; M. F. Pinto","Federal Center for Technological Education Celso Suckow da Fonseca (CEFET-RJ), Rio de Janeiro, Brazil; Federal Center for Technological Education Celso Suckow da Fonseca (CEFET-RJ), Rio de Janeiro, Brazil; Federal Center for Technological Education Celso Suckow da Fonseca (CEFET-RJ), Rio de Janeiro, Brazil; Department of Microsystems, Faculty of Technology, Natural Sciences and Maritime Sciences, University of South-Eastern Norway (USN), Borre, Norway; Federal Center for Technological Education Celso Suckow da Fonseca (CEFET-RJ), Rio de Janeiro, Brazil",IEEE Access,"23 Sep 2024","2024","12","","129040","129063","This work presents an advanced cognitive architecture for networked aerial robots to implement autonomous swarm systems effectively. It focuses on designing, implementing, and evaluating an architecture that enables unmanned aerial vehicles (UAVs) to coordinate and cooperate for complex tasks, with or without human intervention. Inspired by artificial intelligence, cognitive science, and robotics, the architecture integrates perception, planning, decision-making, and adaptive learning to optimize swarm behavior in dynamic environments. The architecture uses a distributed processing model based on the “edge-fog-cloud” (EFC) concept. Edge-level robots handle real-time data collection, local decision-making, and environmental perception. Fog-level vehicles manage intermediate processing and supervision of the groups, while cloud servers perform comprehensive data analysis and long-term storage, being the higher-level hierarchy of the framework. This structure allows efficient distribution of computational tasks, with critical decisions made at the robot level and complex analysis done in the fog or cloud. The implementation of ARCog-NET involves deploying a multi-agent simulation system using the Robot Operating System (ROS) and Gazebo simulator, facilitating the integration of sensors, communication protocols, and data processing algorithms. The performance evaluation demonstrates the architecture’s effectiveness in a wind farm inspection scenario, where the UAV swarm exhibits improved trajectory planning, collision avoidance, and data processing efficiency. Simulation results show that ARCog-NET reduces latency, increases data throughput, and enhances operational effectiveness, providing a robust platform for future developers to focus on applications and direct robot control methods.","2169-3536","","10.1109/ACCESS.2024.3456914","Coordenação de Aperfeiçoamento de Pessoal de Nível Superior-Brasil (CAPES)(grant numbers:001); Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq) and Fundação Carlos Chagas Filho de Amparo à Pesquisa do Estado do Rio de Janeiro (FAPERJ); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10670387","Cognitive architecture;edge-fog-cloud technologies;swarm systems;distributed data processing;autonomy of aerial robots","Robots;Robot kinematics;Cloud computing;Autonomous aerial vehicles;Decision making;Computer architecture;Real-time systems;Network architecture;Edge computing;Distributed databases","","6","","93","CCBYNCND","10 Sep 2024","","","IEEE","IEEE Journals"
"Reinforcement Learning-Driven Adaptive Prefetch Aggressiveness Control for Enhanced Performance in Parallel System Architectures","H. Yang; J. Fang; Y. Hou; X. Su; N. N. Xiong","College of Computer Science, Beijing University of Technology, Beijing, China; College of Computer Science, Beijing University of Technology, Beijing, China; College of Computer Science, Beijing University of Technology, Beijing, China; College of Computer Science, Beijing University of Technology, Beijing, China; Department of Computer, Mathematical and Physical Sciences, Sul Ross State University, Alpine, TX, USA",IEEE Transactions on Parallel and Distributed Systems,"9 Apr 2025","2025","36","5","977","993","In modern parallel system architectures, prefetchers are essential to mitigating the performance challenges posed by long memory access latencies. These architectures rely heavily on efficient memory access patterns to maximize system throughput and resource utilization. Prefetch aggressiveness is a central parameter in managing these access patterns; although increased prefetch aggressiveness can enhance performance for certain applications, it often risks causing cache pollution and bandwidth contention, leading to significant performance degradation in other workloads. While many existing prefetchers rely on static or simple built-in aggressiveness controllers, a more flexible, adaptive approach based on system-level feedback is essential to achieving optimal performance across parallel computing environments. In this paper, we introduce an Adaptive Prefetch Aggressiveness Control (APAC) framework that leverages Reinforcement Learning (RL) to dynamically manage prefetch aggressiveness in parallel system architectures. The APAC controller operates as an RL agent, which optimizes prefetch aggressiveness by dynamically responding to system feedback on prefetch accuracy, timeliness, and cache pollution. The agent receives a reward signal that reflects the impact of each adjustment on both performance and memory bandwidth, learning to adapt its control strategy based on workload characteristics. This data-driven adaptability makes APAC particularly well-suited for parallel architectures, where efficient resource management across cores is essential to scaling system performance. Our evaluation with the ChampSim simulator demonstrates that APAC effectively adapts to diverse workloads and system configurations, achieving performance gains of 6.73$\%$% in multi-core systems compared to traditional Feedback Directed Prefetching (FDP). By improving memory bandwidth utilization, reducing cache pollution, and minimizing inter-core interference, APAC significantly enhances prefetching performance in multi-core processors. These results underscore APAC’s potential as a robust solution for performance optimization in parallel system architectures, where efficient resource management is paramount for scaling modern processing environments.","1558-2183","","10.1109/TPDS.2025.3550531","National Natural Science Foundation of China(grant numbers:62276011,61202076); Beijing Municipal Natural Science Foundation(grant numbers:4192007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10923695","Data prefetchers;memory bandwidth;prefetcher aggressiveness controller;parallel system architectures;reinforcement learning","Prefetching;Systems architecture;Bandwidth;Pollution;Accuracy;System performance;Real-time systems;Random access memory;Resource management;Adaptive systems","","1","","57","CCBYNCND","12 Mar 2025","","","IEEE","IEEE Journals"
"Robust Reinforcement Learning Under Dimension-Wise State Information Drop","G. Kim; J. Kim; S. Lee; J. Baek; H. Moon; S. Shin; Y. Sung","School of Electrical Engineering, KAIST, Daejeon, Republic of Korea; School of Electrical Engineering, KAIST, Daejeon, Republic of Korea; School of Electrical Engineering, KAIST, Daejeon, Republic of Korea; Intelligence C4I Team, Hanwha Systems, Seoul, Gyeonggi-do, Republic of Korea; Intelligence C4I Team, Hanwha Systems, Seoul, Gyeonggi-do, Republic of Korea; Intelligence C4I Team, Hanwha Systems, Seoul, Gyeonggi-do, Republic of Korea; School of Electrical Engineering, KAIST, Daejeon, Republic of Korea",IEEE Access,"1 Oct 2024","2024","12","","135283","135299","Recent advancements in offline reinforcement learning (RL) have showcased the potential for leveraging static datasets to train optimal policies. However, real-world applications often face challenges due to missing or incomplete state information caused by imperfect sensor performance or intentional interlaces. We propose the Dimension-Wise Drop Decision Transformer (D3T), a novel framework designed to address dimension-wise data loss in sensor observations, enhancing the robustness of RL algorithms in real-world scenarios. D3T innovatively incorporates dimension-wise drop information embeddings within the Transformer architecture, facilitating effective decision-making even with incomplete observations. Our evaluation in the D4RL MuJoCo domain demonstrates that D3T significantly outperforms existing methods such as the Decision Transformer, particularly with substantial dimension-wise drops of observations. These results confirm D3T’s capability in managing real-world imperfections in state observations and illustrate its potential to substantially expand the applicability of RL in more complex and dynamic environments.","2169-3536","","10.1109/ACCESS.2024.3462803","Korea Research Institute for Defense Technology Planning and Advancement grant funded by the Defense Acquisition Program Administration(grant numbers:KRIT-CT-21-041); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10681552","Dimension-wise state information drop;masked observation;drop information embedding;reinforcement learning;robust learning","Transformers;Training;Robustness;Terminology;Program processors;Delays;Reinforcement learning;Robust stability","","","","33","CCBY","17 Sep 2024","","","IEEE","IEEE Journals"
"Utilizing Deep improved ResNet50 for Brain Tumor Classification Based MRI","K. Neamah; F. Mohamed; S. R. Waheed; W. H. M. Kurdi; A. Y. Taha; K. A. Kadhim","Faculty of Engineering, School of Computing, University Technology of Malaysia Johor Bahru, Skudai, Johor, Malaysia; UTM-IRDA MaGICX, Institute of Human Centered Engineering, Universiti Teknologi Malaysia Johor Bahru, Skudai, Johor, Malaysia; Islamic University, Najaf, Iraq; Altoosi University College, Computer Science, Najaf, Iraq; Al-Safwa University College, Department of Medical Instrumentation Techniques, Engineering, Karbala, Iraq; Faculty of Engineering, School of Computing, University Technology of Malaysia Johor Bahru, Skudai, Johor, Malaysia",IEEE Open Journal of the Computer Society,"23 Sep 2024","2024","5","","446","456","A robust approach for brain tumor classification is being developed using deep convolutional neural networks (CNNs). This study leverages an open-source dataset derived from the MRI Brats2015 brain tumor dataset. Preprocessing included intensity normalization, contrast enhancement, and downsizing. Data augmentation techniques were also applied, encompassing rotations and flipping. The core of our proposed approach lies in the utilization of a modified ResNet-50 architecture for feature extraction. This model integrates transfer learning by replacing the final layer with a spatial pyramid pooling layer, enabling it to leverage pre-trained parameters from ImageNet. Transfer learning from ImageNet aids in countering overfitting. Our model's performance was evaluated with various hyperparameters, including existing methods in terms of accuracy, precision, recall, F1-score, sensitivity, and specificity. This study showcases the potential of deep learning, transfer learning, and spatial pyramid pooling in MRI-based brain tumor classification, providing an effective tool for medical image analysis. Our methodology employs a modified ResNet-50 architecture with transfer learning, integrating a spatial pyramid pooling layer for feature extraction. Systematic evaluation showcases the model's superiority over existing methods, demonstrating remarkable results in accuracy (0.9902), precision (0.9837), recall (0.9915), F1-score (0.9891), sensitivity, and specificity. The comparative analysis against prominent CNN architectures reaffirms its outstanding performance. Our model not only mitigates overfitting challenges but also offers a promising tool for medical image analysis, underlining the combined efficacy of spatial pyramid pooling and transfer learning. The study's optimization parameters, including 25 epochs, a learning rate of 1e-4, and a balanced batch size, contribute to its robustness and real-world applicability, furthering advancements in efficient brain tumor classification within MRI data.","2644-1268","","10.1109/OJCS.2024.3453924","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10670206","Brain tumor detection;CNN;data augmentation;Resnet-50;transfer learning","Tumors;Brain modeling;Biomedical imaging;Magnetic resonance imaging;Transfer learning;Computer architecture;Feature extraction","","8","","32","CCBYNCND","10 Sep 2024","","","IEEE","IEEE Journals"
"Supporting Intelligence in Disaggregated Open Radio Access Networks: Architectural Principles, AI/ML Workflow, and Use Cases","A. Giannopoulos; S. Spantideas; N. Kapsalis; P. Gkonis; L. Sarakis; C. Capsalis; M. Vecchio; P. Trakadas","Department of Ports Management and Shipping, National and Kapodistrian University of Athens, Euboea, Greece; Department of Ports Management and Shipping, National and Kapodistrian University of Athens, Euboea, Greece; Department of Ports Management and Shipping, National and Kapodistrian University of Athens, Euboea, Greece; Department of Digital Industry Technologies, National and Kapodistrian University of Athens, Euboea, Greece; Department of Digital Industry Technologies, National and Kapodistrian University of Athens, Euboea, Greece; School of Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece; Fondazione Bruno Kessler, Trento, Italy; Department of Ports Management and Shipping, National and Kapodistrian University of Athens, Euboea, Greece",IEEE Access,"19 Apr 2022","2022","10","","39580","39595","Driven by the emerging trend for transparent, open and programmable communications, Open Radio Access Network (O-RAN) constitutes the dominant architectural approach for deploying the future wireless networks. Towards standardizing and specifying the building blocks and principles of O-RAN, a coordinated global effort has been observed, mainly comprised of the O-RAN Alliance, the operators and several research activities. This paper presents the architectural aspects and the current status of O-RAN deployments, integrating both existing and ongoing activities from the O-RAN enablers. Furthermore, since the Artificial Intelligence and Machine Learning (AI/ML) act as key pillars for realizing O-RANs, a comprehensive view on the AI/ML functionality is provided as well. Additionally, a Network Telemetry (NT) architecture is also proposed to ensure end-to-end data collection and real-time analytics. To concretely illustrate the O-RAN supporting mechanisms for hosting AI/ML, we implemented two realistic ML algorithms: (i) a Supervised Learning (SL) based algorithm for cell traffic prediction using the training data of an open dataset and (ii) a Deep Reinforcement Learning (DRL) based algorithm for energy-efficiency maximization using a 5G-compliant simulator to obtain RAN measurements. We schematically demonstrate the AI/ML workflow for both ML-assisted algorithms through the usage of xApps running on the Radio Intelligent Controller (RIC), as well as we outline the role of the O-RAN components involved in the AI/ML loop. Combining the high-level architectural descriptions with a detailed presentation of ML-empowered resource allocation schemes, the paper discusses and summarizes the O-RAN disaggregation principles and the role of AI/ML embedded in future O-RAN deployments.","2169-3536","","10.1109/ACCESS.2022.3166160","European Commission through the Affordable5G Project(grant numbers:H2020-ICT-2020-1); Horizon 2020 and 5G-PPP Programs(grant numbers:957317); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9754560","5G;B5G;O-RAN;AI/ML;radio intelligent controller;resource allocation;supervised learning;reinforcement learning","Computer architecture;5G mobile communication;Software;Resource management;Cloud computing;Real-time systems;Radio access networks","","55","","37","CCBY","11 Apr 2022","","","IEEE","IEEE Journals"
"Adaptive Routing in Wireless Mesh Networks Using Hybrid Reinforcement Learning Algorithm","S. Mahajan; R. Harikrishnan; K. Kotecha","Department of Computer Science Engineering, Symbiosis Institute of Technology, Symbiosis International (Deemed) University, Pune, Maharashtra, India; Department of Electronics and Telecommunication Engineering, Symbiosis Institute of Technology, Symbiosis International (Deemed) University, Pune, Maharashtra, India; Department of Symbiosis Centre for Applied AI (SCAAI), Symbiosis Institute of Technology, Symbiosis International (Deemed) University, Pune, Maharashtra, India",IEEE Access,"17 Oct 2022","2022","10","","107961","107979","Wireless mesh networks are popular due to their adaptability, easy-setup, flexibility, cost, and transmission time-reductions. The routing algorithm plays a vital role in transferring the data between the nodes. The network’s performance is significantly impacted by the route opted by the algorithm. The router takes the decision to send the packet to the next router as per the policy of that algorithm. So even though that decision does not favor the right path selection, the router tends to follow its policy. This can be avoided by having intelligent routers that can make routing decisions on the fly. This paper presents the QL-Feed Forward routing algorithm (QFFR), a new generation of routing algorithms that combines reinforcement learning based on the Q-learning algorithm with a Feed Forward neural network. This algorithm (QFFR) can learn from the network environment and make routing decisions based on the algorithm’s learnings. The AI agent’s ability to select the fastest path, which enhances the efficiency of the routing operation, is demonstrated by the working of the suggested QFFR algorithm. This paper also evaluates the performance of traditional algorithms, namely, Ad-hoc On-Demand Distance-Vector, Optimized-Link-State-routing, Destination-Sequenced Distance-Vector and Distance Source routing. The evaluation parameters include throughput, packet delivery ratio, and delay. The parameters are the outcomes of the time the information takes to reach from source to destination. This analysis highlights the improvement in the routing decision ability of a router. As per analysis, Ad hoc On-Demand Distance Vector Algorithm outperforms with throughput 723.13 Kbps, delay 343.73 ns. Q-learning agent identifies the route and reaches the destination in average of 3.7s in non-grid architecture. The Q-learning agent takes 0.49sec with a grid size ten by ten and 0.53sec in three by four grid size. The suggested QFFR takes 7.62s score-over time with stable, consistent performance.","2169-3536","","10.1109/ACCESS.2022.3210993","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9906058","Deep Learning;reinforcement learning;Q-learning;Markov decision process;Routing Algorithms;Wireless Mesh Networks","Reinforcement learning;Routing protocols;Ad hoc networks;AODV;Wireless communication;Q-learning;Throughput;Delays;Costs;Artificial intelligence;Adaptive systems;Wireless mesh networks","","26","","64","CCBY","30 Sep 2022","","","IEEE","IEEE Journals"
"A Cooperative Online Learning-Based Load Balancing Scheme for Maximizing QoS Satisfaction in Dense HetNets","H. Choi; T. Kim; H. -S. Park; J. K. Choi","School of Information and Communication Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea; School of Information and Communication Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea",IEEE Access,"1 Jul 2021","2021","9","","92345","92357","This paper proposes a cooperative multi-agent online reinforcement learning-based (COMORL) bias offset (BO) control scheme for cell range expansion (CRE) in dense heterogeneous networks (HetNets). The proposed COMORL scheme controls BOs for CRE to maximize the number of user equipments (UEs) that satisfy their quality of service (QoS) requirements, especially in terms of delay and data rates. For this purpose, we developed a QoS satisfaction indicator that measures a violation of delay requirements by considering both QoS requirements and signal-to-interference-plus-noise ratio (SINR). In addition, we formulated a Markov decision process (MDP) model that is solved with a cooperative multi-agent online reinforcement learning algorithm. The proposed COMORL scheme maximizes the global utility for load-coupled base stations. Our simulation results verify the proposed COMORL scheme’s effectiveness in terms of throughput, delay satisfaction ratio, and fairness. Specifically, we verify that the proposed COMORL scheme achieves a maximum of approximately 27% and 30% improvement of the delay satisfaction ratio, which is how many UEs satisfy their delay requirement among all of the UEs in a serving BS under medium and full traffic loads, respectively, in a dynamic scenario in comparison to the max-SINR scheme.","2169-3536","","10.1109/ACCESS.2021.3089782","Institute of Information and Communications Technology Planning and Evaluation (IITP) grant through the Korea Government (MSIT), Development of Autonomous Collaborative Swarm Intelligence Technologies for Disposable IoT Devices(grant numbers:2018-0-00691); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9456913","Hetnets;cell range expansion;load balancing;QoS;cooperative multi-agent reinforcement learning","Quality of service;Delays;Computer architecture;Microprocessors;Load management;Throughput;Optimization","","3","","34","CCBYNCND","16 Jun 2021","","","IEEE","IEEE Journals"
"Artificial Intelligence in UAV Flight Controls: Deep Reinforcement Learning Based Altitude-Hold Strategies for Fixed-Wing UAVs","H. R. Khanzada; A. Maqsood; A. Basit","School of Interdisciplinary Engineering and Science, National University of Science and Technology, Islamabad, Pakistan; School of Interdisciplinary Engineering and Science, National University of Science and Technology, Islamabad, Pakistan; College of Aeronautical Engineering (CAE), National University of Sciences and Technology, Islamabad, Pakistan",IEEE Access,"30 Jun 2025","2025","13","","109670","109686","This paper implements a deep reinforcement learning (DRL) based flight control system for a fixed-wing uncrewed aerial vehicle (UAV). Unlike conventional flight control methods, DRL does not require an exact mathematical system model for the design and can handle non-linear coupled dynamics of highly agile aerospace vehicles like small-size UAVs. The deep deterministic policy gradient (DDPG) method was chosen to suit environments with continuous action spaces. The key contribution of this research is the implementation of three distinct approaches that successfully replace traditional classical control systems with Reinforcement Learning (RL)-based controllers, each offering unique advantages and exploring different trade-offs between interpretability, complexity, and performance crucial for safety-critical aerospace applications. The classical Proportional-Integral-Derivative (PID) flight control architecture, consisting of an altitude controller followed by a pitch (theta) controller, was developed as a baseline. Subsequently, three approaches were investigated; First, the altitude hold controller was replaced by a Reinforcement Learning (RL) agent, while the PID control was maintained for pitch control. In the second approach, both the altitude and pitch control loops were substituted with RL agents. Finally, a single RL agent replaced both the altitude and pitch angle control loops, unifying control under a single agent. A comparative analysis has been made with the widely used conventional PID controls to assess the effectiveness of the each implemented control system. The RL controllers outperformed the baseline PID controllers, among which the unified RL controller achieved a steady-state error of 0.58 meters and a transient response time of 5 seconds, compared to the PID controller’s 1.11 meter steady-state error and transient response time of 16 seconds, thereby reducing the error by 48% and improving the response time by nearly 69%. These results demonstrate the superior accuracy and response efficiency of the proposed RL-based control strategies. Notably, the implementation featuring a single RL agent yields promising results, highlighting the capacity of RL agents to handle complex control challenges. This approach simplifies the control system design by eliminating the need for a multiple-loop architecture. The outcomes of this study underscore the potential of RL-based controllers to enhance the performance of UAVs. Furthermore, the results offer valuable insights for developing future UAV control systems, emphasizing the advantages of RL techniques over traditional PID controls.","2169-3536","","10.1109/ACCESS.2025.3581966","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11045900","Reinforcement learning;uncrewed aerial vehicles;attitude hold;PID control;hybrid control;altitude-hold","Autonomous aerial vehicles;PI control;PD control;Reinforcement learning;Aerodynamics;Vehicle dynamics;Artificial intelligence;Training;Time factors;Mathematical models","","2","","56","CCBYNCND","23 Jun 2025","","","IEEE","IEEE Journals"
"Automated Diagnosis of Knee Osteoarthritis: A Stacked Ensemble Deep Learning Approach with Explainable AI Techniques","M. Azad; T. R. Anik","Department of Computer Science, College of Computer and Information Sciences, Jouf University, Sakaka, Saudi Arabia; Department of Computer Science and Engineering, Ahsanullah University of Science and Technology, Dhaka, Bangladesh",IEEE Access,"","2025","PP","99","1","1","Knee osteoarthritis (KOA) is a widespread degenerative joint disease that poses significant global challenges owing to delayed diagnosis and treatment, often resulting in severe disability. Despite extensive research on predicting KOA, many proposed methods lack reliability, because they fail to incorporate explainable AI (XAI) methodologies, robust preprocessing techniques, and appropriate hyperparameter tuning. This study introduces a deep learning framework for KOA classification, addressing both binary (diagnosis) and multi-class (severity prediction) classification tasks using the Osteoarthritis Initiative (OAI) dataset. Our approach is enhanced by a comprehensive image prepocessing pipeline that includes scaling, sharpening, denoising, histogram equalization, and contrast enhancement, which standardizes image quality and highlights crucial features for classification. The proposed stacked ensemble model, which integrates Xception, EfficientNetB5, and InceptionV3, surpasses individual models, achieving 86.29% accuracy in KOA diagnosis and 96.93% in KOA severity prediction. To ensure transparency and interpretability, we incorporated advanced explainability tools, including Gradient-weighted Class Activation Mapping (Grad-CAM), Faster Score-CAM, and Local Interpretable Model-agnostic Explanations (LIME), providing clear visual insights into the model’s decision-making process. Our findings present a balanced approach that combines performance with transparency, potentially leading to earlier and more accurate KOA diagnoses.","2169-3536","","10.1109/ACCESS.2025.3631513","Al Jouf University(grant numbers:DGSSR-2024-02-02103); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11239041","Knee Osteoarthritis;Image Preprocessing;Deep Learning;Stacked Ensemble;Explainable AI;Hyperparameter Tuning","Accuracy;Deep learning;Three-dimensional displays;Predictive models;Osteoarthritis;Magnetic resonance imaging;X-ray imaging;Tuning;Support vector machines;Transfer learning","","","","","CCBYNCND","11 Nov 2025","","","IEEE","IEEE Early Access Articles"
"Reinforcement Learning Environment for Cyber-Resilient Power Distribution System","A. Sahu; V. Venkatraman; R. Macwan","National Renewable Energy Laboratory, Boulder, CO, USA; National Renewable Energy Laboratory, Boulder, CO, USA; National Renewable Energy Laboratory, Boulder, CO, USA",IEEE Access,"17 Nov 2023","2023","11","","127216","127228","Recently, numerous data-driven approaches to control an electric grid using machine learning techniques have been investigated. Reinforcement learning (RL)-based techniques provide a credible alternative to conventional, optimization-based solvers especially when there is uncertainty in the environment, such as renewable generation or cyber system performance. Efficiently training an agent, however, requires numerous interactions with an environment to learn the best policies. There are numerous RL environments for power systems, and, similarly, there are environments for communication systems. Most cyber system simulators are based in a UNIX environment, while the power system simulators are based in the Windows operating system. Hence the generation of a cyber-physical, mixed-domain RL environment has been challenging. Existing co-simulation methods are efficient, but are resource and time intensive to generate large-scale data sets for training RL agents. Hence, this work focuses on the development and validation of a mixed-domain RL environment using OpenDSS for the power system and leveraging a discrete event simulator Python package, SimPy for the cyber system, which is operating system agnostic. Further, we present the results of co-simulation and training RL agents for a cyber-physical network reconfiguration and Volt-Var control problem in a power distribution feeder.","2169-3536","","10.1109/ACCESS.2023.3282182","National Renewable Energy Laboratory (NREL) operated; Alliance for Sustainable Energy, LLC, for the U.S. Department of Energy (DOE)(grant numbers:DE-AC36-08GO28308); Laboratory Directed Research and Development (LDRD) Program, NREL; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10143194","Reinforcement learning;OpenDSS;SimPy;OpenAI gym;network reconfiguration;re-routing","Power systems;Training;Routing;Reinforcement learning;Data models;Power distribution;Contingency management;Reconfigurable architectures","","11","","32","CCBY","2 Jun 2023","","","IEEE","IEEE Journals"
"Deep Learning Approaches for Predicting Tourism Demand in Urban Destinations","G. Renhua","Dalian University of Finance and Economics, Dalian, Liaoning, China",IEEE Access,"","2025","PP","99","1","1","The increasing complexity of urban systems necessitates advanced computational frameworks to effectively model and predict dynamic phenomena. Traditional statistical models often fall short in capturing the intricate spatiotemporal patterns inherent in such systems, particularly when addressing multifaceted factors like environmental sustainability, infrastructural constraints, and policy interventions. To overcome these limitations, I propose a novel forecasting framework that combines the Tourism Flow-Response Network (TFRNet) with a Policy-Aware Equilibrium Routing (PAER) strategy. This integrated system models spatiotemporal tourism demand alongside policy feedback and system constraints. Our approach, termed the Tourism Flow-Response Network (TFRNet), models urban dynamics through a network where nodes represent distinct regions and edges encapsulate the flow between them. This structure allows for the incorporation of various factors, including congestion levels, environmental impacts, and policy-induced deterrents. Building upon TFRNet, we develop the Policy-Aware Equilibrium Routing (PAER) strategy, which employs game-theoretic principles to align individual agent behaviors with overarching system objectives. PAER facilitates adaptive policy adjustments, such as dynamic pricing and regulatory measures, to guide the system towards equilibrium states that balance utilityization with sustainability goals. Empirical evaluations demonstrate that our integrated framework outperforms traditional models in predictive accuracy and adaptability, offering a robust tool for urban planners and policymakers. The TFRNet + PAER framework represents the primary contribution of this work, providing both predictive accuracy and actionable policy integration for sustainable tourism forecasting. This research aligns with the scope of Frontiers in Computer Science by advancing computational methodologies that address complex, real-world challenges through interdisciplinary approaches.","2169-3536","","10.1109/ACCESS.2025.3632219","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11244905","Spatiotemporal Modeling;Graph-Structured Networks;Adaptive Policy Mechanisms;Urban System Dynamics;Computational Sustainability","Predictive models;Adaptation models;Computational modeling;Deep learning;Accuracy;Spatiotemporal phenomena;Data models;Computer architecture;Planning;Market research","","","","","CCBY","13 Nov 2025","","","IEEE","IEEE Early Access Articles"
"Automated Machine Learning Driven Stacked Ensemble Modeling for Forest Aboveground Biomass Prediction Using Multitemporal Sentinel-2 Data","P. Naik; M. Dalponte; L. Bruzzone","Department of Information Engineering and Computer Science, University of Trento, Trento, Italy; Research and Innovation Centre, Fondazione Edmund Mach, via E. Mach 1, San Michele all'Adige, Italy; Department of Information Engineering and Computer Science, University of Trento, Trento, Italy",IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,"11 Apr 2023","2023","16","","3442","3454","Modeling and large-scale mapping of forest aboveground biomass (AGB) is a complicated, challenging, and expensive task. There are considerable variations in forest characteristics that create functional disparity for different models and needs comprehensive evaluation. Moreover, the human-bias involved in the process of modeling and evaluation affects the generalization of models at larger scales. In this article, we present an automated machine learning framework for modeling, evaluation, and stacking of multiple base models for AGB prediction. We incorporate a hyperparameter optimization procedure for automatic extraction of targeted features from multitemporal Sentinel-2 data that minimizes human-bias in the proposed modeling pipeline. We integrate the two independent frameworks for automatic feature extraction and automatic model ensembling and evaluation. The results suggest that the extracted target-oriented features have an excessive contribution of red-edge and short-wave infrared spectrum. The feature importance scale indicates a dominant role of summer-based features as compared to other seasons. The automated ensembling and evaluation framework produced a stacked ensemble of base models that outperformed individual base models in accurately predicting forest AGB. The stacked ensemble model delivered the best scores of R2cv = 0.71 and RMSE = 74.44 Mgha−1. The other base models delivered R2cv and RMSE ranging between 0.38–0.66 and 81.27–109.44 Mg ha−1, respectively. The model evaluation metrics indicated that the stacked ensemble model was more resistant to outliers and achieved a better generalization. Thus, the proposed study demonstrated an effective automated modeling pipeline for predicting AGB by minimizing human-bias and deployable over large and diverse forest areas.","2151-1535","","10.1109/JSTARS.2022.3232583","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10002318","Aboveground biomass (AGB);automated features;automated machine learning (AutoML);ensemble modeling;hyperparameter optimization","Predictive models;Forestry;Pipelines;Optimization;Biological system modeling;Task analysis;Computational modeling","","15","","90","CCBY","28 Dec 2022","","","IEEE","IEEE Journals"
"Voronoi-Based Multi-Robot Autonomous Exploration in Unknown Environments via Deep Reinforcement Learning","J. Hu; H. Niu; J. Carrasco; B. Lennox; F. Arvin","Department of Electrical and Electronic Engineering, The University of Manchester, Manchester, U.K.; Department of Electrical and Electronic Engineering, The University of Manchester, Manchester, U.K.; Department of Electrical and Electronic Engineering, The University of Manchester, Manchester, U.K.; Department of Electrical and Electronic Engineering, The University of Manchester, Manchester, U.K.; Department of Electrical and Electronic Engineering, The University of Manchester, Manchester, U.K.",IEEE Transactions on Vehicular Technology,"25 Jan 2021","2020","69","12","14413","14423","Autonomous exploration is an important application of multi-vehicle systems, where a team of networked robots are coordinated to explore an unknown environment collaboratively. This technique has earned significant research interest due to its usefulness in search and rescue, fault detection and monitoring, localization and mapping, etc. In this paper, a novel cooperative exploration strategy is proposed for multiple mobile robots, which reduces the overall task completion time and energy costs compared to conventional methods. To efficiently navigate the networked robots during the collaborative tasks, a hierarchical control architecture is designed which contains a high-level decision making layer and a low-level target tracking layer. The proposed cooperative exploration approach is developed using dynamic Voronoi partitions, which minimizes duplicated exploration areas by assigning different target locations to individual robots. To deal with sudden obstacles in the unknown environment, an integrated deep reinforcement learning based collision avoidance algorithm is then proposed, which enables the control policy to learn from human demonstration data and thus improve the learning speed and performance. Finally, simulation and experimental results are provided to demonstrate the effectiveness of the proposed scheme.","1939-9359","","10.1109/TVT.2020.3034800","Engineering and Physical Sciences Research Council(grant numbers:EP/R026084/1,EP/P01366X/1,EP/S03286X/1); EU H2020-FET-OPEN Robocoenosis(grant numbers:899520); Royal Academy of Engineering(grant numbers:CiET1819_13); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9244647","Autonomous exploration;path planning;deep reinforcement learning;multi-vehicle systems;collision avoidance","Collision avoidance;Robot kinematics;Reinforcement learning;Robot sensing systems;Mobile robots;Navigation","","332","","37","CCBY","29 Oct 2020","","","IEEE","IEEE Journals"
"A Framework for Automatic Initialization of Multi-Agent Production Systems Using Semantic Web Technologies","F. Ocker; I. Kovalenko; K. Barton; D. Tilbury; B. Vogel-Heuser","Institute of Automation and Information Systems, Technical University of Munich, Munich, Germany; University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA; Institute of Automation and Information Systems, Technical University of Munich, Munich, Germany",IEEE Robotics and Automation Letters,"15 Aug 2019","2019","4","4","4330","4337","Mass customization and global competition require Cyber-Physical Systems of Systems (CPSoS) to become increasingly flexible. Modern CPSoS have to be able to create a wide and versatile variety of products, which takes centralized approaches to their limits. In addition, they have to produce these products as quickly as possible. Hence, they must be able to react promptly if problems arise, such as the failure of a single machine. Modern agent-based production systems provide the flexibility required to cope with these challenges. While resource agents (RAs) represent the available resources, i.e., machines, such as robots, individual customer orders can be represented by so-called product agents (PAs). However, a challenge in the design of agent-based production systems is still the amount of communication and computation that is necessary online. The PAs have to communicate their requests and the RAs their capabilities and capacities. On this basis, PAs must compute the appropriate production sequence. We propose to automatically initialize every agent with a knowledge base (KB) created a priori using semantic web technologies (SWT). On the one hand, the KBs of RAs describe the RAs’ capabilities in terms of product features and production processes. Every KB of a PA, on the other hand, expresses all possible production sequences based on the customer specification and the CPSoS in question. This allows consistency checks regarding the specification as well as more purposeful communication that focuses on aspects that actually need to be determined at runtime, such as the resources’ current capacities or failures. The framework presented aims to reduce both the communication and computational load necessary at runtime for agent-based CPSoS.","2377-3766","","10.1109/LRA.2019.2931825","NSF Graduate Fellowship; Bayerische Forschungsstiftung; German Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8779665","Agent-Based Systems;Intelligent and Flexible Manufacturing;Semantic Technology","Control systems;Manufacturing systems;Computer architecture;Runtime","","30","","46","CCBY","29 Jul 2019","","","IEEE","IEEE Journals"
"Adaptive Modular Reinforcement Learning for Robot Controlled in Multiple Environments","T. Iwata; T. Shibuya","Graduate School of Systems and Information Engineering, University of Tsukuba, Tsukuba, Japan; Faculty of Engineering, Information and Systems, University of Tsukuba, Tsukuba, Japan",IEEE Access,"27 Jul 2021","2021","9","","103032","103043","This paper proposes an adaptive modular reinforcement learning architecture and an algorithm for robot control operating in multiple environments. Reinforcement learning autonomously acquires control rules by interacting between the agent and the controlled system. Consequently, reinforcement learning is expected to be applied to robot control where model identification is difficult. These robots are often expected to operate in multiple environments. However, existing reinforcement learning algorithms require prior knowledge of changes in the environment. In this paper, we proposed an architecture and algorithm that does not require prior knowledge of the environment. In this architecture, the policy can be acquired by increasing the number of modules based on the interaction with the controlled system. Therefore, the proposed method can be applied to robots whose dynamics change without losing the feature that the reinforcement learning algorithm does not require prior knowledge of the controlled system. Two numerical experiments were conducted to evaluate the proposed method, which improved the performance by approximately 25 % when compared to the conventional methods.","2169-3536","","10.1109/ACCESS.2021.3070704","Japan Society for the Promotion of Science (JSPS) KAKENHI(grant numbers:18K11424); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9393878","Multiple environments;nonstationary environment;reinforcement learning","Reinforcement learning;Subspace constraints;Robots;Predictive models;Markov processes;Heuristic algorithms;Adaptation models","","4","","21","CCBY","2 Apr 2021","","","IEEE","IEEE Journals"
"Dandelion Optimizer-Based Reinforcement Learning Techniques for MPPT of Grid- Connected Photovoltaic Systems","G. A. Ghazi; E. A. Al-Ammar; H. M. Hasanien; W. Ko; J. Park; D. Kim; Z. Ullah","Department of Electrical Engineering, College of Engineering, King Saud University, Riyadh, Saudi Arabia; Department of Electrical Engineering, College of Engineering, King Saud University, Riyadh, Saudi Arabia; Electrical Power and Machines Department, Faculty of Engineering, Ain Shams University, Cairo, Egypt; Department of Electrical Engineering, College of Engineering, King Saud University, Riyadh, Saudi Arabia; Energy Efficiency Center, Korea Conformity Laboratories, Cheongwon-gu, Cheongju-si, Chungbuk, South Korea; Department of Architecture Engineering, Hanbat National University, Daejeon, South Korea; School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, China",IEEE Access,"27 Mar 2024","2024","12","","42932","42948","The integration of photovoltaic (PV) into electric power systems has been widely explored and adopted to address the problems associated with the depletion of fossil fuels and the release of greenhouse gases. PV panels convert sunlight into electricity, minimizing the reliance on fossil fuels and mitigating environmental pollution. It is crucial to optimally utilize the PV power in the system; hence maximum power point tracking (MPPT) algorithms have been developed to ensure optimal performance of grid-connected PV systems at the maximum power point (MPP) despite changes in weather conditions. Moreover, deep reinforcement learning (DRL) developments provide a promising approach for optimizing grid-connected PV systems, replacing the conventional proportional-integral-derivative (PID) controllers. However, there is limited research evaluating the efficiency of these systems using DRL techniques. This paper proposes a new dandelion optimizer (DO)-based DRL for MPPT of grid-connected photovoltaic systems and evaluates the proposed method for a 100-MW PV plant connected to a 33-kV distribution system. The proposed DRL technique uses proximal policy optimization (PPO) and deep deterministic policy gradient (DDPG) algorithms for continuous states and discrete or continuous action spaces to adjust the PV-measured voltage based on a reference one produced via DO-PPO and DO-DDPG methods. To test the effectiveness and practicality of the introduced methods, simulations were conducted using actual input data of a 100 MW PV plant connected to a 33-kV distribution system for typical days in summer and winter seasons using MATLAB/Simulink software. The proposed implemented methods were evaluated by comparing their simulation results with other techniques: DO-PID, particle swarm optimization (PSO), and incremental conductance (InC-PI). The findings revealed that the efficiencies of the DC-DC boost and the voltage source converters using the introduced methods were 84.25%- 85.90%, and 78.33%- 81.10% on a summer day while they were 92.77%- 95% and 86.70%- 89.50% on a winter day, respectively, which proves that these methods were efficient and effective, indicating their promising potential for future applications.","2169-3536","","10.1109/ACCESS.2024.3378749","Korea Institute of Energy Technology Evaluation and Planning (KETEP); Ministry of Trade, Industry and Energy (MOTIE), Republic of Korea(grant numbers:20228500000020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10474368","Dandelion optimizer;deep deterministic policy gradient;deep reinforcement learning;maximum power point tracking;PV systems;proximal policy optimization","Maximum power point trackers;Power harmonic filters;Voltage control;Solar irradiance;Oscillators;Training;Photovoltaic systems;Deep reinforcement learning;Photovoltaic systems;Matlab;Voltage source inverters;Power grids","","20","","51","CCBYNCND","18 Mar 2024","","","IEEE","IEEE Journals"
"GenAINet: Enabling Wireless Collective Intelligence via Knowledge Transfer and Reasoning","H. Zou; Q. Zhao; S. Lasaulce; L. Bariah; M. Bennis; M. Debbah","Artificial Intelligence and Digital Science Research Center, Technology Innovation Institute, Abu Dhabi, United Arab Emirates; Artificial Intelligence and Digital Science Research Center, Technology Innovation Institute, Abu Dhabi, United Arab Emirates; 6G Research Center, Khalifa University, Abu Dhabi, United Arab Emirates; 6G Research Center, Khalifa University, Abu Dhabi, United Arab Emirates; Centre for Wireless Communications, University of Oulu, Oulu, Finland; 6G Research Center, Khalifa University, Abu Dhabi, United Arab Emirates",IEEE Access,"7 May 2025","2025","13","","77764","77777","genai and communication networks are expected to have groundbreaking synergies for 6G. Connecting Generative Artificial Intelligence (GenAI) agents via a wireless network can potentially unleash the power of Collective Intelligence (CI) and pave the way for Artificial General Intelligence (AGI). However, current wireless networks are designed as a “data pipe” and are not suited to accommodate and leverage the power of GenAI. In this paper, we propose the GenAINet framework in which distributed GenAI agents communicate knowledge (facts, experiences, and methods) to accomplish arbitrary tasks. We first propose an architecture for a single GenAI agent and then provide a network architecture integrating GenAI capabilities to manage both network protocols and applications. Building on this, we investigate effective communication and reasoning problems by proposing a semantic-native GenAINet. Specifically, GenAI agents extract semantics from heterogeneous raw data, build and maintain a knowledge model representing the semantic relationships among pieces of knowledge, which is retrieved by GenAI models for planning and reasoning. Under this paradigm, different levels of collaboration can be achieved flexibly depending on the complexity of targeted tasks. Furthermore, we conduct two case studies in which, through wireless device queries, we demonstrate that extracting, compressing and transferring common knowledge can improve query accuracy while reducing communication costs; and in the wireless power control problem, we show that distributed agents can complete general tasks independently through collaborative reasoning without predefined communication protocols. Finally, we discuss challenges and future research directions in applying Large Language Models (LLMs) in 6G networks.","2169-3536","","10.1109/ACCESS.2025.3565859","KU-TII 6G Chair; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10980288","Collective intelligence;large language models;AI agents;semantic communications","Cognition;Wireless networks;Planning;Collective intelligence;Wireless sensor networks;Protocols;Costs;Knowledge transfer;Computer architecture;Artificial general intelligence","","5","","49","CCBY","30 Apr 2025","","","IEEE","IEEE Journals"
"A Patient-Specific Registration of Coronary Angiogram-Fluoroscopy by Similarity- Based Transfer Learning","C. Kim; D. Jeong; D. Kim; J. Ryu; K. Cho","School of Integrated Technology, Gwangju Institute of Science and Technology, Gwangju, Republic of Korea; VIBE, Anseong-si, Gyeonggi-do, Republic of Korea; Korea Railroad Research Institute (KRRI), Uiwang-si, Gyeonggi-do, Republic of Korea; School of Integrated Technology, Gwangju Institute of Science and Technology, Gwangju, Republic of Korea; Department of Cardiology, Chonnam National University Hospital, Gwangju, Republic of Korea",IEEE Access,"1 Oct 2024","2024","12","","133509","133520","Percutaneous coronary intervention (PCI) is an effective treatment for normalizing blood flow in coronary arteries narrowed by stent implantation. Guidewire insertion during PCI requires considerable precision and expertise, and two X-ray videos, a cine loop of angiography and a real-time video of live fluoroscopy, are used to aid guidewire navigation to the target location without entering the wrong blood vessel branches. However, simultaneously watching and interpreting two radiographic videos warrants increased mental effort and intervention time. Additionally, more contrast agents may have to be injected to verify the insertion. Although deep-learning-based dynamic coronary roadmapping (DCR) has been suggested to provide registered images from two different X-ray sources, existing methods may not be suitable for irregular heartbeats or may vary in effectiveness depending on the patient, posing challenges in time-critical situations. To address these challenges, we propose a patient-specific approach for DCR using similarity-based patient data matching in transfer learning with a residual U-Net. The proposed method leverages the anatomical similarities between newly acquired and pre-acquired angiograms by utilizing principal component analysis and cosine similarity to facilitate efficient transfer learning. Moreover, a residual U-Net architecture that incorporates residual blocks and leaky ReLU activation functions to accelerate patient-specific transfer learning is proposed. These advanced techniques resulted in significantly fast transfer learning of less than five minutes from a pre-trained model, as well as high registration image quality with over 30 dB in peak signal-to-noise ratio, while maintaining a registration error of  $1.04\pm 0.19$  mm.","2169-3536","","10.1109/ACCESS.2024.3422135","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10580895","Deep learning;dynamic coronary roadmap;image registration;percutaneous coronary intervention;X-ray angiography;X-ray fluoroscopy","Transfer learning;Training;Videos;Real-time systems;Visualization;Electrocardiography;Arteries;Deep learning;X-ray applications;Image registration;Coronary arteriosclerosis;Blood flow","","","","29","CCBYNCND","2 Jul 2024","","","IEEE","IEEE Journals"
"GPS-Based Beam Prediction Using Lightweight Deep Learning Models for mmWave Networks","M. H. Hashir; Memoona; S. W. Kim","Department of Information and Communication Engineering, Yeungnam University, Gyeongsan, Republic of Korea; Department of Information and Communication Engineering, Yeungnam University, Gyeongsan, Republic of Korea; School of Computer Science and Engineering, Yeungnam University, Gyeongsan, Republic of Korea",IEEE Access,"5 Nov 2025","2025","13","","186333","186346","Millimeter-wave (mmWave) communication systems use narrow, directional beams, but exhaustive beam training is costly in dynamic settings. Prior location-assisted methods often rely on synthetic data that ignores the noise of real-world GPS measurements. We propose a unified framework that first denoises GPS trajectories with Gaussian-process regression and then predicts beams using a bidirectional long short-term memory network with an attention mechanism. Across nine real-world scenarios, our approach improves Top-k accuracy by up to 36%, reduces received-power loss by more than 1 dB, and cuts beam-training overhead by up to 95%. These results highlight the effectiveness of the proposed framework in bridging the gap between simulation-driven research and real-world mmWave beam alignment.","2169-3536","","10.1109/ACCESS.2025.3626953","Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education(grant numbers:NRF-2021R1A6A1A03039493); NRF grant funded by Korea Government [Ministry of Science and ICT (MSIT)](grant numbers:NRF-2022R1A2C1004401); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11222654","Beam prediction;millimeter-wave;deep learning","Millimeter wave communication;Global Positioning System;Structural beams;Accuracy;Predictive models;Vehicle dynamics;Trajectory;Training;Real-time systems;Millimeter wave technology","","","","33","CCBY","30 Oct 2025","","","IEEE","IEEE Journals"
"A Configurable Model-Based Reinforcement Learning Framework for Disaggregated Storage Systems","S. Jeong; H. Woo","Department of Computer Science and Engineering, Sungkyunkwan University, Suwon, South Korea; Department of Computer Science and Engineering, Sungkyunkwan University, Suwon, South Korea",IEEE Access,"16 Feb 2023","2023","11","","14876","14891","With the rapid growth of data-intensive jobs and the use of different hardware in storage, disaggregated storage architecture systems are being used to improve the operational cost efficiency of data centers. The hardware heterogeneity and mixed configurations of disaggregated storage systems, along with the diversity of workloads, often make it difficult for administrators to operate them optimally. In this work, we investigate model-based reinforcement learning (RL) schemes to develop automated system operations and maintain the storage performance across various system settings and workloads in self-managed storage systems. Specifically, we propose a novel configurable model structure in which a system environment is abstracted with a two-level hierarchy of storage devices and a platform and thus the environment can be reconfigured according to a given system specification. Using that novel model structure, we implement a configurable model-based RL framework CoMoRL by which RL agents are trained through model variants that represent a variety of storage system specifications; thus, their learned management policy can be highly robust to the diverse operation conditions of real-world storage systems. We evaluate our CoMoRL framework using a storage cluster that relies on NVMe-oF devices and demonstrate that the framework can be adapted to different scenarios such as volume placement scenarios with Kubernetes and primary affinity control scenarios with Ceph. The learned management policy outperforms an IOPS-based heuristic method and a model-based method by 0.7%~5.1% and 11.8%~29.7%, respectively, for various Kubernetes system specifications, and by 1.6%~5.6% and 8.2%~16.5%, respectively, for various Ceph system specifications, without requiring model and policy retraining. This zero-shot adaptation superiority of our framework makes it possible to realize RL-based self-managing storage systems in data centers with frequent system changes.","2169-3536","","10.1109/ACCESS.2023.3244388","Institute of Information and Communications Technology Planning and Evaluation (IITP); Korea Government through MSIT(grant numbers:2022-0-01045,2022-0-00043); Samsung Electronics; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10042301","Model-based reinforcement learning;configurable model;meta learning;policy adaptation;data placement;disaggregated storage;heterogeneous storage","Adaptation models;Data models;Data centers;Reinforcement learning;Performance evaluation;Nonvolatile memory;Storage management","","1","","43","CCBY","13 Feb 2023","","","IEEE","IEEE Journals"
"Improving the QoS in 5G HetNets Through Cooperative Q-Learning","M. U. Iqbal; E. A. Ansari; S. Akhtar; A. N. Khan","Department of Electrical and Computer Engineering, COMSATS University Islamabad (CUI), Lahore Campus, Lahore, Pakistan; Department of Electrical and Computer Engineering, COMSATS University Islamabad (CUI), Lahore Campus, Lahore, Pakistan; Department of Electrical and Computer Engineering, COMSATS University Islamabad (CUI), Lahore Campus, Lahore, Pakistan; Department of Electrical and Computer Engineering, COMSATS University Islamabad (CUI), Lahore Campus, Lahore, Pakistan",IEEE Access,"25 Feb 2022","2022","10","","19654","19676","Heterogeneous networks are an integral part of the 5G cellular networks as they are one of the important enabling technologies for increased coverage and capacity. However, interferences in multi-tiered architecture bottleneck its performance. Although multiple schemes have been proposed for efficient radio resource management to handle the interferences in heterogeneous networks but provision of quality of service to macrocell and small cell user equipment simultaneously, is still an open research problem. Intelligent schemes for radio resource management in heterogeneous networks have proved their effectiveness due to their self-optimization capabilities. In this research article, a cooperative Q-Learning, algorithm is proposed for efficient joint radio resource management in ultra-dense heterogeneous networks to handle interferences by adaptive power allocation to small cell base stations while considering the minimum quality of service requirements. In this proposed cooperative Q-Learning algorithm, small cell base stations interacts with the neighboring small cell base stations to exchange information and performs self-optimization based on a joint reward function. The proposed solution not only provided significant improvement in the capacity of macrocell and small cell user equipment as compared to other state of art Q-Learning based radio resource management schemes but also ensure the provision of quality of service to all macrocell and small cell user equipment simultaneously in the cluster of 16 small cells. The proposed solution provided a minimum capacity of 2 b/s/Hz to macrocell and small cell user equipment which is 100% higher than the minimum quality of service requirements defined in literature where none of recently proposed solution could meet minimum quality of service requirements. The results analysis shows that cooperation among the small cells yields a significant improvement of 48% in capacity of small cell user equipment at the cost of a slight increase in computational time as compared to independent learning.","2169-3536","","10.1109/ACCESS.2022.3151090","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9712321","Heterogeneous networks;cooperative learning;5G","Quality of service;5G mobile communication;Computer architecture;Microprocessors;Interference;Resource management;Q-learning","","18","","45","CCBY","11 Feb 2022","","","IEEE","IEEE Journals"
"Optimizing Federated Learning With Deep Reinforcement Learning for Digital Twin Empowered Industrial IoT","W. Yang; W. Xiang; Y. Yang; P. Cheng","School of Automation and Information Engineering, Xi’an University of Technology, Xi’an, China; School of Computing, Engineering and Mathematical Sciences, La Trobe University, Melbourne, Australia; School of Automation and Information Engineering, Xi’an University of Technology, Xi’an, China; School of Computing, Engineering and Mathematical Sciences, La Trobe University, Melbourne, VIC, Australia",IEEE Transactions on Industrial Informatics,"15 Dec 2022","2023","19","2","1884","1893","The accelerated development of the Industrial Internet of Things (IIoT) is catalyzing the digitalization of industrial production to achieve Industry 4.0. In this article, we propose a novel digital twin (DT) empowered IIoT (DTEI) architecture, in which DTs capture the properties of industrial devices for real-time processing and intelligent decision making. To alleviate data transmission burden and privacy leakage, we aim to optimize federated learning (FL) to construct the DTEI model. Specifically, to cope with the heterogeneity of IIoT devices, we develop the DTEI-assisted deep reinforcement learning method for the selection process of IIoT devices in FL, especially for selecting IIoT devices with high utility values. Furthermore, we propose an asynchronous FL scheme to address the discrete effects caused by heterogeneous IIoT devices. Experimental results show that our proposed scheme features faster convergence and higher training accuracy compared to the benchmark.","1941-0050","","10.1109/TII.2022.3183465","Shaanxi Innovation Capability Support project(grant numbers:2021TD-25); Natural Science Basic Research Program of Shaanxi(grant numbers:2021JQ-478); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9815106","Deep reinforcement learning (DRL);digital twin (DT);federated learning (FL);Industrial Internet of Things (IIoT);learning efficiency;real time","Industrial Internet of Things;Training;Data models;Real-time systems;Digital twins;Collaborative work;Task analysis","","122","","28","CCBY","4 Jul 2022","","","IEEE","IEEE Journals"
"Over the Quantum Rainbow: Explaining Hybrid Quantum Reinforcement Learning","J. Park; J. Cha; S. Y. -C. Chen; S. Yoo; H. -H. Tseng","Interdisciplinary Program in Artificial Intelligence, Seoul National University; Interdisciplinary Program in Artificial Intelligence, Seoul National University; Wells Fargo; Computational Science Initiative, Brookhaven National Laboratory; Computational Science Initiative, Brookhaven National Laboratory",2024 IEEE International Conference on Quantum Computing and Engineering (QCE),"10 Jan 2025","2024","01","","1583","1594","In the realm of artificial intelligence, deep rein-forcement learning (RL) agents struggle with generalizability and require substantial computational resources, unlike humans who easily adapt and generalize across tasks. To address these challenges, we introduce Quantum Rainbow, a hybrid algorithm that leverages the neural mechanisms of human decision-making and the efficiency of quantum computing. Quantum Rainbow combines variational quantum circuits with the Rainbow Deep Q-Network (DQN) model to create a novel approach in rein-forcement learning that integrates quantum principles into deep learning paradigms. We evaluate our model using behavioral experiments through the Iowa Gambling Task and 4-Armed Bandit Task. Our investigations reveal a significant relationship between the architecture of quantum circuits and the performance of quantum RL agents. Specifically, using causal discovery methods, we demonstrate the critical role of quantum entanglement in enhancing model performance. These findings not only show promising results but also pave the way for future explorations into optimizing quantum circuit architectures for reinforcement learning applications. This study underscores the potential of quantum-enhanced algorithms to achieve “quantum advantage” by addressing fundamental limitations in conventional deep RL methods.","","979-8-3315-4137-8","10.1109/QCE60285.2024.00185","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10821423","Quantum Reinforcement Learning;Explainability;Quantum Entanglement;Parametrized Quantum Circuits;Causal Discovery","Analytical models;Quantum computing;Quantum algorithm;Quantum advantage;Quantum entanglement;Computational modeling;Reinforcement learning;Quantum state;Integrated circuit modeling;Quantum circuit","","1","","70","CCBYNCND","10 Jan 2025","","","IEEE","IEEE Conferences"
"A Survey on Multi-Robot Coordination in Electromagnetic Adversarial Environment: Challenges and Techniques","Y. Wu; X. Ren; H. Zhou; Y. Wang; X. Yi","Artificial Intelligence Research Center (AIRC), National Innovation Institute of Defense Technology (NIIDT), Beijing, China; Artificial Intelligence Research Center (AIRC), National Innovation Institute of Defense Technology (NIIDT), Beijing, China; Artificial Intelligence Research Center (AIRC), National Innovation Institute of Defense Technology (NIIDT), Beijing, China; Artificial Intelligence Research Center (AIRC), National Innovation Institute of Defense Technology (NIIDT), Beijing, China; Artificial Intelligence Research Center (AIRC), National Innovation Institute of Defense Technology (NIIDT), Beijing, China",IEEE Access,"24 Mar 2020","2020","8","","53484","53497","Wireless communications and networking are playing an important role in coordination and cooperation of multi-robot systems (MRS). However, it is challenging to keep a reliable and stable wireless connection in practical applications. Especially, robots acting in electromagnetic adversarial (EA) environments may encounter more serious situations including scarce spectrum, active interference, adversarial competition, etc. In this survey, we firstly analyze the challenges faced by MRS in EA environments, and provide a categorization according to the “sense-decide-act” robot control procedure. Secondly, enabling techniques for each challenge are introduced. Finally, typical robotics software architectures are introduced, as frameworks for efficient arrangement of the above mentioned enabling techniques.","2169-3536","","10.1109/ACCESS.2020.2981408","National Basic Research Program of China (973 Program)(grant numbers:2017YFB1001900); National Natural Science Foundation of China(grant numbers:61906212,91648204,61601486,61802426); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9039556","Electromagnetic adversarial environment;multi-robot coordination;communication connectivity;survey","Robot kinematics;Robot sensing systems;Task analysis;Jamming;Wireless communication;Feature extraction","","15","","127","CCBY","17 Mar 2020","","","IEEE","IEEE Journals"
"Proactive Data Placement in Heterogeneous Storage Systems via Predictive Multi-Objective Reinforcement Learning","S. Xing; Y. Wang","Department of Electrical and Computer Engineering, Duke University, Durham, NC, USA; School of Engineering and Applied Science, University of Pennsylvania, Philadelphia, PA, USA",IEEE Access,"11 Jul 2025","2025","13","","117986","117998","Modern data-intensive applications demand efficient orchestration across heterogeneous storage tiers, ranging from high-performance DRAM to cost-effective cloud storage. Existing tiered storage systems predominantly employ reactive policies that respond to observed access patterns, leading to suboptimal performance under dynamic workloads and failing to address multi-objective optimization requirements. We propose a novel proactive data placement framework that integrates predictive deep learning with multi-objective reinforcement learning to anticipate future data access patterns and optimize placement decisions across storage hierarchies. Our method employs Long Short-Term Memory networks and Transformer architectures to model complex temporal dependencies in I/O traces, generating predictive access probability distributions for data blocks. A deep reinforcement learning agent subsequently leverages these predictions, along with application-specific metadata hints, to make proactive placement decisions that simultaneously optimize latency, throughput, and cost objectives. The system incorporates a sophisticated reward mechanism that balances performance gains against migration overhead, while employing prioritized experience replay and adaptive learning rates to handle non-stationary workload characteristics. Through comprehensive evaluation using both synthetic and real-world traces from deep learning training workloads, our method demonstrates substantial improvements over state-of-the-art algorithms: achieving up to 45.1% reduction in average I/O latency, 32.5% improvement in throughput for critical applications, and 28.8% reduction in storage costs. The framework’s ability to proactively adapt to evolving access patterns while maintaining computational efficiency makes it particularly suitable for large-scale machine learning and scientific computing environments where data placement critically impacts overall system performance.","2169-3536","","10.1109/ACCESS.2025.3586378","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11072103","Proactive data placement;reinforcement learning;heterogeneous storage systems;predictive modeling;data migration","Optimization;Predictive models;Costs;Adaptation models;Reinforcement learning;Throughput;Long short term memory;Computational modeling;Transformers;Random access memory","","7","","55","CCBY","7 Jul 2025","","","IEEE","IEEE Journals"
"Emergent Solutions to High-Dimensional Multitask Reinforcement Learning","S. Kelly; M. I. Heywood","Department of Computer Science, Dalhousie University, 6050 University Avenue, Halifax, NS, B3H 4R2, Canada; Department of Computer Science, Dalhousie University, 6050 University Avenue, Halifax, NS, B3H 4R2, Canada",Evolutionary Computation,"7 Feb 2019","2018","26","3","347","380","Algorithms that learn through environmental interaction and delayed rewards, or reinforcement learning (RL), increasingly face the challenge of scaling to dynamic, high-dimensional, and partially observable environments. Significant attention is being paid to frameworks from deep learning, which scale to high-dimensional data by decomposing the task through multilayered neural networks. While effective, the representation is complex and computationally demanding. In this work, we propose a framework based on genetic programming which adaptively complexifies policies through interaction with the task. We make a direct comparison with several deep reinforcement learning frameworks in the challenging Atari video game environment as well as more traditional reinforcement learning frameworks based on a priori engineered features. Results indicate that the proposed approach matches the quality of deep learning while being a minimum of three orders of magnitude simpler with respect to model complexity. This results in real-time operation of the champion RL agent without recourse to specialized hardware support. Moreover, the approach is capable of evolving solutions to multiple game titles simultaneously with no additional computational cost. In this case, agent behaviours for an individual game as well as single agents capable of playing all games emerge from the same evolutionary run.","1063-6560","","10.1162/evco_a_00232","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8637202","Emergent modularity;cooperative coevolution;genetic programming;reinforcement learning;multitask learning.","","","6","","","Open Access","7 Feb 2019","","","MIT Press","MIT Press Journals"
"On-Policy Versus Off-Policy Reinforcement Learning for Multi-Domain SFC Embedding in SDN/NFV-Enabled Networks","D. Zhao; W. Shi; Y. Lu; X. Li; Y. Liu","Shijiazhuang Campus, Army Engineering University, Shijiazhuang, China; China Coast Guard Academy, Ningbo, China; Shijiazhuang Campus, Army Engineering University, Shijiazhuang, China; Shijiazhuang Campus, Army Engineering University, Shijiazhuang, China; National Key Laboratory of Blind Signal Processing, Chengdu, China",IEEE Access,"9 Sep 2024","2024","12","","123049","123070","In the software defined network (SDN)/network function virtualization (NFV)-enabled networks, service function chains (SFCs) should typically be allocated to deploy these services, which not only entails meeting the service’s Quality of Service (QoS) requirements, but also considering the infrastructure’s limitations. Although this issue has received much attention in the literature, the dynamics, intricacy, complexity and unpredictability of the issue provide several difficulties for researchers and engineers. The traditional methods (e.g., exact, heuristic, meta-heuristic, and game, etc.) are subjected to the complexity of multi-domain cloud network scenarios with dynamic network states, high-speed computational requirements, and enormous service requests. Recent studies have shown that reinforcement learning (RL) is a promising way to deal with the limitations of the traditional methods. On-policy and off-policy are two key categories in the field of RL models, and they both have promising advantages in deal with dynamic resource allocation problems. This paper contains two innovative points at two levels. Firstly, in order to deal with SFC embedding problem in dynamic multi-domain networks, a mixed Markov model combining Markov decision process (MDP) and hidden Markov model (HMM) is constructed, and the corresponding RL model-solving algorithms are proposed. Secondly, in order to distinguish the appropriate model in a given network scenario, the on-policy RL based multiple domain SFC embedding algorithm is compared with the off-policy one. The obtained simulation results show that the proposed RL algorithms can outperform the current baselines in terms of delay, load balancing and response time. Furthermore, we also point out that the off-policy based algorithm is more suitable for small-scale dynamic network scenarios, while the on-policy based algorithm is more suitable for medium to large-scale network scenarios with high convergence requirements.","2169-3536","","10.1109/ACCESS.2024.3430865","National Natural Science Foundation of China(grant numbers:62071483); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10602501","Service function chain (SFC);software defined network (SDN);network function virtualization (NFV);reinforcement learning (RL);Markov decision process (MDP);hidden Markov model (HMM)","Hidden Markov models;Heuristic algorithms;Business;Computer architecture;Resource management;Computational modeling;Cloud computing;Software defined networking;Network function virtualization;Reinforcement learning","","","","34","CCBYNCND","18 Jul 2024","","","IEEE","IEEE Journals"
"DeepTwin: A Deep Reinforcement Learning Supported Digital Twin Model for Micro-Grids","E. Özkan; İ. Kök; S. Özdemır","Department of Computer Engineering, Hacettepe University, Ankara, Türkiye; Department of Artificial Intelligence and Data Engineering, Ankara University, Ankara, Türkiye; Department of Computer Engineering, Hacettepe University, Ankara, Türkiye",IEEE Access,"30 Dec 2024","2024","12","","196432","196441","This paper presents the development and application of a Digital Twin (DT) model for the optimization of micro-grid operations. With the increasing integration of renewable energy resources (RERs) into power grids, micro-grids are essential for enhancing grid resilience and sustainability. The proposed DT model, enhanced with Deep Reinforcement Learning (DRL), simulates and optimizes key micro-grid functions, such as battery scheduling and load balancing, to improve energy efficiency and reduce operational costs. The model incorporates real-time monitoring, service-oriented simulations, cloud-based deployments, “what-if” analyses, advanced data analytics, and security features to enable comprehensive management of DTs. An optimization scenario was conducted to evaluate the effectiveness of the DT and DRL in improving micro-grid performance. The results demonstrated significant revenue improvements: 81.7% for PPO and 56.12% for SAC compared to the baseline. These findings highlight both the promising potential of DT technology and the critical importance of incorporating DRL techniques into the DTs to improve system performance and resilience.","2169-3536","","10.1109/ACCESS.2024.3521124","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10811923","Deep reinforcement learning (DRL);digital twin (DT);energy management system (EMS);Internet of Things (IoT);micro-grids;optimization","Cloud computing;Optimization;Digital twins;Deep reinforcement learning;Data models;Real-time systems;Computational modeling;Mathematical models;Costs;Space heating","","2","","26","CCBYNCND","23 Dec 2024","","","IEEE","IEEE Journals"
"Learning to Walk With Deep Reinforcement Learning: Forward Dynamic Simulation of a Physics-Based Musculoskeletal Model of an Osseointegrated Transfemoral Amputee","B. N. Ogum; L. R. B. Schomaker; R. Carloni","Bernoulli Institute for Mathematics, Computer Science and Artificial Intelligence, Faculty of Science and Engineering, University of Groningen, Groningen, The Netherlands; Bernoulli Institute for Mathematics, Computer Science and Artificial Intelligence, Faculty of Science and Engineering, University of Groningen, Groningen, The Netherlands; Bernoulli Institute for Mathematics, Computer Science and Artificial Intelligence, Faculty of Science and Engineering, University of Groningen, Groningen, The Netherlands",IEEE Transactions on Neural Systems and Rehabilitation Engineering,"24 Jan 2024","2024","32","","431","441","This paper leverages the OpenSim physics-based simulation environment for the forward dynamic simulation of an osseointegrated transfemoral amputee musculoskeletal model, wearing a generic prosthesis. A deep reinforcement learning architecture, which combines the proximal policy optimization algorithm with imitation learning, is designed to enable the model to walk by using three different observation states. The first is a complete state that includes the agent’s kinematics, ground reaction forces, and muscle data; the second is a reduced state that only includes the kinematics and ground reaction forces; the third is an augmented state that combines the kinematics and ground reaction forces with a prediction of the muscle data generated by a fully-connected feed-forward neural network. The empirical results demonstrate that the model trained with the augmented observation state can achieve walking patterns with rewards and gait symmetry ratings comparable to those of the model trained with the complete observation state, while there are no symmetric walking patterns when using the reduced observation state. This paper shows the importance of including muscle data in a deep reinforcement learning architecture for the forward dynamic simulation of musculoskeletal models of transfemoral amputees.","1558-0210","","10.1109/TNSRE.2024.3352416","European Commission’s Horizon 2020 Program as part of the Project MyLeg(grant numbers:780871); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10387751","Deep reinforcement learning;computer simulation;prosthetics","Muscles;Kinematics;Hip;Knee;Computational modeling;Musculoskeletal system;Computer architecture","Humans;Amputees;Walking;Gait;Biomechanical Phenomena;Artificial Limbs","5","","28","CCBY","10 Jan 2024","","","IEEE","IEEE Journals"
"Autonomous Driving: Integration of Segmentation and Depth Camera in a Curriculum Learning Approach","S. Barra; L. Cimmino; V. Loia; M. Nappi; M. Polsinelli","Department of Information Technology and Electrical Engineering, University of Naples Federico II, Napoli, Italy; Department of Computer Science, University of Salerno, Salerno, Italy; Department of Management and Innovation Systems, University of Salerno, Salerno, Italy; Department of Computer Science, University of Salerno, Salerno, Italy; Department of Management and Innovation Systems, University of Salerno, Salerno, Italy",IEEE Internet of Things Journal,"22 Aug 2025","2025","12","17","35237","35248","Autonomous driving (AD) entails vehicles that can perceive their surroundings and navigate without human intervention. This involves utilising a combination of sensors and algorithms to recognize obstacles, interpret traffic signals, and make driving decisions. While AD holds promise for transforming transportation by enhancing safety, reducing congestion, minimising pollution, and optimising efficiency, it poses technical challenges also. This work extends a novel approach to building an autonomous vehicle agent using deep reinforcement learning (DRL) with proximal policy optimisation (PPO) to navigate urban environments simulated by the CAR learning to act (CARLA) Simulator. The agent aims to maintain lane integrity and avoid collisions, even in adverse weather conditions. The proposed architecture integrates a 180-degree environmental view and various multimodal data inputs (RGB, segmentation, and depth camera inputs), extensively tested through experimentation. Notably, the integration of segmentation and depth data results in a 13% reduction in the collision rate, with the proposed agent achieving a total reward of 2510. This approach demonstrates significant progress over the previous framework, showcasing improved obstacle detection and collision avoidance accuracy. Moreover, these findings contribute to ongoing autonomous vehicle research, offering insights into effective strategies for developing robust and dependable driving agents capable of navigating urban environments and interacting with road infrastructure, contributing to advancements in Augmented Intelligence of Things (AIoT)-enabled AD.","2327-4662","","10.1109/JIOT.2025.3579862","Project IDA included in the Spoke 2—Misinformation and Fakes of the Research and Innovation Program(grant numbers:PE00000014); “SEcurity and RIghts in the CyberSpace (SERICS)”, under the National Recovery and Resilience Plan, Mission 4 “Education and Research” - Component 2 “From Research to Enterprise” - Investment 1.3; European Union - NextGenerationEU; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11039194","Autonomous driving (AD);curriculum learning (CL);deep reinforcement learning (DRL);object segmentation;proximal policy optimisation (PPO)","Autonomous vehicles;Cameras;Sensors;Training;Internet of Things;Roads;Artificial intelligence;Meteorology;Deep reinforcement learning;Complexity theory","","","","51","CCBYNCND","17 Jun 2025","","","IEEE","IEEE Journals"
"On Learning Suitable Caching Policies for In-Network Caching","S. Pires; A. Ribeiro; L. N. Sampaio","Department of Computer Science, Federal University of Bahia, Salvador, Brazil; Department of Computer Science, Federal University of Bahia, Salvador, Brazil; Department of Computer Science, Federal University of Bahia, Salvador, Brazil",IEEE Transactions on Machine Learning in Communications and Networking,"8 Aug 2024","2024","2","","1076","1092","In-network cache architectures, such as Information-centric networks (ICNs), have proven to be an efficient alternative to deal with the growing content consumption on networks. In caching networks, any device can potentially act as a caching node. In practice, real cache networks may employ different caching replacement policies by a node. The reason is that the policies may vary in efficiency according to unbounded context factors, such as cache size, content request pattern, content distribution popularity, and the relative cache location. The lack of suitable policies for all nodes and scenarios undermines the efficient use of available cache resources. Therefore, a new model for choosing caching policies appropriately to cache contexts on-demand and over time becomes necessary. In this direction, we propose a new caching meta-policy strategy capable of learning the most appropriate policy for cache online and dynamically adapting to context variations that leads to changes in which policy is best. The meta-policy decouples the eviction strategy from managing the context information used by the policy, and models the choice of suitable policies as online learning with a bandit feedback problem. The meta-policy supports deploying a diverse set of self-contained caching policies in different scenarios, including adaptive policies. Experimental results with single and multiple caches have shown the meta-policy effectiveness and adaptability to different content request models in synthetic and trace-driven simulations. Moreover, we compared the meta-policy adaptive behavior with the Adaptive Replacement Policy (ARC) behavior.","2831-316X","","10.1109/TMLCN.2024.3436472","National Council for Scientific and Technological Development (CNPq)(grant numbers:402854/2022-5,316208/2021-3); Bahia State Research Support Foundation (FAPESB)(grant numbers:TIC0004/2015,BOL0023/2020,BOL0428/2021); Air Force Office of Scientific Research(grant numbers:FA9550-23-1-0631); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10616152","In-network caching;cache replacement policy;online learning;multi-armed bandits;adaptive system","Adaptation models;Context modeling;Production;Machine learning;Adaptive systems;Numerical models;Internet of Things","","5","","30","CCBYNCND","31 Jul 2024","","","IEEE","IEEE Journals"
"Optimal Learning Paradigm and Clustering for Effective Radio Resource Management in 5G HetNets","M. U. Iqbal; E. A. Ansari; S. Akhtar; M. Farooq-I-Azam; S. R. Hassan; R. Asif","Department of Electrical and Computer Engineering, COMSATS University Islamabad (CUI), Lahore Campus, Lahore, Pakistan; Department of Electrical and Computer Engineering, COMSATS University Islamabad (CUI), Lahore Campus, Lahore, Pakistan; Department of Electrical and Computer Engineering, COMSATS University Islamabad (CUI), Lahore Campus, Lahore, Pakistan; Department of Electrical and Computer Engineering, COMSATS University Islamabad (CUI), Lahore Campus, Lahore, Pakistan; School of Computing Sciences, University of East Anglia (UEA), Norwich, U.K; School of Computing Sciences, University of East Anglia (UEA), Norwich, U.K",IEEE Access,"2 May 2023","2023","11","","41264","41280","Ultra-dense heterogeneous networks (UDHN) based on small cells are a requisite part of the future cellular networks as they are proposed as one of the enabling technologies to handle coverage and capacity problems. But co-tier and cross-tier interferences in UDHN severely degrade the quality of service due to K-tiered architecture. Machine learning based radio resource management either through independent learning or cooperative learning is a proven efficient scheme for interference mitigation and quality of service provision in UDHN in a both distributive and cooperative manner. However, an optimal learning paradigm selection, i.e., either independent or cooperative learning and optimal cooperative cluster size in cooperative learning for efficient radio resource management in UDHN is still an open research problem. In this article, a Q-learning based radio resource management scheme is proposed and evaluated for both distributive and cooperative schemes using independent and cooperative learning. The proposed Q-learning solution follows the  $\epsilon -$ greedy policy for optimal convergence. The simulation results for the UDHN in an urban setup show that in comparison to the independent learning paradigm, cooperative learning has no significant impact on macro cell user capacity. However, there is a significant improvement in small cell user capacity and the sum capacity of the cooperating small cells in the cluster. A significant increase of 48.57% and 37.9% is observed in the small cell user capacity, and sum capacity of the cooperating small cells, respectively, using cooperative learning as compared to independent learning which sets cooperative learning as an optimal learning strategy in UDHN. The improvement in small cell user capacity is at cost of increased computational time which is directly proportional to the number of cooperating small cells. To solve the issue of computational time in cooperative learning, an optimal clustering algorithm is proposed. The proposed optimal clustering reduced the computational time by four times in cooperative Q-learning.","2169-3536","","10.1109/ACCESS.2023.3268543","University of East Anglia (UEA), Norwich, U.K.(grant numbers:1012606FA1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10105246","Heterogeneous networks;radio resource management;Q-learning;5G","Resource management;Quality of service;Interference;Optimization;Q-learning;5G mobile communication;Adaptive systems","","5","","43","CCBY","19 Apr 2023","","","IEEE","IEEE Journals"
"Truly Distributed Multicell Multi-Band Multiuser MIMO by Synergizing Game Theory and Deep Learning","K. -K. Wong; G. Liu; W. Cun; W. Zhang; M. Zhao; Z. Zheng","Department of Electronic and Electrical Engineering, University College London, London, U.K; Huawei Noah’s Ark Lab, Hong Kong Science Park, Hong Kong, China; Huawei Noah’s Ark Lab, Hong Kong Science Park, Hong Kong, China; Huawei Noah’s Ark Lab, Hong Kong Science Park, Hong Kong, China; East China Institute of Telecommunications, China Academy of Information and Communications Technology, Beijing, China; East China Institute of Telecommunications, China Academy of Information and Communications Technology, Beijing, China",IEEE Access,"23 Feb 2021","2021","9","","30347","30358","Dynamic frequency allocation (DFA) with massive multiple-input multiple-output (MIMO) is a promising candidate for multicell communications where massive MIMO is adopted to maximize the per-cell capacity whereas the inter-cell interference (ICI) is tackled by DFA. Realizing this approach in a distributed fashion is however very difficult due to the lack of global channel state available at the base stations (BSs) in the cell level. We utilize a forward-looking game to automate reconciliation for DFA in a distributed manner between cells while zero-forcing (ZF) is used at each cell to maximize the multiplexing gain. To maximize the network capacity, multi-agent deep reinforcement learning (DRL) using offline centralized training is leveraged to train the BSs to master their game-theoretic reconciliation strategies. The result is a trained neural network for each BS, empowering it with rich experience of reconciliation with other BSs for converging to a network-efficient equilibrium. The online algorithm is distributed with the BSs competing as expert players to start the negotiation process using their trained actions. Simulation results show that the proposed synergized deep-learning game-theoretic algorithm outperforms significantly the DRL-only and game-theoretic only methods, and other benchmarks for multicell MIMO.","2169-3536","","10.1109/ACCESS.2021.3059587","Engineering and Physical Sciences Research Council (EPSRC)(grant numbers:EP/T015985/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9354637","Centralized training;deep learning;distributed optimization;frequency allocation;game theory;MIMO;multi-agent reinforcement learning;multicell","Training;Microprocessors;Simulation;Computer architecture;Games;Reinforcement learning;Benchmark testing","","8","","28","CCBY","15 Feb 2021","","","IEEE","IEEE Journals"
"Agent-Based Optimizing Match Between Passenger Demand and Service Supply for Urban Rail Transit Network With NetLogo","J. Zhang","College of Transportation, Shandong University of Science and Technology, Qingdao, China",IEEE Access,"26 Feb 2021","2021","9","","32064","32080","Both passenger demand and service supply are among the most important factors that determine the performance of urban rail transit system. It is not easy to find out optimal solution for the match between the passenger demand and service supply with traditional methods, due to the complexity of the combinatorial intelligent supply — demand matching problem. In order to get the comprehensively optimal matching degree, this paper transforms the multi-criteria problem into the distributed artificial intelligence optimization by using multi-agent dynamic interaction technique. On the demand side, the dynamic passenger traffic demand with agents is modelled from perspective of boundedly rational travel decision. On the supply side, the dynamic service supply of train traffic with agent is modelled. The headway time is designated as the main decision variable, for the key link between the passenger demand and service supply is the headway time in different time-of-day intervals. To make the passenger demand more closely matched with service supply in urban rail transit network system at the reasonable travel cost and operational cost, the calculation formula for matching degree is proposed, along with the distributed system architecture for agent-based matching mechanism, and the negotiation-based iterative mechanisms for balancing. The proposed methods are validated on the simulation platform NetLogo. The simulation results emphasize the importance of representing the supply side and the demand side jointly/interactively. These findings are meaningful for policies on both development of efficient capacity usage strategies of urban rail transit network and provision of high level of service for passengers.","2169-3536","","10.1109/ACCESS.2021.3060816","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9359759","Agent;dynamic passenger traffic demand;dynamic service supply of train traffic;intelligent supply — demand matching;NetLogo;urban rail transit","Rails;Planning;Optimization;Uncertainty;Transportation;Time-frequency analysis;Systems architecture","","17","","51","CCBY","22 Feb 2021","","","IEEE","IEEE Journals"
"A Biologically Constrained Cerebellar Model With Reinforcement Learning for Robotic Limb Control","R. Liu; Q. Zhang; Y. Chen; J. Wang; L. Yang","Liaoning Key Laboratory of Integrated Circuit and Biomedical Electronic System, School of Biomedical Engineering, Dalian University of Technology, Dalian, China; Liaoning Key Laboratory of Integrated Circuit and Biomedical Electronic System, School of Biomedical Engineering, Dalian University of Technology, Dalian, China; Liaoning Key Laboratory of Integrated Circuit and Biomedical Electronic System, School of Biomedical Engineering, Dalian University of Technology, Dalian, China; Liaoning Key Laboratory of Integrated Circuit and Biomedical Electronic System, School of Biomedical Engineering, Dalian University of Technology, Dalian, China; Department of Electrical and Computer Engineering, University of Canterbury, Christchurch, New Zealand",IEEE Access,"21 Dec 2020","2020","8","","222199","222210","The cerebellum is known to be critical for accurate adaptive control and motor learning. It has long been recognized that the cerebellum acts as a supervised learning machine. However, recent evidence shows that cerebellum is integral to reinforcement learning. This paper proposes a biologically plausible cerebellar model with reinforcement learning based on the cerebellar neural circuitry to eliminate the need for explicit teacher signals. The learning capacity of cerebellar reinforcement learning is first demonstrated by constructing a simulated cerebellar neural network agent and a detailed model of the human arm and muscle system in the Emergent virtual environment. Next, the cerebellar model is incorporated in both a simulated arm and a Geomagic Touch device to further verify the effectiveness of the cerebellar model in reaching tasks. Results from these experiments indicate that the cerebellar simulation is capable of driving the “arm plant” to arrive at the target positions accurately. Moreover, by examining the effect of the number of basic units, we find the results are consistent with previous findings that the central nervous system may recruit the muscle synergies to realize motor control. The study described here prompts several hypotheses about the relationship between motor control and learning and may be useful in the development of general-purpose motor learning systems for machines.","2169-3536","","10.1109/ACCESS.2020.3042994","National Natural Science Foundation of China (NSFC)(grant numbers:81741137); Liaoning Provincial Natural Science Foundation of China(grant numbers:2020-KF-12-04); China Postdoctoral Science Foundation Funded Project(grant numbers:2020M670714); Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9285238","Cerebellum;cerebellar model;reinforcement learning;robotic limb control","Cerebellum;Brain modeling;Computer architecture;Microprocessors;Integrated circuit modeling;Reinforcement learning;Adaptation models","","4","","39","CCBY","7 Dec 2020","","","IEEE","IEEE Journals"
"An Integrated Parallel Inner Deep Learning Models Information Fusion With Bayesian Optimization for Land Scene Classification in Satellite Images","A. Hamza; M. A. Khan; S. ur Rehman; H. M. Albarakati; R. Alroobaea; A. M. Baqasah; M. Alhaisoni; A. Masood","Department of CS, HITEC University, Taxila, Pakistan; Department of CS, HITEC University, Taxila, Pakistan; Department of CS, HITEC University, Taxila, Pakistan; Computer Engineering Department, College of Computer and Information Systems, Umm Al-Qura University, Makkah, Saudi Arabia; Department of Computer Science, College of Computers and Information Technology, Taif University, Taif, Saudi Arabia; Department of Information Technology, College of Computers and Information Technology, Taif University, Taif, Saudi Arabia; Computer Sciences Department, College of Computer and Information Sciences, Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia; Department of Physics, Norwegian University of Science and Technology, Trondheim, Norway",IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,"3 Nov 2023","2023","16","","9888","9903","Classification of remote scenes in satellite imagery has many applications, such as surveillance, earth observation, etc. Classifying high-resolution remote sensing images in machine learning is a big challenge nowadays. Several automated techniques based on machine learning and deep learning have been introduced in the literature; however, these techniques fail to perform for complex texture images, complex backgrounds, and small objects. In this work, we proposed a new automated technique based on the inner fusion of two deep learning models and feature selection. A new network is designed at the initial phase based on the inner-level fusion of two networks and combined weights. After that, hyperparameters have been initialized based on the Bayesian optimization (BO). Usually, the hyperparameters have been initialized through a manual approach, but that is not an efficient way of selection. After that, the designed model is trained and extracted deep features from the deeper layer. In the last step, a poor–rich controlled entropy-based feature selection technique is developed for the best feature selection. The selected features are finally classified using machine learning classifiers. We performed the experimental process of the proposed architecture on three publically available datasets: Aerial image dataset (AID), UC-Merceds, and WHU-RS19. On these datasets, we obtained the accuracy of 96.3%, 95.6%, and 97.8%, respectively. Comparison is conducted with state-of-the-art techniques and shows improved accuracy.","2151-1535","","10.1109/JSTARS.2023.3324494","Deanship of Scientific Research at Umm Al-Qura University(grant numbers:23UQU4330028DSR002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10285008","Deep learning;feature selection;machine learning;models fusion;remote sensing","Satellite images;Deep learning;Feature extraction;Remote sensing;Optimization;Satellites;Bayes methods","","14","","52","CCBY","13 Oct 2023","","","IEEE","IEEE Journals"
"Understanding and Accelerating Neural Architecture Search With Training-Free and Theory-Grounded Metrics","W. Chen; X. Gong; J. Wu; Y. Wei; H. Shi; Z. Yan; Y. Yang; Z. Wang","Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, TX, USA; Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, TX, USA; Department of Computer Science and Engineering, Texas A&M University, College Station, TX, USA; Institute of Information Science, Beijing Jiaotong University, Beijing, China; School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA, USA; Meta Reality Labs, Burlingame, CA, USA; Zhejiang University, Hangzhou, China; Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, TX, USA",IEEE Transactions on Pattern Analysis and Machine Intelligence,"8 Jan 2024","2024","46","2","749","763","This work targets designing a principled and unified training-free framework for Neural Architecture Search (NAS), with high performance, low cost, and in-depth interpretation. NAS has been explosively studied to automate the discovery of top-performer neural networks, but suffers from heavy resource consumption and often incurs search bias due to truncated training or approximations. Recent NAS works Mellor et al. 2021, Chen et al. 2021, Abdelfattah et al. 2021 start to explore indicators that can predict a network's performance without training. However, they either leveraged limited properties of deep networks, or the benefits of their training-free indicators were not applied to more extensive search methods. By rigorous correlation analysis, we present a unified framework to understand and accelerate NAS, by disentangling “TEG” characteristics of searched networks – Trainability, Expressivity, Generalization – all assessed in a training-free manner. The TEG indicators could be scaled up and integrated with various NAS search methods, including both supernet and single-path NAS approaches. Extensive studies validate the effective and efficient guidance from our TEG-NAS framework, leading to both improved search accuracy and over 56% reduction in search time cost. Moreover, we visualize search trajectories on three landscapes of “TEG” characteristics, observing that a good local minimum is easier to find on NAS-Bench-201 given its simple topology, whereas balancing “TEG” characteristics is much harder on the DARTS space due to its complex landscape geometry.","1939-3539","","10.1109/TPAMI.2023.3328347","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10337787","Generalization;linear region;neural architecture search;neural tangent kernel","Training;Costs;Visualization;Computer architecture;Correlation;Trajectory;Jacobian matrices","","7","","98","CCBYNCND","1 Dec 2023","","","IEEE","IEEE Journals"
"Generating Cryptographic S-Boxes Using the Reinforcement Learning","G. Kim; H. Kim; Y. Heo; Y. Jeon; J. Kim","Department of Mathematics and Financial Information Security, Kookmin University, Seoul, South Korea; Department of Mathematics and Financial Information Security, Kookmin University, Seoul, South Korea; Gyeongsang National University High School (GNUHS), Jinju, South Korea; Department of Mathematics and Financial Information Security, Kookmin University, Seoul, South Korea; Department of Mathematics and Financial Information Security, Kookmin University, Seoul, South Korea",IEEE Access,"14 Jun 2021","2021","9","","83092","83104","Substitution boxes (S-boxes) are essential components of many cryptographic primitives. The Dijkstra algorithm, SAT solvers, and heuristic methods have been used to find bitsliced implementations of S-boxes. However, it is difficult to apply these methods for 8-bit S-boxes because of their size. Therefore, to implement these S-boxes so that the countermeasure of side-channel attack can be applied efficiently, using structures such as Feistel, Lai-Massey, and MISTY that can be bitsliced implemented with a small number of nonlinear operations has been widely used. Since S-boxes constructed with structures consist of small S-boxes and have specific designs, there are limitations to their cryptographic security and efficiency. In this paper, we propose a new method for generating S-boxes by stacking bitwise operations from the identity function, an approach that is different from existing methods. This method can be expressed in Markov decision process, and reinforcement learning is a suitable solver for Markov decision process. Our goal is to train this method to an agent through reinforcement learning to generate S-boxes to which the masking scheme, which is a countermeasure of side-channel attack, can be efficiently applied. In particular, our method provided various S-boxes superior or comparable to existing S-boxes. We produced 8-bit S-boxes with differential uniformity 16 (resp. 32) and linearity 128 (resp. 128), generated with nine (resp. eight) nonlinear operations, for the first time. To our best knowledge, this is the first study to construct cryptographic S-Box by incorporating reinforcement learning.","2169-3536","","10.1109/ACCESS.2021.3085861","This work was supported by Institute of Information & Communications Technology Planning & Evaluation (IITP) grant funded by the Korea government (MSIT)(grant numbers:2021-0-00540); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9446086","S-box;masking efficiency;reinforcement learning;bitsliced implementation;linearity;differential uniformity","Cryptography;Reinforcement learning;Security;Linearity;Stacking;Markov processes;Side-channel attacks","","10","","56","CCBY","3 Jun 2021","","","IEEE","IEEE Journals"
"Machine Learning in E-Commerce: Trends, Applications, and Future Challenges","E. Dritsas; M. Trigka","Department of Informatics and Computer Engineering, University of West Attica, Athens, Greece; Department of Informatics and Computer Engineering, University of West Attica, Athens, Greece",IEEE Access,"11 Jun 2025","2025","13","","99048","99067","The rapid evolution of e-commerce has been significantly influenced by the integration of machine learning (ML) and data science techniques. The present survey provides a comprehensive overview of how ML methods are applied across various functional domains in e-commerce, including personalized recommendations, dynamic pricing, fraud detection, customer segmentation, and behavioral analysis. We categorize and evaluate a wide range of ML paradigms, namely supervised, unsupervised, reinforcement, and hybrid learning, as well as emerging approaches such as neurosymbolic artificial intelligence (AI), federated learning (FL), and quantum ML (QML). Key challenges related to scalability, interpretability, cold-start problems, data sparsity, and privacy are critically analyzed. Additionally, we highlight underexplored areas, such as continual learning (CL) and multi-agent architectures in commerce. The survey incorporates comparative tables, real-world use cases, and a taxonomy of methods to support both academic and industrial perspectives. Ultimately, by analyzing trends and gaps in the literature, we provide a forward-looking research roadmap that bridges ML innovations with the evolving demands of e-commerce ecosystems.","2169-3536","","10.1109/ACCESS.2025.3572865","Hellenic Academic Libraries Link; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11009009","Machine learning;e-commerce;predictive analytics;recommendation systems;personalization;optimization","Electronic commerce;Fraud;Surveys;Pricing;Artificial intelligence;Machine learning;Computational modeling;Data models;Real-time systems;Predictive models","","2","","205","CCBY","22 May 2025","","","IEEE","IEEE Journals"
"UAV Swarm Trajectory Design for Wireless Networks Using Genetic Algorithm-Driven Repulsion Forces","K. Arshid; A. Krayani; L. Marcenaro; D. M. Gómez; C. Regazzoni","Department of Systems Engineering and Automation, Intelligent Systems Laboratory, Carlos III University of Madrid, Leganés, Spain; Department of Engineering and Naval Architecture (DITEN), University of Genoa, Genoa, Italy; Department of Engineering and Naval Architecture (DITEN), University of Genoa, Genoa, Italy; Department of Systems Engineering and Automation, Intelligent Systems Laboratory, Carlos III University of Madrid, Leganés, Spain; Department of Engineering and Naval Architecture (DITEN), University of Genoa, Genoa, Italy",IEEE Access,"9 Sep 2025","2025","13","","155657","155674","Uncrewed Aerial Vehicle (UAV) swarms are increasingly recognized for their versatility and affordability. These swarms have enhanced various applications, including agriculture, surveillance, delivery services, and monitoring. However, fully utilizing the capabilities of UAV swarms requires addressing challenges related to trajectory design, particularly the Multiple Traveling Salesman Problem (MTSP). It involves optimizing the paths of multiple UAVs while avoiding collisions, minimizing overlap and interference, and managing the overall size of the swarm. These challenges highlight the complexities involved in developing high-performance, organized UAV swarm operations. We propose a novel approach based on repulsion force in UAV swarm trajectory design to tackle these issues. Our method utilizes a Genetic Algorithm (GA) to generate a dynamic Repulsion Force (RF) that optimizes the distance between UAVs and the size of the swarm. This approach reduces interference and overlap while effectively navigating the limitations posed by the MTSP. Our proposed solution aims to design efficient trajectories that enhance the overall performance of UAV swarms. We compared our proposed method to existing algorithms, including the MTSPGA, Particle Swarm Optimization (PSO), 2-OPT, Ant Colony (AC) Optimization, and Simulated Annealing (SA), using simulations and evaluations. The results indicate that our proposed method effectively optimizes travel distances and times, reduces interference levels and overlapping, prevents collisions between UAVs, and enhances the size of the UAV swarm. Overall, our method outperforms current approaches, demonstrating its effectiveness for UAV-based applications.","2169-3536","","10.1109/ACCESS.2025.3606121","Universidad Carlos III de Madrid(grant numbers:CRUE-Madroño 2025); European Union under the Italian National Recovery and Resilience Plan (PNRR) of NextGenerationEU partnership on “Telecommunications of the Future” (PE00000001 - program “RESTART”)(grant numbers:CUP E63C22002040007 - D.D. n.1549 of 11/10/2022); Ministry of University and Research (MUR), National Recovery and Resilience Plan (NRRP), Mission 4, Component 2, Investment 1.5, project “RAISE - Robotics and Artificial Intelligence (Al) for Socio-economic Empowerment”(grant numbers:ECS00000035); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11151287","UAV swarm;trajectory design;genetic algorithm;repulsion force;collision avoidance","Autonomous aerial vehicles;Trajectory;Genetic algorithms;Optimization;Interference;Force;Collision avoidance;Atmospheric modeling;Radio frequency;Heuristic algorithms","","1","","45","CCBY","4 Sep 2025","","","IEEE","IEEE Journals"
"DeblurGAN-CNN: Effective Image Denoising and Recognition for Noisy Handwritten Characters","S. Gonwirat; O. Surinta","Department of Information Technology, Faculty of Informatics, Multi-Agent Intelligent Simulation Laboratory (MISL), Mahasarakham University, Mahasarakham, Thailand; Department of Information Technology, Faculty of Informatics, Multi-Agent Intelligent Simulation Laboratory (MISL), Mahasarakham University, Mahasarakham, Thailand",IEEE Access,"1 Sep 2022","2022","10","","90133","90148","Many problems can reduce handwritten character recognition performance, such as image degradation, light conditions, low-resolution images, and even the quality of the capture devices. However, in this research, we have focused on the noise in the character images that could decrease the accuracy of handwritten character recognition. Many types of noise penalties influence the recognition performance, for example, low resolution, Gaussian noise, low contrast, and blur. First, this research proposes a method that learns from the noisy handwritten character images and synthesizes clean character images using the robust deblur generative adversarial network (DeblurGAN). Second, we combine the DeblurGAN architecture with a convolutional neural network (CNN), called DeblurGAN-CNN. Subsequently, two state-of-the-art CNN architectures are combined with DeblurGAN, namely DeblurGAN-DenseNet121 and DeblurGAN-MobileNetV2, to address many noise problems and enhance the recognition performance of the handwritten character images. Finally, the DeblurGAN-CNN could transform the noisy characters to the new clean characters and recognize clean characters simultaneously. We have evaluated and compared the experimental results of the proposed DeblurGAN-CNN architectures with the existing methods on four handwritten character datasets: n-THI-C68, n-MNIST, THI-C68, and THCC-67. For the n-THI-C68 dataset, the DeblurGAN-CNN achieved above 98% and outperformed the other existing methods. For the n-MNIST, the proposed DeblurGAN-CNN achieved an accuracy of 97.59% when the AWGN+Contrast noise method was applied to the handwritten digits. We have evaluated the DeblurGAN-CNN on the THCC-67 dataset. The result showed that the proposed DeblurGAN-CNN achieved an accuracy of 80.68%, which is significantly higher than the existing method, approximately 10%.","2169-3536","","10.1109/ACCESS.2022.3201560","Royal Golden Jubilee Ph.D. Program by the Thailand Research Fund(grant numbers:PHD/0210/2561); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9866776","Handwritten character recognition;denoising image;generative adversarial network;DeblurGAN;convolutional neural network","Character recognition;Feature extraction;Noise measurement;Generative adversarial networks;Image recognition;Handwriting recognition;Convolutional neural networks","","30","","60","CCBY","25 Aug 2022","","","IEEE","IEEE Journals"
"Heuristically Accelerated Reinforcement Learning for Dynamic Secondary Spectrum Sharing","N. Morozs; T. Clarke; D. Grace","Department of Electronics, University of York, Heslington, U.K.; Department of Electronics, University of York, Heslington, U.K.; Department of Electronics, University of York, Heslington, U.K.",IEEE Access,"20 May 2017","2015","3","","2771","2783","This paper examines how flexible cellular system architectures and efficient spectrum management techniques can be used to play a key role in accommodating the exponentially increasing demand for mobile data capacity in the near future. The efficiency of the use of radio spectrum for wireless communications can be dramatically increased by dynamic secondary spectrum sharing; an intelligent approach that allows unlicensed devices access to those parts of the spectrum that are otherwise underutilized by the incumbent users. In this paper, we propose a heuristically accelerated reinforcement learning (HARL)-based framework, designed for dynamic secondary spectrum sharing in Long Term Evolution cellular systems. It utilizes a radio environment map as external information for guiding the learning process of cognitive cellular systems. System level simulations of a stadium temporary event scenario show that the schemes based on the proposed HARL framework achieve high controllability of spectrum sharing patterns in a fully autonomous way. This results in a significant decrease in the primary system quality of service degradation due to interference from the secondary cognitive systems, compared with a state-of-the-art reinforcement learning solution and a purely heuristic typical LTE solution. The spectrum sharing patterns that emerge by using the proposed schemes also result in remarkable reliability of the cognitive eNodeB on the aerial platform. Furthermore, the novel principle and the general structure of heuristic functions proposed in the context of HARL are applicable to a wide range of self-organization problems beyond the wireless communications domain.","2169-3536","","10.1109/ACCESS.2015.2507158","Seventh Framework Programme within the European Commission through the ABSOLUTE Project(grant numbers:FP7-ICT-2011-8-318632); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7350209","Heuristically Accelerated Reinforcement Learning;Spectrum Sharing;Dynamic Spectrum Access;Heuristically accelerated reinforcement learning;spectrum sharing;dynamic spectrum access","Heuristic algorithms;Learning (artificial intelligence);Wireless communication;Acceleration;Decision support systems;Mobile communication;Interference","","25","","36","OAPA","9 Dec 2015","","","IEEE","IEEE Journals"
"Intelligent Handover Management in Ultra-Dense 5G Networks: A Deep Q-Learning-Based Prediction Model","N. Dekate; A. Anubhab; S. Menon; S. Arya; A. Bhowmick; Y. Kumar Choukiker; S. Karattupalayam Chidambaram","Department of Communications Engineering, School of Electronics Engineering, Vellore Institute of Technology, Vellore, Tamil Nadu, India; Department of Communications Engineering, School of Electronics Engineering, Vellore Institute of Technology, Vellore, Tamil Nadu, India; Department of Communications Engineering, School of Electronics Engineering, Vellore Institute of Technology, Vellore, Tamil Nadu, India; Department of Communications Engineering, School of Electronics Engineering, Vellore Institute of Technology, Vellore, Tamil Nadu, India; Department of Communications Engineering, School of Electronics Engineering, Vellore Institute of Technology, Vellore, Tamil Nadu, India; Department of Communications Engineering, School of Electronics Engineering, Vellore Institute of Technology, Vellore, Tamil Nadu, India; Department of Communications Engineering, School of Electronics Engineering, Vellore Institute of Technology, Vellore, Tamil Nadu, India",IEEE Access,"26 Aug 2025","2025","13","","146068","146080","Handover optimization is problematic in ultra-dense 5G networks because of the extremely high number of users and base stations. Unlike other methods, classical optimization approaches are not suitable for such technologies due to their complexity. In this context, a Machine Learning (ML)-based architecture using Deep Neural Networks (DNN) and Reinforcement Learning is proposed for handover and network optimization. The DNN model considers the temporal changes in the state of the network, and reinforcement learning is responsible for policy-based decision-making for proactive intervention, adaptive-driven interference suppression, and spectral efficiency improvement. These findings support the feasibility of the proposed resource allocation technique using ML in wireless communication systems.","2169-3536","","10.1109/ACCESS.2025.3600330","Vellore Institute of Technology (VIT), Vellore, through the Faculty Seed Grant [Research Grant in Engineering Management and Sciences (RGEMS)](grant numbers:SG20240059); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11130187","Reinforcement learning;deep Q-network (DQN);handover management;ultra-dense 5G networks;machine learning (ML);network optimization;mobility management;interference reduction;quality of service (QoS);NetMonster;proactive handover","Handover;Base stations;Quality of service;5G mobile communication;Adaptation models;Load modeling;Reinforcement learning;Data models;Optimization;Decision making","","","","15","CCBY","19 Aug 2025","","","IEEE","IEEE Journals"
"Platform for Detecting Illegal Landfills Using Computer Vision and Satellite Imagery From Web Map Service","S. García González; D. Cruz García; A. Álvarez Sánchez; R. Herrero Pérez; G. Villarrubia González","Expert Systems and Applications Laboratory (ESALAB), Faculty of Science, University of Salamanca, Salamanca, Spain; Expert Systems and Applications Laboratory (ESALAB), Faculty of Science, University of Salamanca, Salamanca, Spain; Expert Systems and Applications Laboratory (ESALAB), Faculty of Science, University of Salamanca, Salamanca, Spain; Expert Systems and Applications Laboratory (ESALAB), Faculty of Science, University of Salamanca, Salamanca, Spain; Expert Systems and Applications Laboratory (ESALAB), Faculty of Science, University of Salamanca, Salamanca, Spain",IEEE Access,"15 Sep 2025","2025","13","","158551","158571","This study addresses the environmental problems of landfills through an innovative solution that combines artificial vision, satellite image analysis and agent-based architecture. The detection of these sources of contamination is particularly complex due to the visual heterogeneity of the objects present in the aerial views. To this end, a proprietary dataset has been developed aimed at identifying irregular landfills from aerial and satellite images. The research focuses on the application and comparison of the latest generation algorithms YOLOv8, YOLOv11 and YOLOv12, deployed in a multi-agent system developed with PANGEA, which allows a distributed and efficient management of the detection process. In addition, a dynamic platform has been implemented that allows the user to select geographical areas within Spain and verify the existence of landfills in these areas. In the event of detection, the system cross-references the results with official public information to determine whether the landfill is legal or illegal. Experiments show that YOLOv8 achieves outstanding performance with an accuracy of 97.25%, recall of 89.59%, F1-score of 93.27%, mAP@50 of 94.74% and mAP@50-95 of 79.06%, evidencing its potential for automated landfill detection in a real operating environment.","2169-3536","","10.1109/ACCESS.2025.3607760","[Ministerio de Ciencia e Innovación (MCIN) Ministry of Science and Innovation, Spain]/[Agencia Estatal de Investigación (AEI) State Research Agency, Spain]/10.13039/501100011033 and FSE+(grant numbers:PREP2023-151701OB); entitled ‘Self-adaptive platform based on intelligent agents for the optimisation and management of operational processes in logistics warehouses (PLAUTON)’(grant numbers:PID2023-151701OB-C21); MICIU/AEI/10.13039/501100011033 and by the European Union through ERDF ‘A way of making Europe’, ERDF/EU, and NextGenerationEU/PRTR; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11153844","Object detection;computer vision;satellite imagery;illegal dumps;convolutional neural networks (CNNs);you only look once (YOLO);deep learning;agent architecture;PANGEA;image classification","Landfills;Remote sensing;Soil;Biological system modeling;Satellite images;Accuracy;Computer architecture;Water pollution;Public healthcare;Deep learning","","","","43","CCBYNCND","9 Sep 2025","","","IEEE","IEEE Journals"
"SPP-L²: A PPO-Enhanced Large Language Model Framework for Student Performance Prediction on Learner-Sourced Questions","Z. Zhang; X. He; Y. Zhang","KeYi College of Zhejiang Sci-Tech University, Hangzhou, Zhejiang, China; KeYi College of Zhejiang Sci-Tech University, Hangzhou, Zhejiang, China; School of Modern Posts, Nanjing University of Posts and Telecommunications, Nanjing, Jiangsu, China",IEEE Access,"18 Sep 2025","2025","13","","161344","161354","In response to the growing complexity and dynamism of learner-sourced education platforms, this paper presents SPP-L2, a unified student performance prediction framework that integrates semantic understanding with reinforcement learning. The framework leverages a signed bipartite graph to capture structured student–question interactions and employs a large language model to encode the nuanced semantics of natural language questions. These representations are fused and used as input to a Proximal Policy Optimization (PPO) agent, which dynamically learns to predict student responses while receiving feedback signals for policy refinement. A value-based feedback mechanism further enhances the system’s ability to adaptively recommend questions and personalize interventions. Extensive experiments conducted on five real-world PeerWise course datasets demonstrate that SPP-L2 outperforms existing methods in terms of prediction accuracy, robustness, and adaptability. The proposed framework provides a principled and scalable solution for intelligent learning platforms by bridging representation learning, policy optimization, and feedback-driven adaptation.","2169-3536","","10.1109/ACCESS.2025.3605947","National Natural Science Foundation of China(grant numbers:62272239); 2024 Special Key Project of Zhejiang Provincial Association for Higher Education on “Research on the Application of Artificial Intelligence in Empowering Education and Teaching”(grant numbers:KT2024436); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11151292","Student performance prediction;reinforcement learning;large language models;graph neural networks;personalized education","Semantics;Predictive models;Reinforcement learning;Education;Adaptation models;Accuracy;Optimization;Large language models;Knowledge engineering;Graph neural networks","","","","29","CCBY","4 Sep 2025","","","IEEE","IEEE Journals"
"Brain Tumor Categorization and Retrieval Using Deep Brain Incep Res Architecture Based Reinforcement Learning Network","J. Chaki; M. Woźniak","School of Computer Science and Engineering, Vellore Institute of Technology, Vellore, India; Faculty of Applied Mathematics, Silesian University of Technology, Gliwice, Poland",IEEE Access,"23 Nov 2023","2023","11","","130584","130600","The categorization and retrieval of brain tumors using Magnetic Resonance Imaging (MRI) is a difficult but necessary process for brain tumor diagnosis. In this study, a reinforcement learning agent is proposed that can interact with an environment that includes brain tumor images and retrieve and categorize the most comparable images to an unknown query image. This article proposes a unique fuzzy and Deep Learning (DL)-based Reinforcement Learning (RL) strategy for categorizing three types of brain tumors as well as no tumors. Deep Brain Incep Res Architecture 2.0 based Reinforcement Learning Network (DBIRA2.0-RLN), the proposed Convolutional Neural Network (CNN)-based technique, benefits from a novel architecture in which brain tumor descriptors are established using the inception block and effective skip-connection mapping arrangement. To improve the efficiency of DBIRA2.0-RLN, improved samples are created by training and testing the system with a fuzzy logic-based technique. To lower the dimension of the descriptor vector for improved image categorization and retrieval, the descriptor vector obtained from DBIRA2.0 is binary coded using Multilinear Principal Component Analysis. DBIRA2.0 produces and preserves brain tumors and no tumor descriptors in several layers, which are then used sequentially in numerous units to construct the final brain tumor categorization and retrieval. The proposed method’s output is tested using a dataset, and the accuracy rates obtained for meningioma tumor, glioma tumor, pituitary tumor, and no tumor are 97.1%, 98.7%, 94.3%, and 100% respectively, indicating that the proposed approach outperforms the other brain tumor categorization and retrieval approaches used in the literature.","2169-3536","","10.1109/ACCESS.2023.3334434","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10322871","Brain tumor image;deep neural network;fuzzy inference system;inception block;residual network;reinforcement learning","Tumors;Feature extraction;Brain modeling;Reinforcement learning;Convolution;Residual neural networks;Magnetic resonance imaging;Brain cancer;Artificial neural networks;Fuzzy systems","","19","","31","CCBYNCND","20 Nov 2023","","","IEEE","IEEE Journals"
"C-GRAIL: Autonomous Reinforcement Learning of Multiple and Context-Dependent Goals","V. G. Santucci; D. Montella; G. Baldassarre","Istituto di Scienze e Tecnologie della Cognizione, Consiglio Nazionale delle Ricerce, Rome, Italy; Istituto di Scienze e Tecnologie della Cognizione, Consiglio Nazionale delle Ricerce, Rome, Italy; Istituto di Scienze e Tecnologie della Cognizione, Consiglio Nazionale delle Ricerce, Rome, Italy",IEEE Transactions on Cognitive and Developmental Systems,"7 Mar 2023","2023","15","1","210","222","When facing the problem of autonomously learning to achieve multiple goals, researchers typically focus on problems where each goal can be solved using just one policy. However, in environments presenting different contexts, the same goal might need different skills to be solved. These situations pose two challenges: 1) recognize which are the contexts that need different policies to perform the goals and 2) learn the policies to accomplish the same goal in the identified relevant contexts. These two challenges are even harder if faced within an open-ended learning framework where potentially an agent has no information on the environment, possibly not even about the goals it can pursue. We propose a novel robotic architecture, contextual GRAIL (C-GRAIL), that solves these challenges in an integrated fashion. The architecture is able to autonomously detect new relevant contexts and ignore irrelevant ones, on the basis of the decrease of the expected performance for a given goal. Moreover, C-GRAIL can quickly learn the policies for new contexts leveraging on transfer learning techniques. The architecture is tested in a simulated robotic environment involving a robot that autonomously discovers and learns to reach relevant target objects in the presence of multiple obstacles generating several different contexts.","2379-8939","","10.1109/TCDS.2022.3152081","European Union’s Horizon 2020 Research and Innovation Programme(grant numbers:713010); “GOAL-Robots”Goal-Based Open-Ended Autonomous Learning Robots; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9714489","Autonomous robotics;context-dependent goals;developmental robotics;intrinsic motivations (IMs);multitask reinforcement learning (RL)","Robots;Task analysis;Training;Robot sensing systems;Reinforcement learning;Multitasking;Face recognition","","3","","62","CCBY","16 Feb 2022","","","IEEE","IEEE Journals"
"Greenhouse Gas Emission Reduction Architecture in Computer Science: A Systematic Review","A. Somantri; K. Surendro","Doctoral Program of Electrical Engineering and Informatics, School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia; Department of Electrical Engineering and Informatics, School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia",IEEE Access,"13 Mar 2024","2024","12","","36239","36256","Computer Science Architecture (CSA), encompassing data, application, technology, and business architecture, is a vital tool for addressing climate change challenges. It aims to reduce greenhouse gas emissions from sectors such as stationary energy, transportation, industry, product use, waste, and land use. CSA principles extend to advanced technologies like artificial intelligence (AI), the Internet of Things (IoT), Machine Learning (ML), data centers, blockchain, multi-agent systems, sensors, and smart grids. This review explores CSA’s role in mitigating greenhouse gas emissions for a sustainable environment. It analyzes implications, indicators, and methodologies for data, application, technology, and business architecture, highlighting their direct impact on creating an environmentally friendly technological landscape. The study also delves into emerging trends and suggestions for future research, contributing to the discourse on leveraging technology for a greener future.","2169-3536","","10.1109/ACCESS.2024.3373786","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10460521","Greenhouse gas emissions;computer science architecture;sustainable environment;review","Climate change;Greenhouse gases;Computer architecture;Environmental monitoring;Sustainable development;Carbon emissions;Machine learning;Computer applications;Computer science;Green design","","14","","114","CCBYNCND","5 Mar 2024","","","IEEE","IEEE Journals"
"Resource Allocation in Information-Centric Wireless Networking With D2D-Enabled MEC: A Deep Reinforcement Learning Approach","D. Wang; H. Qin; B. Song; X. Du; M. Guizani","State Key Laboratory of Integrated Services Networks, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, Xidian University, Xi’an, China; Department of Computer and Information Sciences, Temple University, Philadelphia, PA, USA; Department of Computer Science and Engineering, Qatar University, Doha, Qatar",IEEE Access,"27 Aug 2019","2019","7","","114935","114944","Recently, information-centric wireless networks (ICWNs) have become a promising Internet architecture of the next generation, which allows network nodes to have computing and caching capabilities and adapt to the growing mobile data traffic in 5G high-speed communication networks. However, the design of ICWN is still faced with various challenges with respect to capacity and traffic. Therefore, mobile edge computing (MEC) and device-to-device (D2D) communications can be employed to aid offloading the core networks. This paper investigates the optimal policy for resource allocation in ICWNs by maximizing the spectrum efficiency and system capacity of the overall network. Due to unknown and stochastic properties of the wireless channel environment, this problem was modeled as a Markov decision process. In continuous-valued state and action variables, the policy gradient approach was employed to learn the optimal policy through interactions with the environment. We first recognized the communication mode according to the location of the cached content, considering whether it is D2D mode or cellular mode. Then, we adopt the Gaussian distribution as the parameterization strategy to generate continuous stochastic actions to select power. In addition, we use softmax to output channel selection to maximize system capacity and spectrum efficiency while avoiding interference to cellular users. The numerical experiments show that our learning method performs well in a D2D-enabled MEC system.","2169-3536","","10.1109/ACCESS.2019.2935545","National Natural Science Foundation of China(grant numbers:61772387); Fundamental Research Funds of Ministry of Education and China Mobile(grant numbers:MCM20170202); Natural Science Foundation of Shaanxi Province(grant numbers:2019ZDLGY03-03); Xidian University(grant numbers:5001-20109195456); ISN State Key Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8801829","ICWN;MEC;D2D;resource allocation","Device-to-device communication;Resource management;Wireless communication;Interference;Power control;Servers;Computer architecture","","29","","28","CCBY","15 Aug 2019","","","IEEE","IEEE Journals"
"QoE-Oriented Rate Adaptation for DASH With Enhanced Deep Q-Learning","J. Liu; X. Tao; J. Lu","Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China",IEEE Access,"22 Jan 2019","2019","7","","8454","8469","With the popularity of handheld devices, the development of wireless communication technology and the proliferation of multimedia resources, mobile video has become the main business in LTE networks with explosive traffic demands. How to improve the quality of experience (QoE) of mobile video in the dynamic and complex network environment has become a research focus. Dynamic adaptive streaming over HTTP technology introduces adaptive bitrate (ABR) requests at the client side to improve video QoE and various rate adaptation algorithms are also constantly proposed. In view of the limitations of the existing heuristic or learning-based ABR methods, we propose redirecting enhanced Deep Q-learning toward DASH video QoE (RDQ), a QoE-oriented rate adaptation framework based on enhanced deep Q-learning. First, we establish a chunkwise subjective QoE model and utilize it as the reward function in reinforcement learning so that the strategy can converge toward the direction of maximizing the subjective QoE score. Then, we apply several effective improvements of deep Q-learning to the RDQ agent’s neural network architecture and learning mechanism to achieve faster convergence and higher average reward than other learning-based methods. The proposed RDQ agent has been thoroughly evaluated using trace-based simulation on the real-time LTE network data. For disparate network scenarios and different video contents, the RDQ agent can outperform the existing methods in terms of the QoE score. The breakdown analysis shows that RDQ can suppress the number and the duration of the stalling events to the minimum while maintaining high video bitrate, thus achieving better QoE performance than other methods.","2169-3536","","10.1109/ACCESS.2018.2889999","National Basic Research Project of China (973)(grant numbers:2013CB329006); National Natural Science Foundation of China(grant numbers:61622110,61471220,91538107); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594548","Quality of experience (QoE);dynamic adaptive streaming over HTTP (DASH);enhanced deep-Q learning;rate adaptation","Streaming media;Quality of experience;Bandwidth;Bit rate;Heuristic algorithms;Reinforcement learning;Long Term Evolution","","26","","45","OAPA","28 Dec 2018","","","IEEE","IEEE Journals"
"Selective Trimmed Average: A Resilient Federated Learning Algorithm With Deterministic Guarantees on the Optimality Approximation","M. Kaheni; M. Lippi; A. Gasparri; M. Franceschelli","Akademin för Innovation, Design och Teknik (IDT), Mälardalen University, Västerås, Sweden; Department of Civil, Computer Science and Aeronautical Technologies Engineering, Roma Tre University, Rome, Italy; Department of Civil, Computer Science and Aeronautical Technologies Engineering, Roma Tre University, Rome, Italy; Department of Electrical and Electronic Engineering, University of Cagliari, Cagliari, Italy",IEEE Transactions on Cybernetics,"18 Jul 2024","2024","54","8","4402","4415","The federated learning (FL) paradigm aims to distribute the computational burden of the training process among several computation units, usually called agents or workers, while preserving private local training datasets. This is generally achieved by resorting to a server–worker architecture where agents iteratively update local models and communicate local parameters to a server that aggregates and returns them to the agents. However, the presence of adversarial agents, which may intentionally exchange malicious parameters or may have corrupted local datasets, can jeopardize the FL process. Therefore, we propose selective trimmed average (SETA), which is a resilient algorithm to cope with the undesirable effects of a number of misbehaving agents in the global model. SETA is based on properly filtering and combining the exchanged parameters. We mathematically prove that the proposed algorithm is resilient against data and local model poisoning attacks. Most resilient methods presented so far in the literature assume that a trusted server is in hand. In contrast, our algorithm works both in server–worker and shared memory architectures, where the latter excludes the necessity of a trusted server. The theoretical findings are corroborated through numerical results on MNIST dataset and on multiclass weather dataset (MWD).","2168-2275","","10.1109/TCYB.2024.3350387","Knowledge Foundation (KKS) through Safe and Secure Adaptive Collaborative Systems (SACSys)(grant numbers:20190021); Swedish Agency for Innovation Systems (Vinnova) through GREENER: Intelligent Energy Management in Connected Construction Sites(grant numbers:2019-05877); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10412629","Adversarial attacks;distributed optimization;multiagent systems;resilient federated learning (FL)","Servers;Training;Computational modeling;Stochastic processes;Data models;Optimization;Memory architecture","","9","","48","CCBY","23 Jan 2024","","","IEEE","IEEE Journals"
"Transformer and Meta-Reinforcement Learning-Based Task Offloading for MEC Systems in Dynamic Environments","Y. Li; C. Tang; B. Hou; F. Jiang; Y. Fu","School of Information Science and Engineering, Hunan Normal University, Changsha, China; School of Information Science and Engineering, Hunan Normal University, Changsha, China; School of Computer Science, Hunan University Of Technology and Business, Changsha, China; School of Information Science and Engineering, Hunan Normal University, Changsha, China; Hunan Economic Institute Electric Power Design Co., Ltd, Changsha, China",IEEE Access,"","2025","PP","99","1","1","In mobile edge computing systems, efficient decision-making for task offloading is crucial for enhancing system performance. Currently, existing reinforcement learning-based offloading methods face several primary challenges, including local feature perception, low sample efficiency, long training times, and poor stability. To address these issues, this paper proposes efficient task offloading methods based on transformer and meta-reinforcement learning. Firstly, a novel transformer architecture, Gated Transformer-XL is introduced, allowing the agent to adaptively capture various features and relationships in task offloading decisions and transform them into representations suitable for meta-reinforcement learning algorithms. Secondly, a meta-reinforcement learning framework, Gated Transformer-XL based Proximal policy optimization and Reptile (GTrXL-PR), is proposed, which offers high sample efficiency for new tasks. Even with limited computational resources, user devices can quickly train using local data combined with meta-policies. Finally, Reptile is combined with the proximal policy optimization algorithm to reduce training time by ignoring second-order derivatives, thereby enhancing the stability of the training process. The feasibility and effectiveness of the proposed algorithm are validated through experimental simulations. In experimental simulations, the proposed method achieved approximately a 1.96% reduction in task completion latency across varying rates and numbers of subtasks compared to conventional reinforcement learning methods. The initial latency was also reduced by approximately 0.12% relative to traditional algorithms, validating the feasibility and effectiveness of the proposed algorithm. For more details, the core code is available at https://github.com/liyintao23/Gtrxl_PR.","2169-3536","","10.1109/ACCESS.2025.3550183","National Natural Science Foundation of China(grant numbers:41904127); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10921728","Mobile edge computing;Task offloading;Meta-learning;Reinforcement learning","Transformers;Training;Metalearning;Heuristic algorithms;Adaptation models;Resource management;Optimization;Computational modeling;Servers;Real-time systems","","","","","CCBY","11 Mar 2025","","","IEEE","IEEE Early Access Articles"
"A Survey on the Use of Container Technologies in Autonomous Driving and the Case of BeIntelli","B. Acar; M. G. Augusto; M. Sterling; F. Sivrikaya; S. Albayrak","Chair of Agent Technology, Technische Universität Berlin, Berlin, Germany; Chair of Agent Technology, Technische Universität Berlin, Berlin, Germany; Chair of Agent Technology, Technische Universität Berlin, Berlin, Germany; Chair of Agent Technology, Technische Universität Berlin, Berlin, Germany; Chair of Agent Technology, Technische Universität Berlin, Berlin, Germany",IEEE Open Journal of Intelligent Transportation Systems,"28 Nov 2023","2023","4","","800","814","The application of containerization technology has seen a significant increase in popularity in recent years, both in the business and scientific sectors. In particular, the ability to create portable applications that can be deployed on different machines has become a valuable asset. Autonomous driving has embraced this technology, as it offers a wide range of potential applications, including the operation of autonomous vehicles and the digitization of infrastructure for the development of Cooperative, Connected, and Automated Mobility (CCAM) services. This paper provides a comprehensive analysis of containerization in autonomous driving, emphasizing its application, utility, benefits, and limitations.","2687-7813","","10.1109/OJITS.2023.3331449","German Federal Ministry for Digital and Transport (BMDV) through BeIntelli Project(grant numbers:01MM20004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10314411","Docker;containerization;automotive;CCAM;autonomous driving","Containers;Autonomous vehicles;Virtualization;Virtual machining;Operating systems;Microservice architectures;Industries","","4","","97","CCBYNCND","9 Nov 2023","","","IEEE","IEEE Journals"
"Reinforcement-Learning-Based Trajectory Design and Phase-Shift Control in UAV-Mounted-RIS Communications","T. Sun; S. Yin; L. Deng; F. Richard Yu","Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, China; Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, China; Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, China; Shenzhen Key Laboratory of Digital and Intelligent Technologies and Systems, Shenzhen University, Shenzhen, China",IEEE Transactions on Machine Learning in Communications and Networking,"3 Jan 2025","2025","3","","163","175","Taking advantages of both unmanned aerial vehicles (UAVs) and reconfigurable intelligent surfaces (RISs), UAV-mounted-RIS systems are expected to enhance transmission performance in complicated wireless environments. In this paper, we focus on system design for a UAV-mounted-RIS system and investigate joint optimization for the RIS’s phase shift and the UAV’s trajectory. To cope with the practical issue of inaccessible information on the user terminals’ (UTs) location and channel state, a reinforcement learning (RL)-based solution is proposed to find the optimal policy with finite steps of “trial-and-error”. As the action space is continuous, the deep deterministic policy gradient (DDPG) algorithm is applied to train the RL model. However, the online interaction between the agent and environment may lead to instability during the training and the assumption of (first-order) Markovian state transition could be impractical in real-world problems. Therefore, the decision transformer (DT) algorithm is employed as an alternative for RL model training to adapt to more general situations of state transition. Experimental results demonstrate that the proposed RL solutions are highly efficient in model training along with acceptable performance close to the benchmark, which relies on conventional optimization algorithms with the UT’s locations and channel parameters explicitly known beforehand.","2831-316X","","10.1109/TMLCN.2024.3502576","Beijing Natural Science Foundation(grant numbers:L232040,L223030); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10758222","UAV-aided communications;reconfigurable intelligent surface (RIS);reinforcement learning;trajectory design;phase shift configuration","Trajectory;Wireless communication;Training;Autonomous aerial vehicles;Optimization;Relays;Wireless sensor networks;System analysis and design;Reinforcement learning;Reconfigurable intelligent surfaces","","","","43","CCBY","19 Nov 2024","","","IEEE","IEEE Journals"
"DeepAir: A Multi-Agent Deep Reinforcement Learning-Based Scheme for an Unknown User Location Problem","B. Yamansavascilar; A. Ozgovde; C. Ersoy","Department of Computer Engineering, Bogazici University, Istanbul, Türkiye; Department of Computer Engineering, Bogazici University, Istanbul, Türkiye; Department of Computer Engineering, Bogazici University, Istanbul, Türkiye",IEEE Access,"20 Dec 2024","2024","12","","192195","192208","Unmanned Aerial Vehicles (UAVs) are a major component in next-generation network architecture proposals, playing a critical role in problems like dynamic capacity enhancement, user coverage, and task offloading. When smart utilization of the UAVs is missing, these proposals may require sophisticated approaches, including the deployment of additional edge servers and orchestration efforts. A typical challenge arises from the dynamic nature of real-world problems in which the required capacity should be provided at particular times when fixed infrastructure proves insufficient. One of those existing dynamic problems is the unknown user locations in an infrastructure-less environment in which users cannot connect to any communication device or computation-providing server, which is essential to task offloading in order to achieve the required quality of service (QoS). Therefore, in this study, we investigate this problem thoroughly and propose a novel deep reinforcement learning (DRL) based scheme, DeepAir. DeepAir uses four main phases including sensing, localization, resource allocation, and multi-access edge computing (MEC) to provide the corresponding QoS requirements for the offloaded tasks without violating the maximum tolerable delay. To this end, we use two types of UAVs including detector UAVs, and serving UAVs. We utilize detector UAVs as DRL agents which ensure the sensing, localization, and resource allocation phases. On the other hand, we utilize serving UAVs to provide MEC features. Our experiments show that DeepAir provides higher task success rates by deploying fewer detector UAVs in different scenarios with different numbers of users and user attraction points compared to benchmark methods. Thus, DeepAir achieves 59.65%, 86.06%, and 86.72% task success rates for 2, 4, and 6 detector UAVs, respectively, by using 12 serving UAVs, while the most successful benchmark method provides 28.62%, 41.39%, and 61.09% task success rates for the same configuration, respectively.","2169-3536","","10.1109/ACCESS.2024.3518562","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10804169","Deep reinforcement learning;task offloading;UAVs","Autonomous aerial vehicles;Location awareness;Sensors;Resource management;Quality of service;Detectors;Servers;Image edge detection;Disasters;Cloud computing","","","","33","CCBY","16 Dec 2024","","","IEEE","IEEE Journals"
"An Adaptive Strategy Selection Method With Reinforcement Learning for Robotic Soccer Games","H. Shi; Z. Lin; K. -S. Hwang; S. Yang; J. Chen","School of Computer Science, Northwestern Polytechnical University, Xi’an, China; School of Computer Science, Northwestern Polytechnical University, Xi’an, China; National Sun Yat-sen University, Kaohsiung, Taiwan; School of Computer Science, Northwestern Polytechnical University, Xi’an, China; School of Computer Science, Northwestern Polytechnical University, Xi’an, China",IEEE Access,"7 Mar 2018","2018","6","","8376","8386","Robotic soccer games, which have become popular, require timely and precise decisionmaking in a dynamic environment. To address the problems of complexity in a critical situation, policy improvement in robotic soccer games must occur. This paper proposes an adaptive decisionmaking method that uses reinforcement learning (RL), and the decision-making system for a robotic soccer game is composed of two subsystems. The first subsystem in the architecture for the proposed method criticizes the situation, and the second subsystem implements decision-making policy. Inspired by the support vector machine (SVM), a situation classification method, which is called an improved SVM, embeds a decision tree structure and simultaneously addresses the problems of a large scale and multiple classifications. When a variety of situations that are collected in the field are classified and congregated into the tree structure, the problem of local strategy selection for each individual class of situations over time is regarded as a RL problem and is solved using a Q-learning method. The results of simulations and experiments demonstrate that the proposed method allows satisfactory decision-making.","2169-3536","","10.1109/ACCESS.2018.2808266","National Research and Development Plan of China(grant numbers:2017YFB1001900); Fund of National Ministries(grant numbers:2016ZC53022); Fundamental Research Funds for the Central Universities(grant numbers:3102017JSJ0005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8301430","Robotic soccer;support vector machines;reinforcement learning;Q learning","Games;Support vector machines;Decision making;Robot kinematics;Learning (artificial intelligence);Decision trees","","38","","40","OAPA","23 Feb 2018","","","IEEE","IEEE Journals"
"JAICOB: A Data Science Chatbot","D. Carlander-Reuterfelt; Á. Carrera; C. A. Iglesias; Ó. Araque; J. F. Sánchez Rada; S. Muñoz","Grupo de Sistemas Inteligentes, Universidad Politécnica de Madrid, Madrid, Spain; Grupo de Sistemas Inteligentes, Universidad Politécnica de Madrid, Madrid, Spain; Grupo de Sistemas Inteligentes, Universidad Politécnica de Madrid, Madrid, Spain; Grupo de Sistemas Inteligentes, Universidad Politécnica de Madrid, Madrid, Spain; Grupo de Sistemas Inteligentes, Universidad Politécnica de Madrid, Madrid, Spain; Grupo de Sistemas Inteligentes, Universidad Politécnica de Madrid, Madrid, Spain",IEEE Access,"9 Oct 2020","2020","8","","180672","180680","The application of natural language to improve students' interaction with information systems is demonstrated to be beneficial. In particular, advances in cognitive computing enable a new way of interaction that accelerates insight from existing information sources, thereby contributing to the process of learning. This work aims at researching the application of cognitive computing in blended learning environments. We propose a modular cognitive agent architecture for pedagogical question answering, featuring social dialogue (small talk), improved for a specific knowledge domain. This system has been implemented as a personal agent to assist students in learning Data Science and Machine Learning techniques. Its implementation includes the training of machine learning models and natural language understanding algorithms in a human-like interface. The effectiveness of the system has been validated through an experiment.","2169-3536","","10.1109/ACCESS.2020.3024795","Educational Innovation Programme of Universidad Politécnica de Madrid(grant numbers:IE1819.0908); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9200315","Cognitive informatics;educational technology;human-computer interaction;machine learning;natural language processing","Machine learning;Terminology;Data science;Natural languages;Cognitive systems;Computer architecture;Documentation","","39","","47","CCBY","18 Sep 2020","","","IEEE","IEEE Journals"
"Agentic AI: A Comprehensive Survey of Technologies, Applications, and Societal Implications","A. K. Pati","Department of Computer Science and Engineering, Centre for Data Science, Siksha ‘O’ Anusandhan Deemed to be University, Bhubaneswar, Odisha, India",IEEE Access,"4 Sep 2025","2025","13","","151824","151837","Agentic AI brings a new level of advancement in artificial intelligence (AI), as it is capable of goal-directed behaviour, dynamic adaptation, and self-improvement. It influences various significant fields, such as robotics, healthcare, autonomous vehicles, and labor automation. This paper explores the defining features of agentic AI, highlights its differences from traditional AI, and discusses how autonomy, memory, goal-directed behavior, and adaptive reasoning contribute to increasingly general capabilities. Rather than proposing a new architecture, we offer a conceptual analysis of the trajectory from current agentic frameworks to future agentic AI systems. Examining applications in significant fields, including precision medicine, industrial robotics, and self-driving technologies, and discussing societal impacts, particularly concerning workforce disruption, augmentation, and ethical issues arising from agentic AI systems. The paper identifies key research directions for ensuring beneficial and controllable agentic AI development. This work serves as a primary source for exploring agentic AI by compiling existing research and identifying open questions.","2169-3536","","10.1109/ACCESS.2025.3585609","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11071266","Agentic AI;autonomous agents;autonomous vehicles;multi-agent systems (MAS);reinforcement learning (RL)","Artificial intelligence;Surveys;Collaboration;Reinforcement learning;Ethics;Vehicle dynamics;Security;Medical services;Large language models;Education","","","","129","CCBY","3 Jul 2025","","","IEEE","IEEE Journals"
"A Social Media Based Approach for Route Planning During Urban Events","Z. Wang; W. Huang","Department of Human Geography and Spatial Planning, Faculty of Geosciences, Utrecht University, Utrecht, CB, The Netherlands; Ontario Ministry of Transportation, Toronto, Canada",IEEE Access,"24 Nov 2020","2020","8","","207589","207598","Traffic congestion is a major issue in most big cities, resulting in longer travel time and increased greenhouse gas emission. Various factors can cause traffic congestion, and includes not only traffic events on roads (e.g., car accidents) but also urban events (e.g., football games, concerts, and festivals), where a large number of human activities happen in a certain place and at a certain time. The technology of connected vehicles (CV) has provided a crowd-souring platform enabling communication between vehicles and surrounding information share to be more timely and effective. Taking the advantage of that, in this paper we focus on navigation during urban events, and present an approach to find feasible routes avoiding traffic congestion caused by the different types of events. Using 12-month geo-tagged tweets, we create a human activity network to capture certain types of human activities across cities. Based on that, an event estimation algorithm is developed to find the possible events that would occur in the near future, and to estimate their probabilities. These detected events are represented in the form of obstacle polygons with timestamps, and are used by the routing algorithm to generate congestion avoidance routes. We apply our approach to the road network of Toronto, Ontario, Canada, and the experimental results show the capability of our approach in supporting routing during urban events.","2169-3536","","10.1109/ACCESS.2020.3037531","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9256353","Algorithm;connected vehicles;human activities;urban events;routing","Roads;Social networking (online);Semantics;Prediction algorithms;Planning;Routing;Heuristic algorithms","","4","","26","CCBY","11 Nov 2020","","","IEEE","IEEE Journals"
"Proactive Random-Forest Autoscaler for Microservice Resource Allocation","L. M. Al Qassem; T. Stouraitis; E. Damiani; I. A. M. Elfadel","Center for Cyber-Physical Systems (C2PS), Khalifa University, Abu Dhabi, United Arab Emirates; Center for Cyber-Physical Systems (C2PS), Khalifa University, Abu Dhabi, United Arab Emirates; Center for Cyber-Physical Systems (C2PS), Khalifa University, Abu Dhabi, United Arab Emirates; Center for Cyber-Physical Systems (C2PS), Khalifa University, Abu Dhabi, United Arab Emirates",IEEE Access,"10 Jan 2023","2023","11","","2570","2585","Cloud service providers have been shifting their workloads to microservices to take advantage of their modularity, flexibility, agility, and scalability. However, numerous obstacles remain to achieving the most out of microservice deployments, especially in terms of a Quality of Service (QoS). One possible approach to overcoming these obstacles is to perform autoscaling, which is the ability of cloud infrastructure and services to scale themselves up or down by changing their resource pool. There are two major categories of autoscaling: reactive and proactive. In reactive autoscaling, a feedback loop based on current workload resource usage is implemented to guide resource scaling. One disadvantage of reactive autoscaling is that it may result in inconsistencies between workload demand and resource allocation. In proactive autoscaling, a prediction model is used to guide the future allocation of resources according to current workload metrics. In this paper, a novel proactive autoscaling method is introduced where a two-state, machine-learning Random Forest (RF) model is designed to forecast the future CPU and memory utilization values required by the microservice workload. These predicted values are then used to adjust the resource pool both vertically (hardware resources) and horizontally (microservice replicas). The RF proactive autoscaler has been implemented on a home-grown, open-source microservice prototyping platform and verified using real-world workloads. The experiments show that the RF proactive autoscaler outperforms state-of-the-art ones in terms of allocated resources and latency. The increase in the utilization of allocated resources can reach 90% and the improvement in end-to-end latency, measured by the  $95^{th}$  percentile, can reach 95%.","2169-3536","","10.1109/ACCESS.2023.3234021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10005166","Microservices;autoscalers;resource allocation;resource utilization;machine learning;random forest","Microservice architectures;Predictive models;Radio frequency;Resource management;Measurement;Quality of service;Cloud computing;Microservice architectures;Random forests;Machine learning","","34","","35","CCBY","3 Jan 2023","","","IEEE","IEEE Journals"
"A Real-Time Software Defined Networking Framework for Next-Generation Industrial Networks","L. Moutinho; P. Pedreiras; L. Almeida","Instituto de Telecomunicações (IT), Aveiro, Portugal; Instituto de Telecomunicações (IT), Aveiro, Portugal; Electrical and Computer Engineering Department, Faculty of Engineering, University of Porto (FEUP), Porto, Portugal",IEEE Access,"18 Nov 2019","2019","7","","164468","164479","Industry 4.0 brings in a whole set of new requirements to engineering industrial systems, with notorious impact at the networking layer. A key challenge posed by Industry 4.0 is the operational flexibility needed to support on-the-fly reconfiguration of production cells, stations, and machines. At the networking layer, this flexibility implies dynamic packet handling, scheduling, and dispatching. SoftwareDefined Networking (SDN) provides this level of flexibility in the general Local Area Network (LAN) domain. However, its application in the industry has been hindered by a lack of support for real-time services. This paper addresses this limitation, proposing an extended SDN OpenFlow framework that includes realtime services, leveraging existing real-time data plane Ethernet technologies. We show the OpenFlow enhancements, a real-time SDN controller, and experimental validation and performance assessment. Using a proof-of-concept prototype with 3 switches and cycles of 250μs, we could achieve 1μs jitter on timetriggered traffic and a reconfiguration time between operational modes below 10ms.","2169-3536","","10.1109/ACCESS.2019.2952242","Programa Operacional Temático Factores de Competitividade(grant numbers:PRODUTECH II SIF,POCI-01-0247-FEDER-024541); Research Centre Instituto de Telecomunicações(grant numbers:UID/EEA/50008/2013); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894096","HaRTES;Industry 4.0;OpenFlow;real-time communications;software-defined networking","Real-time systems;Industries;Quality of service;Ethernet;Job shop scheduling;Jitter;Computer architecture","","23","","34","CCBY","7 Nov 2019","","","IEEE","IEEE Journals"
"Towards Securing IIoT: An Innovative Privacy-Preserving Anomaly Detector Based on Federated Learning","S. K. Poorazad; C. Benzaïd; T. Taleb","Centre for Wireless Communications, University of Oulu, Oulu, Finland; Centre for Wireless Communications, University of Oulu, Oulu, Finland; Department of Electrical Engineering and Information Technology, Ruhr University Bochum, Bochum, Germany",IEEE Internet of Things Journal,"","2025","PP","99","1","1","In the light of the growing connectivity and sensitivity of industrial data, cyberattacks and data breaches are becoming more common in the Industrial Internet of Things (IIoT). To cope with such threats, this study presents an anomaly detection system based on a novel Federated Learning (FL) framework. This system detects anomalies such as cyberattacks and protects industrial data privacy by processing data locally and training anomaly detection models on industrial agents without sharing raw data. The proposed FL framework incorporates two key components to enhance both privacy and efficiency. The first component is Homomorphic Encryption (HE), which is integrated into the framework to further protect sensitive data transmissions such as model parameters. HE enhances privacy in FL by preventing adversaries from inferring private industrial data through attacks, such as model inversion attacks. The second component is an innovative dynamic agent selection scheme, wherein a selection threshold is calculated based on agent delays and data size. The purpose of this new scheme is to mitigate the straggler effect and the communication bottleneck that occur in traditional FL architectures, such as synchronous and asynchronous architectures. It ensures that agents are not unfairly selected by the different delays resulting from heterogeneous data in IIoT environments, while simultaneously improving model performance and convergence speed. The proposed framework exhibits superior performance over baseline approaches in terms of accuracy, precision, F1-scores, communication costs, convergence speeds, and fairness rate.","2327-4662","","10.1109/JIOT.2025.3613063","RIGOUROUS(grant numbers:856709); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11175416","Federated Learning;Privacy-preserving;Industrial Internet of Things;Anomaly Detection","Industrial Internet of Things;Training;Data models;Data privacy;Anomaly detection;Accuracy;Servers;Delays;Computational modeling;Privacy","","","","","CCBY","22 Sep 2025","","","IEEE","IEEE Early Access Articles"
"Energy Consumption of Machine Learning Enhanced Open RAN: A Comprehensive Review","X. Liang; Q. Wang; A. Al-Tahmeesschi; S. B. Chetty; D. Grace; H. Ahmadi","School of Physics, Engineering and Technology, University of York, York, U.K; School of Physics, Engineering and Technology, University of York, York, U.K; School of Physics, Engineering and Technology, University of York, York, U.K; School of Physics, Engineering and Technology, University of York, York, U.K; School of Physics, Engineering and Technology, University of York, York, U.K; School of Physics, Engineering and Technology, University of York, York, U.K",IEEE Access,"14 Jun 2024","2024","12","","81889","81910","The Open Radio Access Network (RAN) emerges as a revolutionary architecture promising unprecedented levels of openness, flexibility, and intelligence within radio access networks. Central to this innovation is the integration of Machine Learning (ML) and Artificial Intelligence (AI) within the RAN Intelligent Controller (RIC), aimed at optimizing network operations and enhancing control mechanisms. This paper undertakes a thorough examination of Open RAN, particularly focusing on its energy consumption aspects, which are pivotal for ensuring the sustainability of future wireless networks. In this paper, we review and compare Open RAN architecture with previous network architectures. In particular we focus on O-RAN Alliance specifications. Additionally, we explore the deployment of ML across various facets of Open RAN and highlights how to estimate the energy consumption of ML models. Through constructing explicit energy consumption models for key O-RAN components, we provide a granular analysis of their energy profiles. Finally we compare the energy dynamics of O-RAN against traditional RAN architectures, delineating the impact of virtualization and disaggregation on energy efficiency.","2169-3536","","10.1109/ACCESS.2024.3412758","Engineering and Physical Sciences Research Council United Kingdom, Impact Acceleration Accounts(grant numbers:EP/X525856/1); Department of Science, Innovation and Technology, U.K., through Yorkshire Open-RAN(grant numbers:TS/X013758/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10552840","Open radio access network (Open RAN);energy efficiency;machine learning;disaggregation","Energy consumption;Computer architecture;Energy efficiency;Resource management;Virtualization;Reviews;5G mobile communication;Radio access networks;Open systems","","16","","94","CCBY","11 Jun 2024","","","IEEE","IEEE Journals"
"Discrete decision model and multi-agent simulation of the Liang Zong two-chain hierarchical organization in a complex project","M. Qiang; Z. Yueqiang; A. Shi","Harbin Institute of Technology, Harbin, Heilongjiang, CN; Harbin Institute of Technology, Harbin, Heilongjiang, CN; Harbin Institute of Technology, Harbin, Heilongjiang, CN",Journal of Systems Engineering and Electronics,"10 May 2018","2018","29","2","311","320","Different from the organization structure of complex projects in Western countries, the Liang Zong hierarchical organization structure of complex projects in China has two different chains, the chief-engineer chain and the general-director chain, to handle the trade-off between technical and management decisions. However, previous works on organization search have mainly focused on the single-chain hierarchical organization in which all decisions are regarded as homogeneous. The heterogeneity and the interdependency between technical decisions and management decisions have been neglected. A two-chain hierarchical organization structure mapped from a real complex project is constructed. Then, a discrete decision model for a Liang Zong two-chain hierarchical organization in an NK model framework is proposed. This model proves that this kind of organization structure can reduce the search space by a large amount and that the search process should reach a final stable state more quickly. For a more complicated decision mechanism, a multi-agent simulation based on the above NK model is used to explore the effect of the two-chain organization structure on the speed, stability, and performance of the search process. The results provide three insights into how, compared with the single-chain hierarchical organization, the two-chain organization can improve the search process: it can reduce the number of iterations efficiently; the search is more stable because the search space is a smoother hill-like fitness landscape; in general, the search performance can be improved. However, when the organization structure is very complicated, the performance of a two-chain organization is inferior to that of a single-chain organization. These findings about the efficiency of the unique Chinese-style organization structure can be used to guide organization design for complex projects.","1004-4132","","10.21629/JSEE.2018.02.12","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8355934","complex project;two-chain hierarchical organization;discrete decision model;multi-agent simulation","Organizations;Modeling;Moon;Complexity theory;Industries","","1","","","","10 May 2018","","","BIAI","BIAI Journals"
"Teaching Learning-Based Optimization With Evolutionary Binarization Schemes for Tackling Feature Selection Problems","T. Thaher; M. Mafarja; H. Turabieh; P. A. Castillo; H. Faris; I. Aljarah","Department of Engineering and Technology Sciences, Arab American University, Ramallah, Palestine; Department of Computer Science, Birzeit University, Ramallah, Palestine; Department of Information Technology, College of Computers and Information Technology, Taif University, Taif, Saudi Arabia; Department of Computer Architecture and Technology, University of Granada, Granada, Spain; School of Computing and Informatics, Al Hussein Technical University, Amman, Jordan; King Abdullah II School for Information Technology, The University of Jordan, Amman, Jordan",IEEE Access,"16 Mar 2021","2021","9","","41082","41103","Machine learning techniques heavily rely on available training data in a data set. Certain features in the data can interfere with the learning process, so it is required to remove irrelevant and redundant features to build a robust training model. As such, several feature selection techniques are usually applied in a pre-processing phase to obtain the most appropriate set of features and improve the overall learning process. In this paper, a new feature selection approach is proposed based on a modified Teaching-Learning-based Optimization (TLBO) combined with four new binarization methods: the Elitist, the Elitist Roulette, the Elitist Tournament, and the Rank-based method. The influence of these binarization methods is studied and compared to other state-of-the-art techniques. The experimental results such as Shapiro-Wilk normality and Wilcoxon ranksum test show that both transfer functions and binarization approaches have a significant influence on the effectiveness of the binary TLBO. The experiments show that choosing a fitting transfer function along with a suitable binarization method has a substantial impact on the exploratory and exploitative potentials of the feature selection technique.","2169-3536","","10.1109/ACCESS.2021.3064799","Taif University Researchers Supporting Project, Taif University, Taif, Saudi Arabia(grant numbers:TURSP-2020/125); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9373374","Teaching-learning;feature selection;metaheuristic;transfer function;binarization","Optimization;Feature extraction;Transfer functions;Search problems;Information technology;Particle swarm optimization;Genetic algorithms","","18","","103","CCBY","9 Mar 2021","","","IEEE","IEEE Journals"
"Investigating Impacts of Telemedicine on Emergency Department Through Decreasing Non-Urgent Patients in Spain","E. Shojaei; A. Wong; D. Rexachs; F. Epelde; E. Luque","Department of Computer Architecture and Operating Systems, Universitat Autonoma de Barcelona, Bellaterra, Spain; Department of Computer Architecture and Operating Systems, Universitat Autonoma de Barcelona, Bellaterra, Spain; Department of Computer Architecture and Operating Systems, Universitat Autonoma de Barcelona, Bellaterra, Spain; Department of Medicine, Hospital Universitari Parc Taulí, Sabadell, Spain; Department of Computer Architecture and Operating Systems, Universitat Autonoma de Barcelona, Bellaterra, Spain",IEEE Access,"18 Sep 2020","2020","8","","164238","164245","In this paper, a new method is presented to study the impacts of telemedicine on the performance of an emergency department in Spain. Spain's Demographics indicate that this country is experiencing population aging, resulting in overcrowding of emergency departments and significant demand on the healthcare system. However, it has been reported that most patients visiting emergency departments are not in an urgent clinical condition, thus they causing hospital overcrowding, high medical expenses, delays in clinical service delivery and low service efficiency for urgent patients who truly need emergency care. Telemedicine and e-health are considered as solutions for remote delivery of health services to care seekers in order to decrease hospital visits for patients who are in less of an emergency condition. In this study, by using detailed computational modeling and clinical data, we have investigated the impacts of telemedicine on the performance of an emergency department through estimations of Length of Stay as a quantitative index for evaluation of quality of service in the emergency department. Specifically, an agent-based modeling and simulation system was developed and used to study the behavior of the emergency department by taking detailed modeling parameters, including varying the number of non-urgent arrivals as a result of telemedicine, into account as inputs of the model. The inputs were provided through collection and analysis of clinical data that enabled us to predict how telemedicine changes emergency department visits. Our results indicated that emergency departments would experience decreases equal to 41.14% in total Length of Stay if eliminating all non-urgent visits and decreases of up to 10.48% if restricting the non-urgent visits. The developed computational tool in this study and the corresponding results obtained can provide decision makers and health care providers with objective information on the impacts of e-health services on the efficiency of emergency department and they can have also implications for care delivery, optimizing resources, planning, and improving the quality of care.","2169-3536","","10.1109/ACCESS.2020.3019667","Agencia Estatal de Investigación (AEI), Spain; Fondo Europeo de Desarrollo Regional (FEDER) UE(grant numbers:TIN2017-84875-P); Fundacion Escuelas Universitarias Gimbernat (EUG); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9178375","Emergency department;length of stay;telemedicine and e-health;agent-based modeling and simulation;clinical data collection and analysis;non-urgent visits","Telemedicine;Hospitals;Computational modeling;Analytical models;Predictive models;Sociology","","7","","17","CCBY","26 Aug 2020","","","IEEE","IEEE Journals"
"Safe Reinforcement Learning to Improve FACTS Setpoint Control in Presence of Model Errors","M. Tarle; M. Larsson; G. Ingeström; L. Nordström; M. Björkman","Department of Intelligent Systems, KTH Royal Institute of Technology, Stockholm, Sweden; Hitachi Energy, Baden-Dättwil, Switzerland; Hitachi Energy, Västerås, Sweden; Department of Electrical Engineering, KTH Royal Institute of Technology, Stockholm, Sweden; Department of Intelligent Systems, KTH Royal Institute of Technology, Stockholm, Sweden",IEEE Transactions on Industry Applications,"19 Sep 2025","2025","61","6","8887","8896","There is limited application of closed-loop control using model-based approaches in wide area monitoring, protection, and control. Challenges that impede model-based approaches include engineering complexity, convergence issues, and model errors. Specifically, considering the rapid growth of distributed generation and renewables in the grid, maintaining an updated model without model errors is challenging. As an alternative to model-based approaches, data-driven control architectures based on reinforcement learning (RL) have shown great promise. In this work, we confront safety concerns with data-driven approaches by studying safe RL to improve voltage and power flow control. For both a model-free RL agent and a model-based RL agent, the accumulated constraint violation is investigated in a case study on the IEEE 14-bus and IEEE 57-bus systems. To evaluate performance, agents are compared against a model-based approach subject to errors. Our findings suggest that RL could be considered for optimizing voltage and current setpoints in systems when topological model errors are present.","1939-9367","","10.1109/TIA.2025.3569502","Swedish Foundation for Strategic Research(grant numbers:ID19-0058); Hitachi Energy; Wallenberg AI, Autonomous Systems and Software Program; Knut och Alice Wallenbergs Stiftelse; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11002592","Decision support systems;flexible AC transmission systems (FACTS);power system control;reinforcement learning (RL)","Reinforcement learning;Thyristors;Optimization;Markov decision processes;Costs;Aerospace electronics;Standards;Renewable energy sources;Power system dynamics;Power capacitors","","","","26","CCBY","12 May 2025","","","IEEE","IEEE Journals"
"Multi-Agent Framework for Service Restoration in Distribution Systems With Distributed Generators and Static/Mobile Energy Storage Systems","P. Prabawa; D. -H. Choi","School of Electrical and Electronics Engineering, Chung-Ang University, Seoul, South Korea; School of Electrical and Electronics Engineering, Chung-Ang University, Seoul, South Korea",IEEE Access,"19 Mar 2020","2020","8","","51736","51752","This paper presents a multi-agent system (MAS)-based approach for service restoration in a distribution system with distributed generators (DGs), static energy storage systems (SESSs), and mobile energy storage systems (MESSs). In comparison with existing MAS-based service restoration approaches in a two-layer cyber-physical architecture, excluding the dispatch of MESSs, we propose a three-layer framework that consists of cyber, physical, and transportation layers corresponding to the communication scheme for the MAS, electric distribution system, and transportation network for MESSs, respectively. In the proposed MAS framework, agents communicate and cooperate with each other for service restoration without violating system operation constraints by conducting the following actions: i) Kruskal-algorithm-based island reconfiguration (switch agent), ii) generation of switching sequence and dispatches of DGs and SESSs (DG and static battery agents) under monitored loading condition (load agent), and iii) dispatch of MESSs based on optimal road routing using the Dijkstra algorithm (mobile battery agent). Case studies were carried out in an IEEE 33-bus distribution system, and the results validated the performance of the proposed approach in terms of number of restored loads and restoration time steps, voltage level, and state of charge of the SESSs and MESSs with different numbers of fault lines and SESSs/MESS, and different extents of damaged roads.","2169-3536","","10.1109/ACCESS.2020.2980544","National Research Foundation of Korea(grant numbers:2018R1C1B6000965); Chung-Ang University Research Grants in 2019; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9035499","Service restoration;multi-agent system;mobile energy storage system;distributed generator;restoration sequence;active distribution network","Switches;Generators;Energy storage;Load modeling;Multi-agent systems;Roads","","62","","35","CCBY","13 Mar 2020","","","IEEE","IEEE Journals"
"A Novel Ant Colony Optimization Algorithm With Levy Flight","Y. Liu; B. Cao","School of Software Engineering, Tongji University, Shanghai, China; College of Architecture and Urban Planning, Tongji University, Shanghai, China",IEEE Access,"17 Apr 2020","2020","8","","67205","67213","Ant Colony Optimization (ACO) is a widely applied meta-heuristic algorithm. Little researches focused on the candidate selection mechanism, which was developed based on the simple uniform distribution. This paper employs the Levy flight mechanism based on Levy distribution to the candidate selection process and takes advantage of Levy flight that not only guarantees the search speed but also extends the searching space to improve the performance of ACO. Levy ACO incorporating with Levy flight developed on the top of Max-min ACO. According to the computational experiments, the performance of Levy ACO is significantly better than the original Max-min ACO and some latest Traveling Salesman Problem (TSP) solvers.","2169-3536","","10.1109/ACCESS.2020.2985498","National Natural Science Foundation of China(grant numbers:41771410); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9056538","Ant colony optimization;Levy flight;Levy distribution;traveling salesman problem","Ant colony optimization;Optimization;Reinforcement learning;Random variables;Space exploration;Traveling salesman problems;Indexes","","78","","46","CCBY","3 Apr 2020","","","IEEE","IEEE Journals"
"Reinforcement Learning With Selective Exploration for Interference Management in mmWave Networks","S. Dinh-van; v. -L. Nguyen; B. B. Cebecioglu; A. Masaracchia; M. D. Higgins","Warwick Manufacturing Group, School of Engineering, The University of Warwick, Coventry, U.K.; Advanced Institute of Manufacturing With High-Tech Innovations, National Chung Cheng University (CCU), Minxiong, Chiayi, Taiwan; School of Computing and Digital Technology, Birmingham City University, Birmingham, U.K.; School of Electronic Engineering and Computer Science, Queen Mary University of London, London, U.K.; Warwick Manufacturing Group, School of Engineering, The University of Warwick, Coventry, U.K.",IEEE Transactions on Machine Learning in Communications and Networking,"14 Feb 2025","2025","3","","280","295","The next generation of wireless systems will leverage the millimeter-wave (mmWave) bands to meet the increasing traffic volume and high data rate requirements of emerging applications (e.g., ultra HD streaming, metaverse, and holographic telepresence). In this paper, we address the joint optimization of beamforming, power control, and interference management in multi-cell mmWave networks. We propose novel reinforcement learning algorithms, including a single-agent-based method (BPC-SA) for centralized settings and a multi-agent-based method (BPC-MA) for distributed settings. To tackle the high-variance rewards caused by narrow antenna beamwidths, we introduce a selective exploration method to guide the agent towards more intelligent exploration. Our proposed algorithms are well-suited for scenarios where beamforming vectors require control in either a discrete domain, such as a codebook, or in a continuous domain. Furthermore, they do not require channel state information, extensive feedback from user equipments, or any searching methods, thus reducing overhead and enhancing scalability. Numerical results demonstrate that selective exploration improves per-user spectral efficiency by up to 22.5% compared to scenarios without it. Additionally, our algorithms significantly outperform existing methods by 50% in terms of per-user spectral effciency and achieve 90% of the per-user spectral efficiency of the exhaustive search approach while requiring only 0.1% of its computational runtime.","2831-316X","","10.1109/TMLCN.2025.3537967","WMG Centre High Value Manufacturing Catapult; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10869481","Beam training;deep reinforcement learning;interference management;mmWave;multi agent;power control;selective exploration","Millimeter wave communication;Interference;Array signal processing;Power control;Spectral efficiency;Real-time systems;Computer architecture;Training;Approximation algorithms;Wireless networks","","","","38","CCBY","3 Feb 2025","","","IEEE","IEEE Journals"
"Agentic AI Systems: Architecture and Evaluation Using a Frictionless Parking Scenario","A. Khamis","AI for Smart Mobility Laboratory, Interdisciplinary Research Center for Smart Mobility and Logistics, King Fahd University of Petroleum and Minerals, Dhahran, Saudi Arabia",IEEE Access,"23 Jul 2025","2025","13","","126052","126069","An AI agent is a goal-oriented autonomous computational entity that connects reasoning and action using large language models (LLMs) or Large Reasoning Models (LRMs), memory systems, and external tools to achieve contextually intelligent outcomes. An agentic AI system comprises and coordinates multiple specialized AI agents to achieve complex goals with minimal or no human supervision. In this paper, agentic AI systems are elucidated through a frictionless-parking scenario that illustrates core components of the system, namely the design of individual AI agents, their interaction mechanisms (handoff and cueing), and potential cooperation patterns (augmentative, integrative, and debative). This scenario provides an experimental test-bed for demonstrating how agentic AI can deliver context-aware, personalized services. A six-factor factorial experiment evaluates performance of the implemented AI agents across five user profiles, four GPT backbones, three entropy levels, three verbosity settings, three query complexities, and three prompt specificity levels. To guarantee that each agent’s recommendation is both plausible and constraint-compliant, the system combines guardrails, which reject or rewrite answers that violate user requirements, with Chain-of-Thought prompting that exposes intermediate reasoning steps for internal self-checks. Key metrics (agent’s response time or latency and lexical consistency) show that a lightweight gpt-4o-mini backbone and concise verbosity minimize latency, while medium prompt specificity and moderate query complexity optimize consistency. Decoding entropy influences stylistic diversity without significant latency costs but reduces consistency at high settings. User intent, particularly for creative or ambiguous profiles, drives variability. A SHAP analysis ranks model size, verbosity, and prompt specificity as top performance drivers.","2169-3536","","10.1109/ACCESS.2025.3590264","Deanship of Research (DOR) at King Fahd University of Petroleum and Minerals (KFUPM) through the Agentic AI-Based Framework for Seamless Integrated Mobility(grant numbers:ECR241-ISE-301); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11083588","Agentic AI;AI agents;large language models (LLMs);large reasoning models (LRMs);multi-agent system;parking;urban mobility","Artificial intelligence;Cognition;Urban areas;Planning;Computer architecture;Real-time systems;Large language models;Entropy;Decision making;Complexity theory","","","","29","CCBY","17 Jul 2025","","","IEEE","IEEE Journals"
"Adaptive Defense: Zero-Day Attack Detection in NIDS With Deep Reinforcement Learning","K. Alam; M. Fahad Monir; M. Junayed Hossain; M. Shorif Uddin; M. T. Habib","Department of Computer Science and Engineering (CSE), Independent University at Bangladesh, Dhaka, Bangladesh; Department of Computer Science and Engineering (CSE), Independent University at Bangladesh, Dhaka, Bangladesh; Department of Computer Science and Engineering (CSE), Independent University at Bangladesh, Dhaka, Bangladesh; Department of Computer Science and Engineering, Jahangirnagar University, Dhaka, Bangladesh; Department of Computer Science and Engineering (CSE), Independent University at Bangladesh, Dhaka, Bangladesh",IEEE Access,"11 Jul 2025","2025","13","","116345","116361","Zero-Day attack detection in Network Intrusion Detection Systems (NIDS) refers to the ability to identify previously unseen attack patterns during testing without having been explicitly trained on those specific attacks, utilizing learned features from other known attacks. In this paper, we propose a Deep Reinforcement Learning (DRL)-based NIDS designed for Zero-Day attack detection. We use a stacked LSTM architecture to extend the learning capabilities of the DRL agent. We apply several oversampling techniques to handle the issue of class imbalance since the zero-day attack datasets are not as abundant. We use some of the most widely available benchmark datasets in NIDS domain, which all together cover a wide range of attack types, such as reconnaissance, ddoS, infiltration, injection, password attacks, brute force, dos, backdoor, and benign traffic. For example, we converted attacks to 1 and benign traffic to 0, then excluded certain attack categories (DoS and Backdoor) from the training dataset while keeping them in the test dataset. This makes those attack types zero-day attacks, as they are entirely unseen during training. We also compare which data balancing technique works better among K-means SMOTE, SMOTE, Borderline-SMOTE and ADASYN on the performance of our DRL agent. We then demonstrate how powerful our agent is by validating many datasets for remarkable success in detecting both known and unknown attacks in a zero-day manner. Our work has been made publicly available on GitHub (https://github.com/codewithkhurshed/ZDAD) to support researchers in advancing zero-day attack detection in NIDS.","2169-3536","","10.1109/ACCESS.2025.3585445","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11063272","Zero-day attack detection;deep reinforcement learning;cybersecurity;network intrusion detection systems;internet;unseen attack generalization;digital infrastructure;industrialization;governance;SDG 9;SDG 16","Training;Network intrusion detection;Security;Testing;Deep reinforcement learning;Data models;Computer security;Adaptation models;Long short term memory;Network security","","1","","36","CCBY","2 Jul 2025","","","IEEE","IEEE Journals"
"SSDWSN: A Scalable Software-Defined Wireless Sensor Networks","M. Alsaeedi; M. M. Mohamad; A. Al-Roubaiey","Faculty of Computing, Universiti Teknologi Malaysia, Johor Bahru, Malaysia; Faculty of Computing, Universiti Teknologi Malaysia, Johor Bahru, Malaysia; Computer Engineering Department, College of Computing and Mathematics, King Fahd University of Petroleum and Minerals, Dhahran, Saudi Arabia",IEEE Access,"13 Feb 2024","2024","12","","21787","21806","In multi-hop wireless sensor networks (WSNs), sensors operate autonomously and make routing decisions independently. However, these devices are often located in remote or inaccessible areas and have limited energy and memory resources. As the network scales, efficient management to conserve resources and extend its lifetime becomes increasingly challenging. Software-defined WSNs (SDWSNs) offer a solution by enabling centralized control of low-power WSNs. However, continuously updating the controller with the network state generates significant traffic, resulting in energy loss, increased overhead, and reduced scalability and network lifetime. This study proposes a scalable SDWSN framework (SSDWSN) to address these challenges. The proposed approach focuses on scheduling, balanced routing, aggregation, and reducing traffic overhead caused by periodic network state updates to the controller. This paper presents the architecture of the proposed framework, along with the Deep Reinforcement Learning (DRL) agent. It also proposes two Proximal Policy Optimization (PPO)-based learning policies, namely PPO-ATCP and PPO-NSFP. These policies are designed to efficiently utilize SDWSN network resources and accurately predict the network state by continuously monitoring the synchronized network state within the controller, taking appropriate actions, and updating the learning parameters based on reward functions. The simulation results demonstrate the effectiveness of PPO-ATCP and PPO-NSFP in reducing controller-bound traffic overhead by 57% and 85%, respectively, while improving energy efficiency by 28% and 53% in SDWSNs. Additionally, PPO-NSFP achieved a minimum accuracy of 85% in network state prediction under different network-size scenarios.","2169-3536","","10.1109/ACCESS.2024.3362353","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10422802","Software-defined wireless sensor networks;control traffic overhead;proximal policy optimization;deep reinforcement learning;energy efficiency","Wireless sensor networks;Routing;Sensors;Scalability;Optimization;Telecommunication traffic;Protocols;Software defined networking;Deep learning;Reinforcement learning","","6","","49","CCBYNCND","5 Feb 2024","","","IEEE","IEEE Journals"
"HRL-TSCH: A Hierarchical Reinforcement Learning-Based TSCH Scheduler for IIoT","F. F. Jurado-Lasso; C. Orfanidis; J. F. Jurado; X. Fafoutis","Embedded Systems Engineering Section, DTU Compute, Technical University of Denmark, Lyngby, Denmark; Embedded Systems Engineering Section, DTU Compute, Technical University of Denmark, Lyngby, Denmark; Department of Basic Science, Faculty of Engineering and Administration, Universidad Nacional de Colombia Sede Palmira, Palmira, Colombia; Embedded Systems Engineering Section, DTU Compute, Technical University of Denmark, Lyngby, Denmark",IEEE Transactions on Cognitive Communications and Networking,"5 Dec 2024","2024","10","6","2102","2118","The Industrial Internet of Things (IIoT) demands adaptable Networked Embedded Systems (NES) for optimal performance. Combined with recent advances in Artificial Intelligence (AI), tailored solutions can be developed to meet specific application requirements. This study introduces HRL-TSCH, an approach rooted in Hierarchical Reinforcement Learning (HRL), to devise Time Slotted Channel Hopping (TSCH) schedules provisioning IIoT demand. HRL-TSCH employs dual policies: one at a higher level for TSCH schedule link management, and another at a lower level for timeslot and channel assignments. The proposed RL agents address a multi-objective problem, optimizing throughput, power efficiency, and network delay based on predefined application requirements. Simulation experiments demonstrate HRL-TSCH‘s superiority over existing state-of-art approaches, effectively achieving an optimal balance between throughput, power consumption, and delay, thereby enhancing IIoT network performance.","2332-7731","","10.1109/TCCN.2024.3408459","DAIS. DAIS has received funding from the ECSEL Joint Undertaking (JU)(grant numbers:101007273); European Union’s Horizon 2020 research and innovation programme and Sweden, Spain, Portugal, Belgium, Germany, Slovenia, Czech Republic, Netherlands, Denmark, Norway, and Turkey; Innovationsfonden(grant numbers:0228-00004A); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10546985","Industrial Internet of Things (IIoT);Networked Embedded Systems (NES);sleep scheduling;Time Slotted Channel Hopping (TSCH);Reinforcement Learning (RL);Software-Defined Wireless Sensor Networks (SDWSNs)","Schedules;Industrial Internet of Things;Heuristic algorithms;Delays;Scheduling algorithms;Throughput;Optimal scheduling","","7","","35","CCBY","3 Jun 2024","","","IEEE","IEEE Journals"
"Trait Based Trustworthiness Assessment in Human-Agent Collaboration Using Multi-Layer Fuzzy Inference Approach","S. Hussain; R. A. Naqvi; S. Abbas; M. A. Khan; T. Sohail; D. Hussain","School of Computer Science, National College of Business Administration and Economics, Lahore, Pakistan; Department of Unmanned Vehicle Engineering, Sejong University, Seoul, South Korea; School of Computer Science, National College of Business Administration and Economics, Lahore, Pakistan; Department of Software Engineering, Pattern Recognition and Machine Learning Laboratory, Gachon University, Seongnam, South Korea; Department of Mathematics, University of Jhang, Jhang, Pakistan; School of Computational Sciences, Korea Institute for Advanced Study (KIAS), Seoul, Republic of Korea",IEEE Access,"21 May 2021","2021","9","","73561","73574","Trust is an essential requirement for effective Human-Agent interaction as artificial agents are becoming part of human society in a social context. To blend into our society and maximize their acceptability and reliability, artificial agents need to adapt to the complexity of their surroundings, like humans. This adaptation should come through knowing whom to trust by evaluating the trustworthiness of its human mate. It is therefore required to build cognitive agents with trust models that may allow them to trust humans the same way a human trusts other humans keeping under consideration all factors influencing the human agent trust mechanism. Several antecedents within the cognitive system itself and the surroundings dynamically influence the trust mechanism. Personality, as a trusted antecedent has been found to have a substantial impact in predicting human interactor’s trustworthiness that critically assists trust decision making. Current research, therefore, aims to infuse characteristics of respective humans as the antecedent of the human agent trust process. This is accomplished by incorporating into the trust model the agent’s capability to perceive the personality traits of the human interactor. The current work is focused on introducing a trustworthiness assessment model (TAMFIS) based on fuzzy inference to assess human’s trustworthiness towards artificial agents by exploring the human’s personality traits that predict trustworthiness. The artificial agent could develop its character towards its human collaborators that will help it in effective interactions. The testing of the proposed architecture is carried out using Dempster Shafer Theory of belief and estimation. It is anticipated that the proposed trust model will effectively evaluate the trustworthiness of human collaborators and develop a more reliable human–agent trust relationship.","2169-3536","","10.1109/ACCESS.2021.3079838","Korea Institute for Advanced Study (KIAS)(grant numbers:CG076601); Sejong University Faculty Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9429236","Big 5 personality traits;multi-agent systems;trustworthiness;artificial agent;Dempster Shafer theory","Collaboration;Fuzzy logic;Biological system modeling;Psychology;Estimation;Task analysis","","29","","57","CCBY","12 May 2021","","","IEEE","IEEE Journals"
"GOSELO: Goal-Directed Obstacle and Self-Location Map for Robot Navigation Using Reactive Neural Networks","A. Kanezaki; J. Nitta; Y. Sasaki","National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; National Institute of Advanced Industrial Science and Technology, Tokyo, Japan",IEEE Robotics and Automation Letters,"8 Jan 2018","2018","3","2","696","703","Robot navigation using deep neural networks has been drawing a great deal of attention. Although reactive neural networks easily learn expert behaviors and are computationally efficient, they suffer from generalization of policies learned in specific environments. As such, reinforcement learning and value iteration approaches for learning generalized policies have been proposed. However, these approaches are more costly. In this letter, we tackle the problem of learning reactive neural networks that are applicable to general environments. The key concept is to crop, rotate, and rescale an obstacle map according to the goal location and the agent's current location so that the map representation will be better correlated with self-movement in the general navigation task, rather than the layout of the environment. Furthermore, in addition to the obstacle map, we input a map of visited locations that contains the movement history of the agent, in order to avoid failures that the agent travels back and forth repeatedly over the same location. Experimental results reveal that the proposed network outperforms the state-of-the-art value iteration network in the grid-world navigation task. We also demonstrate that the proposed model can be well generalized to unseen obstacles and unknown terrain. Finally, we demonstrate that the proposed system enables a mobile robot to successfully navigate in a real dynamic environment.","2377-3766","","10.1109/LRA.2017.2783400","New Energy and Industrial Technology Development Organization; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8207619","Deep learning in robotics and automation;visual-based navigation;recognition","Navigation;Path planning;Robots;Neural networks;Agriculture;Computational modeling","","22","","23","OAPA","14 Dec 2017","","","IEEE","IEEE Journals"
"Logarithmic Potential Field: A New Leader– Follower Robotic Control Mechanism to Enhance the Execution Speed and Safety Attributes","R. Fareh; M. Baziyad; S. Khadraoui; B. Brahmi; M. Bettayeb","Electrical Engineering Department, University of Sharjah, Sharjah, United Arab Emirates; RISE, University of Sharjah, Sharjah, United Arab Emirates; Electrical Engineering Department, University of Sharjah, Sharjah, United Arab Emirates; Department of Electrical Engineering, College Ahuntsic, Montreal, QC, Canada; Electrical Engineering Department, University of Sharjah, Sharjah, United Arab Emirates",IEEE Access,"17 Aug 2023","2023","11","","85451","85466","The leader-follower formation approach is a commonly used strategy in multi-robot systems, usually implemented with a hierarchical control architecture combining path planning and formation control. The leader robot determines the desired trajectory while the follower robots track the motion of the leader robot using a control system. However, this hierarchical architecture does not ensure successful obstacle avoidance for follower robots. Several solutions proposed adding an obstacle avoidance layer, but this can increase the system complexity and reduce the computational speed, hindering real-time performance. Improving the opposing attributes, namely the execution speed, path length, safety, and smoothness, together is a challenging path-planning problem in robotics. This paper proposes a novel leader-follower control mechanism that combines formation control and obstacle avoidance in one step. The new path planning technique focuses on enhancing execution speed and safety while ensuring the generation of smooth paths with acceptable path lengths. The main contribution of the proposed technique lies in the development of a novel potential field modeling approach specifically designed for follower robots in a multi-robot system. The proposed potential field model consists of three terms, namely, the Gaussian term, the Euclidean term, and the Logarithmic term, which are all optimized later using Particle Swarm Optimization (PSO) to generate the path. The Gaussian term, acting as a repulsive force, represents the Gaussian distance to each obstacle in the environment. It exhibits a strong value in close proximity to obstacles, while it gradually decays exponentially as the distance from the obstacles increases. The second term, the Euclidean term, which is the Euclidean distance to the leader robot, is responsible to find the shortest path to the leader robot. Finally, to ensure follower robot safety, a logarithmic term is integrated into the potential field model, facilitating automatic switching between attractive and repulsive forces generated by the leader robot. The incorporation of a logarithmic term into the potential field model stands as a significant innovation in the proposed technique. This inclusion enables the leader robot to generate an initial attractive force towards the followers, which dynamically transitions into a repulsive force as the follower robots approach. This automatic switching behavior enhances processing efficiency while ensuring collision avoidance. A kinematic control strategy is applied to the system in order to test the proposed path planning technique. The experimental results have proven the effectiveness of the proposed system, which has shown superior performance over the well-known techniques A*, RRT*, PRM, and also Hybrid-A* in terms of execution speed and the path length.","2169-3536","","10.1109/ACCESS.2023.3303873","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10214001","Multi-robot;leader-follower;path planning;potential field;kinematic control","Robots;Robot kinematics;Collision avoidance;Task analysis;Path planning;Multi-robot systems;Behavioral sciences","","4","","32","CCBYNCND","9 Aug 2023","","","IEEE","IEEE Journals"
"Selective Reading for Arabic Sentiment Analysis","M. Zouidine; M. Khalil","LMCSA, FSTM, Hassan II University of Casablanca, Casablanca, Morocco; LMCSA, FSTM, Hassan II University of Casablanca, Casablanca, Morocco",IEEE Access,"8 Apr 2025","2025","13","","59157","59169","This work introduces a novel deep learning method for Arabic sentiment analysis, arguing that reading the entire input sequence is not always necessary. Many texts can be accurately classified without processing all input tokens. The method employs a reinforcement learning agent that selects relevant tokens using a selection policy network. Instead of predicting sentiment polarity from the entire input, the model focuses only on tokens chosen by the policy network. To empirically evaluate the proposed method, experiments were carried out on three Arabic sentiment analysis datasets: Large Arabic Book Reviews (LABR), Hotels Arabic Reviews Data (HARD), and Arabic Sentiment Tweets Dataset (ASTD). The results demonstrate a significant improvement in Arabic sentiment classification with the selective reading method, achieving state-of-the-art accuracy while using only a fraction of the tokens. However, the approach introduces additional computational cost due to the reinforcement learning component, and its scalability to larger datasets might require further optimization.","2169-3536","","10.1109/ACCESS.2025.3556976","Ministry of Higher Education, Scientific Research, and Innovation, the Digital Development Agency (DDA), and the National Center for Scientific and Technical Research (CNRST) of Morocco(grant numbers:Alkhawarizmi/2020/01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10947753","Arabic natural language processing;convolutional neural network;deep reinforcement learning;gated recurrent unit;selective reading","Sentiment analysis;Long short term memory;Convolutional neural networks;Feature extraction;Analytical models;Reviews;Deep learning;Vectors;Training;Social networking (online)","","1","","72","CCBY","2 Apr 2025","","","IEEE","IEEE Journals"
"DAWN: Designing Distributed Agents in a Worldwide Network","Z. Aminiranjbar; J. Tang; Q. Wang; S. Pant; M. Viswanathan","Cisco Systems, Inc., San Jose, CA, USA; Cisco Systems, Inc., San Jose, CA, USA; Cisco Systems, Inc., San Jose, CA, USA; Cisco Systems, Inc., San Jose, CA, USA; Cisco Systems, Inc., San Jose, CA, USA",IEEE Access,"12 Aug 2025","2025","13","","138795","138812","The rapid evolution of Large Language Models (LLMs) has transformed them from basic conversational tools into sophisticated entities capable of complex reasoning and decision-making. These advancements have led to the development of specialized LLM-based agents designed for diverse tasks such as coding and web browsing. As these agents become more capable, the need for a robust framework that facilitates global agentic communication and collaboration for building sophisticated software solutions has become increasingly important. Distributed Agents in a Worldwide Network (DAWN) addresses this need by providing an architectural framework that allows globally distributed agents of any provenance to be registered, discovered, and organized for building AI-based applications and solutions. In DAWN, a Principal Agent Service composes and oversees the execution of agentic applications. It delegates tasks to one or more Gateway Agent Services that provide for the discovery, registration, and connection of the most suitable agents to fit each application’s needs. DAWN offers three operational modes: No-LLM mode for deterministic and classical software development, Copilot for decision-making augmented using AI, and LLM Agent for autonomous operations. Last but not least, DAWN ensures the safety and security of agent collaborations globally through a dedicated safety, security, and compliance layer, protecting the network against attackers and adhering to stringent security and compliance standards. These features make DAWN a robust framework for designing, developing, and deploying agent-based applications across business and consumer applications.","2169-3536","","10.1109/ACCESS.2025.3588425","Cisco Outshift, the Innovation Engine of Cisco Systems, Inc; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11078243","Large language model;AI agents;agentic software development;multi-agent systems;agentic frameworks","Logic gates;Security;Safety;Collaboration;Multi-agent systems;Software development management;Computer architecture;Cognition;Software tools;Large language models","","1","","72","CCBY","11 Jul 2025","","","IEEE","IEEE Journals"
"Unveiling Agents’ Confidence in Opinion Dynamics Models via Graph Neural Networks","V. A. Vargas-Pérez; J. Giráldez-Cru; P. Mesejo; O. Cordón","Department of Computer Science and Artificial Intelligence (DECSAI), University of Granada (UGR), Granada, Spain; University of Seville (US), Seville, Spain; Department of Computer Science and Artificial Intelligence (DECSAI), University of Granada (UGR), Granada, Spain; Department of Computer Science and Artificial Intelligence (DECSAI), University of Granada (UGR), Granada, Spain",IEEE Transactions on Computational Social Systems,"3 Apr 2025","2025","12","2","725","737","Opinion Dynamics models in social networks are a valuable tool to study how opinions evolve within a population. However, these models often rely on agent-level parameters that are difficult to measure in a real population. This is the case of the confidence threshold in opinion dynamics models based on bounded confidence, where agents are only influenced by other agents having a similar opinion (given by this confidence threshold). Consequently, a common practice is to apply a universal threshold to the entire population and calibrate its value to match observed real-world data, despite being an unrealistic assumption. In this work, we propose an alternative approach using graph neural networks to infer agent-level confidence thresholds in the opinion dynamics of the Hegselmann-Krause model of bounded confidence. This eliminates the need for additional simulations when faced with new case studies. To this end, we construct a comprehensive synthetic training dataset that includes different network topologies and configurations of thresholds and opinions. Through multiple training runs utilizing different architectures, we identify GraphSAGE as the most effective solution, achieving a coefficient of determination $R^{2}$ above 0.7 in test datasets derived from real-world topologies. Remarkably, this performance holds even when the test topologies differ in size from those considered during training.","2329-924X","","10.1109/TCSS.2024.3508452","ERDF “A way of making Europe”(grant numbers:CONFIA PID2021-122916NB-I00); FPU Program(grant numbers:FPU20/02441); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10792931","Agent-based modeling;bounded confidence;graph neural networks;Hegselmann–Krause model;opinion dynamics","Graph neural networks;Computational modeling;Training;Predictive models;Analytical models;Social networking (online);Network topology;Ions;Data models;Context modeling","","","","53","CCBY","11 Dec 2024","","","IEEE","IEEE Journals"
"Legal Query RAG","R. S. M. Wahidur; S. Kim; H. Choi; D. S. Bhatti; H. -N. Lee","School of Electrical Engineering and Computer Science, Gwangju Institute of Science and Technology, Gwangju, South Korea; Artificial Intelligence Graduate School, Gwangju Institute of Science and Technology, Gwangju, South Korea; School of Electrical Engineering and Computer Science, Gwangju Institute of Science and Technology, Gwangju, South Korea; School of Electrical Engineering and Computer Science, Gwangju Institute of Science and Technology, Gwangju, South Korea; School of Electrical Engineering and Computer Science, Gwangju Institute of Science and Technology, Gwangju, South Korea",IEEE Access,"3 Mar 2025","2025","13","","36978","36994","Recently, legal practice has seen a significant rise in the adoption of Artificial Intelligence (AI) for various core tasks. However, these technologies remain in their early stages and face challenges such as understanding complex legal reasoning, managing biased data, ensuring transparency, and avoiding misleading responses, commonly referred to as hallucinations. To address these limitations, this paper introduces Legal Query RAG (LQ-RAG), a novel Retrieval-Augmented Generation framework with a recursive feedback mechanism specifically designed to overcome the critical shortcomings of standard RAG implementations in legal applications. The proposed framework incorporates four key components: a custom evaluation agent, a specialized response generation model, a prompt engineering agent, and a fine-tuned legal embedding LLM. Together, these components effectively minimize hallucinations, improve domain-specific accuracy, and deliver precise, high-quality responses for complex queries. Experimental results demonstrate that the fine-tuned embedding LLM achieves a 13% improvement in Hit Rate and a 15% improvement in Mean Reciprocal Rank (MRR). Comparisons with general LLMs reveal a 24% performance gain when using the Hybrid Fine-Tuned Generative LLM (HFM), the specialized response generation model integrated into the LQ-RAG framework. Furthermore, LQ-RAG achieves a 23% improvement in relevance score over naive configurations and a 14% improvement over RAG with Fine-Tuned LLMs (FTM). These findings underscore the potential of domain-specific fine-tuned LLMs, combined with advanced RAG modules and feedback mechanisms, to significantly enhance the reliability and performance of AI in legal practice. The reliance of this study on a proprietary model as the evaluation agent, combined with the lack of feedback from human experts, highlights the need for improvement. Future efforts should focus on developing a specialized legal evaluation agent and enhancing its performance by incorporating feedback from domain experts.","2169-3536","","10.1109/ACCESS.2025.3542125","Institute of Information & communications Technology Planning & Evaluation (IITP); Korea Government (MSIT) (IITP-2025-RS-2021-II210118, Development of decentralized consensus composition technology for large-scale nodes); IITP (Institute of Information & Communications Technology Planning & Evaluation)-ITRC (Information Technology Research Center); Korea Government [Ministry of Science and Information and Communication Technology (ICT)](grant numbers:IITP-2025-RS-2021-II211835); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10887211","Retrieval-augmented generation;legal query;LLM agent;information retrieval","Law;Retrieval augmented generation;Accuracy;Tuning;Semantics;Hybrid power systems;Adaptation models;Training;Reliability;Mathematical models","","6","","63","CCBY","14 Feb 2025","","","IEEE","IEEE Journals"
"Studying Forgetting in Faster R-CNN for Online Object Detection: Analysis Scenarios, Localization in the Architecture, and Mitigation","B. Wagner; D. Pellerin; S. Huet","CNRS, Grenoble INP, GIPSA-Laboratory, Université Grenoble Alpes, Grenoble, France; CNRS, Grenoble INP, GIPSA-Laboratory, Université Grenoble Alpes, Grenoble, France; CNRS, Grenoble INP, GIPSA-Laboratory, Université Grenoble Alpes, Grenoble, France",IEEE Access,"13 Jan 2025","2025","13","","6067","6079","Online Object Detection (OOD) requires learning new object categories from a stream of images, similar to an agent exploring new environments. In this context, the widely used architecture Faster R-CNN (Region Convolutional Neural Network) faces catastrophic forgetting: the acquisition of new knowledge leads to the loss of previously learned information. In this paper, we investigate the learning and forgetting mechanisms of Faster R-CNN in OOD through three main contributions. First, we observe that the forgetting curves of the Faster R-CNN exhibit patterns similar to those described in human memory studies by Hermann Ebbinghaus: knowledge is lost exponentially over time and recall improves knowledge retention. Second, we present a new methodology to analyse the Faster R-CNN architecture and quantify forgetting across the Faster R-CNN components. We show that forgetting is mainly localised in the Softmax classification layer. Finally, we propose a new training strategy for OOD called Configurable Recall (CR). CR performs recalls on old data using images stored in a memory buffer with variable frequency and recall length to ensure efficient learning. CR also masks the logits of old objects in the softmax classification layer to mitigate forgetting. We evaluate our strategy against state-of-the-art methods on three OOD benchmarks. We analyse the effectiveness of different types of recall in mitigating forgetting and show that CR outperforms existing methods.","2169-3536","","10.1109/ACCESS.2024.3523637","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10817562","Catastrophic forgetting;online object detection;faster R-CNN;Ebbinghaus forgetting curve;natural replay;online continual learning","Benchmark testing;Object detection;Training;Streaming media;Data models;Feature extraction;Computer architecture;Proposals;Continuing education;Object recognition","","1","","70","CCBY","27 Dec 2024","","","IEEE","IEEE Journals"
"Multi-Agent Reinforcement Learning-Based Resource Management for End-to-End Network Slicing","Y. Kim; H. Lim","School of Electrical Engineering and Computer Science, Gwangju Institute of Science and Technology (GIST), Gwangju, Republic of Korea; AI Graduate School, Gwangju Institute of Science and Technology (GIST), Gwangju, Republic of Korea",IEEE Access,"16 Apr 2021","2021","9","","56178","56190","To meet the explosive growth of mobile traffic, the 5G network is designed to be flexible and support multi-access edge computing (MEC), thereby improving the end-to-end quality of service (QoS). In particular, 5G network slicing, which allows a physical infrastructure to split into multiple logical networks, keeps the balance of network resource allocation among different service types with on-demand resource requests. However, achieving effective resource allocation across the end-to-end network is difficult due to the dynamic characteristics of slicing requests such as uncertain real-time resource demand and heterogeneous requirements. In this paper, we develop a reinforcement learning (RL)-based dynamic resource allocation framework for end-to-end network slicing with heterogeneous requirements in multi-layer MEC environments. We first design a hierarchical MEC architecture and formulate a resource allocation problem for the end-to-end network slicing as an optimization problem using the Markov decision process (MDP). Using proximal policy optimization (PPO), we develop independently-collaborative and jointly-collaborative dynamic resource allocation algorithms to maximize resource efficiency while satisfying the QoS of slices. Experimental results show that the proposed algorithms can recognize the characteristics of slice requests and coming resource demands and efficiently allocate resources with a high QoS satisfaction rate.","2169-3536","","10.1109/ACCESS.2021.3072435","Agency for Defense Development, South Korea(grant numbers:UD200007ED); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9400356","5G;network slicing;multi-access edge computing;network resource management;multi-agent reinforcement learning","Resource management;Network slicing;5G mobile communication;Dynamic scheduling;Quality of service;Delays;Computer architecture","","49","","33","CCBYNCND","12 Apr 2021","","","IEEE","IEEE Journals"
"Collaborative Autonomous Navigation of Quadrotors in Unknown Outdoor Environments: An Active Visual SLAM Approach","S. Elahian; M. A. Amiri Atashgah; B. Tarvirdizadeh","Department of Aerospace Engineering, College of Interdisciplinary Science and Technology, University of Tehran, Tehran, Iran; Department of Aerospace Engineering, College of Interdisciplinary Science and Technology, University of Tehran, Tehran, Iran; Department of Mechatronics Engineering, School of Intelligent Systems Engineering, College of Interdisciplinary Science and Technology, Advanced Service Robots (ASR) Laboratory, University of Tehran, Tehran, Iran",IEEE Access,"17 Oct 2024","2024","12","","147115","147128","The development of an integrated path-planning and Simultaneous Localization and Mapping (ASLAM) system, specifically designed for the autonomous and real-time guidance of quadrotors navigating through unexplored outdoor environments helps to map the generation of unknown natural resources. To achieve this goal, a path-planning methodology that leverages system observability is exploited for a quadrotor. This path-planning method is underpinned by the eigenvalues of the Gramian matrix, which are used as a measure of system observability degree, to increase the precision of the quadrotor’s estimated position. In SLAM, high accuracy in the quadrotor’s state estimation improves the accuracy of the map landmarks position estimation. To enhance the accuracy and fortify system robustness, implementing a centralized distributed architecture within a group of three quadrotors is advocated. In this setup, the role of a central hub for information fusion from all agents and determining the most observable path for the entire group is assigned to the leader quadrotor. An assessment of the proposed path-planning method against a random path-planning approach within a single-agent architecture is conducted across various scenarios. This evaluation compares the Root Mean Square Error (RMSE) of the quadrotor’s state estimation. The results illustrate a notable improvement in accuracy. Furthermore, a comparison is conducted to assess the performance of the multi-agent architecture in contrast to the single-agent architecture using the proposed method. The simulation and experimental results confirm a better accuracy in all scenarios and highlight the increased robustness of the cooperative architecture, particularly in fault scenarios, compared to a single-agent architecture.","2169-3536","","10.1109/ACCESS.2024.3473792","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10704676","Autonomous navigation;concurrent path-planning;active simultaneous localization and mapping;quadrotors;system observability;position estimation;cooperative architecture","Quadrotors;Simultaneous localization and mapping;Accuracy;Mathematical models;Observability;Computer architecture;Robustness;Real-time systems;Location awareness;Autonomous robots;Position measurement;Navigation","","","","58","CCBYNCND","3 Oct 2024","","","IEEE","IEEE Journals"
"Efficient Integration of Reinforcement Learning in Graph Neural Networks-Based Recommender Systems","A. Sharifbaev; M. Mozikov; H. Zaynidinov; I. Makarov","Department of Artificial Intelligence, Tashkent University of Information Technologies named after Muhammad al-Khwarizmi, Tashkent, Uzbekistan; AIRI, Moscow, Russia; Department of Artificial Intelligence, Tashkent University of Information Technologies named after Muhammad al-Khwarizmi, Tashkent, Uzbekistan; AIRI, Moscow, Russia",IEEE Access,"19 Dec 2024","2024","12","","189439","189448","Recommendation systems have advanced significantly in recent years, achieving greater accuracy and relevance. However, traditional approaches often suffer from a mismatch between the losses used during training and the metrics used for evaluation. Models are typically trained to minimize a loss function, while their effectiveness during testing is assessed using different ranking metrics, leading to suboptimal recommendation quality. To address this limitation, reinforcement learning (RL) has emerged as a promising solution. Although RL has been applied in recommendation systems, the integration of graph neural networks (GNNs) within this framework remains underexplored. In this study, we bridge this gap by integrating GNNs and RL to enhance ranking accuracy and recommendation quality. We propose two key innovations: 1) leveraging learnable graphs to embed user-item interactions, with RL optimizing user rewards to improve ranking quality, and 2) modifying GNN architectures with skip connections to enhance recommendation accuracy while reducing training time and improving convergence. Our comprehensive analysis on multiple real-world datasets demonstrates the impact of different GNN architectures and their modifications on the effectiveness of recommendation systems. Our findings demonstrate the potential of combining GNNs and RL to overcome the limitations of traditional recommendation models and achieve state-of-the-art performance, with XSimGCL-skip achieving an average improvement of approximately 2.5% over baseline methods.","2169-3536","","10.1109/ACCESS.2024.3516517","grant for research centers in the field of artificial intelligence, provided by the Analytical Center (ACRF) in accordance with the subsidy agreement; agreement with the Ivannikov Institute for System Programming of the Russian Academy of Sciences dated November 2, 2021(grant numbers:70-2021-00142); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10795136","Recommendation system;graph neural networks;reinforcement learning;double deep Q-networks","Recommender systems;Graph neural networks;Reinforcement learning;Training;Accuracy;Optimization;Heuristic algorithms;Extraterrestrial measurements;Decision making;Adaptation models","","4","","41","CCBY","12 Dec 2024","","","IEEE","IEEE Journals"
"ResilioMate: A Resilient Multi-Agent Task Executing Framework for Enhancing Small Language Models","Y. Xiong; M. Huang; X. Liang; M. Tao","School of Transportation Engineering, East China Jiaotong University, Nanchang, Jiangxi, China; School of Transportation Engineering, East China Jiaotong University, Nanchang, Jiangxi, China; School of Transportation Engineering, East China Jiaotong University, Nanchang, Jiangxi, China; School of Computer Science and Technology, Guangdong University of Technology, Guangzhou, China",IEEE Access,"23 May 2025","2025","13","","86892","86911","Recent advances in large language models (LLMs) have been limited by their processing requirements and vulnerability to adversarial assaults, whilst short language models (SLMs) struggle with performance consistency in complex tasks. This research introduces ResilioMate, a resilient multi-agent framework that enhances SLMs by utilizing distributed cognitive burden distribution, dual-scale memory systems, and collaborative bias prevention strategies. The method employs dynamic task decomposition across specialized agents (e.g., Assistant, Checker) to minimize computational costs and combines short-term trajectory tracking with long-term self-reflective optimization for adaptive execution. At its core, the LeptoConnect model series (1.8B/7B parameters) is created using hybrid attention distillation and dynamic curriculum learning to enable cross-domain competence while retaining SLM efficiency. ResilioMate accomplishes three critical improvements: 1) The 1.8B LeptoConnect model attains 81.6% of GPT-4’s performance in knowledge graph construction through parameter-efficient fine-tuning with structured weight matrices; 2) LeptoConnect-7B achieves a score of 41.3 in database operations, compared to GPT-4’s 32.0, through collaborative cognitive load allocation; and 3) A bias-interception network effectively suppresses adversarial propagation while achieving code correction performance of ROUGE-L’s 42.86. The framework’s dual-scale memory architecture reduces computational redundancy by 26.4% through real-time task tracking and multi-agent knowledge refinement. These developments illustrate ResilioMate’s efficacy in bridging the performance gap between SLMs and LLMs, offering a scalable solution for the deployment of efficient language agents in real-time and peripheral computing environments.","2169-3536","","10.1109/ACCESS.2025.3567244","National Natural Science Foundation of China(grant numbers:52202413); Jiangxi Provincial University Social Science Foundation(grant numbers:GL21213); Natural Science Foundation of Jiangxi Province(grant numbers:20232BAB214093); Jiangxi Association for Science and Technology Youth Talent Support Program(grant numbers:02023QT15); Jiangxi Provincial Key Laboratory of Comprehensive Stereoscopic Traffic Information Perception and Fusion; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10988534","ResilioMate;multi-agent systems;small language models;dual-scale memory systems;LeptoConnect","Computational modeling;Collaboration;Structured Query Language;Robustness;Real-time systems;Databases;Computer architecture;Adaptation models;Reflection;Optimization","","1","","52","CCBY","5 May 2025","","","IEEE","IEEE Journals"
"Adaptive Cache Policy Optimization Through Deep Reinforcement Learning in Dynamic Cellular Networks","A. Srinivasan; M. Amidzadeh; J. Zhang; O. Tirkkonen","Department of Information and Communications Engineering, Aalto University, Espoo, Finland; Department of Information and Communications Engineering, Aalto University, Espoo, Finland; Department of Electrical and Computer Engineering, University of California, Davis, CA, USA; Department of Information and Communications Engineering, Aalto University, Espoo, Finland",Intelligent and Converged Networks,"18 Jul 2024","2024","5","2","81","99","We explore the use of caching both at the network edge and within User Equipment (UE) to alleviate traffic load of wireless networks. We develop a joint cache placement and delivery policy that maximizes the Quality of Service (QoS) while simultaneously minimizing backhaul load and UE power consumption, in the presence of an unknown time-variant file popularity. With file requests in a time slot being affected by download success in the previous slot, the caching system becomes a non-stationary Partial Observable Markov Decision Process (POMDP). We solve the problem in a deep reinforcement learning framework based on the Advantageous Actor-Critic (A2C) algorithm, comparing Feed Forward Neural Networks (FFNN) with a Long Short-Term Memory (LSTM) approach specifically designed to exploit the correlation of file popularity distribution across time slots. Simulation results show that using LSTM-based A2C outperforms FFNN-based A2C in terms of sample efficiency and optimality, demonstrating superior performance for the non-stationary POMDP problem. For caching at the UEs, we provide a distributed algorithm that reaches the objectives dictated by the agent controlling the network, with minimum energy consumption at the UEs, and minimum communication overhead.","2708-6240","","10.23919/ICN.2024.0007","Academy of Finland(grant numbers:345109); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10601662","wireless caching;deep reinforcement learning;advantageous actor critic;long short term memory;non-stationary Partial Observable Markov Decision Process (POMDP)","Energy consumption;Power demand;Costs;Heuristic algorithms;Simulation;Markov decision processes;Quality of service","","1","","35","","18 Jul 2024","","","TUP","TUP Journals"
"Intelligent Autoscaling of Microservices in the Cloud for Real-Time Applications","A. A. Khaleq; I. Ra","Department of Computer Science and Engineering, University of Colorado at Denver, Denver, CO, USA; Department of Computer Science and Engineering, University of Colorado at Denver, Denver, CO, USA",IEEE Access,"31 Mar 2021","2021","9","","35464","35476","Cloud applications are becoming more containerized in nature. Developing a cloud application based on a microservice architecture imposes different challenges including scalability at the container level. What adds to the challenge is that cloud applications impose quality of service (QoS) requirements and have various resource demands requiring a customized scaling approach. For example, real-time applications require near real time response time as a QoS. Existing autoscaling technologies such as Kubernetes offer some customization to a set of threshold values for autoscaling. The challenge is identifying the right values for the different autoscaling parameters that will guarantee QoS in a changing dynamic environment. Advancements in machine learning and reinforcement learning (RL) provides a means for autoscaling in cloud applications with no domain knowledge. In this article, we introduce an intelligent autonomous autoscaling system for microservices autoscaling in the cloud with QoS constraints. The system consists of two modules. The first module identifies the microservice resource demand via a generic autoscaling algorithm deployed on the Google Kubernetes Engine (GKE). Our algorithm adapts the Kubernetes autoscaling paradigm based on the application resource requirements. The second module uses reinforcement learning agents to learn and identify the autoscaling threshold values based on the resource demand and QoS. Experimental results show an enhancement in the microservice response time up to 20% compared to the default autoscaling paradigm. In addition, the RL agents can identify the autoscaling threshold values while maintaining a response time below the QoS constraint. Our proposed work provides a customized autoscaling solution for microservices in cloud applications while adhering to QoS constraints with minimum user interaction.","2169-3536","","10.1109/ACCESS.2021.3061890","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9361549","Autonomous autoscaling;Kubernetes;microservices autoscaling;real-time cloud applications;reinforcement learning","Measurement;Quality of service;Time factors;Real-time systems;Cloud computing;Machine learning algorithms;Containers","","70","","29","CCBYNCND","24 Feb 2021","","","IEEE","IEEE Journals"
"MAPE-K Interfaces for Formal Modeling of Real-Time Self-Adaptive Multi-Agent Systems","A. Qasim; S. A. R. Kazmi","Department of Computer Science, Government College University, Lahore, Pakistan; Department of Computer Science, Government College University, Lahore, Pakistan",IEEE Access,"28 Sep 2016","2016","4","","4946","4958","Formal modeling of multi-agent systems is an active area of research. The use of precise and unambiguous notation of formal methods is used to accurately describe and reason about the system under consideration at the design time. Multi-agent systems deployed in dynamic and unpredictable environment needs to have the ability of self-adaptation, making them adaptable to the failures. State of the art encourages the use of MAPE-K feedback loop for the provision of self-adaptation in any system. There is a dire need of formal vocabulary that can be used for the conceptual design of any real-time multi-agent system with self-adaptation. In this paper, we have proposed a set of predefined interfaces for the provision of self-adaptation in real-time multi-agent systems. The interfaces are based on monitor, analyze, plan, and execute phases of the MAPE-K feedback loop. We formally specify our interfaces using timed-communicating object-Z language. The complete framework is elaborated using a trivial case-study of conveyor belt system based on a real-time agent architecture.","2169-3536","","10.1109/ACCESS.2016.2592381","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7529096","Formal methods;self-adaptation;autonomic computing;multi-agent systems;real-time systems","Multi-agent systems;Real-time systems;Feedback;Monitoring;Autonomic computing;Self-organizing networks","","14","","31","OAPA","2 Aug 2016","","","IEEE","IEEE Journals"
"A Survey on Applications of Deep Learning in Cloud Radio Access Network","R. T. Rodoshi; W. Choi","Department of Computer Engineering, Chosun University, Gwangju, South Korea; Department of Computer Engineering, Chosun University, Gwangju, South Korea",IEEE Access,"28 Apr 2021","2021","9","","61972","61997","The necessity for high-speed and low-latency connectivity of the vast number of mobile users is rising with the immense usage of mobile applications. A cloud radio access network (C-RAN) is a promising framework for next-generation cellular communication, which can satisfy the requirements of significantly increasing data traffic and user demands. In C-RAN, the data processing unit can be centralized and virtualized in data centers and can be shared among distributed base stations. Deep learning (DL) appears to be a feasible approach for facilitating the data processing capability, resource management in the cloud, and predicting dynamic traffic in cellular communication. The convergence of C-RAN and DL is expected to bring new prospects to both interdisciplinary research and industrial applications. In this regard, different approaches have been proposed for DL-based C-RAN in the literature. This article provides a comprehensive survey of the state-of-the-art DL techniques applied in C-RAN. A brief introduction of the C-RAN architecture and DL techniques is given to provide insights into these two emerging technologies. Existing surveys are also discussed to highlight the research gap. The reviewed works are categorized into power consumption optimization, network performance maximization, and QoS maximization based on their optimization objectives. The key ideas of DL applied in the reviewed schemes are also mentioned, and the performance evaluation techniques used in the research are discussed and compared. Lastly, research challenges and open research issues are highlighted to provide future research directions.","2169-3536","","10.1109/ACCESS.2021.3074180","Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education(grant numbers:NRF-2019R1F1A1046687); research fund from Chosun University(grant numbers:2020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9408568","Cloud radio access network;deep learning;evaluation techniques;optimization objectives;performance metrics","Computer architecture;Base stations;Optimization;Cellular networks;Baseband;Virtualization;Poles and towers","","7","","121","CCBY","20 Apr 2021","","","IEEE","IEEE Journals"
"Designing Intelligent Agents in Normative Systems Toward Data Regulation Representation","P. H. Alves; F. Correia; I. Frajhof; C. S. De Souza; H. Lopes","Department of Informatics, Pontifical Catholic University of Rio de Janeiro (PUC-Rio), Rio de Janeiro, Brazil; Department of Informatics, Pontifical Catholic University of Rio de Janeiro (PUC-Rio), Rio de Janeiro, Brazil; Law Department, Pontifical Catholic University of Rio de Janeiro (PUC-Rio), Rio de Janeiro, Brazil; Department of Informatics, Pontifical Catholic University of Rio de Janeiro (PUC-Rio), Rio de Janeiro, Brazil; Department of Informatics, Pontifical Catholic University of Rio de Janeiro (PUC-Rio), Rio de Janeiro, Brazil",IEEE Access,"2 Jun 2023","2023","11","","51590","51605","Personal data protection regulation plays an important role in defining the rights and obligations of the agents involved in processing personal data (i.e., data subjects, controllers, and processors). These agents are allowed to execute actions to achieve their goals by obeying the personal data protection rules; however, this exercise may spawn data flow information asymmetry; for instance, a company may have more information regarding how that data is being used than individuals. This asymmetry can undermine individuals’ ability to protect their rights and interests and lead to a lack of trust in organizations and government bodies responsible for protecting their data. In this context, this article proposes: (i) a consent metamodel based on the literature to aid agents in identifying their major concerns when sharing personal data; (ii) a structure to build use case scenarios in the personal data regulation context; (iii) an intelligent normative multiagent system architecture to represent the personal data regulation rights and obligations, as well as the agent’s decision-making process. The latter will consider the normative rewards and punishments in the aforementioned scenario structure; (iv) a use case in the open banking scenario. This article demonstrates how we propose to contribute to representing agents’ preferences and data regulation concerns. We do so with a normative multiagent system and designing agents with cognitive reasoning capabilities.","2169-3536","","10.1109/ACCESS.2023.3276294","National Council for Scientific and Technological Development (CNPq), Brazil; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10124204","BDI architecture;data regulation;multiagent system;norms;personal data","Regulation;Data protection;Open banking;Law;Decision making;Companies;Privacy;Multi-agent systems","","2","","56","CCBY","15 May 2023","","","IEEE","IEEE Journals"
"A heuristic algorithm for designing near-optimal mobile agent itineraries","D. Gavalas","Department of Cultural Technology and Communication, University of the Aegean, Mytilene, Greece",Journal of Communications and Networks,"20 Dec 2012","2006","8","1","123","131","Several distributed architectures, incorporating mobile agent technology, have been recently proposed to answer the scalability limitations of their centralized counterparts. However, these architectures fail to address scalability problems, when distributed tasks requiring the employment of itinerant agents is considered. This is because they lack mechanisms that guarantee optimization of agents' itineraries so as to minimize the total migration cost in terms of the round-trip latency and the incurred traffic. This is of particular importance when MAs itineraries span multiple subnets. The work presented herein aspires to address these issues. To that end, we have designed and implemented an algorithm that adapts methods usually applied for addressing network design problems in the specific area of mobile agent itinerary planning. The algorithm not only suggests the optimal number of mobile agents that minimize the overall cost but also constructs optimal itineraries for each of them. The algorithm implementation has been integrated into our mobile agent framework research prototype and tested in real network environments, demonstrating significant cost savings.","1976-5541","","10.1109/JCN.2006.6182912","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6182912","Heuristic;itinerary planning;mobile agents;network monitoring;optimization;performance evaluation","Hip;Planning;Algorithm design and analysis;Heuristic algorithms;Monitoring;Joining processes;Partitioning algorithms","","4","","28","","20 Dec 2012","","","KICS","KICS Journals"
"Predictive Agent-Based Crowd Model Design Using Decentralized Control Systems","C. Berceanu; I. Banu; B. S. Husebo; M. Patrascu","Complex Systems Laboratory, University Politehnica of Bucharest, Bucureşti, Romania; Complex Systems Laboratory, University Politehnica of Bucharest, Bucureşti, Romania; Centre for Elderly and Nursing Home Medicine, University of Bergen, Bergen, Norway; Complex Systems Laboratory, University Politehnica of Bucharest, Bucureşti, Romania",IEEE Systems Journal,"23 Feb 2023","2023","17","1","1383","1394","As a complex system, crowd dynamics emerge bottom-up from the local interactions between pedestrians as component subsystems. This article proposes a predictive agent-based crowd simulation model to analyze the outcomes of emergency evacuation scenarios taking into account collisions between pedestrians, smoke, fire sprinklers, and exit indicators. The crowd model is based on a decentralized control system structure, where each pedestrian agent is governed through a deliberative-reactive control architecture. The simulation model for evacuation includes a routing-based control system for dynamic-guided evacuation. A design case illustrates the modeling process. Results show that the crowd simulation model based on agent autonomy and local interactions is able to generate higher level crowd dynamics through emergence.","1937-9234","","10.1109/JSYST.2022.3188339","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9837827","Agent-based modeling;complex systems;decentralized control;emergence;human behavior modeling;intelligent agents;simulation model","Behavioral sciences;Computational modeling;Buildings;Predictive models;Complex systems;Sensors;Safety","","13","","62","CCBY","22 Jul 2022","","","IEEE","IEEE Journals"
"Cooperative Multi-Agent Deep Reinforcement Learning for Dynamic Task Execution and Resource Allocation in Vehicular Edge Computing","R. Rauch; Z. Becvar; P. Mach; J. Gazda","Department of Computers and Informatics, Technical University of Kosice, Kosice, Slovakia; Deparment of Telecommunication Engineering, Faculty of Electrical Engineering, Czech Technical University in Prague, Praha, Czech Republic; Deparment of Telecommunication Engineering, Faculty of Electrical Engineering, Czech Technical University in Prague, Praha, Czech Republic; Department of Computers and Informatics, Technical University of Kosice, Kosice, Slovakia",IEEE Transactions on Vehicular Technology,"17 Apr 2025","2025","74","4","5741","5756","Computer vision plays a crucial role in enabling connected autonomous vehicles (CAVs) to observe and comprehend their surroundings. The computer vision tasks are typically based on convolutional neural networks (CNNs). However, CNNs often require significant processing power. Techniques like early exiting and split computing enhance CNN task execution latency and adaptability to varying environmental conditions. Since the split computing introduces additional overhead for offloading of the task from the CAV to an edge servers, we incorporate multiple autoencoders within each split point to enhance the adaptability of splitting under varying environmental conditions. However, the autoencoders introduce an additional layer of complexity related to the selection of the optimal compression strategy alongside the splitting and exiting decisions. To tackle this challenge, we introduce a novel approach based on the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm. This algorithm dynamically and jointly determines the most suitable exit point, split point, and autoencoder. Furthermore, the MADDPG-based approach considers other CAVs when selecting action, promoting cooperation among CAVs. Our results demonstrate that the proposed approach reduces latency up to 44.4% while maintaining at least comparable or even higher accuracy of the computed vision outcome compared to the state-of-the-art solutions.","1939-9359","","10.1109/TVT.2024.3520637","Slovak Research and Development Agency Project(grant numbers:APVV SK-CZ-RD-21-0028,APVV-23-0512); Slovak Academy of Sciences Project(grant numbers:VEGA 1/0685/23); Ministry of Education, Youth and Sports, Czech Republic(grant numbers:LUASK22064); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10810664","Autonomous mobility;computer vision;cooperative multi-agent;deep learning;dynamic task execution","Servers;Autoencoders;Computer vision;Accuracy;Computational modeling;Autonomous vehicles;Sensors;Edge computing;Complexity theory;Wireless communication","","5","","68","CCBY","20 Dec 2024","","","IEEE","IEEE Journals"
"Implementing Agentic AI Into ERP Software","S. Sarferaz","Research and Development, SAP SE, Walldorf, Germany",IEEE Access,"21 Oct 2025","2025","13","","178945","178960","Enterprise Resource Planning (ERP) systems serve as the backbone of modern business operations, digitalizing and integrating processes across organizational departments. These systems encompass a wide array of functions, including sales, marketing, finance, supply chain management, manufacturing, services, procurement, and human resources, acting as a centralized repository of organizational data and processes. The sheer scale and complexity of ERP solutions, which typically manage tens of thousands of business processes and store data in thousands of tables, present a significant opportunity for the integration of agentic artificial intelligence (AI). However, the implementation of agentic AI within ERP systems poses considerable challenges due to the intricate nature of these platforms. ERP solutions often comprise hundreds of millions of lines of code and are designed to accommodate a variety of industry-specific and regional requirements. This complexity necessitates a systematic approach to the development and integration of agentic AI capabilities. This paper addresses the critical research question: How can agentic AI business applications be systematically developed within ERP systems? To answer this, we employ a multi-faceted methodology encompassing the extraction of business requirements from real-world use cases, the design and development of a framework for agentic AI implementation, the evaluation of the proposed framework using actual ERP scenarios. Our research aims to bridge the gap between theoretical AI concepts and practical ERP implementation, providing a structured approach for organizations to leverage agentic AI within their existing ERP infrastructure. By doing so, we seek to enhance the capabilities of ERP systems, enabling more intelligent, adaptive, and efficient business processes across various industries and geographical regions.","2169-3536","","10.1109/ACCESS.2025.3621887","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11204015","Enterprise resource planning;ERP;artificial intelligence;AI;agentic AI;AI agents;enterprise AI;business AI;business applications;software integration;AI development","Artificial intelligence;Business;Programming;Computer architecture;Systematics;Systematic literature review;Libraries;Enterprise resource planning;Complexity theory;Scalability","","","","34","CCBYNCND","15 Oct 2025","","","IEEE","IEEE Journals"
"ISSF: An Intelligent Security Service Framework for Cloud-Native Operations","Y. Yan; K. Huang; M. Siegel","School of Information, Renmin University of China, Beijing, China; School of Information, Renmin University of China, Beijing, China; Cybersecurity at MIT Sloan, MIT, Cambridge, Massachusetts, USA",Journal of Web Engineering,"4 Aug 2025","2025","24","4","655","686","The growing system complexity of microservice architectures and the bilateral enhancement of artificial intelligence (AI) for both attackers and defenders present increasing security challenges for cloud-native operations. In particular, cloud-native operators require a holistic view of the dynamic security posture for the microservice-based cloud-native environment from a defense aspect. Additionally, both attackers and defenders can adopt advanced AI technologies. This makes the dynamic interaction and benchmark among different intelligent offense and defense strategies more crucial. Hence, following the multi-agent deep reinforcement learning (RL) paradigm, this research develops an agent-based intelligent security service framework (ISSF) for cloud-native operations. It includes a dynamic attack graph model to represent the cloud-native environment and an action model to represent offense and defense actions. Then we develop an approach to enable the training, publishing, and evaluating of intelligent security services using diverse deep RL algorithms and training strategies, facilitating their systematic development and benchmarking. The experiments demonstrate that our framework can sufficiently model the security posture of a cloudnative system for defenders, effectively develop and quantitatively benchmark different intelligent security services for both attackers and defenders, and guide further optimization.","1544-5976","","10.13052/jwe1540-9589.2447","National Natural Science Foundation of China(grant numbers:62172425); Fundamental Research Funds for the Central Universities; Research Funds of Renmin University of China(grant numbers:22XNKJ04); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11112807","Cloud-native;dynamic attack graph;intelligent security service model;security service training;publishing and evaluating","Training;Performance evaluation;Systematics;Publishing;Microservice architectures;Benchmark testing;Stability analysis;Security;Artificial intelligence;Optimization","","","","55","","4 Aug 2025","","","River Publishers","River Publishers Journals"
"Intelligent Energy Management Systems for Electrified Vehicles: Current Status, Challenges, and Emerging Trends","R. Ostadian; J. Ramoul; A. Biswas; A. Emadi","McMaster Automotive Resource Centre (MARC), McMaster University, Hamilton, ON, Canada; McMaster Automotive Resource Centre (MARC), McMaster University, Hamilton, ON, Canada; McMaster Automotive Resource Centre (MARC), McMaster University, Hamilton, ON, Canada; McMaster Automotive Resource Centre (MARC), McMaster University, Hamilton, ON, Canada",IEEE Open Journal of Vehicular Technology,"1 Sep 2020","2020","1","","279","295","Powertrain electrification has heightened the need for an energy management strategy, which has been a continuing concern in the development of electrified vehicles. The energy management control unit manages power flow between different energy sources in an electrified powertrain that directly affects vehicle performance. Developing an energy management strategy that is compatible with different real-world driving scenarios has opened a significant field of study for researchers. Recent advances and progress in intelligent control approaches have facilitated developing an intelligent energy management strategy. However, there are inadequate numbers of studies on the latest energy management strategies. The presented review paper aims to provide the requirements of intelligent energy management strategies as well as a new categorization of them into principle-based, data-driven, and composite methods. Besides, enabling technologies for implementing an energy management system with a comparison of different controller chips are described to give readers an experimental view. Future trends and existing challenges are presented, which generate fresh insight into energy management strategies.","2644-1330","","10.1109/OJVT.2020.3018146","Natural Sciences and Engineering Research Council of Canada (NSERC), NSERC Industrial Research Chair in Electrified Powertrains; Canada Research Chair in Transportation Electrification and Smart Mobility; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9172102","Data-driven methods;electric vehicles;intelligent energy management strategy;reinforcement learning;powertrain architecture","Computer architecture;Energy management;Batteries;Hybrid electric vehicles;Mechanical power transmission;Ice;Real-time systems","","47","","123","CCBY","20 Aug 2020","","","IEEE","IEEE Journals"
"Advances and Challenges in Deep Learning for Automated Welding Defect Detection: A Technical Survey","A. Mohammed; M. Hussain","Department of Computer Science, University of Huddersfield, Huddersfield, U.K.; Department of Computer Science, University of Huddersfield, Huddersfield, U.K.",IEEE Access,"3 Jun 2025","2025","13","","94553","94569","Automated welding defect detection has emerged as a pivotal aspect of quality assurance in high-stakes industries such as aerospace, oil and gas, and construction. This paper presents a comprehensive review of state-of-the-art Deep Learning (DL) models tailored for welding defect detection, segmentation, and classification, emphasizing technical advancements and persistent challenges. A critical analysis of single-stage and two-stage architectures is conducted to evaluate their ability to address issues like small defect sizes, low image contrast, and diverse defect geometries. The study also highlights the integration of advanced preprocessing techniques, such as noise reduction and contrast enhancement, within DL workflows to improve feature extraction and detection accuracy. Persistent challenges, such as the scarcity of large, labeled datasets, lack of real-time applicability, and limited model interpretability, are explored in depth. To address these gaps, the survey proposes future directions, including the use of self-supervised learning, domain adaptation, Generative Adversarial Networks (GANs), and explainable AI techniques to enhance the robustness, scalability, and transparency of welding defect detection systems. By synthesizing insights from more than a decade of research, this paper provides a detailed roadmap for advancing automated welding inspection technologies, enabling reliable deployment in real-world industrial environments.","2169-3536","","10.1109/ACCESS.2025.3574083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11016031","Artificial intelligence (AI);computer vision;deep learning;radiographic images;image classification;image segmentation;automated welding defect detection;image enhancement","Welding;Defect detection;Radiography;Surveys;Image enhancement;Filtering;Wiener filters;Inspection;Image edge detection;Accuracy","","5","","95","CCBY","27 May 2025","","","IEEE","IEEE Journals"
"A Deep Reinforcement Learning Approach to Proactive Content Pushing and Recommendation for Mobile Users","D. Liu; C. Yang","School of Electronics and Information Engineering, Beihang University (BUAA), Beijing, China; School of Electronics and Information Engineering, Beihang University (BUAA), Beijing, China",IEEE Access,"12 Jul 2019","2019","7","","83120","83136","The gain from proactive caching at mobile devices highly relies on the accurate prediction of user demands and mobility, which, however, is hard to achieve due to the random user behavior. In this paper, we leverage personalized content recommendation to reduce the uncertainty of user demands in sending requests. We formulate a joint content pushing and recommendation problem that maximizes the net profit of a mobile network operator. To cope with the challenges in modeling and learning user behavior, we establish a reinforcement learning (RL) framework to resolve the problem. To circumvent the curse of dimensionality of reinforcement learning for the joint problem, that is, with very large action and state spaces, we decompose the original problem into two RL problems, where two agents with different goals operate together, and we limit the number of possible actions in each state of the pushing agent by harnessing the well-learned recommendation policy. To enable the generalization of action values from experienced states to the unexperienced states with function approximation, we find a proper way to represent the state and action of the pushing agent. Then, we resort to double deep-Q network with dueling architecture to solve the two problems. The simulation results show that the learned recommendation and pushing policies are able to converge and can increase the net profit significantly compared with baseline policies.","2169-3536","","10.1109/ACCESS.2019.2925019","MOE-CMCC Science Foundation of China(grant numbers:1-4 MCM2017); National Natural Science Foundation of China(grant numbers:61731002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8746132","Wireless edge caching;content recommendation;pushing;deep reinforcement learning","Reinforcement learning;Servers;Mobile handsets;Uncertainty;Wireless communication;Simulation;Probability distribution","","36","","42","CCBY","26 Jun 2019","","","IEEE","IEEE Journals"
"DQRA: Deep Quantum Routing Agent for Entanglement Routing in Quantum Networks","L. Le; T. N. Nguyen","College of Computing and Software Engineering, Kennesaw State University, Marietta, GA, USA; College of Computing and Software Engineering, Kennesaw State University, Marietta, GA, USA",IEEE Transactions on Quantum Engineering,"8 Mar 2022","2022","3","","1","12","Quantum routing plays a key role in the development of the next-generation network system. In particular, an entangled routing path can be constructed with the help of quantum entanglement and swapping among particles (e.g., photons) associated with nodes in the network. From another side of computing, machine learning has achieved numerous breakthrough successes in various application domains, including networking. Despite its advantages and capabilities, machine learning is not as much utilized in quantum networking as in other areas. To bridge this gap, in this article, we propose a novel quantum routing model for quantum networks that employs machine learning architectures to construct the routing path for the maximum number of demands (source–destination pairs) within a time window. Specifically, we present a deep reinforcement routing scheme that is called Deep Quantum Routing Agent (DQRA). In short, DQRA utilizes an empirically designed deep neural network that observes the current network states to accommodate the network’s demands, which are then connected by a qubit-preserved shortest path algorithm. The training process of DQRA is guided by a reward function that aims toward maximizing the number of accommodated requests in each routing window. Our experiment study shows that, on average, DQRA is able to maintain a rate of successfully routed requests at above 80% in a qubit-limited grid network and approximately 60% in extreme conditions, i.e., each node can be repeater exactly once in a window. Furthermore, we show that the model complexity and the computational time of DQRA are polynomial in terms of the sizes of the quantum networks.","2689-1808","","10.1109/TQE.2022.3148667","National Science Foundation(grant numbers:CNS-2103405); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9706320","Deep learning;deep reinforcement learning (DRL);machine learning;next-generation network;quantum network routing;quantum networks","Routing;Qubit;Quantum entanglement;Repeaters;Quantum networks;Teleportation;Neural networks","","34","","37","CCBY","7 Feb 2022","","","IEEE","IEEE Journals"
"Neuromorphic Digital-Twin-Based Controller for Indoor Multi-UAV Systems Deployment","R. Ahmadvand; S. S. Sharif; Y. M. Banad","School of Electrical and Computer Engineering, University of Oklahoma, Norman, OK, USA; School of Electrical and Computer Engineering, University of Oklahoma, Norman, OK, USA; School of Electrical and Computer Engineering, University of Oklahoma, Norman, OK, USA",IEEE Journal of Indoor and Seamless Positioning and Navigation,"29 May 2025","2025","3","","165","174","This study introduces a novel distributed cloud-edge framework for autonomous multi-unmanned aerial vehicle (UAV) systems that combines the computational efficiency of neuromorphic computing with nature-inspired control strategies. The proposed architecture equips each UAV with an individual spiking neural network (SNN) that learns to reproduce optimal control signals generated by a cloud-based controller, enabling robust operation even during communication interruptions. By integrating spike coding with nature-inspired control principles inspired by tilapia fish territorial behavior, our system achieves sophisticated formation control and obstacle avoidance in complex urban environments. The distributed architecture leverages cloud computing for complex calculations while maintaining local autonomy through edge-based SNNs, significantly reducing energy consumption and computational overhead compared to traditional centralized approaches. Our framework addresses critical limitations of conventional methods, including the dependence on premodeled environments, computational intensity of traditional methods, and local minima issues in potential field approaches. Simulation results demonstrate the system's effectiveness across two different scenarios: first, the indoor deployment of a multi-UAV system made up of 15 UAVs, and second, the collision-free formation control of a moving UAV flock, including six UAVs considering the obstacle avoidance. Due to the sparsity of spiking patterns, and the event-based nature of SNNs on average for the whole group of UAVs, the framework achieves almost 90% reduction in computational burden compared to traditional von Neumann architectures implementing traditional artificial neural networks.","2832-7322","","10.1109/JISPIN.2025.3567374","NASA Oklahoma EPSCoR Initialization(grant numbers:80NSSCM0029); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10989580","Cloud-edge computing;distributed control;formation control;multi-UAV systems;nature-inspired control;spiking neural networks (SNNs)","Computer architecture;Neurons;Cloud computing;Autonomous aerial vehicles;Formation control;Neuromorphic engineering;Navigation;Decentralized control;Computational efficiency;Collision avoidance","","2","","36","CCBY","6 May 2025","","","IEEE","IEEE Journals"
"Computer-Aided Layout Generation for Building Design: A Review","J. Liu; Y. Xue; H. Ni; R. Yu; Z. Zhou; S. X. Huang","The Pennsylvania State University, University Park, PA, USA; The Ohio State University, Columbus, OH, USA; University of Memphis, Memphis, TN, USA; University of Louisville, Louisville, KY, USA; Manycore Tech Inc., Hangzhou, China; The Pennsylvania State University, University Park, PA, USA",Computational Visual Media,"29 Sep 2025","2025","11","4","677","707","Generating realistic building layouts for automatic building design has been studied in both computer vision and architectural domains. Traditional approaches in the latter, which are based on optimization techniques or heuristic design guidelines, can synthesize desirable layouts, but usually require post-processing and involve human interaction in the design pipeline, making them costly and time-consuming. The advent of deep generative models has significantly improved the fidelity and diversity of the generated architecture layouts, reducing the workload of designers and making the process much more efficient. This paper presents a comprehensive review of three major research topics in architectural layout design and generation: floorplan layout generation, scene layout synthesis, and generation of various other formats of building layouts. For each topic, we overview the leading paradigms, categorized either by research domains (architecture or machine learning) or by user input conditions or constraints. We then introduce commonly-adopted benchmark datasets used to verify the effectiveness of the methods, as well as corresponding evaluation metrics. Finally, we identify the well-solved problems and limitations of existing approaches, and then propose promising directions for future research. This survey has an associated project which aims to maintain the resources, at https://github.com/jcliu0428/awesome-building-layout-generation.","2096-0662","","10.26599/CVM.2025.9450484","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11119146","computer-aided design;building layout;machine learning;deep generative models","Layout;Buildings;Computational modeling;Reviews;Training;Surveys;Generators;Generative adversarial networks;Diffusion models;Data models","","","","175","","6 Aug 2025","","","TUP","TUP Journals"
"UnifiedKP: A Unified Network Knowledge Plane for Large Model-Enabled 6G Networks","T. Wu; C. Wei; L. Xia","Zhengzhou Railway Vocational and Technical College, Zhengzhou, China; Zhengzhou Railway Vocational and Technical College, Zhengzhou, China; Zhengzhou Railway Vocational and Technical College, Zhengzhou, China",IEEE Access,"6 Oct 2025","2025","13","","170441","170453","The emergence of large language models (LLMs) and agentic systems is revolutionizing the landscape of 6G networks by enabling unprecedented levels of autonomous intelligence, including self-configuration, self-optimization, and self-healing capabilities. However, current implementations face significant challenges. Individual intelligence tasks require isolated knowledge retrieval pipelines. This isolation results in redundant data flows, inconsistent interpretations, and increased operational complexity. Inspired by the service model unification efforts in Open-RAN that promote interoperability and vendor diversity, we propose UnifiedKP: a unified Network Knowledge Plane specifically designed for large model-enabled autonomous 6G network intelligence. By decoupling network knowledge acquisition and management from intelligence logic, UnifiedKP streamlines development workflows and significantly reduces maintenance complexity for intelligence engineers. Through an intuitive and consistent knowledge interface, UnifiedKP enhances interoperability for network intelligence agents while maintaining semantic consistency across diverse intelligence tasks. We demonstrate the effectiveness of UnifiedKP through two representative intelligence applications: live network knowledge question-answering and edge AI service orchestration. Experimental results show that UnifiedKP reduces knowledge retrieval latency by 47%, improves knowledge consistency by 82%, and decreases development complexity by 65% compared to traditional isolated approaches. Our framework achieves 94.3% accuracy in network anomaly detection and reduces service orchestration time by 38% in dynamic edge computing environments. These findings establish UnifiedKP as a foundational architecture for realizing truly autonomous and intelligent 6G networks.","2169-3536","","10.1109/ACCESS.2025.3610890","Henan Provincial Science and Technology Research Project, China(grant numbers:242102210206); Research project of Zhengzhou Railway Vocational and Technical College, China(grant numbers:2024KY004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11168264","6G networks;large language models;network knowledge plane;autonomous networks;edge AI","Knowledge engineering;6G mobile communication;Accuracy;Semantics;Computer architecture;Complexity theory;Logic;Edge AI;Cognition;Pipelines","","","","34","CCBY","17 Sep 2025","","","IEEE","IEEE Journals"
"Closed-Loop Deep Brain Stimulation With Reinforcement Learning and Neural Simulation","C. -H. Cho; P. -J. Huang; M. -C. Chen; C. -W. Lin","Department of Biomedical Engineering, National Taiwan University, Taipei, Taiwan; Graduate Degree Program of Artificial Intelligence, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Department of Biomedical Engineering, National Taiwan University, Taipei, Taiwan; Department of Biomedical Engineering, National Taiwan University, Taipei, Taiwan",IEEE Transactions on Neural Systems and Rehabilitation Engineering,"27 Sep 2024","2024","32","","3615","3624","Deep Brain Stimulation (DBS) is effective for movement disorders, particularly Parkinson’s disease (PD). However, a closed-loop DBS system using reinforcement learning (RL) for automatic parameter tuning, offering enhanced energy efficiency and the effect of thalamus restoration, is yet to be developed for clinical and commercial applications. In this research, we instantiate a basal ganglia-thalamic (BGT) model and design it as an interactive environment suitable for RL models. Four finely tuned RL agents based on different frameworks, namely Soft Actor-Critic (SAC), Twin Delayed Deep Deterministic Policy Gradient (TD3), Proximal Policy Optimization (PPO), and Advantage Actor-Critic (A2C), are established for further comparison. Within the implemented RL architectures, the optimized TD3 demonstrates a significant 67% reduction in average power dissipation when compared to the open-loop system while preserving the normal response of the simulated BGT circuitry. As a result, our method mitigates thalamic error responses under pathological conditions and prevents overstimulation. In summary, this study introduces a novel approach to implementing an adaptive parameter-tuning closed-loop DBS system. Leveraging the advantages of TD3, our proposed approach holds significant promise for advancing the integration of RL applications into DBS systems, ultimately optimizing therapeutic effects in future clinical trials.","1558-0210","","10.1109/TNSRE.2024.3465243","Minister of Science and Technology Council, Taiwan(grant numbers:MOST 111-2221-E-002-079-MY3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10684783","Basal ganglia-thalamic (BGT) network;closed-loop deep brain stimulation (cl-DBS);Parkinson’s disease (PD);reinforcement learning (RL)","Neurons;Brain modeling;Pathology;Deep brain stimulation;Biological system modeling;Reinforcement learning;Mathematical models","Deep Brain Stimulation;Humans;Thalamus;Reinforcement, Psychology;Basal Ganglia;Computer Simulation;Algorithms;Parkinson Disease;Models, Neurological;Neural Networks, Computer","6","","39","CCBY","20 Sep 2024","","","IEEE","IEEE Journals"
"MMTraP: Multi-Sensor Multi-Agent Trajectory Prediction in BEV","S. Sharma; A. Das; G. Sistu; M. Halton; C. Eising","Department Electronic and Computer Engineering, University of Limerick, Limerick, Ireland; Department Electronic and Computer Engineering, University of Limerick, Limerick, Ireland; Department Electronic and Computer Engineering, University of Limerick, Limerick, Ireland; Department Electronic and Computer Engineering, University of Limerick, Limerick, Ireland; Department Electronic and Computer Engineering, University of Limerick, Limerick, Ireland",IEEE Open Journal of Vehicular Technology,"23 Jun 2025","2025","6","","1551","1567","Accurate detection and trajectory prediction of moving vehicles are essential for motion planning in autonomous driving systems. While traffic regulations provide clear boundaries, real-world scenarios remain unpredictable due to the complex interactions between vehicles. This challenge has driven significant interest in learning-based approaches for trajectory prediction. We present MMTraP: Multi-Sensor and Multi-Agent Trajectory Prediction in BEV. This method integrates camera, LiDAR, and radar data to create detailed Bird's-Eye-View representations of driving scenes. Our approach employs a hierarchical vector transformer architecture that first detects and classifies vehicle motion patterns before predicting future trajectories through spatiotemporal relationship modeling. This work specifically focuses on vehicle interactions and environmental constraints. Despite its significance, multi-agent trajectory prediction and moving object segmentation are still underexplored in the literature, especially in real-time applications. Our method leverages multisensor fusion to obtain precise BEV representations and predict vehicle trajectories. Our multi-sensor fusion approach achieves the highest vehicle Intersection over Union (IoU) of 63.23% and an overall mean IoU (mIoU) of 64.63%, demonstrating its effectiveness in utilizing all available sensor modalities. Additionally, we demonstrate vehicle segmentation and trajectory prediction capabilities across various lighting and weather conditions. The proposed approach has been rigorously evaluated using the nuScenes dataset. Results show that our method improves the accuracy of trajectory predictions and outperforms state-of-the-art techniques, particularly in challenging environments such as congested urban areas. For instance, in complex traffic scenarios, our approach achieves a relative improvement of 5% in trajectory prediction accuracy compared to baseline methods. This work advances vehicle-focused prediction systems by integrating multi-sensor BEV representation and interaction-aware transformers. Our approach shows promise in enhancing the reliability and accuracy of trajectory predictions for autonomous driving applications, potentially improving overall safety and efficiency in diverse driving environments.","2644-1330","","10.1109/OJVT.2025.3574385","Science Foundation Ireland(grant numbers:18/CRT/6049); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11016806","Sensor fusion;encoder-decoder transformer;bird's-eye-view;semantic segmentation, multi-agent trajectory prediction","Trajectory;Radar;Autonomous vehicles;Cameras;Laser radar;Accuracy;Sensor fusion;Motion segmentation;Computer vision;Meteorology","","1","","84","CCBY","28 May 2025","","","IEEE","IEEE Journals"
"MP-TD3: Multi-Pool Prioritized Experience Replay-Based Asynchronous Twin Delayed Deep Deterministic Policy Gradient Algorithm","W. Tan; D. Huang","College of Engineering, Huaqiao University, Quanzhou, China; College of Engineering, Huaqiao University, Quanzhou, China",IEEE Access,"5 Aug 2024","2024","12","","105268","105280","The prioritized experience replay mechanisms have achieved remarkable success in accelerating the convergence of reinforcement learning algorithms. However, applying traditional prioritized experience replay mechanisms directly to asynchronous reinforcement learning leads to slow convergence, due to the difficulty for an agent to utilize excellent experiences obtained by other agents interacting with the environment. To address the above issue, we propose a Multi-pool Prioritized experience replay-based asynchronous Twin Delayed Deep Deterministic policy gradient algorithm (MP-TD3). Specifically, a multi-pool prioritized experience replay mechanism is proposed to strengthen the experience interactions among different agents to accelerate the network convergence. Then, a global-pool self-cleaning mechanism based on sample diversity and a global-pool self-cleaning mechanism based on TD-errors are designed to overcome the deficiency that the samples suffer from high redundancy and low information content in the global-pool, respectively. Finally, a multi-batch sampling mechanism is investigated to further reduce the training time. Extensive experiments validate that the proposed MP-TD3 significantly improve the convergence speed and performance compared with state-of-the-art methods.","2169-3536","","10.1109/ACCESS.2024.3435949","National Key Research and Development Program of China(grant numbers:2021YFE0205400); National Natural Science Foundation of China(grant numbers:61901183,61976098); Fundamental Research Funds for the Central Universities(grant numbers:ZQN-921); Collaborative Innovation Platform Project of Fujian Province(grant numbers:2021FX03); Natural Science Foundation of Fujian Province(grant numbers:2023J01140); Natural Science Foundation of Fujian Provincial Science and Technology Department(grant numbers:2021H6037); Key Project of Quanzhou Science and Technology Plan(grant numbers:2021C008R,2023C007R); Key Science and Technology Project of Xiamen City(grant numbers:3502Z20231005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10614601","Asynchronous reinforcement learning;twin delayed deep deterministic algorithm;prioritized experience replay;TD-error","Training;Parallel processing;Convergence;Correlation;Network architecture;Training data;Reinforcement learning","","3","","44","CCBYNCND","30 Jul 2024","","","IEEE","IEEE Journals"
"A Neuro-Inspired Control Architecture to Enhance Robot Self-Preservation and Adaptation in Autonomous Navigation Tasks","A. Usai; A. Rizzo","Department of Electronics and Telecommunications, Politecnico di Torino, Torino, Italy; Department of Electronics and Telecommunications, Politecnico di Torino, Torino, Italy",IEEE Robotics and Automation Letters,"14 Jul 2025","2025","10","8","8491","8497","Ensuring survival and self-preservation is essential to design intelligent robots that adapt to dynamic and unfamiliar environments. Inspired by the dual-pathway model from neuroscience, we introduce a control architecture designed to ensure the adaptability of robotic behavior during navigation. This approach parallels the neuroscientific “Low Road” paradigm by incorporating constructs resembling the thalamus, implemented as a nonlinear filter; the amygdala, modeled as a Soft Actor-Critic (SAC) reinforcement learning agent; and the brainstem-cerebellum connection, represented by a Nonlinear Model Predictive Controller (NMPC). Our findings indicate superior adaptiveness, generalizability, and computational efficiency compared to standard NMPCs and Artificial Potential Fields in both static and dynamic environments with obstacles of varying risk levels.","2377-3766","","10.1109/LRA.2025.3583630","Sustainable Mobility National Research Center funded by European Union Next-GenerationEU; Future Artificial Intelligence Research funded by European Union Next-GenerationEU; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11054284","Bioinspired robot learning;neurorobotics;cognitive control architectures","Robots;Brain;Roads;Computer architecture;Vectors;Robot kinematics;Navigation;Computational modeling;Adaptation models;Brain modeling","","","","25","CCBY","27 Jun 2025","","","IEEE","IEEE Journals"
"Designing negotiating agent for automated negotiations","Y. Feng; M. Cao; Y. Lei","School of Management, Harbin Institute of Technology, Harbin 150001, China; School of Management, Harbin Institute of Technology, Harbin 150001, China; School of Management, Harbin Institute of Technology, Harbin 150001, China",Tsinghua Science and Technology,"17 Jan 2012","2005","10","S1","817","823","Traditional research in automated negotiation is focused on negotiation protocol and strategy. This paper studies automated negotiation from a new point of view, proposes a novel concept, namely negotiating agent, and discusses its significance in construction of automated negotiation system, with an abstract model formally described and the architecture designed, which supports both goal-directed reasoning and reactive response. A communication model was proposed to construct interaction mechanism used by negotiating agents, in which the negotiation language used by agents is defined. The communication model and the language are defined in a way general enough to support a wide variety of market mechanisms, thus being particularly suitable for flexible applications such as electronic business. The design and expression of the negotiation ontology is also discussed. On the base of the theoretical model of negotiating agent, negotiating agent architecture and negotiating agent communication model (NACM) are explicit and formal specifications for the agents negotiating in an E-business environment; especially, NACM defines the negotiation language template shared among all agents formally and explicitly. The novelty of the communication model is twofold.","1007-0214","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6075750","automated negotiation;Belief-Desire-Intention model;agent;knowledge query and manipulation language (KQML);foundation for intelligent physical agent (FIPA);agent communication language (ACL);ontology","Protocols;Cognition;Ontologies;Registers;Subscriptions;Generators;Semantics","","","","","","17 Jan 2012","","","TUP","TUP Journals"
"Adaptive Resource Optimized Edge Federated Learning in Real-Time Image Sensing Classifications","P. Tam; S. Math; C. Nam; S. Kim","Department of Software Convergence, Soonchunhyang University, Asan, South Korea; Department of Software Convergence, Soonchunhyang University, Asan, South Korea; Department of Software Convergence, Soonchunhyang University, Asan, South Korea; Department of Software Convergence, Soonchunhyang University, Asan, South Korea",IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,"10 Nov 2021","2021","14","","10929","10940","With the exponential growth of the Internet of things (IoT) in remote sensing image applications, network resource orchestration and data privacy are significant aspects to handle in bigdata cellular networks. The image data sharing procedure toward central cloud servers in order to perform real-time classifications has leaked client personalization and heavily burdened the communication networks. Thus, the deployment of IoT image sensors in privacy-constrained sectors requires an optimized federated learning (FL) scheme to efficiently consider both aspects of securing data privacy and maximizing the model accuracy with sufficient communication and computation resources. In this article, an adaptive model communication scheme with virtual resource optimization for edge FL is proposed by converging a deep q-learning algorithm to enforce a self-learning agent interacting with network functions virtualization orchestrator and software-defined networking based architecture. The agent targets to optimize the resource control policy of virtual multi-access edge computing entities in virtualized infrastructure manager. The proposed scheme trains the learning model and weighs the optimal actions for particular network states by using an epsilon-greedy strategy. In the exploitation phase, the scheme considers multiple spatial-resolution sensing conditions and allocates computation offloading resources for global multiconvolutional neural networks model aggregation based on the congestion states. In the simulation results, the quality of service and global collaborative model performance metrics were evaluated in terms of delay, packet drop ratios, packet delivery ratios, loss values, and overall accuracy.","2151-1535","","10.1109/JSTARS.2021.3120724","Bio and Medical Technology Development Program; National Research Foundation; Korean government(grant numbers:NRF-2019M3E5D1A02069073); Ministry of Science, ICT; National Program for Excellence in SW; Institute of Information & Communications Technology Planning & Evaluation(grant numbers:2021-0-01399); Soonchunhyang University Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9580651","Convolutional neural networks (CNN);deep q-learning (DQL);federated learning (FL);quality of service (QoS);real-time image classifications","Computational modeling;Sensors;Data models;Servers;Real-time systems;Adaptation models;Resource management","","45","","47","CCBY","19 Oct 2021","","","IEEE","IEEE Journals"
"Deep Reinforcement Learning for Intelligent Load Balancing in Smart Power Grids","B. Liu","School of Information Science and Engineering, Yanshan University, Qinhuangdao, China",IEEE Access,"24 Sep 2025","2025","13","","164170","164185","This study addresses the challenge of intelligent load balancing in modern power grids, which are increasingly characterized by renewable energy sources, electric vehicles, and decentralized generation. Traditional control mechanisms, often based on rule-based systems, fail to cope with the dynamic and stochastic nature of these grids. To overcome these limitations, we propose an innovative hierarchical reinforcement learning framework for load balancing, integrating Proximal Policy Optimization (PPO) within a dual-layer control architecture. This framework employs both local agent-based decision-making and a global critic network for system-wide optimization. The approach is designed to adapt to the temporal and spatial variability inherent in modern power grids, ensuring efficient load distribution and stability across various operating conditions. We introduce the Grid-aware Structured Embedding Network (GSEN), a novel model that enhances power grid state estimation by capturing multi-scale topological and temporal dependencies. GSEN integrates spectral graph convolutions and temporal attention mechanisms, providing robust, real-time predictions. The Stability-Aware Adaptive Inference Mechanism (SAIM) enhances the stability and adaptability of the model by dynamically adjusting inference pathways based on real-world grid conditions. Empirical evaluations demonstrate that the proposed framework outperforms traditional methods and state-of-the-art models, showing significant improvements in load balancing efficiency and energy dispatch precision. These findings underline the potential of reinforcement learning-based solutions to meet the growing complexity and demands of smart power grids, providing a scalable and adaptable solution for intelligent grid management.","2169-3536","","10.1109/ACCESS.2025.3606914","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11153398","Proximal policy optimization;hierarchical control;adaptive systems;decentralized decision-making;energy informatics","Load management;Smart grids;Power grids;Load modeling;Real-time systems;Power system dynamics;Adaptation models;Power system stability;Decision making;Optimization","","","","40","CCBY","8 Sep 2025","","","IEEE","IEEE Journals"
"Wireless Access Control in Edge-Aided Disaster Response: A Deep Reinforcement Learning-Based Approach","H. Zhou; X. Wang; M. Umehira; X. Chen; C. Wu; Y. Ji","Graduate School of Science and Engineering, Ibaraki University, Hitachi, Japan; Graduate School of Science and Engineering, Ibaraki University, Hitachi, Japan; Graduate School of Science and Engineering, Ibaraki University, Hitachi, Japan; VTT Technical Research Centre of Finland, Oulu, Finland; Graduate School of Informatics and Engineering, The University of Electro-Communications, Chofu, Japan; Information Systems Architecture Research Division, National Institute of Informatics, Tokyo, Japan",IEEE Access,"29 Mar 2021","2021","9","","46600","46611","The communication infrastructure is most likely to be damaged after a major disaster occurred, which would lead to further chaos in the disaster stricken area. Modern rescue activities heavily rely on the wireless communications, such as safety status report, disrupted area monitoring, evacuation instruction, rescue coordination, etc. Large amount of data generated from victims, sensors and responders must be delivered and processed in a fast and reliable way, even when the normal communication infrastructure is degraded or destroyed. To this end, reconstructing the post-disaster network by deploying MDRU (Movable and Deployable Resource Unit) and relay unit at edge is a very promising solution. However, the optimal wireless access control in this heterogeneous hastily formed network is extremely challenging, due to the frequent varying environment and the lack of statistics information in advance in post-disaster scenarios. In this paper, we propose a learning based wireless access control approach for edge-aided disaster response network. More specifically, we model the wireless access control procedure as a discrete-time single agent Markov decision process, and solve the problem by exploiting deep reinforcement learning technique. By extensive simulation results, we show that the proposed mechanism significantly outperforms the baseline schemes in terms of delay and packet drop rate.","2169-3536","","10.1109/ACCESS.2021.3067662","Japan Society for the Promotion of Science (JSPS) Grant-in-Aid for Scientific Research(C)(grant numbers:20K11764); Telecommunications Advancement Foundation; Research Organization of Information and Systems (ROIS) National Institute of Informatics (NII) Open Collaborative Research(grant numbers:2020-20FA01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9382256","Disaster response network;deep reinforcement learning;wireless access control;network edge","Wireless communication;Access control;Relays;Dynamic scheduling;Ad hoc networks;Reinforcement learning;Resource management","","20","","36","CCBY","22 Mar 2021","","","IEEE","IEEE Journals"
"A deep-Q learning approach to mobile operator collaboration","A. Karapantelakis; E. Fersman","Machine Design department, Royal Institute of Technology, Stockholm, Sweden; Machine Design department, Royal Institute of Technology, Stockholm, Sweden",Journal of Communications and Networks,"12 Jan 2021","2020","22","6","455","466","Next-generation mobile connectivity services include a large number of devices distributed across vast geographical areas. Mobile network operators will need to collaborate to fulfill service requirements at scale. Existing approaches to multi-operator services assume already-established collaborations to fulfill customer service demand with specific quality of service (QoS). In this paper, we propose an agent-based architecture, where establishment of collaboration for a given connectivity service is done proactively, given predictions about future service demand. We build a simulation environment and evaluate our approach with a number of scenarios and in context of a real-world use case, and compare it with existing collaboration approaches. Results show that by learning how to adapt their collaboration strategy, operators can fulfill a greater part of the service requirements than by providing the service independently, or through pre-established, intangible service level agreements.","1976-5541","","10.23919/JCN.2020.000032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9321159","Agent-based architectures;deep reinforcement learning;mobile networks;5G;6G","Collaboration;Quality of service;Service level agreements;5G mobile communication;Throughput;Next generation networking;Mobile handsets","","","","","","12 Jan 2021","","","KICS","KICS Journals"
"Research on Personalized Recommendation Based on Matrix Factorization, Clustering, and Deep Reinforcement Learning","Y. Jiang; J. Zhang; L. Qiao","School of Mathematics and Statistics, Sichuan University of Science and Engineering, Yibin, China; School of Mathematics and Statistics, Sichuan University of Science and Engineering, Yibin, China; School of Mathematics and Statistics, Sichuan University of Science and Engineering, Yibin, China",IEEE Access,"2 Oct 2025","2025","13","","169866","169880","To address the challenges of data sparsity, cold start, and insufficient dynamic adaptability in traditional recommendation systems, this study proposes a personalized recommendation model named CDRL-MF, which integrates Matrix Factorization, multi-view clustering, and Deep Reinforcement Learning. The method achieves performance improvement through a three-stage collaborative optimization process: First, a dual-channel architecture employing Singular Value Decomposition and an Artificial Neural Network generates high-quality user and item embeddings. Second, multi-view K-means clustering is introduced to construct precise user interest clusters by synthesizing user rating patterns, statistical attributes, and content features. Finally, a Cluster-Guided Deep Reinforcement Recommendation framework is designed, where a DDPG-based agent integrates user states, item cluster features, and real-time feedback to achieve continuous dynamic optimization of recommendation policies. Experimental results on the MovieLens 1M dataset demonstrate that the CDRL-MF model significantly outperforms multiple baseline models across key evaluation metrics, including rating prediction (MAE, RMSE) and Top-N recommendation (Precision, Recall, F1, NDCG). Furthermore, the model exhibits excellent balancing capabilities in recommendation diversity, novelty, and user group fairness. By incorporating differential privacy and federated learning mechanisms, it maintains acceptable performance trade-offs while ensuring user privacy protection. Additional experiments on large-scale datasets such as Amazon Reviews and Netflix Prize further validate its robust generalization capability and practicality.","2169-3536","","10.1109/ACCESS.2025.3614675","Opening Project of Sichuan Province University Key Laboratory of Bridge Nondestructive Detection and Engineering Computing(grant numbers:2022QYY06); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11181059","Recommendation system;matrix Factorization;multi-view clustering;deep reinforcement learning;dynamic optimization","Recommender systems;Optimization;Deep reinforcement learning;Computer architecture;Clustering algorithms;Accuracy;Motion pictures;Collaborative filtering;Collaboration;Artificial neural networks","","","","34","CCBY","26 Sep 2025","","","IEEE","IEEE Journals"
"Reinforcement Guided Genetic Algorithm for Application Mapping in Network-on-Chip Architectures: Toward Transparent and Efficient MPSoC Scheduling","A. A. J. Al-Hchaimi; M. A. Al-Shareeda; A. T. Azar; W. El-Shafai","Department of Cybersecurity Techniques Engineering, Thi-Qar Technical College, Southern Technical University, Basra, Iraq; Department of Electronic Technologies, Basra Technical Institute, Southern Technical University, Basra, Iraq; College of Computer and Information Sciences, Prince Sultan University, Riyadh, Saudi Arabia; College of Computer and Information Sciences, Prince Sultan University, Riyadh, Saudi Arabia",IEEE Access,"16 Oct 2025","2025","13","","177520","177536","In this paper, we present a novel hybrid application mapping framework that integrates Genetic Algorithm (GA) with Reinforcement Learning (RL) to optimize task allocation in 2D Network-on-Chip based Multiprocessor System-on-Chip (NoC-based MPSoC) architectures. The goal is to reduce overall communication costs and improve runtime efficiency during the task-to-core mapping process. The RL agent is embedded within the GA loop to dynamically steer selection, crossover, and mutation operations using real-time feedback on mapping quality. Our methodology is evaluated on both real applications (e.g., PIP, MPEG, VOPD) and synthetic TGFF workloads across NoC mesh sizes from  $3\times 3$  to  $12\times 11$ . Experimental results demonstrate that GA+RL consistently outperforms the baseline GA. For instance, in the TGFF-G5 benchmark (80 cores), the GA+RL approach achieved a minimum communication cost of 116.354, compared to 244.645 with original GA, representing over 52% improvement. Across all trials, GA+RL also showed lower standard deviations and earlier convergence generations. To improve interpretability, we incorporate Explainable AI (XAI) techniques using SHapley Additive exPlanations (SHAP) to analyze feature contributions. Results reveal that average communication hops and total bandwidth are key factors influencing mapping efficiency. The GA+RL model demonstrates greater transparency and consistency, aiding design-time decisions. This work has direct implications for industrial platforms, including Kalray MPPA-256 (autonomous vehicles), Intel SCC (cloud/HPC), Adapteva Epiphany (IoT Edges), and Tilera TILE-Gx (Cybersecurity), where efficient and adaptive application mapping is critical. Aligned with UN SDG 2 (Zero Hunger), the framework also supports real-time scheduling in agriculture IoT systems, enabling energy-efficient deployment of smart technologies to enhance food production and sustainability.","2169-3536","","10.1109/ACCESS.2025.3616179","Research, Development, and Innovation Authority (RDIA), Saudi Arabia,(grant numbers:13382-psu-2023-PSNU-R-3-1-EI); Prince Sultan University, Riyadh, Saudi Arabia, through paying the article processing charges of this publication.; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11184724","Network-on-chip;application mapping;genetic algorithm;reinforcement learning;MPSoC;convergence-aware optimization;XAI;SHAP","Optimization;Runtime;Costs;Convergence;Adaptation models;Genetic algorithms;Real-time systems;Computer architecture;Routing;Network-on-chip","","","","58","CCBYNCND","30 Sep 2025","","","IEEE","IEEE Journals"
"Autonomous Drone Swarm Navigation and Multitarget Tracking With Island Policy-Based Optimization Framework","S. Qamar; S. H. Khan; M. A. Arshad; M. Qamar; J. Gwak; A. Khan","Department of Computer and Information Sciences, Pattern Recognition Laboratory (PRLab), Pakistan Institute of Engineering and Applied Sciences, Nilore, Islamabad, Pakistan; Department of Computer and Information Sciences, Pattern Recognition Laboratory (PRLab), Pakistan Institute of Engineering and Applied Sciences, Nilore, Islamabad, Pakistan; Department of Computer and Information Sciences, Pattern Recognition Laboratory (PRLab), Pakistan Institute of Engineering and Applied Sciences, Nilore, Islamabad, Pakistan; Department of Computer Science, University of Azad Jammu and Kashmir Muzaffarabad, Azad Kashmir, Pakistan; Department of Software, Korea National University of Transportation, Chungju, South Korea; Department of Computer and Information Sciences, Pattern Recognition Laboratory (PRLab), Pakistan Institute of Engineering and Applied Sciences, Nilore, Islamabad, Pakistan",IEEE Access,"5 Sep 2022","2022","10","","91073","91091","Swarm intelligence has been applied to replicate numerous natural processes and relatively simple species to achieve excellent performance in a variety of disciplines. An autonomous approach employing deep reinforcement learning is presented in this study for swarm navigation. In this approach, complex 3D environments with static and dynamic obstacles and resistive forces such as linear drag, angular drag, and gravity are modeled to track multiple dynamic targets. In this regard, a novel island policy optimization model is introduced to tackle multiple dynamic targets simultaneously and thus make the swarm more dynamic. Moreover, new reward functions for robust swarm formation and target tracking are devised to learn complex swarm behaviors. Since the number of agents is not fixed and has only the partial observance of the environment, swarm formation and navigation become challenging. In this regard, the proposed strategy consists of four main components to tackle the aforementioned challenges: 1) Island policy-based optimization framework with multiple targets tracking 2) Novel reward functions for multiple dynamic target tracking 3) Improved policy and critic-based framework for the dynamic swarm management 4) Memory. The dynamic swarm management phase translates basic sensory input to high-level commands and thus enhances swarm navigation and decentralized setup while maintaining the swarm’s size fluctuations. While in the island model, the swarm can split into individual sub-swarms according to the number of targets, thus allowing it to track multiple targets that are far apart. Also, when multiple targets come close to each other, these sub-swarms have the ability to rejoin and thus form a single swarm surrounding all the targets. Customized state-of-the-art policy-based deep reinforcement learning neuro-architectures are employed to achieve policy optimization. The results show that the proposed strategy enhances swarm navigation by achieving a high cumulative reward and a low policy loss. The simulations show that the proposed framework can efficiently track multiple static and dynamic targets in complex environments.","2169-3536","","10.1109/ACCESS.2022.3202208","PAIC, PIEAS, IT Endowment under Pakistan Higher Education Commission (HEC) and “Regional Innovation Strategy (RIS)” through the National Research Foundation of Korea (NRF); Ministry of Education (MOE)(grant numbers:2021RIS-001 (1345341783)); Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education(grant numbers:NRF-2020R1I1A3074141); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9868790","Navigation;swarm robotics;deep reinforcement learning;obstacle avoidance;target tracking;multi-agent","Target tracking;Behavioral sciences;Navigation;Drones;Distance measurement;Particle swarm optimization;Optimization;Robots;Multi-agent systems","","21","","62","CCBY","26 Aug 2022","","","IEEE","IEEE Journals"
"Multi-Agent System-Based Event-Triggered Hybrid Control Scheme for Energy Internet","C. Dou; D. Yue; Q. -L. Han; J. M. Guerrero","Institute of Electrical Engineering, Yanshan University, Qinhuangdao, China; Institute of Advanced Technology, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Software and Electrical Engineering, Swinburne University of Technology, Melbourne, Australia; Department of Energy Technology, Aalborg University, Aalborg East, Denmark",IEEE Access,"20 May 2017","2017","5","","3263","3272","This paper is concerned with an event-triggered hybrid control for the energy Internet based on a multi-agent system approach with which renewable energy resources can be fully utilized to meet load demand with high security and well dynamical quality. In the design of control, a multi-agent system framework is first constructed. Then, to describe fully the hybrid behaviors of all distributed energy resources and logical relationships between them, a differential hybrid Petri-net model is established, which is an original work. The most important contributions based on this model propose four types of event-triggered hybrid control strategies whereby the multi-agent system implements the hierarchical hybrid control to achieve multiple control objectives. Finally, the effectiveness of the proposed control is validated by means of simulation results.","2169-3536","","10.1109/ACCESS.2017.2670778","National Natural Science Foundation of China(grant numbers:61573300,61533010); Hebei Provincial Natural Science Foundation of China(grant numbers:E2016203374); Primary Research & Development Plan of Jiangsu Province(grant numbers:BE2016184); Australian Research Council Discovery Project(grant numbers:DP160103567); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7858692","Energy Internet;multi-agent system;hybrid control;event-triggered control;differential hybrid Petri-net","Switches;Internet;Multi-agent systems;Security;Voltage control;Senior members","","32","","16","OAPA","17 Feb 2017","","","IEEE","IEEE Journals"
"E-CNMPC: Edge-Based Centralized Nonlinear Model Predictive Control for Multiagent Robotic Systems","A. S. Seisa; B. Lindqvist; S. G. Satpute; G. Nikolakopoulos","Robotics and AI Team, Department of Computer, Electrical and Space Engineering, Luleå University of Technology, Luleå, Sweden; Robotics and AI Team, Department of Computer, Electrical and Space Engineering, Luleå University of Technology, Luleå, Sweden; Robotics and AI Team, Department of Computer, Electrical and Space Engineering, Luleå University of Technology, Luleå, Sweden; Robotics and AI Team, Department of Computer, Electrical and Space Engineering, Luleå University of Technology, Luleå, Sweden",IEEE Access,"24 Nov 2022","2022","10","","121590","121601","With the wide deployment of autonomous multi-agent robotic systems, control solutions based on centralized algorithms have been developed. Even though these centralized algorithms can optimize the performance of the multi-agent robotic systems, they require a lot of computational effort, and a centralized unit to undertake the entire process. Yet, many robotic platforms like some ground robots and even more, aerial robots, do not have the computing capacity to execute this kind of frameworks on their onboard computers. While cloud computing has been used as a solution for offloading computationally demanding robotic applications, from the robots to the cloud servers, the latency they introduce to the system has made them unsuitable for time sensitive applications. To overcome these challenges, this article promotes an Edge computing-based Centralized Nonlinear Model Predictive Control (E-CNMPC) framework to control, and optimize, in swarm formation, the trajectory of multiple ground robotic agents, while taking under consideration potential collisions. The data processing procedure for the time critical application of controlling the robots in a centralized manner, is offloaded to the edge machine, thus the framework benefits from the provided edge resources, features, and centralized optimal performance, while the latency remains bounded in desired values. Besides, real experiments were conducted as a proof-of-concept of the proposed framework to evaluate the system’s performance and effectiveness.","2169-3536","","10.1109/ACCESS.2022.3223446","European Union’s Horizon 2020 Research and Innovation Program through the Marie Skłodowska-Curie(grant numbers:953454); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9955515","Edge-based centralized nonlinear model predictive control (E-CNMPC);edge computing;Kubernetes;robotics","Robots;Cloud computing;Computer architecture;Behavioral sciences;Task analysis;Edge computing;Collision avoidance","","11","","60","CCBY","18 Nov 2022","","","IEEE","IEEE Journals"
"Dynamic THz Backhaul for 6G Local Area Networks: Architecture, Analysis, Challenges and Future Directions","J. Kokkoniemi; S. Shahabuddin; P. Ghasemzadeh; J. F. O’Hara","Centre for Wireless Communications (CWC), University of Oulu, Oulu, Finland; Oklahoma State University, Stillwater, OK, USA; Oklahoma State University, Stillwater, OK, USA; Oklahoma State University, Stillwater, OK, USA",IEEE Wireless Communications,"","2025","PP","99","1","8","As the communications technology advances towards the era of sixth-generation (6G) communication systems, densification of networks is still one of the promising ways to improve the overall network capacity. Dense networks impose strict requirements and deployment problems for the backhaul infrastructure and its operations. Millimeter wave and low terahertz (THz) bands (30–500 GHz) offer ample capacity to meet any data rate requirements, but are challenging to implement on small-scale devices due to large antenna gain requirements. These are less concerning in a backhaul infrastructure, where devices are more costly and equipped to support such specifications. This article studies the opportunities presented by utilizing THz communications for backhaul operations with tailored architectures for 6G local area networks. Herein, urban microcell and small cell base station networks are investigated. Constraints for backhaul links in these networks are considered from various perspectives including the channel, hardware, physical layer signal processing, and intelligent network management challenges. Even though the THz frequency bands show remarkable potential for dense backhaul operations due to their large capacity, many practical challenges remain that must be addressed for real-world implementation.","1558-0687","","10.1109/MWC.2025.3601676","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11206127","","Backhaul networks;Terahertz communications;6G mobile communication;Wireless communication;Costs;Signal to noise ratio;Millimeter wave communication;Hardware;Antennas;Urban areas","","","","","CCBY","17 Oct 2025","","","IEEE","IEEE Early Access Articles"
"From Warfighting Needs to Robot Actuation: A Complete Rapid Integration Swarming Solution","E. M. Taranta; A. Seiwert; A. Goeckner; K. Nguyen; E. Cherry","Northrop Grumman Corporation, Mission Systems, Orlando, FL 32817; Northrop Grumman Corporation, Mission Systems, Aurora, CO 80017; Northrop Grumman Corporation, Mission Systems, Annapolis, MD 21401; Northrop Grumman Corporation, Mission Systems, Aurora, CO 80017; Northrop Grumman Corporation, Mission Systems, McLean, VA 22102",Field Robotics,"25 Feb 2025","2023","3","","460","515","Swarm robotics systems have the potential to transform warfighting in urban environments but until now have not seen large-scale field testing. We present the Rapid Integration Swarming Ecosystem (rise), a platform for future multi-agent research and deployment. rise enables rapid integration of third-party swarm tactics and behaviors, which was demonstrated using both physical and simulated swarms. Our physical testbed is composed of more than 250 networked heterogeneous agents and has been extensively tested in mock warfare scenarios at five urban combat training ranges. rise implements live, virtual, constructive simulation capabilities to allow the use of both virtual and physical agents simultaneously, while our “fluid fidelity” simulation enables adaptive scaling between low and high fidelity simulation levels based on dynamic runtime requirements. Both virtual and physical agents are controlled with a unified gesture-based interface that enables a greater than 150:1 agent-to-operator ratio. Through this interface, we enable efficient swarm-based mission execution. rise translates mission needs to robot actuation with rapid tactic integration, a reliable testbed, and efficient operation.","2771-3989","","10.55417/fr.2023015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10876048","human robot interaction;swarm robotics;tactics","Robots;Robot sensing systems;Hardware;Software;Robot kinematics;Ecosystems;Command and control systems;Swarm robotics;Surveys;Software algorithms","","2","","","CCBY","25 Feb 2025","","","FRPS","FRPS Journals"
"PersoNet: A Novel Framework for Personality Classification-Based Apt Customer Service Agent Selection","L. Sandra; H. Prabowo; F. L. Gaol; S. M. Isa","Computer Science Department, Bina Nusantara University, West Jakarta, Indonesia; Computer Science Department, Bina Nusantara University, West Jakarta, Indonesia; Computer Science Department, Bina Nusantara University, West Jakarta, Indonesia; Computer Science Department, Bina Nusantara University, West Jakarta, Indonesia",IEEE Access,"21 Feb 2024","2024","12","","25200","25214","Personality classification has garnered significant interest in psychology, computational social science, and Machine Learning (ML) due to its wide-ranging applications. This paper presents PersoNet, an innovative framework developed to identify personality types using the Myers-Briggs Type Indicator (MBTI), aimed at enhancing customer service experiences by matching customers with suitable support agents. PersoNet employs a Bidirectional Long Short-Term Memory (BiLSTM) neural network architecture and has achieved an impressive classification accuracy of over 93.98%. Our extensive experiments with the MBTI dataset reveal that the BiLSTM architecture effectively captures both temporal dependencies and semantic subtleties in textual data, contributing to this high level of accuracy. Consequently, PersoNet can accurately select customer service agents who match customer personalities, achieving a Customer Satisfaction Rate (CSR) of over 97.82%–a notable improvement of 20.25% in CSR based on our experimental data. These results establish PersoNet as a cutting-edge tool in personality classification, surpassing existing methods in both accuracy and computational efficiency and markedly enhancing customer service quality.","2169-3536","","10.1109/ACCESS.2024.3364352","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10430165","Personality classification;deep learning;neural networks;natural language processing;BiLSTM network;MBTI dataset","Social networking (online);Customer services;Psychology;Mathematical analysis;Computer architecture;Video games;Training;Human factors;Deep learning;Natural language processing;Data models;Classification algorithms;Customer services","","3","","50","CCBYNCND","8 Feb 2024","","","IEEE","IEEE Journals"
"ATT-BLKAN: A Hybrid Deep Learning Model Combining Attention is Used to Enhance Business Process Prediction","J. Xu; X. Fang","School of Mathematics and Big Data, Anhui University of Science and Technology, Huainan, China; School of Mathematics and Big Data, Anhui University of Science and Technology, Huainan, China",IEEE Access,"28 Feb 2025","2025","13","","36175","36189","The role of predictive business process tasks in business process management is significant, as they are capable of anticipating potential process events and implementing timely interventions to address discrepancies between the anticipated and actual workflow. Nevertheless, existing deep learning-based predictive methods are unable to adequately address the current problem due to shortcomings in the training data, the model itself, or the architectures employed. In this paper, we propose a novel training framework for business process prediction based on improved BiLSTM-KAN, which addresses the issue of adaptability to continuous time data. This is achieved by enhancing the BiLSTM model’s ability to capture long-term dependencies through the addition of Agent Attention, while utilising KAN in place of the traditional Multi-Layer Perceptron (MLP) to improve prediction performance and mechanism interpretability. The results demonstrate that the proposed method outperforms all baseline methods in terms of prediction accuracy. This is evidenced by experiments conducted on five real publicly available event logs, which yielded improvements in accuracy of 12.4%, 7.16%, 9.77%, 12.27%, and 5.98%, respectively. The proposed method offers novel insights into the domain of predictive business processes and demonstrates the considerable potential of KAN in the field of predictive analytics.","2169-3536","","10.1109/ACCESS.2025.3545071","National Natural Science Foundation, China(grant numbers:61572035,61402011); Anhui Provincial Natural Science Foundation (Water Science Joint Fund)(grant numbers:2308085US11); Key Research and Development Program of Anhui Province(grant numbers:2022a05020005); Leading Backbone Talent Project in Anhui Province, China(grant numbers:2020-1-12); Anhui Province Academic and Technical Leader Foundation(grant numbers:2022D327); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10902041","Business process prediction;BiLSTM-KAN model;agent attention;deep learning;event log","Business;Predictive models;Data models;Accuracy;Deep learning;Context modeling;Analytical models;Splines (mathematics);Feature extraction;Computational modeling","","1","","27","CCBY","24 Feb 2025","","","IEEE","IEEE Journals"
"InDS: Intelligent DRL Strategy for Effective Virtual Network Embedding of an Online Virtual Network Requests","T. G. K. Kumar; S. K. Addya; S. G. Koolagudi","Department of Computer Science and Engineering, Cloud and Smart System Services Laboratory, National Institute of Technology Karnataka, Surathkal, India; Department of Computer Science and Engineering, Cloud and Smart System Services Laboratory, National Institute of Technology Karnataka, Surathkal, India; Department of Computer Science and Engineering, Cloud and Smart System Services Laboratory, National Institute of Technology Karnataka, Surathkal, India",IEEE Access,"19 Jul 2024","2024","12","","94843","94860","Network virtualization is a demanding feature in the evolution of future Internet architectures. It enables on-demand virtualized resource provision for heterogeneous Virtual Network Requests (VNRs) from diverse end users over the underlying substrate network. However, network virtualization provides various benefits such as service separation, improved Quality of Service, security, and more prominent resource usage. It also introduces significant research challenges. One of the major such issues is allocating substrate network resources to VNR components such as virtual machines and virtual links, also named as the virtual network embedding, and it is proven to be  $\mathbb {N}\mathbb {P}$ -hard. To address the virtual network embedding problem, most of the existing works are 1) Single-objective, 2) They failed to address dynamic and time-varying network states 3) They neglected network-specific features. All these limitations hinder the performance of existing approaches. This work introduces an embedding framework called Intelligent Deep Reinforcement Learning (DRL) Strategy for effective virtual network embedding of an online VNRs (InDS). The proposed InDS uses an actor-critic model based on DRL architecture and Graph Convolutional Networks (GCNs). The GCN effectively captures dependencies between the VNRs and substrate network environment nodes by extracting both network and system-specific features. In DRL, the asynchronous advantage actor-critic agents can learn policies from these features during the training to decide which virtual machines to embed on which servers over time. The actor-critic helps in efficiently learning optimal policies in complex environments. The suggested reward function considers multiple objectives and guides the learning process effectively. Evaluation of simulation results shows the effectiveness of InDS in achieving optimal resource allocation and addressing diverse objectives, including minimizing congestion, maximizing acceptance, and revenue-to-cost ratios. The performance of InDS exhibits superiority in achieving 28% of the acceptance ratio and 45% of the revenue-to-cost ratio by effectively managing the network congestion compared to other existing baseline works.","2169-3536","","10.1109/ACCESS.2024.3424474","National Institute of Technology Karnataka (NITK), Surathkal as per MOU; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10587234","Network virtualization;deep reinforcement learning;resource utilization;network features;congestion;acceptance ratio;virtual network embedding","Training;Bandwidth;Resource management;Substrates;Feature extraction;Costs;Virtualization;Network function virtualization;Telecommunication congestion control","","4","","42","CCBYNCND","8 Jul 2024","","","IEEE","IEEE Journals"
"Ecological Active Vision: Four Bioinspired Principles to Integrate Bottom–Up and Adaptive Top–Down Attention Tested With a Simple Camera-Arm Robot","D. Ognibene; G. Baldassare","Department of Informatics, Kings College London, London, UK; Consiglio Nazionale delle Ricerche, Laboratory of Computational Embodied Neuroscience (CNR-ISTC-LOCEN), Roma, Italy",IEEE Transactions on Autonomous Mental Development,"19 May 2017","2015","7","1","3","25","Vision gives primates a wealth of information useful to manipulate the environment, but at the same time it can easily overwhelm their computational resources. Active vision is a key solution found by nature to solve this problem: a limited fovea actively displaced in space to collect only relevant information. Here we highlight that in ecological conditions this solution encounters four problems: 1) the agent needs to learn where to look based on its goals; 2) manipulation causes learning feedback in areas of space possibly outside the attention focus; 3) good visual actions are needed to guide manipulation actions, but only these can generate learning feedback; and 4) a limited fovea causes aliasing problems. We then propose a computational architecture (“BITPIC”) to overcome the four problems, integrating four bioinspired key ingredients: 1) reinforcement-learning fovea-based top-down attention; 2) a strong vision-manipulation coupling; 3) bottom-up periphery-based attention; and 4) a novel action-oriented memory. The system is tested with a simple simulated camera-arm robot solving a class of search-and-reach tasks involving color-blob “objects.” The results show that the architecture solves the problems, and hence the tasks, very efficiently, and highlight how the architecture principles can contribute to a full exploitation of the advantages of active vision in ecological conditions.","1943-0612","","10.1109/TAMD.2014.2341351","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6863681","Bottom-up top–down overt attention;camera-arm robot;ecological active vision;eye-hand coupling;inhibition of return;memory;partial observability;reinforcement learning","Visualization;Robots;Couplings;Computer architecture;Cameras;Learning (artificial intelligence);Face","","44","","116","IEEE","24 Jul 2014","","","IEEE","IEEE Journals"
"Learning Hand Movement Interaction Control Using RNNs: From HHI to HRI","O. S. Oguz; B. M. Pfirrmann; M. Guo; D. Wollherr","Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany",IEEE Robotics and Automation Letters,"13 Aug 2018","2018","3","4","4100","4107","A key problem in robotics is enabling an autonomous agent to perform human-like arm movements in close proximity to another human. However, modeling the human decision and control process of the movement during dyadic interaction presents a challenge. Although, most prior approaches rely on multicomponent robot motion planning architectures, we use data of two humans performing interfering arm reaching movements to extract and transfer interaction behavior control skill to a robotic agent. A recurrent neural network-based framework is constructed to learn a policy that computes control signals for a robot end effector in order to replace one human. The learned policy is benchmarked against unseen interaction data and a state-of-the-art learning from demonstration framework in simulated scenarios. We compare several architectures and investigate a new activation function of three stacked tanh(). The results show that the proposed framework successfully learns a policy to imitate human movement behavior control during dyadic interaction. The policy is transferred to a real robot and its feasibility for close-proximity human-robot interaction is shown.","2377-3766","","10.1109/LRA.2018.2862923","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8424874","Human-robot interaction;human-in-the-loop;learning from demonstration;recurrent neural networks","Recurrent neural networks;Task analysis;Manipulators;Computer architecture;Hidden Markov models;Convergence","","2","","26","OAPA","3 Aug 2018","","","IEEE","IEEE Journals"
"Design and Architecture for Anti-Hidden Faults Multiagent Protection System in Smart Grids","T. Eliyan; S. F. Al-Gahtani; Z. M. S. Elbarbary; F. Wadie","Department of Electrical Engineering, Faculty of Engineering at Shoubra, Benha University, Cairo, Egypt; Department of Electrical Engineering, College of Engineering, King Khalid University, Abha, Saudi Arabia; Department of Electrical Engineering, College of Engineering, King Khalid University, Abha, Saudi Arabia; Mechatronics and Robotics Engineering Department, Faculty of Engineering, Egyptian Russian University, Badr City, Egypt",IEEE Access,"3 Apr 2025","2025","13","","55332","55344","The sensitivity of modern day smart devices and the continuously evolving power system into smart grid has raised the level of requirements from protection systems to zero-tolerance for hidden faults. Researchers have continuously proposed various protection schemes to enhance the performance of protection systems. However, high resistance hidden faults could still pass undetected for most of the proposed schemes or could be detected but suffer from high requirements of phasor measurement units (PMUs) or low confidence in the scheme decision. In this paper, an Anti-hidden fault multiagent protection system (AHF-MPS) is proposed that detects hidden faults with minimal PMU requirements and high confidence level in the detection decision. The AHF-MPS employs PMUs as primary agents which detects the periodic change in the phase angle of positive sequence currents that arises due to fault incidents. The second step of AHF-MPS is to initiate an accelerating factor to overcurrent protection devices acting as secondary agents. The system was tested upon IEEE 34 testing system and the results showed successful detection of hidden faults with operating times ranging from 77 ms up to 432 ms depending on fault location. That proved its ability in detecting hidden faults with minimal requirements proving its superiority to its peers.","2169-3536","","10.1109/ACCESS.2025.3555487","Deanship of Scientific Research, King Khalid University, through the General Research Project(grant numbers:RGP.2/472/45); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10943215","Smart grids;protection systems;hidden faults;phasor measurement unit","Phasor measurement units;Protection;Fault detection;Complexity theory;Transmission line measurements;Reliability;Voltage measurement;Current measurement;Smart grids;Impedance","","1","","44","CCBY","28 Mar 2025","","","IEEE","IEEE Journals"
"On Using Composability Tools for Reliability Analysis of Unmanned Multi-Aircraft Systems: A Case Study","D. Muniraj; D. Abou Jaoude; M. Farhood","Kevin T. Crofton Department of Aerospace and Ocean Engineering, Virginia Tech, Blacksburg, USA; Department of Mechanical Engineering, American University of Beirut, Beirut, Lebanon; Kevin T. Crofton Department of Aerospace and Ocean Engineering, Virginia Tech, Blacksburg, USA",IEEE Access,"28 Jan 2020","2020","8","","16331","16349","This paper presents a case study that demonstrates how tools from compositional verification can be used to design and analyze complex multi-agent systems operating in dynamic and uncertain environments. The case study concerns the design of an unmanned multi-aircraft system tasked to compromise an aerial encroacher by deploying countermeasures. The constituent agents, termed defenders, are fixed-wing unmanned aircraft. To successfully compromise the encroacher, at least one defender must be within a prespecified distance from the encroacher for a certain period, and the defenders must avoid collision among themselves and with the encroacher. Verifying this global property using monolithic (system-level) verification techniques is a challenging task due to the complexity of the components (defenders) and the interactions among them. To overcome these challenges, the components are designed to have a modular architecture, thereby enabling the use of component-based reasoning to simplify the task of verifying the global system property. Results from Euclidean geometry and formal methods are used to prove most component properties. For properties where analytical tools are overly conservative, focused Monte Carlo simulations are carried out. Restricting the use of simulations (or testing) to local verification of partial component properties leads to increasing the reliability of the system.","2169-3536","","10.1109/ACCESS.2020.2966763","Division of Civil, Mechanical and Manufacturing Innovation(grant numbers:CMMI-1351640,CNS-1801611); Division of Industrial Innovation and Partnerships(grant numbers:IIP-1539975,CNS-1650465); significant contributions from C-UAS industry members; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8960336","Compositional reasoning;formal verification;system analysis and design;temporal logic of actions;unmanned aerial vehicles","Tools;Cognition;Task analysis;Reliability engineering;Aircraft;Multi-agent systems","","","","34","CCBY","15 Jan 2020","","","IEEE","IEEE Journals"
"Optimizing the Perceptual Quality of Time-Domain Speech Enhancement with Reinforcement Learning","X. Hao; C. Xu; L. Xie; H. Li","School of Computer Science, Northwestern Polytechnical University, Xi'an, China; Department of Electrical and Computer Engineering, National University of Singapore, Singapore, Singapore; School of Computer Science, Northwestern Polytechnical University, Xi'an, China; Department of Electrical and Computer Engineering, National University of Singapore, Singapore, Singapore",Tsinghua Science and Technology,"21 Jun 2022","2022","27","6","939","947","In neural speech enhancement, a mismatch exists between the training objective, i.e., Mean-Square Error (MSE), and perceptual quality evaluation metrics, i.e., perceptual evaluation of speech quality and short-time objective intelligibility. We propose a novel reinforcement learning algorithm and network architecture, which incorporate a non-differentiable perceptual quality evaluation metric into the objective function using a dynamic filter module. Unlike the traditional dynamic filter implementation that directly generates a convolution kernel, we use a filter generation agent to predict the probability density function of a multivariate Gaussian distribution, from which we sample the convolution kernel. Experimental results show that the proposed reinforcement learning method clearly improves the perceptual quality over other supervised learning methods with the MSE objective function.","1007-0214","","10.26599/TST.2021.9010048","National Research Foundation of Singapore(grant numbers:AISG-100E-2018-006); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9802900","speech enhancement;neural networks;dynamic filter;reinforcement learning","Measurement;Training;Convolution;Heuristic algorithms;Reinforcement learning;Speech enhancement;Filtering algorithms","","11","","43","","21 Jun 2022","","","TUP","TUP Journals"
"Using Fuzzy Inference Systems for the Creation of Forex Market Predictive Models","A. Hernandez-Aguila; M. García-Valdez; J. -J. Merelo-Guervós; M. Castañón-Puga; O. C. López","Department of Graduate Studies, National Technological Institute of Mexico, Tijuana, Mexico; Department of Graduate Studies, National Technological Institute of Mexico, Tijuana, Mexico; Department of Computer Architecture and Technology, University of Granada, Granada, Spain; Chemistry and Engineering School, Autonomous University of Baja California, Tijuana, Mexico; Department of Graduate Studies, National Technological Institute of Mexico, Tijuana, Mexico",IEEE Access,"13 May 2021","2021","9","","69391","69404","This paper presents a method for creating Forex market predictive models using multi-agent and fuzzy systems, which have the objective of simulating the interactions that provoke changes in the price. Agents in the system represent traders performing buy and sell orders in a market, and fuzzy systems are used to model the rules followed by traders performing trades in a live market and intuitionistic fuzzy logic to model their decisions' indeterminacy. We use functions to restrict the agents' decisions, which make the agents become specialized at particular market conditions. These “specialization” functions use the grades of membership obtained from an agent's fuzzy system and thresholds obtained from training data sets, to determine if that agent is specialized enough to handle a market's current conditions. We have performed experiments and compared against the state of the art. Results demonstrate that our method obtains predictive errors (using mean absolute error) that are in the same order of magnitude than those errors obtained by models generated using deep learning and models generated by random forest, AdaBoost, XGBoost, and support-vector machines. Furthermore, we performed experiments that show that identifying specialized agents yields better results.","2169-3536","","10.1109/ACCESS.2021.3077910","Project DeepBio(grant numbers:TIN2017-85727-C4-2-P); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9424586","Economic forecasting;fuzzy systems;multi-agent system;forex market","Fuzzy sets;Fuzzy logic;Predictive models;Fuzzy systems;Hidden Markov models;Biological system modeling;Shape","","18","","56","CCBY","6 May 2021","","","IEEE","IEEE Journals"
"Learning to Fly: A Distributed Deep Reinforcement Learning Framework for Software-Defined UAV Network Control","H. Cheng; L. Bertizzolo; S. D’oro; J. Buczek; T. Melodia; E. S. Bentley","Department of Electrical and Computer Engineering, Institute for Wireless Internet of Things, Northeastern University, Boston, MA, USA; Department of Electrical and Computer Engineering, Institute for Wireless Internet of Things, Northeastern University, Boston, MA, USA; Department of Electrical and Computer Engineering, Institute for Wireless Internet of Things, Northeastern University, Boston, MA, USA; Department of Electrical and Computer Engineering, Institute for Wireless Internet of Things, Northeastern University, Boston, MA, USA; Department of Electrical and Computer Engineering, Institute for Wireless Internet of Things, Northeastern University, Boston, MA, USA; Air Force Research Laboratory, Rome, NY, USA",IEEE Open Journal of the Communications Society,"12 Jul 2021","2021","2","","1486","1504","Control and performance optimization of wireless networks of Unmanned Aerial Vehicles (UAVs) require scalable approaches that go beyond architectures based on centralized network controllers. At the same time, the performance of model-based optimization approaches is often limited by the accuracy of the approximations and relaxations necessary to solve the UAV network control problem through convex optimization or similar techniques, and by the accuracy of the channel network models used. To address these challenges, this article introduces a new architectural framework to control and optimize UAV networks based on Deep Reinforcement Learning (DRL). Furthermore, it proposes a virtualized, `ready-to-fly' emulation environment to generate the extensive wireless data traces necessary to train DRL algorithms, which are notoriously hard to generate and collect on battery-powered UAV networks. The training environment integrates previously developed wireless protocol stacks for UAVs into the CORE/EMANE emulation tool. Our `ready-to-fly' virtual environment guarantees scalable collection of high-fidelity wireless traces that can be used to train DRL agents. The proposed DRL architecture enables distributed data-driven optimization (with up to 3.7 × throughput improvement and 0.2 × latency reduction in reported experiments), facilitates network reconfiguration, and provides a scalable solution for large UAV networks.","2644-125X","","10.1109/OJCOMS.2021.3092690","Air Force Research Laboratory (AFRL)(grant numbers:FA8750-18-C-0122); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9465215","UAV networks;non-terrestrial netoworks;deep reinforcement learning;AI for wireless networks;6G","Optimization;Ad hoc networks;Protocols;Drones;Emulation;Wireless sensor networks;Virtual environments","","15","","55","CCBY","25 Jun 2021","","","IEEE","IEEE Journals"
"Direct load control of thermostatically controlled loads based on sparse observations using deep reinforcement learning","F. Ruelens; B. J. Claessens; P. Vrancx; F. Spiessens; G. Deconinck","Department of Electrical Engineering, KU Leuven, Leuven, Belgium; REstore, Centrica, Antwerp, Belgium; AI-lab, Vrije Universiteit Brussel, Brussels, Belgium; Vito/EnergyVille, Mol, Belgium; Department of Electrical Engineering, KU Leuven, Leuven, Belgium",CSEE Journal of Power and Energy Systems,"19 Dec 2019","2019","5","4","423","432","This paper considers a demand response agent that must find a near-optimal sequence of decisions based on sparse observations of its environment. Extracting a relevant set of features from these observations is a challenging task and may require substantial domain knowledge. One way to tackle this problem is to store sequences of past observations and actions in the state vector, making it high dimensional, and apply techniques from deep learning. This paper investigates the capabilities of different deep learning techniques, such as convolutional neural networks and recurrent neural networks, to extract relevant features for finding near-optimal policies for a residential heating system and electric water heater that are hindered by sparse observations. Our simulation results indicate that in this specific scenario, feeding sequences of time-series to an Long Short-Term Memory (LSTM) network, which is a specific type of recurrent neural network, achieved a higher performance than stacking these time-series in the input of a convolutional neural network or deep neural network.","2096-0042","","10.17775/CSEEJPES.2019.00590","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8928284","Convolutional networks;deep reinforcement learning;long short-term memory;residential demand response","Feature extraction;Load management;Water heating;Machine learning;Resistance heating;Observability;Task analysis","","7","","","","8 Dec 2019","","","CSEE","CSEE Journals"
"Deep Reinforcement Learning Based Routing in IP Media Broadcast Networks: Feasibility and Performance","P. Amaral; D. Simões","Departamento de Engenharia Electrotécnica e de Computadores, Faculdade de Ciências e Tecnologia (FCT), Universidade Nova de Lisboa, Caparica, Portugal; Departamento de Engenharia Electrotécnica e de Computadores, Faculdade de Ciências e Tecnologia (FCT), Universidade Nova de Lisboa, Caparica, Portugal",IEEE Access,"20 Jun 2022","2022","10","","62459","62470","The media broadcast industry has evolved from Serial Digital Interface (SDI) based infrastructures to IP networks. While IP based video broadcast is well established in the data plane, the use of IP networks to transport media flows still poses challenges in terms of resource management and orchestration. Software Defined Networking (SDN) based orchestration architectures have emerged in the industry that use SDN to route the media flows of a broadcast service across the provider IP network. Several approaches to multimedia flow routing in IP based SDN networks have been proposed in the context of streaming applications over the Internet. These range from model based linear optimization solutions that have high complexity to simple shortest path based routing with either Static Link Costs (SLC) or Dynamic Link Costs (DLC). More recently model-free optimization methods such as Deep Reinforcement Learning (DRL) have been proposed for routing and Traffic Engineering (TE) of multimedia flows in SDN networks. The media broadcast scenario however has specific requirements, with services like Master Control Room (MCR) operation and live broadcasting of events, and it has been rarely addressed in the literature. In this work we propose a DRL based routing method for this scenario and compare it to SLC and DLC algorithms based on Dijkstra shortest paths. This is, to our knowledge, the first work to follow this approach in the context of media broadcast services in IP infrastructures. The algorithm is designed considering the specifications and capabilities of one of the leading SDN orchestrators in the market and considers the more common Service Level Agreement (SLA) requirements in the industry. Three different DRL algorithms are implemented and compared and we evaluate them using a real service provider network topology. The results indicate that DRL based routing is applicable in real production scenarios and that it achieves considerable performance gains when compared to the SLC and DLC shortest path algorithms commonly used today.","2169-3536","","10.1109/ACCESS.2022.3182009","Fundação para a Ciência e Tecnologia/Ministério da Ciência Tecnologia e Ensino Superior (FCT/MCTES) through National Funds and When Applicable Co-Funded EU Funds(grant numbers:UIDB/50008/2020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793657","Media broadcast networks;artificial intelligence;deep reinforcement learning;network orchestration;routing;software defined networks","Routing;Media;Heuristic algorithms;IP networks;Costs;Optimization;Network topology","","4","","29","CCBY","10 Jun 2022","","","IEEE","IEEE Journals"
"Hydra-RAN: Multi-Functional Communications and Sensing Networks Applications: Intelligent Parking Systems","R. I. Abd; D. J. Findley; S. Mohammady; M. Ardakani; K. Soon Kim","Department of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea; Department of Civil, Construction, and Environmental Engineering, North Carolina State University, Centennial Campus, Raleigh, NC, USA; School of Electrical and Electronic Engineering, Technological University Dublin, Dublin 6, Ireland; Department of Electrical and Computer Engineering, University of Alberta, Edmonton, AB, Canada; Department of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea",IEEE Open Journal of the Communications Society,"7 Oct 2025","2025","6","","8311","8334","Smart cities and intelligent transportation systems (ITS) confront substantial urban mobility challenges, with parking management emerging as a particularly complex subsystem. The operational efficacy of these systems is fundamentally constrained by dynamic stochastic variables, including spatiotemporal resource distribution, demand volatility, multimodal traffic interdependencies, and competing urban development priorities. These factors generate nonlinear system behaviors that manifest as chronic inefficiencies in parking resource allocation, ultimately degrading overall urban mobility performance. The Hydra radio access network (Hydra-RAN) is envisioned as a next-generation multifunctional (NG-MF) platform. A comprehensive solution designed to consolidate existing networks and technologies into a cohesive, integrated framework. This advanced architecture promotes a synergistic environment, enabling the simultaneous operation of multiple networks and applications. While Hydra-RAN supports a broad spectrum of applications, this study focuses specifically on its perceptive parking management - an innovative solution enabled by the network’s distinctive integration of multi-sparse input processing and multi-task learning (SMTL) paradigms. This approach provides intelligent real-time classification and dynamic allocation of available parking spaces through edge network nodes. The system’s advanced capabilities stem from three key technological integrations: (1) continuous processing of real-time urban data streams, (2) a hierarchical framework for computational task distribution across three integrated tiers: edge computing (EC), fog computing (FC), and cloud computing (CC), and (3) semantic communication protocols, collectively representing a paradigm shift in intelligent parking management. Our proposed solution demonstrated a 50% reduction in communication overhead, 75% improved real-time decision-making accuracy, and enhanced scalability in modern urban environments. These results have significant implications, e.g., for reducing operational costs, improving resource utilization, and supporting sustainable urban development.","2644-125X","","10.1109/OJCOMS.2025.3615970","Institute of Information and communications Technology Planning and Evaluation (IITP) Grant; Korea government (MSIT) through the YKCS Open RAN Global Collaboration Center under Grant IITP-2025-RS-2024-00434743 (30%) and through the 6G·Cloud Research and Education Open Hub(grant numbers:IITP-2025-RS-2024-00428780 (40%)); National Research Foundation of Korea (NRF) Grant; Korea Government; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11184823","Hydra radio access network (Hydra-RAN);multi-functional networks;perceptive networks;next-generation multi-functional (NG-MF) platforms;AI/ML engines;accurate user status;multi-sparse input and multi-task learning (SMTL);semantic communication;and parking systems","Real-time systems;Computer architecture;Wireless sensor networks;Decision making;Semantic communication;Resource management;Edge computing;Smart cities;Next generation networking;Integrated sensing and communication","","","","64","CCBYNCND","30 Sep 2025","","","IEEE","IEEE Journals"
"Automatic DenseNet Sparsification","T. Li; W. Jiao; L. -N. Wang; G. Zhong","Department of Computer Science and Technology, Ocean University of China, Qingdao, China; Department of Computer Science and Technology, Ocean University of China, Qingdao, China; Department of Computer Science and Technology, Ocean University of China, Qingdao, China; Department of Computer Science and Technology, Ocean University of China, Qingdao, China",IEEE Access,"10 Apr 2020","2020","8","","62561","62571","As a classic and well-performed deep convolutional neural network, DenseNet links every layer to each of its preceding layers via skip connections. However, the dense connectivity of the links leads to much redundance, consuming lots of computational resources. In this paper, to automatically prune redundant skip connections in DenseNet, we introduce a novel reinforcement learning method called automatic DenseNet sparsification (ADS). In ADS, we use adjacent matrix to represent dense connections in DenseNet, and design an agent using recurrent neural networks (RNNs) to sparsify the matrix, i. e. removing redundant skip connections in DenseNet. The validation accuracies of the sparsified DenseNets are used as rewards to update the agent, which promotes the agent to generate sparsified DenseNets with high performance. Extensive experiments demonstrate the effectiveness of ADS: The performance of the sparsified DenseNet surpasses not only the original DenseNet but related models; Moreover, the sparsified DenseNet has strong transferability when it is applied to new tasks. More importantly, ADS is very efficient. For the compression of a 40-layer DenseNet, it takes less than 1 day on a single GPU.","2169-3536","","10.1109/ACCESS.2020.2984130","Major Project for New Generation of AI(grant numbers:2018AAA0100400); National Natural Science Foundation of China (NSFC)(grant numbers:41706010); Joint Fund of the Equipments Pre-Research and Ministry of Education of China(grant numbers:6141A020337); Open Fund of Engineering Research Center for Medical Data Mining and Application of Fujian Province(grant numbers:MDM2018007); Fundamental Research Funds for the Central Universities of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9050458","Automatic model compression;reinforcement learning;sparsified DenseNet;transferability","Reinforcement learning;Task analysis;Computational modeling;Convolution;Recurrent neural networks;Graphics processing units;Redundancy","","20","","46","CCBY","30 Mar 2020","","","IEEE","IEEE Journals"
"Procedural Content Generation Using Reinforcement Learning for Disaster Evacuation Training in a Virtual 3D Environment","J. Agarwal; S. Shridevi","School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India; Centre for Advanced Data Science, Vellore Institute of Technology, Chennai, India",IEEE Access,"14 Sep 2023","2023","11","","98607","98617","This research addresses the need for effective disaster evacuation training methods by proposing a virtual reality system that utilizes Reinforcement Learning Procedural Content Generation (RL-PCG) algorithms. The aim of this study is to provide a cost-effective and safe way to conduct disaster evacuation preparedness training, surpassing the limitations of traditional real-life drills. The paper’s objectives encompass the design of a novel 3-layer PCG architecture for generating realistic disaster simulations in virtual reality, the implementation of a working prototype for fire disaster scenarios, and the evaluation of the proposed system’s effectiveness through comparison with existing RL agents. Significant findings include the superiority of the RL-PCG agent in generating diverse and realistic disaster scenarios with faster training time and lesser number of steps, even with limited processor capabilities. In conclusion, this research establishes that the RL-PCG Scenario for Disaster Evacuation Training in VR is a more effective method, leading to improved disaster preparedness for individuals, and opens avenues for further advancements in disaster training using virtual reality and reinforcement learning technologies. For a video demo of this work, please visit https://youtu.be/3WZnQOfUP94.","2169-3536","","10.1109/ACCESS.2023.3313725","Vellore Institute of Technology, India; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10246257","Disaster evacuation training;procedural content generation;reinforcement learning;virtual reality","Training;Games;Solid modeling;Virtual reality;Reinforcement learning;Heuristic algorithms;Phonocardiography;Disaster management","","5","","35","CCBY","11 Sep 2023","","","IEEE","IEEE Journals"
"Enhanced Multi-Critic Deep Reinforcement Learning for Channel Estimation in 6G N2V or I2V Communications","P. Mithillesh Kumar; M. Supriya","Dept. of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Bengaluru, India; Dept. of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Bengaluru, India",IEEE Access,"","2025","PP","99","1","1","The need for self-adaptive systems is increasing with the growth in automation to improve accuracy and performance. Such self-adaptive systems can be built using Reinforcement Learning (RL) models with the help of simulated and recorded data. Deep Reinforcement Learning (DRL) is proposed by infusing NN into RL models and can be used to improve performance in use cases with sparse reward distributions. Traditional Actor-Critic DRL models act with a single critic and single actor network in case of on-policy execution. In contrast, the performance of the agent which makes decisions in the environment improves when considering the information exchange from multiple critics. In this work, the proposed Teacher Tutor Trainee a version of Multi Critic architecture provides the impact of information exchange from multiple critics for a channel estimation use case. Channel Estimation is a method of calculating the impact of the propagation medium and other external factors that deteriorate a signal and its optimization. The performance improvement can be observed from the increase in the explained variance. On implementation, it is observed that the Proximal Policy Optimization model has shown better performance than the Advantage Actor-Critic model.","2169-3536","","10.1109/ACCESS.2025.3630331","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11232479","Advantage Actor-Critic;Channel Estimation;Electronic Communications Committee 33 model;Friis model;Multi Critic;Okumura Hata Model;Proximal Policy Optimization;Network to Vehicle;Infrastructure to Vehicle;Stanford University Interim model","Channel estimation;Mathematical models;Computational modeling;Analytical models;Computer architecture;6G mobile communication;Deep reinforcement learning;Information exchange;Data models;Telecommunication network reliability","","","","","CCBY","7 Nov 2025","","","IEEE","IEEE Early Access Articles"
"6G Mobile Communications for Multi-Robot Smart Factory","Z. Chen; K. -C. Chen; C. Dong; Z. Nie","University of South Florida, Tampa, FL, USA; University of South Florida, Tampa, FL, USA; Fuzhou University, Fuzhou, Fujian, China; University of South Florida, Tampa, FL, USA",Journal of ICT Standardization,"22 Sep 2023","2021","9","3","371","404","Private or special-purpose wireless networks present a new technological trend for future mobile communications, while one attractive application scenario is the wireless communication in a smart factory. In addition to wireless technologies, this paper pays special attention to treat a smart factory as the integration of collaborative multi-robot systems for production robots and transportation robots. Multiple aspects of collaborative multi-robot systems enabled by wireless networking have been investigated, dynamic multi-robot task assignment for collaborative production robots and subsequent transportation robots, social learning to enhance precision and robustness of collaborative production robots, and more efficient operation of collaborative transportation robots. Consequently, the technical requirements of 6G mobile communication can be logically highlighted.","2246-0853","","10.13052/jicts2245-800X.934","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10255487","Smart factory;industry 4.0;smart manufacturing;wireless communication;uRLLC;mMTC;5G;6G;multi-robot system;multi-agent system;collaboration;artificial intelligence;machine learning;reinforcement learning;social learning;security","6G mobile communication;Wireless networks;Collaboration;Transportation;Production;Market research;Communication system security","","5","","103","","22 Sep 2023","","","River Publishers","River Publishers Journals"
"An Intelligent Agent-Based Resilient Framework for Marine Vessel Mission Adaptations","N. Kougiatsos; E. L. Scheffers; M. C. van Benten; D. L. Schott; P. de Vos; R. R. Negenborn; V. Reppa","Department of Maritime and Transport Technology, Faculty of Mechanical Engineering, Delft University of Technology, Delft, The Netherlands; Department of Maritime and Transport Technology, Faculty of Mechanical Engineering, Delft University of Technology, Delft, The Netherlands; Department of Maritime and Transport Technology, Faculty of Mechanical Engineering, Delft University of Technology, Delft, The Netherlands; Department of Maritime and Transport Technology, Faculty of Mechanical Engineering, Delft University of Technology, Delft, The Netherlands; Department of Maritime and Transport Technology, Faculty of Mechanical Engineering, Delft University of Technology, Delft, The Netherlands; Department of Maritime and Transport Technology, Faculty of Mechanical Engineering, Delft University of Technology, Delft, The Netherlands; Department of Maritime and Transport Technology, Faculty of Mechanical Engineering, Delft University of Technology, Delft, The Netherlands",IEEE Open Journal of Intelligent Transportation Systems,"6 Mar 2025","2025","6","","184","203","Waterborne transport is very important for moving freight and passengers globally. To make this transport more efficient, vessel design must adapt to changing missions, regulations and the occurrence of malfunctions. This paper presents the design of an intelligent decision-support framework to assist marine engineers and vessel operators in updating the system and control architecture of marine vessels before and during a mission. The connection between the system architecture and control design perspectives is enabled using a semantics-based technique. To this end, the multi-level vessel control system is described by a semantic database, a knowledge graph used to connect the components automatically, and quantitative service criteria. Considering the system architecture, the optimal modification is deduced using modularity and complexity criteria, originating from the field of network theory. On the control side, an intelligent automation supervisor is designed to make offline and online decisions regarding the energy deficit to execute a new mission and the active automation configuration during operation. For offline decisions, system architecture modifications are requested by the vessel designers to cover the energy deficit. During operation, switching between hardware and virtual sensors as well as switching between energy management controllers is implemented to handle the effects of sensor faults. The framework is successfully applied to a case study of a tugboat used to adapt to missions with different power requirements, while simulation results are used to indicate its application in supporting the decisions of vessel designers and human vessel operators.","2687-7813","","10.1109/OJITS.2025.3539419","Project READINESS of the Research Programme “Topsector Water & Maritime: The Blue Route“ which is partly financed by the Dutch Research Council (NWO)(grant numbers:TWM.BL.019.002); Project RODIN funded by the Delft University of Technology; Project SH2IPDRIVE; Ministry of Economic Affairs and Climate Policy, RDM regulation, carried out by the Netherlands Enterprise Agency(grant numbers:MOB21013); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10876184","Decision support systems;intelligent systems;knowledge-representation techniques;resilient operation;network theory (graphs);marine safety","Systems architecture;Semantics;Regulation;Energy management;Control design;Switches;Propulsion;Optimization;Machinery;Knowledge graphs","","","","60","CCBY","5 Feb 2025","","","IEEE","IEEE Journals"
"Flow Splitter: A Deep Reinforcement Learning-Based Flow Scheduler for Hybrid Optical-Electrical Data Center Network","Y. Tang; H. Guo; T. Yuan; X. Gao; X. Hong; Y. Li; J. Qiu; Y. Zuo; J. Wu","State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, Beijing, China; Pattern Recognition Laboratory, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, Beijing, China",IEEE Access,"19 Sep 2019","2019","7","","129955","129965","Hybrid optical-electrical switching based data center network (HOE-DCN) has been regarded as a promising architecture for the next generation data center network (DCN). To achieve traffic optimization, the main superiority of HOE-DCN is its capability to offload the long-lived `elephant' flows by optical interconnections, and transmit the latency-sensitive `mice' flows by electrical switching. However, most previous works identify and schedule the flows according to a fixed flow size threshold, which can hardly handle the highly dynamic network conditions in recent DCN. In order to achieve more effective flow scheduling in HOE-DCN, in this paper, we propose Flow Splitter (FS), a deep reinforcement learning (DRL) based flow scheduler which enables HOE-DCN to make instant flow scheduling according to the runtime network conditions. To train a more effective DRL agent, we upgrade the DRL method named Deep Deterministic Policy Gradient (DDPG) and propose DDPG-FS, which is capable of learning a high-performance flow scheduling policy in the complex network environment. Through simulation, we prove that our FS can significantly improve the performance of HOE-DCN. Compared with the recent flow scheduling approaches for HOE-DCN, our FS can obviously reduce the average flow complete time of arrival flows, especially the latency-sensitive mice flows.","2169-3536","","10.1109/ACCESS.2019.2940445","National Natural Science Foundation of China(grant numbers:61471054,61331008); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8832226","Optical switching;data center network;deep reinforcement learning;flow scheduling","Optical switches;Switching circuits;Optical packet switching;Optical buffering;Schedules;Scheduling;Optical fiber networks","","16","","43","CCBY","11 Sep 2019","","","IEEE","IEEE Journals"
"A Framework for Verifiable and Auditable Collaborative Anomaly Detection","G. Santin; I. Skarbovsky; F. Fournier; B. Lepri","Digital Society Center, Bruno Kessler Foundation (FBK), Trento, Italy; IBM Research, Haifa University Campus, Mount Carmel Haifa, Israel; IBM Research, Haifa University Campus, Mount Carmel Haifa, Israel; Digital Society Center, Bruno Kessler Foundation (FBK), Trento, Italy",IEEE Access,"16 Aug 2022","2022","10","","82896","82909","Collaborative and Federated Leaning are emerging approaches to manage cooperation between a group of agents for the solution of Machine Learning tasks, with the goal of improving each agent’s performance without disclosing any data. In this paper we present a novel algorithmic architecture that tackle this problem in the particular case of Anomaly Detection (or classification of rare events), a setting where typical applications often comprise data with sensible information, but where the scarcity of anomalous examples encourages collaboration. We show how Random Forests can be used as a tool for the development of accurate classifiers with an effective insight-sharing mechanism that does not break the data integrity. Moreover, we explain how the new architecture can be readily integrated in a blockchain infrastructure to ensure the verifiable and auditable execution of the algorithm. Furthermore, we discuss how this work may set the basis for a more general approach for the design of collaborative ensemble-learning methods beyond the specific task and architecture discussed in this paper.","2169-3536","","10.1109/ACCESS.2022.3196391","H2020 INFINITECH Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9849646","Algorithm auditing;anomaly detection;blockchain;collaborative learning","Collaboration;Collaborative work;Anomaly detection;Radio frequency;Training;Computer architecture;Task analysis","","1","","56","CCBY","4 Aug 2022","","","IEEE","IEEE Journals"
"Supervised Learning of Lyapunov Functions Using Laplace Averages of Approximate Koopman Eigenfunctions","S. A. Deka; D. V. Dimarogonas","Department of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden; Department of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden",IEEE Control Systems Letters,"27 Jul 2023","2023","7","","3072","3077","Modern data-driven techniques have rapidly progressed beyond modelling and systems identification, with a growing interest in learning high-level dynamical properties of a system, such as safe-set invariance, reachability, input-to-state stability etc. In this letter, we propose a novel supervised Deep Learning technique for constructing Lyapunov certificates, by leveraging Koopman Operator theory-based numerical tools (Extended Dynamic Mode Decomposition and Generalized Laplace Analysis) to robustly and efficiently generate explicit ground truth data for training. This is in stark contrast to existing Deep Learning methods where the loss functions plainly penalize Lyapunov condition violation in the absence of labelled data for direct regression. Furthermore, our approach leads to a linear parameterization of Lyapunov candidate functions in terms of stable eigenfunctions of the Koopman operator, making them more interpretable compared to standard DNN-based architecture. We demonstrate and validate our approach numerically using 2-dimensional and 10-dimensional examples.","2475-1456","","10.1109/LCSYS.2023.3291657","EU CANOPIES; VR; KAWFoundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10171181","Data-driven modeling;Koopman operator;Lyapunov function;machine learning;neural networks","Eigenvalues and eigenfunctions;Lyapunov methods;Trajectory;Convergence;Deep learning;Neural networks;Stability analysis","","6","","19","CCBY","3 Jul 2023","","","IEEE","IEEE Journals"
"Relational Reinforcement Learning Based Autonomous Cell Activation in Cloud-RANs","G. Sun; G. O. Boateng; D. Ayepah-Mensah; G. Liu","School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science, Zhongshan Institute, University of Electronic Science and Technology of China, Zhongshan, China",IEEE Access,"24 May 2019","2019","7","","63588","63604","The emergence of future 5G technologies has given cloud radio access networks (C-RANs) considerable attention. In the C-RANs, distributed remote radio heads (RRHs) are connected to centralized baseband units (BBUs) which have high capacity processors through radio links to forward radio signals from users. For the BBU pool to control energy consumption and user satisfaction levels, reinforcement learning techniques become the best option. In this paper, we propose an autonomous cell activation framework and customized physical resource allocation schemes to balance energy consumption and QoS satisfaction in wireless networks. We formulate the cell activation problem as a Markov decision process and set up a relational reinforcement learning model based on online k-means clustering and anchor-graph hashing (AGH) to satisfy the user QoS demand and to achieve low energy consumption with the minimum number of the active RRHs under varying traffic demand and user mobility. The extensive simulations are conducted to show the effectiveness of our proposed solution under a mobility scenario compared with the state-of-the-art schemes.","2169-3536","","10.1109/ACCESS.2019.2916470","National Natural Science Foundation of China(grant numbers:61771098); Fundamental Research Funds for the Central Universities(grant numbers:ZYGX2018J068); Fund from the Department of Science and Technology of Sichuan Province(grant numbers:2017GFW0128,8ZDYF2268,2018JY0578,2017JY0007); ZTE Innovation Research Fund for Universities Program 2016; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8713452","Relational reinforcement learning;anchor graph hashing;online k-means clustering;autonomous cell activation;cloud radio access networks","Resource management;Computer architecture;Quality of service;Reinforcement learning;Microprocessors;Energy efficiency;Cloud computing","","7","","33","OAPA","13 May 2019","","","IEEE","IEEE Journals"
"A Systematic Literature Review of Hallucinations in Large Language Models","C. Woesle; L. Fischer-Brandies; R. Buettner","Chair of Hybrid Intelligence, Helmut-Schmidt-University/University of the Federal Armed Forces Hamburg, Hamburg, Germany; Chair of Hybrid Intelligence, Helmut-Schmidt-University/University of the Federal Armed Forces Hamburg, Hamburg, Germany; Chair of Hybrid Intelligence, Helmut-Schmidt-University/University of the Federal Armed Forces Hamburg, Hamburg, Germany",IEEE Access,"27 Aug 2025","2025","13","","148231","148253","This review systematically maps research on hallucinations in large language models using a descriptive scheme that links model outputs to four system architectures: unaugmented generation, post-hoc reactive validation, proactive detection-and-mitigation, and fully integrated detection-and-mitigation designs. Our methodology for this systematic review follows the PRISMA guidelines to ensure transparency and reproducibility. We searched IEEE Xplore, ACM Digital Library, and ScienceDirect for studies published between 2015 and January 2025 and extracted 125 peer-reviewed papers across nine application domains. Quantitative analysis shows that question answering and multimodal tasks account for 48% of all papers, whereas software engineering, educational technology, and autonomous systems are underexplored. Although 87.5% of the studies rely on additional reactive or proactive defenses, only 8.8% implement integrated architecture-level safeguards, revealing a critical gap in unified and dynamic architectures. The resulting classification matrix and domain map provide a diagnostic tool for locating blind spots and comparing architectural maturity. Three actionable priorities emerge: develop integrated reasoning-and-verification loops that pre-empt hallucinations; transfer proven causal-intervention and multi-agent validation pipelines to high-stakes, under-represented domains and benchmark them under real conditions; and build modular, cross-domain evaluation frameworks that isolate the contribution of individual mitigation components and support ablation studies. By consolidating fragmented evidence and quantifying architecture-domain imbalances, this review establishes a traceable foundation for engineering reliable, explainable, and domain-adaptable countermeasures to hallucinations in generative language technology.","2169-3536","","10.1109/ACCESS.2025.3601206","Open-Access-Publication-Fund of the Helmut-Schmidt-University/University of the Federal Armed Forces Hamburg; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11132297","Large language models;hallucinations;architecture;detection techniques;mitigation strategies;systematic literature review","Prevention and mitigation;Systematic literature review;Large language models;Systems architecture;Semantics;Question answering (information retrieval);Computer architecture;Taxonomy;Technological innovation;Retrieval augmented generation","","","","159","CCBY","21 Aug 2025","","","IEEE","IEEE Journals"
"Architecture of an Artificial Intelligence Model Manager for Event-Driven Component-Based SCADA Systems","Z. Sičanica; S. Sučić; B. Milašinović","Končar—Digital, Zagreb, Croatia; Končar—Digital, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia",IEEE Access,"23 Mar 2022","2022","10","","30414","30426","This paper analyzes Hat, an open-source framework for developing event-driven component-based SCADA applications, and discusses possibilities to add various analytical tools to such platforms. As a part of the contribution, an open-source component called Artificial Intelligence Model Manager (AIMM) has been developed and integrated into a Hat-based SCADA platform. AIMM is extensible through various plugins, allowing the addition of various models for advanced analytics e.g., machine learning tools, statistical tools, etc. The paper describes AIMM architecture and provides a use case in which state estimation was performed in a medium-voltage distribution grid. This case study demonstrates that it is possible to extend component-based SCADA systems with components for advanced analytics with minimal fundamental system changes.","2169-3536","","10.1109/ACCESS.2022.3159715","Advanced Tools Towards Cost-efficient Decarbonisation of Future Reliable Energy Systems (ATTEST) Project through the European Union’s Horizon 2020 Research and Innovation Program(grant numbers:864298); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9734070","Artificial intelligence;power system analysis computing;SCADA systems;software architecture","SCADA systems;Computer architecture;State estimation;Neural networks;Security;Analytical models;Monitoring","","1","","48","CCBY","14 Mar 2022","","","IEEE","IEEE Journals"
"Cyrus+: A DRL-Based Puncturing Solution to URLLC/eMBB Multiplexing in O-RAN","E. Ghoreishi; B. Abolhassani; Y. Huang; S. Acharya; W. Lou; Y. T. Hou","Virginia Tech, Blacksburg, VA, USA; Virginia Tech, Blacksburg, VA, USA; NVIDIA Corporation, Santa Clara, CA, USA; Virginia Tech, Blacksburg, VA, USA; Virginia Tech, Blacksburg, VA, USA; Virginia Tech, Blacksburg, VA, USA",IEEE Transactions on Machine Learning in Communications and Networking,"24 Oct 2025","2025","3","","1178","1196","Puncturing is a promising technique in 3GPP to multiplex Enhanced Mobile Broadband (eMBB) and Ultra-Reliable Low Latency Communications (URLLC) traffic on the same 5G New Radio (NR) air interface. The essence of puncturing is to transmit URLLC packets on demand upon their arrival, by preempting the radio resources (or subcarriers) that are already allocated to eMBB traffic. Although it is considered most bandwidth efficient, puncturing URLLC data on eMBB can lead to degradation of eMBB’s performance. Most of the state-of-the-art research addressing this problem employ raw eMBB data throughput as performance metric. This is inadequate as, after puncturing, eMBB data may or may not be successfully decoded at its receiver. This paper presents Cyrus+—a deep reinforcement learning (DRL)-based puncturing solution that employs goodput (through feedback from a receiver’s decoder), rather than estimated raw throughput, in its design of reward function. Further, Cyrus+ is tailored specifically for the Open RAN (O-RAN) architecture and fully leverages O-RAN’s three control loops at different time scales in its design of DRL. In the Non-Real-Time (Non-RT) RAN Intelligent Controller (RIC), Cyrus+ initializes the policy network that will be used in the RT Open Distributed Unit (O-DU). In the Near-RT RIC, Cyrus+ refines the policy based on dynamic network conditions and feedback from the receivers. In the RT O-DU, Cyrus+ generates a puncturing codebook by considering all possible URLLC arrivals. We build a standard-compliant link-level 5G NR simulator to demonstrate the efficacy of Cyrus+. Experimental results show that Cyrus+ outperforms benchmark puncturing algorithms and meets the stringent timing requirement in 5G NR (numerology 3).","2831-316X","","10.1109/TMLCN.2025.3618815","NSF Grant(grant numbers:CNS-2312447); Office of Naval Research (ONR) Multidisciplinary University Research Initiative (MURI) Grant(grant numbers:N00014-19-1-2621); Virginia Commonwealth Cyber Initiative (CCI); Virginia Tech Institute for Critical Technology and Applied Science (ICTAS); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11195824","5G NR;multiplexing;eMBB;URLLC;puncturing;O-RAN;real time;deep reinforcement learning;soft actor-critic","Ultra reliable low latency communication;Mathematical models;Open RAN;Multiplexing;Throughput;Receivers;Communication channels;Decoding;Bandwidth;Timing","","","","42","CCBY","7 Oct 2025","","","IEEE","IEEE Journals"
"Scalable Nanophotonic-Electronic Spiking Neural Networks","L. E. Srouji; Y. -J. Lee; M. B. On; L. Zhang; S. J. B. Yoo","Electrical and Computer Engineering, University of California Davis, Davis, CA, USA; Electrical and Computer Engineering, University of California Davis, Davis, CA, USA; Electrical and Computer Engineering, University of California Davis, Davis, CA, USA; Electrical and Computer Engineering, University of California Davis, Davis, CA, USA; Electrical and Computer Engineering, University of California Davis, Davis, CA, USA",IEEE Journal of Selected Topics in Quantum Electronics,"3 Nov 2022","2023","29","2: Optical Computing","1","13","Spiking neural networks (SNN) provide a new computational paradigm capable of highly parallelized, real-time processing. Photonic devices are ideal for the design of high-bandwidth, parallel architectures matching the SNN computational paradigm. Furthermore, the co-integration of CMOS and photonic elements combineslow-loss photonic devices with analog electronics for greater flexibility of nonlinear computational elements. We designed and simulated an optoelectronic spiking neuron circuit on a monolithic silicon photonics (SiPh) process that replicates useful spiking behaviors beyond the leaky integrate-and-fire (LIF). Additionally, we explored two learning algorithms with the potential for on-chip learning using Mach-Zehnder Interferometric (MZI) meshes as synaptic interconnects. A variation of Random Backpropagation (RPB) was experimentally demonstrated on-chip and matched the performance of a standard linear regression on a simple classification task. In addition, we applied the Contrastive Hebbian Learning (CHL) rule to a simulated neural network composed of MZI meshes for a random input-output mapping task. The CHL-trained MZI network performed better than random guessing but did not match the performance of the ideal neural network (without the constraints imposed by the MZI meshes). Through these efforts, we demonstrate that co-integrated CMOS and SiPh technologies are well-suited to the design of scalable SNN computing architectures.","1558-4542","","10.1109/JSTQE.2022.3217011","Air Force Office of Scientific Research(grant numbers:FA9550-181-1-0186); Office of the Director of National Intelligence(grant numbers:2021-21090200004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9928320","Neuromorphic computing;spiking neural networks;nanophotonics;photonic integrated circuits;silicon photonics","Neurons;Photonics;Behavioral sciences;Biology;Wavelength division multiplexing;Optical network units;Neural networks","","9","","82","CCBY","25 Oct 2022","","","IEEE","IEEE Journals"
"An Interpretable Deep Actor–Critic Framework for Automated Propofol Dosing During General Anesthesia","D. Zhang; F. Wang","Guangdong Medical University, Zhanjiang, China; Guangdong Medical University, Zhanjiang, China",IEEE Access,"12 Sep 2025","2025","13","","157175","157190","Administering general anesthesia demands anesthesiologists to concurrently regulate various physiological functions, often under time-critical conditions. The automation of hypnotic drug delivery offers the potential to enhance precision in maintaining optimal sedation levels while allowing clinicians to focus on more complex intraoperative decisions. In this study, we propose a reinforcement learning (RL) framework to guide the real-time administration of propofol, a widely used anesthetic agent. Building upon earlier discrete-action approaches, our model adopts a continuous-action actor-critic architecture. It incorporates a policy network that generates a continuous probability distribution over infusion rates based on dynamic anesthetic state observations, along with a value network that evaluates the desirability of those states. The RL agent is trained on synthetic patient simulations derived from pharmacokinetic and pharmacodynamic (PK/PD) models with randomized parameter sets to ensure robustness across diverse patient profiles. We examine three distinct reward formulations tailored to different clinical objectives and evaluate agent performance in both simulated scenarios and retrospective clinical data from nine surgical cases. To enhance transparency and support clinical adoption, we apply Shapley Additive Explanations (SHAP) to interpret the agent’s dosing rationale. The analysis revealed that dosing decisions were primarily influenced by the level of unconsciousness (LoU) error and predicted effect-site concentration, with LoU target dominating steady-state control. These clinically consistent patterns demonstrate that the agent’s recommendations align with established pharmacological principles, thereby improving clinician trust and interpretability. Experimental results demonstrate that the proposed RL agent surpasses traditional PID controllers in maintaining target sedation levels and aligns closely with anesthesiologist-administered dosages in real cases. This work represents a novel advancement in automated anesthesia control, showcasing the adaptability of reward functions and the integration of interpretability tools to support the development of clinically relevant AI-based drug delivery system.","2169-3536","","10.1109/ACCESS.2025.3605643","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11147164","Automated anesthesia;propofol dosing;reinforcement learning;actor–critic framework;continuous drug infusion;pharmacokinetic/pharmacodynamic modeling;clinical decision support;SHAP interpretability;personalized anesthesia control;synthetic patient simulation","Anesthesia;Drugs;Brain modeling;Biomedical monitoring;Pharmacokinetics;Monitoring;Mathematical models;Surgery;Real-time systems;Pharmacodynamics","","","","52","CCBY","3 Sep 2025","","","IEEE","IEEE Journals"
"Deep Reinforcement Learning-Based Scheduling for Multiband Massive MIMO","V. H. L. Lopes; C. V. Nahum; R. M. Dreifuerst; P. Batista; A. Klautau; K. V. Cardoso; R. W. Heath","Institute of Informatics, Federal University of Goiás, Goiânia, Brazil; Department of Computer and Telecommunication Engineering, Federal University of Pará, Belém, Brazil; Wireless Networking and Communications Group, The University of Texas at Austin, Austin, TX, USA; Ericsson Research, Stockholm, Sweden; Department of Computer and Telecommunication Engineering, Federal University of Pará, Belém, Brazil; Institute of Informatics, Federal University of Goiás, Goiânia, Brazil; Department of Electronics and Computer Engineering, North Carolina State University, Raleigh, NC, USA",IEEE Access,"6 Dec 2022","2022","10","","125509","125525","Fifth-generation (5G) cellular communication systems have embraced massive multiple-input-multiple-output (MIMO) in the low- and mid-band frequencies. In a multiband system, the base station can serve different users in each band, while the user equipment can operate only in a single band simultaneously. This paper considers a massive MIMO system where channels are dynamically allocated in different frequency bands. We treat multiband massive MIMO as a scheduling and resource allocation problem and propose deep reinforcement learning (DRL) agents to perform user scheduling. The DRL agents use buffer and channel information to compose their observation space, and the agent’s reward function maximizes the transmitted throughput and minimizes the packet loss rate. We compare the proposed DRL algorithms with traditional baselines, such as maximum throughput and proportional fairness. The results show that the DRL models outperformed baselines obtaining a 20% higher network sum rate and an 84% smaller packet loss rate. Moreover, we compare different DRL algorithms focusing on training time to assess the online implementation of the DRL agents, showing that the best agent needs about 50K training steps to converge.","2169-3536","","10.1109/ACCESS.2022.3224808","Innovation Center, Ericsson Telecom. S.A., Brazil; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9963967","Multiband scheduling;MIMO;DRL-based scheduling;mmWave","Optimization;Massive MIMO;Resource management;Throughput;Observability;Training;Computer architecture;Millimeter wave communication","","8","","72","CCBY","24 Nov 2022","","","IEEE","IEEE Journals"
"Distributed Probabilistic Fuzzy Rule Mining for Clinical Decision Making","S. Sharif; M. -R. Akbarzadeh-T","Department of Computer Engineering, Center of Excellence on Soft Computing and Intelligent Information Processing, Ferdowsi University of Mashhad, Mashhad, Iran; Department of Computer Engineering, Center of Excellence on Soft Computing and Intelligent Information Processing, Ferdowsi University of Mashhad, Mashhad, Iran",Fuzzy Information and Engineering,"22 Mar 2024","2021","13","4","436","459","INTRODUCTION: With the growing size, complexity, and distributivity of databases, efficiency and scalability have become highly desirable attributes of data mining algorithms in decision support systems. OBJECTIVES: This study aims for a computational framework for clinical decision support systems that can handle inconsistent dataset while also being interpretable and scalable. METHODS: This paper proposes a Distributed Probabilistic Fuzzy Rule Mining (DPFRM) algorithm that extracts probabilistic fuzzy rules from numerical data using a self-organizing multi-agent approach. This agent-based method provides better scalability and fewer rules through agent interactions and rule-sharing. RESULTS: The performance of the proposed approach is investigated on several UCI medical datasets. The DPFRM is also used for predicting the mortality rate of burn patients. Statistical analysis confirms that the DPFRM significantly improves burn mortality prediction by at least 3%. Also, the training time is improved by 17% if implemented by a parallel computer. However, this speedup decreases with increased distributivity, due to the added communication overhead. CONCLUSION: The proposed approach can improve the accuracy of decision making by better handling of inconsistencies within the datasets. Furthermore, noise sensitivity analysis demonstrates that the DPFRM deteriorates more robustly as the noise levels increase.","1616-8666","","10.1080/16168658.2021.1978803","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10478230","Multi-agent systems;probabilistic fuzzy logic;distributed decision making;self-organization;rule extraction;clinical decision support systems","Decision support systems;Training;Uncertainty;Statistical analysis;Sensitivity analysis;Scalability;Distributed databases","","","","61","","22 Mar 2024","","","TUP","TUP Journals"
"PolyVerif: An Open-Source Environment for Autonomous Vehicle Validation and Verification Research Acceleration","R. Razdan; M. İ. Akbaş; R. Sell; M. Bellone; M. Menase; M. Malayjerdi","Florida Polytechnic University, Lakeland, FL, USA; Department of Electrical Engineering and Computer Science, Embry-Riddle Aeronautical University, Daytona Beach, FL, USA; Department of Mechanical and Industrial Engineering, Tallinn University of Technology, Tallinn, Estonia; FinEst Smart City Centre of Excellence, Tallinn University of Technology, Tallinn, Estonia; Acclivis Technologies Pvt. Ltd., Maharashtra, Pune, India; Department of Mechanical and Industrial Engineering, Tallinn University of Technology, Tallinn, Estonia",IEEE Access,"27 Mar 2023","2023","11","","28343","28354","Validation and Verification (V&V) of Artificial Intelligence (AI) based cyber physical systems such as Autonomous Vehicles (AVs) is currently a vexing and unsolved problem. AVs integrate subsystems in areas such as detection, sensor fusion, localization, perception, and path planning. Each of these subsystems contains significant AI content integrated with traditional hardware and software components. The complexity for validating even a subsystem is daunting and the task of validating the whole system is nearly impossible. Fundamental research in advancing the state-of-the-art for AV V&V is required. However, for V&V researchers, it is exceedingly difficult to make progress because of the massive infrastructure requirements to demonstrate the viability of any solution. This paper presents PolyVerif, the world’s first open-source solution focused on V&V researchers with the objective of accelerating the state-of-the-art for AV V&V research. PolyVerif provides an AI design and verification framework consisting of a digital twin creation process, an open-source AV engine, access to several open-source physics based simulators, and open-source symbolic test generation engines. PolyVerif’s objective is to arm V&V researchers with a framework which extends the state-of-the-art on any one of the many major axes of interest and use the remainder of the infrastructure to quickly demonstrate the viability of their solution. Given its open-source nature, researchers can also contribute their innovations to the project. Using this critical property of open-source environments, the innovation rate of the whole research community to solve these vexing issues can be greatly accelerated. Finally, the paper also presents results from several projects which have used PolyVerif.","2169-3536","","10.1109/ACCESS.2023.3258681","European Union’s Horizon 2020 Research and Innovation Program(grant numbers:856602); European Regional Development Fund, co- funded by the Estonian Ministry of Education and Research(grant numbers:2014-2020.4.01.20-0289); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10075634","Autonomous vehicles;validation and verification;modeling and simulation;artificial intelligence","Software engineering;Artificial intelligence;Software algorithms;Inference algorithms;Autonomous vehicles;Hardware;System analysis and design","","18","","44","CCBYNCND","17 Mar 2023","","","IEEE","IEEE Journals"
"Radiation-Hardened—AI-Accelerated Custom IC Design Methodology","V. Gogolou; S. Karipidis; E. Papageorgiou; A. Michailidis; T. Noulis","Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki, Greece; Physics Department, Aristotle University of Thessaloniki, Thessaloniki, Greece; Physics Department, Aristotle University of Thessaloniki, Thessaloniki, Greece; Physics Department, Aristotle University of Thessaloniki, Thessaloniki, Greece; Physics Department, Aristotle University of Thessaloniki, Thessaloniki, Greece",IEEE Access,"3 Jun 2025","2025","13","","93869","93882","In this work, a radiation hardened - AI accelerated custom IC design methodology is proposed. The methodology employs reinforcement learning (RL) to optimize the IC design process, integrating radiation dosage performance degradation assessments and radiation-hardened-by-design (RHBD) MOSFET cell implementations at both schematic and layout levels. This approach streamlines the development of radiation-immune silicon products by embedding artificial intelligence to accelerate the design process and advanced radiation hardening strategies directly into the standard design flow. To validate the proposed framework, a charge-sensitive amplifier (CSA) based on a folded-cascode architecture is designed and assessed in a 180 nm standard CMOS process, demonstrating the efficiency of the methodology in radiation-resilient analog front-end systems.","2169-3536","","10.1109/ACCESS.2025.3574058","Deutscher Akademischer Austauschdienst (DAAD)-Projekt Radiation-Hard Integrated Circuits Educational Platform “RADHARD,”; Federal Foreign Office and German Academic Exchange Service (Deutscher Akademischer Austauschdienst) in the framework of the “Hochschulpartnerschaftenmit Griechenland 2023–2025” Action(grant numbers:57647733); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11015949","Radiation hardened;reinforcement learning;design methodology;enclosed layout transistor;post radiation modeling;charge sensitive amplifier","Radiation hardening (electronics);Layout;Transistors;Standards;Capacitance;MOSFET;Reinforcement learning;Integrated circuit modeling;Integrated circuit reliability;Computer architecture","","","","34","CCBY","27 May 2025","","","IEEE","IEEE Journals"
"Low-Carbon Economic Dispatch of Electricity-Heat-Gas Integrated Energy Systems Based on Deep Reinforcement Learning","Y. Zhang; Y. Han; D. Liu; X. Dong","School of Electrical Engineering, Shenyang University of Technology, Shenyang, China; School of Electrical Engineering, Shenyang University of Technology, Shenyang, China; School of Electrical Engineering, Shenyang University of Technology, Shenyang, China; Beijing Ke Dong Co., Ltd., NARI Group Corporation, Beijing, China",Journal of Modern Power Systems and Clean Energy,"22 Nov 2023","2023","11","6","1827","1841","The optimal dispatch methods of integrated energy systems (IESs) currently struggle to address the uncertainties resulting from renewable energy generation and energy demand. Moreover, the increasing intensity of the greenhouse effect renders the reduction of IES carbon emissions a priority. To address these issues, a deep reinforcement learning (DRL)-based method is proposed to optimize the low-carbon economic dispatch model of an electricity-heat-gas IES. In the DRL framework, the optimal dispatch model of the IES is formulated as a Markov decision process (MDP). A reward function based on the reward-penalty ladder-type carbon trading mechanism (RPLT-CTM) is introduced to enable the DRL agents to learn more effective dispatch strategies. Moreover, a distributed proximal policy optimization (DPPO) algorithm, which is a novel policy-based DRL algorithm, is employed to train the DRL agents. The multithreaded architecture enhances the exploration ability of the DRL agents in complex environments. Experimental results illustrate that the proposed DPPO-based IES dispatch method can mitigate carbon emissions and reduce the total economic cost. The RPLT-CTM-based reward function outperforms the CTM-based methods, providing a 4.42% and 6.41% decrease in operating cost and carbon emission, respectively. Furthermore, the superiority and computational efficiency of DPPO compared with other DRL-based methods are demonstrated by a decrease of more than 1.53% and 3.23% in the operating cost and carbon emissions of the IES, respectively.","2196-5420","","10.35833/MPCE.2022.000671","National Natural Science Foundation of China(grant numbers:61102124); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10113803","Integrated energy system (IES);carbon trading;optimal dispatch;deep reinforcement learning (DRL);distributed proximal policy optimization","Uncertainty;Carbon dioxide;Economics;Costs;Optimal scheduling;Renewable energy sources;Emissions trading","","18","","49","","1 May 2023","","","SGEPRI","SGEPRI Journals"
"QACM: QoS-Aware xApp Conflict Mitigation in Open RAN","A. Wadud; F. Golpayegani; N. Afraz","School of Computer Science, University College Dublin, Dublin, Ireland; School of Computer Science, University College Dublin, Dublin, Ireland; Bangladesh Institute of Governance and Management, Dhaka, Bangladesh",IEEE Transactions on Green Communications and Networking,"28 Aug 2024","2024","8","3","978","993","The advent of Open Radio Access Network (RAN) has revolutionized the field of RAN by introducing elements of native support of intelligence and openness into the next generation of mobile network infrastructure. Open RAN paves the way for standardized interfaces and enables the integration of network applications from diverse vendors, thereby enhancing network management flexibility. However, control decision conflicts occur when components from different vendors are deployed together. This article provides an overview of various types of conflicts that may occur in Open RAN, with a particular focus on intra-component conflict mitigation among Extended Applications (xApps) in the Near Real Time RAN Intelligent Controller (Near-RT-RIC). A QoS-Aware Conflict Mitigation (QACM) method is proposed that finds the optimal configuration of conflicting parameters while maximizing the number of xApps that have their Quality of Service (QoS) requirements met. We compare the performance of the proposed QACM method with two benchmark methods for priority and non-priority cases. The results indicate that our proposed method is the most effective in maintaining QoS requirements for conflicting xApps.","2473-2400","","10.1109/TGCN.2024.3431945","European Union’s Horizon Europe Research and Innovation Program through the Marie Skłodowska- Curie SE(grant numbers:RE-ROUTE 101086343); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10608140","Open RAN;conflict mitigation;QoS;xApp;Near-RT-RIC","Open RAN;Prevention and mitigation;Quality of service;Radio access networks;Benchmark testing;Computer architecture","","4","","25","CCBY","24 Jul 2024","","","IEEE","IEEE Journals"
"Adaptive deep reinforcement learning-based secure transmission mechanism for underwater wireless sensor networks","X. Liu; H. Wang; F. Mao; S. Wu","Graduate Student studying in the School of Physics and Information Engineering at Minnan Normal University in Fujian, China; Graduate Student studying in the School of Physics and Information Engineering at Minnan Normal University in Fujian, China; Graduate Student studying in the School of Physics and Information Engineering at Minnan Normal University in Fujian, China; School of Information and Electronic Engineering, Liming Vocational University, Quanzhou 362000, China",IEICE Transactions on Communications,"","2025","PP","99","1","12","To address the security challenges of underwater wireless sensor networks (UWSNs) in complex and hostile environments, this paper investigates the physical-layer secrecy performance of the transmitter-receiver link, with particular emphasis on transmission optimization under eavesdropping threats. We formulate a non-linear, non-convex optimization problem that jointly allocates sub-channels and transmission power to maximize the secrecy rate while considering the inherent constraints of underwater acoustic communication. To efficiently solve this problem, we develop a deep reinforcement learning (DRL)-based resource allocation algorithm that integrates a prioritized experience replay mechanism, thereby enhancing learning efficiency and improving optimization performance. Extensive simulations are conducted to assess the convergence and adaptability of the proposed method under varying node densities and maximum transmission power levels. The results demonstrate that the proposed algorithm consistently achieves higher system security, greater stability, and faster convergence compared to several benchmark schemes.","1745-1345","","10.23919/transcom.2025EBP3068","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11207124","underwater wireless sensor networks;multi-agent reinforcement learning;dueling network architecture;resource allocation;physical layer security","Security;Eavesdropping;Interference;Optimization;Signal to noise ratio;Physical layer security;Mobile nodes;Wireless sensor networks;Underwater communication;Underwater acoustics","","","","","","17 Oct 2025","","","IEICE","IEICE Early Access Articles"
"Autonomous Cooperative Multi-Vehicle System for Interception of Aerial and Stationary Targets","L. A. Tony; S. Jana; V. P. Varun; A. A. Bhise; S. A. M. Varman; B. V. Vidyadhara; M. S. Gadde; R. Krishnapuram; D. Ghose","Guidance, Control, and Decision Systems Laboratory (GCDSL), Department of Aerospace Engineering, Indian Institute of Science, Bangalore-560012, India; Guidance, Control, and Decision Systems Laboratory (GCDSL), Department of Aerospace Engineering, Indian Institute of Science, Bangalore-560012, India; Robert Bosch Center for Cyber-Physical Systems, Indian Institute of Science, Bangalore-560012, India; Guidance, Control, and Decision Systems Laboratory (GCDSL), Department of Aerospace Engineering, Indian Institute of Science, Bangalore-560012, India; Robert Bosch Center for Cyber-Physical Systems, Indian Institute of Science, Bangalore-560012, India; Guidance, Control, and Decision Systems Laboratory (GCDSL), Department of Aerospace Engineering, Indian Institute of Science, Bangalore-560012, India; Guidance, Control, and Decision Systems Laboratory (GCDSL), Department of Aerospace Engineering, Indian Institute of Science, Bangalore-560012, India; Robert Bosch Center for Cyber-Physical Systems, Indian Institute of Science, Bangalore-560012, India; Guidance, Control, and Decision Systems Laboratory (GCDSL), Department of Aerospace Engineering, Indian Institute of Science, Bangalore-560012, India",Field Robotics,"25 Feb 2025","2022","2","","107","146","This paper presents the design, development, and testing of hardware-software systems by the IISc-TCS team for Challenge 1 of the Mohamed Bin Zayed International Robotics Challenge 2020. The goal of Challenge 1 was to grab a ball suspended from a maneuvering UAV and pop balloons anchored to the ground, using suitable manipulators. The important tasks carried out to address this challenge include the design and development of a hardware system with efficient grabbing and popping mechanisms, considering the restrictions in volume and payload, design of accurate target interception algorithms using visual information suitable for outdoor environments, and development of a software architecture for dynamic, multi-agent, aerial systems performing complex tasks. In this paper, we discuss the design of a custom end-effector mounted on a single degree of freedom manipulator, and robust algorithms for the interception of targets in an uncertain environment. Vision-based guidance and tracking strategies are developed based on the concept of pursuit engagement and artificial potential function. The software architecture presented in this work develops an Operation Management System (OMS) architecture that allocates static and dynamic tasks collaboratively among multiple UAVs to perform any given task. An important aspect of this work is that all the systems developed were designed to operate in completely autonomous mode. A detailed description of the architecture along with simulations of complete challenge in the Gazebo environment and field experiment results are also included in this work. The developed hardware-software system is useful for counter-UAV systems and can be used for other applications.","2771-3989","","10.55417/fr.2022005","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10876028","cooperative robots;computer vision;motion planning;obstacle avoidance;planning","Autonomous aerial vehicles;Target tracking;Visualization;Robots;Software algorithms;Heuristic algorithms;Hardware;Software architecture;Manipulator dynamics;Feature extraction","","1","","","CCBY","25 Feb 2025","","","FRPS","FRPS Journals"
"Incorporating Online Learning Into MCTS-Based Intention Progression","C. Song; Y. Yao; S. Chan","School of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; School of Computer Science, University of Nottingham Ningbo China, Ningbo, China; School of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China",IEEE Access,"25 Apr 2024","2024","12","","56400","56413","Agents have been applied to a wide variety of fields, including power systems and spacecraft. Belief-Desire-Intention (BDI) agents, as one of the most widely used and researched architectures, have the advantage of being able to pursue multiple goals in parallel. The problem of deciding “what to do” next at each of the agent’s deliberation cycle is therefore critical for BDI agents, which is defined as the intention progression problem (IPP). Among all existing approaches to IPP, the majority of approaches have overlooked the significance of runtime historical data, thereby limiting the adaptability and decision-making capabilities of agents. In this paper, we propose to incorporate online learning into the current state-of-the-art intention progression approach  $S_{A}$  to overcome the above limitations. This approach not only prevents  $S_{A}$  from consuming computational resources on ineffective and inefficient simulations, but also significantly improves the execution efficiency of the agent. Especially when dealing with large-scale problem domains, this improvement significantly enhances the planning capability of the agents. In particular, we have proposed the  $SA_{Q}$  and  $SA_{L}$  schedulers, both of which can learn how to generate “reasonable” rollouts during the simulation phase of MCTS based on historical simulation data at run time. We compare the performance of our approach with the state-of-the-art  $S_{A}$  in a range of scenarios of increasing difficulty. The results demonstrate that our approaches outperform  $S_{A}$ , both in terms of the number of goals achieved and the computational overhead required.","2169-3536","","10.1109/ACCESS.2024.3390796","National Natural Science Foundation of China(grant numbers:61906168); Zhejiang Provincial Natural Science Foundation of China(grant numbers:LY23F020023); Yongjiang Talent Introduction Program(grant numbers:2022A-234-G); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10504897","BDI agents;intention progression problem;Monte-Carlo tree search;online learning","Simulation;Monte Carlo methods;Decision making;Maintenance;Computational modeling;Taxonomy;Search problems;Electronic learning","","1","","40","CCBYNCND","18 Apr 2024","","","IEEE","IEEE Journals"
"RL-RTree: A Reinforcement Learning-Optimized Dynamic R-Tree for High-Dimensional Spatial Indexing","Y. Peng","School of Mathematics and Computer Application, Shangluo University, Shangluo, China",IEEE Access,"8 Jul 2025","2025","13","","114346","114355","Spatial indexing in high-dimensional dynamic environments faces critical challenges, including the curse of dimensionality and rapid distribution shifts, which degrade the performance of traditional indexes like R*-trees and static learned indexes. We propose RL-RTree, a dynamic R-tree optimization method that integrates Spatial Graph Attention Networks (SGAT) for density-aware embeddings and online reinforcement learning (RL) to adjust query strategies in real-time. The hybrid offline-online architecture decouples embedding learning from runtime policy optimization. Experiments on 10- to 100-dimensional data show that RL-RTree improves query speed by 75.2% and accuracy by 14.3% compared to R*-trees. For dynamic scenarios, it achieves  $3.7\times $  faster recovery than static indexes and maintains 91.3% accuracy under high noise ( $\sigma =0.5$ ). This work bridges the gap between learning-based indexing and real-time adaptive systems, enabling sub-second updates for mission-critical applications like autonomous vehicles and recommendation engines. The interpretable RL policies and SGAT embeddings set a new paradigm for robust high-dimensional indexing.","2169-3536","","10.1109/ACCESS.2025.3583701","Shaanxi Provincial Department of Education Scientific Research Program(grant numbers:24JK0421); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11053811","RL-RTree;dynamic;spatial indexing","Spatial indexes;Optimization;Vehicle dynamics;Real-time systems;Indexing;Adaptation models;Reinforcement learning;Accuracy;Faces;Semantics","","","","22","CCBYNCND","27 Jun 2025","","","IEEE","IEEE Journals"
"Interpretable Machine Learning for Characterization of Focal Liver Lesions by Contrast-Enhanced Ultrasound","S. Turco; T. Tiyarattanachai; K. Ebrahimkheil; J. Eisenbrey; A. Kamaya; M. Mischi; A. Lyshchik; A. E. Kaffas","Department of Electrical Engineering, Eindhoven University of Technology, Eindhoven, AZ, The Netherlands; Department of Radiology, Stanford Medicine, Stanford, CA, USA; Department of Electrical Engineering, Eindhoven University of Technology, Eindhoven, AZ, The Netherlands; Department of Radiology, Thomas Jefferson University, Philadelphia, PA, USA; Department of Radiology, Stanford Medicine, Stanford, CA, USA; Department of Electrical Engineering, Eindhoven University of Technology, Eindhoven, AZ, The Netherlands; Department of Radiology, Thomas Jefferson University, Philadelphia, PA, USA; Department of Radiology, Stanford Medicine, Stanford, CA, USA","IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control","27 Apr 2022","2022","69","5","1670","1681","This work proposes an interpretable radiomics approach to differentiate between malignant and benign focal liver lesions (FLLs) on contrast-enhanced ultrasound (CEUS). Although CEUS has shown promise for differential FLLs diagnosis, current clinical assessment is performed only by qualitative analysis of the contrast enhancement patterns. Quantitative analysis is often hampered by the unavoidable presence of motion artifacts and by the complex, spatiotemporal nature of liver contrast enhancement, consisting of multiple, overlapping vascular phases. To fully exploit the wealth of information in CEUS, while coping with these challenges, here we propose combining features extracted by the temporal and spatiotemporal analysis in the arterial phase enhancement with spatial features extracted by texture analysis at different time points. Using the extracted features as input, several machine learning classifiers are optimized to achieve semiautomatic FLLs characterization, for which there is no need for motion compensation and the only manual input required is the location of a suspicious lesion. Clinical validation on 87 FLLs from 72 patients at risk for hepatocellular carcinoma (HCC) showed promising performance, achieving a balanced accuracy of 0.84 in the distinction between benign and malignant lesions. Analysis of feature relevance demonstrates that a combination of spatiotemporal and texture features is needed to achieve the best performance. Interpretation of the most relevant features suggests that aspects related to microvascular perfusion and the microvascular architecture, together with the spatial enhancement characteristics at wash-in and peak enhancement, are important to aid the accurate characterization of FLLs.","1525-8955","","10.1109/TUFFC.2022.3161719","NIH/NCI(grant numbers:R01 CA215520); Hanarth Fonds Fellowship for AI in Oncology; KNAW Van Leersum Grant; 4TU Precision Medicine Program, High Tech for a Sustainable Future; Universities of Technology of the Netherlands; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9740202","Medical imaging;medical signal and image processing;medical tissue characterization;ultrasound (US) contrast agents","Feature extraction;Lesions;Cancer;Frequency locked loops;Liver;Ultrasonic imaging;Spatiotemporal phenomena","Carcinoma, Hepatocellular;Contrast Media;Humans;Liver;Liver Neoplasms;Machine Learning;Sensitivity and Specificity;Ultrasonography","32","","59","CCBY","23 Mar 2022","","","IEEE","IEEE Journals"
"RegimeFolio: A Regime Aware ML System for Sectoral Portfolio Optimization in Dynamic Markets","Y. Zhang; D. Goel; H. Ahmad; C. Szabo","The University of Adelaide, Adelaide, SA, Australia; CSIRO’s Data61, Melbourne, VIC, Australia; The University of Adelaide, Adelaide, SA, Australia; The University of Adelaide, Adelaide, SA, Australia",IEEE Access,"31 Oct 2025","2025","13","","184722","184744","Financial markets are inherently non-stationary, with shifting volatility regimes that alter asset co-movements and return distributions. Standard portfolio optimization methods, typically built on stationarity or regime-agnostic assumptions, struggle to adapt to such changes. To address these challenges, we propose RegimeFolio, a novel regime-aware and sector-specialized framework that, unlike existing regime-agnostic models (e.g., DeepVol, DRL optimizers), integrates explicit volatility regime segmentation with sector-specific ensemble forecasting and adaptive mean–variance allocation. This modular architecture ensures forecasts and portfolio decisions remain aligned with current market conditions, enhancing robustness and interpretability in dynamic markets. RegimeFolio combines three components: i) an interpretable VIX-based classifier for market regime detection; ii) regime and sector-specific ensemble learners (Random Forest, Gradient Boosting) to capture conditional return structures; and iii) a dynamic mean–variance optimizer with shrinkage-regularized covariance estimates for regime-aware allocation. We evaluate RegimeFolio on 34 large cap U.S. equities from 2020 to 2024. The framework achieves a annualized return of 25.1%, a Sharpe ratio of 1.17, a 12% lower maximum drawdown, and a 15–20% improvement in forecast accuracy compared to conventional and advanced machine learning benchmarks. These results show that explicitly modeling volatility regimes in predictive learning and portfolio allocation enhances robustness and leads to more dependable decision-making in real markets.","2169-3536","","10.1109/ACCESS.2025.3624822","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11215751","Cross-sectoral analysis;dynamic allocation;machine learning;market volatility;portfolio optimization;regime switching;VIX","Portfolios;Resource management;Optimization;Predictive models;Forecasting;Biological system modeling;Dynamic scheduling;Machine learning;Adaptation models;Robustness","","","","40","CCBY","23 Oct 2025","","","IEEE","IEEE Journals"
"Malignancy Detection in Lung and Colon Histopathology Images Using Transfer Learning With Class Selective Image Processing","S. Mehmood; T. M. Ghazal; M. A. Khan; M. Zubair; M. T. Naseem; T. Faiz; M. Ahmad","Faculty of Computing, Riphah School of Computing and Innovation, Riphah International University, Lahore Campus, Lahore, Pakistan; Center for Cyber Security, Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia (UKM), Bangi, Selangor, Malaysia; Faculty of Computing, Riphah School of Computing and Innovation, Riphah International University, Lahore Campus, Lahore, Pakistan; Faculty of Computing, Riphah International University, Islamabad, Pakistan; Faculty of Computing, Riphah School of Computing and Innovation, Riphah International University, Lahore Campus, Lahore, Pakistan; School of Information Technology, Skyline University College, University City of Sharjah, Al Sharjah, United Arab Emirates; School of Computer Science, National College of Business Administration and Economics, Lahore, Pakistan",IEEE Access,"11 Mar 2022","2022","10","","25657","25668","Cancer accounts for a huge mortality rate due to its aggressiveness, colossal potential of metastasis, and heterogeneity (causing resistance against chemotherapy). Lung and colon cancers are among the most prevalent types of cancer around the globe that can occur in both males and females. Early and accurate diagnosis of these cancers can substantially improve the quality of treatment as well as the survival rate of cancer patients. We propose a highly accurate and computationally efficient model for the swift and accurate diagnosis of lung and colon cancers as an alternative to current cancer detection methods. In this study, a large dataset of lung and colon histopathology images was employed for training and the validation process. The dataset is comprised of 25000 histopathology images of lung and colon tissues equally divided into 5 classes. A pretrained neural network (AlexNet) was tuned by modifying the four of its layers before training it on the dataset. Initial classification results were promising for all classes of images except for one class with an overall accuracy of 89%. To improve the overall accuracy and keep the model computationally efficient, instead of implementing image enhancement techniques on the entire dataset, the quality of images of the underperforming class was improved by applying a contrast enhancement technique which is fairly simple and efficient. The implementation of the proposed methodology has not only improved the overall accuracy from 89% to 98.4% but has also proved computationally efficient.","2169-3536","","10.1109/ACCESS.2022.3150924","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9709814","Colon cancer;convolutional neural networks;histopathology;image processing;lung cancer;transfer learning","Cancer;Lung;Colon;Feature extraction;Convolutional neural networks;Computed tomography;Histopathology","","205","","39","CCBY","10 Feb 2022","","","IEEE","IEEE Journals"
"Saving Energy and Spectrum in Enabling URLLC Services: A Scalable RL Solution","M. Ganjalizadeh; H. S. Ghadikolaei; A. Azari; A. Alabbasi; M. Petrova","School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden; Ericsson Research, Ericsson AB, Stockholm, Sweden; Ericsson Research, Ericsson AB, Stockholm, Sweden; Ericsson Research, Ericsson AB, Stockholm, Sweden; School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden",IEEE Transactions on Industrial Informatics,"11 Aug 2023","2023","19","10","10265","10276","Communication systems supporting cyber-physical production applications should satisfy stringent delay and reliability requirements. Diversity techniques and power control are the main approaches to reduce latency and enhance the reliability of wireless communications at the expense of redundant transmissions and excessive resource usage. Focusing on the application layer reliability key performance indicators (KPIs), we design a deep reinforcement learning orchestrator for power control and hybrid automatic repeat request retransmissions to optimize these KPIs. Furthermore, to address the scalability issue that emerges in the per-device orchestration problem, we develop a new branching soft actor–critic framework, in which a separate branch represents the action space of each industrial device. Our orchestrator enables near-real-time control and can be implemented in the edge cloud. We test our solution with a Third Generation Partnership Project-compliant and realistic simulator for factory automation scenarios. Compared with the state of the art, our solution offers significant scalability gains in terms of computational time and memory requirements. Our extensive experiments show significant improvements in our target KPIs, over the state of the art, especially for fifth percentile user availability. To achieve these targets, our framework requires substantially less total energy or spectrum, thanks to our scalable reinforcement learning solution.","1941-0050","","10.1109/TII.2023.3240592","Swedish Foundation for Strategic Research(grant numbers:iPhD:ID17-0079); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10032107","Availability;energy saving;factory automation;reinforcement learning (RL);reliability;soft actor–critic (SAC);ultrareliable low-latency communications (URLLC);5G","Reliability;Ultra reliable low latency communication;Delays;Power control;Computer architecture;5G mobile communication;Microprocessors","","8","","30","CCBY","30 Jan 2023","","","IEEE","IEEE Journals"
"Machiavellian Robots and Their Theory of Mind","A. Sgorbissa; L. Morocutti; I. D'Angelo; C. T. Recchiuto",NA; NA; NA; NA,IEEE Transactions on Affective Computing,"","2024","PP","99","1","18","The objective of this work is to develop and evaluate computational cognitive models of Theory of Mind (ToM) and Machiavellian behavior embedded in a humanoid robot. Machiavellianism, together with psychopathy and narcissism, is part of the Dark Triad (DT), three constructs that correspond to socially aversive yet not necessarily pathological personalities. The motivations of the present work are both theoretical and application-oriented. In the long term, we aim to: (i) Provide researchers with new insights into the Machiavellian as well as other DT constructs through simulated and robotic setups; (ii) Provide a tool to train psychologists to deal with social and antisocial behavior in a controlled setup; (iii) Help people become aware of the behavioral mechanisms that they may expect from people with DT traits in social and affective relationships; (iv) Assist robotic engineers in developing better robots by identifying behaviors that should be avoided. To this end, we explored a computational model of ToM in the popular Planning Domain Definition Language (PDDL), and defined a domain with the necessary elements to induce Machiavellian behavior during planning and execution. Subsequently, we implemented our computational model in a software architecture controlling the behavior of a humanoid robot and recorded videos of the robot interacting with two actors. Finally, we conducted experiments with 300 participants divided into 6 conditions to verify whether the implemented framework is versatile enough to generate behaviors that participants would rate as either more Machiavellian or less Machiavellian based on their observations of the recorded videos.","1949-3045","","10.1109/TAFFC.2024.3494595","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10747266","Robot personality;theory of mind","Robots;Computational modeling;Cognition;Ethics;Humanoid robots;Planning;Computer architecture;Videos;Robot sensing systems;Affective computing","","1","","","CCBY","7 Nov 2024","","","IEEE","IEEE Early Access Articles"
"DRL-Assisted Dynamic Subconnected Hybrid Precoding for Multi-Layer THz mMIMO-NOMA System","M. Shahjalal; M. H. Rahman; M. M. Alam; M. Z. Chowdhury; Y. M. Jang","Department of Electrical and Electronic Engineering, University of Liberal Arts Bangladesh, Dhaka, Bangladesh; Department of Electronics Engineering, Kookmin University, Seoul, South Korea; School of Electrical and Data Engineering, University of Technology Sydney, Sydney, NSW, Australia; Department of Electrical and Electronic Engineering, Khulna University of Engineering and Technology, Khulna, Bangladesh; Department of Electronics Engineering, Kookmin University, Seoul, South Korea",IEEE Transactions on Vehicular Technology,"18 Sep 2024","2024","73","9","12950","12961","Massive multiple-input multiple-output (mMIMO) techniques can be combined with the non-orthogonal multiple access (NOMA) scheme in terahertz (THz) communication to achieve multiplexing gains and satisfy the ultra-high capacity and massive connectivity requirements. However, the development of a near-optimal solution for energy and spectral efficiency problems in a dynamic wireless cellular environment remains challenging. In this paper, a cooperative THz mMIMO-NOMA enabled base station is established to optimize the power consumption and maximize the spectral efficiency. A multi-layer mMIMO antenna architecture is used to perform dynamic sub-connected hybrid precoding in each layer. The fuzzy c-means clustering algorithm is used to group densely located users into clusters to efficiently use the power coefficients. To optimize the power distribution constraints and coordination of the hybrid precoding structure, a multi-agent deep reinforcement learning algorithm is developed, which operates in a distributive manner. Each base station layer involves an agent that trains a deep Q-network, and optimal actions are executed by sharing exchangeable network parameters among layers. The simulation results indicate that the proposed scheme is able to learn the trade-off between maximization of the energy efficiency and overall system capacity.","1939-9359","","10.1109/TVT.2024.3385494","Institute of Information and communications Technology Planning and Evaluation(grant numbers:2022-0-00590); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10493846","Deep reinforcement learning (DRL);hybrid precoding;massive multiple-input multiple-output (mMIMO);non-orthogonal multiple access (NOMA);Terahertz (THz)","Terahertz communications;Antennas;Radio frequency;NOMA;Spectral efficiency;Wireless communication;Precoding","","1","","28","CCBY","8 Apr 2024","","","IEEE","IEEE Journals"
"IoT Vulnerability Assessment for Sustainable Computing: Threats, Current Solutions, and Open Challenges","P. Anand; Y. Singh; A. Selwal; M. Alazab; S. Tanwar; N. Kumar","Department of Computer Science and Information Technology, Central University of Jammu, Jammu, India; Department of Computer Science and Information Technology, Central University of Jammu, Jammu, India; Department of Computer Science and Information Technology, Central University of Jammu, Jammu, India; College of Engineering, IT & Environment, Charles Darwin University, Casuarina, Australia; Department of Computer Science and Engineering, Institute of Technology, Nirma University, Ahmadabad, India; Department of Computer Science Engineering, Thapar Institute of Engineering and Technology (Deemed to be University), Patiala, India",IEEE Access,"22 Sep 2020","2020","8","","168825","168853","Over the last few decades, sustainable computing has been widely used in areas like social computing, artificial intelligence-based agent systems, mobile computing, and Internet of Things (IoT). There are social, economic, and commercial impacts of IoT on human lives. However, IoT nodes are generally power-constrained with data transmission using an open channel, i.e., Internet which opens the gates for various types of attacks on them. In this context, several efforts are initiated to deal with the evolving security issues in IoT systems and make them self-sufficient to harvest energy for smooth functioning. Motivated by these facts, in this paper, we explore the evolving vulnerabilities in IoT devices. We provide a state-of-the-art survey that addresses multiple dimensions of the IoT realm. Moreover, we provide a general overview of IoT, Sustainable IoT, its architecture, and the Internet Engineering Task Force (IETF) protocol suite. Subsequently, we explore the open-source tools and datasets for the proliferation in research and growth of IoT. A detailed taxonomy of attacks associated with various vulnerabilities is also presented in the text. Then we have specifically focused on the IoT Vulnerability Assessment techniques followed by a case study on sustainability of Smart Agriculture. Finally, this paper outlines the emerging challenges related to IoT and its sustainability, and opening the doors for the beginners to start research in this promising area.","2169-3536","","10.1109/ACCESS.2020.3022842","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9189773","IoT;machine learning;sustainability;cyberattacks;vulnerabilities;security;privacy","Security;Protocols;Internet of Things;Computer architecture;Temperature sensors","","115","","214","CCBY","9 Sep 2020","","","IEEE","IEEE Journals"
"Toward Data Systems That Are Business Semantic Centric and AI Agents Assisted","C. Pang","School of Systems Science and Industrial Engineering, Binghamton University, State University of New York, Binghamton, NY, USA",IEEE Access,"8 Jul 2025","2025","13","","113752","113762","Contemporary businesses operate in dynamic environments requiring rapid adaptation to achieve goals and maintain competitiveness. Existing data platforms often fall short by emphasizing tools over alignment with business needs, resulting in inefficiencies and delays. To address this gap, I propose the Business Semantics Centric, AI Agents Assisted Data System (BSDS), a holistic system that integrates architecture, workflows, and team organization to ensure data systems are tailored to business priorities rather than dictated by technical constraints. BSDS redefines data systems as dynamic enablers of business success, transforming them from passive tools into active drivers of organizational growth. BSDS has a modular architecture that comprises curated data linked to business entities, a knowledge base for context-aware AI agents, and efficient data pipelines. AI agents play a pivotal role in assisting with data access and system management, reducing human effort, and improving scalability. Complementing this architecture, BSDS incorporates workflows optimized for both exploratory data analysis and production requirements, balancing speed of delivery with quality assurance. A key innovation of BSDS is its incorporation of the human factor. By aligning data team expertise with business semantics, BSDS bridges the gap between technical capabilities and business needs. Validated through real-world implementation, BSDS accelerates time-to-market for data-driven initiatives, enhances cross-functional collaboration, and provides a scalable blueprint for businesses of all sizes. Future research can build on BSDS to explore optimization strategies using complex systems and adaptive network theories, as well as developing autonomous data systems leveraging AI agents.","2169-3536","","10.1109/ACCESS.2025.3583260","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11050404","Data system;data architecture;data engineering;AI agent;business semantics;data science;machine learning","Business;Artificial intelligence;Data systems;Data models;Semantics;Data science;Knowledge based systems;Scalability;Pipelines;Computer architecture","","","","39","CCBYNCND","25 Jun 2025","","","IEEE","IEEE Journals"
"COMIX: Generalized Conflict Management in O-RAN xApps—Architecture, Workflow, and a Power Control Case","A. E. Giannopoulos; S. T. Spantideas; G. Levis; A. S. Kalafatelis; P. Trakadas","Research and Development Department, Four Dot Infinity (FDI), Athens, Greece; Research and Development Department, Four Dot Infinity (FDI), Athens, Greece; Research and Development Department, Four Dot Infinity (FDI), Athens, Greece; Research and Development Department, Four Dot Infinity (FDI), Athens, Greece; Research and Development Department, Four Dot Infinity (FDI), Athens, Greece",IEEE Access,"11 Jul 2025","2025","13","","116684","116700","Open Radio Access Network (O-RAN) is transforming the telecommunications landscape by enabling flexible, intelligent, and multi-vendor networks. Central to its architecture are xApps hosted on the Near-Real-Time RAN Intelligent Controller (Near-RT RIC), which optimize network functions in real time. However, the concurrent operation of multiple xApps with conflicting objectives can lead to suboptimal performance. This paper introduces a generalized Conflict Management scheme for Multi-Channel Power Control in O-RAN xApps (COMIX), designed to detect and resolve conflicts between xApps. To demonstrate COMIX, we focus on two Deep Reinforcement Learning (DRL)-based xApps for power control: one maximizes the data rare across UEs, and the other optimizes system-level energy efficiency. COMIX employs a standardized Conflict Mitigation Framework (CMF) for conflict detection and resolution and leverages the Network Digital Twin (NDT) to evaluate the impact of conflicting actions before applying them to the live network. We validate the framework using a realistic multi-channel power control scenario under various conflict resolution policies, demonstrating its effectiveness in balancing antagonistic objectives. Evaluation results show that COMIX achieves up to 60% energy savings across different Service-Level Agreement (SLA) policies compared to a baseline conflict-unaware system, with negligible impact (around 3%) on system throughput. While this study considers power control xApps, the COMIX framework is generalizable and can be applied to any xApp conflict scenario involving resource contention or KPI interdependence.","2169-3536","","10.1109/ACCESS.2025.3585774","UNITY-6G Project; EU HORIZON-JU-SNS-2024 Program(grant numbers:101192650); “REACT-6G” Project; HORIZON-JU-SNS-2022, 2nd 6G-SANDBOX Open Call(grant numbers:GA101096328); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11071295","6G;conflict detection;conflict management;deep reinforcement learning;energy efficiency;O-RAN;power control;resource management;xApp","Open RAN;Power control;Optimization;Energy efficiency;Throughput;Energy resolution;Resource management;Real-time systems;Quality of service;Prevention and mitigation","","","","35","CCBY","3 Jul 2025","","","IEEE","IEEE Journals"
"Creating and Capturing Artificial Emotions in Autonomous Robots and Software Agents","C. Hoffmann; P. Linden; M. -E. Vidal","Research Group Robots and Software Agents with Emotions, Sankt Augustin, Germany; University of Bonn, Germany; TIB Leibnitz Information Centre for Science and Technology, Hannover, Germany",Journal of Web Engineering,"22 Sep 2023","2021","20","4","993","1030","This paper presents ARTEMIS, a control system for autonomous robots or software agents. ARTEMIS can create human-like artificial emotions during interactions with their environment. We describe the underlying mechanisms for this. The control system also captures its past artificial emotions. A specific interpretation of a knowledge graph, called an Agent Knowledge Graph, stores these artificial emotions. ARTEMIS then utilizes current and stored emotions to adapt decision making and planning processes. As proof of concept, we realize a concrete software agent based on the ARTEMIS control system. This software agent acts as a user assistant and executes their orders and instructions. The environment of this user assistant consists of several other autonomous agents that offer their services. The execution of a user's orders requires interactions of the user assistant with these autonomous service agents. These interactions lead to the creation of artificial emotions within the user assistant. The first experiments show that it is possible to realize an autonomous user assistant with plausible artificial emotions with ARTEMIS and record these artificial emotions in its Agent Knowledge Graph. The results also show that captured emotions support successful planning and decision making in complex dynamic environments. The user assistant with emotions surpasses an emotionless version of the user assistant.","1544-5976","","10.13052/jwe1540-9589.2043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10246227","Autonomous agents;artificial emotions;agent knowledge graphs","Decision making;Knowledge graphs;Control systems;Autonomous agents;Planning;Autonomous robots","","1","","46","","22 Sep 2023","","","River Publishers","River Publishers Journals"
"Collaboration of Smart IoT Devices Exemplified With Smart Cupboards","I. García-Magariño; F. González-Landero; R. Amariglio; J. Lloret","Department of Software Engineering and Artificial Intelligence, Complutense, University of Madrid, Madrid, Spain; Edison Desarrollos, Teruel, Spain; Massachusetts General Hospital, Boston, MA, USA; Instituto de Investigación para la Gestión Integrada de Zonas Costeras, Universitat Politecnica de Valencia, Valencia, Spain",IEEE Access,"29 Jan 2019","2019","7","","9881","9892","The variety of smart things connected to Internet hampers the possibility of having a stand-alone solution for service-centric provisioning in the Internet of Things (IoT). The different features of smart objects in processing capabilities, memory, and size make it difficult for final users to learn the installation and usage of all these devices in collaboration with other IoT objects, hindering the user experience. In this context, we propose a collaboration mechanism for IoT devices based on the multi-agent systems with mobile agents. This paper illustrates the current approach with smart cupboards for potentially tracking memory losses. The user study revealed that users found working products of this approach usable, easy-to-learn and useful, and they agreed that the current approach could provide a high quality of experience not only in the specific case of service-centric IoT devices for tracking memory losses but also in other domains. The learning capability by means of this approach was showed with significant reductions of reaction times and number of errors over the first and second tests with the current approach. System response times were appropriate for both continuous rendering and presenting the classification results. The usage of RAM memory was also adequate for the common actual devices.","2169-3536","","10.1109/ACCESS.2018.2890393","Dpto. de Innovación, Investigación y Universidad del Gobierno de Aragón through the program FEDER Aragón 2014-2020 Construyendo Europa desde Aragón(grant numbers:T49_17R); University of Zaragoza and the Foundation Ibercaja through the Research Project Construcción de un framework para agilizar el desarrollo de aplicaciones móviles en el ámbito de la salud(grant numbers:JIUZ-2017-TEC-03); Estancias de movilidad en el extranjero José Castillejo para jóvenes doctores Program, Spanish Ministry of Education, Culture and Sport(grant numbers:CAS17/00005); Universidad de Zaragoza(grant numbers:IT24/16,IT1/18); Research Project Desarrollo Colaborativo de Soluciones AAL, Spanish Ministry of Economy and Competitiveness(grant numbers:TIN2014-57028-R); Organismo Autónomo Programas Educativos Europeos(grant numbers:2013-1-CZ1-GRU06-14277); Ministerio de Economía y Competitividad(grant numbers:TIN2017-84802-C2-1-P); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8598738","IoT;user experience;smart object;collaboration;smart cupboard","Collaboration;Mobile agents;Games;Software;Internet of Things;Performance evaluation","","12","","18","OAPA","1 Jan 2019","","","IEEE","IEEE Journals"
"A Review on Integrating Autonomy Into System of Systems: Challenges and Research Directions","M. Torkjazi; A. K. Raz","Department of Systems Engineering and Operations Research, George Mason University, Fairfax, VA, USA; Department of Systems Engineering and Operations Research, George Mason University, Fairfax, VA, USA",IEEE Open Journal of Systems Engineering,"26 Sep 2024","2024","2","","157","178","Artificial intelligence and machine learning (AI/ML) technologies convert conventional engineered systems into autonomous systems that are capable of performing tasks in their operational environment with limited to no human involvement. These technologies can reduce demands for human workload while enabling a suite of new capabilities such as autonomous vehicles and smart cities. However, a major challenge is the integration of these autonomous systems into a system of systems (SoSs), essentially resulting in a system of autonomous systems (SoASs). SoASs are fraught with new challenges that compound issues from the founding domains of SoS, AI/ML, and autonomous systems. To understand the new set of challenges for SoAS, this article conducts an extensive review of both theoretical and application-based literature published in the founding domains. The goal is to examine how individual challenges in each domain intersect and exacerbate when multiple independent systems with AI/ML are integrated into an SoAS. A particular emphasis is placed on highlighting how interactions across these domains manifest at the SoAS level. As a result, four overarching challenges for SoASs are identified that must be addressed by systems engineers to ensure a successful realization of the SoAS in the future: 1) SoAS foundation; 2) emergence, safety, and performance; 3) architecture and integration; and 4) test and evaluation. Each challenge is comprehensively examined in the three founding domains by discussing domain-specific state-of-the-art methods and tools that different engineering disciplines have proposed to address. For each challenge, we also investigated how the existing tools and methods apply to addressing the challenge for SoAS and highlighted the remaining gaps that still need to be addressed. Furthermore, this article identifies systems engineering research needs for improving SoAS foundations, analysis of autonomy impacts, and enabling SoAS architecture, integration, and evaluation methods. Conducting research studies in these fields will improve systems engineering practices for a successful and effective realization of SoAS.","2771-9987","","10.1109/OJSE.2024.3456037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10669760","Autonomy integration;SoS challenges;SoS engineering;system of autonomous systems (SoASs);system of systems (SoSs)","Autonomous systems;Systems engineering and theory;Reviews;Computer architecture;System of systems;Machine learning;Research and development;Autonomous vehicles;Smart cities","","3","","198","CCBYNCND","9 Sep 2024","","","IEEE","IEEE Journals"
"A Multi-Phase DRL-Driven SDN Migration Framework Addressing Budget, Legacy Service Compatibility, and Dynamic Traffic","K. Yuan Tan; S. Chin Tan; T. Chee Chuah","Faculty of Computing and Informatics, Multimedia University, Cyberjaya, Malaysia; Faculty of Computing and Informatics, Multimedia University, Cyberjaya, Malaysia; Faculty of Engineering, Multimedia University, Cyberjaya, Malaysia",IEEE Access,"24 Feb 2025","2025","13","","33202","33219","Software-Defined Networking (SDN) is a network architecture that offers enhanced flexibility, programmability, and more efficient traffic load management by decoupling the control plane from the data plane. However, complete migration to SDN is challenging for most organizations due to costs and operational complexities. Hybrid SDN has emerged as a practical incremental path where legacy and SDN-enabled nodes coexist, yet existing migration strategies typically address only individual challenges such as dynamic traffic patterns, legacy service compatibility, and budget constraints. This paper introduces SMART (SDN Migration Assisted by a Deep Reinforcement Learning (DRL) Technique), a comprehensive framework that simultaneously addresses dynamic traffic patterns, legacy service compatibility, and phased migration under budget constraints. By integrating a DRL model with a clustering algorithm, SMART determines the migration sequence to minimize link utilization and reduce the number of SDN-enabled nodes required for effective traffic load distribution under dynamic traffic patterns. Extensive evaluations on the Abilene and GEANT network topologies demonstrate that SMART outperforms three existing approaches, achieving most of the SDN benefits by migrating only 36% and 52% of legacy nodes, respectively. This approach can potentially lower migration costs by up to 64% while achieving network optimization objectives. These insights provide both a foundation for future research in network migration strategies and practical guidance for organizations planning cost-effective transitions from legacy to SDN-based architectures.","2169-3536","","10.1109/ACCESS.2025.3543236","Ministry of Higher Education Malaysia through the Fundamental Research Grant Scheme(grant numbers:FRGS/1/2023/ICT04/MMU02/1); Multimedia University Malaysia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10891760","DRL;hybrid SDN;SDN migration;software-defined networking","Traffic control;Optimization;Organizations;Measurement;Costs;Heuristic algorithms;Load management;Telecommunication traffic;Routing;Multimedia computing","","4","","73","CCBY","18 Feb 2025","","","IEEE","IEEE Journals"
"Dynamic Pricing in Multi-Tenant MANO With Resource Sharing: A Stackelberg Game Approach","M. Reza Abedi; M. Fasanghari; M. Akbari; N. Mokari; H. Yanikomeroglu","ECE Department, Tarbiat Modares University, Tehran, Iran; Strategic Studies and Digital Economics Department, ICT Research Institute, Tehran, Iran; Communication Technology Department, ICT Research Institute, Tehran, Iran; ECE Department, Tarbiat Modares University, Tehran, Iran; Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada",IEEE Open Journal of the Communications Society,"14 Nov 2024","2024","5","","7002","7021","Network slicing is used to support the stringent requirements of sixth generation (6G) services by dividing an infrastructure network into multiple logical networks that can enable service-oriented resource allocation. However, there are several orchestration issues when considering multiple infrastructure providers (InPs) and multiple tenants in a recursive architecture. There are also challenging issues in designing efficient auction mechanisms for such multi-domain and multi-tenant network slicing. To address these challenges, we consider multi-tenant management and orchestration as a multi-buyer, multi-seller scenario, and propose a novel two-stage auction mechanism that aims to increase the overall utility of all participants while mitigating the overall cost of the network. We formulate this two-stage auction mechanism as a multi-leader multi-follower (MLMF) Stackelberg game approach that converges to a Stackelberg equilibrium. In this game, there are multiple InPs that lease network, computing, and storage infrastructure resources to multiple Tier1 tenants in the first stage of the auction mechanism. Next, Tier1 tenants instantiate triple 6G slices as extremely reliable and low-latency communications (eURLLC), ultra-massive machine-type communications (umMTC), and further enhanced mobile broadband (FeMBB) slices, and lease smaller slices to Tier2 tenants through the second step of the auction mechanism. Tier2 tenants then serve different eURLLC, umMTC, and FeMBB users who have specific and mostly different requirements and constraints, while Tier2 tenants manage their own resources to maximize their utility. Due to the distributed nature of the proposed problem, we consider distributed reinforcement learning (DRL) as a solution. Simulation results show that our DRL-based solution increases the average profit of the network by 19% compared to the existing state-of-the-art benchmark.","2644-125X","","10.1109/OJCOMS.2024.3480987","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10716743","Lease transfer;infrastructure provider;multi-domain network slicing;MLMF Stackelberg game;multi-timescale decision making;distributed reinforcement learning","Indium phosphide;III-V semiconductor materials;Resource management;Games;6G mobile communication;Network slicing;Pricing;Dynamic scheduling;Quality of service;Costs","","1","","47","CCBYNCND","15 Oct 2024","","","IEEE","IEEE Journals"
"Simulation-Based Evolutionary Optimization of Air Traffic Management","A. Pellegrini; P. D. Sanzo; B. Bevilacqua; G. Duca; D. Pascarella; R. Palumbo; J. J. Ramos; M. À. Piera; G. Gigante","Lockless S.r.l., Rome, Italy; Lockless S.r.l., Rome, Italy; Instititute for Sustainable Society and Innovation (ISSNOVA), Naples, Italy; Instititute for Sustainable Society and Innovation (ISSNOVA), Naples, Italy; Centro Italiano Ricerche Aerospaziali (CIRA), Capua, Italy; Centro Italiano Ricerche Aerospaziali (CIRA), Capua, Italy; Department of Telecommunication and Systems Engineering, Universitat Autònoma de Barcelona (UAB), Barcelona, Spain; Department of Telecommunication and Systems Engineering, Universitat Autònoma de Barcelona (UAB), Barcelona, Spain; Centro Italiano Ricerche Aerospaziali (CIRA), Capua, Italy",IEEE Access,"11 Sep 2020","2020","8","","161551","161570","In the context of aerospace engineering, the optimization of processes may often require to solve multi-objective optimization problems, including mixed variables, multi-modal and non-differentiable quantities, possibly involving highly-expensive objective function evaluations. In Air Traffic Management (ATM), the optimization of procedures and protocols becomes even more complicated, due to the involvement of human controllers, which act as final decision points in the control chain. In this article, we propose the use of computational intelligence techniques, such as Agent-Based Modelling and Simulation (ABMS) and Evolutionary Computing (EC), to design a simulation-based distributed architecture to optimize control plans and procedures in the context of ATM. We rely on Agent-Based fast-time simulations to carry out offline what-if analysis of multiple scenarios, also taking into account human-related decisions, during the strategic or pre-tactical phases. The scenarios are constructed using real-world traffic data traces, while multiple optimization variables governed by an EC algorithm allow to explore the search space to identify the best solutions. Our optimization approach relies on ad-hoc multi-objective performance metrics which allow to assess the goodness of the control of aircraft and air traffic regulations. We present experimental results which prove the viability of our approach, comparing them with real-world data traces, and proving their meaningfulness from an Air Traffic Control perspective.","2169-3536","","10.1109/ACCESS.2020.3021192","Single European Sky ATM Research (SESAR) Joint Undertaking (Evolutionary Air Traffic Management (EvoATM) Project) through European Union’s Horizon 2020 Research and Innovation Program(grant numbers:783189); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9184863","Air traffic control;distributed optimization;evolutionary algorithms;modeling and simulation;multi-objective optimization;support to strategic design","Optimization;Atmospheric modeling;Computer architecture;Computational modeling;Analytical models;Measurement;Complexity theory","","14","","50","CCBY","2 Sep 2020","","","IEEE","IEEE Journals"
"Enhancing XR Application Performance in Multi-Connectivity Enabled mmWave Networks","M. A. Javed; P. Liu; S. S. Panwar","Department of Electrical and Computer Engineering, New York University Tandon School of Engineering, Brooklyn, NY, USA; Department of Electrical and Computer Engineering, New York University Tandon School of Engineering, Brooklyn, NY, USA; Department of Electrical and Computer Engineering, New York University Tandon School of Engineering, Brooklyn, NY, USA",IEEE Open Journal of the Communications Society,"20 Oct 2023","2023","4","","2421","2438","mmWave communications are paving the way for next-generation cellular networks due to their inherent ability to provide high data rates and mitigate interference. Coupled with this are the enormous potential and challenges posed by eXtended Reality (XR) applications which are becoming increasingly ubiquitous. In this paper, we leverage the unique characteristics of mmWave networks to re-think and re-design fundamental network architecture and functions in order to meet the strict requirements of deadline-driven XR applications. We propose a multi-tiered multi-connectivity architecture that allows users (UEs) to connect to multiple base stations (gNBs) simultaneously and switch rapidly between them in case of blockages. By replicating UE data at multiple gNBs close to the UE, we ensure that we satisfy strict Quality of Service (QoS) constraints even with unpredictable, dynamic blockages of the mmWave links. We show through extensive system-level simulations that our network architecture allows us to shield UEs from high handover delays and minimizes data plane interruptions in case of blockages. Moreover, we note that existing algorithms for network functions such as gNB selection and scheduling are not optimized for the multi-connectivity paradigm, nor do they specifically cater to strict deadline constraints or intermittent wireless links. We propose a Deep Reinforcement Learning framework that selects gNBs for data replication by explicitly optimizing to meet strict deadline constraints of XR traffic. Our Deep Learning agent analyzes global state information and predicts the best selection of gNBs to preemptively replicate data for future transmissions. Furthermore, we propose a scheduler based on maximal weight matching, dubbed  $\beta -$ MWM, which is specifically tailored to exploit multi-connectivity. We show that our Deep Learning based Data Replication Predictor and  $\beta -$ MWM scheduler perform better than existing, conventional algorithms and result in markedly better performance for XR applications with strict deadlines.","2644-125X","","10.1109/OJCOMS.2023.3322383","NYU Wireless; NY State Center for Advanced Technology in Telecommunications (CATT); NYU IT High-Performance Computing Resources, Services, and Staff Expertise; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10272712","Blockages;deadline-driven scheduling;deep learning;DQN;handover;low latency;millimeter wave;mmWave;multi-connectivity;quality of service;reinforcement learning;XR applications","Millimeter wave communication;X reality;5G mobile communication;Quality of service;Base stations;3GPP;Network architecture","","4","","51","CCBYNCND","5 Oct 2023","","","IEEE","IEEE Journals"
"H∞ Control for Discrete-Time Multi-Player Systems via Off-Policy Q-Learning","J. Li; Z. Xiao","School of Information and Control Engineering, Liaoning Shihua University, Liaoning, China; School of Information and Control Engineering, Liaoning Shihua University, Liaoning, China",IEEE Access,"14 Feb 2020","2020","8","","28831","28846","This paper presents a novel off-policy game Q-learning algorithm to solve H∞ control problem for discrete-time linear multi-player systems with completely unknown system dynamics. The primary contribution of this paper lies in that the Q-learning strategy employed in the proposed algorithm is implemented in an off-policy policy iteration approach other than on-policy learning, since the off-policy learning has some well-known advantages over the on-policy learning. All of players struggle together to minimize their common performance index meanwhile defeating the disturbance that tries to maximize the specific performance index, and finally they reach the Nash equilibrium of game resulting in satisfying disturbance attenuation condition. For finding the solution of the Nash equilibrium, H control problem is first transformed into an optimal control problem. Then an off-policy Q-learning algorithm is put forward in the typical adaptive dynamic programming (ADP) and game architecture, such that control policies of all players can be learned using only measured data. More importantly, the rigorous proof of no bias of solution to the Nash equilibrium by using the proposed off-policy game Q-learning algorithm is presented. Comparative simulation results are provided to verify the effectiveness and demonstrate the advantages of the proposed method.","2169-3536","","10.1109/ACCESS.2020.2970760","National Natural Science Foundation of China(grant numbers:61673280); Open Project of Key Field Alliance of Liaoning Province(grant numbers:2019-KF-03-06); Project of Liaoning Shihua University(grant numbers:2018XJJ-005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8977468","H∞ control;off-policy Q-learning;game theory;Nash equilibrium","Games;Heuristic algorithms;Nash equilibrium;Performance analysis;Control systems;Attenuation","","5","","48","CCBY","31 Jan 2020","","","IEEE","IEEE Journals"
"A Multi-Agent System for Cybersecurity Threat Detection and Correlation Using Large Language Models","Y. Hmimou; M. Tabaa; A. Khiat; Z. Hidila","Multidisciplinary Laboratory of Research and Innovation (LPRI), Moroccan School of Engineering Sciences (EMSI), Casablanca, Morocco; Multidisciplinary Laboratory of Research and Innovation (LPRI), Moroccan School of Engineering Sciences (EMSI), Casablanca, Morocco; 2IACS Laboratory, ENSET, Hassan II University of Casablanca, Casablanca, Morocco; Multidisciplinary Laboratory of Research and Innovation (LPRI), Moroccan School of Engineering Sciences (EMSI), Casablanca, Morocco",IEEE Access,"1 Sep 2025","2025","13","","150199","150215","As cyber-attacks rapidly evolve across communication, infrastructure and data layers, traditional security solutions such as rule-based intrusion detection systems (IDS) or signature-based antivirus programs are effective at detecting known threats, but they often lack the contextual understanding and semantic interpretation necessary to detect complex or evolving attacks. For example, spear-phishing campaigns, advanced persistent threats (APTs), and multi-stage attacks often escape detection due to their subtle and context-dependent nature. This limitation creates a critical gap in detecting coordinated or subtle attack patterns that span multiple systems and domains. The need for semantic understanding, cross-domain visibility, and adaptive detection is increasingly urgent, particularly as threat actors employ polymorphic and AI-driven strategies that traditional systems cannot interpret or correlate effectively. This paper presents a modular multi-agent architecture that integrates established cybersecurity analysis tools with large language models (LLMs) to achieve intelligent, explicable and highly accurate detection of threats across diverse data types. Three specialized agents: 1) email verification, 2) log analysis, and 3) IP address scanning each operate independently with tailored detection pipelines that combine domain-specific tools and LLM-powered semantic analysis components to identify, characterize, and report threats specific to their domain. At the core of the system lies a contextual recommendation system that processes and cross-analyzes the outputs of all specialized agents to detect complex threat patterns such as multi-vector, time-based, or stealth attacks that would otherwise evade isolated detection mechanisms. The evaluation on benchmark datasets, including CIC-IDS 2017, SpamAssassin, and custom simulated network environments, demonstrates threat detection accuracy of 93.6%, multi-agent correlation accuracy of 87%, and false positive reduction of 41.3% compared to traditional approaches. The use of LLMs for both structured explanations and chain-of-thought reporting further enhances analyst confidence and reduces triage time.","2169-3536","","10.1109/ACCESS.2025.3602681","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11141466","Multi-agent systems;LLMs;contextual threat analysis;semantic analysis;email phishing detection;log-based anomaly detection;IP scanning","Correlation;Phishing;Computer security;Semantics;Pipelines;IP networks;Electronic mail;Recommender systems;Cognition;Accuracy","","","","57","CCBY","25 Aug 2025","","","IEEE","IEEE Journals"
"PlaneLoc2: Indoor Global Localization Using Planar Segments and Passive Stereo Camera","J. Wietrzykowski","Institute of Robotics and Machine Intelligence, Poznan University of Technology, Poznan, Poland",IEEE Access,"30 Jun 2022","2022","10","","67219","67229","This paper introduces PlaneLoc2 - a novel indoor global localization system designed to harness the potential of stereo cameras. A need for robust global localization that does not produce incorrect results (false positives) is present in almost every life-long autonomy task. We show that planar segments extracted from stereo vision data by a neural network enable such robust localization. Planar segments are easier to discriminate than keypoint features and provide easy-to-use geometric constraints. We propose an architecture that exploits a single deep neural network (DNN) to detect planar segments, produce appearance descriptors, and estimate segment geometry. Moreover, we introduce a novel view-based segment map and a novel pose retrieval procedure that considers the uncertainty of features to efficiently use the geometric constraints provided by them. We also show that the new learned descriptor provides better discrimination than the hand-crafted one. Finally, we present experimental results that show that our solution outperforms other state-of-the-art global localization methods and does not produce incorrect agent poses. For both test scenes it recognizes at least 15% more poses than the second best method without incorrect recognitions.","2169-3536","","10.1109/ACCESS.2022.3185732","Polish National Science Centre (NCN)(grant numbers:UMO-2018/31/N/ST6/00941); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9804481","Simultaneous localization and mapping;artificial neural networks;stereo image processing","Location awareness;Sensors;Cameras;Image segmentation;Geometry;Feature extraction;Laser radar","","2","","30","CCBY","23 Jun 2022","","","IEEE","IEEE Journals"
"Reinforcement Learning for Robust Header Compression (ROHC) Under Model Uncertainty","S. Jing; S. Zhang; Z. Ding","Department of Electrical and Computer Engineering, University of California, Davis, CA, USA; Department of Electrical and Computer Engineering, University of Louisiana at Lafayette, Lafayette, LA, USA; Department of Electrical and Computer Engineering, University of California, Davis, CA, USA",IEEE Transactions on Machine Learning in Communications and Networking,"16 Jul 2024","2024","2","","1033","1044","Robust header compression (ROHC), critically positioned between network and MAC layers, plays an important role in modern wireless communication networks for improving data efficiency. This work investigates bi-directional ROHC (BD-ROHC) integrated with a novel architecture of reinforcement learning (RL). We formulate a partially observable Markov decision process (POMDP), where the compressor is the POMDP agent, and the environment consists of the decompressor, channel, and header source. Our work adopts the well-known deep Q-network (DQN), which takes the history of actions and observations as inputs, and outputs the Q-values of corresponding actions. Compared with the ideal dynamic programming (DP) proposed in existing works, the newly proposed method is scalable to the state, action, and observation spaces. In contrast, DP often incurs formidable computation costs when the number of states becomes large due to long decompressor feedback delays and complex channel models. In addition, the new method does not require prior knowledge of the transition dynamics and accurate observation dependency of the model, which are often unavailable in practical applications.","2831-316X","","10.1109/TMLCN.2024.3409200","National Science Foundation(grant numbers:2009001,2029027); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10547320","Bi-directional robust header compression (BD-ROHC);network layer;packet header","IP networks;Delays;Channel models;History;Decoding;Bidirectional control;Wireless networks","","2","","20","CCBY","4 Jun 2024","","","IEEE","IEEE Journals"
"AnnotationGym: A Generic Framework for Automatic Source Code Annotation","H. Shahzad; A. Sanaullah; S. Arora; U. Drepper; M. C. Herbordt","Electrical and Computer Engineering Department, Boston University, Boston, MA, USA; Red Hat Inc., Raleigh, NC, USA; Red Hat Inc., Raleigh, NC, USA; Red Hat Inc., Raleigh, NC, USA; Electrical and Computer Engineering Department, Boston University, Boston, MA, USA",IEEE Access,"9 Sep 2025","2025","13","","155321","155339","A common approach to code optimization is to insert compiler hints in the source code using annotations. Two major challenges with using annotations effectively are their complexity and lack of portability. This means, first, that significant developer expertise is required, and, second, that the supported annotations, as well as their syntax and use, can vary substantially. Moreover, there is not currently any tool that can output performant annotation-inserted codes for different back-ends. To address these challenges, we present AnnotationGym, an easy-to-use, open-source, generic infrastructure that supplements or replaces the developer in annotating source code. It demonstrates a novel application of AI methods to code annotation. In addition to improving code performance, the flexibility of AnnotationGym enables easy comparisons of performance and optimization strategies among compilers and target architectures and thus provides an extensible platform to facilitate further progress in this field. AnnotationGym automatically extracts structured information about the target code and compiler to generate a list of possible annotations. AI-based optimization algorithms then traverse this space to determine the best set of annotations depending on the developer goals. To demonstrate its effectiveness, we run AnnotationGym on popular, representative workloads from the Polybench suite, as well as targeting various compilers (GCC, AMD HLS, Intel HLS), optimization algorithms (Reinforcement Learning, Bayesian Optimization), and architectures (CPU, FPGA). We also test our approach on FPGA codes derived, e.g., from the Rodinia and OpenDwarfs benchmarks and that are hand-optimized using standard best practices. An interesting finding is that the best overall performance obtained by AnnotationGym was generally with unoptimized codes.","2169-3536","","10.1109/ACCESS.2025.3605852","NSF(grant numbers:CCF-1919130); Red Hat; Advanced Micro Devices, Inc (AMD) and Intel, both through donated Field-Programmable Gate Arrays (FPGAs), tools, and Intellectual Property (IP); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11148243","Code annotation;reinforcement learning;source-to-source code optimization;compiler hints","Annotations;Codes;Source coding;Field programmable gate arrays;Optimization;Hardware;Space exploration;Benchmark testing;Semantics;Runtime","","1","","56","CCBY","3 Sep 2025","","","IEEE","IEEE Journals"
"Big Data and I2X Communication Infrastructure for Traffic Optimization and Accident Prevention on Automated Roads","J. García-González; J. Fernández-Andrés; N. Aliane; J. Sánchez-Soriano","Department of Science, Computing and Technology, Universidad Europea de Madrid, Villaviciosa de Odón, Spain; Department of Industrial and Aerospace Engineering, Universidad Europea de Madrid, Villaviciosa de Odón, Spain; Department of Industrial and Aerospace Engineering, Universidad Europea de Madrid, Villaviciosa de Odón, Spain; Advanced Artificial Intelligence Group (A2IG), Escuela Politécnica Superior, Universidad Francisco de Vitoria, Pozuelo de Alarcón, Spain",IEEE Access,"1 Aug 2025","2025","13","","133497","133509","This paper presents a scalable big data infrastructure designed to support traffic optimization and accident prevention in automated and connected road environments. The proposed system integrates real-time data acquisition from heterogeneous sources, including multichannel roadside camera gantries and IoT-enabled vehicle telemetry. The architecture is built upon technologies such as Apache Kafka, Apache Beam, and MongoDB, enabling high-throughput data ingestion, processing, and storage. To validate its performance, two experimental use-cases were developed: one for large-scale image ingestion and another for vehicle telemetry data streaming. The system successfully handled over 48 GB of image data and more than 3.4 million telemetry messages under real-time constraints. Results show that applying data compression techniques—such as resolution reduction and transmission throttling—reduced image upload durations by up to 77%, improving ingestion efficiency without compromising system robustness. These findings demonstrate the feasibility of deploying the proposed infrastructure as a foundational layer for future intelligent traffic management systems.","2169-3536","","10.1109/ACCESS.2025.3592310","I+D+i Projects funded by Ministerio de Ciencia e Innovación, Agencia Estatal de Investigación(grant numbers:PDC2022-133684-C33,PID2022-140554OB-C33); I+D+i Project funded by the Regional Government of Madrid(grant numbers:TEC-2024/ECO-277/SEGVAUTO-5G-CM); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11095663","Big data;real-time;intelligent transportation systems (ITS);infrastructure;streaming;V2X communication","Real-time systems;Roads;Telemetry;Decision making;Computer architecture;Big Data;Autonomous vehicles;Sensors;NoSQL databases;Data ingestion","","1","","45","CCBY","24 Jul 2025","","","IEEE","IEEE Journals"
"Task Offloading and Resource Allocation in an RIS-Assisted NOMA-Based Vehicular Edge Computing","A. -B. Yakubu; A. H. Abd El-Malek; M. Abo-Zahhad; O. Muta; M. M. Elsabrouty","Department of Electronics and Communications Engineering, Egypt-Japan University of Science and Technology, New Borg El-Arab, City, Alexandria, Egypt; Department of Electronics and Communications Engineering, Egypt-Japan University of Science and Technology, New Borg El-Arab, City, Alexandria, Egypt; Department of Electronics and Communications Engineering, Egypt-Japan University of Science and Technology, New Borg El-Arab, City, Alexandria, Egypt; Faculty of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan; Department of Electronics and Communications Engineering, Egypt-Japan University of Science and Technology, New Borg El-Arab, City, Alexandria, Egypt",IEEE Access,"11 Sep 2024","2024","12","","124330","124348","With the rise of intelligent transportation (ITS), autonomous cars, and on-the-road entertainment and computation, vehicular edge computing (VEC) has become a primary research topic in 6G and beyond communications. On the other hand, reconfigurable intelligent surfaces (RIS) are a major enabling technology that can help in the task offloading domain. This study introduces a novel VEC architecture that incorporates non-orthogonal multiple access (NOMA) and reconfigurable intelligent surfaces (RIS), where vehicles perform binary or partial computation offloading to edge nodes (eNs) for task execution. We construct a vehicle-to-infrastructure (V2I) transmission model by considering vehicular interference and formulating a joint task offloading and resource allocation (JTORA) problem with the goal of reducing total service latency and energy usage. Next, we decompose this problem into task offloading (TO) problem on the vehicle side and resource allocation (RA) problem on the eN side. Specifically, we describe offloading decisions and offloading ratios as a decentralized partially observable Markov decision process (Dec-POMDP). Subsequently, a multi-agent distributed distributional deep deterministic policy gradient (MAD4PG) is proposed to solve the TO problem, where every vehicular agent learns the global optimal policy and obtains individual decisions. Furthermore, a whale optimization algorithm (WOA) is used to optimize the phase shift coefficient of the RIS. Upon receiving offloading ratios and offloading decisions from vehicles, edge nodes utilize the Lagrange multiplier method (LMM) and Karush-Kuhn-Tucker (KKT) conditions to address the RA problem. Finally, we design a simulation model based on real-world vehicular movements. The numerical results demonstrate that, compared to previous algorithms, our proposed approach reduces the overall delay and energy consumption more effectively.","2169-3536","","10.1109/ACCESS.2024.3454810","Seventh Tokyo International Conference on African Development (TICAD7) African Scholarship; Egypt-Japan University of Science and Technology (E-JUST) and the Egyptian Ministry of Higher Education; Japan Society for the Promotion of Science (JSPS) KAKENHI(grant numbers:24K07490); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10666695","Reconfigurable intelligent surface;non-orthogonal multiple access;real-time task offloading;vehicular edge computing;multi-agent deep reinforcement learning","Reconfigurable intelligent surfaces;Resource management;Optimization;NOMA;Edge computing;Cloud computing;Energy consumption;Deep reinforcement learning","","11","","54","CCBYNCND","5 Sep 2024","","","IEEE","IEEE Journals"
"Exploration Degree Bias: The Hidden Influence of Node Degree in Graph Neural Network-Based Reinforcement Learning","P. Tarábek; D. Matis","Faculty of Management Science and Informatics, University of Žilina, Žilina, Slovakia; Faculty of Management Science and Informatics, University of Žilina, Žilina, Slovakia",IEEE Access,"20 Jan 2025","2025","13","","10746","10757","Graph Neural Networks (GNNs) have demonstrated remarkable performance in tasks involving graph-structured data, but they also exhibit biases linked to node degrees. This paper explores a specific manifestation of such bias, termed Exploration Degree Bias (EDB), in the context of Reinforcement Learning (RL). We show that EDB arises from the inherent design of GNNs, where nodes with high or low degrees disproportionately influence output logits used for decision-making. This phenomenon impacts exploration in RL, skewing it away from mid-degree nodes, potentially hindering the discovery of optimal policies. We provide a systematic investigation of EDB across widely used GNN architectures—GCN, GraphSAGE, GAT, and GIN—by quantifying correlations between node degrees and logits. Our findings reveal that EDB varies by architecture and graph configuration, with GCN and GIN exhibiting the strongest biases. Moreover, analysis of DQN and PPO RL agents illustrates how EDB can distort exploration patterns, with DQN exhibiting EDB under low exploration rates and PPO showing a partial ability to counteract these effects through its probabilistic sampling mechanism. Our contributions include defining and quantifying EDB, providing experimental insights into its existence and variability, and analyzing its implications for RL. These findings underscore the need to address degree-related biases in GNNs to enhance RL performance on graph-based tasks.","2169-3536","","10.1109/ACCESS.2025.3528878","Ministry of Education, Science, Research and Sport of the Slovak Republic(grant numbers:VEGA 1/0525/23); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10838508","Exploration degree bias;graph neural networks;message-passing mechanism;node degree bias;reinforcement learning","Reinforcement learning;Convolution;Correlation;Aggregates;Training;Limiting;Hands;Graph convolutional networks;Testing;Taxonomy","","","","46","CCBY","13 Jan 2025","","","IEEE","IEEE Journals"
"Deep Reinforcement Learning-Based AI Task Offloading in Resource-Constrained IIoT Computing Environments","D. Yu; X. Liu; J. Ning; S. Wang; C. Zhu; W. Zhao","School of Computer Science and Technology, Tongji University, Shanghai, China; College of Electronic and Information Engineering, Tongji University, Shanghai, China; College of Electronic and Information Engineering, Tongji University, Shanghai, China; School of Computer Science and Technology, Tongji University, Shanghai, China; COSMOPlat Institute of Industrial Intelligence, Qingdao, China; School of Computer Science and Technology, Tongji University, Shanghai, China",IEEE Internet of Things Journal,"","2025","PP","99","1","1","As a key enabler of Industry 4.0, the Industrial Internet of Things (IIoT) has been rapidly advancing, driving the increasingly widespread adoption of artificial intelligence (AI) in industrial production. However, the high computational demands of AI tasks contrast sharply with the limited computing resources available in industrial environments, highlighting the need for efficient task offloading strategies. This paper addresses AI task offloading under resource-constrained IIoT scenarios by proposing LSTM-Enhanced Hierarchical-Classification Offloading with DQN (LHC-DQN). The proposed framework adopts a two-layer offloading architecture: the first layer performs global scheduling by assigning tasks to cloud, edge, or device resources, while the second layer refines the allocation. Cloud and edge nodes apply mathematical optimization, whereas device nodes leverage DRL agents for autonomous decision-making. To handle AI task heterogeneity, a classification-aware mechanism is introduced in the first layer, deploying separate DQN agents for inference and training tasks to improve adaptability and efficiency. Furthermore, an LSTM module is integrated into the DQN backbone to capture temporal dependencies in task states. Experimental results in a simulated environment demonstrate that LHC-DQN significantly outperforms traditional methods, increasing task completion rates from approximately 47% to 68%. Ablation and generalization tests further confirm the robustness and effectiveness of the proposed method. Overall, LHC-DQN offers a practical and efficient solution for intelligent task offloading and resource scheduling in IIoT environments.","2327-4662","","10.1109/JIOT.2025.3620126","JZJG25142(grant numbers:2022YFB3305700); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11199314","AI Task Offloading;Cloud-Edge-Device Computing;Deep Reinforcement Learning;Multi-Agents;Industrial Internet of Things","Artificial intelligence;Computational modeling;Industrial Internet of Things;Resource management;Optimization;Cloud computing;Collaboration;Adaptation models;Processor scheduling;Image edge detection","","","","","CCBY","10 Oct 2025","","","IEEE","IEEE Early Access Articles"
"A Systematic Review of Chatbots: Classification, Development, and Their Impact on Tourism","L. Benaddi; C. Ouaddi; A. Jakimi; B. Ouchao","Software Engineering and Information Systems Engineering (GL-ISI) Team, Faculty of Sciences and Techniques of Errachidia (FSTE), University of Moulay Ismail (UMI), Meknes, Morocco; Software Engineering and Information Systems Engineering (GL-ISI) Team, Faculty of Sciences and Techniques of Errachidia (FSTE), University of Moulay Ismail (UMI), Meknes, Morocco; Software Engineering and Information Systems Engineering (GL-ISI) Team, Faculty of Sciences and Techniques of Errachidia (FSTE), University of Moulay Ismail (UMI), Meknes, Morocco; Software Engineering and Information Systems Engineering (GL-ISI) Team, Faculty of Sciences and Techniques of Errachidia (FSTE), University of Moulay Ismail (UMI), Meknes, Morocco",IEEE Access,"6 Jun 2024","2024","12","","78799","78810","Recently, we have observed a noticeable evolution and growing use and incorporation of chatbots on websites, mobile and social networking apps. A chatbot is a computer program that exhibits a capacity to converse quite naturally with users in a way that resembles a human dialogue. Examples of chatbots can be found in several areas, including education, commerce, and tourism. The use of Artificial Intelligence (AI) and its sub-fields, such as Machine Learning, Deep Learning, and Natural Language Processing (NLP), is increasing across all business sectors. One of the most advanced applications of this technology is the chatbot, which is particularly beneficial due to the quick response times and its simplicity. Nevertheless, although studies on chatbots exist in tourism, academic research covering their adoption, technological evolution, and impact on this sector is still relatively sparse. Therefore, this study aims to provide a comprehensive overview of chatbots and their effect on tourism. First, we provide a new classification of chatbots based on specific criteria. Second, we explore the conceptual architecture of chatbots and their key components. Third, this study aims to assess and contrast the main existing tools for developing chatbots, classifying them and highlighting their key advantages and disadvantages. Fourth, this study aims to examine the integration of chatbots in the tourism sector by identifying their key applications in the industry over the past decade. Additionally, it seeks to analyze the impact of chatbots on the various functionalities outlined in the 6A framework for tourism. To achieve this, a thorough search will be conducted using five prominent databases - Scopus, ACM, IEEE Xplore, Springer Link, and Web of Science - covering the period from 2013 to 2023. For this study, 1155 academic publications were reviewed after applying a systematic review protocol including purpose, research questions, keywords, digital libraries, search strings, and inclusion and exclusion criteria. Only 31 were identified to be primary studies.","2169-3536","","10.1109/ACCESS.2024.3408108","Ministry of Higher Education, Scientific Research and Innovation, the Digital Development Agency (DDA); National Center for Scientific and Technical Research (CNRST) of Morocco(grant numbers:Alkhawarizmi/2020/32); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10542991","Chatbot;conversational agent;tourism;history of chatbots;classification;architecture;artificial intelligence;NLP","Chatbots;Reviews;Artificial intelligence;Systematics;Oral communication;Virtual assistants;Task analysis;Natural language processing;Classification algorithms","","26","","59","CCBYNCND","31 May 2024","","","IEEE","IEEE Journals"
"Exploration and Exploitation of New Knowledge Emergence to Improve the Collective Intelligent Decision-Making Level of Web-of-Cells With Cyber-Physical-Social Systems Based on Complex Network Modeling","L. Cheng; T. Yu","School of Electric Power, South China University of Technology, Guangzhou, China; School of Electric Power, South China University of Technology, Guangzhou, China",IEEE Access,"17 Dec 2018","2018","6","","74204","74239","Through exploration and exploitation of new knowledge emergence, the collective intelligent decision-making (CID) level of Web-of-Cells (WoC) proposed by ELECTRA will be dramatically improved. For this purpose, we thoroughly investigate complex network theory and modeling methods for WoC with cyber-physical-social systems (CPSS). WoC is a new intelligent dispatching framework characterized by weak centralization, self-organization coupling, high independence, efficient coordination, and autonomous learning. Based on these characteristics and actual engineering demands, in this paper, we adopt complex network theory, parallel machine learning, and multi-agent stochastic game theory to address three basic scientific issues in WoC dispatching and control: how to build a complex network model for WoC with CPSS to stimulate new knowledge emergence; how to analyze the evolution structure stability and operation stability during this knowledge emergence process; and how to use the emerged new knowledge to achieve cell autonomy and system-wide coordination based on independent and CID, respectively. Finally, we conduct some explorations and make a prospect for WoC. The biggest innovation of this paper lies in thoroughly investigating how to fully stimulate and utilize new knowledge emergence from WoC to greatly improve its CID level of dispatching and control. This will be of great significance to the development of new-generation power system smart dispatching in the future.","2169-3536","","10.1109/ACCESS.2018.2879025","National Natural Science Foundation of China(grant numbers:51777078,51177055); China Southern Power Grid(grant numbers:GZKJQQ00000419); Science and Technology Project of China Southern Power Grid Company Ltd.(grant numbers:GDKJXM20180576); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8516907","Web-of-Cells;exploration and exploitation;new knowledge emergence;collective intelligent decision-making;complex network theory;parallel machine learning;multi-agent stochastic game theory;cyber-physical-social systems;cell autonomy;system-wide coordination;smart grid;dispatching and control;ELECTRA","Computer architecture;Microprocessors;Power grids;Renewable energy sources;Decision making","","24","","132","OAPA","31 Oct 2018","","","IEEE","IEEE Journals"
"Formal Specification and Verification of Self-Adaptive Concurrent Systems","M. I. Fakhir; S. A. R. Kazmi","Department of Computer Science, Government College University, Lahore, Pakistan; Department of Computer Science, Government College University, Lahore, Pakistan",IEEE Access,"10 Jul 2018","2018","6","","34790","34803","The assurance of required quality properties is one of the major challenges in self-adaptive systems (SASs). SASs have the capability to adapt their dynamic behavior autonomously at runtime due to uncertain changes in the environment. In general, an SAS is much difficult to specify and verify, because of its highly complex internal behavior and especially when time constraints are involved. In this research, we use modal μ-calculus (Mμ) for the specification and verification of colored Petri nets-based self-adaptive concurrent systems. We propose self-adaptive multi-agent concurrent system (SMACS) framework that is specifically designed for complex architectures. The internal structure of SMACS framework is based on MAPE-K feedback loop. Each phase of the feedback loop works as an internal agent (Int-Agent) known as Monitor Int-Agent, Analyzer Int-Agent, Planer Int-Agent, and Executer Int-Agent. The decentralized approach is being used in this research, and due to this approach, all agents intelligently adapt their behavior in the environment and send updates to other agents. For verification of internal properties like liveness, safeness, and deadlock-freedom of each agent, the TAPA model checker is being used. For the implementation of SMACS framework, traffic monitoring system is chosen as a case study.","2169-3536","","10.1109/ACCESS.2018.2849821","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8392667","Self-adaptive;multi-agent;formal specification;formal verification;modal μ-calculus;TAPA model checker","Adaptation models;Calculus;Feedback loop;Multi-agent systems;Model checking;Petri nets;Complex systems","","7","","36","OAPA","22 Jun 2018","","","IEEE","IEEE Journals"
"RoSA: A Framework for Modeling Self-Awareness in Cyber-Physical Systems","M. Götzinger; D. Juhász; N. Taherinejad; E. Willegger; B. Tutzer; P. Liljeberg; A. Jantsch; A. M. Rahmani","Department of Future Technologies, University of Turku, Turku, Finland; Institute of Computer Technology, TU Wien, Vienna, Austria; Institute of Computer Technology, TU Wien, Vienna, Austria; Institute of Computer Technology, TU Wien, Vienna, Austria; Institute of Computer Technology, TU Wien, Vienna, Austria; Department of Future Technologies, University of Turku, Turku, Finland; Institute of Computer Technology, TU Wien, Vienna, Austria; Department of Computer Science, University of California at Irvine, Irvine, USA",IEEE Access,"10 Aug 2020","2020","8","","141373","141394","The role of smart and autonomous systems is becoming vital in many areas of industry and society. Expectations from such systems continuously rise and become more ambitious: long lifetime, high reliability, high performance, energy efficiency, and adaptability, particularly in the presence of changing environments. Computational self-awareness promises a comprehensive assessment of the system state for sensible and well-informed actions and resource management. Computational self-awareness concepts can be used in many applications such as automated manufacturing plants, telecommunication systems, autonomous driving, traffic control, smart grids, and wearable health monitoring systems. Developing self-aware systems from scratch for each application is the most common practice currently, but this is highly redundant, inefficient, and uneconomic. Hence, we propose a framework that supports modeling and evaluation of various self-aware concepts in hierarchical agent systems, where agents are made up of self-aware functionalities. This paper presents the Research on Self-Awareness (RoSA) framework and its design principles. In addition, self-aware functionalities abstraction, data reliability, and confidence, which are currently provided by RoSA, are described. Potential use cases of RoSA are discussed. Capabilities of the proposed framework are showcased by case studies from the fields of healthcare and industrial monitoring. We believe that RoSA is capable of serving as a common framework for self-aware modeling and applications and thus helps researchers and engineers in exploring the vast design space of hierarchical agent-based systems with computational self-awareness.","2169-3536","","10.1109/ACCESS.2020.3012824","Federal Ministry Republic of Austria for Climate Action, Environment, Energy, Mobility, Innovation and Technology (BMVIT)/Austrian Research Promotion Agency (FFG) under the program Production of the Future in the project SAVE(grant numbers:FFG 864883); European Union’s Horizon 2020 Framework Programme for Research and Innovation(grant numbers:674875 (oCPS Marie Curie Network)); Tekniikan Edistämissäätiö (Finnish Foundation for Technology Promotion); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9151960","Computational self-awareness;framework;agent-based;hierarchical;modeling;development;monitoring;observe-decide-act","Monitoring;Computer architecture;Reliability;Computational modeling;Sensors;Aerospace electronics;Adaptation models","","16","","104","CCBY","29 Jul 2020","","","IEEE","IEEE Journals"
"Cooperative UAV Clustering for Fair Coverage of Communication Regions","J. Wu; L. Gu; Z. Jia; J. Wu","School of Computer Science, Shenyang Aerospace University, Shenyang, China; School of Computer Science, Shenyang Aerospace University, Shenyang, China; School of Computer Science, Shenyang Aerospace University, Shenyang, China; School of Artificial Intelligence, Guilin University of Electronic Technology, Guilin, China",Intelligent and Converged Networks,"4 Apr 2025","2025","6","1","1","19","Cooperative unmanned aerial vehicles (UAVs) cluster technology is considered a prospective solution for area coverage problems, enabling network access and emergency communications in remote areas. In this paper, we investigate how to control UAV cluster to achieve long-term and stable regional coverage while maintaining link connectivity and minimizing energy consumption, given the limited communication range and energy consumption of the UAVs themselves. To this end, we propose a cooperative UAV cluster strategy based on multi-agent deep reinforcement learning (MADRL) to achieve fair coverage of communication regions, which we call MADRL-based cooperative UAV cluster strategy (MADRL-CUCS). Our solution is a centralized training distributed execution architecture and defines a cluster structure for leader UAVs and follower UAVs. Under the premise of comprehensively considering the maximum coverage, we use a new energy efficiency function to minimize energy consumption, so as to extend the network lifetime of the UAVs cluster networks. The new fairness index and collision avoidance factor are used to ensure that the UAV cluster achieve effective and secure regional coverage. We adopt depth first search algorithm to check the link connectivity of the UAVs during the coverage process. Experiments show that the MADRL-CUCS algorithm outperforms the benchmark algorithm.","2708-6240","","10.23919/ICN.2025.0001","National Natural Science Foundation of China(grant numbers:62376165); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10949778","unmanned aerial vehicle (UAV) cluster networks;communication coverage;multi-agent deep reinforcement learning;fairness","Training;Energy consumption;Clustering algorithms;Benchmark testing;Autonomous aerial vehicles;Deep reinforcement learning;Energy efficiency;Indexes;Collision avoidance;Drones","","","","30","","4 Apr 2025","","","TUP","TUP Journals"
"Spiking Neural Network Discovers Energy-Efficient Hexapod Motion in Deep Reinforcement Learning","K. Naya; K. Kutsuzawa; D. Owaki; M. Hayashibe","Department of Robotics, Graduate School of Engineering, Neuro-Robotics Laboratory, Tohoku University, Sendai, Japan; Department of Robotics, Graduate School of Engineering, Neuro-Robotics Laboratory, Tohoku University, Sendai, Japan; Department of Robotics, Graduate School of Engineering, Neuro-Robotics Laboratory, Tohoku University, Sendai, Japan; Department of Robotics, Graduate School of Engineering, Neuro-Robotics Laboratory, Tohoku University, Sendai, Japan",IEEE Access,"12 Nov 2021","2021","9","","150345","150354","In Deep Reinforcement Learning (DRL) for robotics application, it is important to find energy-efficient motions. For this purpose, a standard method is to set an action penalty in the reward to find the optimal motion considering the energy expenditure. This method is widely used for the simplicity of implementation. However, since the reward is a linear sum, if the penalty is too large, the system will fall into local minima and no moving solution can be obtained. In contrast, if the penalty is too small, the effect may not be sufficient. Therefore, it is necessary to adjust the amount of the penalty so that the agent always moves dynamically, and the energy-saving effect is sufficient. Nevertheless, since adjusting the hyperparameters is computationally expensive, we need a learning method that is robust to the penalty setting problem. We investigated on the Spiking Neural Network (SNN), which has been attracting attention for its computational efficiency and neuromorphic architecture. We conducted gait experiments using a hexapod agent while varying the energy penalty settings in the simulation environment. By applying SNN to the conventional state-of-the-art DRL algorithms, we examined whether the agent could explore for an optimal gait with a larger penalty variation and obtain an energy-efficient gait verified with Cost of Transport (CoT), a metric of energy efficiency for gait. Soft Actor-Critic (SAC)+SNN resulted in a CoT of 1.64, Twin Delayed Deep Deterministic policy gradient (TD3)+SNN resulted in a CoT of 2.21, and Deep Deterministic policy gradient (DDPG)+SNN resulted in a CoT of 2.08 (1.91 for normal SAC, 2.38 for TD3, and 2.40 for DDPG). DRL combined with SNN succeeded in learning more energy efficient gait with lower CoT.","2169-3536","","10.1109/ACCESS.2021.3126311","JSPS Grant-in-Aid for Scientific Research on Innovative Areas Hyper-Adaptability Project(grant numbers:20H05458); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9606760","Spiking neural network;deep reinforcement learning;energy efficiency;hexapod gait;spatio-temporal backpropagation","Neurons;Legged locomotion;Task analysis;Robots;Computational modeling;Torque;Mathematical models","","12","","30","CCBY","8 Nov 2021","","","IEEE","IEEE Journals"
"Cooperative Intersection Support System Based on Mirroring Mechanisms Enacted by Bio-Inspired Layered Control Architecture","M. Da Lio; A. Mazzalai; M. Darin","Department of Industrial Engineering, University of Trento, Povo, Italy; Department of Industrial Engineering, University of Trento, Povo, Italy; Research Center of FCA (Fiat Chrysler Automobiles), CRF, Povo, Italy",IEEE Transactions on Intelligent Transportation Systems,"1 May 2018","2018","19","5","1415","1429","This paper presents a cooperative intersection support system implemented with an artificial cognitive system enacted by an agent that replicates human driver longitudinal sensorimotor control in the application domain. The engineering of the agent exploits recent ideas from Cognitive Science, among which the notion of mirroring (the agent discovering driver intentions by simulating possible human actions). The paper introduces the design principles for the agent and the following implementation. The system is evaluated with experimental data and compared to state of the art implementations that use different approaches.","1558-0016","","10.1109/TITS.2017.2731901","Trento (PAT), Italy(grant numbers:e2Call); European Commission (interactIVe.)(grant numbers:FP7 246587); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8011474","Advanced driver assistance systems;intersection support;driver modeling;layered control architectures;artificial cognitive systems","Vehicles;Roads;Robot sensing systems;Safety;Trajectory;Sensor systems","","11","","52","OAPA","16 Aug 2017","","","IEEE","IEEE Journals"
"Next-Gen Internet of Drones: Federated Learning and Digital Twin Synergy for Energy-Efficient Task Allocation and Seamless Service Migration","A. Arsalan; T. Umer; R. Asif Rehman; B. -S. Kim","Department of Computer Science, COMSATS University Islamabad, Lahore Campus, Lahore, Pakistan; Department of Computer Science, COMSATS University Islamabad, Lahore Campus, Lahore, Pakistan; FAST School of Computing, National University of Computer and Emerging Sciences, Lahore Campus, Lahore, Pakistan; Department of Software and Communications Engineering, Hongik University, Sejong City, South Korea",IEEE Access,"17 Apr 2025","2025","13","","64459","64472","The computing-intensive tasks generated by Internet of Things devices cannot be handled alone by themselves due to limitations in battery and processing power. An appropriate approach to this problem is the Internet of Drones (IoDs) with edge computing capabilities, which can offload the created tasks from IoT devices to IoDs. To improve sustainability by maximizing energy efficiency, minimizing duplicate service migrations, and guaranteeing dynamic task offloading in UAV-supported IoD networks, this paper proposes a Federated Digital aided Internet of Drones (FD-IoD) architecture. The proposed framework guarantees the long-term viability of IoD-based edge networks by combining digital twin technology with federated deep reinforcement learning. The FD-IoD framework integrates energy harvesting algorithms and optimizes mobility-aware resource management to extend drone lifespan and reduce unnecessary computational overheads. To adjust to various IoT environments, the framework uses a dual-layer optimization approach that combines local agent learning with global decision-making via digital twin. The framework outperforms current benchmarks by up to 40% in energy efficiency, lower service migration rates, and faster task completion rates, as shown by extensive simulations. Additionally, the proposed framework guarantees decreased latency, efficient resource use, and queue stability even in heavy demand.","2169-3536","","10.1109/ACCESS.2025.3558439","Framework of the International Cooperation Program managed by the National Research Foundation of Korea(grant numbers:RS-2023-NR121113); National Research Foundation of Korea (NRF) grant; Korean Government [Ministry of Science and ICT (MSIT)](grant numbers:RS-2022-NR069069); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10950141","Digital twin;Internet of Drones;federated reinforcement learning;task offloading;service migration;energy efficiency","Resource management;Drones;Optimization;Energy efficiency;Decision making;Costs;Dynamic scheduling;Digital twins;Real-time systems;Energy harvesting","","","","32","CCBY","7 Apr 2025","","","IEEE","IEEE Journals"
"Crops Leaf Disease Recognition From Digital and RS Imaging Using Fusion of Multi Self-Attention RBNet Deep Architectures and Modified Dragonfly Optimization","I. Haider; M. A. Khan; M. Nazir; A. Hamza; O. Alqahtani; M. T. -H. Alouane; A. Masood","Department of Computer Science, HITEC University, Taxila, Pakistan; Department of Computer Science, HITEC University, Taxila, Pakistan; Department of Computer Science, HITEC University, Taxila, Pakistan; Department of Computer Science, HITEC University, Taxila, Pakistan; College of Computer Science, King Khalid University, Abha, Saudi Arabia; College of Computer Science, King Khalid University, Abha, Saudi Arabia; Department of Physics, Norwegian University of Science and Technology, Trondheim, Norway",IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,"4 Apr 2024","2024","17","","7260","7277","Globally, pests and plant diseases severely threaten forestry and agriculture. Plant protection could be substantially enhanced by using noncontact, extremely effective, and reasonably priced techniques for identifying and tracking pests and plant diseases across large geographic areas. Precision agriculture is the study of using other technologies, such as hyperspectral remote sensing, to increase cultivation instead of traditional agricultural methods with less negative environmental effects. In this article, we proposed a novel deep-learning architecture and optimization algorithm for crop leaf disease recognition. In the initial step, a multilevel contrast enhancement technique is proposed for a better visual of the disease on the leaves of cotton and wheat. After that, we proposed three novel residual block and self-attention mechanisms, named 3-residual block-deep convolutional neural network (RBNet) Self, 5-RBNet Self, and 9-RBNet Self. After that, the proposed models are trained on enhanced images and later extracted deep features from the self-attention layer. The 5-RBNET Self and 9-RBNET Self performed well in terms of accuracy and precision rate; therefore, we did not consider the 3-RBNET Self for the next process. The dragonfly optimization algorithm is proposed for the best feature selection and applied to the self-attention features of 5-RBNET Self and 9-RBNET Self models to improve the classification performance further and reduce the computational cost. The proposed method is evaluated on two publically available crop disease images, such as the cotton, wheat, and EuroSAT datasets. For both crops, the proposed method obtained a maximum accuracy of 98.60% and 93.90%, respectively, whereas for the EuroSAT, the proposed method obtained an accuracy of 83.10%. Compared to the results with recent techniques, the proposed method shows improved accuracy and precision rate.","2151-1535","","10.1109/JSTARS.2024.3378298","Deanship of Scientific Research, King Khalid University; Research Project(grant numbers:RGP.2/146/44); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10474107","Agriculture;classification;deep learning (DL);optimization;remote sensing (RS);self-attention","Feature extraction;Diseases;Crops;Cotton;Convolutional neural networks;Optimization;Remote sensing","","18","","73","CCBYNCND","19 Mar 2024","","","IEEE","IEEE Journals"
"Software defined networking agent demonstration to enable configuration and management of XGS-PON architectures","D. de Pintos; N. Merayo; C. Sangrador; J. C. Aguado; I. de Miguel; R. J. Duran Barroso","Universidad de Valladolid, Valladolid, Spain; Universidad de Valladolid, Valladolid, Spain; Universidad de Valladolid, Valladolid, Spain; Universidad de Valladolid, Valladolid, Spain; Universidad de Valladolid, Valladolid, Spain; Universidad de Valladolid, Valladolid, Spain",Journal of Optical Communications and Networking,"17 Aug 2023","2023","15","9","620","637","This paper describes the design and implementation of an OpenFlow software defined network (SDN) agent that manages and configures 10-gigabit-capable symmetric passive optical network (XGS-PON) architectures. Acting as an OpenFlow switch, the SDN agent communicates with an SDN controller using OpenFlow, while holding direct communication with the optical line terminal (OLT) through the chipset manufacturer-specific application programming interface, eliminating the need for emulating SDN layers in hardware devices. The proposal was evaluated through experiments conducted on a White Box XGS-PON OLT using the Open Network Operating System. The results demonstrate that the proposal facilitates a real-time SDN configuration of various Internet services, successfully fulfilling different quality of service requirements. Due to its ease of deployment, low complexity, smooth learning curve, scalability, and flexibility in integrating services, the proposal has significant potential. As a result, it offers a rapid SDN solution for configuring and testing new functionalities with minimal programming changes required in specific layers of the developed SDN agent.","1943-0639","","10.1364/JOCN.494694","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10223475","","Computer architecture;Proposals;Quality of service;Software;Passive optical networks;Optical network units;Bandwidth","","3","","","","17 Aug 2023","","","IEEE","IEEE Journals"
"Fuzzy Logic and Accelerated Reinforcement Learning-Based User Association for Dense C-RANs","R. T. Rodoshi; T. Kim; W. Choi","Department of Computer Engineering, Chosun University, Gwangju, Republic of Korea; School of Software, Hallym University, Chuncheon, Republic of Korea; Department of Computer Engineering, Chosun University, Gwangju, Republic of Korea",IEEE Access,"30 Aug 2021","2021","9","","117910","117924","Cloud radio access network (C-RAN) is a potential mobile network architecture providing seamless connectivity to users with high data rates by integrating it with the small-cell technology of 5G mobile communication systems. In C-RAN, base station functionality is divided into a baseband unit (BBU) and remote radio head (RRH); the BBUs from multiple sites are centralized and virtualized using cloud computing and virtualization techniques. Frequent handovers occur in the network, which results in control message flooding and repeated service outages because of the dense deployment of short-range RRHs and user mobility. It is necessary to optimize handover control parameters before the handover and re-associate the user with an RRH to minimize unnecessary handovers in the network. Traditional handover schemes rely on signal strengths of RRHs, which cause a large number of unnecessary handovers when a user moves within the coverage of multiple-overlapped RRHs. This study investigates the handover in C-RAN by carefully optimizing the handover control parameter and selecting the target RRH for handover. Our main goal is associating the user with an RRH such that association after the handover remains possible for as long as possible while maintaining the quality of service (QoS) requirements of the users. We have used fuzzy logic to optimize the handover control parameter and a reinforcement learning-based algorithm to select the target RRH. A key component of the proposed RL-based scheme is using an acceleration technique for the faster convergence of the algorithm. Numerical results show that the proposed scheme can significantly reduce the number of handovers while ensuring QoS requirements.","2169-3536","","10.1109/ACCESS.2021.3107325","Basic Science Research Program through the National Research Foundation of Korea (NRF); Ministry of Science and ICT (MSIT)(grant numbers:NRF-2019R1F1A1046687); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9521471","C-RAN;fuzzy logic;reinforcement learning;user association;handover","Handover;5G mobile communication;Optimization;Quality of service;Base stations;Fuzzy logic;Prediction algorithms","","5","","29","CCBY","24 Aug 2021","","","IEEE","IEEE Journals"
"Preserving Agents Connectivity Amidst Static Obstacles: A Distributed Predictive Supervision Approach within Robot Operating System","A. Casavola; V. D'Angelo; A. E. Qemmah; G. Gagliardi; F. Tedesco; F. A. Torchiaro","DIMES Engineering Department, University of Calabria, Rende, Cosenza, Italy; DIMES Engineering Department, University of Calabria, Rende, Cosenza, Italy; DIMES Engineering Department, University of Calabria, Rende, Cosenza, Italy; DIMES Engineering Department, University of Calabria, Rende, Cosenza, Italy; DIMES Engineering Department, University of Calabria, Rende, Cosenza, Italy; DIMES Engineering Department, University of Calabria, Rende, Cosenza, Italy",IEEE Transactions on Intelligent Vehicles,"","2024","PP","99","1","18","This work focuses on a novel distributed multilayer architecture that addresses both obstacle and collision avoidance and connectivity keeping prescriptions when supervising a group of autonomous vehicles operating in a formation. The fundamental principles of the approach are derived from well-known distributed command governor concepts, which are here expanded to enforce a minimum spanning tree for safe communication between the vehicles. The edges of this tree may be adjusted in real-time to enhance overall performance. Additionally, the on-line distributed determination of particular separation hyper-planes is employed to reduce the inherent nonconvexity of obstacle avoidance constraints. In order to assist the implementation in actual vehicles, a practical implementation of the control architecture on the Robot Operating System (ROS) is discussed, together with conditions that formally ensure the feasibility of the suggested method. Simulations on coordinating marine autonomous surface vehicles are offered using the Gazebo simulator to demonstrate the effectiveness of the proposed approach. Finally, a real-world experiment on marine surface vehicles showcases the implementability of the proposed strategy.","2379-8904","","10.1109/TIV.2024.3517315","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10807156","Obstacle Avoidance;Collision Avoidance;Formation Keeping;Distributed Command Governor;Constrained Control;Multi-Agent Coordination;Robot Operating System","Collision avoidance;Vehicle dynamics;Planning;Operating systems;Navigation;Computer architecture;Vectors;Tracking;Switches;Robot kinematics","","1","","","CCBY","18 Dec 2024","","","IEEE","IEEE Early Access Articles"
"Optimization of the Deployment of Relay Nodes in Cellular Networks","R. M. Mokhtar; H. M. Abdel-Atty; K. R. Mahmoud","Electrical Engineering Department, Faculty of Engineering, Port Said University, Port Said, Egypt; Electrical Engineering Department, Faculty of Engineering, Port Said University, Port Said, Egypt; Department of Electronics and Communications, Faculty of Engineering, Helwan University, Cairo, Egypt",IEEE Access,"3 Aug 2020","2020","8","","136605","136616","Significant and continuous contributions related to 4G/5G cellular networks are still accelerating the investigation of the approaches that can boost the cell characteristics following the new aspirations of the users. The challenge of achieving sufficient coverage at the cell edge; represents a constant concern for both users and operators; in addition to ensuring a reasonable cost, are the most important search fields and in our scope of interest. As relay nodes can provide a solution, a scenario for a plan of relay nodes deployment at the cell edge is proposed, taking into account the interference due to the relay nodes. Since optimization algorithms are effective in terms of planning, an advanced hybrid particle swarm optimization and gravitational search algorithm (PSOGSA) is applied to the proposed scenario to detect the optimum solution. The optimum solution represents the optimum plan that attains the best coverage with the minimum cost. We submit cost analysis depends on three trails of construction cost, power and channel cost efficiency. To highlight that the optimal plan has been revealed, another recently developed optimization algorithm, a simplified adaptive bat algorithm based on frequency (FSABA) and a classic particle swarm optimization (PSO) algorithm are also applied to the suggested scenario. The obtained results are compared with the related findings of the PSOGSA. From the simulations, it is found that the PSOGSA achieves better performance than the other two algorithms with fruitful and promising results, and the optimal plan featuring great coverage at the cell edge and cost-saving is attained.","2169-3536","","10.1109/ACCESS.2020.3011472","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9146529","A simplified adaptive bat algorithm based on frequency (FSABA);cell edge;particle swarm optimization and gravitational search algorithm (PSOGSA);relay nodes","Relays;Optimization;Interference;Planning;Signal to noise ratio;Microprocessors;Computer architecture","","5","","46","CCBY","23 Jul 2020","","","IEEE","IEEE Journals"
"EdgeAIBus: AI-Driven Joint Container Management and Model Selection Framework for Heterogeneous Edge Computing","B. Ali; M. Golec; S. S. Gill; F. Cuadrado; S. Uhlig","School of Electronic Engineering and Computer Science, Queen Mary University of London, London, U.K.; School of Electronic Engineering and Computer Science, Queen Mary University of London, London, U.K.; School of Electronic Engineering and Computer Science, Queen Mary University of London, London, U.K.; Technical University of Madrid (UPM), Madrid, Spain; School of Electronic Engineering and Computer Science, Queen Mary University of London, London, U.K.",IEEE Transactions on Parallel and Distributed Systems,"2 Oct 2025","2025","36","11","2412","2424","Containerized Edge computing offers lightweight, reliable, and quick solutions to latency-critical Machine Learning (ML) and Deep Learning (DL) applications. Existing solutions considering multiple Quality of Service (QoS) parameters either overlook the intricate relation of QoS parameters or pose significant scheduling overheads. Furthermore, reactive decision-making can damage Edge servers at peak load, incurring escalated costs and wasted computations. Resource provisioning, scheduling, and ML model selection substantially influence energy consumption, user-perceived accuracy, and delay-oriented Service Level Agreement (SLA) violations. Addressing contrasting objectives and QoS simultaneously while avoiding server faults is highly challenging in the exposed heterogeneous and resource-constrained Edge continuum. In this work, we propose the EdgeAIBus framework that offers a novel joint container management and ML model selection algorithm based on Importance Weighted Actor-Learner Architecture to optimize energy, accuracy, SLA violations, and avoid server faults. First, Patch Time Series Transformer (PatchTST) is utilized for CPU usage predictions of Edge servers for its 8.51% Root Mean Squared Error and 5.62% Mean Absolute Error. Leveraging pipelined predictions, EdgeAIBus conducts consolidation, resource oversubscription, and ML/DL model switching with possible migrations to conserve energy, maximize utilization and user-perceived accuracy, and reduce SLA violations. Simulation results show EdgeAIBus oversubscribed 110% cluster-wide CPU with real usage up to 70%, conserved 14 CPU cores, incurred less than 1% SLA violations with 2.54% drop in inference accuracy against industry-led Model Switching Balanced load and Google Kubernetes Optimized schedulers. Google Kubernetes Engine experiments demonstrate 80% oversubscription, 14 CPU cores conservation, 1% SLA violations, and 3.81% accuracy loss against the counterparts. Finally, constrained setting experiment analysis shows that PatchTST and EdgeAIBus can produce decisions within 100 ms in a 1-core and 1 GB memory device.","1558-2183","","10.1109/TPDS.2025.3602521","PhD Scholarship at Queen Mary University of London; HE ACES(grant numbers:101093126); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11139102","Edge computing;container migration;consolidation;deep reinforcement learning;Kubernetes;service level agreement;oversubscription;energy conservation","Containers;Accuracy;Servers;Switches;Service level agreements;Quality of service;Load modeling;Edge computing;Computational modeling;Scheduling","","2","","35","CCBY","25 Aug 2025","","","IEEE","IEEE Journals"
"Empowering Traffic Steering in 6G Open RAN With Deep Reinforcement Learning","F. Kavehmadavani; V. -D. Nguyen; T. X. Vu; S. Chatzinotas","Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg; College of Engineering and Computer Science and the Center for Environmental Intelligence, VinUniversity, Gia Lam, Hanoi, Vietnam; Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg",IEEE Transactions on Wireless Communications,"10 Oct 2024","2024","23","10","12782","12798","The sixth-generation (6G) wireless network landscape is evolving toward enhanced programmability, virtualization, and intelligence to support heterogeneous use cases. The O-RAN Alliance is pivotal in this transition, introducing a disaggregated architecture and open interfaces within the 6G network. Our paper explores an intelligent traffic steering (TS) scheme within the Open radio access network (RAN) architecture, aimed at improving overall system performance. Our novel TS algorithm efficiently manages diverse services, improving shared infrastructure performance amid unpredictable demand fluctuations. To address challenges like varying channel conditions, dynamic traffic demands, we propose a multi-layer optimization framework tailored to different timescales. Techniques such as long-short-term memory (LSTM), heuristics, and multi-agent deep reinforcement learning (MADRL) are employed within the non-real-time (non-RT) RAN intelligent controller (RIC). These techniques collaborate to make decisions on a larger timescale, defining custom control applications such as the intelligent TS-xAPP deployed at the near-real-time (near-RT) RIC. Meanwhile, optimization on a smaller timescale occurs at the RAN layer after receiving inferences/policies from RICs to address dynamic environments. The simulation results confirm the system’s effectiveness in intelligently steering traffic through a slice-aware scheme, improving eMBB throughput by an average of 99.42% over slice isolation.","1558-2248","","10.1109/TWC.2024.3396273","European Research Council (ERC) Actively Enhanced Cognition-based Framework for Design of Complex Systems (AGNOSTIC) project(grant numbers:H2020/ERC2020POC/957570/DREAM); Luxembourg National Research Fund, via project Risk-aware and Distributed Multiagent Reinforcement Learning for Resources and Control Management in Multilayer Ground-Air-Space Networks (RUTINE)(grant numbers:C22/IS/17220888); VinUniversity Seed Grant Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10528242","Deep reinforcement learning;open radio access network;traffic steering;network intelligence;traffic prediction;intelligent radio resource management","Ultra reliable low latency communication;Resource management;Throughput;Optimization;Quality of service;5G mobile communication;Long short term memory","","8","","46","CCBY","9 May 2024","","","IEEE","IEEE Journals"
"Scalable Satellite Handover Management in Non-Terrestrial Networks: A Distributed MADQL Approach","N. Badini; M. Jaber; M. Marchese; F. Patrone","Department of Electrical, Electronics and Telecommunications Engineering, and Naval Architecture (DITEN), University of Genoa, Genoa, Italy; Department of Electrical, Electronics and Telecommunications Engineering, and Naval Architecture (DITEN), University of Genoa, Genoa, Italy; Department of Electrical, Electronics and Telecommunications Engineering, and Naval Architecture (DITEN), University of Genoa, Genoa, Italy; Department of Electrical, Electronics and Telecommunications Engineering, and Naval Architecture (DITEN), University of Genoa, Genoa, Italy",IEEE Transactions on Aerospace and Electronic Systems,"","2025","PP","99","1","16","Satellite communications provide means for extending next-generation communication technology to areas beyond terrestrial network coverage. Multiple Low Earth Orbit (LEO) satellites have been deployed in constellations to offer ground users direct Internet connection at any time, place, and condition. However, integrating Non-Terrestrial Networks (NTNs) into terrestrial communication systems presents several challenges, including the management of handover strategies due to the rapid satellite movement. Even if previous studies have explored various approaches to optimize handovers in NTNs, they have often overlooked critical factors, such as user-specific data throughput requirements, limited satellite energy, and the need for dynamic adaptation to real-time network conditions. To address these gaps, this paper proposes a Scalable Multi-Agent Satellite Handover (SMASH) framework based on Distributed Multi-Agent Deep Q-Learning for optimized handover decisions and dynamic satellite selection. SMASH aims to ensure seamless connectivity while effectively managing satellite resources to meet diverse demands. It features an adaptive resource allocation strategy driven by user demands and network conditions, thereby ensuring application-specific Quality of Service requirements. We validate and evaluate SMASH using a satellite network simulator, conducting a comprehensive sensitivity analysis and benchmarking its performance against existing approaches in the literature. The proposed handover technique significantly enhances NTN communication performance by reducing the average number of handovers and optimizing satellite resource allocation, thereby preventing user blocking. The SMASH framework ensures continuous service delivery by dynamically adapting to fluctuations in both user demand and satellite resource availability.","1557-9603","","10.1109/TAES.2025.3594697","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11112684","Satellite Communications and Networking;Non-Terrestrial Networks;LEO Satellite Handover;Deep Reinforcement Learning;Resource Management","Handover;Satellites;Satellite broadcasting;Low earth orbit satellites;Resource management;Throughput;Quality of service;3GPP;Satellite antennas;Load modeling","","","","","CCBY","4 Aug 2025","","","IEEE","IEEE Early Access Articles"
"Synergy: An overlay internetworking architecture and implementation","M. Kwon; S. Fahmy","Department of Computer Science, Rochester Institute of Technology, Rochester, NY, USA; Computer Science department, Purdue University, West Lafayette, IN, USA",Journal of Communications and Networks,"21 Dec 2012","2010","12","2","181","190","A multitude of overlay network designs for resilient routing, multicasting, quality of service, content distribution, storage, and object location have been proposed. Overlay networks offer several attractive features, including ease of deployment, flexibility, adaptivity, and an infrastructure for collaboration among hosts. In this paper, we explore cooperation among co-existing, possibly heterogeneous, overlay networks. We discuss a spectrum of cooperative forwarding and information sharing services, and investigate the associated scalability, heterogeneity, and security problems. Motivated by these services, we design Synergy, a utility-based overlay internetworking architecture that fosters overlay cooperation. Our architecture promotes fair peering relationships to achieve synergism. Results from Internet experiments with cooperative forwarding overlays indicate that our Synergy prototype improves delay, throughput, and loss performance, while maintaining the autonomy and heterogeneity of individual overlay networks.","1976-5541","","10.1109/JCN.2010.6391375","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6391375","Cooperation;experimentation with real networks/ testbeds;overlay networks;peer-to-peer;routing;system design","Routing;Peer to peer computing;Computer architecture;Routing protocols;Bandwidth;Delay","","3","","41","","21 Dec 2012","","","KICS","KICS Journals"
"BHCNet: Neural Network-Based Brain Hemorrhage Classification Using Head CT Scan","M. F. Mushtaq; M. Shahroz; A. M. Aseere; H. Shah; R. Majeed; D. Shehzad; A. Samad","Department of Artificial Intelligence, The Islamia University of Bahawalpur, Bahawalpur, Punjab, Pakistan; Department of Computer Science, The Islamia University of Bahawalpur, Bahawalpur, Punjab, Pakistan; Department of Computer Science, King Khalid University, Abha, Saudi Arabia; Department of Computer Science, King Khalid University, Abha, Saudi Arabia; Directorate of IT, The Islamia University of Bahawalpur, Bahawalpur, Punjab, Pakistan; Department of Computer Science, National University of Computer and Emerging Sciences, Chiniot-Faislabad Campus, Islamabad, Pakistan; Department of Data Science, The Islamia University of Bahawalpur, Bahawalpur, Punjab, Pakistan",IEEE Access,"19 Aug 2021","2021","9","","113901","113916","Brain Hemorrhage is the eruption of the brain arteries due to high blood pressure or blood clotting that could be a cause of traumatic injury or death. It is the medical emergency in which a doctor also need years of experience to immediately diagnose the region of the internal bleeding before starting the treatment. In this study, the deep learning models Convolutional Neural Network (CNN), hybrid models CNN + LSTM and CNN + GRU are proposed for the Brain Hemorrhage classification. The 200 head CT scan images dataset is used to boost the accuracy rate and computational power of the deep learning models. The major aim of this study is to use the abstraction power of deep learning on a set of fewer images because in most crucial cases extensive datasets are not available on the spot. The image augmentation and imbalancing the dataset methods are adopted with CNN model to design a unique architecture and named as Brain Hemorrhage Classification based on Neural Network (BHCNet). The performance of the proposed approach are analyzed in terms of accuracy, precision, sensitivity, specificity and F1-score. Further, the experimental results are evaluated by comparative analyses of the balanced and imbalanced dataset with CNN, CNN + LSTM and CNN + GRU models. The promising results are achieved with CNN by imbalancing the dataset and gain highest accuracy that outperforms the hybrid CNN + LSTM and CNN + GRU models. The results reveals the effectiveness of the proposed model for accurate prediction to save the life of the patient in the meantime and fast employment in the real life scenario.","2169-3536","","10.1109/ACCESS.2021.3102740","Deanship of Scientific Research at King Khalid University, Abha, Saudi Arabia, through the Large Research Groups Program(grant numbers:2/177/2021); New Opportunities and Challenges of Smart Cities using Multi-agent Systems; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9507442","Brain hemorrhage;image classification;deep learning;CNN;image augmentation;CT scan","Hemorrhaging;Computed tomography;Brain modeling;Deep learning;Medical diagnostic imaging;Magnetic resonance imaging;Head","","31","","82","CCBY","5 Aug 2021","","","IEEE","IEEE Journals"
"Multimodal Pedestrian Trajectory Prediction Based on Relative Interactive Spatial-Temporal Graph","D. Zhao; T. Li; X. Zou; Y. He; L. Zhao; H. Chen; M. Zhuo","School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; Tiandi (Changzhou) Automation Company Ltd., Changzhou, China; Tiandi (Changzhou) Automation Company Ltd., Changzhou, China; Tiandi (Changzhou) Automation Company Ltd., Changzhou, China; Tiandi (Changzhou) Automation Company Ltd., Changzhou, China",IEEE Access,"29 Aug 2022","2022","10","","88707","88718","Predicting and understanding pedestrian intentions is crucial for autonomous vehicles and mobile robots to navigate in a crowd. However, the movement of pedestrian is random. Pedestrian trajectory modeling needs to consider not only the past movement of pedestrians, the interaction between different pedestrians, the constraints of static obstacles in the scene, but also multi-modal of the human trajectory, which brings challenges to pedestrian trajectory prediction. Most of the existing trajectory prediction methods only consider the interaction between pedestrians in the scene, ignoring the static obstacles in the scene can also have impacts on the trajectory of pedestrian. In this paper, a scalable relative interactive spatial-temporal graph generation adversarial network architecture (RISTG-GAN) is proposed to generate a reasonable multi-modal prediction trajectory by considering the interaction effects of all agents in the scene. Our method extends recent work on trajectory prediction. First, LSTM nodes are flexibly used to model the spatial-temporal graph of human-environment interactions, and the spatial-temporal graph is converted into feed-forward differentiable feature coding, and the time attention module is proposed to capture the trajectory information in time domain and learn the time dependence in long time range. Then, we capture the relative importance of the interaction of all agents in the scene on the pedestrian trajectory through the improved relative scaled dot product attention and use the generative adversarial network architecture for training to generate reasonable pedestrian future trajectory distribution. Experiments on five commonly used real public datasets show that RISTG-GAN is better than previous work in terms of reasoning speed, accuracy and the rationality of trajectory prediction.","2169-3536","","10.1109/ACCESS.2022.3200066","Science and Technology Innovation and Entrepreneurship Fund Project of Tiandi Technology Company Ltd.(grant numbers:2019-TD-ZD007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9862988","Pedestrian trajectory prediction;spatial-temporal graph;time attention;relative scaled dot product attention;generative adversarial network","Trajectory;Predictive models;Hidden Markov models;Logic gates;Generative adversarial networks;Legged locomotion;Visualization","","6","","49","CCBY","18 Aug 2022","","","IEEE","IEEE Journals"
"UResNet-Based Enhancement of Underwater Images Through Variational Contrast and Saturation","A. Jain; Shivam; S. Angelin Beulah; M. Sivagami","School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India; School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India; School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India; School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India",IEEE Access,"29 Aug 2025","2025","13","","149637","149656","Underwater imaging is an ever trending and evolving field in which the images obtained are subjected to enhancement to identify the critical features of the underwater world. Various enhancement approaches have evolved and certain issues have been identified in these techniques leading to a new technique. Generally, underwater images suffer from blurriness, color distortion, light absorption and scattering in water, low contrast issues which affect the overall clarity and visual appeal of the image. Our research demonstrates that hybrid preprocessing when combined with advanced deep learning models such as Underwater ResNet (UResNet) give high quality and visually appealing images. Three model variants have been explored in this work, the standard UResNet, UResNet augmented with a Sobel filter, and UResNet enhanced with a squeeze-and-excitation (SE) block. The models have employed on the EUVP (Enhancing Underwater Visual Perception) dataset. The core challenges such as color distortion, low contrast, and poor saturation have been overcome by the hybrid preprocessing pipeline, which combines Underwater White Balance (UWB) and Variational Contrast and Saturation Enhancement (VCSE) techniques that corrects the color imbalances, enhances the contrast, and amplifies the saturation before deep learning interference. The pre-processed images were given to all modified UResNet models and it was found that all models outperform the baseline model in both qualitative and quantitative evaluations. Among the three models that were modified, the SE-integrated model consistently delivered superior performance with all the metrics, highlighting significant improvements in color fidelity, contrast, edge definition, and overall image clarity. These results show the effectiveness of combining hybrid preprocessing with structure-aware deep learning architectures to improve underwater image quality and adaptability across diverse marine environments.","2169-3536","","10.1109/ACCESS.2025.3591362","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11087581","Sobel filter;squeeze-and-excitation block;underwater image enhancement;UResNet;UWB;VCSE","Image color analysis;Distortion;Deep learning;Image enhancement;Visualization;Adaptation models;Absorption;Lighting;Accuracy;Tuning","","1","","31","CCBY","22 Jul 2025","","","IEEE","IEEE Journals"
"Assessment of Urban Fabric for Smart Cities","X. Li; Z. Lv; I. H. Hijazi; H. Jiao; L. Li; K. Li","School of Urban Design, Wuhan University, Wuhan, China; Chinese Academy of Science, Shenzhen Institute of Advanced Technology, Beijing, China; Urban Planning Engineering Department, An-Najah National University, Nablus, Palestine; School of Urban Design, Wuhan University, Wuhan, China; Laboratory of Architectural Algorithm and Application, School of Architecture, Southeast University, Nanjing, China; School of Urban Design, Wuhan University, Wuhan, China",IEEE Access,"20 May 2017","2016","4","","373","382","Comprehensive understandings to the built environment especially the urban form is a prerequisite for building a smart city. This paper is based on computational methods to examine the urban fabric of Hankou, China, as a case study. Quantitative and comparative analyses are involved to understand the characteristics on the block scale, where massive demolition and new construction coincide with the existing historical context. Five urban fabric indicators are defined (i.e., density, compactness, fragmentation, variance, and cohesion) to conduct a case study for the 83 selected blocks using geographic information system tools and statistical analysis. Distribution patterns and correlations between these indicators are analyzed. Comparisons are made between typical blocks with high, median, and low fabric densities using comprehensive fabric indicators. The research results indicate that the organic order of the original urban fabric is facing damage, especially from arbitrary demolition, overinfilling, and spontaneous encroachment. Finally, this paper discusses how retaining the urban fabric makes the city a vibrant place to live. The sustainable development of a city should attach great importance to the protection and continuation of local characteristics of integrity and authenticity. The described analytical methods could contribute to the optimization of urban design strategies for future smart cities.","2169-3536","","10.1109/ACCESS.2016.2517072","National Natural Science Foundation of China(grant numbers:51408442); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7381572","smart cities;GIS;urban fabric;Hankou;hybridity;Chinese urbanization;Smart cities;GIS;urban fabric;Hankou;hybridity;Chinese urbanization","Construction industry;Urban areas;Urban areas;Electronic mail;Smart cities;China;Statistical analysis;Sustainable development;Geographic information systems","","28","","57","OAPA","13 Jan 2016","","","IEEE","IEEE Journals"
"Cooperative Multi-Agent Traffic Monitoring Can Reduce Camera Surveillance","D. A. Guastella; E. Pournaras","Machine Learning Group, Université Libre de Bruxelles, Brussels, Belgium; School of Computing, University of Leeds, Leeds, U.K",IEEE Access,"21 Dec 2023","2023","11","","142125","142145","Smart mobility initiatives encompass innovative methods to support traffic management experts in decisions for how to improve urban infrastructures and reduce carbon footprint. Accurate and continuous information about traffic is necessary to implement effectively such decisions. This is not always possible because of the cost of the information: it is not possible to install sensor devices at large scale because of financial costs and privacy; employing a plethora of sensors requires significant computational capabilities to process the generated data. A centralized data analysis can hinder real-time applications, and limit their practical deployment in traffic management systems. This paper introduces a novel privacy-aware method for estimating traffic density using edge computing and without over-deploying privacy-intrusive surveillance technologies such as cameras. The objective is to reduce the cost of collecting data while providing accurate information to support traffic operators in decision making. We evaluate the proposed solution using a realistic traffic data of Bologna in Italy. Results shows that it yields a 45% lower average estimation error compared to standard prediction methods. Virtual traffic monitoring devices are associated with software agents that collect data from simulated traffic and estimate traffic density measurements when this information is not available. In our experiments, when we replace 50% of camera devices with cooperative low-cost edge devices, we obtain an average percentage error of just 22%. This result indicates that the cooperation between virtual traffic monitoring devices offers a means to avoid massive deployment of camera surveillance devices using low-cost information provided by connected vehicles. We also compared the results to those obtained by standard regression techniques.","2169-3536","","10.1109/ACCESS.2023.3343620","Traffic prOcessing foR uRban EnvironmentS (TORRES), a Joint Research and Development Project; “Région de Bruxelles-Capitale-Innoviris”(grant numbers:2022-RDIR-59b); UK Research and Innovation (UKRI) Future Leaders Fellowship: ‘Digitally Assisted Collective Governance of Smart City Commons–ARTIO’(grant numbers:MR/W009560/1); Alan Turing Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10360829","Smart city;traffic monitoring;multi-agent systems;missing information estimation;Internet of Things;urban sensing","Monitoring;Estimation;Cameras;Soft sensors;Real-time systems;Density measurement;Computer architecture","","6","","30","CCBY","15 Dec 2023","","","IEEE","IEEE Journals"
"Analysis of Depth and Semantic Mask for Perceiving a Physical Environment Using Virtual Samples Generated by a GAN","J. Maldonado-Romo; M. Aldape-P&#x00E9;rez; A. Rodr&#x00ED;guez-Molina","Postgraduate Department, Instituto Polit&#x00E9;cnico Nacional, CIDETEC, Mexico City, Mexico; Postgraduate Department, Instituto Polit&#x00E9;cnico Nacional, CIDETEC, Mexico City, Mexico; Tecnológico Nacional de México/IT de Tlalnepantla, Research and Postgraduate Division, Estado de M&#x00E9;xico, Mexico",IEEE Access,"19 Jan 2022","2022","10","","5595","5607","Micro aerial vehicles (MAVs) can make explorations in 3D environments using technologies capable of perceiving the environment to map and estimate the location of objects that could cause collisions, such as Simultaneous Localization and Mapping (SLAM). Nevertheless, the agent needs to move during the environment mapping, reducing the flying time to employ additional activities. It has to be noted that adding more devices (sensors) to MAVs implies more power consumption. Since more energy to perform tasks is required, growing the dimensions of MAVs limits the flying time. Contrarily, Generative Adversarial Networks (GAN) have demonstrated the usefulness of creating images from one domain to another, but the GAN domain changes require a large number of samples. Therefore, an interoperability coefficient is employed to determine a minimum number of samples to connect the different domains. In order to prove the coefficient, the performance to estimate the depth and semantic mask between authentic and virtual samples with the number limited of samples is analyzed. Consequently, an RGB-D sensor can be replaced by a few samples of a real scenario based on GANs. Although GAN allows creating images with depth and semantic mask information, there is an additional problem to be tackled: the presence of intrinsic noise, where a simple GAN architecture is not enough. In this proposal, the performance of this solution against a physical RGB-D sensor (Microsoft Kinect V1) and other state-of-the-art approaches is compared. Experimental results allow us to affirm that this proposal is a viable option to replace a physical RGB-D sensor with limited information.","2169-3536","","10.1109/ACCESS.2021.3137797","Secretaría de Investigación y Posgrado (SIP); Comisión de Operación y Fomento de Actividades Académicas (COFAA) of the Instituto Politécnico Nacional (IPN); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9661297","Computer vision;perception environment;3D mapping;machine learning","Generative adversarial networks;Sensors;Semantics;Cost function;Generators;Three-dimensional displays;Navigation","","4","","61","CCBY","23 Dec 2021","","","IEEE","IEEE Journals"
"Contrast-aware image enhancement network for low-light images","J. Y. Park; I. K. Eom","Department of Electronics Engineering, Pusan National University, Pusan, Republic of Korea; Department of Electronics Engineering, Pusan National University, Pusan, Republic of Korea",IEEE Access,"","2025","PP","99","1","1","Low-light image enhancement is a challenging problem in computer vision due the inherently fragile nature of low-light images, which suffer from low brightness, poor contrast, and color distortion. This study proposes a contrast-aware low-light image enhancement network in the wavelet domain. The contrast measure defined as the ratio of the high-frequency coefficient to the low-frequency coefficient serves as a key factor in restoring natural illumination. The proposed network includes U-shaped lightening and sharpening blocks, complemented by lightened and sharpened feature attention blocks. The lightening block, which uses wavelet low-frequency subbands as input, is employed to restore brightness. The lightened information is then transmitted to high-frequency subbands through the lightened feature attention block. The sharpening block is used to enhance image detail within high-frequency subbands. The sharpened information is then relayed to the lightened low-frequency subbands to balance the image contrast. The proposed network achieves balanced contrast by facilitating the exchange of enhancement information between the low- and high-frequency subbands. Additionally, we introduce a saturation guide block to restore image color effectively. This study restores each component through wavelet decomposition and uses the concept of contrast to restore it to a natural image. This could be further developed by combining color space decomposition. The effectiveness of the proposed network is evaluated through extensive experiments on well-known benchmarks. Simulation results confirm that the proposed low-light enhancement network surpasses other state-of-the-art approaches.","2169-3536","","10.1109/ACCESS.2025.3629128","National Research Foundation of Korea(grant numbers:RS-2023-00243132); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11227097","Low-light image enhancement;contrast-aware;wavelet transform;sharpening back-projection;feature attention","Image color analysis;Image restoration;Brightness;Lighting;Image enhancement;Wavelet transforms;Wavelet domain;Reflectivity;Computer vision;Computer architecture","","","","","CCBY","5 Nov 2025","","","IEEE","IEEE Early Access Articles"
"Device Agent Assisted Blockchain Leveraged Framework for Internet of Things","T. M. Nasrullah; M. M. Islam; M. A. Uddin; M. A. Khan; M. A. Layek; A. Stranieri; E. -N. Huh","Department of Computer Science and Engineering, Jagannath University, Dhaka, Bangladesh; Department of Computer Science and Engineering, Jagannath University, Dhaka, Bangladesh; Department of Computer Science and Engineering, Jagannath University, Dhaka, Bangladesh; Department of Computer Science and Engineering, Jagannath University, Dhaka, Bangladesh; Department of Computer Science and Engineering, Jagannath University, Dhaka, Bangladesh; Internet Commerce Security Laboratory, Centre for Informatics and Applied Optimisation, Federation University, Ballarat, VIC, Australia; Department of Computer Science and Engineering, Kyung Hee University, Global Campus, Yongin, South Korea",IEEE Access,"6 Jan 2023","2023","11","","1254","1268","Blockchain (BC) is a burgeoning technology that has emerged as a promising solution to peer-to-peer communication security and privacy challenges. As a revolutionary technology, blockchain has drawn the attention of academics and researchers. Cryptocurrencies have already effectively utilized BC technology. Many researchers have sought to implement this technique in different sectors, including the Internet of Things. To store and manage IoT data, we present in this paper a lightweight BC-based architecture with a modified raft algorithm-based consensus protocol. We designed a Device Agent that executes a novel registration procedure to connect IoT devices to the blockchain. We implemented the framework on Docker using the Go programming language. We have simulated the framework on a Linux environment hosted in the cloud. We have conducted a detailed performance analysis using a variety of measures. The results demonstrate that our suggested solution is suitable for facilitating the management of IoT data with increased security and privacy. In terms of throughput and block generation time, the results indicate that our solution might be 40% to 45% faster than the existing blockchain.","2169-3536","","10.1109/ACCESS.2022.3231491","Ministry of Science and ICT (MSIT), South Korea, under the Grand Information Technology Research Center Support Program Supervised by the Institute for Information & Communications Technology Planning & Evaluation (IITP)(grant numbers:IITP-2022-2015-0-00742); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9996396","Blockchain;cryptocurrency;distributed;IoT;ledger;device agent;device registration;miners;docker","Internet of Things;Blockchains;Security;Medical services;Data privacy;Privacy;Bitcoin","","3","","44","CCBY","21 Dec 2022","","","IEEE","IEEE Journals"
"Adaptive Ruminant Optimization With LoRa-Based Communication for Formation Control of Multiple UAVs","M. Aamir Khan; Z. A. Ali; M. Haris Muneer; R. Hasan","Department of Electronic Engineering, Sir Syed University of Engineering and Technology, Karachi, Pakistan; Department of Electronic Engineering, Sir Syed University of Engineering and Technology, Karachi, Pakistan; Department of Underwater Acoustic Engineering, Harbin Engineering University, Harbin, China; Department of Science and Engineering, Southampton Solent University, Southampton, U.K.",IEEE Access,"9 May 2025","2025","13","","80076","80087","In a dynamic environment with mountains and hazardous peaks, avoiding collisions and maintaining the desired formation is a crucial problem. This paper addresses this problem by presenting a novel formation control strategy of a cluster of UAVs in three different scenarios. The first scenario is designed to test the designed algorithm and hence contains no obstacles. The second scenario introduces some obstacles in the form of mountains to see whether the proposed algorithm can avoid the obstacles while maintaining the formation. In the last scenario, all the UAVs join together in one big cluster and have to avoid the obstacles while maintaining the formation. To design the environment for the scenarios, this study uses graph theory. To address the aforementioned scenarios, this paper offers a novel strategy by integrating a bio-inspired algorithm called the Adaptive Ruminant Optimization Algorithm (AROA) with the Long Range (LoRa) communication to achieve the formation control of multiple UAVs. Initially, AROA offers the best agents of each of the swarm. Then, the proposed method helps choose the best agent to be the leader for each of the swarm. The leader of each swarm finds the best trajectory for each swarm. LoRa-based networking technique is used for the connectivity between the UAVs. In addition, this study uses basis splines (B-splines) to smooth the planned trajectories of UAVs. Lastly, simulations demonstrate the better convergence and efficiency of the designed strategy by comparing it with classic algorithms. The simulations also show that the proposed method successfully maintains formation control in all three scenarios.","2169-3536","","10.1109/ACCESS.2025.3565815","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10980250","Ruminant optimization algorithm;long range communication;formation control and path planning","Optimization;Formation control;LoRa;Autonomous aerial vehicles;Classification algorithms;Clustering algorithms;Resource management;Computer architecture;Biological system modeling;Trajectory","","","","29","CCBY","30 Apr 2025","","","IEEE","IEEE Journals"
"Industrial Foundation Model","L. Ren; H. Wang; J. Dong; Z. Jia; S. Li; Y. Wang; Y. Laili; D. Huang; L. Zhang; B. Li","School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China",IEEE Transactions on Cybernetics,"23 Apr 2025","2025","55","5","2286","2301","Recently, foundation models (such as ChatGPT) have emerged with powerful learning, understanding, and generalization abilities, showcasing tremendous potential to revolutionarily promote modern industry. Despite significant advancements in various fields, existing general foundation models face challenges in industry when dealing with the data of specialized modalities, the tasks of varying-scenario with multiple processes, and the requirements of trustworthy output, which makes industrial foundation model (IFM) a necessity. This article proposes a system architecture of termed IFMsys, including model training, model adaptation, and model application. Specifically, in model training, a base model is constructed by pretraining on multimodal industrial data and fine-tuning with fundamental industrial mechanisms. In model adaptation, the base model is developed into a series of task-oriented and domain-specific IFMs through fine-tuning with representative tasks and domain knowledge. In model application, an industrial agent-centric collaboration system and a comprehensive application framework of IFM are proposed to enhance the industrial product lifecycle applications. In addition, a prototype system of the IFM, namely, MetaIndux, is delivered, with application examples presented in typical industrial tasks. Finally, future research directions and open issues of IFM are prospected. We hope this article will inspire the advancements in the theories, technologies, and applications in this emerging research field of IFM.","2168-2275","","10.1109/TCYB.2025.3527632","National Science Foundation of China (NSFC)(grant numbers:62225302,623B2014,62173023); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10922728","AIGC;embodied intelligence;industrial agent;industrial AI;industrial foundation model (IFM);intelligent manufacturing;MetaIndux","Foundation models;Adaptation models;Solid modeling;Data models;Training;Manufacturing;Maintenance;Industries;Systems architecture;Research and development","","10","","49","CCBYNCND","11 Mar 2025","","","IEEE","IEEE Journals"
"Robust Myocardial Perfusion MRI Quantification With DeepFermi","S. Brahma; A. Kofler; F. F. Zimmermann; T. Schaeffter; A. Chiribiri; C. Kolbitsch","Physikalisch-Technische Bundesanstalt, Braunschweig, Germany; Physikalisch-Technische Bundesanstalt, Germany; Physikalisch-Technische Bundesanstalt, Germany; Physikalisch-Technische Bundesanstalt, Germany; School of Imaging Sciences and Biomedical Engineering, King's College London, U.K.; Physikalisch-Technische Bundesanstalt, Germany",IEEE Transactions on Biomedical Engineering,"20 Feb 2025","2025","72","3","1031","1044","Stress perfusion cardiac magnetic resonance is an important technique for examining and assessing the blood supply of the myocardium. Currently, the majority of clinical perfusion scans are evaluated based on visual assessment by experienced clinicians. This makes the process subjective, and to this end, quantitative methods have been proposed to offer a more user-independent assessment of perfusion. These methods, however, rely on time-consuming deconvolution analysis and are susceptible to data outliers caused by artifacts due to cardiac or respiratory motion. In our work, we introduce a novel deep-learning method that integrates the commonly used Fermi function with a neural network architecture for fast, accurate, and robust myocardial perfusion quantification. This approach employs the Fermi model to ensure that the perfusion maps are consistent with measured data, while also utilizing a prior based on a 3D convolutional neural network to generalize spatio-temporal information across different patient data. Our network is trained within a self-supervised learning framework, which circumvents the need for ground-truth perfusion labels that are challenging to obtain. Furthermore, we extended this training methodology by adopting a technique that ensures estimations are resistant to data outliers, thereby improving robustness against motion artifacts. Our simulation experiments demonstrated an overall improvement in the accuracy and robustness of perfusion parameter estimation, consistently outperforming traditional deconvolution analysis algorithms across varying Signal-to-Noise Ratio scenarios in the presence of data outliers. For the in vivo studies, our method generated robust perfusion estimates that aligned with clinical diagnoses, while being approximately five times faster than conventional algorithms.","1558-2531","","10.1109/TBME.2024.3485233","Deutsche Forschungsgemeinschaft(grant numbers:289347353,GRK2260,BIOQIC,372486779,SFB,1340); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10731565","Deep learning;fermi-deconvolution;magnetic resonance imaging;myocardial perfusion quantification","Myocardium;Optimization;Robustness;Signal to noise ratio;Convolutional neural networks;Accuracy;Visualization;Deep learning;Magnetic resonance imaging","Humans;Deep Learning;Myocardial Perfusion Imaging;Heart;Algorithms;Magnetic Resonance Imaging;Neural Networks, Computer;Image Processing, Computer-Assisted;Perfusion Magnetic Resonance Imaging","2","","59","CCBY","23 Oct 2024","","","IEEE","IEEE Journals"
"Research on smart wireless aerial networks facilitating digital twin construction","G. K. Tran; J. Nakazato; K. Suto; H. So; H. Iwamoto","Institute of Science Tokyo; Tokyo University of Science; Hokkaido University; Kogakuin University; Fuji Television Network, Inc.; Institute of Science Tokyo",IEICE Transactions on Communications,"","2025","PP","99","1","13","This paper proposes a comprehensive framework for constructing smart wireless aerial networks to support high-fidelity digital twin (DT) systems. To meet the stringent data rate demands of airborne Light Detection and Ranging (LiDAR) sensing, we analyze the required throughput for point cloud transmission and design a millimeter-wave (mmWave) aerial link budget model. A software-defined architecture integrating Network Function Virtualization/Software Defined Networking (NFV/SDN) is introduced to enable dynamic Unmanned Aerial Vehicle (UAV) orchestration, routing, and network slicing. To enhance robustness and efficiency, we propose two application-layer innovations: a multi-route redundant communication framework and a semantic image transmission protocol using deep joint source-channel coding (DJSCC) with feature-based elastic compression. Furthermore, we implement a multi-agent reinforcement learning strategy to enable autonomous UAV placement and relay network formation in dynamic environments. Simulation results demonstrate the proposed system's scalability, adaptability, and potential to enable reliable and efficient DT construction across diverse deployment scenarios.","1745-1345","","10.23919/transcom.2025SCI0001","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11223841","mmWave;UAV;digital twin;meshed network;NFV/SDN;semantic communication;autonomous placement","Autonomous aerial vehicles;Laser radar;Millimeter wave communication;Wireless sensor networks;Digital twins;Point cloud compression;Drones;Aperture antennas;Noise;Bandwidth","","","","","","31 Oct 2025","","","IEICE","IEICE Early Access Articles"
"Twin Delayed Deep Deterministic Policy Gradient for Intelligent Optimization in STAR-RIS-Assisted Wireless Networks","M. Iqbal; M. Ali; T. Ashraf; A. Kaushik; M. S. AKRAM; F. Sajid; J. -Y. Pan","Department of Communications Engineering, National Chung Cheng University, Minxiong, Taiwan; Department of Electrical Engineering, National University of Sciences and Technology (NUST), Islamabad, Pakistan; Department of Communications Engineering, National Chung Cheng University, Minxiong, Taiwan; Chief Innovation Officer (CIO) at the RakFort, Ireland, and IIITD, India; Department of Electrical Engineering, National University of Sciences and Technology (NUST), Islamabad, Pakistan; School of Electronic and Information Engineering, Changchun University of Science and Technology, Changchun, China; Department of Communications Engineering, National Chung Cheng University, Minxiong, Taiwan",IEEE Open Journal of the Communications Society,"","2025","PP","99","1","1","Reconfigurable intelligent surfaces (RIS) have emerged as a key technology to enhance the performance of next-generation wireless networks by intelligently reconfiguring the propagation environment. In particular, simultaneously transmitting and reflecting RIS (STAR-RIS) extend this paradigm by enabling full-space coverage through concurrent reflection and transmission. This paper investigates a downlink multiple-input single-output (MISO) system assisted by a STAR-RIS and addresses the joint optimization of base station beamforming and RIS coefficients. To tackle the inherent non-convexity of this problem, we propose a reinforcement learning framework based on the Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm. The proposed approach formulates the design task as a continuous control problem, allowing the agent to directly learn interference-aware policies that adapt to dynamic channel conditions. Extensive simulations validate the effectiveness of the proposed framework. The results demonstrate that the TD3-based policy achieves stable convergence and significantly improves the achievable sum rate compared to the baseline Deep Deterministic Policy Gradient (DDPG) method and the passive RIS benchmark. Performance scaling with the number of RIS elements and transmit power is clearly observed, confirming the scalability of the approach. In addition, hyperparameter sensitivity analysis highlights the importance of learning rate and decay parameter tuning for robust training. Cumulative distribution function (CDF) comparisons further show that the proposed framework enhances both average throughput and reliability across different channel realizations. The findings establish deep reinforcement learning, and TD3 in particular, as a promising tool for real-time optimization in STAR-RIS-assisted wireless systems. The proposed framework provides a flexible and scalable solution for intelligent resource allocation, paving the way for more reliable and efficient 6G communication networks.","2644-125X","","10.1109/OJCOMS.2025.3631341","National Science and Technology Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11240115","RIS;STAR-RIS;MISO systems;Deep Reinforcement Learning (DRL);TD3;Beamforming Optimization;6G Networks","Optimization;Wireless communication;Array signal processing;MISO;Reconfigurable intelligent surfaces;Wireless sensor networks;Resource management;NOMA;Energy efficiency;Computer architecture","","","","","CCBY","11 Nov 2025","","","IEEE","IEEE Early Access Articles"
"Toward Fairer and More Accurate Real-Time Pedestrian Attribute Recognition for Enhanced Women’s Safety: A Domain-Adversarial Multi-Head Model With Agent-Based Reporting","M. Balaji; G. Anitha","Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Chennai, India; Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Chennai, India",IEEE Access,"15 Aug 2025","2025","13","","141018","141037","Effective surveillance systems play a vital role in improving public security, most important among which are applications related to women’s security, where the capacity to correctly carry out Pedestrian Attribute Recognition (PAR) is of utmost importance. Current PAR models are susceptible to being thrown off by dataset bias, mainly gender bias due to training set imbalance, resulting in suboptimal generalization and incorrect prediction across groups. This paper solves the challenges above by creating a Domain-Adversarial Training for Multi-Head Pedestrian Attribute Recognition (DAMH-PAR) model. DAMH-PAR uses a domain-adversarial training method combined with a multi-head structure to provide specialized training to various sets of attributes. The model learns invariant domain features upon training independent “expert” heads per dataset, which are chosen during inference to produce detailed pedestrian descriptions. The usefulness of the model is established by its capacity to predict pedestrian attributes accurately from security feeds even under heavy lighting. Such details, combined with violence detection and proximity modules, forms critical contextual information for automated safety systems. Testing DAMH-PAR model on PETA and PA-100K datasets reveals significant performance improvement compared to existing top-performing benchmarks. The DAMH-PAR model achieves 90.50% Mean Accuracy on PETA and 94.31% accuracy on PA-100K, which is more than the previously established standards. The performance highlights the potential of the suggested methodology to develop more effective and unbiased PAR models for meaningful development in security and safety surveillance tasks.","2169-3536","","10.1109/ACCESS.2025.3592975","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11097321","Domain discriminator;domain-adversarial training (DAT);gradient reversal layer (GRL);inception-ResNet-v2;LLM;multi-head architecture;pedestrian attribute recognition (PAR);YOLO","Pedestrians;Surveillance;Training;Security;Feature extraction;Safety;Real-time systems;Computational modeling;Accuracy;Deep learning","","","","40","CCBYNCND","28 Jul 2025","","","IEEE","IEEE Journals"
"An Adaptive Multi-Agent LLM-Based Clinical Decision Support System Integrating Biomedical RAG and Web Intelligence","Ç. U. Öğdü; K. Arslanoğlu; M. Karaköse","Department of Computer Engineering, Fırat University, Elâzığ, Türkiye; Department of Computer Engineering, Fırat University, Elâzığ, Türkiye; Department of Computer Engineering, Fırat University, Elâzığ, Türkiye",IEEE Access,"30 Sep 2025","2025","13","","167390","167404","Increasing data complexity in clinical decision-making processes hinders physicians’ ability to make rapid and accurate decisions. This study proposes an innovative solution to this problem by designing a multi-layered, adaptive Clinical Decision Support System (CDSS) comprising interacting large language model (LLM) agents. The proposed system performs semantic-level information retrieval using a BioBERT-based vector database, enhances information retrieval by accessing up-to-date medical resources via the web, and restructures outputs by activating an adaptive optimization loop in low-confidence situations. Through the structuring of clinical texts, cross-validation of symptom analyses with literature and internet sources, and collaborative data fusion among agents, the system integrates multi-source data and produces consistent decisions. In experiments conducted on the MedQA, PubMedQA, and MedBullets datasets, the system achieved accuracies of 94%, 88%, and 84%, respectively, representing substantial improvements over state-of-the-art methods and demonstrating the significance of the proposed architecture for clinical decision-making reliability. This framework is not merely an information retrieval engine; it is a clinical intelligence partner designed to learn, actively contribute to the decision process, and focus on reliability. In contrast to current CDSS protocols, which frequently depend on static modules or single-agent models, our architecture tackles some of the shortcomings in timeliness, multi-source evidence fusion, and confidence calibration. This originality enables the system to be a next-generation clinical intelligence partner by enabling an unprecedented level of transparency, customizability, and adaptability in real-world decision-making processes.","2169-3536","","10.1109/ACCESS.2025.3613340","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11176078","Clinical decision support system;large language models;multi-agent system","Accuracy;Reliability;Real-time systems;Medical diagnostic imaging;Large language models;Data integration;Protocols;Heuristic algorithms;Decision support systems;Databases","","","","35","CCBY","23 Sep 2025","","","IEEE","IEEE Journals"
"An Intelligent SDWN Routing Algorithm Based on Network Situational Awareness and Deep Reinforcement Learning","J. Li; M. Ye; L. Huang; X. Deng; H. Qiu; Y. Wang; Q. Jiang","School of Information and Communication, Guilin University of Electronic Technology, Guilin, China; School of Information and Communication, Guilin University of Electronic Technology, Guilin, China; School of Computer Science and Information Security, Guilin University of Electronic Technology, Guilin, China; School of Information and Communication, Guilin University of Electronic Technology, Guilin, China; School of Information and Communication, Guilin University of Electronic Technology, Guilin, China; School of Computer Science and Information Security, Guilin University of Electronic Technology, Guilin, China; Guangxi Key Laboratory of Wireless Broadband Communication and Signal Processing, Guilin University of Electronic Technology, Guilin, China",IEEE Access,"10 Aug 2023","2023","11","","83322","83342","To address the challenges of obtaining network state information, flexibly forwarding data, and improving the communication quality of service (QoS) in wireless network transmission environments in response to dynamic changes in network topology, this paper introduces an intelligent routing algorithm based on deep reinforcement learning (DRL) with network situational awareness under a software-defined wireless networking (SDWN) architecture. First, comprehensive network traffic information is collected under the SDWN architecture, and a graph convolutional network-gated recurrent unit (GCN-GRU) prediction mechanism is used to perceive future traffic trends. Second, a proximal policy optimization (PPO) DRL-based data forwarding mechanism is designed in the knowledge plane. The predicted network traffic matrix and topology information matrix are treated as the DRL environment, while next-hop adjacent nodes are treated as executable actions, and action selection policies are designed for different network conditions. To guide the learning and improvement of the DRL agent’s routing strategy, reward functions of different forms are designed by utilizing network link information and different penalty mechanisms. Additionally, importance sampling steps and gradient clipping methods are employed during gradient updating to enhance the convergence speed and stability of the designed intelligent routing method. Experimental results show that this solution outperforms traditional routing methods in network throughput, delay, packet loss rate, and wireless node distance. Compared to value-function-based Dueling Deep Q-Network (DQN) routing, the convergence of the proposed method is significantly faster and more stable. Simultaneously, hardware storage consumption is reduced, and real-time routing decisions can be made using the current network state information. The source code can be accessed at https://github.com/GuetYe/DRL-PPONSA.","2169-3536","","10.1109/ACCESS.2023.3302178","National Natural Science Foundation of China(grant numbers:62161006,62172095); Subsidization of Innovation Project of Guangxi Graduate Education(grant numbers:YCSW2023310); Key Laboratory of Cognitive Radio and Information Processing, Ministry of Education, Guilin University of Electronic Technology(grant numbers:CRKL220103); Guangxi Key Laboratory of Wireless Wideband Communication and Signal Processing(grant numbers:GXKL06220110,GXKL06230102); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10209181","Deep reinforcement learning;gradient clipping;intelligent routing;importance sampling;network situational awareness;software-defined wireless networking","Routing;Prediction algorithms;Heuristic algorithms;Predictive models;Wireless networks;Optimization methods;Data models","","10","","51","CCBYNCND","4 Aug 2023","","","IEEE","IEEE Journals"
"Autonomous Coordinated Control Strategy for Complex Process of Traffic Information Physical Fusion System Based on Big Data","G. Yan; H. Wang","College of Civil Engineering, Chongqing Vocational Institute of Engineering, Chongqing, China; School of Management, Qingdao Agricultural University, Qingdao, China",IEEE Access,"18 Aug 2020","2020","8","","148370","148377","In the era of big data, the global data is growing explosively. The huge growth rate makes data processing and storage difficult, especially in the field of transportation. Based on the above background, this paper aims to study the autonomous coordinated control strategy for the complex process of traffic information physical fusion system based on big data. In this paper, the information physical fusion system is applied to the modern transportation system, and it is used to realize the high integration of computation, communication and control. Realize the independent and coordinated control of the transportation system. This paper proposes an autonomous traffic management mechanism based on multi-agent CPS system. In view of the instability and untimely of the original control strategy, a new traffic optimization control strategy conflict reduction control strategy is proposed. In order to solve the complexity of traffic system, the generation method of CPS autonomous control strategy based on multi-agent is studied and analyzed. Through the evaluation and verification of the conflict reduction control strategy and the online simulation of the incremental data synchronization strategy, it can be seen that the inconsistency ratio curves of message quantity and byte transmission quantity are always kept at a relatively low level, 1% and 2%, respectively. During the whole experiment, the average number of inconsistent messages and byte transmission of the agent are ideally controlled at 1.2 messages / train and 0.5kb/train.","2169-3536","","10.1109/ACCESS.2020.3008820","Shandong Province Social Science Project(grant numbers:18CGLJ35); Project of Teaching Steering Committee of Logistics Management and Engineering Specialty(grant numbers:JZW2019123); Qingdao Shuangbai Research Project 2019 Project(grant numbers:2019-C-01); 2019 Shandong Humanities and Social Sciences Project(grant numbers:19-ZZ-GL-09); 2019 Qingdao Social Science Planning Research Project(grant numbers:QDSKL1901168); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9139224","Information physics fusion production system;multi-agent system;complex process;control strategy;big data","Process control;Task analysis;Sensors;Big Data;Computer architecture;Distributed databases;Control systems","","2","","25","CCBY","13 Jul 2020","","","IEEE","IEEE Journals"
"An Automated Framework of Superpixels-Saliency Map and Gated Recurrent Unit Deep Convolutional Neural Network for Land Cover and Crops Disease Classification","I. Haider; M. A. Khan; M. Nazir; S. Masood; N. Kraiem; D. Abdulaziz Alhammadi","Department of Computer Science, HITEC University, Taxila, Pakistan; Department of Artificial Intelligence, College of Computer Engineering and Science, Prince Mohammad Bin Fahd University, Dhahran, Saudi Arabia; Department of Computer Science, HITEC University, Taxila, Pakistan; IRC for Finance and Digital Economy, King Fahd University of Petroleum and Minerals, Dhahran, Saudi Arabia; College of Computer Science, King Khalid University, Abha, Saudi Arabia; Department of Information Systems, College of Computer and Information Sciences, Princess Nourah bint Abdulrahman University, P.O.Box 84428, Riyadh, Saudi Arabia",IEEE Access,"6 May 2025","2025","13","","76370","76387","In this work, we proposed an automated deep learning and saliency map architecture for the segmentation of crops, leaf disease segmentation, and land cover classification. The proposed framework is based on two embedded steps. In the first step, crop leaf disease segmentation was performed using superpixel clustering-based saliency maps and Bayesian optimization. The contrast enhancement technique is designed in the first segmentation phase and is passed to the saliency technique for the disease segmentation. In the second phase, EfficientNet-b0 architecture is fine-tuned with hyperparameters optimized via Bayesian Optimization. Also, the fine-tuned model is embedded with a single self-attention residual block fused with an efficient average pool layer. Training has been performed on segmented and contrast-enhanced images that were later fused using a serial-embedded approach. The extracted features in the testing phase are further optimized using the modified moth flame-controlled bisection (MFcB) technique. Finally, the extracted features are classified using machine learning classifiers for the final classification. Experiments are performed on the publically available cucumber leaf dataset and Remote sensing dataset with an improved accuracy of 97.6% and 92.90%, respectively. A comparison with state-of-the-art techniques shows that the proposed architecture has improved performance.","2169-3536","","10.1109/ACCESS.2025.3561151","Deanship of Scientific Research at King Khalid University through Large Group Research Project(grant numbers:RGP2/428/46); Princess Nourah bint Abdulrahman University Researchers Supporting Project, Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia(grant numbers:PNURSP2025R508); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10965697","Cucumber leaf disease;contrast enhancement;superpixel clustering;saliency map;deep learning;optimization;classification","Diseases;Accuracy;Feature extraction;Crops;Image segmentation;Optimization;Deep learning;Training;Remote sensing;Overfitting","","3","","55","CCBY","15 Apr 2025","","","IEEE","IEEE Journals"
"Vibration Control of Piezoelectric Cantilever Beam With Physics-Informed Neural Networks","J. Lao; Y. Chen; H. Li","School of Intelligent Manufacturing, Hangzhou Polytechnic, Fuyang, Hangzhou, Zhejiang, China; School of Intelligent Manufacturing, Hangzhou Polytechnic, Fuyang, Hangzhou, Zhejiang, China; School of Intelligent Manufacturing, Hangzhou Polytechnic, Fuyang, Hangzhou, Zhejiang, China",IEEE Access,"22 Aug 2025","2025","13","","145442","145450","Intelligent actuators, particularly piezoelectric actuators, are widely used for vibration control of engineering structures like beams, plates, and shells due to their advantages of good linearity, high precision, and simple configuration. However, traditional control methods often suffer from limited adaptability to complex dynamic environments. This paper proposes a Physics-Informed Neural Networks (PINNs) enhanced Deep Reinforcement Learning (DRL) framework for high-precision vibration control of piezoelectric cantilever beams. Unlike conventional model-based methods, our approach integrates the Euler-Bernoulli beam dynamics directly into the DRL training process, generating voltage control strategies under physical constraints through joint optimization of data-driven loss and partial differential equation (PDE) residuals. A Double Deep Q-Network (DDQN) agent observes real-time tip displacement and velocity, then outputs voltage actions. In the paper, the fundamental electromechanical coupling mechanism is established based on the cantilever beam’s governing equations and sensor equations of general shell structures. Employing modal expansion methods, we derive both the modal voltage expression and the modal force formulation for the piezoelectric actuator. The architecture of the Deep Reinforcement Learning (DRL) controller—specifically a Physics-Informed Double Deep Q-Network and its underlying neural network structure are subsequently detailed. Evaluations across the first three vibration modes under free decay, sinusoidal excitation and white noise loads demonstrate that the PINNs-DRL controller significantly outperforms conventional negative velocity feedback (NVF) in suppressing transient oscillations and residual vibrations.","2169-3536","","10.1109/ACCESS.2025.3598501","Scientific Research Fund of Zhejiang Provincial Education Department(grant numbers:Y202352502,Y202352510); Hangzhou Joint Fund of Zhejiang Provincial Natural Science Foundation of China(grant numbers:LHZY24A010006); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11123844","Vibration control;cantilever beam;piezoelectric actuator;deep reinforcement learning","Structural beams;Vibrations;Vibration control;Actuators;Piezoelectric actuators;Strain;Deep reinforcement learning;Adaptation models;PD control;Mathematical models","","","","31","CCBY","13 Aug 2025","","","IEEE","IEEE Journals"
"SPARQ: Efficient Entanglement Distribution and Routing in Space–Air–Ground Quantum Networks","M. Shaban; M. Ismail; W. Saad","Cybersecurity Education, Research, and Outreach Center and the Department of Computer Science, Tennessee Tech University, Cookeville, TN, USA; Cybersecurity Education, Research, and Outreach Center and the Department of Computer Science, Tennessee Tech University, Cookeville, TN, USA; Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA",IEEE Transactions on Quantum Engineering,"18 Oct 2024","2024","5","","1","20","In this article, a space–air–ground quantum (SPARQ) network is developed as a means for providing a seamless on-demand entanglement distribution. The node mobility in SPARQ poses significant challenges to entanglement routing. Existing quantum routing algorithms focus on stationary ground nodes and utilize link distance as an optimality metric, which is unrealistic for dynamic systems, like SPARQ. Moreover, in contrast to the prior art that assumes homogeneous nodes, SPARQ encompasses heterogeneous nodes with different functionalities further complicates the entanglement distribution. To solve the entanglement routing problem, a deep reinforcement learning (RL) framework is proposed and trained using deep Q-network (DQN) on multiple graphs of SPARQ to account for the network dynamics. Subsequently, an entanglement distribution policy, third-party entanglement distribution (TPED), is proposed to establish entanglement between communication parties. A realistic quantum network simulator is designed for performance evaluation. Simulation results show that the TPED policy improves entanglement fidelity by 3% and reduces memory consumption by 50% compared with benchmark. The results also show that the proposed DQN algorithm improves the number of resolved teleportation requests by 39% compared with shortest path baseline and the entanglement fidelity by 2% compared with an RL algorithm that is based on long short-term memory. It also improved entanglement fidelity by 6% and 9% compared with state-of-the-art benchmarks. Moreover, the entanglement fidelity is improved by 15% compared with DQN trained on a snapshot of SPARQ. Additionally, SPARQ enhances the average entanglement fidelity by 23.5% compared with existing networks spanning only space and ground layers.","2689-1808","","10.1109/TQE.2024.3464572","National Science Foundation(grant numbers:2210251); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10684482","Entanglement distribution;entanglement fidelity;entanglement swapping;quantum routing;space–air–ground quantum (SPARQ)","Quantum entanglement;Routing;Quantum networks;Repeaters;Qubit;Teleportation;Network architecture;Air to ground communication","","4","","61","CCBYNCND","19 Sep 2024","","","IEEE","IEEE Journals"
"EdgeMatch: A Smart Approach for Scheduling IoT-Edge Tasks With Multiple Criteria Using Game Theory","A. Bandyopadhyay; V. Mishra; S. Swain; K. Chatterjee; S. Dey; S. Mallik; A. Al-Rasheed; M. Abbas; B. O. Soufiene","School of Computer Engineering, Kalinga Institute of Industrial Technology Deemed to be University, Bhubaneswar, Odisha, India; School of Computer Engineering, Kalinga Institute of Industrial Technology Deemed to be University, Bhubaneswar, Odisha, India; School of Computer Engineering, Kalinga Institute of Industrial Technology Deemed to be University, Bhubaneswar, Odisha, India; Department of Computer Science and Engineering, Nalla Malla Reddy Engineering College, Hyderabad, India; Indian Institute of Technology Ropar, Rupnagar, India; Harvard T. H. Chan School of Public Health, Boston, MA, USA; Department of Information Systems, College of Computer and Information Sciences, Princess Nourah bint Abdulrahman University, P.O. Box 84428, Riyadh, Saudi Arabia; Department of Electrical Engineering, College of Engineering, King Khalid University, Abha, Saudi Arabia; Prince Laboratory Research, ISITcom, University of Sousse, Hammam Sousse, Sousse, Tunisia",IEEE Access,"17 Jan 2024","2024","12","","7609","7623","For an extended period, a technological architecture known as cloud IoT links IoT devices to servers located in cloud data centers. Real-time data analytic are made possible by this, enabling better, data-driven decision making, optimization, and risk reduction. Since cloud systems are often located at a considerable distance from IoT devices, the rise of time-sensitive IoT applications has driven the requirement to extend cloud architecture for timely delivery of critical services. Balancing the allocation of IoT services to appropriate edge nodes while guaranteeing low latency and efficient resource utilization remains a challenging task. Since edge nodes have lower resource capabilities than the cloud. The primary drawback of current methods in this situation is that they only tackle the scheduling issue from one side. Task scheduling plays a pivotal role in various domains, including cloud computing, operating systems, and parallel processing, enabling effective management of computational resources. In this research, we provide a multiple-factor autonomous IoT-Edge scheduling method based on game theory to solve this issue. Our strategy involves two distinct scenarios. In the first scenario, we introduced an algorithm containing choices for the IoT and edge nodes, allowing them to evaluate each other using factors such as delay and resource usage. The second scenario involves both a centralized and a distributed scheduling approach, leveraging the matching concept and considering each other. In addition, we also introduced a preference-based stable mechanism (PBSM) algorithm for resource allocation. In terms of the execution time for IoT services and the effectiveness of resource consolidation for edge nodes, the technique we use achieves better results compared with the two commonly used Min-Min and Max-Min scheduling algorithms.","2169-3536","","10.1109/ACCESS.2024.3350556","Princess Nourah bint Abdulrahman University Researchers(grant numbers:PNURSP2024R235); Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia; Deanship of Scientific Research at King Khalid University (KKU) for funding this research through the Research Group Program(grant numbers:R.G.P.2/572/44); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10381691","Edge computing;IoT;fog computing;resource allocation;game theory;matching algorithm;centralized matching;distributed matching","Internet of Things;Edge computing;Scheduling;Task analysis;Resource management;Cloud computing;Quality of service","","13","","76","CCBYNCND","5 Jan 2024","","","IEEE","IEEE Journals"
"ST-3DView: Multi-Scale Contrast-Enhanced 3D Point Cloud Reconstruction of Single-View Objects From Video Scene Transition","D. Chakraborty; W. Chiracharit; K. Chamnongthai","Department of Electronic and Telecommunication Engineering, King Mongkut’s University of Technology Thonburi, Bangkok, Thailand; Department of Electronic and Telecommunication Engineering, King Mongkut’s University of Technology Thonburi, Bangkok, Thailand; Department of Electronic and Telecommunication Engineering, King Mongkut’s University of Technology Thonburi, Bangkok, Thailand",IEEE Access,"25 Apr 2025","2025","13","","69596","69618","3D object tracking in monocular video relies on understanding the scene content to improve the continuity of the tracking signal. Reconstructing 3D shapes of single-view objects is essential for capturing object depth, orientation, and position within the scene. While existing deep learning-based methods excel in 3D reconstruction and tracking, they primarily focus on object feature semantics in normal frames, neglecting scene transition (ST) frames. This limitation leads to object information loss and discontinuity during tracking. This paper proposes a novel method for 3D reconstruction of single-view objects in monocular video scenes, focusing on fade scene transitions. First, large video datasets are pre-processed and segmented into sequences using cut transition detection via adaptive histogram equalization (AHE), and Euclidean distance estimation (EDE). Second, fade transition sequences are detected and classified into fade-in, fade-out, and mixed-fade scene transitions using pixel intensity-based adaptive threshold. Third, contrast enhancement is applied to fade transition frames using contrast-limited adaptive histogram equalization (CLAHE) to improve object feature extraction. Fourth, a modified DeepLabv3+ network is employed to generate multi-scale features for semantic foreground object and background segmentation. Finally, the segmented objects are processed through the proposed Point-wise multilayer perceptron (MLP) network, which reconstructs 3D object point clouds from segmented 2D single-view object pixels. Experimental evaluations on object categories “Chair,” “Car,” and “Airplane” from the benchmark TRECVID, Pix3D, ShapeNet, and Multimedia datasets achieved an accuracy improvement of 6.52% for fade transition detection and satisfactory results in 3D point cloud reconstruction.","2169-3536","","10.1109/ACCESS.2025.3561456","King Mongkut’s University of Technology Thonburi’s Postdoctoral Fellowship for the 2024 (2567) fiscal year under Integrated System for Research and Innovation Management (KIRIM)(grant numbers:27928,06/2567); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10966840","3D neural network;3D reconstruction;encoder-decoder architecture;object segmentation;point cloud;scene transition detection;shot boundary detection;video scene content understanding","Three-dimensional displays;Point cloud compression;Shape;Feature extraction;Image reconstruction;Semantics;Computer architecture;Object tracking;Histograms;Airplanes","","","","82","CCBY","16 Apr 2025","","","IEEE","IEEE Journals"
"Dynamic Spectrum Anti-Jamming for Low-Altitude Communication Networks: A Coalitional Game Learning Perspective","J. Du; Y. Xu; X. Wang; S. Liu; H. Wang; R. Chen; H. Han; Y. Xu","College of Communications Engineering, Army Engineering University of PLA, Nanjing, China; College of Communications Engineering, Army Engineering University of PLA, Nanjing, China; Information Support Force Engineering University, Wuhan, China; College of Communications Engineering, Army Engineering University of PLA, Nanjing, China; College of Communications Engineering, Army Engineering University of PLA, Nanjing, China; College of Communications Engineering, Army Engineering University of PLA, Nanjing, China; College of Communications Engineering, Army Engineering University of PLA, Nanjing, China; College of Communications Engineering, Army Engineering University of PLA, Nanjing, China",IEEE Wireless Communications,"","2025","PP","99","1","8","Low-altitude communication networks (LACNs), characterized by dynamic air-ground coordination in exposed electromagnetic spaces, are highly susceptible to malicious jamming. To address this issue, coalition-based networking has emerged as a flexible architecture, enabling heterogeneous air-ground agents to form collaborative groups for joint jamming avoidance and internal spectrum cooperation. However, the inherent mobility of low-altitude aerial nodes and the unpredictability of jamming environments pose critical challenges to low-altitude air-ground dynamic spectrum access, particularly in managing real-time interference relationships caused by aerial platform mobility. This paper proposes a coalition-based deep reinforcement learning framework that integrates coalition formation games (CFG) into multi-agent decision-making processes to resolve these challenges. First, we identify four critical issues in low-altitude aerial dynamic spectrum anti-jamming (DSAJ), which consist of dynamics, heterogeneity, limited resources, and malicious jamming threats. To address these challenges, we develop a hierarchical framework comprising three components: task-driven coalition formation, robust inter-coalition spectrum sharing, and distributed intra-coalition anti-jamming access for real-time interference coordination. Besides, a case study demonstrates how aerial and ground node coalitions collaboratively optimize spectrum utilization while countering jamming attacks. Finally, we discuss future research directions, including coalition robustness analysis, scalability in large-scale networks, and real-world deployment.","1558-0687","","10.1109/MWC.2025.3612872","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11222696","Dynamic spectrum anti-jamming;coalition formation game;multi-agent deep reinforcement learning;low-altitude communication networks","Jamming;Dynamic scheduling;Interference;Vehicle dynamics;Resource management;Topology;Network topology;Games;Collaboration;Real-time systems","","","","","CCBY","30 Oct 2025","","","IEEE","IEEE Early Access Articles"
"A Cloud-Based Architecture for the Internet of Spectrum Devices Over Future Wireless Networks","Q. Wu; G. Ding; Z. Du; Y. Sun; M. Jo; A. V. Vasilakos","College of Electronic and Information Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China; National Mobile Communications Research Laboratory, Southeast University, Nanjing, China; PLA Academy of National Defense Information, Wuhan, China; National Digital Switching System Engineering & Technological Research Center, Zhengzhou, China; Department of Computer and Information Science, Korea University, Sejong City, South Korea; Department of Computer Science, Electrical and Space Engineering, Luleå University of Technology, Luleå, Sweden",IEEE Access,"20 May 2017","2016","4","","2854","2862","The dramatic increase in data rates in wireless networks has caused radio spectrum usage to be an essential and critical issue. Spectrum sharing is widely recognized as an affordable, near-term method to address this issue. This paper first characterizes the new features of spectrum sharing in future wireless networks, including heterogeneity in sharing bands, diversity in sharing patterns, crowd intelligence in sharing devices, and hyperdensification in sharing networks. Then, to harness the benefits of these unique features and promote a vision of spectrum without bounds and networks without borders, this paper introduces a new concept of the Internet of spectrum devices (IoSDs) and develops a cloud-based architecture for IoSD over future wireless networks, with the prime aim of building a bridging network among various spectrum monitoring devices and massive spectrum utilization devices, and enabling a highly efficient spectrum sharing and management paradigm for future wireless networks. Furthermore, this paper presents a systematic tutorial on the key enabling techniques of the IoSD, including big spectrum data analytics, hierarchal spectrum resource optimization, and quality of experience-oriented spectrum service evaluation. In addition, the unresolved research issues are also presented.","2169-3536","","10.1109/ACCESS.2016.2576286","National Natural Science Foundation of China(grant numbers:61301160,61501510); Natural Science Foundation of Jiangsu Province(grant numbers:BK20150717); China Post-Doctoral Science Foundation Funded Project; Jiangsu Planned Projects for Post-Doctoral Research Funds; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7484255","Internet of spectrum devices (IoSD);cognitive radio;data analytics;resource optimization;quality of experience (QoE);Internet of spectrum devices (IoSD);cognitive radio;data analytics;resource optimization;quality of experience (QoE)","Internet of things;Spectrum management;Data analytics;Resource management;Quality of experience;Cognitive radio;Wireless networks;Cloud computing;Systematics","","39","","23","OAPA","2 Jun 2016","","","IEEE","IEEE Journals"
"A Review on Communication Aspects of Demand Response Management for Future 5G IoT- Based Smart Grids","S. Ahmadzadeh; G. Parr; W. Zhao","School of Computing Sciences, University of East Anglia, Norwich, U.K.; School of Computing Sciences, University of East Anglia, Norwich, U.K.; School of Computing Sciences, University of East Anglia, Norwich, U.K.",IEEE Access,"31 May 2021","2021","9","","77555","77571","In recent power grids, the need for having a two-way flow of information and electricity is crucial. This provides the opportunity for suppliers and customers to better communicate with each other by shifting traditional power grids to smart grids (SGs). In this paper, demand response management (DRM) is investigated as it plays an important role in SGs to prevent blackouts and provide economic and environmental benefits for both end-users and energy providers. In modern power grids, the development of communication networks has enhanced DRM programmes and made the grid smarter. In particular, with progresses in the 5G Internet of Things (IoT), the infrastructure for DRM programmes is improved with fast data transfer, higher reliability, increased security, lower power consumption, and a massive number of connections. Therefore, this paper provides a comprehensive review of potential applications of 5G IoT technologies as well as the computational and analytical algorithms applied for DRM programmes in SGs. The review holistically brings together sensing, communication, and computing (optimization, prediction), areas usually studied in a scattered way. A broad discussion on various DRM programmes in different layers of enhanced 5G IoT based SGs is given, paying particular attention to advances in machine learning (ML) and deep learning (DL) algorithms alongside challenges in security, reliability, and other factors that have a role in SGs’ performance.","2169-3536","","10.1109/ACCESS.2021.3082430","School of Computing Sciences, University of East Anglia; Innovate U.K(grant numbers:105843); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9437171","Smart grid;demand response management;5G;Internet of Things","5G mobile communication;Load management;Communications technology;Smart grids;Internet of Things;Security;Computer architecture","","73","","127","CCBY","20 May 2021","","","IEEE","IEEE Journals"
"Connected and Autonomous Vehicle Cohort Speed Control Optimization via Neuroevolution","F. Jacquelin; J. Bae; B. Chen; D. Robinette; P. Santhosh; J. Orlando; D. Knopp","Department of Mechanical Engineering-Engineering Mechanics, Michigan Technological University, Houghton, MI, USA; Department of Mechanical Engineering-Engineering Mechanics, Michigan Technological University, Houghton, MI, USA; Department of Mechanical Engineering-Engineering Mechanics, Michigan Technological University, Houghton, MI, USA; Department of Mechanical Engineering-Engineering Mechanics, Michigan Technological University, Houghton, MI, USA; Department of Mechanical Engineering-Engineering Mechanics, Michigan Technological University, Houghton, MI, USA; AVL, Plymouth, MI, USA; Department of Mechanical Engineering-Engineering Mechanics, Michigan Technological University, Houghton, MI, USA",IEEE Access,"21 Sep 2022","2022","10","","97794","97801","Predictive Energy Management (PrEM) research is at the forefront of modern transportation’s energy consumption reduction efforts. The development of PrEM optimization algorithms has been tailored to selfish vehicle operation and implemented in the form of vehicle dynamics and/or adaptive powertrain control functions. With the progress in vehicle automation, this paper focuses on extending PrEM into the realm of a System of Systems (SoS). The proposed approach uses the shared information among Connected and Automated Vehicles (CAV) and the infrastructure to synthesize a reduced energy speed trajectory at the cohort level within urban environments. Neuroevolution is employed to incorporate a generalized optimum controller, robust to the emergent behaviors typical of multi-agents SoS. The authors demonstrated the use of heuristics and systems engineering processes in abstracting and integrating the resulting neural network within the control architecture, which enables novel added-value features such as green wave pass/fail classification and e-Horizon velocity prediction. The resulting controller is faster than real-time and was validated with a multi-agent simulation environment and on a real-world closed-loop track at the American Center for Mobility (ACM). The GM Bolt and Volt CAV mixed cohort testing at ACM demonstrated energy reductions from 7% to 22% depending on scenarios.","2169-3536","","10.1109/ACCESS.2022.3206364","U.S. Department of Energy’s Office of Energy Efficiency and Renewable Energy (EERE) under the Vehicle Technologies Office (VTO)(grant numbers:DE-EE0009209); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9888127","Minimum energy control;optimal control;intelligent systems;artificial intelligence;mobile robots;systems engineering","Vehicle dynamics;Neural networks;Mechanical power transmission;Behavioral sciences;Optimization;Training data;Artificial intelligence;Mobile robots;Intelligent systems","","4","","19","CCBY","12 Sep 2022","","","IEEE","IEEE Journals"
"ViGAT: Bottom-Up Event Recognition and Explanation in Video Using Factorized Graph Attention Network","N. Gkalelis; D. Daskalakis; V. Mezaris","Centre for Research and Technology Hellas (CERTH), Information Technologies Institute, Thermi, Greece; Centre for Research and Technology Hellas (CERTH), Information Technologies Institute, Thermi, Greece; Centre for Research and Technology Hellas (CERTH), Information Technologies Institute, Thermi, Greece",IEEE Access,"18 Oct 2022","2022","10","","108797","108816","In this paper a pure-attention bottom-up approach, called ViGAT, that utilizes an object detector together with a Vision Transformer (ViT) backbone network to derive object and frame features, and a head network to process these features for the task of event recognition and explanation in video, is proposed. The ViGAT head consists of graph attention network (GAT) blocks factorized along the spatial and temporal dimensions in order to capture effectively both local and long-term dependencies between objects or frames. Moreover, using the weighted in-degrees (WiDs) derived from the adjacency matrices at the various GAT blocks, we show that the proposed architecture can identify the most salient objects and frames that explain the decision of the network. A comprehensive evaluation study is performed, demonstrating that the proposed approach provides state-of-the-art results on three large, publicly available video datasets (FCVID, MiniKinetics, ActivityNet). Source code is made publicly available at: https://github.com/bmezaris/ViGAT","2169-3536","","10.1109/ACCESS.2022.3213652","European Union’s Horizon 2020 Programme(grant numbers:832921,101021866); QuaLiSID—Quality of Life Support System for People with Intellectual Disability Project; European Union and Greek National Funds through the Operational Program Competitiveness, Entrepreneurship and Innovation, under the Call RESEARCH-CREATE-INNOVATE(grant numbers:T2EDK-00306); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9915576","Video event recognition;eXplainable AI (XAI);graph attention network;factorized attention;bottom-up","Feature extraction;Spatiotemporal phenomena;Transformers;Event recognition;Proposals;Detectors;Data mining;Video recording;Object recognition","","14","","111","CCBY","10 Oct 2022","","","IEEE","IEEE Journals"
"Energy Management in Smart Buildings and Homes: Current Approaches, a Hypothetical Solution, and Open Issues and Challenges","U. Mir; U. Abbasi; T. Mir; S. Kanwal; S. Alamri","College of Computing and Informatics, Saudi Electronic University, Dammam, Saudi Arabia; Department of Sciences, Grande Prairie Regional College (GPRC), Grande Prairie, Canada; Department of Electronic Engineering, Balochistan University of Information Technology, Engineering and Management Sciences, Quetta, Pakistan; College of Computing and Informatics, Saudi Electronic University, Dammam, Saudi Arabia; College of Computing and Informatics, Saudi Electronic University, Dammam, Saudi Arabia",IEEE Access,"7 Jul 2021","2021","9","","94132","94148","Energy plays a pivotal role for economic development of a country. A reliable energy source is needed to improve the living standards of people. To achieve such a goal, governments and industries are trying to install a new energy infrastructure called the “Smart Grid”. This helps to manage the electricity generation and distribution in an efficient manner. Buildings and other structures are the biggest consumers of electricity. There is a need to reduce the energy consumption so that the resources can be utilized efficiently. Therefore, in this paper, we give a comprehensive state-of-the-art on various recent techniques and solutions which provide energy savings in smart homes and buildings. This includes statistical models, cloud computing based solutions, fog computing and smart metering based architectures, and several other IoT (internet of things) inspired solutions. We also present a hypothetical model that treats energy supply and usage in buildings as a self-managing energy system (SES). This paper is concluded by highlighting several open issues and challenges related to energy management in buildings.","2169-3536","","10.1109/ACCESS.2021.3092304","Saudi Electronic University (SEU)(grant numbers:7677-CAI-2019-3-1-A); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9465101","Energy management;smart buildings and homes","Buildings;Energy management;Smart buildings;Internet of Things;Edge computing;Computational modeling;Cloud computing","","43","","98","CCBY","25 Jun 2021","","","IEEE","IEEE Journals"
"Multi-Unmanned Aerial Vehicles Cooperative Tactics: A Survey","A. Freitas; C. A. Rabbath; C. Williams; N. Lechevin; S. Givigi","Department of Electrical Engineering, Queen’s University, Kingston, ON, Canada; School of Computing, Queen’s University, Kingston, ON, Canada; Department of Physics, Royal Military College of Canada, Kingston, ON, Canada; Defence Research and Development Canada, Valcartier, QC, Canada; Department of Electrical Engineering, Queen’s University, Kingston, ON, Canada",IEEE Access,"16 Jul 2025","2025","13","","119897","119921","With recent advances in unmanned aerial vehicles (UAVs), there is a growing need for cooperation among multiple vehicles. One approach to enable cooperation is through tactics. However, there is a lack of consensus on how these tactics should be defined or applied to cooperative UAV systems. Moreover, the existing literature does not clearly identify the main challenges inherent in cooperative tactics. We survey recent contributions across both military and civilian domains to consolidate how the term cooperative tactics is employed. We propose a framework that clarifies the core components of multi-UAV cooperation and identifies the main research blocks addressed in the existing work.","2169-3536","","10.1109/ACCESS.2025.3583981","Natural Sciences and Engineering Council of Canada through the Discovery Grant Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11059364","Autonomous aerial vehicles;control systems;cooperative systems;decision making;game theory;military systems;multi-agent systems;swarm intelligence","Autonomous aerial vehicles;Planning;Vehicle dynamics;Surveys;Real-time systems;Employment;Resource management;Formation control;Art;Synchronization","","1","","156","CCBYNCND","30 Jun 2025","","","IEEE","IEEE Journals"
"A Blockchain-Oriented Task Scheduling and Allocation System for ROS Enabled Mobile Robots","M. O. Şen; F. Okumuş; A. Fatıh Kocamaz","Department of Computer Engineering, İnönü University, Malatya, Türkiye; Department of Software Engineering, İnönü University, Malatya, Türkiye; Department of Computer Engineering, İnönü University, Malatya, Türkiye",IEEE Access,"16 Jul 2025","2025","13","","119842","119862","In multi-mobile robot applications, the operational processes such as the management of robots, task assignment, monitoring of assigned tasks, communication and coordination between robots, and data storage are executed through a centralized server system. Therefore, most critical decisions are made on this centralized server rather than by the robots themselves. However, working in a centralized system has numerous disadvantages such as the obligation to maintain a server, routing all communication through a central unit, susceptibility to connectivity issues that render the system inoperable, and increased bandwidth requirements as the number of robots increases. Moreover, any communication issues between the server computers and any of the robots in centralized systems affect the entire system’s operation. To address these limitations, a blockchain-powered distributed communication system for inter-robot communication has been developed in this study. A task allocation application between robots has been implemented on this developed distributed communication system. In the application, Hyperledger Fabric (HLF) has been utilized as the blockchain platform due to its advantages. Each robot is a peer in the blockchain network in the proposed system. A cost function which is computed in all robots has been introduced to reduce the communication load in the blockchain network during task distribution and to enable optimal task allocation among robots. With the proposed system, robots compute and choose the most suitable tasks using the cost function, hence transactions on the blockchain network are kept at optimal level. After reaching consensus of peers on task allocations via HLF, task data are transmitted to robots by Robot Operating System (ROS) integration. With the proposed system, a dynamic and distributed architecture has been introduced and implemented where mobile robots can communicate with each other over a blockchain network without the need for a centralized server. In experimental studies conducted on real robots, the proposed system demonstrated optimal task allocation across multiple phases, effectively adapting to various task requirements in different scenarios. For instance, in one scenario, the system effectively allocated a total of 9 tasks, distributed across two phases: 3 tasks in the first phase and 6 tasks in the second phase. This study presents an innovative contribution to the literature on communication of robots and task allocation. Also, this study has a high potential to be adapted to industrial applications including robotic instruments.","2169-3536","","10.1109/ACCESS.2025.3585860","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11068982","Blockchain;Hyperledger Fabric;mobile robots;Robot Operating System (ROS);smart contracts","Robots;Blockchains;Robot kinematics;Mobile robots;Robot sensing systems;Peer-to-peer computing;Servers;Resource management;Service robots;Distributed ledger","","1","","42","CCBY","3 Jul 2025","","","IEEE","IEEE Journals"
"Ten Years of Asset Administration Shell: Developments, Research Opportunities, and Adoption Challenges","L. Sakurada; F. de la Prieta; P. Leitao","Research Centre in Digitalization and Intelligent Robotics (CeDRI), Laboratório Associado para a Sustentabilidade e Tecnologia em Regiões de Montanha (SusTEC), Instituto Politécnico de Bragança, Bragança, Portugal; BISITE Digital Innovation Hub, University of Salamanca, Edificio Multiusos I+D+i, Salamanca, Spain; Research Centre in Digitalization and Intelligent Robotics (CeDRI), Laboratório Associado para a Sustentabilidade e Tecnologia em Regiões de Montanha (SusTEC), Instituto Politécnico de Bragança, Bragança, Portugal",IEEE Access,"25 Jul 2025","2025","13","","127721","127741","Over the past decade, the Asset Administration Shell (AAS) has emerged as a cornerstone of digital transformation in Industry 4.0 (I4.0), providing a standardized approach to managing digital representations of industrial assets. With 2025 marking approximately ten years since its introduction, this article aims to provide a comprehensive analysis and discussion of AAS development over the past decade, potential research opportunities, and the challenges associated with its adoption. To this end, the study combines a literature survey with an examination of specifications from key organizations, such as the Plattform Industrie 4.0 and the Industrial Digital Twin Association (IDTA), which play a central role in the AAS standardization and development. A key insight from this survey is that AAS is progressing toward becoming a game-changer in realizing I4.0. Unlike a decade ago, AAS has now reached a level of maturity that enables its increasing adoption, supported by specifications and standards, dedicated development platforms for its implementation, and several examples in the literature showing a wide range of applications. Additionally, research opportunities for AAS align with emerging industrial trends and contribute to addressing them. However, several challenges must still be addressed to facilitate the widespread adoption of the AAS.","2169-3536","","10.1109/ACCESS.2025.3586716","UID/05757-Research Centre in Digitalization and Intelligent Robotics (CeDRI); and SusTEC, LA/P/0007/2020 (DOI: 10.54499/LA/P/0007/2020); Foundation for Science and Technology (FCT) for the Ph.D(grant numbers:2020.09234.BD (DOI: 10.54499/2020.09234.BD)); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11072423","Asset administration shells;cyber-physical systems;industry 4.0;reference architecture model industrie 4.0","Reviews;Interoperability;Industries;Collaboration;Digital representation;Stakeholders;Market research;Fourth Industrial Revolution;Surveys;Solid modeling","","1","","168","CCBY","7 Jul 2025","","","IEEE","IEEE Journals"
"Intelligent Resource Management for eMBB and URLLC in 5G and Beyond Wireless Networks","R. M. Sohaib; O. Onireti; Y. Sambo; R. Swash; S. Ansari; M. A. Imran","James Watt School of Engineering, University of Glasgow, Glasgow, U.K; James Watt School of Engineering, University of Glasgow, Glasgow, U.K; James Watt School of Engineering, University of Glasgow, Glasgow, U.K; Aidrivers Ltd., London, U.K; James Watt School of Engineering, University of Glasgow, Glasgow, U.K; James Watt School of Engineering, University of Glasgow, Glasgow, U.K",IEEE Access,"4 Jul 2023","2023","11","","65205","65221","In the era of 5G and beyond wireless networks, the simultaneous support of enhanced Mobile Broadband (eMBB) and Ultra-Reliable Low Latency Communications (URLLC) poses significant challenges in managing radio resources efficiently. By leveraging the puncturing technique, we propose an intelligent resource management framework for meeting the strict latency and reliability requirement of URLLC services and the high data rate for eMBB services. In particular, a semi-supervised learning and deep reinforcement learning (DRL) based architecture is proposed to manage the resources intelligently. We decompose the optimization problem into two subproblems: 1) resource block allocation (RBA) strategy for eMBB slice, and 2) URLLC scheduling. Through extensive simulations and performance evaluations, we demonstrate the effectiveness of the proposed technique in optimizing resource utilization, minimizing latency for URLLC users, and maximizing the throughput for eMBB services. Simulation findings demonstrate that the proposed methodology can ensure the URLLC reliability requirements while maintaining higher average sum rate for eMBB and higher convergence rate. The proposed framework paves the way for the efficient coexistence of diverse services, enabling wireless network operators to optimize resource allocation, improve user experience, and meet the specific requirements of eMBB and URLLC applications.","2169-3536","","10.1109/ACCESS.2023.3288698","Engineering and Physical Sciences Research Council (EPSRC) U.K.-India Future Networks Initiative(grant numbers:ref-EP/W016524/1); University of East Anglia in U.K.; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10159393","5G;DNN;DRL;RAN slicing;eMBB;URLLC","Ultra reliable low latency communication;Resource management;Reliability;Wireless networks;Optimization;Job shop scheduling;Symbols","","26","","50","CCBY","22 Jun 2023","","","IEEE","IEEE Journals"
"Research on Detection Optimization of the 3.0 Base Version of the Metering Automation System Based on Reinforcement Learning Algorithm","L. Zeng; G. Lin; J. Yang; G. Chen; S. Li; G. Liu; J. Bi","CSG Digital Power Grid Group Company Ltd., Guangzhou, Guangdong, China; CSG Digital Power Grid Group Company Ltd., Guangzhou, Guangdong, China; CSG Digital Power Grid Group Company Ltd., Guangzhou, Guangdong, China; CSG Digital Power Grid Group Company Ltd., Guangzhou, Guangdong, China; CSG Digital Power Grid Group Company Ltd., Guangzhou, Guangdong, China; CSG Digital Power Grid Group Company Ltd., Guangzhou, Guangdong, China; Yantai Dongfang Wisdom Electric Company Ltd., Yantai, Shandong, China",IEEE Access,"9 Sep 2025","2025","13","","155697","155713","In response to the problems of low detection efficiency and insufficient strategy optimization ability of the current base version detection tools in dynamic and complex scenarios, this paper proposes a detection optimization framework based on deep reinforcement learning. Firstly, by constructing a dual-mode dynamic testing model that integrates local detection and online detection, the base version quality assessment process is formalized as a Markov decision process, where the state space covers key indicators such as functional integrity, interface consistency, and storage throughput (refer to the GB/T 25000 standard). Secondly, an intelligent agent based on the Deep Q-Network (DQN) is designed to achieve adaptive optimization of detection dimension selection, feature index priority scheduling, and test case generation. A multi-objective hybrid reward mechanism (R =0.6 defect discovery rate +0.3 throughput gain - 0.1* time cost) is innovatively introduced to balance detection quality and resource consumption in dynamic interaction. Experiments show that this method improves detection efficiency by 37.2% compared to traditional schemes, with a feature index coverage rate of 98.5%, and its robustness in multi-unit detection scenarios is verified in third-party testing. The developed microservice architecture detection tool integrates a reinforcement learning decision interface, supporting real-time visualization of detection progress and automatic generation of electronic reports. This research provides an innovative solution for the full life cycle quality control of smart grid base versions.","2169-3536","","10.1109/ACCESS.2025.3606062","Science and Technology Project of China Southern Power Grid Company Ltd(grant numbers:210000KC24060046); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11151291","Measurement automation system;reinforcement learning;base version;quality inspection;feature engineering","Optimization;Testing;Throughput;Real-time systems;Power system dynamics;Resource management;Quality assessment;Heuristic algorithms;Feature extraction;Adaptation models","","","","23","CCBY","4 Sep 2025","","","IEEE","IEEE Journals"
"Intent-Based Infrastructure and Service Orchestration Using Agentic-AI","D. Brodimas; A. Birbas; D. Kapolos; S. Denazis","Department of Electrical and Computer Engineering, University of Patras, Patras, Greece; Department of Electrical and Computer Engineering, University of Patras, Patras, Greece; Department of Electrical and Computer Engineering, University of Patras, Patras, Greece; Department of Electrical and Computer Engineering, University of Patras, Patras, Greece",IEEE Open Journal of the Communications Society,"11 Sep 2025","2025","6","","7150","7168","This paper introduces a novel framework that integrates agentic Artificial Intelligence (AI) with Intent-Based Networks (IBN) to enable autonomous management, configuration, and optimization of mobile network services and resources. Leveraging the advanced reasoning and natural language processing capabilities of an Large Language Model (LLM), the proposed architecture translates high-level user intents into precise network actions, facilitating user-friendly and scalable network orchestration. The framework employs a distributed multi-agent system, where specialized agents collaborate to decompose user intents, provide computational infrastructure, and deploy services using industry-standard Infrastructure-as-Code (IaC) tools. By supporting natural language interactions, the system reduces operational complexity and enhances accessibility for users with varying technical expertise. Experimental evaluations demonstrate significant improvements in task completion rates, response accuracy, and operational efficiency compared to traditional manual methods, particularly for complex network management tasks. In essence, this work creates an intelligent network orchestration framework that adapts to user needs by automatically configuring network and computing resources while operating with minimal human intervention.","2644-125X","","10.1109/OJCOMS.2025.3600706","University Research Council, Aga Khan University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11131150","Agentic artificial intelligence;intent based networks;infrastructure as code;model context protocol","Artificial intelligence;Cognition;Translation;Industries;5G mobile communication;Planning;Oral communication;Context modeling;Computer architecture;Complexity theory","","1","","68","CCBY","20 Aug 2025","","","IEEE","IEEE Journals"
"Neighbor Cell List Optimization in Handover Management Using Cascading Bandits Algorithm","C. Wang; J. Yang; H. He; R. Zhou; S. Chen; X. Jiang","Department of Automation, University of Science and Technology of China, Hefei, China; Department of Automation, University of Science and Technology of China, Hefei, China; Department of Automation, University of Science and Technology of China, Hefei, China; Department of Electrical and Computer Engineering, Texas A&M University, College Station, USA; Department of Automation, University of Science and Technology of China, Hefei, China; Department of Automation, University of Science and Technology of China, Hefei, China",IEEE Access,"28 Jul 2020","2020","8","","134137","134150","Frequent handover is a key challenge in 5G Ultra-Dense Networks (UDN). In this paper, we show the significance of configuring Neighbor Cell List (NCL) in handover procedure. To cope with the high dynamic of UDN, we propose an online-learning method, namely the Cost-aware Cascading Bandits NCL configuration (CCB-NCL) algorithm, which applies the cascading model and Multi-Armed Bandits (MAB) theory to configure the efficient Neighbor Cell List (eNCL) and improves the handover performance by assisting the User Equipment (UE) to choose the optimal target Base Station (BS). We provide rigorous proof of regret bound to show the asymptotic convergence of the proposed CCB-NCL algorithm. The robustness and efficiency of the proposed algorithm are both demonstrated in different network scenarios, where varies BS densities, BS dynamic and network heterogeneity are considered respectively. In the simulation work, we reproduce two existing methods of configuring NCL in handover management, named dynamic threshold based solution and received signal strength based solution. In comparison with the existing solutions, the proposed algorithm can reduce the overlarge signaling cost and unnecessary delay in the preparation phase of handover procedure by significantly shortening the length of NCLs and reducing the number of scanned BSs. Extensive simulations are conducted in different scenarios to validate the robustness of the proposed algorithm and the results show that the proposed CCB-NCL algorithm is a superior approach to efficient handover management.","2169-3536","","10.1109/ACCESS.2020.3011015","Strategic Priority Research Program of the Chinese Academy of Sciences(grant numbers:ZDRW-KT-2016-02); Youth Innovation Promotion Association of the Chinese Academy of Sciences(grant numbers:CX2100107001); Anhui Provincial Natural Science Foundation(grant numbers:1908085QF266); China Electronics Technology Group Corporation (CETC) Joint Advanced Research Foundation(grant numbers:6141B08080101); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9145486","Cascading bandits;handover management;NCL configuration;user association;ultra-dense networks","Handover;Heuristic algorithms;5G mobile communication;Optimization;Wireless networks;Computer architecture","","11","","30","CCBY","21 Jul 2020","","","IEEE","IEEE Journals"
"Q-Learning Based Cognitive Domain Ontology Representation and Solving on Low Power Computing Platforms","N. Rahman; T. Atahary; C. Yakopcic; T. M. Taha; S. Douglass","Department of Electrical and Computer Engineering (ECE), University of Dayton, Dayton, OH, USA; Department of Electrical and Computer Engineering (ECE), University of Dayton, Dayton, OH, USA; Department of Electrical and Computer Engineering (ECE), University of Dayton, Dayton, OH, USA; Department of Electrical and Computer Engineering (ECE), University of Dayton, Dayton, OH, USA; Air Force Research Laboratory, Wright Patterson AFB, Dayton, OH, USA",IEEE Access,"3 Jan 2024","2024","12","","131","147","Cognitive agents make systems autonomous through the process of decision automation by mining an existing knowledge repository at run time. These processes can often be highly compute intensive, and would thus run slowly on the low-power computing platforms typically seen in autonomous systems. This paper examines how knowledge be represented in a Q-table and proposes a novel fast algorithm to mine that knowledge based on constraints. We evaluate this approach for the knowledge mining process of a specific agent: Cognitively Enhanced Complex Event Processing (CECEP). Within CECEP, knowledge is represented using Cognitive Domain Ontologies (CDO), and is mined using situational inputs and constraints. This is a novel approach to store information and is able to accommodate CDOs with millions of solutions. To show that the approach can run on low power hardware in real-time, this algorithm was executed on two low-power minicomputing platforms - Intel’s NUC and Asus’s Tinker Board. At present, no other optimized CDO solvers can generate solutions on these platforms. The algorithm generated the same amount of solutions as a GPU-enabled optimized path-based forward checking CDO solver, while consuming around 7.7 and 5.15 times less energy (Joules) on the NUC and Tinker Board respectively.","2169-3536","","10.1109/ACCESS.2023.3346908","Air Force Research Laboratory (AFRL)(grant numbers:AFRL-2021-4287); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10373852","Knowledge mining;cognitive agents;autonomous decision making","Color;Q-learning;II-VI semiconductor materials;Cadmium compounds;Real-time systems;Ontologies;Decision making;Autonomous systems;Ontologies","","","","37","CCBYNCND","25 Dec 2023","","","IEEE","IEEE Journals"
"Trusted UAV Network Coverage Using Blockchain, Machine Learning, and Auction Mechanisms","A. S. Khan; G. Chen; Y. Rahulamathavan; G. Zheng; B. Assadhan; S. Lambotharan","School of Computing, Electronics and Mathematics, Coventry University, Coventry, U.K.; School of Engineering, University of Leicester, Leicester, U.K.; Institute for Digital Technologies, Loughborough University London, London, U.K.; Wolfson School of Mechanical, Electrical and Manufacturing Engineering, Loughborough University, Loughborough, U.K.; Electrical Engineering Department, King Saud University, Riyadh, Saudi Arabia; Wolfson School of Mechanical, Electrical and Manufacturing Engineering, Loughborough University, Loughborough, U.K.",IEEE Access,"2 Jul 2020","2020","8","","118219","118234","The UAV is emerging as one of the greatest technology developments for rapid network coverage provisioning at affordable cost. The aim of this paper is to outsource network coverage of a specific area according to a desired quality of service requirement and to enable various entities in the network to have intelligence to make autonomous decisions using blockchain and auction mechanisms. In this regard, by considering a multiple-UAV network where each UAV is associated to its own controlling operator, this paper addresses two major challenges: the selection of the UAV for the desired quality of network coverage and the development of a distributed and autonomous real-time monitoring framework for the enforcement of service level agreement (SLA). For a suitable UAV selection, we employ a reputation-based auction mechanism to model the interaction between the business agent who is interested in outsourcing the network coverage and the UAV operators serving in closeby areas. In addition, theoretical analysis is performed to show that the proposed auction mechanism attains a dominant strategy equilibrium. For the SLA enforcement and trust model, we propose a permissioned blockchain architecture considering Support Vector Machine (SVM) for real-time autonomous and distributed monitoring of UAV service. In particular, smart contract features of the blockchain are invoked for enforcing the SLA terms of payment and penalty, and for quantifying the UAV service reputation. Simulation results confirm the accuracy of theoretical analysis and efficacy of the proposed model.","2169-3536","","10.1109/ACCESS.2020.3003894","Engineering and Physical Sciences Research Council(grant numbers:EP/R006385/1,EP/N007840/1,EP/R006377/1); Leverhulme Trust(grant numbers:RPG-2017-129); U.K.–India Education Research Initiative (UKIERI)(grant numbers:UGC-UKIERI-2016-17-019); International Scientific Partnership Program (ISPP) with King Saud University(grant numbers:ISPP 134); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121974","Blockchain;auction;support vector machine;service level agreement;unmanned aerial vehicles;ergodic capacity","Blockchain;Unmanned aerial vehicles;Quality of service;Monitoring;Machine learning","","33","","71","CCBY","22 Jun 2020","","","IEEE","IEEE Journals"
"DeepKneeExplainer: Explainable Knee Osteoarthritis Diagnosis From Radiographs and Magnetic Resonance Imaging","M. R. Karim; J. Jiao; T. Döhmen; M. Cochez; O. Beyan; D. Rebholz-Schuhmann; S. Decker","Fraunhofer Institute for Applied Information Technology (FIT), Sankt Augustin, Germany; Fraunhofer Institute for Systems and Innovation Research ISI, Karlsruhe, Germany; Fraunhofer Institute for Applied Information Technology (FIT), Sankt Augustin, Germany; Department of Computer Science, Faculty of Sciences, Vrije Universiteit Amsterdam, Amsterdam, The Netherlands; Fraunhofer Institute for Applied Information Technology (FIT), Sankt Augustin, Germany; ZB MED—Information Centre for Life Sciences, Cologne, Germany; Fraunhofer Institute for Applied Information Technology (FIT), Sankt Augustin, Germany",IEEE Access,"15 Mar 2021","2021","9","","39757","39780","Osteoarthritis (OA) is a degenerative joint disease, which significantly affects middle-aged and elderly people. Although primarily identified via hyaline cartilage change based on medical images, technical bottlenecks like noise, artifacts, and modality impose an enormous challenge on high-precision, objective, and efficient early quantification of OA. Owing to recent advancements, approaches based on neural networks (DNNs) have shown outstanding success in this application domain. However, due to nested non-linear and complex structures, DNNs are mostly opaque and perceived as black-box methods, which raises numerous legal and ethical concerns. Moreover, these approaches do not have the ability to provide the reasoning behind diagnosis decisions in the way humans would do, which poses an additional risk in the clinical setting. In this paper, we propose a novel explainable method for knee OA diagnosis based on radiographs and magnetic resonance imaging (MRI), which we called DeepKneeExplainer. First, we comprehensively preprocess MRIs and radiographs through the deep-stacked transformation technique against possible noises and artifacts that could contain unseen images for domain generalization. Then, we extract the region of interests (ROIs) by employing U-Net architecture with ResNet backbone. To classify the cohorts, we train DenseNet and VGG architectures on the extracted ROIs. Finally, we highlight class-discriminating regions using gradient-guided class activation maps (Grad-CAM++) and layer-wise relevance propagation (LRP), followed by providing human-interpretable explanations of the predictions. Comprehensive experiments based on the multicenter osteoarthritis study (MOST) cohorts, our approach yields up to 91% classification accuracy, outperforming comparable state-of-the-art approaches. We hope that our results will encourage medical researchers and developers to adopt explainable methods and DNN-based analytic pipelines towards an increasing acceptance and adoption of AI-assisted applications in the clinical practice for improved knee OA diagnoses.","2169-3536","","10.1109/ACCESS.2021.3062493","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9363889","Knee osteoarthritis;biomedical imaging;deep neural networks;neural ensemble;explainability;Grad-CAM++;layer-wise relevance propagation","Magnetic resonance imaging;Feature extraction;Diagnostic radiography;Osteoarthritis;Bones;Biomedical imaging;Knee","","42","","93","CCBYNCND","26 Feb 2021","","","IEEE","IEEE Journals"
"Trustworthiness Modeling and Analysis of Cyber-physical Manufacturing Systems","Z. Yu; L. Zhou; Z. Ma; M. A. El-Meligy","School of Information and Navigation, Air Force Engineering University, Xi’an, China; Xi’an Institute of Applied Optics, Xi’an, China; School of Information and Navigation, Air Force Engineering University, Xi’an, China; Advanced Manufacturing Institute, King Saud University, Riyadh, Saudi Arabia",IEEE Access,"21 Dec 2017","2017","5","","26076","26085","Cyber-physical manufacturing systems (CPMSs) are a new paradigm of manufacturing systems that integrate cyber systems and physical systems to aid smart manufacturing. CPMSs can improve the system's flexibility and productivity and adapt to new market demands. However, CPMSs are susceptible to cyber-attacks, which can modify manufacturing intents to produce parts incorrectly and cause hazards to equipment, employees, and consumers. Therefore, the trustworthiness of CPMSs is critical to the entire systems. In order to describe and analyze the trustworthiness of CPMSs, generalized stochastic Petri nets are adopted to model CPMSs and the trustworthiness is measured from three metrics, i.e., the reliability, availability and security. To study the trustworthiness evolution of CPMSs, a malicious software spreading dynamics model is presented, and its dynamic behaviors are analyzed. Finally, the CPMS trustworthiness evolution model is constructed depending on the proposed dynamics model. The simulation results demonstrate that the proposed approach is effective to model and analyze the CPMS trustworthiness.","2169-3536","","10.1109/ACCESS.2017.2777438","National Natural Science Foundation of China(grant numbers:61202128,71571190); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8119805","Cyber-attack;cyber-physical systems;generalized stochastic Petri net;manufacturing systems;trustworthiness","Manufacturing systems;Analytical models;Computational modeling;Object oriented modeling;Cyber-physical systems;Industries","","31","","57","OAPA","24 Nov 2017","","","IEEE","IEEE Journals"
"A Novel Attention-Guided Enhanced U-Net With Hybrid Edge-Preserving Structural Loss for Low-Dose CT Image Denoising","M. Zubair; H. Md Rais; T. Alazemi","Institute of Emerging Digital Technologies (EDiT), Center For Cyber Physical Systems (C2PS), Universiti Teknologi PETRONAS, Seri Iskandar, Malaysia; Institute of Emerging Digital Technologies (EDiT), Center For Cyber Physical Systems (C2PS), Universiti Teknologi PETRONAS, Seri Iskandar, Malaysia; Department of Electronic Electrical Engineering, Brunel University London, Uxbridge, U.K.",IEEE Access,"14 Jan 2025","2025","13","","6909","6923","Computed Tomography (CT) scan, pivotal for medical diagnostics, involves exposure to electromagnetic radiation, potentially elevating the risk of leukemia and cancer. Low-dose CT (LDCT) imaging has emerged to mitigate these risks, extensively reducing radiation exposure by up to 86%. However, it significantly reduces the quality of LDCT images and introduces noise and artifacts, degrading the diagnostic accuracy of the Computer Aided Diagnostic (CAD) system. This study presents a novel U-Net architecture, featuring several key enhancements. The model integrates residual blocks to improve feature representation and employs a custom hybrid loss function that combines structural loss with gradient regularization using the Euclidean norm, promoting superior CT image quality retention. Additionally, incorporating Attention Gates in the up-sampling layers of a proposed model optimizes the extraction of critical features, ensuring more precise denoising of CT images. The proposed model undergoes iterative training, using a custom loss function to refine its parameters and improve CT image denoising progressively. Its performance is rigorously evaluated both qualitatively and quantitatively on the ‘2016 Low-dose CT AAPM Grand Challenge dataset’. The results, assessed through the metrics Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index Measure (SSIM), and Root Mean Square Error (RMSE), demonstrated promising improvements compared to state-of-the-art techniques. The model effectively reduces noise while preserving critical fine details, establishing itself as a highly efficient solution for LDCT image denoising.","2169-3536","","10.1109/ACCESS.2025.3526619","Institute of Emerging Digital Technologies (EDiT) & Center For Cyber Physical Systems (C2PS), Universiti Teknologi PETRONAS, Seri Iskandar, Malaysia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10829953","Attention gate;deep learning;image enhancement;LDCT image denoising;residual blocks","Computed tomography;Noise;Noise reduction;Image denoising;Computational modeling;Generative adversarial networks;Solid modeling;Image quality;Feature extraction;Accuracy","","10","","54","CCBY","7 Jan 2025","","","IEEE","IEEE Journals"
"Why Asset Administration Shells: A Survey on Uses and Challenges","A. Alexopoulos; G. Kalogeras; K. Koutras; A. Kalogeras","Athena Research Center, Industrial Systems Institute, Athens, Greece; Athena Research Center, Industrial Systems Institute, Athens, Greece; Athena Research Center, Industrial Systems Institute, Athens, Greece; Athena Research Center, Industrial Systems Institute, Athens, Greece",IEEE Access,"23 Jul 2025","2025","13","","126582","126609","In the cadre of the Industry 4.0 initiative, and its proposed RAMI 4.0 reference architecture, the Asset Administration Shell (AAS) is gaining traction in the industrial sector, ushering production practices to new precedents and enabling the incorporation of the latest digital technologies. However, the task of instigating the new era of industry is not without difficulties. The current work performs a systematic literature review of AAS by thoroughly reviewing 86 recently published journal articles. The aim is to put in scope current use cases of the AAS, categorise them and, thus, paint a comprehensive picture of AAS usage, by synthesizing all recent journal literature. The second part of the work focuses on highlighting current challenges that appear at the intersection of AAS with necessities of the industrial sector, as well as with the AAS’s integration with novel concepts and technologies.","2169-3536","","10.1109/ACCESS.2025.3589931","framework of the National Recovery and Resilience Plan Greece 2.0; European Union–NextGenerationEU(grant numbers:TAEDR-0535864); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11082140","Asset administration shell;interoperability;Industry 4.0;RAMI 4.0;standardization;flexible manufacturing;challenges","Manufacturing;Systematic literature review;Industries;Maintenance;Interoperability;Fourth Industrial Revolution;Internet of Things;Solid modeling;Europe;Databases","","","","137","CCBY","16 Jul 2025","","","IEEE","IEEE Journals"
"Loose Coupling: An Invisible Thread in the History of Technology","A. Mämmelä; J. Riekki; M. Kiviranta","VTT Technical Research Centre of Finland Ltd., Oulu, Finland; Center for Ubiquitous Computing, University of Oulu, Oulu, Finland; VTT Technical Research Centre of Finland Ltd., Oulu, Finland",IEEE Access,"21 Jun 2023","2023","11","","59456","59482","We present an interdisciplinary survey of the history of loosely coupled systems. We apply the presented concepts in communication networks and suggest hybrid self-organizing networks (SONs) as a universal model for future networks. Self-organizing networks can fulfill the tight requirements of future networks but are challenging to use due to their complexity and immaturity. Moreover, the lack of an externally defined goal and centralized control has resulted in many distributed self-organizing systems failing. This is because the nonlinear relationships between the system parts result in emergence, i.e., we cannot predict the behavior of the whole from the behavior of the parts. Furthermore, a set of local optima does not produce a global optimum. Hybrid SONs tackle these challenges with loose or weak coupling of interacting agents that combine centralized control for global optimization with distributed control for local optimization. In the loose centralized control of almost autonomous agents, decisions are made mostly locally with small delays. This architecture has beneficial properties such as stability, obtained by decoupling the feedback loops: vertically with time-scale separation and horizontally with interference avoidance. Applications of loose coupling include modular electronics and computer design, structured software design, and service-oriented architectures, especially for microservices. Cross-layer design for network optimization is a new reason to use loose coupling in networks to improve stability. We also summarize some recent trends and present a roadmap to the future. We expect that loose coupling will be widely used in self-organizing networks of future wireless systems.","2169-3536","","10.1109/ACCESS.2023.3284685","Dynamic coverage Extension and Distributed Intelligence for human Centric applications with assured security, privacy and trust: from 5G to 6G (DEDICAT 6G) Project through the European Union (EU) Horizon 2020 Research and Innovation Program(grant numbers:101016499); Academy of Finland 6G Flagship(grant numbers:318927); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10147219","Feedback;information and communication technologies (ICT);loosely coupled systems;multi-agent systems;network layer;self-organizing networks","Couplings;Feedback loop;Communication networks;Information and communication technology;Self-organizing networks;Optimization","","11","","241","CCBY","9 Jun 2023","","","IEEE","IEEE Journals"
"Generation of Critical Information and Sharing Mechanism for Multi-Robot Mission Success","D. Jo; Y. Kwon","Department of Industrial Engineering, Ajou University, Suwon, Republic of Korea; Department of Industrial Engineering, Ajou University, Suwon, Republic of Korea",IEEE Access,"26 Aug 2025","2025","13","","146855","146873","This paper shows a real-time information-sharing mechanism and custom task allocation strategy for cooperative multi-robot systems operating in uncertain and dynamic environments. The proposed method is based on a decentralized, asynchronous architecture utilizing the Quality of Service (QoS) features of the Robot Operating System 2 (ROS2) framework and Data Distribution Service (DDS) middleware. To validate its practical applicability, extensive simulation experiments and real-world robot tests were conducted using mobile robot platforms under varying network conditions. Key performance metrics including message delay, reaction time, packet loss, and mission success rate were evaluated across multi-QoS configurations. Results show that Reliable and Transient Local settings provide the most consistent performance, ensuring stable obstacle information transmission and robust map updates even in environments with significant communication constraints. Additionally, comparisons between simulation and physical experiments reveal the impact of system-level variables such as synchronization error, network behavior, and sensor noise. The findings confirm the robustness and adaptability of the proposed approach and demonstrate its potential to serve as a scalable framework for future heterogeneous multi-robot deployments.","2169-3536","","10.1109/ACCESS.2025.3600319","Pebble-i Company(grant numbers:S-2023-G0001-00363); Ajou Universary(grant numbers:S-2023-C2394-00001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11130179","MRS;QoS;DDS;ROS2;autonomous robots;multi-robot cooperation;real-time communication;map sharing;information sharing mechanism;task allocation;distributed algorithms;mobile robot system;swarm robotics;AI-enabled multi-robot systems;AI-based robotics","Robots;Robot kinematics;Real-time systems;Resource management;Information sharing;Quality of service;Scalability;Robustness;Reliability;Simultaneous localization and mapping","","","","54","CCBY","19 Aug 2025","","","IEEE","IEEE Journals"
"See clearly on rainy days: Hybrid multiscale loss guided multi-feature fusion network for single image rain removal","H. Fu; Y. Zhang; H. Ma","Beijing Key Laboratory of Intelligent Telecommunications Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing 100876, China; Beijing Key Laboratory of Intelligent Telecommunications Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing 100876, China; Beijing Key Laboratory of Intelligent Telecommunications Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing 100876, China",Computational Visual Media,"20 Feb 2025","2021","7","4","467","482","The quality of photos is highly susceptible to severe weather such as heavy rain; it can also degrade the performance of various visual tasks like object detection. Rain removal is a challenging problem because rain streaks have different appearances even in one image. Regions where rain accumulates appear foggy or misty, while rain streaks can be clearly seen in areas where rain is less heavy. We propose removing various rain effects in pictures using a hybrid multiscale loss guided multiple feature fusion de-raining network (MSGMFFNet). Specially, to deal with rain streaks, our method generates a rain streak attention map, while preprocessing uses gamma correction and contrast enhancement to enhanced images to address the problem of rain accumulation. Using these tools, the model can restore a result with abundant details. Furthermore, a hybrid multiscale loss combining L1 loss and edge loss is used to guide the training process to pay attention to edge and content information. Comprehensive experiments conducted on both synthetic and real-world datasets demonstrate the effectiveness of our method.","2096-0662","","10.1007/s41095-021-0210-3","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10897523","single image rain removal;multiple feature fusion;deep learning;hybrid multiscale loss","Rain;Feature extraction;Image restoration;Image edge detection;Data mining;Image reconstruction;Computer architecture;Deep learning;Visualization;Training","","","","","","20 Feb 2025","","","TUP","TUP Journals"
"Hybrid Decision Making via Deep Learning for Integrated Visual Object Detection, Pose Estimation and Energy Control in IoT Connected Multi-Robot Systems using 5G Network","M. Dwedar; A. Jesser","Intelligent Cyber Physical Institution, Heilbronn University of Applied Science, Germany; Intelligent Cyber Physical Institution, Heilbronn University of Applied Science, Germany",IEEE Access,"","2025","PP","99","1","1","In dynamic, real-world environments, effective decision-making in Multi-Robot Systems (MRS) requires both robust perception and scalable inter-agent coordination. This work presents a unified perception and control framework that leverages a Faster Region-Based Convolutional Neural Network (Faster-RCNN) integrated with a Perspective-n-Point (PnP) optimization layer collectively referred to as the Faster-RCNN-Pose pipeline to enable accurate, low latency object detection and 6-DoF pose estimation across heterogeneous robotic agents. Unlike traditional decoupled pipelines, our end-to-end architecture performs simultaneous inference of object class, bounding box, and spatial orientation, thereby improving system level responsiveness and decision fidelity. By embedding this pipeline within an MQTT-based 5G communication infrastructure, robots can rapidly share spatial awareness, allocate tasks, and coordinate actions in real time. The proposed framework supports energy-aware navigation, multi-agent collaboration, and dynamic task reallocation, even as mission complexity and fleet size increase. Evaluations in open-environment deployments confirm that the system maintains high localization accuracy, low pose error, and consistent inter-agent coordination under motion, occlusion, and environmental variability. While communication latency remains a relevant constraint, especially in brokered architectures, the system includes latency compensation mechanisms and predictive control logic to preserve decision consistency. Overall, this work contributes a modular, scalable, and communication-resilient perception-to-decision pipeline for next-generation IoT-connected MRS, advancing the frontier of distributed collaborative robotics in unstructured, high-variability environments.","2169-3536","","10.1109/ACCESS.2025.3630823","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11235941","Deep Learning;M2M;Robotics;Autonomous Systems;Hybrid Decision-Making;IoT;Embedded AI;Computer Vision","Robots;Robot kinematics;Pose estimation;Decision making;Real-time systems;Pipelines;Delays;5G mobile communication;Robot sensing systems;Resource management","","","","","CCBY","10 Nov 2025","","","IEEE","IEEE Early Access Articles"
"Traffic Management of Multi-AGV Systems by Improved Dynamic Resource Reservation","P. Verma; J. M. Olm; R. Suarez","Tavil Ind, S.A.U., Sant Jaume de Llierca, Spain; Department of Mathematics, Universitat Politècnica de Catalunya, Barcelona, Spain; Institute of Industrial and Control Engineering, Universitat Politècnica de Catalunya, Barcelona, Spain",IEEE Access,"12 Feb 2024","2024","12","","19790","19805","Automated guided vehicles (AGVs) are widely used for material handling in warehouses and automated production lines due to their high efficiency and low failure rate with respect to human operated load carriers. However, AGVs usually interact with each other because of the restricted capacity of the layout, and conflicts arise. Although many traffic scheduling algorithms have been proposed to address the AGV fleet control problem, most of them are inefficient for collision and deadlock avoidance in dynamic environments. This paper proposes an improved dynamic resource reservation (IDRR) based method which renders time-efficient task completion and deadlock-free movements of multiple AGVs in a manufacturing system. Unlike traditional approaches, most of which adopt a dynamic single agent reservation of the shared resource points and/or force path deviations, IDRR exploits dynamic multiple reservations of shared resource points. This is combined with a conflict detection and resolution method that accommodates the AGV motions when they meet at a resource point. Extensive, realistic simulation results demonstrate the feasibility and efficiency of the proposed collision and deadlock prevention method in productivity, travelled distance, and time completion of the assigned tasks. The proposal can be implemented on both central and local controllers.","2169-3536","","10.1109/ACCESS.2024.3362293","Generalitat de Catalunya through the Industrial Doctorate Project(grant numbers:2021 DI 16); Government of Spain through the Agencia Estatal de Investigación Project(grant numbers:PID2021-122821NB-I00); Generalitat de Catalunya through the AGAUR Project(grant numbers:2021 SGR 00376); Industrial Doctorate Project(grant numbers:2021 DI 16); Spanish Government(grant numbers:PID2020-114819GB-I00); Generalitat de Catalunya through the Industrial Doctorate Project(grant numbers:2021 DI 16); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10419190","Multi-AGV systems;collision and deadlock avoidance;dynamic resource reservation;traffic control","Layout;System recovery;Task analysis;Dynamic scheduling;Heuristic algorithms;Vehicle dynamics;Routing;Traffic control;Remotely guided vehicles","","8","","36","CCBYNCND","5 Feb 2024","","","IEEE","IEEE Journals"
"Methodology for Distributed Optimization of Flexible Energy Resources Through Semi-Automated Model Transformation and Deployment","V. Henkel; L. P. Wagner; M. Kilthau; F. Gehlhoff; A. Fay","Institute of Automation Technology, Helmut Schmidt Universitat, Hamburg, Germany; Institute of Automation Technology, Helmut Schmidt Universitat, Hamburg, Germany; Institute of Automation Technology, Helmut Schmidt Universitat, Hamburg, Germany; Institute of Automation Technology, Helmut Schmidt Universitat, Hamburg, Germany; Chair of Automation, Ruhr University, Bochum, Germany",IEEE Open Journal of the Industrial Electronics Society,"4 Nov 2025","2025","6","","1682","1703","Effectively utilizing flexible energy resources requires optimizing their operation over time to balance dynamic demand and fluctuating supply from volatile renewable sources. Traditionally, this has been achieved through centralized optimization models, which suffer from scalability limitations, single points of failure, and limited flexibility when applied to decentralized and dynamically changing environments. Distributed models offer a promising alternative, providing enhanced flexibility, robustness, and computational efficiency by enabling parallel processing and reducing coordination delays. Thus, this work presents a methodology for the semi-automated transformation of centralized optimization models into distributed architectures, leveraging containerized multiagent systems to achieve scalable and efficient optimization across multiple computing units. A case study involving 120 electrolyzers distributed across up to five optimization agents, including both homogeneous and heterogeneous configurations, demonstrates that the distributed approach accelerates computation time by a factor up to 27.42 compared to a centralized model while accepting a solution quality deviation of only 2.2%. The optimization integrates site-wide and real-time optimization, ensuring adaptability to fluctuating renewable energy availability and improving system resilience. This combination enables long-term strategic planning while allowing real-time adjustments to maximize renewable energy utilization. The findings highlight the benefits of distributed optimization in modular energy systems and confirm that containerized multiagent architectures enhance scalability and computational efficiency, making the approach well-suited for real-world applications in decentralized and modular energy networks.","2644-1284","","10.1109/OJIES.2025.3623250","German Federal Ministry of Education and Research and the Projektträger Jülich GmbH, based on a resolution of the German Bundestag; dtec.bw – Digitalization and Technology Research Center of the Bundeswehr; European Union—NextGenerationEU; OptiFlex (dtec.bw)(grant numbers:03HY116); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11207504","Alternating direction method of multipliers;distributed optimization;multiagent system;scalability","Optimization;Energy resources;Optimization models;Convex functions;Scalability;Computational modeling;Industrial electronics;Computational efficiency;Data models;Computer architecture","","","","55","CCBYNCND","20 Oct 2025","","","IEEE","IEEE Journals"
"Dual Modality Reverse Reranking (DM-RR) Based Image Retrieval Framework","I. Ahmed; N. Iltaf; R. Latif; N. S. M. Jamail; Z. Khan","Department of Computer Software Engineering, National University of Sciences and Technology Islamabad, Rawalpindi, Pakistan; Department of Computer Software Engineering, National University of Sciences and Technology Islamabad, Rawalpindi, Pakistan; College of Computer and Information Sciences (CCIS), Prince Sultan University, Riyadh, Saudi Arabia; College of Computer and Information Sciences (CCIS), Prince Sultan University, Riyadh, Saudi Arabia; School of Electrical Engineering and Computer Science, Gwangju Institute of Science and Technology (GIST), Gwangju, South Korea",IEEE Open Journal of the Industrial Electronics Society,"2 Sep 2024","2024","5","","886","897","Retrieval of a product with desired modifications from a vast inventory of online industrial platforms is frequently encountered in our daily life. This study presents a specialized framework to retrieve user's queried product with its desired changes incorporated. To facilitate interaction between the end-user and agent in such scenarios, a multimodal content-based image retrieval system is essential. The system extracts textual and visual attributes, combining them through inductive learning to a unified representation. It is based on an in-depth understanding of visual characteristics that are modified by textual semantics. Lastly, a novel reverse reranking (RR) algorithm arranges the joint representation of dual modality queries and their corresponding target images for efficient retrieval. The proposed framework is novel compared to earlier methodologies. First, it achieves successful fusion of two different modalities. Second, it introduces a RR algorithm in the inference stage for efficient retrieval. The proposed framework's enhanced performance has been assessed using the Fashion-200 K and MIT-States real-world benchmark datasets. The proposed system can be used in real-world applications subject to its practical implications, such as generalization to diverse domains, availability of domain specific data, nature of the data and queries, and availability of computational resources.","2644-1284","","10.1109/OJIES.2024.3435956","Prince Sultan University for paying the Article Processing Charges; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10614798","Textual and visual embedding generations;bidirectional encoder representation from transformer (BERT);residual neural network-50 (RESNET-50);collaborative embeddings composition;inference-based learning;reverse reranking (RR)","Feature extraction;Visualization;Image retrieval;Semantics;Computer architecture;Transformers;Text analysis;Bidirectional control;Encoding;Residual neural networks;Neural networks","","1","","40","CCBYNCND","30 Jul 2024","","","IEEE","IEEE Journals"
"Mathematical Programming Through the Lens of LLMs: Systematic Evidence and Empirical Gaps","M. J. Abdel-Rahman; Y. Alslman; D. Refai; A. Saleh; M. A. A. Loha; M. Y. Hamed","Data Science Department, Princess Sumaya University for Technology, Amman, Jordan; Computer Science Department, Princess Sumaya University for Technology, Amman, Jordan; Information and Computer Science Department, King Fahd University of Petroleum and Minerals, Dhahran, Saudi Arabia; Computer Science Department, Princess Sumaya University for Technology, Amman, Jordan; Data Science Department, Princess Sumaya University for Technology, Amman, Jordan; Data Science Department, Princess Sumaya University for Technology, Amman, Jordan",IEEE Access,"28 Oct 2025","2025","13","","180953","180991","This paper investigates the capabilities of large language models (LLMs) in formulating and solving decision-making problems using mathematical programming. We first conduct a systematic review and meta-analysis of recent literature to assess how well LLMs understand, structure, and solve optimization problems across domains. The analysis is guided by critical review questions focusing on learning approaches, dataset designs, evaluation metrics, and prompting strategies. Our systematic evidence is complemented by targeted experiments designed to evaluate the performance of state-of-the-art LLMs in automatically generating optimization models for problems in computer networks. Using a newly constructed dataset, we apply three prompting strategies: Act-as-expert, chain-of-thought, and self-consistency, and evaluate the obtained outputs based on optimality gap, token-level F1 score, and compilation accuracy. Results show promising progress in LLMs’ ability to parse natural language and represent symbolic formulations, but also reveal key limitations in accuracy, scalability, and interpretability. These empirical gaps motivate several future research directions, including structured datasets, domain-specific fine-tuning, hybrid neuro-symbolic approaches, modular multi-agent architectures, and dynamic retrieval via chain-of-RAGs. This paper contributes a structured roadmap for advancing LLM capabilities in mathematical programming.","2169-3536","","10.1109/ACCESS.2025.3618987","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11195073","Linear programming;combinatorial optimization;large language models;fine-tuning;in-context learning;retrieval-augmented generation","Reviews;Mathematical models;Optimization;Mathematical programming;Natural language processing;Operations research;Linear programming;Protocols;Lenses;Generative Pre-trained transformer","","","","85","CCBY","7 Oct 2025","","","IEEE","IEEE Journals"
"New Approach for Conversational Agent Definition by Non-Programmers: A Visual Domain-Specific Language","L. Rodríguez-Gil; J. García-Zubia; P. Orduña; A. Villar-Martinez; D. López-De-Ipiña","LabsLand-C. Gordóniz, Bilbao, Spain; Faculty of Engineering, University of Deusto, Bilbao, Spain; LabsLand-C. Gordóniz, Bilbao, Spain; DeustoTech-Deusto Foundation, Bilbao, Spain; DeustoTech-Deusto Foundation, Bilbao, Spain",IEEE Access,"16 Jan 2019","2019","7","","5262","5276","Intelligent tutors and conversational agents (CAs) have proven to be useful learning tools. They have potential not only as stand-alone devices but also as integrable components to enrich and complement other educational resources. For this, new authoring approaches and platforms are required. They should be accessible to non-programmers (such as most teachers) and they should be integrable into current web-based educational platforms. This paper proposes a new approach to define such agents through a visual domain-specific language based on Google Blockly (a scratch-like language). It also develops a web-based integrable authoring platform to serve as a prototype, describing the requirements and architecture. To evaluate whether this novel approach is effective, a multi-stage experiment was conducted. First, participants learned to use the prototype authoring platform through an interactive tutorial. Second, they created a CA with a specific domain model. Times and performance were measured. Finally, they answered a standardized usability questionnaire (UMUX) and a purpose-specific survey. Results show that participants were able to learn to use the domain-specific language in a short time. Moreover, the purpose-specific survey indicates that their perception of the approach (and its potential) is positive. The standardized questionnaire indicates that even in its prototype stage, its usability is satisfactory.","2169-3536","","10.1109/ACCESS.2018.2883500","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8601197","Visual programming languages;customizable systems;conversational agents;intelligent tutoring systems;online learning;online labs","Visualization;Google;Computer languages;Authoring systems;Tools;DSL;Prototypes","","15","","65","OAPA","4 Jan 2019","","","IEEE","IEEE Journals"
"Spatially-Distributed Missions With Heterogeneous Multi-Robot Teams","E. Feo-Flushing; L. M. Gambardella; G. A. D. Caro","Department of Computer Science, Carnegie Mellon University Qatar, Doha, Qatar; Dalle Molle Institute for Artificial Intelligence (IDSIA USI-SUPSI), Lugano, Switzerland; Department of Computer Science, Carnegie Mellon University Qatar, Doha, Qatar",IEEE Access,"11 May 2021","2021","9","","67327","67348","This work is about mission planning in teams of mobile autonomous agents. We consider tasks that are spatially distributed, non-atomic, and provide an utility for integral and also partial task completion. Agents are heterogeneous, therefore showing different efficiency when dealing with the tasks. The goal is to define a system-level plan that assigns tasks to agents to maximize mission performance. We define the mission planning problem through a model including multiple sub-problems that are addressed jointly: task selection and allocation, task scheduling, task routing, control of agent proximity over time. The problem is proven to be NP-hard and is formalized as a mixed integer linear program (MILP). Two solution approaches are proposed: one heuristic and one exact method. Both combine a generic MILP solver and a genetic algorithm, resulting in efficient anytime algorithms. To support performance scalability and to allow the effective use of the model when online continual replanning is required, a decentralized and fully distributed architecture is defined top-down from the MILP model. Decentralization drastically reduces computational requirements and shows good scalability at the expenses of only moderate losses in performance. Lastly, we illustrate the application of the mission planning framework in two demonstrators. These implementations show how the framework can be successfully integrated with different platforms, including mobile robots (ground and aerial), wearable computers, and smart-phone devices.","2169-3536","","10.1109/ACCESS.2021.3076919","Sinergia grant(grant numbers:CRSI22_133059 (project SWARMIX)); Swiss National Science Foundation (SNSF); National Priorities Research Program (NPRP) grant(grant numbers:10-0213-170458); Qatar National Research Fund (a member of Qatar Foundation); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9420064","Multi-robot systems;mobile robots;cooperative systems;planning;decision support systems;optimization methods;genetic algorithms;mathematical programming","Task analysis;Resource management;Routing;Scalability;Computational modeling;Optimization;Vehicle routing","","6","","53","CCBY","30 Apr 2021","","","IEEE","IEEE Journals"
"A Digital Twin-Empowered Framework for Interactive Consumers in Manufacturing Using Wearable Device","T. Phuong Nguyen; H. Nguyen; H. -L. Cao; T. T. Bui; H. Q. T. Ngo","HUTECH Institute of Engineering, HUTECH University, Ho Chi Minh City, Vietnam; HUTECH Institute of Engineering, HUTECH University, Ho Chi Minh City, Vietnam; Brubotics and Flanders Make, Vrije Universiteit Brussel, Brussel, Belgium; Faculty of Mechanical Engineering, Ho Chi Minh City University of Technology (HCMUT), Ho Chi Minh City, Vietnam; Faculty of Mechanical Engineering, Ho Chi Minh City University of Technology (HCMUT), Ho Chi Minh City, Vietnam",IEEE Access,"26 Aug 2025","2025","13","","146557","146568","In the cyber-physical world, human-robot interaction (HRI) plays an increasingly important role in digital twin (DT)-enabled development, particularly in smart manufacturing. This investigation introduces a novel DT-based robotic framework for HRI (DTbRF-HRI), aiming to further productivity, automation, and safety. Our framework includes major elements such as real-time data communication, a common digital model, and a simulation environment for obstacle avoidance and autonomous manipulation. One contribution of our works is the application of an enhanced A-star algorithm for motion planning to support fast generation of paths and avoiding collisions. The data exchange between the physical and virtual agent is supported through system architecture and communication protocols, which meet with being very fast. The resulting framework is validated using numerical simulation and physical experiments in a common electronic consumer manufacturing scenario. Findings demonstrate the effectiveness, robustness, and practicability of DTbRF-HRI in improving intelligent robotic process in a cyber-physical system.","2169-3536","","10.1109/ACCESS.2025.3598864","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11124867","Digital twin;intelligent robot;cyber-physical system;human–robot interaction","Robots;Robot kinematics;Manufacturing;Human-robot interaction;Service robots;Real-time systems;Digital twins;Consumer electronics;Production;Internet of Things","","","","27","CCBY","14 Aug 2025","","","IEEE","IEEE Journals"
"Construction of Knowledge Graph for Enterprise Mergers and Acquisitions: Cross-Domain Value Mining Method of Large Language Model (LLM) and Graph Neural Network","L. Li","School of Economics and Management, Zhengzhou Electric Power Vocational and Technical College, Zhengzhou, China",IEEE Access,"16 Oct 2025","2025","13","","176622","176638","Enterprise mergers and acquisitions (M&A) involve complex, cross-domain decision-making processes that rely on both structured and unstructured data sources. Traditional knowledge graph construction techniques, often rule-based or reliant on shallow learning, struggle with scalability, adaptability, and semantic generalization in such dynamic environments. A new framework for cross-domain value mining is introduced, which integrates Large Language Models and Graph Neural Networks to enable enterprise M&A knowledge graph construction and inference. Central to our approach is the E-GraphNet (Enterprise Graph Network), a modular graph-based neural architecture that models enterprises as asynchronous, multi-agent decision systems. Each node in E-GraphNet represents an enterprise entity, while edges encode organizational dependencies and communication delays. E-GraphNet introduces edge-conditioned message passing and policy-execution signatures to enable dynamic alignment with strategic directives, ensuring real-time and scalable inference across distributed enterprise contexts. To further enhance adaptability under uncertainty and partial observability, we introduce Decision-Aware Perturbation Routing (DAPR). DAPR injects controlled perturbations into decision pathways, simulates distributed decision shifts, and optimizes routing through attention-guided correction mechanisms. This enables the system to remain robust in the face of delayed feedback and external perturbations, improving resilience in real-world M&A scenarios. Evaluation across various enterprise datasets indicates that the LLM-GNN framework delivers superior performance compared to existing baselines in tasks related to knowledge extraction and graph inference. The framework offers a scalable, interpretable, and efficient solution for modeling enterprise structures and forecasting M&A outcomes, advancing the field of intelligent enterprise analytics.","2169-3536","","10.1109/ACCESS.2025.3615942","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11184812","Enterprise mergers and acquisitions;knowledge graph construction;large language models;graph neural networks;decision-aware optimization","Knowledge graphs;Corporate acquisitions;Graph neural networks;Cognition;Semantics;Optimization;Data mining;Biological system modeling;Adaptation models;Soft sensors","","","","45","CCBY","30 Sep 2025","","","IEEE","IEEE Journals"
"Sample and Structure-Guided Network for Road Crack Detection","S. Wu; J. Fang; X. Zheng; X. Li","Key Laboratory of Spectral Imaging Technology CAS, Xi’an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi’an, China; School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China; Key Laboratory of Spectral Imaging Technology CAS, Xi’an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi’an, China; Key Laboratory of Spectral Imaging Technology CAS, Xi’an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi’an, China",IEEE Access,"20 Sep 2019","2019","7","","130032","130043","As an indispensable task for traffic management department, road maintenance has attracted much attention during the last decade due to the rapid development of traffic network. As is known, crack is the early form of many road damages, and repair it in time can significantly save the maintenance cost. In this case, how to detect crack regions quickly and accurately becomes a huge demand. Actually, many image processing technique based methods have been proposed for crack detection, but their performances can not meet our expectations. The reason is that, most of these methods use bottom features such as color and texture to detect the cracks, which are easily influenced by the varied conditions such as light and shadow. Inspired by the great successes of machine learning and artificial intelligence, this paper presents a sample and structure guided network for detecting road cracks. Specifically, the proposed network is based on U-Net architecture, which remains the details from input to output by using skip connection strategy. Then, because the scale of crack samples is much smaller than that of non-crack ones, directly using the conventional cross entropy loss can not optimize the network effectively. In this case, the Focal loss is utilized to address the model optimization problem. Additionally, we incorporate the self-attention strategy into the proposed network, which enhances its stability by encoding the 2-order information among different local regions into the final features. Finally, we test the proposed method on four datasets, three public ones with labels and a photographed one without labels, to validate its effectiveness. It is noteworthy that, for the photographed dataset, we design a series of image processing strategies such as contrast enhancement to improve the generalization capability of the proposed method.","2169-3536","","10.1109/ACCESS.2019.2940767","National Natural Science Foundation of China(grant numbers:61806193,61702498,61772510); Chinese Academy of Sciences(grant numbers:QYZDB-SSW-JSC015); State Key Laboratory of Transient Optics and Photonics; Chinese Academy of Sciences(grant numbers:SKLST2017010); CAS “Light of West China” Program(grant numbers:XAB2017B26,XAB2017B15); Xi’an Postdoctoral Innovation Base Scientific Research Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8835080","Road crack detection;neural network;representation capability;sample imbalance;structural information","Roads;Feature extraction;Task analysis;Maintenance engineering;Manuals;Machine learning","","46","","49","CCBY","12 Sep 2019","","","IEEE","IEEE Journals"
"PRIVOT: Privacy-Resilient Intelligent DAG Blockchain Architecture for IoT","F. Alanazi; M. Zareei; A. Rodríguez Arreola","Department of Electrical Engineering, College of Engineering, Prince Sattam bin Abdulaziz University, Al-Kharj, Saudi Arabia; Tecnologico de Monterrey, School of Engineering and Sciences, Monterrey, Mexico; Tecnologico de Monterrey, School of Engineering and Sciences, Monterrey, Mexico",IEEE Access,"11 Aug 2025","2025","13","","137592","137602","The rapid growth of the Internet of Things (IoT) demands solutions that can secure massive streams of sensitive data without sacrificing performance. Traditional blockchains struggle in IoT environments, facing significant challenges with transaction speed, scalability, and privacy. This paper introduces PRIVOT, a novel blockchain architecture that integrates a Directed Acyclic Graph (DAG) for high-throughput consensus with lightweight zero-knowledge proofs (ZKPs) for confidential transactions, rateless coded computation for private analytics, and an AI-driven manager that dynamically balances security and efficiency. Our simulations show that PRIVOT significantly outperforms traditional blockchain approaches, achieving high transaction throughput (up to 480 TPS on a 500-device network) with confirmation latencies under 2.1 seconds, even under heavy load. The framework provides robust privacy, limiting data leakage to less than 0.1% against significant node collusion, while keeping computational overhead low enough for resource-constrained IoT devices. By unifying these techniques, PRIVOT offers a scalable and resilient solution ideal for large-scale IoT deployments where both high performance and strong privacy are paramount.","2169-3536","","10.1109/ACCESS.2025.3593365","Prince Sattam bin Abdulaziz University(grant numbers:PSAU/2025/R/1447); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11098777","IoT security;blockchain;zero-knowledge proofs;coded computation;DAG-enabled consensus;AI-driven privacy","Internet of Things;Privacy;Blockchains;Artificial intelligence;Throughput;Scalability;Real-time systems;Cryptography;Codes;Data privacy","","","","38","CCBY","28 Jul 2025","","","IEEE","IEEE Journals"
"New Energy and CCUS Thermal Power Synergistic Peaking Cost Model and Apportionment Optimization Strategy","Y. Song; G. Wang; H. Li; Y. Sun; H. Jin; T. Su; X. Wu; Q. Zhang","Shenyang Institute of Engineering, Shenyang, China; Shenyang Institute of Engineering, Shenyang, China; Shenyang Institute of Engineering, Shenyang, China; Shenyang Institute of Engineering, Shenyang, China; Shenyang Institute of Engineering, Shenyang, China; Shenyang Institute of Engineering, Shenyang, China; Shenyang Institute of Engineering, Shenyang, China; 2Electric Power Research Institute, State Grid Liaoning Electric Power Company Ltd., Shenyang, China",IEEE Access,"31 Jul 2025","2025","13","","132501","132513","Driven by the global carbon neutral strategy, the large-scale application of Carbon Capture, Utilization and Storage (CCUS) technology has significantly weakened the peaking margin of thermal power units, and the traditional peaking cost allocation model fails to take into account the inequitable distribution of costs faced by the carbon capture power plants participating in peaking. This study proposes a peaking cost quantification method based on multidimensional characterization. In terms of temporal characteristics, the scenario substitution method is used to quantify the participation of different peaking entities in peaking; in terms of spatial characteristics, the initiative constraints of unit peaking are taken into account to ensure that each peaking entity actively participates in peaking and profits from it. Considering the impact of carbon capture power plants’ participation in peak shifting on carbon emission reduction and carbon cost, we constructed a dynamic peak shifting model for multiple subjects. We innovatively construct a two-layer architecture of “spatio-temporal two-dimensional quantization and dynamic game sharing”, and adopt the improved kernel method to establish a coalition reorganization trigger mechanism to solve the unfair sharing of peaking costs when carbon capture power plants participate in peaking. Taking the improved IEEE34 node as an example, the results show that the established cost calculation model can accurately calculate the peak shaving cost of each unit in different scenarios. The total cost of thermal power peak shaving using CCUS is 6.5% lower than that of conventional thermal power units, which significantly verifies the effectiveness of CCUS technology in reducing the economic burden of peak shaving. When the carbon price is 150-250 yuan/ton, the carbon emission is reduced by 40%-50%, which highlights the dual advantages of the model in deep emission reduction and carbon price co-optimization, and the cost increase is  $\le 5$ %, which proves the feasibility of achieving large-scale carbon emission reduction under the premise of strictly controlling the economic cost. On the basis of completing energy conservation and emission reduction, the peak regulation task is completed at the minimum cost, and the unity of economy and environmental protection is achieved. Compared with the Shapley value method, the correlation coefficient of the contribution of the kernel method is increased to 0.91, which indicates that the accuracy of the proposed method for the evaluation of multi-agent contribution is significantly improved, and the fairness of the peak-shifting cost-sharing model of the kernel method is significantly improved, which provides a reliable solution for solving the problem of cost allocation imbalance between traditional power supply and CCUS units.","2169-3536","","10.1109/ACCESS.2025.3585989","Liaoning Provincial Science and Technology Program Joint Fund (Natural Science Foundation-General Project)(grant numbers:2024-MSLH-327); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11071675","Bi-level game optimization;carbon capture optimization;CCUS-new energy synergy;nucleolus allocation;peaking cost dynamics","Costs;Regulation;Carbon dioxide;Carbon capture and storage;Resource management;Optimization;Kernel;Wind power generation;Energy storage;Power system dynamics","","1","","22","CCBY","4 Jul 2025","","","IEEE","IEEE Journals"
"Urban Traffic Routing Using Weighted Multi-Map Strategies","A. Paricio; M. A. Lopez-Carmona","Departamento de Automática, Universidad de Alcalá, Alcala de Henares, Spain; Departamento de Automática, Universidad de Alcalá, Alcala de Henares, Spain",IEEE Access,"28 Oct 2019","2019","7","","153086","153101","Urban traffic routing has to deal with individual mobility and collective wellness considering citizens, multi-modal transport, and fleet traffic with conflicting interests such as electric vehicles, local distribution, public transport, and private vehicles. Different interests, goals, and regulations, suggest the development of new multi-objective routing mechanisms which may improve traffic flow. In this work, Traffic Weighted Multi-Maps (TWM) is presented as a novel traffic routing mechanism based on the strategical generation and distribution of complementary cost maps for traffic fleets, oriented towards the application of differentiated traffic planning and control policies. TWM is built upon a centralized control architecture, where a Traffic Management Center generates and distributes customized cost maps of the road network. These maps are used individually to calculate routes. In this research, we present the TWM theoretical model and experimental results based on microscopic simulations over a real city traffic network under multiple scenarios, including traffic incidents management. Experimental evaluation takes into account driver's adherence to the system and considers a multi-objective analysis both for the global network parameters (congestion, travel time, and route length) and for the subjective driving experience. Experimental results deliver performance improvements from 20% to 50%. TWM is fully compatible with existing traffic routing systems and has promising future evolution applying new algorithms, policies and network profiles.","2169-3536","","10.1109/ACCESS.2019.2947699","Spanish Ministry of Economy, Industry, and Competitiveness(grant numbers:TIN2016-80622-P (AEI/FEDER, UE),TEC2013-45183-R (AEI/FEDER, UE)); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8871165","Dynamic traffic assignment;traffic control;traffic simulation;vehicle routing;traffic big data;decision making;multi-agent systems;multi-map routing;TWM","Routing;Planning;Microscopy;Urban areas;Proposals;Vehicle dynamics;Cost function","","17","","51","CCBY","16 Oct 2019","","","IEEE","IEEE Journals"
"Active Environmental Monitoring and Anomaly Search System for Space Habitat With Markov Decision Process and Active Sensing","Y. Guo; Z. Xu; J. H. Saleh","School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, USA",IEEE Access,"2 Apr 2021","2021","9","","49683","49696","For future crewed missions that could last years with limited ground support, the environmental control and life support system (ECLSS) will likely evolve to meet new, more stringent reliability and autonomy requirements. In this work, we focus on improving the performance of the environmental monitoring and anomaly detection systems using Markov decision process and active sensing. We exploit actively moving sensors to develop a novel sensing architecture and supporting analytics, termed Active environmental Monitoring and Anomaly Search System (AMASS). We design a Dynamic Value Iteration policy to solve the path planning problem for the moving sensors in a dynamic environment. To test and validate AMASS, we developed a series of computational experiments for fire search, and we assessed the performance against three metrics: (1) anomaly detection time lag, (2) source location uncertainty, and (3) state estimation error. The results demonstrate that: AMASS provides 10~15 times better performance than the traditional fixed sensor monitoring and detection strategy; ventilation in the monitored environment affects the performance by 6~40 times for any monitoring architecture with fixed or moving sensors; the monitoring performance cannot be fully reflected in a monolithic, single metric, but should include different metrics for the timeliness and spatial resolution of the detection function.","2169-3536","","10.1109/ACCESS.2021.3068950","Space Technology Research Institute through the National Aeronautics and Space Administration’s (NASA’s) Space Technology Research Grants Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9386106","Anomaly detection;environmental monitoring;Markov decision process;space habitat","Sensors;Robot sensing systems;Temperature sensors;Temperature measurement;Environmental monitoring;Markov processes;State estimation","","3","","44","CCBY","24 Mar 2021","","","IEEE","IEEE Journals"
"To Smart City: Public Safety Network Design for Emergency","S. Wan; J. Lu; P. Fan; K. B. Letaief","Tsinghua National Laboratory for Information Science and Technology, Tsinghua University, Beijing, China; Tsinghua National Laboratory for Information Science and Technology, Tsinghua University, Beijing, China; Tsinghua National Laboratory for Information Science and Technology, Tsinghua University, Beijing, China; Department of Electronic Engineering, Hong Kong University of Science and Technology, Hong Kong",IEEE Access,"14 Feb 2018","2018","6","","1451","1460","In smart cities, there are always unpredicted emergencies, which must be handled to maintain the regular order. Then a smart system is needed to detect threats and deal with them. In this paper, we propose a system structure composed of a central agent and three layers: unmanned aerial vehicle (UAV) layer, multirobot layer and sensor network layer. The UAVs act as moving sensors and conveyors in the air. They provide the overall rough monitoring data from the air and transport robots to the emergency occurring places. The robots on the ground are responsible for obtaining detailed monitoring data and dealing with the emergencies. The sensor networks keep monitoring the environment and assist robots and UAVs in the range to complete their tasks. The central agent can adjust the system according to the specific task requirements. We provide a general system design and review main required technologies, highlighting the challenges and some possible solutions. The future researching directions are presented to guide the system design.","2169-3536","","10.1109/ACCESS.2017.2779137","China Major State Basic Research Development Program (973 Program)(grant numbers:2012CB316100 (2)); National Natural Science Foundation of China(grant numbers:61771283); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8125683","UAV;multi-robot system;distributed sensors;smart city;emergency","Robot sensing systems;Unmanned aerial vehicles;Surveillance;Smart cities;Security","","35","","28","OAPA","4 Dec 2017","","","IEEE","IEEE Journals"
"Graph-Based Conditional Generative Adversarial Networks for Major Depressive Disorder Diagnosis With Synthetic Functional Brain Network Generation","J. -H. Oh; D. -J. Lee; C. -H. Ji; D. -H. Shin; J. -W. Han; Y. -H. Son; T. -E. Kam","Department of Artificial Intelligence, Korea University, Seoul, Republic of Korea; Department of Artificial Intelligence, Korea University, Seoul, Republic of Korea; Department of Artificial Intelligence, Korea University, Seoul, Republic of Korea; Department of Artificial Intelligence, Korea University, Seoul, Republic of Korea; Department of Artificial Intelligence, Korea University, Seoul, Republic of Korea; Department of Artificial Intelligence, Korea University, Seoul, Republic of Korea; Department of Artificial Intelligence, Korea University, Seoul, Republic of Korea",IEEE Journal of Biomedical and Health Informatics,"6 Mar 2024","2024","28","3","1504","1515","Major Depressive Disorder (MDD) is a pervasive disorder affecting millions of individuals, presenting a significant global health concern. Functional connectivity (FC) derived from resting-state functional Magnetic Resonance Imaging (rs-fMRI) serves as a crucial tool in revealing functional connectivity patterns associated with MDD, playing an essential role in precise diagnosis. However, the limited data availability of FC poses challenges for robust MDD diagnosis. To tackle this, some studies have employed Deep Neural Networks (DNN) architectures to construct Generative Adversarial Networks (GAN) for synthetic FC generation, but this tends to overlook the inherent topology characteristics of FC. To overcome this challenge, we propose a novel Graph Convolutional Networks (GCN)-based Conditional GAN with Class-Aware Discriminator (GC-GAN). GC-GAN utilizes GCN in both the generator and discriminator to capture intricate FC patterns among brain regions, and the class-aware discriminator ensures the diversity and quality of the generated synthetic FC. Additionally, we introduce a topology refinement technique to enhance MDD diagnosis performance by optimizing the topology using the augmented FC dataset. Our framework was evaluated on publicly available rs-fMRI datasets, and the results demonstrate that GC-GAN outperforms existing methods. This indicates the superior potential of GCN in capturing intricate topology characteristics and generating high-fidelity synthetic FC, thus contributing to a more robust MDD diagnosis.","2168-2208","","10.1109/JBHI.2023.3340325","Institute of Information & communications Technology Planning & Evaluation; Korea government(grant numbers:2019-0-00079); Artificial Intelligence Graduate School Program(grant numbers:2022-0-00871); Development of AI Autonomy and Knowledge Enhancement for AI Agent Collaboration; National Research Foundation of Korea(grant numbers:RS202300212498); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10349934","Conditional generative adversarial networks;graph convolutional networks;major depressive disorder;resting-state functional Magnetic Resonance Imaging (rs-fMRI);synthetic functional connectivity","Topology;Generative adversarial networks;Network topology;Feature extraction;Bioinformatics;Laplace equations;Convolutional neural networks","Humans;Depressive Disorder, Major;Magnetic Resonance Imaging;Brain;Brain Mapping","14","","66","CCBYNCND","8 Dec 2023","","","IEEE","IEEE Journals"
"A Hybrid Meta-Heuristic Feature Selection Method for Identification of Indian Spoken Languages From Audio Signals","A. Das; S. Guha; P. K. Singh; A. Ahmadian; N. Senu; R. Sarkar","Institute of Radio Physics and Electronics, University of Calcutta, Kolkata, India; Institute of Radio Physics and Electronics, University of Calcutta, Kolkata, India; Department of Information Technology, Jadavpur University, Kolkata, India; Institute of IR 4.0, The National University of Malaysia (UKM), Bangi, Malaysia; Institute for Mathematical Research, Universiti Putra Malaysia, Serdang, Malaysia; Department of Computer Science and Engineering, Jadavpur University, Kolkata, India",IEEE Access,"12 Oct 2020","2020","8","","181432","181449","With the recent advancements in the fields of machine learning and artificial intelligence, spoken language identification-based applications have been increasing in terms of the impact they have on the day-to-day lives of common people. Western countries have been enjoying the privilege of spoken language recognition-based applications for a while now, however, they have not gained much popularity in multi-lingual countries like India owing to various complexities. In this paper, we have addressed this issue by attempting to identify different Indian languages based on various well-known features like Mel-Frequency Cepstral Coefficient (MFCC), Linear Prediction Coefficient (LPC), Discrete Wavelet Transform (DWT), Gammatone Frequency Cepstral Coefficient (GFCC) as well as a few deep learning architecture based features like i-vector and x-vector extracted from the audio signals. After comparing the initial results, it is observed that the combination of MFCC and LPC produces the best results. Then we have developed a new nature-inspired feature selection (FS) algorithm by hybridizing Binary Bat Algorithm (BBA) with Late Acceptance Hill-Climbing (LAHC) to select the optimal subset from the said feature vectors in order to reduce the model complexity and help it train faster. Using Random Forest (RF) classifier, we have achieved an accuracy of 92.35% on Indic TTS database developed by IIT-Madras, and an accuracy of 100% on the Indic Speech database developed by the Speech and Vision Laboratory (SVL) IIIT-Hyderabad. The proposed algorithm is also found to outperform many standard meta-heuristic FS algorithms. The source code of this work is available at: https://github.com/CodeChef97dotcom/Feature-Selection.","2169-3536","","10.1109/ACCESS.2020.3028241","Fundamental Research Grant Scheme (FRGS) provided by the Ministry of Education, Malaysia(grant numbers:FRGS/1/2018/STG06/UPM/02/2); Universiti Putra Malaysia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9210572","Spoken language identification;feature selection;binary Bat algorithm;late acceptance hill climbing algorithm;MFCC and LPC features","Feature extraction;Mel frequency cepstral coefficient;Machine learning;Classification algorithms;Databases;Complexity theory;Discrete wavelet transforms","","41","","62","CCBY","1 Oct 2020","","","IEEE","IEEE Journals"
"Methodological Approach for Developing Reconfigurable Automation Systems","I. Sarachaga; A. Burgos; M. L. Alvarez; N. Iriondo; M. Marcos","Department of Automatic Control and Systems Engineering, Escuela de Ingeniería de Bilbao, University of the Basque Country, Bilbao, Spain; Department of Automatic Control and Systems Engineering, Escuela de Ingeniería de Bilbao, University of the Basque Country, Bilbao, Spain; Department of Automatic Control and Systems Engineering, Escuela de Ingeniería de Bilbao, University of the Basque Country, Bilbao, Spain; Department of Automatic Control and Systems Engineering, Escuela de Ingeniería de Bilbao, University of the Basque Country, Bilbao, Spain; Department of Automatic Control and Systems Engineering, Escuela de Ingeniería de Bilbao, University of the Basque Country, Bilbao, Spain",IEEE Transactions on Industrial Informatics,"22 Jan 2020","2020","16","3","1460","1469","One challenge for the designers of the current industrial control systems consists of assuring the system reconfiguration at runtime, envisaged at system design time. This article focuses specifically on the fault tolerance to controller failures (as it is the most complex challenge) aiming at redistributing the responsibilities at runtime in order to finish the current production plan. Its applicability is illustrated by means of a case study that consists of a reconfigurable control application based on the IEC 61131-3 for a flexible assembly cell. A prototype software tool guides the developer during the development process. This approach contributes to develop more flexible control systems because they can react in case of a controller failure, to increase the system availability during its operation and to reduce the production downtimes to perform the maintenance tasks.","1941-0050","","10.1109/TII.2019.2925837","Euskal Herriko Unibertsitatea(grant numbers:GIU18/162); Ministerio de Ciencia, Innovación y Universidades(grant numbers:RTI2018-096116-B-I00); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8765797","Industrial automation;IEC 61131-3;methodology for industrial automation systems (MeiA ${}_{\scriptsize\bullet}$ );reconfigurable control applications","Control systems;Automation;Production;IEC Standards;Runtime;Software;Process control","","4","","27","CCBY","18 Jul 2019","","","IEEE","IEEE Journals"
"A Compact Circularly Polarized MIMO Dielectric Resonator Antenna Over Electromagnetic Band-Gap Surface for 5G Applications","H. N. Chen; J. -M. Song; J. -D. Park","Division of Electronics and Electrical Engineering, Dongguk University, Seoul, South Korea; Division of Electronics and Electrical Engineering, Dongguk University, Seoul, South Korea; Division of Electronics and Electrical Engineering, Dongguk University, Seoul, South Korea",IEEE Access,"8 Oct 2019","2019","7","","140889","140898","We present a wideband circularly polarized (CP) multiple-input multiple-output (MIMO) dielectric resonator antenna (DRA) with enhanced diversity. In the DRA element, two diagonal edges of the DR were truncated at 45° to obtain a wider axial ratio larger than 0.65 GHz. The DRA element was excited by a cross-ring slot with specific slot-arm ratio through microstrip-line (MSTL) implemented at the backside of the FR4 substrate to generate CP fields. Small triangular stands at the edge of the DR were employed to hold it in place to avoid any degradation from the uncontrollable bonding agent used for attaching DR onto the FR4 substrate. The DRA achieved an impedance bandwidth better than 0.8 GHz with an antenna gain of 4.83 dBi. Using the DRA with the MSTL feed, two-element CP-DRA array was implemented with electromagnetic band-gap (EBG) structure etched onto the ground plane of the MSTL. The proposed architecture achieves isolation better than 26 dB over the desired frequency band without any performance degradation while maintaining its compact size in the array. Various diversity analysis was carried out on the implemented circularly polarized MIMO DRA. The measured results demonstrated that the proposed singly fed DRA with EBG on the ground plate is suitable for implementing wideband circular polarized MIMO antennas in a compact size.","2169-3536","","10.1109/ACCESS.2019.2943880","National Research Foundation of Korea; Ministry of Science, ICT and Future Planning(grant numbers:2018R1C1B5045481); Korea Institute of Energy Technology Evaluation and Planning; Ministry of Trade, Industry and Energy(grant numbers:20194030202320); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8850095","Dielectric resonator antennas;electromagnetic band-gap;MIMO;mutual coupling","MIMO communication;Antennas;Substrates;Periodic structures;Mutual coupling;Metamaterials;Wideband","","94","","47","CCBY","26 Sep 2019","","","IEEE","IEEE Journals"
"A Privacy-Preserving Distributed Greedy Framework to Desynchronize Power Consumption in a Network of Thermostatically Controlled Loads","M. Kaheni; A. V. Papadopoulos; E. Usai; M. Franceschelli","IDT, Mälardalen University, Västerås, Sweden; IDT, Mälardalen University, Västerås, Sweden; DIEE, University of Cagliari, Cagliari, Italy; DIEE, University of Cagliari, Cagliari, Italy",IEEE Transactions on Control Systems Technology,"25 Oct 2024","2024","32","6","2476","2483","This manuscript presents a novel distributed greedy framework applicable to a network of thermostatically controlled loads (TCLs) to desynchronize the network’s aggregated power consumption. Compared to the existing literature, our proposed framework offers two distinct novelties. First, our proposed algorithm relaxes the restrictive assumptions associated with the communication graph among TCLs. To elaborate, our algorithm only requires a connected graph to execute control, a condition less demanding than its counterpart algorithms that mandate a star architecture, K-regular graphs, or undirected connected graphs. Second, a significant novel feature is the relaxation of the obligation to share private information, such as each unit’s local power consumption and appliance temperatures, either with a central coordinator or neighboring TCLs. The findings presented in this brief are validated through simulations conducted over a network comprising 1000 TCLs.","1558-0865","","10.1109/TCST.2024.3425210","Project “Network 4 Energy Sustainable Transition (NEST)”; National Recovery and Resilience Plan (NRRP), (Mission 4, Component 2, Investment 1.3–Call for Tender No. 1561 of 11.10.2022), Ministero dell’Universita e della Ricerca (MUR), Project code PE0000021; Fondazione di Sardegna; “Formal Methods and Technologies for the Future of Energy Systems”(grant numbers:F72F20000350007); Swedish Research Council [Vetenskapsrådet (VR)]; “Pervasive Self-Optimizing Computing Infrastructures (PSI)”(grant numbers:2020-05094); Knowledge Foundation [kunskapsoch kompetensutveckling-stiftelsen (KKS)]; “Safe and Secure Adaptive Collaborative Systems (SACSys)”(grant numbers:20190021); Mälardalen University Automation Research Center (MARC)(grant numbers:20240011); Swedish Agency for Innovation Systems (Vinnova); “GREENER: Intelligent Energy Management in Connected Construction Sites”(grant numbers:2019-05877); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10604709","Demand response;distributed optimization;greedy control;multiagent systems;thermostatically controlled loads (TCLs)","Power demand;Thermostats;Water heating;Temperature distribution;Privacy;Temperature measurement;Energy consumption;Demand response;Optimization methods;Decentralized control;Greedy algorithms;Multi-agent systems;Temperature control","","3","","27","CCBY","18 Jul 2024","","","IEEE","IEEE Journals"
"Decentralized Edge-to-Cloud Load Balancing: Service Placement for the Internet of Things","Z. Nezami; K. Zamanifar; K. Djemame; E. Pournaras","Faculty of Computer Engineering, University of Isfahan, Isfahan, Iran; Faculty of Computer Engineering, University of Isfahan, Isfahan, Iran; School of Computing, University of Leeds, Leeds, U.K.; School of Computing, University of Leeds, Leeds, U.K.",IEEE Access,"3 May 2021","2021","9","","64983","65000","The Internet of Things (IoT) requires a new processing paradigm that inherits the scalability of the cloud while minimizing network latency using resources closer to the network edge. On the one hand, building up such flexibility within the edge-to-cloud continuum consisting of a distributed networked ecosystem of heterogeneous computing resources is challenging. On the other hand, IoT traffic dynamics and the rising demand for low-latency services foster the need for minimizing the response time and a balanced service placement. Load-balancing for fog computing becomes a cornerstone for cost-effective system management and operations. This paper studies two optimization objectives and formulates a decentralized load-balancing problem for IoT service placement: (global) IoT workload balance and (local) quality of service (QoS), in terms of minimizing the cost of deadline violation, service deployment, and unhosted services. The proposed solution, EPOS Fog, introduces a decentralized multi-agent system for collective learning that utilizes edge-to-cloud nodes to jointly balance the input workload across the network and minimize the costs involved in service execution. The agents locally generate possible assignments of requests to resources and then cooperatively select an assignment such that their combination maximizes edge utilization while minimizes service execution cost. Extensive experimental evaluation with realistic Google cluster workloads on various networks demonstrates the superior performance of EPOS Fog in terms of workload balance and QoS, compared to approaches such as First Fit and exclusively Cloud-based. The results confirm that EPOS Fog reduces service execution delay up to 25% and the load-balance of network nodes up to 90%. The findings also demonstrate how distributed computational resources on the edge can be utilized more cost-effectively by harvesting collective intelligence.","2169-3536","","10.1109/ACCESS.2021.3074962","Government Ministry of Science, Research and Technology of the Islamic Republic of Iran; Swiss Federal Institute of Technology in Lausanne (EPFL); Swiss Federal Institute of Technology (ETH) in Zürich; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9418552","Agent;cloud computing;collective learning;distributed optimization;edge computing;fog computing;Internet of Things (IoT);load-balancing;service placement","Internet of Things;Cloud computing;Edge computing;Quality of service;Delays;Servers;Computer architecture","","78","","82","CCBY","28 Apr 2021","","","IEEE","IEEE Journals"
"Improving Secrecy Capacity in the Face of Eavesdropping in SWIPT CIoT Networks With Actor-Critic DRL","N. Abdel Khalek; W. Hamouda","Department of Electrical and Computer Engineering, Concordia University, Montreal, QC, Canada; Department of Electrical and Computer Engineering, Concordia University, Montreal, QC, Canada",IEEE Open Journal of the Communications Society,"8 Jul 2025","2025","6","","5328","5343","One of the key enablers of 6th-generation (6G) wireless networks is cognitive radio, offering optimized spectrum utilization, enhanced device intelligence, and improved security. This article investigates secure communication in an energy-harvesting (EH) cognitive Internet of Things (CIoT) network operating over cascaded fading channels. Here, a CIoT transmitter employs an intelligent strategy to allocate time for simultaneous wireless information and power transfer (SWIPT) and transmission power to maximize the secrecy rate. The CIoT receiver operates in full-duplex (FD) mode, receiving confidential messages while simultaneously emitting cooperative jamming signals to disrupt an eavesdropper. We formulate the challenging non-convex optimization problem to maximize secrecy capacity while ensuring spectrum sharing and energy constraints and model the CIoT agent’s decision-making as a model-free Markov decision process (MDP). We then propose a deep reinforcement learning (DRL) approach to determine the optimal strategy for secure transmission and resource allocation. Specifically, we derive the instantaneous secrecy rate and employ a deep deterministic policy gradient (DDPG) algorithm with a lightweight actor-critic architecture to efficiently address dynamic channel occupancy, EH opportunities, and fading conditions. The proposed DDPG algorithm allows the CIoT agent to adapt to dynamic environments, enhance transmission security, and extend network lifetime without prior knowledge. Extensive simulations confirm its convergence and effectiveness in improving secrecy capacity, throughput, and energy efficiency. Moreover, the results attest to its superior performance compared to existing benchmarks.","2644-125X","","10.1109/OJCOMS.2025.3578149","Natural Sciences and Engineering Research Council of Canada (NSERC)(grant numbers:00881); Fonds de Recherche du Québec - Nature et Technologies (FRQNT)(grant numbers:10.69777/315554); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029087","Full-duplex communications;cognitive IoT networks;spectrum sharing;cooperative jamming;eavesdropping;actor-critic;deep deterministic policy gradient (DDPG);simultaneous wireless information and power transfer (SWIPT);energy harvesting","Security;Internet of Things;Eavesdropping;Jamming;Resource management;Optimization;Energy efficiency;Simultaneous wireless information and power transfer;Vehicle dynamics;Heuristic algorithms","","","","57","CCBY","9 Jun 2025","","","IEEE","IEEE Journals"
"Lightweight Self-Supervised Monocular Depth Estimation Through CNN and Transformer Integration","Z. Wang; Y. Zou; J. Lv; Y. Cao; H. Yu","College of Artificial Intelligence and Software, Liaoning Petrochemical University, Fushun, Liaoning, China; College of Artificial Intelligence and Software, Liaoning Petrochemical University, Fushun, Liaoning, China; Neusoft Reach Automotive Technology Company Ltd., Shenyang, China; College of Artificial Intelligence and Software, Liaoning Petrochemical University, Fushun, Liaoning, China; College of Artificial Intelligence and Software, Liaoning Petrochemical University, Fushun, Liaoning, China",IEEE Access,"18 Nov 2024","2024","12","","167934","167943","Self-supervised monocular depth estimation is a promising research area due to its ability to train models without relying on expensive and difficult-to-obtain ground truth depth labels. In this domain, models often employ Convolutional Neural Networks (CNNs) and Transformers for feature extraction. While CNNs excel at capturing local features, they struggle with global information due to their limited receptive field. On the other hand, Transformers can capture global features but are computationally expensive. To balance performance and computational efficiency, this paper proposes a lightweight self-supervised monocular depth estimation model that integrates CNN and Transformer architectures. The model introduces an Agent Attention mechanism to effectively model global context while significantly reducing computational complexity. Furthermore, spatial and channel restructured convolution techniques are utilized to minimize the computational cost associated with redundant feature extraction in visual tasks. Validation on the KITTI dataset shows that the model reaches an Absolute Relative Error of 0.104 and a Squared Relative Error of 0.757 while maintaining a nearly constant number of parameters. The accuracy improved to 0.889, with computational complexity (FLOPs) reduced to 4.993G, and training time decreased from 15.5 hours to 13.5 hours. The model also demonstrated strong generalization on the Make 3D dataset, with only 3.0M parameters and low computational complexity, indicating its suitability for resource-constrained devices.","2169-3536","","10.1109/ACCESS.2024.3494872","National Natural Science Foundation of China(grant numbers:61702247); Basic Scientific Research Project of Liaoning Provincial Department of Education(grant numbers:LJKMZ20220723,LJKMZ20220); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10749800","Machine vision;monocular depth estimation;lightweight;self-supervised learning","Transformers;Computational modeling;Feature extraction;Computational efficiency;Accuracy;Training;Image reconstruction;Convolution;Convolutional neural networks;Computer architecture","","2","","30","CCBYNCND","11 Nov 2024","","","IEEE","IEEE Journals"
"MathVision: An Accessible Intelligent Agent for Visually Impaired People to Understand Mathematical Equations","M. Awais Ahmad; T. Ahmed; M. Aslam; A. Rehman; F. S. Alamri; S. A. Bahaj; T. Saba","Department of CS, University of Engineering and Technology, Lahore, Punjab, Pakistan; Department of CS, University of Engineering and Technology, Lahore, Punjab, Pakistan; Department of CS, University of Engineering and Technology, Lahore, Punjab, Pakistan; Artificial Intelligence and Data Analytics Lab, CCIS, Prince Sultan University, Riyadh, Saudi Arabia; Department of Mathematical Sciences, College of Science, Princess Nourah Bint Abdulrahman University, P.O. Box 84428, Riyadh, Saudi Arabia; MIS Department College of Business Administration, Prince Sattam Bin Abdulaziz University, AlKharj, Saudi Arabia; Artificial Intelligence and Data Analytics Lab, CCIS, Prince Sultan University, Riyadh, Saudi Arabia",IEEE Access,"13 Jan 2025","2025","13","","6155","6165","2.2 billion people worldwide suffer from some form of vision impairment, according to the World Health Organization. Children with vision impairment and visual impairment may experience impaired physical, linguistic, and cognitive development, resulting in reduced levels of academic accomplishment. Many visually impaired people are working in the education sector whether they are students or teachers. Without external assistance reading of mathematical equations in images for visually impaired people is very challenging due to the complexity of notations, symbols, and variables. This paper presents a model named MathVision which converts the mathematical equation into voice. This voice is quite helpful for visually impaired people to understand mathematical equations. The proposed model is comprised of YOLOv7 object detection architecture to detect and categorize mathematical equations inside images into four distinct types: limits, trigonometry, integration, and an additional category. The input image is divided into a grid by the YOLOv7 model, and each grid cell is responsible for finding equations that fall into its respective category. bounding box coordinates, object labels, and probability scores are predicted for each equation. In the next stage, a fine-tuned DenseNet is utilized for detailed feature extraction from mathematical equation images. This involves optimizing a pre-trained DenseNet model to capture intricate patterns specific to equations. The fine-tuned DenseNet enhances overall accuracy in equation detection and categorization within the system. In the subsequent phase, an attention mechanism-based LSTM network is employed to generate natural language descriptions for mathematical equations. During the decoding process, the model is better able to focus on pertinent portions of the equation due to the integration of attention. The LSTM architecture, chosen for its effectiveness with sequential data, is trained on a dataset containing paired examples of equations and corresponding human-generated descriptions. Fine-tuning includes optimizing hyperparameters for the task, and evaluation metrics such as the BLEU score are used to assess the model’s performance in generating accurate and contextually relevant textual representations for the detected mathematical content. Our text-to-speech system takes input in the form of a natural language sentence generated by the LSTM model and converts it to the voice. This TTS using natural language processing analyzes and processes the text then it converts this processed text into speech using digital signal processing technology. A platform-independent pyttsx3 python library is used for converting text into speech. It also works offline which is the main reason for using this library in this research work. As there was no dataset available of mathematical equations with their natural language description, we created a custom dataset. We conducted real-world experiments in various visually impaired schools to see whether visually impaired students can understand mathematical equations by hearing the voice. These experiments prove that the MathVision Model is an efficient way for visually impaired students to read and write mathematical equations by listening to the voice of equations generated by proposed model.INDEX TERMS Mathematical equations, fine-tuned, YOLO v7, convolution neural network, attention mechanism, long short term memory, neural text to speech, technological development.","2169-3536","","10.1109/ACCESS.2024.3514079","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10787000","Mathematical equations;fine-tuned;YOLO v7;convolution neural network;attention mechanism;long short term memory;neural text to speech;technological development","Mathematical models;Accuracy;Symbols;Natural languages;Feature extraction;Long short term memory;Handwriting recognition;Neural networks;Image recognition;Decoding","","1","","33","CCBY","9 Dec 2024","","","IEEE","IEEE Journals"
"A Resource-Efficient 3D U-Net for Hippocampus Segmentation Using CLAHE and SCE-3DWT Techniques","F. F. Khan; J. -H. Kim; C. -S. Park; J. -I. Kim; G. -R. Kwon","Department of Information and Communication Engineering, Chosun University, Dong-gu, Gwangju, South Korea; Department of Information and Communication Engineering, Chosun University, Dong-gu, Gwangju, South Korea; Department of Computer Education, Sungkyunkwan University, Jongno-gu, Seoul, Republic of Korea; Department of Information and Communication Engineering, Chosun University, Dong-gu, Gwangju, South Korea; Department of Information and Communication Engineering, Chosun University, Dong-gu, Gwangju, South Korea",IEEE Access,"12 Jun 2025","2025","13","","99923","99938","Hippocampus segmentation on MRI (magnetic resonance imaging) plays a vital role in detecting, diagnosing, tracking, and monitoring neurodegenerative diseases, particularly Alzheimer’s disease. While larger datasets often provide an advantage in deep learning-based segmentation, smaller datasets pose unique challenges due to limited data variability and an increased risk of overfitting. This study addresses these challenges by developing a computationally efficient and accurate 3D U-Net model tailored for hippocampus segmentation. The proposed approach employs a preprocessing pipeline combining 3D Contrast Limited Adaptive Histogram Equalization (CLAHE) and Selective Coefficient-Enhanced 3D Wavelet Transform (SCE-3DWT), which enhances contrast and reduces noise for improved feature extraction. The experimental evaluation was conducted using the EADC-ADNI HarP dataset, comprising 135 hippocampal MRI scans with an input image size of  $64\times 64 \times 96$ . The model achieved a Dice coefficient of 0.8838 and a Jaccard Index of 0.7920, surpassing recent state-of-the-art methods. Comparative analysis highlights reduced Over-Segmentation Ratio (OSR = FP/(FP+TP), 0.0594) and Under-Segmentation Ratio (USR = FN/(FN+TP), 0.0569, reflecting its robustness and generalization. The lightweight architecture, designed with a maximum filter size of 512, operates efficiently without relying on transfer learning, making it accessible for broader applications. Future work will focus on integrating post processing techniques, leveraging larger and more diverse datasets, and exploring higher-resolution volumetric data to further improve segmentation accuracy and clinical utility. This study contributes to the advancement of medical image analysis, offering a resource-efficient framework for precise hippocampus segmentation, with potential implications for improved Alzheimer’s disease management.","2169-3536","","10.1109/ACCESS.2025.3577266","National Research Foundation of Korea (NRF); Korean Government Ministry of Science and Information and Communication Technology (MSIT)(grant numbers:NRF-2021R1I1A3050703); BrainKorea21Four Program, through the NRF; Ministry of Education(grant numbers:4299990114316); Basic Science Research Program through the NRF; Ministry of Education(grant numbers:RS-2023-0027033); Alzheimer's Disease Neuroimaging Initiative (ADNI); National Institutes of Health(grant numbers:U01 AG024904); Department of Defense ADNI under Award(grant numbers:W81XWH-12-2-0012); Global-Learning and Academic Research Institution for Master's PhD students, and Postdocs [Global Leading Advanced Medical Platform (G-LAMP)] Program of the National Research Foundation of Korea (NRF); Ministry of Education(grant numbers:RS-2023-00285353); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11027081","Alzheimer’s disease;3D contrast limited adaptive histogram equalization (CLAHE);EADC-ADNI Harmonized protocol (HarP) dataset;hippocampus segmentation;selective coefficient-enhanced 3D wavelet transform for MRI segmentation (SCE-3DWT);3D U-Net","Three-dimensional displays;Image segmentation;Magnetic resonance imaging;Hippocampus;Histograms;Wavelet transforms;Alzheimer's disease;Accuracy;Adaptive equalizers;Neuroimaging","","3","","23","CCBY","6 Jun 2025","","","IEEE","IEEE Journals"
"A Cyber Resilient Framework for V2X Enabled Roundabouts in Intelligent Transportation Systems","W. Abbass; N. Abbas; U. Majeed; W. Nawaz; Q. Abbas; A. Hussain Farooqi","Department of Electrical and Computer Engineering, Capital University of Science and Technology (CUST), Islamabad, Pakistan; Department of Computer Science, Muslim Youth University, Islamabad, Pakistan; Department of Computer Science and Automation, Technische Universität Ilmenau, Ilmenau, Germany; Department of Information Systems, College of Computer and Information Systems, Islamic University of Madinah, Madinah, Saudi Arabia; Department of Computer Science, College of Computer and Information Systems, Islamic University of Madinah, Madinah, Saudi Arabia; Faculty of Computing and AI, Air University, Islamabad, Pakistan",IEEE Access,"9 Sep 2025","2025","13","","154775","154802","Vehicle-to-everything (V2X) communication systems are increasingly susceptible to cyber-physical threats that exploit trust assumptions, coordination latency, and semantic inconsistencies across agents. These vulnerabilities, particularly in dense or adversarial environments, undermine the reliability of cooperative perception, anomaly detection, and safety-critical maneuver execution. This paper presents CR-V2XR, a cross-layer, federated, and trust-aware coordination framework designed to enhance resilience in connected and autonomous vehicular networks. CR-V2XR integrates multi-modal anomaly detection with delay-sensitive trust estimation using features extracted from basic safety messages (BSMs), behavioral deviations, entropy shifts, and inter-vehicle trust validation. The architecture employs federated learning for distributed anomaly detection without centralized aggregation and uses a control layer that supports delay-aware trajectory selection. A multi-objective NSGA-III optimizer enables online trade-off adaptation across detection accuracy (DA), collision probability, and communication overhead. Simulations across eleven adversarial scenarios, including Sybil, wormhole, falsification, and replay attacks, demonstrate that CR-V2XR achieves 95% detection accuracy under worst-case attacks, reduces collision probability from 0.61 to 0.27 at 300 vehicles, maintains bounded delay, typically 45–60 ms under nominal load, and remains resilient under high-stress conditions with delays up to 180 ms and communication overhead ( $\leq 6.1$  MB/s). Compared to centralized IDS and stateless baselines, CR-V2XR improves detection fidelity, scalability, and robustness under non-IID data and partial synchronization. These results establish CR-V2XR as a viable architecture for delay-constrained, trust-centric coordination in federated V2X environments subject to persistent adversarial threats.","2169-3536","","10.1109/ACCESS.2025.3604095","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11145039","Vehicle-to-everything (V2X) communication;federated learning;trust modeling;intrusion detection systems (IDS);cyber-physical security;multi-agent coordination;intelligent transportation systems (ITS)","Vehicle-to-everything;Real-time systems;Computer security;Security;Image edge detection;Anomaly detection;Vehicle dynamics;Safety;Electronic mail;Computer crime","","2","","60","CCBY","29 Aug 2025","","","IEEE","IEEE Journals"
"MixNet: Physics Constrained Deep Neural Motion Prediction for Autonomous Racing","P. Karle; F. Török; M. Geisslinger; M. Lienkamp","Department of Mobility Systems Engineering, TUM School of Engineering and Design, Institute of Automotive Technology, Technical University of Munich (TUM), Munich, Germany; Department of Mobility Systems Engineering, TUM School of Engineering and Design, Institute of Automotive Technology, Technical University of Munich (TUM), Munich, Germany; Department of Mobility Systems Engineering, TUM School of Engineering and Design, Institute of Automotive Technology, Technical University of Munich (TUM), Munich, Germany; Department of Mobility Systems Engineering, TUM School of Engineering and Design, Institute of Automotive Technology, Technical University of Munich (TUM), Munich, Germany",IEEE Access,"17 Aug 2023","2023","11","","85914","85926","Reliably predicting the motion of contestant vehicles surrounding an autonomous racecar is crucial for effective and performant ego-motion planning. Although highly expressive, deep neural networks are black-box models, making their usage challenging in this safety-critical applications of autonomous racing. On the other hand, physics-based models provide high safety guarantees for the predicted trajectory but lack accuracy. The method presented in this paper targets this trade-off. We introduce a method to predict the trajectories of opposing racecars with deep neural networks considering physical constraints to restrict the output and to improve its feasibility. We report the method’s performance against an LSTM-based encoder-decoder architecture on data acquired from multi-agent racing simulations. The proposed method outperforms the baseline model in prediction accuracy and robustness. Still, it fulfills quality guarantees of smoothness and consistency of the predicted trajectory and prevents out-of-track predictions. Thus, a robust real-world application of the model with high prediction accuracy is proven. The presented model was deployed on the racecar of the Technical University of Munich for the Indy Autonomous Challenge 2021. The code used in this research is available as open-source software at https://www.github.com/TUMFTM/MixNet.","2169-3536","","10.1109/ACCESS.2023.3303841","Technische Universität München; Bavarian Research Foundation (BFS); Institute for Ethics in Artificial Intelligence (IEAI); Leibniz-Rechenzentrum; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10214014","Autonomous racing;hybrid deep neural networks;motion prediction;scenario understanding","Trajectory;Predictive models;Hidden Markov models;Decoding;History;Behavioral sciences;Prediction algorithms;Autonomous vehicles;Neural networks;Deep learning;Motion control","","8","","50","CCBYNCND","9 Aug 2023","","","IEEE","IEEE Journals"
"Fine-Tuning Multimodal Transformer Models for Generating Actions in Virtual and Real Environments","A. Staroverov; A. S. Gorodetsky; A. S. Krishtopik; U. A. Izmesteva; D. A. Yudin; A. K. Kovalev; A. I. Panov","Artificial Intelligence Research Institute (AIRI), Moscow, Russia; Center of Cognitive Modeling, Moscow Institute of Physics and Technology, Dolgoprudny, Russia; Center of Cognitive Modeling, Moscow Institute of Physics and Technology, Dolgoprudny, Russia; Center of Cognitive Modeling, Moscow Institute of Physics and Technology, Dolgoprudny, Russia; Artificial Intelligence Research Institute (AIRI), Moscow, Russia; Artificial Intelligence Research Institute (AIRI), Moscow, Russia; Artificial Intelligence Research Institute (AIRI), Moscow, Russia",IEEE Access,"23 Nov 2023","2023","11","","130548","130559","In this work, we propose and investigate an original approach to using a pre-trained multimodal transformer of a specialized architecture for controlling a robotic agent in an object manipulation task based on language instruction, which we refer to as RozumFormer. Our model is based on a bimodal (text-image) transformer architecture originally trained for solving tasks that use one or both modalities, such as language modeling, visual question answering, image captioning, text recognition, text-to-image generation, etc. The discussed model has been adapted for robotic manipulation tasks by organizing the input sequence of tokens in a particular way, consisting of tokens for text, images, and actions. We have demonstrated that such a model adapts well to new tasks and shows better results with fine-tuning than complete training in simulation and real environments. To transfer the model from the simulator to a real robot, new datasets were collected and annotated. In addition, experiments controlling the agent in a visual environment using reinforcement learning have shown that fine-tuning the model with a mixed dataset that includes examples from the initial visual-linguistic tasks only slightly decreases performance on these tasks, simplifying the addition of tasks from another domain.","2169-3536","","10.1109/ACCESS.2023.3334791","Analytical Center for the Government of the Russian Federation(grant numbers:000000D730321P5Q0002,70-2021-00138); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10323309","Action generation;bimodal transformer models;intelligent agent;robotic manipulator arm control","Robots;Task analysis;Robot kinematics;Transformers;Cameras;Robot vision systems;Adaptation models;Manipulators;Robot control","","3","","50","CCBYNCND","20 Nov 2023","","","IEEE","IEEE Journals"
"Multimodal Human-Robot Interface for Accessible Remote Robotic Interventions in Hazardous Environments","G. Lunghi; R. Marin; M. Di Castro; A. Masi; P. J. Sanz","Interactive Robotic Systems Laboratory, Jaume I University of Castellón, Castellón de la Plana, Spain; Interactive Robotic Systems Laboratory, Jaume I University of Castellón, Castellón de la Plana, Spain; CERN, Survey, Measurement and Mechatronics (EN-SMM) Group, Geneva, Switzerland; CERN, Survey, Measurement and Mechatronics (EN-SMM) Group, Geneva, Switzerland; Interactive Robotic Systems Laboratory, Jaume I University of Castellón, Castellón de la Plana, Spain",IEEE Access,"16 Sep 2019","2019","7","","127290","127319","Human-Robot Interfaces have a key role in the design of secure and efficient robotic systems. Great effort has been put during the past decades on the design of advanced interfaces for domestic and industrial robots. However, robots for intervention in unplanned and hazardous scenarios still need further research, especially when the mission requires the use of multiple robotic systems, to obtain an acceptable level of usability and safety. This paper describes the design and the software engineering process behind the development of a modular and multimodal Human-Robot Interface for intervention with a cooperative team of robots, as well as its validation and commissioning, as it is being used in real operations at CERN's accelerators complex. The proposed Human-Robot Interface allows the control of a heterogeneous set of robots homogeneously, providing the operator, among other features, with live scripting functionalities which can be programmed and adapted in run-time, for example, to increase operator's multi-tasking in a multi-agent scenario. The operator is given the capability to enter in the control loop between the HRI and the robot and customize the control commands according to the operation. To provide such functionalities, well-defined software development approaches have been adopted, for guaranteeing the modularity and the safety of the system during its continuous development. The paper describes the modules offered by the HRI, such as the multimodality, multi-robot control, safety, operators training, and communications architecture, among others. The HRI and the CERN Robotic Framework where it belongs are designed in a modular manner, in order to be able to adapt both, software and hardware architecture in a short time, to the next planned mission. Results present the experience gained with the system, demonstrating a high level of usability, learnability and safety when operated by both, non-experts and qualified robotic operators. The multimodal user interface has demonstrated to be very accurate and secure, providing a unique system to control, in a teleoperated or supervised manner, both single and multiple heterogeneous mobile manipulators. At the moment of writing, the user interface has been successfully used in 100 real interventions in radioactive industrial environments. The presented HRI is a novel research contribution in terms of multimodality, adaptability and modularity for mobile manipulator robotic teams in radioactive environments, especially for its software architecture, as part of the CERN Robotic Framework.","2169-3536","","10.1109/ACCESS.2019.2939493","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8823931","Human robot interaction;mobile robots;teleoperators;telerobotics;multiagent systems;software engineering","Service robots;Robot sensing systems;Safety;Tools;Human-robot interaction","","47","","84","CCBY","4 Sep 2019","","","IEEE","IEEE Journals"
"An Innovative Prefabricated Microsystem for Industrial IoT: Addressing Remote Onboarding and OS Provisioning Challenges for Edge Nodes","C. Chen; T. Chen; Z. Jiang; L. Wang","Department of Information Construction and Management, Huaqiao University, Quanzhou, Fujian, China; Client Computing Group, Intel (SHZ8), Shanghai, China; Client Computing Group, Intel (SHZ8), Shanghai, China; Client Computing Group, Intel (SHZ8), Shanghai, China",IEEE Access,"3 Sep 2025","2025","13","","150583","150593","Chinese industrial IoT devices frequently encounter challenges during the cloud-based remote onboarding and OS provisioning: BIOS system of many industrial IoT devices does not support the HTTPS Boot protocol, which limits its ability to securely receive configuration information and increases security risks. Although there are alternative options such as PXE boot or manual configuration, both have security risks. For this reason, this paper has designed an innovative prefabricated micro-system with agent mechanism that enables Edge Nodes to securely access the cloud servers for management and control. Specifically, once the operator installs the uOS image on the Edge Node for initial deployment, bidirectional secure communication is established between the agent and the cloud server, enabling the Edge Node to successfully complete onboarding. Subsequently, the agent retrieves the latest configuration data from the cloud server to finalize provisioning. The pre-fabricated microsystem also supports fault recovery and process monitoring. Furthermore, this study conducts performance and maximum concurrency tests under both mTLS and TLS + JWT protocols. The innovative agent solution proposed herein will provide robust technical support and enhanced security guarantees for China’s Industrial Internet of Things (IIoT).","2169-3536","","10.1109/ACCESS.2025.3600962","National Social Science Foundation of China(grant numbers:21BGL054); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11131131","Industrial IoT device;remote onboarding and provisioning;secure communication;microsystem;agent mechanism","Security;Industrial Internet of Things;Protocols;Authentication;Servers;Cloud computing;Operating systems;Hardware;Computer architecture;Micromechanical devices","","","","27","CCBY","20 Aug 2025","","","IEEE","IEEE Journals"
"Distributed Finite-Time Cooperative Control for Quadrotor Formation","Y. Li; J. Yang; K. Zhang","School of Astronautics, Northwestern Polytechnical University, Xi’an, China; School of Astronautics, Northwestern Polytechnical University, Xi’an, China; School of Astronautics, Northwestern Polytechnical University, Xi’an, China",IEEE Access,"3 Jun 2019","2019","7","","66753","66763","This paper investigates a finite-time formation control problem for multiple networked quadrotors. A novel distributed control approach is presented under the leader-follower formation framework, and the approach is developed based on the finite-time Lyapunov theory and the homogeneous system theory such that all quadrotors form and maintain a desired geometric pattern within finite time while tracking a reference trajectory. The designed control law is composed of a dynamic observer, a position controller and an attitude controller, in which the observer is adopted to provide estimates of the leader quadrotor information for each follower quadrotor, and the controllers are in a cascade structure. It is shown that the finite-time leader-follower formation of a group of quadrotors can be achieved via the distributed control approach, and the cascade control architecture conforms to quadrotor dynamic characteristics. The constructive procedures on how to synthesize such a control law are also given. The effectiveness of the proposed control approach is verified by the simulation.","2169-3536","","10.1109/ACCESS.2019.2915594","National Natural Science Foundation of China(grant numbers:61803311); China Postdoctoral Science Foundation(grant numbers:2019M653745); National Space Support Technology Foundation of China(grant numbers:2014-HT-XGD); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8709666","Finite-time control;formation control;unmanned aerial vehicles","Aircraft;Stability analysis;Decentralized control;Observers;Attitude control;Rotors","","26","","45","OAPA","8 May 2019","","","IEEE","IEEE Journals"
"Integrating Conversational Agents and Knowledge Graphs Within the Scholarly Domain","A. Meloni; S. Angioni; A. Salatino; F. Osborne; D. Reforgiato Recupero; E. Motta","Department of Mathematics and Computer Science, University of Cagliari, Cagliari, Italy; Department of Mathematics and Computer Science, University of Cagliari, Cagliari, Italy; Knowledge Media Institute, The Open University, Milton Keynes, U.K; Knowledge Media Institute, The Open University, Milton Keynes, U.K; Department of Mathematics and Computer Science, University of Cagliari, Cagliari, Italy; Knowledge Media Institute, The Open University, Milton Keynes, U.K",IEEE Access,"9 Mar 2023","2023","11","","22468","22489","In the last few years, chatbots have become mainstream solutions adopted in a variety of domains for automatizing communication at scale. In the same period, knowledge graphs have attracted significant attention from business and academia as robust and scalable representations of information. In the scientific and academic research domain, they are increasingly used to illustrate the relevant actors (e.g., researchers, institutions), documents (e.g., articles, patents), entities (e.g., concepts, innovations), and other related information. Following the same direction, this paper describes how to integrate conversational agents with knowledge graphs focused on the scholarly domain, a.k.a. Scientific Knowledge Graphs. On top of the proposed architecture, we developed AIDA-Bot, a simple chatbot that leverages a large-scale knowledge graph of scholarly data. AIDA-Bot can answer natural language questions about scientific articles, research concepts, researchers, institutions, and research venues. We have developed four prototypes of AIDA-Bot on Alexa products, web browsers, Telegram clients, and humanoid robots. We performed a user study evaluation with 15 domain experts showing a high level of interest and engagement with the proposed agent.","2169-3536","","10.1109/ACCESS.2023.3253388","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10061222","Chatbots;knowledge graphs;human–robot interaction;scholarly data;user experience;virtual assistant","Chatbots;Knowledge graphs;Virtual assistants;Computer architecture;Task analysis;Ontologies;Humanoid robots","","26","","76","CCBY","6 Mar 2023","","","IEEE","IEEE Journals"
"Why Do Opinions and Actions Diverge? A Dynamic Framework to Explore the Impact of Subjective Norms","C. Song; V. Cvetkovic; R. Su","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Architecture and the Built Environment, KTH Royal Institute of Technology, Stockholm, Sweden; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",IEEE Transactions on Computational Social Systems,"","2025","PP","99","1","12","Socio-psychological studies have identified a common phenomenon where an individual’s public actions do not necessarily coincide with their private opinions, yet most existing models fail to capture the dynamic interplay between these two aspects. To bridge this gap, we propose a novel agent-based modeling framework that integrates opinion dynamics with a decision-making mechanism. More precisely, our framework generalizes the classical Hegselmann-Krause (HK) model by combining it with a utility maximization problem. Preliminary results from our model demonstrate that the degree of opinion-action divergence within a population can be effectively controlled by adjusting two key parameters that reflect agents’ personality traits, while the presence of social network amplifies the divergence. In addition, we study the social diffusion process by introducing a small number of committed agents into the model, and identify three key outcomes: adoption of innovation, rejection of innovation, and the enforcement of unpopular norms, consistent with findings in socio-psychological literature. The strong relevance of the results to real-world phenomena highlights our framework’s potential for future applications in understanding and predicting complex social behaviors.","2329-924X","","10.1109/TCSS.2025.3598697","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11152607","Agent-based modeling;bounded confidence;decision-making;opinion dynamics;social diffusion;subjective norms","Opinion dynamics;Mathematical models;Psychology;Decision making;Technological innovation;Steady-state;Social networking (online);Network topology;Integrated circuit modeling;Topology","","","","","CCBY","8 Sep 2025","","","IEEE","IEEE Early Access Articles"
"Security of Internet of Agents: Attacks and Countermeasures","Y. Wang; Y. Pan; S. Guo; Z. Su","School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China; School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China; School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China; School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China",IEEE Open Journal of the Computer Society,"17 Oct 2025","2025","6","","1611","1624","With the rise of large language and vision-language models, AI agents have evolved into autonomous, interactive systems capable of perception, reasoning, and decision-making. As they proliferate across virtual and physical domains, the Internet of Agents (IoA) has emerged as a key infrastructure for enabling scalable and secure coordination among heterogeneous agents. This survey offers a comprehensive examination of the security and privacy landscape in IoA systems. We begin by outlining the IoA architecture and its distinct vulnerabilities compared to traditional networks, focusing on four critical aspects: identity authentication threats, cross-agent trust issues, embodied security, and privacy risks. We then review existing and emerging defense mechanisms and highlight persistent challenges. Finally, we identify open research directions to advance the development of resilient and privacy-preserving IoA ecosystems.","2644-1268","","10.1109/OJCS.2025.3589638","National Natural Science Foundation of China(grant numbers:62302387,U22A2029,U24A20237); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11081880","Internet of agents (IoA);AI agents;large models;security;and privacy","Security;Privacy;Surveys;Protocols;Artificial intelligence;Internet;Biological system modeling;Ecosystems;Reviews;Collaboration","","1","","71","CCBYNCND","16 Jul 2025","","","IEEE","IEEE Journals"
"A cyber-anima-based model of material conscious information network","J. Shen; Y. Huang; Y. Chai","Department of Automation, Tsinghua University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China; National Engineering Laboratory for E-commerce Technology, Tsinghua University, Beijing, China",International Journal of Crowd Science,"7 Jul 2022","2017","1","1","9","25","Purpose – This paper aims to study the node modeling, multi-agent architecture and addressing method for the material conscious information network (MCIN), which is a large-scaled, open-styled, self-organized and ecological intelligent network of supply–demand relationships. Design/methodology/approach – This study models the MCIN by node model definition, multi-agent architecture design and addressing method presentation. Findings – The prototype of novel E-commerce platform based on the MCIN shows the effectiveness and soundness of the MCIN modeling. By comparing to current internet, the authors also find that the MCIN has the advantages of socialization, information integration, collective intelligence, traceability, high robustness, unification of producing and consuming, high scalability and decentralization. Research limitations/implications – Leveraging the dimensions of structure, character, knowledge and experience, a modeling approach of the basic information can fit all kinds of the MCIN nodes. With the double chain structure for both basic and supply–demand information, the MCIN nodes can be modeled comprehensively. The anima-desire-intention-based multi-agent architecture makes the federated agents of the MCIN nodes self-organized and intelligent. The MCIN nodes can be efficiently addressed by the supply-demand-oriented method. However, the implementation of the MCIN is still in process. Practical implications – This paper lays the theoretical foundation for the future networked system of supply–demand relationship and the novel E-commerce platform. Originality/value – The authors believe that the MCIN, first proposed in this paper, is a transformational innovation which facilitates the infrastructure of the future networked system of supply–demand relationship.","2398-7294","","10.1108/IJCS-01-2017-0001","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9819806","E-commerce;Cyber physics social system;Multi-agent;Supply-demand relationship","Technological innovation;Intelligent networks;Biological system modeling;Scalability;Prototypes;Collective intelligence;Robustness","","9","","6","","7 Jul 2022","","","TUP","TUP Journals"
"A Review on Air-Ground Coordination in Mobile Edge Computing: Key Technologies, Applications and Future Directions","S. Li; G. Liu; L. Li; Z. Zhang; W. Fei; H. Xiang","School of Art, Nanjing University of Information Science and Technology, Nanjing, China; School of Software, Nanjing University of Information Science and Technology, Nanjing, China; College of Computer Science and Technology, China University of Petroleum (East China), Qingdao, China; College of Computer Science and Technology, China University of Petroleum (East China), Qingdao, China; School of Math and Applied Mathematics, Nanjing University of Information Science and Technology, Nanjing, China; School of Software, Nanjing University of Information Science and Technology, Nanjing, China",Tsinghua Science and Technology,"30 Dec 2024","2025","30","3","1359","1386","In recent years, Mobile Edge Computing (MEC) has received extensive research attention due to its characteristics, such as real-time data processing and flexible application deployment. However, traditional MEC server deployment relies on the terrestrial Base Stations (BSs), resulting in high deployment costs and limited coverage range. In response to these challenges, air-ground coordination has emerged, which effectively combines the advantages of edge computing and Unmanned Aerial Vehicles (UAVs), providing an effective architecture for edge intelligence. By utilizing the flexibility of UAVs and empowering them into edge nodes with computing resources, the coverage range of MEC can be expanded, thereby reducing the reliance of edge devices on terrestrial BSs. Furthermore, leveraging terrestrial BSs as supplements to the computing power compensates for relatively limited computational capabilities of UAVs. Although extensive studies have been conducted on air-ground coordination, there are few related summaries of application technologies and prospects. Thus, the key technologies of air-ground coordination and applications are comprehensively reviewed in this paper. Finally, to provide guidance for interested researchers, the development trends and potential applications of air-ground coordination are explored.","1007-0214","","10.26599/TST.2024.9010142","National Natural Science Foundation of China(grant numbers:62372242,92267104); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10817761","air-ground coordination;air-ground control;air-ground perception;emergency management;resource management","Multi-access edge computing;Reviews;Market research;Real-time systems;Air to ground communication;Servers;Resource management;Vehicle dynamics;Research and development;Optimization","","4","","144","","30 Dec 2024","","","TUP","TUP Journals"
"Hybrid Physics-LSTM Framework for Wind Power Prediction and Control in Virtual Microgrid Simulations","S. L. Flórez; G. Hernández González; J. Prieto; F. de la Prieta","BISITE Digital Innovation Hub, Edificio Multiusos I+D+i, University of Salamanca, Salamanca, Spain; BISITE Digital Innovation Hub, Edificio Multiusos I+D+i, University of Salamanca, Salamanca, Spain; BISITE Digital Innovation Hub, Edificio Multiusos I+D+i, University of Salamanca, Salamanca, Spain; BISITE Digital Innovation Hub, Edificio Multiusos I+D+i, University of Salamanca, Salamanca, Spain",IEEE Access,"17 Jul 2025","2025","13","","122175","122186","Three-dimensional physical systems play a pivotal role in the development of cyber-physical infrastructures, particularly in the implementation of digital twins that enable the evaluation of hypothetical and adverse scenarios through high-fidelity simulation. This work presents a real-time 3D monitoring and feedback system designed for a custom transverse-axis wind turbine, integrating physical modeling principles with simulation engines developed initially for game environments. This hybrid architecture facilitates the virtual prototyping, testing, and validation of wind energy systems under near-operational conditions. The proposed framework combines two key components: 1) a physics-based model grounded in the mechanical and electromagnetic dynamics of wind turbine operation, and 2) a data-driven architecture composed of multiple layers. The physical layer interfaces directly with the sensors and actuators of the turbine, ensuring real-time synchronization between the physical and virtual systems. Data acquisition and communication are managed through the MQTT protocol, enabling low-latency streaming and robust interoperability. A long short-term memory neural network is integrated into the architecture to enhance predictive capabilities and trained to forecast wind energy production. An intelligent battery management system subsequently utilizes the output of the model to optimize charging strategies.","2169-3536","","10.1109/ACCESS.2025.3586798","IoTalentum Project within the Framework of Marie Skłodowska-Curie Actions Innovative Training Networks (ITN)-European Training Networks (ETN); European Union Horizon 2020 Research and Innovation Program(grant numbers:953442); International Chair Project on Trustworthy Artificial Intelligence and Demographic Challenge within the National Strategy for Artificial Intelligence (ENIA), in the framework of the European Recovery, Transformation, and Resilience Plan(grant numbers:TSI-100933-2023-0001); Secretary of State for Digitalization and Artificial Intelligence and by the European Union (Next Generation); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11072391","Wind turbine simulation;unity engine;LSTM;real-time monitoring;physics-informed models;MQTT protocol;battery energy storage system;energy forecasting;smart grid optimization","Adaptation models;Digital twins;Real-time systems;Predictive models;Wind turbines;Forecasting;Long short term memory;Load modeling;Microgrids;Data models","","1","","33","CCBY","7 Jul 2025","","","IEEE","IEEE Journals"
"CaRaFFusion: Improving 2D Semantic Segmentation With Camera-Radar Point Cloud Fusion and Zero-Shot Image Inpainting","H. Sun; B. K. Sahin; G. Stettinger; M. Bernhard; M. Schubert; R. Wille","Technical University of Munich, Munich, Germany; Infineon Technologies AG, Neubiberg, Germany; Infineon Technologies AG, Neubiberg, Germany; Ludwig Maximilian University of Munich, Munich, Germany; Ludwig Maximilian University of Munich, Munich, Germany; Technical University of Munich, Munich, Germany",IEEE Robotics and Automation Letters,"2 Jun 2025","2025","10","7","7007","7014","Segmenting objects in an environment is a crucial task for autonomous driving and robotics, as it enables a better understanding of the surroundings of each agent. Although camera sensors provide rich visual details, they are vulnerable to adverse weather conditions. In contrast, radar sensors remain robust under such conditions, but often produce sparse and noisy data. Therefore, a promising approach is to fuse information from both sensors. In this work, we propose a novel framework to enhance camera-only baselines by integrating a diffusion model into a camera-radar fusion architecture. We leverage radar point features to create pseudo-masks using the Segment-Anything model, treating the projected radar points as point prompts. Additionally, we propose a noise reduction unit to denoise these pseudo-masks, which are further used to generate inpainted images that complete the missing information in the original images. Our method improves the camera-only segmentation baseline by 2.63% in mIoU and enhances our camera-radar fusion architecture by 1.48% in mIoU on the Waterscenes dataset. This demonstrates the effectiveness of our approach for semantic segmentation using camera-radar fusion under adverse weather conditions.","2377-3766","","10.1109/LRA.2025.3572418","EU ECSEL Joint Undertaking(grant numbers:101007326); National Funding Authorities the German Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11008814","Deep Learning for visual perception;sensor fusion;deep learning methods;computer vision for transportation","Radar;Radar imaging;Image segmentation;Feature extraction;Point cloud compression;Semantic segmentation;Cameras;Noise;Noise reduction;Meteorology","","","","45","CCBY","21 May 2025","","","IEEE","IEEE Journals"
"Intelligent Role-Based Access Control Model and Framework Using Semantic Business Roles in Multi-Domain Environments","R. Ghazal; A. K. Malik; N. Qadeer; B. Raza; A. R. Shahid; H. Alquhayz","Department of Computer Science, COMSATS University Islamabad (CUI), Islamabad, Pakistan; Department of Computer Science, COMSATS University Islamabad (CUI), Islamabad, Pakistan; Department of Computer Science, Federal Urdu University of Arts, Science, and Technology at Islamabad, Islamabad, Pakistan; Department of Computer Science, COMSATS University Islamabad (CUI), Islamabad, Pakistan; Department of Computer Science, COMSATS University Islamabad (CUI), Islamabad, Pakistan; Department of Computer Science and Information, College of Science Al-Zulfi, Majmaah University, Al Majma’ah, Saudi Arabia",IEEE Access,"22 Jan 2020","2020","8","","12253","12267","Today's rapidly developing communication technologies and dynamic collaborative business models made the security of data and resources more crucial than ever especially in multi-domain environments like Cloud and Cyber-Physical Systems (CPS). It enforced the research community to develop enhanced access control techniques and models for resources across multi-domain distributed environments so that the security requirements of all participating organizations can be fulfilled through considering dynamicity of changing environments and versatility of access control policies. The popularity of Role-Based Access Control (RBAC) model is irrefutable because of low administrative overhead and large-scale implementation in business organizations. However, it does not incorporate the dynamically changing policies and lacks semantically meaningful business roles which could have a diverse impact upon access decisions in multi-domain business environments. This paper describes our proposed novel access control framework that uses semantic business roles and intelligent agents through implementation of our Intelligent RBAC (I-RBAC) model. It encompasses occupational entitlements as roles for multiple domains. We use the dataset of original occupational roles provided by Standard Occupational Classification (SOC), USA. The novelty of the paper lies in developing a core I-RBAC ontology using real-world semantic business roles and intelligent agent technologies together for achieving required level of access control in highly dynamic multi-domain environment. The intelligent agents use WordNet and bidirectional LSTM deep neural network for automated population of organizational ontology from unstructured text policies. This dynamically learned organizational ontology is further matched with our core I-RBAC ontology in order to extract unified semantic business roles. The proposed I-RBAC model is mathematically described and the overall I-RBAC framework and its implementation architecture is explained. At the end, the I-RBAC model is validated through the implementation results that show a linear runtime trend of the model in presence of a large number of permission assignments and multiple queries.","2169-3536","","10.1109/ACCESS.2020.2965333","Majmaah University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8954638","Access control;multi-domain distributed environment;secure collaboration;ontology;multi agent system;LSTM","Access control;Task analysis;Ontologies;Collaboration;Semantics","","33","","54","CCBY","9 Jan 2020","","","IEEE","IEEE Journals"
"Theory and Method of Time-varying Computational Experiments for the Fully Mechanized Mining Process in an Artificial System Environment","Z. Feng; S. Zhu; J. Wu; H. Guo","School of Information Engineering, Yulin University, Yulin, China; School of Energy Engineering, Yulin University, Yulin, China; School of Information Engineering, Yulin University, Yulin, China; School of Information Engineering, Yulin University, Yulin, China",IEEE Access,"27 Nov 2019","2019","7","","168162","168174","As mining depth gradually increases, the complex and changeable behavior state of mine production systems leads to the increasingly prominent problem of “planning is difficult to control”. The safety production situation and the difficulty of emergency management are gradually upgraded. However, the theoretical study on the behavioral trend of complex mine production systems is still an immature field. This paper proposes the scientific problem of “theory and method of time-varying computational experiments for fully mechanized mining processes in artificial system environments”. Taking the typical fully mechanized mining process in the Yushen mining area in northern Shaanxi, China, as the research object, through computer modeling, simulation and use of multiagent system theory, APSM (Agent Publish-Subscribe Model) coordination technology, multiagent cross-emergence and multilayer learning networks, the artificial fully mechanized mining system modeling, sequential mining process deduction and state transfer theory are systematically studied. First, an artificial system model equivalent to the function of the actual fully mechanized mining system is constructed. Then, under the artificial system environment, the time-varying computational experiments of the fully mechanized mining process are realized through the autonomous deduction of the fully mechanized mining agent based on a multilayer neural network and the emergence of multiagent interactions based on subscription perception; this approach aims to solve the problem of determining the overall behavior trend of the mine under the condition of “long time and large space” and to provide intellectual support and scientific basis for the “first experiment and then produce” technological model of intelligent mining.","2169-3536","","10.1109/ACCESS.2019.2954591","National Natural Science Foundation of China(grant numbers:51864046); The theory and method of time-varying computational experiments for the mining process in the Yushen mining area; Education Department of Shaanxi Province(grant numbers:16JK1896); Research on parallel control theory and method of mine safety production under Internet of Things; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8907780","Mine;fully mechanized mining process;artificial system;time-varying computational experiments","Market research;Time-varying systems;Production systems;Data mining;Computational modeling;Safety","","3","","46","CCBY","20 Nov 2019","","","IEEE","IEEE Journals"
"EcoptiAI: E-Commerce Process Optimization and Operational Cost Minimization Through Task Automation Using Agentic AI","O. -R. Alecsoiu; N. Faruqui; A. A. Panagoret; C. A. Ionuţ; D. M. Panagoret; R. -V. Nitu; M. A. Mutu","Faculty of Educational Sciences, Law and Public Administration, “Constantin Brâncuşi” University of Târgu Jiu, Târgu Jiu, Romania; Department of Software Engineering, Daffodil International University, Birulia, Dhaka, Bangladesh; Faculty of Science and Engineering of Alexandria, Valahia University of Târgovişte, Târgovişte, Romania; Faculty of Economic Sciences, “Constantin Brâncuşi” University of Târgu Jiu, Târgu Jiu, Romania; Faculty of Economic Sciences, “Constantin Brâncuşi” University of Târgu Jiu, Târgu Jiu, Romania; Faculty of Economic Sciences, “Constantin Brâncuşi” University of Târgu Jiu, Târgu Jiu, Romania; Faculty of Economic Sciences, “Constantin Brâncuşi” University of Târgu Jiu, Târgu Jiu, Romania",IEEE Access,"28 Apr 2025","2025","13","","70254","70268","The rapid expansion of e-commerce has increased the complexity of operational processes, making it challenging to manage tasks such as product cataloging, customer responses, delivery updates, and feedback collection efficiently. These challenges often result in elevated operational costs and decreased customer satisfaction. This paper introduces EcoptiAI, an agentic AI-powered framework leveraging a transformer-based model as an intelligent agent to automate essential e-commerce processes. EcoptiAI minimizes manual effort, streamlines workflows, and optimizes procedural costs by handling tasks such as product description generation, catalog updates, personalized customer communication, and empathetic delivery status updates. The system employs an empathetic tone for delay notifications, distinguishing itself from standard cold responses, and automates customer feedback analysis, ensuring an enhanced customer experience. The transformer model underlying EcoptiAI has been trained using a uniquely structured dataset created from diverse e-commerce-related sources, including product catalogs, customer reviews, and operational logs. The experimental analysis demonstrates that EcoptiAI reduces procedural costs by 52.7% on average and achieves high-performance metrics, with an accuracy of 92.42%, precision of 92.44%, recall of 92.40%, and an F1-score of 92.41%. The findings indicate the transformative potential of agentic AI in driving cost-effective, automated e-commerce operations while enhancing customer satisfaction. This paper provides a comprehensive evaluation of EcoptiAI’s design, implementation, and impact, paving the way for scalable and intelligent e-commerce automation solutions.","2169-3536","","10.1109/ACCESS.2025.3560549","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10964222","Agentic AI;e-commerce automation;transformer-based model;customer experience optimization;operational cost reduction","Electronic commerce;Artificial intelligence;Automation;Transformers;Costs;Reviews;Delays;Customer satisfaction;Pipelines;Optimization","","2","","43","CCBY","14 Apr 2025","","","IEEE","IEEE Journals"
"A Comprehensive Review on Big Data for Industries: Challenges and Opportunities","S. Sarker; M. S. Arefin; M. Kowsher; T. Bhuiyan; P. K. Dhar; O. -J. Kwon","Department of Computer Science, University of Memphis, Memphis, TN, USA; Department of Computer Science and Engineering, Chittagong University of Engineering and Technology, Chattogram, Bangladesh; Department of Computer Science, Stevens Institute of Technology, Hoboken, NJ, USA; Department of Computer Science and Engineering, Daffodil International University, Dhaka, Bangladesh; Department of Computer Science and Engineering, Chittagong University of Engineering and Technology, Chattogram, Bangladesh; Department of Electrical Engineering, Sejong University, Gwangjin, Seoul, South Korea",IEEE Access,"6 Jan 2023","2023","11","","744","769","Technological advancements in large industries like power, minerals, and manufacturing are generating massive data every second. Big data techniques have opened up numerous opportunities to utilize massive datasets in several effective ways to improve the efficacy of related industries. This paper presents a review of big data technologies used in the power, mineral, and manufacturing industries for various purposes. We analyze the meta-data of the collected papers before reviewing and selecting papers by applying selection criteria and paper quality assessment strategy. Then we propose a taxonomy of big data application areas in the power, mineral, and manufacturing industries. We have studied current big data architectures and techniques implemented in industry sectors and have uncovered the big data research gaps in industry sectors. To address the gaps, we point out some relevant research questions and, to answer the questions, we make some future research recommendations that might explore interesting research ideas for building a big data-driven industry. As the careful use of big data benefits every other industry sector; hence, supportive big data frameworks need to be developed to speed up the big data analysis process. Proper multi-dimensional big data assessment is also needed to take into account for serving effective data analysis tasks. Industry automation is also heavily influenced by the proper utilization of big data. While an intelligent agent can make many processes and heavy production loads in the manufacturing industry, it can work in a risky environment such as mines efficiently. To train agents for working in a specific environment big data can be used.","2169-3536","","10.1109/ACCESS.2022.3232526","Institute for Information and Communications Technology Promotion (IITP) Grant by the Korea Government (MSIT) (Development of JPEG Systems Standard for Snack Culture Contents)(grant numbers:2020-0-00347); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9999445","Big data for industry;smart grid;power system;oil and gas industry;minerals;big data technology;manufacturing industry;big-data-driven industry","Big Data;Gas industry;Minerals;Petroleum industry;Manufacturing industries;Quality assessment;Drilling;Smart grids;Power systems","","27","","136","CCBY","26 Dec 2022","","","IEEE","IEEE Journals"
"EDB-Net: Efficient Dual-Branch Convolutional Transformer Network for Hyperspectral Image Classification","H. Guo; W. Liu","State Key Laboratory of Dynamic Measurement Technology, School of Instrument and Electronics, North University of China, Taiyuan, China; State Key Laboratory of Dynamic Measurement Technology, School of Instrument and Electronics, North University of China, Taiyuan, China",IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,"23 May 2025","2025","18","","12485","12500","Hyperspectral image (HSI) classification, as a pivotal technology in remote sensing data processing, has garnered significant attention in recent years. Deep learning (DL) has been widely adopted for HSI classification due to its superior feature extraction capabilities. Nevertheless, the deployment of most existing DL models on resource-constrained devices remains challenging because of their intricate architectures and high computational demands. To tackle this challenge, we propose a lightweight dual-branch convolutional transformer network with efficient attention-aware mechanism (EDB-Net), which aims to balance model complexity, classification accuracy, and inference speed. EDB-Net achieves this by conducting an in-depth analysis and modeling of spatial-spectral features through two independent pipelines: one based on convolutional neural networks and the other on Transformer, thereby leveraging the complementary strengths of both approaches. Specifically, we introduce a novel lightweight spatial-spectral Transformer that incorporates a lightweight multi-head efficient attention-aware mechanism. This design ingeniously mitigates the quadratic growth of computational complexity associated with the standard self-attention mechanism's softmax calculation via the agent tokens approach. In addition, by correlating the self-attention map with the query vector, our model accurately extracts useful information to generate an attention gate that highlights key elements of the spectral sequence. Furthermore, the gated recurrent unit is incorporated into the algorithm to enhance the learning and analytical capabilities for spectral sequence data. Experimental results demonstrate that EDB-Net maintains high classification accuracy while significantly reducing computational complexity, outperforming existing state-of-the-art methods.","2151-1535","","10.1109/JSTARS.2025.3567485","Science and Technology Research Project of Henan Province(grant numbers:252102241019); Key Scientific Research Projects of Colleges and Universities of Henan Province(grant numbers:25B510005); Higher Education Teaching Reform Research and Practice Projects of Henan Province(grant numbers:2024SJGLX0951); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10989234","Convolutional neural networks (CNNS);hyperspectral image (HSI);self-attention mechanism;transformer","Transformers;Feature extraction;Accuracy;Computer architecture;Computational complexity;Computational modeling;Classification algorithms;Attention mechanisms;Hyperspectral imaging;Heuristic algorithms","","2","","58","CCBY","6 May 2025","","","IEEE","IEEE Journals"
"Multimodal Graph-based Stacked Transformer Network for Brain Tumor Classification, Segmentation and Report Generation","R. Kapoor; S. Shridevi; N. Damodaran","School of Computer Science and Engineering, Vellore Institute of Technology, Vandalur Kelambakkam Road, Chennai, India; School of Computer Science and Engineering, Deputy Director, Centre for Neuroinformatics, Vellore Institute of Technology, Vandalur Kelambakkam Road, Chennai, India; Senior Consultant Neurosurgeon, Gleneagles Hospitals, Chennai, India",IEEE Access,"","2025","PP","99","1","1","Conventional artificial intelligence driven healthcare diagnostics tend to process medical images and clinical text in isolation, losing possible synergistic insights that emerge from their integration. This work presents a novel Multimodal Graph-Based Stacked Transformer Network (MM-GSTN) that combines both modalities of text and vision to create interpretable diagnostic reports. The MM-GSTN combines heterogeneous data through vision transformers and language models with a clinical knowledge graph to encode relationships among patient data, diseases, and symptoms. The proposed architecture, MM-GSTN, is powered by Meta’s Segment Anything Analysis (SAM) for accurate brain mapping, along with the EfficientNet-B0 model, which is combined with a multistacked transformer network, resulting in a classification accuracy of 99%. The system further produces a comprehensive diagnostic report from the finetuned Llama-3.2-11B Vision-Instruct language model utilizing Low-Rank Adaptation (LoRA) training technique, resulting in improved Rouge-1 and Rouge-L scores from 0.005 to 0.072 and BLEU score from 0.036 to 0.068. Integrating a graph network into the overall system maps the relationships between patient data, diseases, and symptoms, which significantly enhances the diagnostic accuracy and clinical decision-making. This work highlights the potential of MM-GSTN as a scalable and explainable AI tool for the diagnosis of brain tumors.","2169-3536","","10.1109/ACCESS.2025.3631733","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11240166","Brain Mapping;Deep Learning;Graph Neural Networks;Brain Healthcare Diagnosis;Large Language Model;Multimodal Learning;Transformers","Accuracy;Transformers;Brain modeling;Tumors;Medical diagnostic imaging;Training;Medical services;Data models;Large language models;Image segmentation","","","","","CCBY","11 Nov 2025","","","IEEE","IEEE Early Access Articles"
"Designing RBFNs Structure Using Similarity-Based and Kernel-Based Fuzzy C-Means Clustering Algorithms","I. Czarnowski; J. Jędrzejowicz; P. Jędrzejowicz","Department of Information Systems, Gdynia Maritime University, Gdynia, Poland; Department of Informatics, University of Gdansk, Gdansk, Poland; Department of Information Systems, Gdynia Maritime University, Gdynia, Poland",IEEE Access,"8 Jan 2021","2021","9","","4411","4422","The RBF networks belong to a set of artificial neural network architectures. RBF networks have been successfully applied for solving various data mining tasks including classification, and regression. Successful implementation of the RBF network depends on numerous factors among which, the crucial is its structure. The decision on the network structure has to be taken at the network initialization stage. It requires calculating or inducing the number of centroids, and their respective locations. The above problem is known to be NP-hard, and hence, not easily solvable. The traditional approach for deciding on the number of hidden units is based on applying the k-means algorithm for calculating cluster centroids. Unfortunately, the procedure guarantees neither a satisfactory accuracy nor the required generalization level of the RBF network under development. To alleviate the problem for cluster determination, i.e. number of centroids, we propose the similarity-based algorithm (SCA) for the RBF networks initialization, as well as an alternative method for initializing RBFNs using the kernel-based fuzzy clustering algorithm (KFCM-K). In both cases, the number of resulting centroids and their initial locations are provided automatically. The next step involves applying the optimization procedure resulting in the selection of the final centroids' location. The procedure is integrated with the output weights determination. Since the discussed optimization problem is computationally difficult it has been decided to apply the agent-based population learning algorithm (PLA) which belongs to the class of metaheuristics. A comparative study of approaches based on SCA and KFCM-K is included in the paper. Their effectiveness is demonstrated experimentally using artificial and real benchmark datasets. The results of the computational experiment have shown that both proposed approaches for designing RBFNs perform significantly better than other algorithms used for this task.","2169-3536","","10.1109/ACCESS.2020.3048104","Gdynia Maritime University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9311115","Radial basis function network (RBFN);RBFN initialization;classification;clustering;multi-agent system","Radial basis function networks;Clustering algorithms;Neurons;Sociology;Cost function;Computer architecture;Task analysis","","8","","59","CCBY","30 Dec 2020","","","IEEE","IEEE Journals"
"Early Warning of Nerve Agent Release in Large Indoor Environments Based on Encoder-Decoder Coupling Physics-Informed Neural Network","S. Sun; Y. Peng; A. Wang; Y. Xie; Y. Hu; Z. Hou","National Key Laboratory of Advanced Micro and Nano Manufacture Technology, Shanghai Jiao Tong University, Shanghai, China; National Key Laboratory of Advanced Micro and Nano Manufacture Technology, Shanghai Jiao Tong University, Shanghai, China; Department of Micro/Nano Electronics, School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; National Key Laboratory of Advanced Micro and Nano Manufacture Technology, Shanghai Jiao Tong University, Shanghai, China; Department of Micro/Nano Electronics, School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; National Key Laboratory of Advanced Micro and Nano Manufacture Technology, Shanghai Jiao Tong University, Shanghai, China",IEEE Access,"25 Jul 2025","2025","13","","128231","128248","Accurately perceiving spatial distribution patterns, detecting dynamic evolution characteristics, and issuing early warnings set higher standards for indoor safety and protection efforts. Computational fluid dynamics (CFD) methods provide accurate predictions but struggle with real-time performance, while neural networks offer rapid predictions, though their performance declines with high-dimensional fluid flow. Nerve agents were used in a subway attack in Japan. For counter-terrorism surveillance purposes, the real-time and accurate detection of nerve agents is critical for providing early warnings to the public and coordinating subsequent rescue operations. Therefore, in this work, a new model called Encoder-Decoder Coupling Physics-Informed Neural Network is proposed, which learns from concentration data generated by experimentally validated CFD simulations and the spatio-temporal information to solve high-dimensional partial differential equations and provide predictions of nerve agents distribution that more closely align with objective physical laws. Extensive experiments are conducted, and the results indicate that our model attains the highest performance among all the algorithms proposed in this paper. The difference between the actual and predicted results is small, and the scatter points are distributed around the fitted curves. In addition, it can make predictions with millisecond-level response time to achieve real-time monitoring. We propose a data-physics dual-driven surrogate model for real-time monitoring and early warning of the distribution of nerve agents in indoor environments.","2169-3536","","10.1109/ACCESS.2025.3587245","National Key Research and Development Program of China(grant numbers:2023YFC2604700); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11075685","Nerve agents;CFD;encoder-decoder coupling physics-informed neural network;transformer;early warning","Ventilation;Real-time systems;Transformers;Predictive models;Mathematical models;Boundary conditions;Indoor environment;Data models;Couplings;Computational modeling","","","","58","CCBY","10 Jul 2025","","","IEEE","IEEE Journals"
"PerceptNet-V2X: Perception Network for Vehicle to Everything Scenarios in Autonomous Driving","B. T. Costa; C. Pereira; A. Maykol Pinto","Faculty of Engineering, University of Porto, Porto, Portugal; Faculty of Engineering, University of Porto, Porto, Portugal; Faculty of Engineering, University of Porto, Porto, Portugal",IEEE Access,"29 Oct 2025","2025","13","","182645","182660","Collaborative perception is essential for autonomous vehicles (AVs) to overcome individual sensing limitations in occluded or complex traffic environments. This paper introduces PerceptNet-V2X, a novel intermediate collaboration framework for scalable perception in Vehicle-to-Everything (V2X) settings. At its core is the Full Perspective View (FPV), a new compact 2D representation of 3D point clouds that preserves critical geometric structure while enabling effective multi-agent spatial reasoning. Unlike conventional Bird’s Eye View (BEV) projections, FPV mitigates data sparsity and enhances compatibility with modern 2D detection architectures. The framework integrates the FPV representation with state-of-the-art detectors such as YOLOV12 and RT-DETR, demonstrating flexible and modular deployment. Comprehensive evaluations on the OPV2V and V2X-Real datasets validate FPV’s impact on collaborative perception performance. On the OPV2V synthetic benchmark, PerceptNet-V2X achieves 95.63% AP@0.5 and 94.36% F1@0.5, representing improvements of up to 5.02% AP and 3.15% F1 over traditional BEV representations. On the V2X-Real real-world dataset, the framework delivers 61.55% mAP@0.3, a 16% gain over prior approaches. Overall, this work contributes a scalable, modular and effective collaborative perception solution centered on the FPV representation, advancing the reliability of multi-agent autonomous systems. Code available at: https://github.com/brumocas/PerceptNet_FuseNet_V2X","2169-3536","","10.1109/ACCESS.2025.3624285","European Structural and Investment Funds in Fundo Europeu de Desenvolvimento REgional (FEDER) Component, through the Operational Competitiveness and Internationalization Program, ATLAS Project(grant numbers:014632); roboTics and Artificial intelligence Living labs improving Operations in PV Scenarios (TALOS) Project funded by European Commission under the Horizon Europe Framework(grant numbers:101119744); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11214316","Collaborative perception;autonomous driving;deep learning;information fusion;object detection","Collaboration;Detectors;Three-dimensional displays;Point cloud compression;Computer architecture;Real-time systems;Accuracy;Autonomous vehicles;Robustness;Benchmark testing","","","","38","CCBY","22 Oct 2025","","","IEEE","IEEE Journals"
"Situation Aware Cognitive Assistance in Smart Homes","L. Chen; C. Nugent","School of Computing and Mathematics, University of Ulster, County Antrim, Northern Ireland; School of Computing and Mathematics, University of Ulster, County Antrim, Northern Ireland",Journal of Mobile Multimedia,"8 Jul 2025","2010","6","3","263","280","Smart Homes (SH) have emerged as a realistically viable solution capable of providing technology-driven assistive living for the elderly and disabled. Nevertheless, it still remains a challenge to provide situation-aware cognitive assistance for those in need in their Activity of Daily Living (ADL). This paper introduces a systematic approach to providing situation-aware ADL assistances in a smart home environment. The approach makes use of semantic technologies for sensor data modeling, fusion and management, thus creating machine understandable and processable situational data. It exploits intelligent agents for interpreting and reasoning semantic situational (meta)data to enhance situation-aware decision support for cognitive assistance. We analyze the nature and issues of SH-based healthcare for cognitively deficient inhabitants. We discuss the ways in which semantic technologies enhance situation comprehension. We describe a cognitive agent for realizing high-level cognitive capabilities such as prediction and explanation. We outline the implementation of a prototype assistive system and illustrate the proposed approach through simulated and real-time ADL assistance scenarios in the context of situation aware assistive living.","1550-4654","","JMM/JMM.2010.11074389","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11074389","Ontologies;situation awareness;assistive agent;smart homes;cognitive assistance","Systematics;Prototypes;Systems architecture;Smart homes;Switches;Ontologies;Data models;Cognition;Real-time systems;Semantic technology","","","","28","","8 Jul 2025","","","River Publishers","River Publishers Journals"
"Cloud robotics: Current status and open issues","J. Wan; S. Tang; H. Yan; D. Li; S. Wang; A. V. Vasilakos","School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China; School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China; School of Electrical Engineering, Guangdong Mechanical and Electrical College, Guangzhou, China; School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China; School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China; Department of Computer Science, Electrical and Space Engineering, Luleå University of Technology, Luleå, Sweden",IEEE Access,"20 May 2017","2016","4","","2797","2807","With the development of cloud computing, big data, and other emerging technologies, the integration of cloud technology and multi-robot systems makes it possible to design multi-robot systems with improved energy efficiency, high real-time performance, and low cost. In order to address the potential of clouds in enhancing robotics for industrial systems, this paper describes the basic concepts and development process of cloud robotics and the overall architecture of these systems. Then, the major driving forces behind the development of cloud robotics are carefully analyzed from the point of view of cloud computing, big data, open source resources, robot cooperative learning, and network connectivity. Subsequently, the key issues and challenges in the current cloud robotic systems are proposed, and some possible solutions are also given. Finally, the potential value of cloud robotic systems in different practical applications is discussed.","2169-3536","","10.1109/ACCESS.2016.2574979","National Natural Science Foundation of China(grant numbers:61572220,61262013,51575194); Fundamental Research Funds for the Central Universities(grant numbers:2015ZZ079); Natural Science Foundation of Guangdong Province, China(grant numbers:2015A030313746,2015A030308002,2016A030313734,2016A030313735); National Key Technology Research and Development Program of China(grant numbers:5642015BAF20B01); Science and Technology Planning Project of Guangdong Province, China(grant numbers:2012A090100012,2013B010134010,2014B090921003,2014A050503009); Science and Technology Planning Project of Guangzhou City(grant numbers:201508030007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7482658","cloud computing;big data;open source;cloud robotics;internet of things;Cloud computing;big data;open source;cloud robotics;internet of things","Cloud computing;Big data;Open source code;Service robots;Internet of things;Multi-robot systems;Energy efficiency;Real-time systems","","103","","68","OAPA","1 Jun 2016","","","IEEE","IEEE Journals"
"Review of Service Restoration for Distribution Networks","F. Shen; Q. Wu; Y. Xue","Department of Electrical Engineering, Center for Electric Power and Energy, Technical University of Denmark, Lyngby, Denmark; Department of Electrical Engineering, Center for Electric Power and Energy, Technical University of Denmark, Lyngby, Denmark; State Grid Electric Power Research Institute, Nanjing, China",Journal of Modern Power Systems and Clean Energy,"22 Jan 2020","2020","8","1","1","14","With the rapid deployment of the advanced metering infrastructure (AMI) and distribution automation (DA), self-healing has become a key factor to enhance the resilience of distribution networks. Following a permanent fault occurrence, the distribution network operator (DNO) implements the self-healing scheme to locate and isolate the fault and to restore power supply to out-of-service portions. As an essential component of self-healing, service restoration has attracted considerable attention. This paper mainly reviews the service restoration approaches of distribution networks, which requires communication systems. The service restoration approaches can be classified as centralized, distributed, and hierarchical approaches according to the communication architecture. In these approaches, different techniques are used to obtain service restoration solutions, including heuristic rules, expert systems, metaheuristic algorithms, graph theory, mathematical programming, and multi-agent systems. Moreover, future research areas of service restoration for distribution networks are discussed.","2196-5420","","10.35833/MPCE.2018.000782","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8932654","Distribution networks;fault detection;fault isolation;service restoration;self-healing scheme","Circuit faults;Distribution networks;Fault location;Communication systems;Microgrids;Network topology","","45","","99","","13 Dec 2019","","","SGEPRI","SGEPRI Journals"
"RGB Cameras Failures and Their Effects in Autonomous Driving Applications","A. Ceccarelli; F. Secci","Department of Mathematics and Informatics, University of Florence, Florence, Italy; Department of Mathematics and Informatics, University of Florence, Florence, Italy",IEEE Transactions on Dependable and Secure Computing,"10 Jul 2023","2023","20","4","2731","2745","RGB cameras are one of the most relevant sensors for autonomous driving applications. It is undeniable that failures of vehicle cameras may compromise the autonomous driving task, possibly leading to unsafe behaviors when images that are subsequently processed by the driving system are altered. To support the definition of safe and robust vehicle architectures and intelligent systems, in this paper we define the failure modes of a vehicle camera, together with an analysis of effects and known mitigations. Further, we build a software library for the generation of the corresponding failed images, and we feed them to six object detectors for mono and stereo cameras and to the self-driving agent of an autonomous driving simulator. The resulting misbehaviors with respect to operating with clean images allow a better understanding of failures effects and the related safety risks in image-based applications.","1941-0018","","10.1109/TDSC.2022.3156941","H2020 programme; Marie Sklodowska-Curie(grant numbers:823788 (ADVANCE)); Regione Toscana; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9729634","Autonomous driving;RGB camera;failures;obstacles detection;driving simulation;image-based applications","Cameras;Lenses;Autonomous vehicles;Image sensors;Sensors;Image color analysis;Information filters","","37","","96","CCBY","7 Mar 2022","","","IEEE","IEEE Journals"
"Dispersed Computing Resource Discovery Model and Algorithm for Polymorphic Migration Network Architecture","C. Zhou; L. Zhang; G. Zeng; F. Lin","School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; Transport Planning and Research Institute, Ministry of Transport, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China",Chinese Journal of Electronics,"29 Jun 2023","2023","32","4","821","839","Dynamic resource discovery in a network of dispersed computing resources is an open problem. The establishment and maintenance of resource pool information are critical, which involves both the polymorphic migration of the network and the time and energy costs resulting from node selection and frequent interactions of information between nodes. The resource discovery problem for dispersed computing can be considered a dynamic multi-level decision problem. A bi-level programming model of dispersed computing resource discovery is developed, which is driven by time cost, energy consumption and accuracy of information acquisition. The upper-level model is to design a reasonable network structure of resource discovery, and the lower-level model is to explore an effective discovery mode. Complex network topology features are used for the first time to analyze the polymorphic migration characteristics of resource discovery networks. We propose an integrated calibration method for energy consumption parameters based on two discovery modes (i.e., agent mode and self-directed mode). A symmetric trust region based heuristic algorithm is proposed for solving the system model. The numerical simulation is performed in a dispersed computing network with multiple modes and topological states, which proves the feasibility of the model and the effectiveness of the algorithm.","2075-5597","","10.23919/cje.2022.00.305","National Natural Science Foundation of China(grant numbers:62072031,61971032); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10168800","Dispersed computing;Resource discovery;Polymorphic migration network;Bi-level programming model;Heuristic algorithm","Energy consumption;Costs;Computational modeling;Heuristic algorithms;Complex networks;Programming;Numerical simulation","","","","19","","29 Jun 2023","","","CIE","CIE Journals"
"Semantic Communication Empowered 6G Networks: Techniques, Applications, and Challenges","Y. Wang; H. Han; Y. Feng; J. Zheng; B. Zhang","Academy of Military Science, Beijing, China; Academy of Military Science, Beijing, China; Academy of Military Science, Beijing, China; Academy of Military Science, Beijing, China; Academy of Military Science, Beijing, China",IEEE Access,"18 Feb 2025","2025","13","","28293","28314","With the explosion of intelligent network applications and the prosperity of artificial intelligence (AI) technologies, the sixth generation (6G) wireless networks are not only expected to further improve network capacity, but also anticipated to establish a new architecture of “Intelligent Connectivity of Everything”. Semantic communication (SC) is a promising solution for future 6G networks due to its natural capability of integrating application requirements and information meaning into data transmission processes. In this paper, a comprehensive survey that overviews how SC can be applied for 6G networks and the key technologies of SC is presented. For this purpose, we first provide a detailed overview of the concepts of semantic information (SI) and SC, as well as the classifications of SC. Then, we present the vision of mutual support between SC technologies and 6G networks, as well as the potential benefits using SC for 6G applications. To achieve the benefits of SC, the fundamental theories and four important technologies in SC are thoroughly investigated, which are SC system architecture design, SI extraction, SI transmission, and SC performance evaluation. Then, we introduce open problems and potential research directions pertaining to SC. In a nutshell, this paper provides a holistic review of concepts, applications, fundamentals, key technologies, existing challenges, and open issues of SC tailored to the requirements of 6G networks.","2169-3536","","10.1109/ACCESS.2025.3532797","Project of the National Natural Science Foundation of China(grant numbers:62171454); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10849550","Semantic communication (SC);semantic information (SI);6G networks;artificial intelligence (AI);knowledge graph (KG)","6G mobile communication;Artificial intelligence;Surveys;Symbols;Semantic communication;Performance evaluation;Data mining;Pragmatics;Optical transmitters;Intelligent networks","","3","","132","CCBY","22 Jan 2025","","","IEEE","IEEE Journals"
"Keeping Children Safe Online With Limited Resources: Analyzing What is Seen and Heard","A. Jevremovic; M. Veinovic; M. Cabarkapa; M. Krstic; I. Chorbev; I. Dimitrovski; N. Garcia; N. Pombo; M. Stojmenovic","Department of Computer Science and Electrical Engineering, Singidunum University, Belgrade, Serbia; Department of Computer Science and Electrical Engineering, Singidunum University, Belgrade, Serbia; School of Electrical Engineering, University of Belgrade, Belgrade, Serbia; School of Electrical Engineering, University of Belgrade, Belgrade, Serbia; Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University in Skopje, Skopje, North Macedonia; Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University in Skopje, Skopje, North Macedonia; Department of Computer Science, University of Beira Interior, 6201-001, Portugal; Department of Computer Science, University of Beira Interior, 6201-001, Portugal; Department of Computer Science and Electrical Engineering, Singidunum University, Belgrade, Serbia",IEEE Access,"1 Oct 2021","2021","9","","132723","132732","It is every parent’s wish to protect their children from online pornography, cyber bullying and cyber predators. Several existing approaches analyze a limited amount of information stemming from the interactions of the child with the corresponding online party. Some restrict access to websites based on a blacklist of known forbidden URLs, others attempt to parse and analyze the exchanged multimedia content between the two parties. However, new URLs can be used to circumvent a blacklist, and images, video, and text can individually appear to be safe, but need to be judged jointly. We propose a highly modular framework of analyzing content in its final form at the user interface, or Human Computer Interaction (HCI) layer, as it appears before the child: on the screen and through the speakers. Our approach is to produce Children’s Agents for Secure and Privacy Enhanced Reaction (CASPER), which analyzes screen captures and audio signals in real time in order to make a decision based on all of the information at its disposal, with limited hardware capabilities. We employ a collection of deep learning techniques for image, audio and text processing in order to categorize visual content as pornographic or neutral, and textual content as cyberbullying or neutral. We additionally contribute a custom dataset that offers a wide spectrum of objectionable content for evaluation and training purposes. CASPER demonstrates an average accuracy of 88% and an F1 score of 0.85 when classifying text, and an accuracy of 95% when classifying pornography.","2169-3536","","10.1109/ACCESS.2021.3114389","European Union’s Horizon 2020 Research and Innovation Program through Next Generation Internet (NGI) Trust(grant numbers:825618); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9541357","Cyber-bullying;cyber-grooming;online safety;pornography filter;real time agent","Feature extraction;Streaming media;Visualization;Training;Skin;Real-time systems;Hardware","","19","","43","CCBY","20 Sep 2021","","","IEEE","IEEE Journals"
"A Consensus-Based Current Sharing Algorithm for Energy Storage Systems: An Application to Aeronautic Microgrids","G. Canciello; A. Russo; A. Cavallo","Aeromechs, Aversa, Italy; Dipartimento di Ingegneria, Università degli Studi della Campania “Luigi Vanvitelli,”, Aversa, Italy; Dipartimento di Ingegneria, Università degli Studi della Campania “Luigi Vanvitelli,”, Aversa, Italy",IEEE Access,"13 Nov 2024","2024","12","","164325","164336","More Electric Aircraft (MEA) and All Electric Aircraft (AEA) require advanced autonomous electric Energy Management Systems (EMS) onboard the aircraft. The aircraft electric network can be considered as an islanded microgrid, and as such some approaches typical of the microgrid management can be used onboard the aircraft to design an effective EMS. In particular, distributed control with consensus techniques represents a promising approach due to the advantages in terms of reliability, computational simplicity and low-bandwidth requirement which are of great interest for implementation onboard. A consensus-based solution to the problem of coordinating and balancing several Energy Storage Systems (ESSs) coexisting in a generic aircraft architecture is proposed and analyzed. The proposed algorithm selects the current setpoints for each ESS according to their state of charge while ensuring safety of operations. Theoretical results and detailed simulations show the effectiveness of the proposed approach.","2169-3536","","10.1109/ACCESS.2024.3486916","selection notice issued by the Rector’s decree n. 509 of 13/06/2022 for the funding of fundamental and applied research projects dedicated to young researchers—ACTNOW and by the Italian Ministry of Universities and Research (MUR)(grant numbers:FSE-REACT-EU (Fondo Sociale Europeo-Assistenza alla Ripresa per la Coesione e i Territori d’Europa)); PON (Programma Operativo Nazionale) Ricerca e Innovazione 2014–2020 DM1062/2021; European Union under GA no 101101961 - HECATE; Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or Clean Aviation Joint Undertaking; Neither the European Union nor the granting authority can be held responsible for them; Clean Aviation Joint Undertaking and its Members; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10736608","More electric aircraft;consensus;microgrid control;distributed control","Aircraft;Microgrids;Batteries;Aerospace control;Optimization;Generators;State of charge;Real-time systems;Decentralized control;Communication networks","","1","","34","CCBYNCND","28 Oct 2024","","","IEEE","IEEE Journals"
"Reward for Exploration Based on View Synthesis","S. Taguchi; S. Koide; K. Shibata; H. Deguchi","Toyota Central R&D Labs., Inc., Nagakute, Aichi, Japan; Toyota Central R&D Labs., Inc., Nagakute, Aichi, Japan; Toyota Central R&D Labs., Inc., Nagakute, Aichi, Japan; Toyota Central R&D Labs., Inc., Nagakute, Aichi, Japan",IEEE Access,"31 Oct 2023","2023","11","","118830","118840","Research on embodied-AI has flourished in recent years to make AI accessible to real-world information. Visual exploration is a very fundamental task in embodied-AI applications such as object-goal navigation, embodied questioning and answering (EQA), and rearrangement. However, it is still a challenging task. The frontier-based method is successful but it is difficult to use for reinforcement learning (RL). Moreover, it heavily relies on two-dimensional grid-map representation, therefore difficult to apply free movement in three-dimensional environments. We propose a novel reward for RGB-D camera-based exploration to maximize the amount of new information contained in the observations obtained from the camera. The basic idea of our method is to predict the destination image by view synthesis using a point cloud obtained by back-projecting depth information. The more lacks in this predicted image, the more likely it is to contain unknown information. For efficient exploration, we also propose topological map implementation to prevent the agent from repetitively visiting the same states. Our method achieves a performance of coverage of area, objects and landmarks comparable to that of state-of-the-art visual exploration methods without using two-dimensional grid maps. Furthermore, we implement object-goal navigation through integration of object detection and simple point-goal navigation, and it outperforms the task-specific RL method with the same architecture on the success rate.","2169-3536","","10.1109/ACCESS.2023.3326883","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10292637","Embodied-AI;visual exploration;object-goal navigation;view synthesis","Task analysis;Navigation;Point cloud compression;Visualization;Optimization;Image reconstruction;Robot kinematics","","","","42","CCBYNCND","23 Oct 2023","","","IEEE","IEEE Journals"
"Planning the Future of Smart Cities With Swarms of Fully Autonomous Unmanned Aerial Vehicles Using a Novel Framework","K. Kuru","School of Engineering, University of Central Lancashire, Preston, U.K.",IEEE Access,"12 Jan 2021","2021","9","","6571","6595","The autonomy of unmanned aerial vehicles (UAVs) - self-governing in the aerospace discipline has been a remarkable research area with the development of the advanced bespoke microcontrollers embedded with advanced AI techniques for the last several decades. The road forward about the operational environment is certain about the swarms of fully automated UAVs (FAUAVs), that is, urban areas. FAUAVs with self-learning and self-decision-making abilities by executing non-trivial sequences of events with decimetre-level accuracy based on a set of rules, control loops and constraints using dynamic flight plans and trajectories are taking their indispensable parts within smart cities (SCs). Therefore, their integration with the SC components using real-time data analytics is urgent. This is mainly required to establish a better swarm intelligence along with a safer and optimised harmonious smart ecosystem that enables cooperative FAUAV-SC automation systems with collaborative automated intelligence engaging in the concepts of Internet of Everything (IoE) and Automation of Everything (AoE). Planning the future of cities with swarms of FAUAVs is explored in this paper to optimise the use of FAUAVs with a diverse range of applications and a contemporary methodology is proposed using a holistic framework - FAUAVinSCF equipped with various effective and efficient techniques along with a novel FAUAV routing technique customisable to the constraints of FAUAVs and urban areas. With the methodology, the components of SC and FAUAVs involving recent and impending technological advancements are moulded together to make this inevitable transformation a harmonious part of the inhabitants contributing to the cities' liveability and sustainability. The framework consists of a decentralized agent-based control architecture that monitors and controls the swarms of resource-constraint FAUAVs for their real-time requirements in optimising their urban uses. The outcomes of the methodology suggest that the constraints of FAUAVs can be mitigated significantly in urban areas and consequently, their efficacy can be increased in realising their diverse range of missions.","2169-3536","","10.1109/ACCESS.2020.3049094","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9314128","Autonomous unmanned aerial vehicles (UAVs);smart city;Internet of Things (IoT);Internet-of-Drones (IoD);Internet of Everything (IoE);Automation of Everything (AoE)","Task analysis;Automation;Drones;Particle swarm optimization;Real-time systems;Batteries;Internet of Things","","87","","128","CCBY","5 Jan 2021","","","IEEE","IEEE Journals"
"TWINBOT: Autonomous Underwater Cooperative Transportation","R. Pi; P. Cieślak; P. Ridao; P. J. Sanz","Computer Vision and Robotics Research Institute (VICOROB), Universitat de Girona, Girona, Spain; Computer Vision and Robotics Research Institute (VICOROB), Universitat de Girona, Girona, Spain; Computer Vision and Robotics Research Institute (VICOROB), Universitat de Girona, Girona, Spain; Interactive and Robotic Systems Lab (IRS-Lab), Jaume I University, Castellón de la Plana, Spain",IEEE Access,"9 Mar 2021","2021","9","","37668","37684","Underwater Inspection, Maintenance, and Repair operations are nowadays performed using Remotely Operated Vehicles (ROV) deployed from dynamic-positioning vessels, having high daily operational costs. During the last twenty years, the research community has been making an effort to design new Intervention Autonomous Underwater Vehicles (I-AUV), which could, in the near future, replace the ROVs, significantly decreasing these costs. Until now, the experimental work using I-AUVs has been limited to a few single-vehicle interventions, including object search and recovery, valve turning, and hot stab operations. More complex scenarios usually require the cooperation of multiple agents, i.e., the transportation of large and heavy objects. Moreover, using small, autonomous vehicles requires consideration of their limited load capacity and limited manipulation force/torque capabilities. Following the idea of multi-agent systems, in this paper we propose a possible solution: using a group of cooperating I-AUVs, thus sharing the load and optimizing the stress exerted on the manipulators. Specifically, we tackle the problem of transporting a long pipe. The presented ideas are based on a decentralized Task-Priority kinematic control algorithm adapted for the highly limited communication bandwidth available underwater. The aforementioned pipe is transported following a sequence of poses. A path-following algorithm computes the desired velocities for the robots’ end-effectors, and the on-board controllers ensure tracking of these setpoints, taking into account the geometry of the pipe and the vehicles’ limitations. The utilized algorithms and their practical implementation are discussed in detail and validated through extensive simulations and experimental trials performed in a test tank using two 8 DOF I-AUVs.","2169-3536","","10.1109/ACCESS.2021.3063669","TWINBOT “TWIN ROBOTS FOR COOPERATIVE UNDERWATER INTERVENTION MISSIONS” Project funded by the Spanish Ministry of economy, industry, and competitiveness(grant numbers:DPI2017-86372-C3); Valencian Government (CIRTESU Project)(grant numbers:IDIFEDER/2018/013); Secretaria d’Universitats i Recerca del Departament d’Economia i Coneixement de la Generalitat de Catalunya(grant numbers:2019FI_B_00812); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9367135","Autonomous underwater intervention;cooperative robots;cooperative manipulation;task priority control","Robots;Transportation;Task analysis;Kinematics;Robot kinematics;Robot sensing systems;Valves","","50","","29","CCBY","2 Mar 2021","","","IEEE","IEEE Journals"
"Intent-Based Network Resource Orchestration in Space-Air-Ground Integrated Networks: A Graph Neural Networks and Deep Reinforcement Learning Approach","S. Alam; W. -C. Song","Department of Electronic Engineering, Jeju National University, Jeju-si, Jeju-do, Republic of Korea; Department of Computer Engineering, Jeju National University, Jeju-si, Jeju-do, Republic of Korea",IEEE Access,"13 Dec 2024","2024","12","","185057","185077","The Space-Air-Ground Integrated Network (SAGIN) offers a promising solution for seamless connectivity, high data rates, and wide-area coverage. However, its multi-segment architecture poses significant challenges in efficient resource management and Quality of Service assurance across diverse services. To address these challenges, we propose an Intent-Based Networking (IBN) system that streamlines network automation within the SAGIN ecosystem. Our system model integrates an IBN module with the SAGIN infrastructure, allowing network operators to express their service intents, such as Low-Latency Virtual Network Requests (LLVNRs) and High-Bandwidth Virtual Network Requests (HBVNRs), along with their respective QoS requirements. To tackle the inherent complexity, we employ a Deep Deterministic Policy Gradient (DDPG) based DRL-IBN framework. The DRL agent interacts with the SAGIN environment using a feature matrix extracted via Graph Neural Network (GNN), facilitating informed decision-making for resource allocation based on VNR acceptance. Through extensive simulations and numerical evaluations, we demonstrate the superiority of our proposed DRL-IBN algorithm over baseline approaches, such as LC-VNE and RW-MM-SP, in maximizing system utility, ensuring QoS satisfaction, and enabling efficient resource utilization in the dynamic and heterogeneous SAGIN environment. Our results indicate that the DRL-IBN framework achieves higher VNR acceptance ratios, better resource utilization, and more effective QoS assurance based on minimum QoS violation, proving its effectiveness and robustness in managing the complexities of the SAGIN network.","2169-3536","","10.1109/ACCESS.2024.3507829","Regional Innovation Strategy (RIS) through the National Research Foundation of Korea (NRF); Ministry of Education (MOE)(grant numbers:2023-RIS009); Korea Government (MOE), Jeju New Energy Industry Advancement IHRC(grant numbers:5199990414118); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10770209","Intent based networking;deep reinforcement learning;space air ground integrated network;network orchestration;graph neural network","Quality of service;Resource management;Space-air-ground integrated networks;Satellites;Optimization;Ethics;Delays;Dynamic scheduling;Complexity theory;Autonomous aerial vehicles","","1","","39","CCBY","27 Nov 2024","","","IEEE","IEEE Journals"
"VOICE: Visual Oracle for Interaction, Conversation, and Explanation","D. Jia; A. Irger; L. Besançon; O. Strnad; D. Luo; J. Björklund; A. Kouyoumdjian; A. Ynnerman; I. Viola","Computer, Electrical and Mathematical Science and Engineering (CEMSE) Division, King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia; Computer, Electrical and Mathematical Science and Engineering (CEMSE) Division, King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia; Department of Science and Technology, Linköping University, Linköping, Sweden; Computer, Electrical and Mathematical Science and Engineering (CEMSE) Division, King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia; Computer, Electrical and Mathematical Science and Engineering (CEMSE) Division, King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia; Department of Computing Science, Umeå University, Umeå, Sweden; Computer, Electrical and Mathematical Science and Engineering (CEMSE) Division, King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia; Department of Science and Technology, Linköping University, Linköping, Sweden; Computer, Electrical and Mathematical Science and Engineering (CEMSE) Division, King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia",IEEE Transactions on Visualization and Computer Graphics,"4 Sep 2025","2025","31","10","8828","8845","We present VOICE, a novel approach to science communication that connects large language models’ conversational capabilities with interactive exploratory visualization. VOICE introduces several innovative technical contributions that drive our conversational visualization framework. Based on the collected design requirements, we introduce a two-layer agent architecture that can perform task assignment, instruction extraction, and coherent content generation. We employ fine-tuning and prompt engineering techniques to tailor agents’ performance to their specific roles and accurately respond to user queries. Our interactive text-to-visualization method generates a flythrough sequence matching the content explanation. In addition, natural language interaction provides capabilities to navigate and manipulate 3D models in real-time. The VOICE framework can receive arbitrary voice commands from the user and respond verbally, tightly coupled with a corresponding visual representation, with low latency and high accuracy. We demonstrate the effectiveness of our approach by implementing a proof-of-concept prototype and applying it to the molecular visualization domain: analyzing three 3D molecular models with multiscale and multi-instance attributes. Finally, we conduct a comprehensive evaluation of the system, including quantitative and qualitative analyses on our collected dataset, along with a detailed public user study and expert interviews. The results confirm that our framework and prototype effectively meet the design requirements and cater to the needs of diverse target users.","1941-0506","","10.1109/TVCG.2025.3579956","Knut och Alice Wallenbergs Stiftelse(grant numbers:KAW 2019.0024); King Abdullah University of Science and Technology(grant numbers:BAS/1/1680-01-01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11037292","Conversational visualization;multiscale data;explanatory visualization","Visualization;Data visualization;Oral communication;Biology;Biological system modeling;Three-dimensional displays;Solid modeling;Real-time systems;Prototypes;Interviews","","","","59","CCBY","16 Jun 2025","","","IEEE","IEEE Journals"
"Modeling Method for the Coupling Relations of Microgrid Cyber-Physical Systems Driven by Hybrid Spatiotemporal Events","X. Bo; X. Chen; H. Li; Y. Dong; Z. Qu; L. Wang; Y. Li","School of Electrical Engineering, Northeast Electric Power University, Jilin, China; State Grid Jilin Electric Power Company Ltd., Baishan Power Supply Company, Baishan, China; State Grid Jilin Electric Power Company Ltd., Jilin Power Supply Company, Jilin, China; School of Electrical Engineering, Northeast Electric Power University, Jilin, China; School of Electrical Engineering, Northeast Electric Power University, Jilin, China; School of Electrical Engineering, Northeast Electric Power University, Jilin, China; School of Electrical Engineering, Northeast Electric Power University, Jilin, China",IEEE Access,"3 Feb 2021","2021","9","","19619","19631","The essence of the microgrid cyber-physical system (CPS) lies in the cyclical conversion of information flow and energy flow. Most of the existing coupling models are modeled with static networks and interface structures, in which the closed-loop data flow characteristic is not fully considered. It is difficult for these models to accurately describe spatiotemporal deduction processes, such as microgrid CPS attack identification, risk propagation, safety assessment, defense control, and cascading failure. To address this problem, a modeling method for the coupling relations of microgrid CPS driven by hybrid spatiotemporal events is proposed in the present work. First, according to the topological correlation and coupling logic of the microgrid CPS, the cyclical conversion mechanism of information flow and energy flow is analyzed, and a microgrid CPS architecture with multi-agents as the core is constructed. Next, the spatiotemporal evolution characteristic of the CPS is described by hybrid automata, and the task coordination mechanism of the multi-agent CPS terminal is designed. On this basis, a discrete-continuous correlation and terminal structure characteristic representation method of the CPS based on heterogeneous multi-groups are then proposed. Finally, four spatiotemporal events, namely state perception, network communication, intelligent decision-making, and action control, are defined. Considering the constraints of the temporal conversion of information flow and energy flow, a microgrid CPS coupling model is established, the effectiveness of which is verified by simulating false data injection attack (FDIA) scenarios.","2169-3536","","10.1109/ACCESS.2021.3053402","Key Projects of the National Natural Science Foundation of China(grant numbers:51437003); Jilin Science and Technology Development Plan Project of China(grant numbers:20180201092GX,20200401097GX); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9330507","Microgrid cyber-physical systems;spatiotemporal event-driven;multi-agent;coupling modeling;CPS terminal","Microgrids;Couplings;Spatiotemporal phenomena;Control systems;Analytical models;Data models;Power systems","","7","","37","CCBY","21 Jan 2021","","","IEEE","IEEE Journals"
"Multi-Level Resource Sharing Framework Using Collaborative Fog Environment for Smart Cities","T. Qayyum; Z. Trabelsi; A. W. Malik; K. Hayawi","Department of Computing, School of Electrical Engineering and Computer Science, National University of Sciences and Technology (NUST), Islamabad, Pakistan; College of Information Technology, United Arab Emirates University, Al Ain, United Arab Emirates; Department of Computing, School of Electrical Engineering and Computer Science, National University of Sciences and Technology (NUST), Islamabad, Pakistan; College of Technological Innovation, Zayed University, Abu Dhabi, United Arab Emirates",IEEE Access,"5 Feb 2021","2021","9","","21859","21869","Fog computing has proved its importance over legacy cloud architectures for computation, storage, and communication where edge devices are used to facilitate the delay-sensitive applications. The inception of fog nodes has brought computing intelligence close to the end-devices. Many fog computing frameworks have been proposed where edge devices are used for computation. In this paper, we proposed a simulation framework for fog devices that can use end devices to handle the peak computation load to provide better Quality of Services (QoS). The regional fog nodes are deployed at network edge locations which are used as an intelligent agent to handle the computation requests by either scheduling them on local servers, cloud data centers, or at the under-utilized end-user devices. The proposed device-to-device resource sharing model relies on Ant Colony Optimization (ACO) and Earliest Deadline First(EDF) Algorithm to provide a better quality of service using device available at multi-layer design. The concept of using IoT devices as fog nodes has improved the performance of legacy fog based systems. The proposed work is benchmarked in terms of system cost, efficiency, energy, and quality of service. Further, the proposed framework is with xFogSim in terms of task efficiency.","2169-3536","","10.1109/ACCESS.2021.3054420","United Arab Emirates (UAE) University UAEU Program for Advanced Research (UPAR) Research Grant Program(grant numbers:31T122); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9335598","Fog computing;IoT;resource management;fog simulators;OMNeT++","Task analysis;Performance evaluation;Quality of service;Resource management;Edge computing;Computational modeling;Logic gates","","27","","49","CCBY","25 Jan 2021","","","IEEE","IEEE Journals"
"Neural Network-Based Adaptive Finite-Time Consensus Tracking Control for Multiple Autonomous Underwater Vehicles","J. Cui; L. Zhao; J. Yu; C. Lin; Y. Ma","School of Automation, Qingdao University, Qingdao, China; School of Automation, Qingdao University, Qingdao, China; School of Automation, Qingdao University, Qingdao, China; School of Automation, Qingdao University, Qingdao, China; School of Automation, Qingdao University, Qingdao, China",IEEE Access,"22 Mar 2019","2019","7","","33064","33074","Considering the problem of consensus tracking control for multiple autonomous underwater vehicle (AUV) system, a neural network-based finite-time nonsingular fast terminal sliding mode control method is proposed. First, in order to elaborate on the communication relationship, the algebraic graph theory is combined with a leader–follower architecture. Next, the modified nonsingular fast terminal sliding mode is adopted to improve the fast response characteristic of the system, and distributed control laws are constructed based on the force analysis of each AUV. Furthermore, neural networks technique is employed to approximate the uncertain dynamics and forces caused by the harsh environment of the ocean. Finally, it is proved that the tracking errors can converge to a small neighborhood of the origin by using the proposed algorithm. The effectiveness and robustness of the proposed algorithm are illustrated by a simulation example.","2169-3536","","10.1109/ACCESS.2019.2903833","National Key Research and Development Plan(grant numbers:2017YFB1303503); National Natural Science Foundation of China(grant numbers:61573204,61501276,61603204,61673227); Shandong Province(grant numbers:ZR2018JL020); Taishan Scholar Special Project Fund(grant numbers:TSQN20161026); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8663361","Adaptive neural control;multiple AUV system;nonsingular terminal sliding mode;finite time;graph theory","Graph theory;Topology;Convergence;Force;Neural networks;Interference;Adaptive systems","","35","","45","OAPA","8 Mar 2019","","","IEEE","IEEE Journals"
"Integrated Bidding and Battery Scheduling in a Microgrid for Sealed-Bid Double Auction Power Trading With Peer Microgrids Under Uncertainty and Its Blockchain-Based Implementation","Z. J. B.; S. R.; G. Pathirikkat","Electrical Engineering Department, National Institute of Technology Calicut, Kozhikode, India; Electrical Engineering Department, National Institute of Technology Calicut, Kozhikode, India; Electrical Engineering Department, National Institute of Technology Calicut, Kozhikode, India",IEEE Access,"11 Jul 2025","2025","13","","117953","117970","This paper proposes a novel framework for conducting sealed-bid double auctions in power trading for multi-microgrid networks, addressing the critical challenge of jointly optimizing bidding decisions and battery scheduling under uncertainty in renewable energy generation and load demand. In contrast to existing approaches that treat these components independently, our method explicitly models their interdependency for maximizing trading efficiency. We assume a normal distribution of prediction errors and introduce an uncertainty range and a bid buffer capacity to account for expected variations in forecasted generation and load, enabling more robust coordination between bidding and storage operations. While Q-learning determines the exact bid, the feasible power availability or demand is derived from the uncertainty range, ensuring consistency between learned bidding decisions and forecast-aware constraints. The Q-learning relies solely on its historical bidding outcomes without attempting to predict the bids of other participants. In parallel, battery operations are optimized using a hybrid method that combines Genetic Algorithm (GA) and Simulated Annealing (SA), explicitly incorporating the bid buffer capacity to align scheduling with market commitments. We also propose a fully decentralized and tamper-resistant execution architecture based on a consortium blockchain, where multiple aggregator agents within each microgrid, representing renewable sources, loads, storage systems, and the bid agent, function as independent blockchain nodes. Simulation results on a benchmark microgrid system with Monte-Carlo modeled prediction errors demonstrate that the proposed approach significantly enhances both economic benefits and trading robustness compared to conventional frameworks.","2169-3536","","10.1109/ACCESS.2025.3586465","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11072108","Microgrid network;power trading;strategic bid;battery scheduling;uncertainty;blockchain","Batteries;Microgrids;Uncertainty;Renewable energy sources;Blockchains;Optimal scheduling;Biological system modeling;Q-learning;Genetic algorithms;Schedules","","1","","42","CCBYNCND","7 Jul 2025","","","IEEE","IEEE Journals"
"Translating Image XAI to Multivariate Time Series","L. Tronchin; E. Cordelli; L. R. Celsi; D. Maccagnola; M. Natale; P. Soda; R. Sicilia","Department of Engineering, Unit of Computer Systems and Bioinformatics, University Campus Bio-Medico of Rome, Rome, Italy; Department of Engineering, Unit of Computer Systems and Bioinformatics, University Campus Bio-Medico of Rome, Rome, Italy; ELIS Innovation Hub, Rome, Italy; Advanced Analytics, Assicurazioni Generali Italia, Milan, Italy; Advanced Analytics, Assicurazioni Generali Italia, Milan, Italy; Department of Engineering, Unit of Computer Systems and Bioinformatics, University Campus Bio-Medico of Rome, Rome, Italy; Department of Engineering, Unit of Computer Systems and Bioinformatics, University Campus Bio-Medico of Rome, Rome, Italy",IEEE Access,"27 Feb 2024","2024","12","","27484","27500","As Artificial Intelligence (AI) is becoming part of our daily lives, the need to understand and trust its decisions is becoming a pressing issue. EXplainable AI (XAI) aims at answering this demand, providing tools to get insights into the models’ behaviour and reasoning. Following this trend, our research paper explores the explainability of a deployed multimodal architecture applied to a real-world dataset of multivariate time series. The study aims to enhance the trustworthiness of an AI agent responsible for crash detection in an insurance company’s automatic assistance service. By introducing an XAI layer, we provide insights into the AI agent’s decision-making process, enabling the optimization of emergency medical services allocation. The dataset consists of real-world telematics data collected from vehicles equipped with black box technology. The challenge lies in explaining the complex interactions within the multivariate time series data to accurately understand the forces applied to vehicles during accidents. To this end, we adapt to this context two state-of-the-art XAI model-specific approaches, originally designed for images. We offer a qualitative and a quantitative evaluation, also comparing with a well-known agnostic method, and further validating our findings on an external dataset. The results show that Integrated Gradients, among the methodologies examined, is the most effective approach. Its ability to handle the complexity of the data provides the most comprehensive and insightful explanations for the considered use case. The findings emphasize the potential of XAI to enhance the trustworthiness of AI systems and optimize emergency response in the insurance industry. Code is available at https://github.com/ltronchin/translating-xai-mts.git.","2169-3536","","10.1109/ACCESS.2024.3366994","Piano Nazionale di Ripresa e Resilienza (PNRR) Ministero dell’Universitá e della Ricerca (MUR) Project, Rome Technopole (National Research Programme (NRP) Mission 4 Component 2 Investment 1.5; European Union–NextGenerationEU)(grant numbers:PE0000013-FAIR,ECS 0000024,CUP C83C22000510001); ELIS Innovation Hub within a Joint Research Project with Assicurazioni Generali Italia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10439172","Explainability;evaluation;multivariate time series;car crash detection","Artificial intelligence;Time series analysis;Convolutional neural networks;Explainable AI;Task analysis;Data models;Accidents;Explainable AI","","4","","38","CCBYNCND","19 Feb 2024","","","IEEE","IEEE Journals"
"Multi-Modal Pedestrian Trajectory Prediction for Edge Agents Based on Spatial-Temporal Graph","X. Zou; B. Sun; D. Zhao; Z. Zhu; J. Zhao; Y. He","School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; Suzhou Institute for Advanced Study, University of Science and Technology of China, Suzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China",IEEE Access,"13 May 2020","2020","8","","83321","83332","Edge agents, represented by socially-aware robots and autonomous vehicles, have gradually been integrated into human society. The safety navigation system in interactive scenes is of great importance to them. The key of this system is that the edge agent has the ability to predict the pedestrian trajectory in the dynamic scene, so as to avoid collision. However, predicting pedestrian trajectories in dynamic scenes is not an easy task, because it is necessary to comprehensively consider the spatial-temporal structure of human-environment interaction, visual attention, and the multi-modal behavior of human walking. In this paper, a scalable spatial-temporal graph generation adversarial network architecture (STG-GAN) is introduced, which can comprehensively consider the influence of human-environment interaction and generate a reasonable multi-modal prediction trajectory. First, we use LSTM nodes to flexibly transform the spatial-temporal graph of human-environment interactions into feed-forward differentiable feature coding, and innovatively propose the global node to integrate scene context information. Then, we capture the relative importance of global interactions on pedestrian trajectories through scaled dot product attention, and use recurrent sequence modeling and generative adversarial network architecture for common training, so as to generate reasonable pedestrian future trajectory distributions based on rich mixed features. Experiments on public data sets show that STG-GAN is superior to previous work in terms of accuracy, reasoning speed and rationality of trajectory prediction.","2169-3536","","10.1109/ACCESS.2020.2991435","National Key Research and Development Program of China(grant numbers:2017YFC 0804402); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9082663","Trajectory prediction;spatial-temporal graph;generative adversarial network;global node;scaled dot product attention","Trajectory;Predictive models;Navigation;Adaptation models;Legged locomotion;Prediction algorithms","","19","","49","CCBY","30 Apr 2020","","","IEEE","IEEE Journals"
"Accurate and Efficient LiDAR SLAM by Learning Unified Neural Descriptors","B. Feng; Y. Zhang","Department of Electronics Engineering, College of Information Engineering, Shanghai Maritime University, Shanghai, China; Department of Electronics Engineering, College of Information Engineering, Shanghai Maritime University, Shanghai, China",IEEE Access,"4 Jun 2025","2025","13","","94705","94720","Point clouds generated by LiDAR sensors have been widely exploited in Simultaneous Localization and Mapping (SLAM). However, existing LiDAR SLAM approaches based on hand-crafted features easily suffer from being either overly sparse or dense, causing low-fidelity map construction or severe scalability problems. Recent deep learning-based features under the existing SLAM framework can be poorly affected by error accumulation problems over time. To address these issues, we propose a unified architecture named DeepPointMap++, which enables both memory-efficient map representation and accurate multi-scale localization. We design a deep encoder to extract highly representative unified neural descriptors from the input point clouds and propose a novel deep decoder to find their correspondences. It also incorporates a foreground-background classifier during feature extraction, effectively separating dynamic foreground objects from the static background to boost the final localization and mapping effects. In the experiment, DeepPointMap++ outperformed other state-of-the-art methods on multiple auto-driving benchmarks. We also showcase the versatility of our framework by extending it to more challenging multi-agent collaborative SLAM.","2169-3536","","10.1109/ACCESS.2025.3566472","National Natural Science Foundation of China(grant numbers:61673259); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10982267","LiDAR;map reconstruction;odometer;unified neural descriptors;SLAM","Simultaneous localization and mapping;Feature extraction;Accuracy;Location awareness;Point cloud compression;Laser radar;Robustness;Scalability;Odometry;Vehicle dynamics","","","","52","CCBYNCND","2 May 2025","","","IEEE","IEEE Journals"
"An Open-Source Multi-Robot Framework System for Collaborative Environments Based on ROS2","F. Yumbla; M. Fajardo-Pruna; A. Piguave; D. Ronquillo; R. Ortiz; J. B. Choi; G. Díaz; X. G. Pañeda; H. Moon","Facultad de Ingeniería en Mecánica y Ciencias de la Producción, Escuela Superior Politécnica del Litoral (ESPOL), Campus Gustavo Galindo, Guayaquil, Ecuador; Facultad de Ingeniería en Mecánica y Ciencias de la Producción, Escuela Superior Politécnica del Litoral (ESPOL), Campus Gustavo Galindo, Guayaquil, Ecuador; Facultad de Ingeniería en Mecánica y Ciencias de la Producción, Escuela Superior Politécnica del Litoral (ESPOL), Campus Gustavo Galindo, Guayaquil, Ecuador; Facultad de Ingeniería en Mecánica y Ciencias de la Producción, Escuela Superior Politécnica del Litoral (ESPOL), Campus Gustavo Galindo, Guayaquil, Ecuador; Department of Mechanical Engineering, The State University of New York (SUNY Korea), Incheon, South Korea; Department of Mechanical Engineering, The State University of New York (SUNY Korea), Incheon, South Korea; Electrical, Electronics and Control Engineering Department, Spanish University for Distance Education (UNED), Madrid, Spain; Departamento de Informática, Ingeniería Telemática, Universidad de Oviedo, Oviedo, Spain; Department of Mechanical Engineering, Sungkyunkwan University, Jangan-gu, Suwon-si, Gyeonggi-do, South Korea",IEEE Access,"28 Jan 2025","2025","13","","16288","16302","Despite the rise of robotics and automation in industrial applications, the widespread adoption of collaborative robotics still needs to be improved due to the lack of interoperability between robots and the low adaptability of existing systems. Solving this problem would mean a significant advance in robotics and industrial automation. Under this context, an open-source MultiRobot Framework based on ROS2 was developed in the present research to effectively communicate and coordinate robotics agents and sensors in closed collaborative environments. A simulation-based control and software design was performed using the GAZEBO tool. A centralized architecture was obtained with an autonomous navigation module for the planning and robot routes monitoring, a computer vision module for the location and management of uncertainties, and a task controller module to assign mobilization mission objects. In conclusion, using ROS2 to communicate and coordinate various mechatronic systems effectively results in a robust, flexible, and scalable solution critical to industrial processes.","2169-3536","","10.1109/ACCESS.2025.3530391","Robotics, Automation and Mechatronics Engineering Laboratory (RAMEL), Ecuador; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10843238","Collaborative robotics;interoperability;artificial vision;autonomous navigation;scalability","Robots;Robot kinematics;Robot sensing systems;Sensors;Cameras;Robot vision systems;Navigation;Collaboration;Computer vision;Service robots","","3","","30","CCBY","16 Jan 2025","","","IEEE","IEEE Journals"
"OPTNet: Optimized Pixel-Transformer Model for Adaptive Retinal Fundus Image Enhancement","F. M. Alqahtani; S. Adwan; M. Y. Ahmad; S. B. Karman","Department of Biomedical Engineering, Faculty of Engineering, Universiti Malaya, Kuala Lumpur, Malaysia; Department of Electrical Engineering, Faculty of Engineering, Universiti Malaya, Kuala Lumpur, Malaysia; Department of Biomedical Engineering, Faculty of Engineering, Universiti Malaya, Kuala Lumpur, Malaysia; Department of Biomedical Engineering, Faculty of Engineering, Universiti Malaya, Kuala Lumpur, Malaysia",IEEE Access,"22 Aug 2025","2025","13","","145416","145441","Retinal low-quality images present significant challenges for accurate diagnosis and monitoring of eye diseases by obscuring critical anatomical features and reducing analytical precision. This study introduces OPTNet,1 an optimized pixel-wise transformer model designed to efficiently enhance degraded or low-quality retinal images. The proposed approach consists of three main stages: 1) pre-processing to standardize image dimensions and balance color channels, 2) model development, in which a lightweight ANN-based feature extractor learns retinal structures and generates self-measured quality labels, and 3) pixel-level transformation guided by these predicted labels to perform localized enhancement. The performance of OPTNet was evaluated using statistical metrics across various architectures during training and testing, and benchmarked on six public retinal datasets: DRIVE, CHASE-DB1, HRF, DRHAGIS, FIRE, and FIVES. A comprehensive evaluation was conducted using both full-reference and no-reference quality assessment (QA) metrics, supported by qualitative analysis. OPTNet achieved competitive results including a 21.3% improvement in NIQE and 17.8% reduction in BRISQUE compared with existing methods. The final scores included SSIM (0.1925), VIF (0.1911), BIF (1.3018), EME (11.1704), NIQE (4.0730), and BRISQUE (30.3003), indicating perceptual and structural enhancement. Additionally, it effectively preserved brightness and anatomical fidelity while minimizing distortion (CD = 0.4214), blur (0.0889), and artifacts (0.2903). In conclusion, OPTNet outperforms state-of-the-art enhancement techniques by striking a robust balance between quality improvement and artifact suppression, demonstrating its strong potential for integration into clinical ophthalmic diagnostic pipelines.1The term ""Pixel-Transformer"" in OPTNet does not refer to attention-based Transformer architectures. Rather, it denotes a convolutional module that performs pixel-wise transformations to enhance structural features, particularly in low-contrast retinal regions.","2169-3536","","10.1109/ACCESS.2025.3596045","Prince Sattam Bin Abdulaziz University(grant numbers:PSAU/2025/R/1446); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11113289","Retinal image;low contrast;pixel-transformer;adaptive enhancement;quantitative metrics;visual assessment","Retina;Lighting;Accuracy;Noise reduction;Image color analysis;Filters;Biomedical imaging;Measurement;Image quality;Diabetic retinopathy","","","","81","CCBY","5 Aug 2025","","","IEEE","IEEE Journals"
"Multi-Operator Spectrum and MEC Resource Sharing in Next Generation Cellular Networks","T. Mahboob; S. Tariq Shah; M. Choi; S. -H. Kim; M. Young Chung","Department of Electrical and Computer Engineering, Sungkyunkwan University, Jangan-gu, Suwon-si, Gyeonggi-do, Republic of Korea; School of Computer Science and Engineering, University of Essex, Colchester, U.K.; Department of Electronic Engineering, Kyung Hee University, Yongin, Republic of Korea; Department of Electrical and Computer Engineering, Sungkyunkwan University, Jangan-gu, Suwon-si, Gyeonggi-do, Republic of Korea; Department of Electrical and Computer Engineering, Sungkyunkwan University, Jangan-gu, Suwon-si, Gyeonggi-do, Republic of Korea",IEEE Access,"10 Jul 2024","2024","12","","91634","91648","Next-generation cellular networks offer enhanced-mobile broadband, ultra-reliable low latency, and massive machine-type communications. Conventional technology may not meet these demands due to complexity and dynamicity of the network and diverse traffic requirements. To overcome these limitations, resource sharing among network operators is widely studied. The service performance can be improved by leveraging multi-access edge computing (MEC) technology. A mobile user receiving service from virtual network function at the MEC, may experience performance degradation due to lack of resources. To meet the quality of service requirements of users, this paper proposes a multi-operator spectrum and MEC resource sharing scheme. We introduce a user plane function agent at main cloud of the mobile network operator (MNO) that enables inter-operator communications and manages resource sharing requests. Service continuity is enabled by relocating users’ associated VNFs considering current resources at the edge network. The proposed scheme has been evaluated using simulations and an experimental testbed. The results show that the proposed scheme reduces network delay, improves network throughput, increases spectrum utilization, increases successful VNF placement ratio, reduces the packet drop ratio, reduces load on edge nodes, and increases revenue for the operator, compared to that of the conventional scheme.","2169-3536","","10.1109/ACCESS.2024.3422073","Samsung Research in Samsung Electronics; National Research Foundation of Korea (NRF); Korean Government [Ministry of Science and ICT (MSIT)](grant numbers:NRF-2022R1C1C1010766); National Research Foundation of Korea (NRF) funded by Korean Government (MSIT)(grant numbers:2022R1A4A3033401); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10580890","Mobile network operators (MNOs);multi-access edge computing (MEC);network function virtualization (NFV);spectrum sharing;virtual network function (VNF) placement","Resource management;Quality of service;Computer architecture;Cloud computing;Cellular networks;Throughput;Next generation networking;Multiaccess communication;Network function virtualization;Radio spectrum management","","3","","45","CCBYNCND","2 Jul 2024","","","IEEE","IEEE Journals"
"Monitoring Level of Hypnosis Using Stationary Wavelet Transform and Singular Value Decomposition Entropy With Feedforward Neural Network","M. I. Dutt; W. Saadeh","Department of Electrical Engineering, Lahore University of Management Sciences, Lahore, Pakistan; Engineering and Design Department, Western Washington University, Bellingham, WA, USA",IEEE Transactions on Neural Systems and Rehabilitation Engineering,"11 Apr 2023","2023","31","","1963","1973","Classifying the patient’s depth of anesthesia (LoH) level into a few distinct states may lead to inappropriate drug administration. To tackle the problem, this paper presents a robust and computationally efficient framework that predicts a continuous LoH index scale from 0–100 in addition to the LoH state. This paper proposes a novel approach for accurate LoH estimation based on Stationary Wavelet Transform (SWT) and fractal features. The deep learning model adopts an optimized temporal, fractal, and spectral feature set to identify the patient sedation level irrespective of age and the type of anesthetic agent. This feature set is then fed into a multilayer perceptron network (MLP), a class of feed-forward neural networks. A comparative analysis of regression and classification is made to measure the performance of the chosen features on the neural network architecture. The proposed LoH classifier outperforms the state-of-the-art LoH prediction algorithms with the highest accuracy of 97.1% while utilizing minimized feature set and MLP classifier. Moreover, for the first time, the LoH regressor achieves the highest performance metrics ( $\text{R}^{{{2}}}=0.9$ , MAE = 1.5) as compared to previous work. This study is very helpful for developing highly accurate monitoring for LoH which is important for intraoperative and postoperative patients’ health.","1558-0210","","10.1109/TNSRE.2023.3264797","Engineering and Design Department, Western Washington University; Higher Education Commission (HEC), Pakistan Technology Transfer Support Fund(grant numbers:TTSF-50); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10093766","Level of hypnosis (LoH);multilayer perceptron (MLP);electroencephalogram (EEG);stationary wavelet transform (SWT)","Electroencephalography;Anesthesia;Feature extraction;Monitoring;Indexes;Fractals;Transforms","Humans;Wavelet Analysis;Entropy;Neural Networks, Computer;Algorithms;Hypnosis","12","","52","CCBY","5 Apr 2023","","","IEEE","IEEE Journals"
"A Digital Twin Driven Human-Centric Ecosystem for Industry 5.0","V. Villani; M. Picone; M. Mamei; L. Sabattini","Department of Sciences and Methods for Engineering (DISMI), University of Modena and Reggio Emilia, Reggio Emilia, Italy; Department of Sciences and Methods for Engineering (DISMI), University of Modena and Reggio Emilia, Reggio Emilia, Italy; Department of Sciences and Methods for Engineering (DISMI), University of Modena and Reggio Emilia, Reggio Emilia, Italy; Department of Sciences and Methods for Engineering (DISMI), University of Modena and Reggio Emilia, Reggio Emilia, Italy",IEEE Transactions on Automation Science and Engineering,"8 Apr 2025","2025","22","","11291","11303","Industry 5.0 embodies the vision for the future of factories, emphasizing the importance of sustainable industrialization and the role of industry in society, through the key concept of placing the well-being of workers at the center of the production process. Building upon this vision, we propose a new paradigm to design human-centric industrial applications. To this end, we exploit Digital Twin (DT) technology to build a digital replica for each entity on the shop floor and support and augment interaction among workers and machines. While so far DTs in automation have been proposed for machine digitalization, the core element of the proposed approach is the Operator Digital Twin (ODT). In this scenario, biometrics allows to build a reliable model of those operator’s characteristics that are relevant in working contexts. Biometric traits are measured and processed to detect physical, emotional, and mental conditions, which are used to define the operator’s state. Perspectively, this allows to manage and monitor production and processes in an operator-in-the-loop manner, where not only is the operator aware of the state of the plant, but also any technological agent in the plant acts and reacts according to the operator’s needs and conditions. In this paper, we define the modeling of the envisioned ecosystem, present the designed DT’s blue-print architecture, discuss its implementation in relevant application scenarios, and report an example of implementation in a collaborative robotics scenario.Note to Practitioners—This paper was motivated by the problem of designing human-cyber-physical systems, where production processes are managed by concurrently taking into account operators, machines and plant status. This answers the needs of the novel Industry 5.0 paradigm, which aims to enhance social sustainability of modern factories. To this end, we propose an architecture based on digital twins that allows to develop a digital layer, detached from the physical one, where the plant can be monitored and managed. This allows the creation of a digital ecosystem where machines, operators, and the interactions among them are represented, augmented, and managed. We discuss how the proposed architecture can be applied to three relevant scenarios: remote training and maintenance, line operation and line supervision. Moreover, the implementation in a collaborative robotics scenario is presented, to provide an example of the proposed architecture can be implemented in industrial scenarios.","1558-3783","","10.1109/TASE.2024.3410703","“A Sustainable and Orchestrated Digital Twin Ecosystem for Human-Centric Industry 5.0” funded by University of Modena and Reggio Emilia: Fondo di Ateneo per la Ricerca 2023(grant numbers:0269801-E83D23000480005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10564577","Industry 5.0;digital twins;human-centric automation","Automation;Production;Ecosystems;Digital twins;Fifth Industrial Revolution;Biometrics (access control);Production facilities","","14","","55","CCBYNCND","19 Jun 2024","","","IEEE","IEEE Journals"
"SwinMalle-UNet: A Hybrid U-Net Integrating Swin Transformer and Deformable Fusion Modules for Brachial Plexus Nerve Segmentation in Ultrasound Imaging","Q. Tong; Y. Jiang; L. Wang","School of Computer and Information Engineering, Shanghai Polytechnic University, Shanghai, China; School of Computer and Information Engineering, Shanghai Polytechnic University, Shanghai, China; School of Computer and Information Engineering, Shanghai Polytechnic University, Shanghai, China",IEEE Access,"31 Oct 2025","2025","13","","184464","184477","Precise segmentation of brachial plexus nerves in ultrasound imaging is essential for clinical anesthesia guidance and neurological evaluation. However, achieving precise nerve boundary delineation remains challenging due to the inherently low contrast, speckle noise, and the complex, variable morphology of nerves in ultrasound data. While deep learning models have shown promise, traditional Convolutional Neural Networks (CNNs) are constrained by fixed receptive fields, limiting their adaptability to non-rigid nerve structures. Conversely, Transformer-based models, while excelling at global context modeling, often face challenges with fine-grained detail recovery in data-limited medical scenarios. To address these limitations, we propose SwinMalle-UNet, a novel hybrid segmentation network that innovatively integrates the Swin Transformer with a deformable fusion mechanism within the classic U-Net architecture. The encoder employs a hierarchical Swin Transformer to efficiently capture multi-scale global contextual information. The decoder, our core contribution, features a deformable fusion module that dynamically adjusts feature sampling positions in a data-driven manner. This design facilitates precise pixel-level feature alignment and enhances adaptability to the irregular morphology of brachial plexus nerves. We comprehensively evaluated our model on a core multi-target brachial plexus dataset (UBPD) and a large-scale public benchmark (USNS). Experimental results demonstrate that our approach achieves state-of-the-art performance, outperforming a wide range of baseline and state-of-the-art models such as U-Net, Attention U-Net, DeepLabV3+, TransUNet, an EfficientFormerV2-based model (EFv2-UNet), and a strong Swin-UNet baseline.","2169-3536","","10.1109/ACCESS.2025.3624701","Project “Research and Application of a Digital Intelligent Brain Platform based on Multi-Agent Collaboration” Fund(grant numbers:2024-GZL-RGZN-01011); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11215791","Brachial plexus nerves;deformable convolution;semantic segmentation;SwinMalle-UNet;ultrasound imaging","Transformers;Decoding;Brachytherapy;Image segmentation;Ultrasonic imaging;Feature extraction;Standards;Windows;Adaptation models;Kernel","","","","25","CCBYNCND","23 Oct 2025","","","IEEE","IEEE Journals"
"Redesigning power grid dispatching automation systems by integrating LLMs, KGs, and AI agents","G. Liu; Y. Tang; W. Guo; J. Dang","Xi'an University of Technology, 710049, China and Univers, Santa Clara, CA, 95054, USA; Univers, Santa Clara, CA, 95054, USA; Guangdong Power Grid Co., Ltd. Power Dispatching Control Center, Guangzhou, 510600, China; School of Electrical Engineering, Xi’an University of Technology, 710049, China",CSEE Journal of Power and Energy Systems,"","2025","PP","99","1","12","The rapid integration of high-proportion renewable energy and the escalating complexity of modern power systems have exposed critical limitations in conventional grid dispatching automation systems, particularly in real-time responsiveness, adaptive coordination, and collaborative decision-making. To address these challenges, this paper present a novel next-generation dispatching automation framework that synergistically integrates large language models (LLMs), knowledge graphs (KGs), and AI agent technologies. The proposed system harnesses LLMs for advanced natural language processing and semantic reasoning, employs KGs to construct a structured, multidimensional knowledge representation of grid entities and their interdependencies, and deploys AI agents for autonomous decision-making and dynamic operational optimization. Collectively, these components establish a closed-loop intelligent architecture encompassing “perception-cognition-decision-execution”, enhancing system-wide situational awareness and adaptive control. This study proposed a unified integration methodology for LLMs, KGs, and AI agents in power system dispatching and modularized functional implementations for scalable deployment. Furthermore, it provided comprehensive multi-scenario analyses to verify operational efficacy. The proposed system offers a transformative technical pathway for advancing intelligent dispatching in next-generation power grids by resolving key bottlenecks in data interoperability, decision transparency, and dynamic adaptability.","2096-0042","","10.17775/CSEEJPES.2025.03480","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11230261","Large language models;knowledge graphs;AI agents;dispatching automation systems;graph model","Dispatching;Automation;Artificial intelligence;Power grids;Semantics;Power system dynamics;Power systems;Adaptation models;Real-time systems;Optimization","","","","","","5 Nov 2025","","","CSEE","CSEE Early Access Articles"
"Recurrent 3D attentional networks for end-to-end active object recognition","M. Liu; Y. Shi; L. Zheng; K. Xu; H. Huang; D. Manocha","School of Computer, National University of Defense Technology, Changsha 410073, China; Department of Computer Science and Electrical & Computer Engineering, University of Maryland, College Park, 20742, USA; School of Computer, National University of Defense Technology, Changsha 410073, China; School of Computer, National University of Defense Technology, Changsha 410073, China; School of Computer, National University of Defense Technology, Changsha 410073, China; Visual Computing Research Center, Shenzhen University, Shenzhen 518060, China; Department of Computer Science and Electrical & Computer Engineering, University of Maryland, College Park, 20742, USA",Computational Visual Media,"20 Feb 2025","2019","5","1","91","104","Active vision is inherently attention-driven: an agent actively selects views to attend in order to rapidly perform a vision task while improving its internal representation of the scene being observed. Inspired by the recent success of attention-based models in 2D vision tasks based on single RGB images, we address multi-view depth-based active object recognition using an attention mechanism, by use of an end-to-end recurrent 3D attentional network. The architecture takes advantage of a recurrent neural network to store and update an internal representation. Our model, trained with 3D shape datasets, is able to iteratively attend the best views targeting an object of interest for recognizing it. To realize 3D view selection, we derive a 3D spatial transformer network. It is differentiable, allowing training with backpropagation, and so achieving much faster convergence than the reinforcement learning employed by most existing attention-based models. Experiments show that our method, with only depth input, achieves state-of-the-art next-best-view performance both in terms of time taken and recognition accuracy.","2096-0662","","10.1007/s41095-019-0135-2","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10897549","active object recognition;recurrent neural network;next-best-view;3D attention","Three-dimensional displays;Shape;Object recognition;Solid modeling;Feature extraction;Transformers;Backpropagation;Training;Casting;Recurrent neural networks","","","","","","20 Feb 2025","","","TUP","TUP Journals"
"Critical Roles of Control Engineering in the Development of Intelligent and Connected Vehicles","Y. Fei; P. Shi; Y. Liu; L. Wang","School of Vehicle and Mobility, Tsinghua University, Beijing, China; School of Electrical and Mechanical Engineering, The University of Adelaide, Adelaide, SA, Australia; Department of Architecture and Civil Engineering, Chalmers University of Technology, Gothenburg, SE, Sweden; School of Vehicle and Mobility, Tsinghua University, Beijing, China",Journal of Intelligent and Connected Vehicles,"4 Jul 2024","2024","7","2","79","85","In recent years, advancements in onboard computing hardware and wireless communication technology have remarkably stimulated the development of intelligent and connected vehicles (ICVs). Specifically, some researchers have investigated the issue of employing various advanced control techniques to optimize the performance of autonomous vehicles in practice (Sun et al., 2023; Zhang et al., 2023a, 2023b). Therefore, this article aims to discuss why and how control engineering plays an essential role in the development of ICVs.","2399-9802","","10.26599/JICV.2023.9210040","National Key R&D Program of China; National Natural Science Foundation of China(grant numbers:52221005,52220105001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10586906","","","","8","","22","","4 Jul 2024","","","TUP","TUP Journals"
