DOI,Source title,Abstract,REASON
10.1002/aaai.12128,AI Magazine,"The development of artificial intelligence (AI) agents capable of human-level understanding of video content and conducting conversations with humans on this basis is a promising application that people expect. However, this is a challenging task that requires the holistic integration of multimodal information with temporal dependencies and reasoning, as well as social and physical commonsense. In addition, the development of appropriate systematic evaluation methods is essential. In this context, we introduce the Video Turing Test (VTT), a blind test used to evaluate human-likeness in terms of video comprehension ability. Moreover, we propose Vincent as a video understanding AI. We explain the configuration of VTT, the architecture of Vincent to prepare for VTT and the proposed evaluation methods for video comprehension. We also estimate the current intelligence level of AI based on our results and discuss future research directions. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1002/adhm.202200249,Advanced Healthcare Materials,"The initial contact with blood and its components, including plasma proteins and platelets, directs the body's response to foreign materials. Natural scaffolds of extracellular matrix or fibrin contain fibrils with nanoscale dimensions, but how platelets specifically respond to the topography and architecture of fibrous materials is still incompletely understood. Here, planar and nanofiber scaffolds are fabricated from native fibrinogen to characterize the morphology of adherent platelets and activation markers for phosphatidylserine exposure and α-granule secretion by confocal fluorescence microscopy and scanning electron microscopy. Different fibrinogen topographies equally support the spreading and α-granule secretion of washed platelets. In contrast, preincubation of the scaffolds with plasma diminishes platelet spreading on planar fibrinogen surfaces but not on nanofibers. The data show that the enhanced interactions of platelets with nanofibers result from a higher locally accessible surface area, effectively increasing the ligand density for integrin-mediated responses. Overall, fibrinogen nanofibers direct platelets toward robust adhesion formation and α-granule secretion while minimizing their procoagulant activity. Similar results on fibrinogen-coated polydimethylsiloxane substrates with micrometer-sized 3D features suggest that surface topography could be used more generally to steer blood-materials interactions on different length scales for enhancing the initial wound healing steps. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1002/advs.202309392,Advanced Science,"MXene-based thermal camouflage materials have gained increasing attention due to their low emissivity, however, the poor anti-oxidation restricts their potential applications under complex environments. Various modification methods and strategies, e.g., the addition of antioxidant molecules and fillers have been developed to overcome this, but the realization of long-term, reliable thermal camouflage using MXene network (coating) with excellent comprehensive performance remains a great challenge. Here, a MXene-based hybrid network comodified with hyaluronic acid (HA) and hyperbranched polysiloxane (HSi) molecules is designed and fabricated. Notably, the presence of appreciated HA molecules restricts the oxidation of MXene sheets without altering infrared stealth performance, superior to other water-soluble polymers; while the HSi molecules can act as efficient cross-linking agents to generate strong interactions between MXene sheets and HA molecules. The optimized MXene/HA/HSi composites exhibit excellent mechanical flexibility (folded into crane structure), good water/solvent resistance, and long-term stable thermal camouflage capability (with low infrared emissivity of ≈0.29). The long-term thermal camouflage reliability (≈8 months) under various outdoor weathers and the scalable coating capability of the MXene-coated textile enable them to disguise the IR signal of various targets in complex environments, indicating the great promise of achieved material for thermal camouflage, IR stealth, and counter surveillance. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1002/advs.202406933,Advanced Science,"Myocardial infarction (MI) continues to be a leading cause of death worldwide. The precise quantification of infarcted tissue is crucial to diagnosis, therapeutic management, and post-MI care. Late gadolinium enhancement-cardiac magnetic resonance (LGE-CMR) is regarded as the gold standard for precise infarct tissue localization in MI patients. A fundamental limitation of LGE-CMR is the invasive intravenous introduction of gadolinium-based contrast agents that present potential high-risk toxicity, particularly for individuals with underlying chronic kidney diseases. Herein, a completely non-invasive methodology is developed to identify the location and extent of an infarct region in the left ventricle via a machine learning (ML) model using only cardiac strains as inputs. In this approach, the remarkable performance of a multi-fidelity ML model is demonstrated, which combines rodent-based in-silico-generated training data (low-fidelity) with very limited patient-specific human data (high-fidelity) in predicting LGE ground truth. The results offer a new paradigm for developing feasible prognostic tools by augmenting synthetic simulation-based data with very small amounts of in vivo human data. More broadly, the proposed approach can significantly assist with addressing biomedical challenges in healthcare where human data are limited. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1002/advs.202507952,Advanced Science,"The advent of nanomedicine is profoundly revolutionizing conventional paradigms in cancer therapeutics. Selected formulations encompassing lipid nanoparticles and polymeric nanoparticles have already attained regulatory approval for clinical treatment. Nonetheless, achieving precise spatiotemporal control of exogenous nanomedicine within intricate physiological environments remains a formidable challenge. Drawing inspiration from evolutionarily optimized natural biological architectures, the development of biomembrane-derived nanostructures with unique biological activities provides a new impetus for designing personalized antitumor drugs. Biomembrane-derived constituents, particularly cell membrane, extracellular vesicles, and other bioactive payloads, have inherited their precise targeting, specific tumor killing, and dynamic tumor immunosuppressive microenvironments remodeling properties in antitumor intervention. Here, the diverse biomembrane engineering strategies to equip the biomembrane with plentiful functionalities are highlighted. Moreover, the cutting-edge innovations of mammalian cells/bacteria/plants-derived biomembrane nanostructures and their applications for advancing cancer nanomedicine development are systematically reviewed. Finally, the current challenges and future opportunities are proposed to realize the whole potential of biomembrane nanomedicine toward clinical transformation. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1002/btm2.10383,Bioengineering and Translational Medicine,"Tissue engineering (TE) is currently considered a cutting-edge discipline that offers the potential for developing treatments for health conditions that negatively affect the quality of life. This interdisciplinary field typically involves the combination of cells, scaffolds, and appropriate induction factors for the regeneration and repair of damaged tissue. Cell fate decisions, such as survival, proliferation, or differentiation, critically depend on various biochemical and biophysical factors provided by the extracellular environment during developmental, physiological, and pathological processes. Therefore, understanding the mechanisms of action of these factors is critical to accurately mimic the complex architecture of the extracellular environment of living tissues and improve the efficiency of TE approaches. In this review, we recapitulate the effects that biochemical and biophysical induction factors have on various aspects of cell fate. While the role of biochemical factors, such as growth factors, small molecules, extracellular matrix (ECM) components, and cytokines, has been extensively studied in the context of TE applications, it is only recently that we have begun to understand the effects of biophysical signals such as surface topography, mechanical, and electrical signals. These biophysical cues could provide a more robust set of stimuli to manipulate cell signaling pathways during the formation of the engineered tissue. Furthermore, the simultaneous application of different types of signals appears to elicit synergistic responses that are likely to improve functional outcomes, which could help translate results into successful clinical therapies in the future. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1002/btm2.70013,Bioengineering and Translational Medicine,"Managing delivery of complex multidrug infusions in anesthesia and critical care presents a significant clinical challenge. Current practices relying on manual control of infusion pumps often result in unpredictable drug delivery profiles and dosing errors—key issues highlighted by the United States Food and Drug Administration (FDA). To address these issues, we introduce the SMART (synchronized-pump management algorithms for reliable therapies) framework, a novel approach that leverages low Reynolds number drug transport physics and machine learning to accurately manage multidrug infusions in real-time. SMART is activated based on the Shafer number ((Formula presented.)), a novel non-dimensional number that quantifies the relative magnitude of a drug's therapeutic action timescale to its transport timescale within infusion manifolds. SMART is useful when (Formula presented.), where drug transport becomes the rate limiting step in achieving the desired therapeutic effects. When activated, SMART monitors multidrug concentrations within infusion manifolds and leverages this information to perform end-to-end management of drug delivery using an ensemble of deterministic and deep reinforcement learning (RL) decision networks. Notably, SMART RL networks employ differentially sampled split buffer architecture that accelerates learning and improves performance by seamlessly combining deterministic predictions with RL experience during training. SMART deployed in standalone infusion pumps under simulated clinical conditions outperformed state-of-the-art manual control protocols. This framework has the potential to revolutionize critical care by enhancing accuracy of medication delivery and reducing cognitive workloads. Beyond critical care, the ability to accurately manage multi-liquid delivery via complex manifolds will have important bearings for manufacturing and process control. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1002/cae.20094,Computer Applications in Engineering Education,"This article describes the environment used in the Computer Architecture Department of the Technical University of Madrid (UPM) for managing small laboratory work projects and a specifie application for an Assembly Language Programming Laboratory. The approach is based on a chain of tools that a small team of teachers can use to efficiently manage a course with a large number of students (400 per year). Students use this tool chain to complete their assignments using an MC88110 CPU simulator also developed by the Department. Students use a Delivery Agent tool to send files containing their implementations. These files are stored in one of the Department servers. Every student laboratory assignment is tested by an Automatic Project Evaluator that executes a set of previously designed and configured tests. These tools are used by teachers to manage mass courses thereby avoiding restrictions on students working on the same assignment. This procedure may encourage students to copy others' laboratory work and we have therefore developed a complementary tool to help teachers find ""replicated"" laboratory assignment implementations. This tool is a plagiarism detection assistant that completes the tool-chain functionality. Jointly, these tools have demonstrated over the last decade that important benefits can be gained from the exploitation of a global laboratory work management system. Some of the benefits may be transferable to an area of growing importance that we have not directly explored, i.e. distance learning environments for technical subjects. © 2007 Wiley Periodicals, Inc. © 2008 Elsevier B.V., All rights reserved.",TOPIC
10.1002/cpe.8348,Concurrency and Computation: Practice and Experience,"Cross-resolution person re-identification (CR-ReID) seeks to overcome the challenge of retrieving and matching specific person images across cameras with varying resolutions. Numerous existing studies utilize established CNNs and ViTs to resize captured low-resolution (LR) images and align them with high-resolution (HR) image features or construct common feature spaces to match between images of different resolutions. However, these methods ignore the potential feature connection between the LR and HR images of the same pedestrian identity. Besides, the CNNs or ViTs usually obtain outliers within the attention maps of LR images; this inclination to excessively concentrate on anomalous information may obscure the genuine and anticipated characteristics between images, which makes it challenging to extract meaningful information from the images. In this work, we propose the abnormal feature elimination and reconfiguration Transformer (ARTransformer), a novel network architecture for robust cross-resolution person re-identification tasks. This method uses a resolution feature discriminator to learn resolution-invariant features and output feature matrices of images with different resolutions. It then calculates the potential feature relationships between images of pedestrians with the same identity but different resolutions through a new cross-resolution landmark agent attention (CR-LAA) mechanism. Conclusively, it utilizes output feature matrices to model LR and HR image interactions by mitigating abnormal image features and prioritizing attention on the target person by learning representations from input images of various resolutions. Experimental results show that ARTransformer performs well in matching images with different resolutions, even with unseen resolution, and extensive evaluations on four real-world datasets confirm the excellent results of our approach. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1002/ett.4842,Transactions on Emerging Telecommunications Technologies,"Multimedia content in 5G/6G networks makes safe, confidential, and efficient content delivery difficult. Intelligent systems that adapt to the ever-changing network environment are needed to distribute multimedia content in these networks. Reinforcement learning (RL) can optimize multimedia content distribution based on network congestion, capacity, and user preferences. This study proposes RL-based intelligent multimedia content distribution. RL algorithms learn from the network environment and generate optimum judgments incorporating several aspects of the suggested framework. The framework delivers multimedia material securely and privately with great quality. This study provides an intelligent multimedia content delivery architecture that uses RL approaches to solve 5G/6G content delivery problems. This research presents an RL system optimized with the double DQN algorithm having a reward of 51604.93 in 7000 episodes for efficient video file sharing on intracity buses. The RL agent balances network congestion and bandwidth by leveraging multiple sources such as bus and intersection caches and base stations, improving secure multimedia content delivery in 5G/6G networks and enhancing the passenger experience. The study confirms the system's effectiveness using reward and loss metrics and identifies potential future research directions. Future work could explore additional RL algorithms, scalability for larger networks, complex delivery scenarios, and integration with blockchain and edge computing for improved security and efficiency in multimedia content delivery. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1002/jcc.26984,Journal of Computational Chemistry,"Conformer-RL is an open-source Python package for applying deep reinforcement learning (RL) to the task of generating a diverse set of low-energy conformations for a single molecule. The library features a simple interface to train a deep RL conformer generation model on any covalently bonded molecule or polymer, including most drug-like molecules. Under the hood, it implements state-of-the-art RL algorithms and graph neural network architectures tuned specifically for molecular structures. Conformer-RL is also a platform for researching new algorithms and neural network architectures for conformer generation, as the library contains modular class interfaces for RL environments and agents, allowing users to easily swap components with their own implementations. Additionally, it comes with tools to visualize and save generated conformers for further analysis. Conformer-RL is well-tested and thoroughly documented with tutorials for each of the functionalities mentioned above, and is available on PyPi and Github: https://github.com/ZimmermanGroup/conformer-rl. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1002/rnc.7626,International Journal of Robust and Nonlinear Control,"Reinforcement learning is commonly associated with training of reward-maximizing (or cost-minimizing) agents, in other words, controllers. It can be applied in model-free or model-based fashion, using a priori or online collected system data to train involved parametric architectures. In general, online reinforcement learning does not guarantee closed loop stability unless special measures are taken, for instance, through learning constraints or tailored training rules. Particularly promising are hybrids of reinforcement learning with classical control approaches. In this work, we suggest a method to guarantee practical stability of the system-controller closed loop in a purely online learning setting, in other words, without offline training. Moreover, we assume only partial knowledge of the system model. To achieve the claimed results, we employ techniques of classical adaptive control. The implementation of the overall control scheme is provided explicitly in a digital, sampled setting. That is, the controller receives the state of the system and computes the control action at discrete, specifically, equidistant moments in time. The method is tested in adaptive traction control and cruise control where it proved to significantly reduce the cost. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1002/sim.10068,Statistics in Medicine,"Data sharing barriers present paramount challenges arising from multicenter clinical studies where multiple data sources are stored and managed in a distributed fashion at different local study sites. Merging such data sources into a common data storage for a centralized statistical analysis requires a data use agreement, which is often time-consuming. Data merging may become more burdensome when propensity score modeling is involved in the analysis because combining many confounding variables, and systematic incorporation of this additional modeling in a meta-analysis has not been thoroughly investigated in the literature. Motivated from a multicenter clinical trial of basal insulin treatment for reducing the risk of post-transplantation diabetes mellitus, we propose a new inference framework that avoids the merging of subject-level raw data from multiple sites at a centralized facility but needs only the sharing of summary statistics. Unlike the architecture of federated learning, the proposed collaborative inference does not need a center site to combine local results and thus enjoys maximal protection of data privacy and minimal sensitivity to unbalanced data distributions across data sources. We show theoretically and numerically that the new distributed inference approach has little loss of statistical power compared to the centralized method that requires merging the entire data. We present large-sample properties and algorithms for the proposed method. We illustrate its performance by simulation experiments and the motivating example on the differential average treatment effect of basal insulin to lower risk of diabetes among kidney-transplant patients compared to the standard-of-care. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1002/wnan.1336,Wiley Interdisciplinary Reviews: Nanomedicine and Nanobiotechnology,"As ordered nanoscale architectures, viruses and virus-like particles (VLPs) remain unsurpassed by synthetic strategies to produce uniform and symmetric nanoparticles. Maintaining or mimicking the symmetry of pathogenic viruses, VLPs offer a ready platform for facilitating recognition, uptake, and processing by the immune system. An emerging understanding of how viruses interact with the immune system offers a means of precisely designing nanoparticles for biomedical use, both with respect to the structure of the particle as well as their ability to stimulate the immune system. Here we discuss recent advances by our group toward two parallel and complementary applications of VLPs, derived primarily from plants, bacteriophage, and nonviral sources, in biomedicine: diagnostic imaging and rational vaccine design. First we discuss advances in increasing VLP payloads of gadolinium magnetic resonance imaging (MRI) contrast agent as well as controlling the characteristics of individual gadolinium containing molecules to increase efficacy. In order to better understand the in vivo potential of VLP constructs, we then discuss the interface of protein-cages and the immune system beginning with the nonspecific innate immune system stimulation and continuing into the use of nonpathogenic VLPs as scaffolds for specific antigen presentation and control of the immune response. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1002/wnan.1591,Wiley Interdisciplinary Reviews: Nanomedicine and Nanobiotechnology,"The self-assembly of viral building blocks bears exciting prospects for fabricating new types of bionanoparticles with multivalent protein shells. These enable a spatially controlled immobilization of functionalities at highest surface densities—an increasing demand worldwide for applications from vaccination to tissue engineering, biocatalysis, and sensing. Certain plant viruses hold particular promise because they are sustainably available, biodegradable, nonpathogenic for mammals, and amenable to in vitro self-organization of virus-like particles. This offers great opportunities for their redesign into novel “green” carrier systems by spatial and structural synthetic biology approaches, as worked out here for the robust nanotubular tobacco mosaic virus (TMV) as prime example. Natural TMV of 300 x 18 nm is built from more than 2,100 identical coat proteins (CPs) helically arranged around a 6,395 nucleotides ssRNA. In vitro, TMV-like particles (TLPs) may self-assemble also from modified CPs and RNAs if the latter contain an Origin of Assembly structure, which initiates a bidirectional encapsidation. By way of tailored RNA, the process can be reprogrammed to yield uncommon shapes such as branched nanoobjects. The nonsymmetric mechanism also proceeds on 3'-terminally immobilized RNA and can integrate distinct CP types in blends or serially. Other emerging plant virus-deduced systems include the usually isometric cowpea chlorotic mottle virus (CCMV) with further strikingly altered structures up to “cherrybombs” with protruding nucleic acids. Cartoon strips and pictorial descriptions of major RNA-based strategies induct the reader into a rare field of nanoconstruction that can give rise to utile soft-matter architectures for complex tasks. This article is categorized under: Biology-Inspired Nanomaterials > Protein and Virus-Based Structures Nanotechnology Approaches to Biology > Nanoscale Systems in Biology Biology-Inspired Nanomaterials > Nucleic Acid-Based Structures. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1007/11431053_18,Lecture Notes in Computer Science,"Business models on the basis of digital content require sophisticated descriptions of that content, as well as service-oriented carrier architectures that allow to negotiate and enforce contract and license schemes in heterogeneous digital application environments. We describe Knowledge Content Objects (KCO), that provide expressive semantic descriptions of digital content, based on an ontology of Information Objects, built under the DOLCE, DnS and Plan Ontologies (DDPO). In particular, we discuss how this structure supports business requirements within the context of paid content. Interactions between agents are embedded into digital infrastructures that are implemented on an advanced knowledge content carrier architecture (KCCA) that communicates via a dedicated protocol (KCTP). We show how this architecture allows to integrate existing digital repositories so that the content can be made available to a semantically rich digital environment. © Springer-Verlag Berlin Heidelberg 2005. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1007/3-540-36124-3_47,Lecture Notes in Computer Science,"This paper makes two primary contributions toward establishing support for application-specific factors in middleware security mechanisms. First, it develops a simple classification framework for reasoning about the architecture of the security mechanisms in distributed applications that follow the decision-enforcement paradigm of the reference monitor. It uses the framework to demonstrate that the existing solutions lack satisfying tradeoffs for a wide range of those applications that require application-specific factors to be used in security decisions while mediating access requests. Second, by introducing attribute function in addition to decision and enforcement functions, it proposes a novel scheme for clean separation among suppliers of middleware security, security decision logic, and application-logic, while supporting application-specific protection policies. To illustrate the scheme on a concrete example, we describe its mapping into CORBA Security. © Springer-Verlag Berlin Heidelberg 2002. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1007/3-540-46080-2_74,Lecture Notes in Computer Science,"JCSP is a library of Java packages providing an extended version of the CSP/occam model for Communicating Processes. The current (1.0) release supports concurrency within a single Java Virtual Machine (which may be multi-processor). This paper presents recent work on extended facilities for the dynamic construction of CSP networks across distributed environments (such as the Internet). Details of the underlying network fabric and control (such as machine addresses, socket connections, local multiplexing and de-multiplexing of application channels, acknowledgement packets to preserve synchronisation semantics) are hidden from the JCSP programmer, who works entirely at the application level and CSP primitives. A simple brokerage service - based on channel names - is provided to let distributed JCSP components find and connect to each other. Distributed JCSP networks may securely evolve, as components join and leave at run-time with no centralised or pre-planned control. Higher level brokers, providing user-defined matching services, are easy to bootstrap on top of the basic Channel Name Server (CNS) - using standard JCSP processes and networking. These may impose user-defined control over the structure of network being built. JCSP network channels may be configured for the automatic loading of class files for received objects whose classes are not available locally (this uses the network channel from which they were received - The sender must have them). Also provided are connection channels (for extended bi-directional transactions between clients and servers) and anonymous channels (to set up communications without using any central registry - such as the given CNS). The aims of JCSP.net are to simplify the construction and programming of dynamically distributed and parallel systems. It provides high-level support for CSP architectures, unifying concurrency logic within and between processors. Applications cover all areas of concurrent computing - including e-commerce, agent technology, home networks, embedded systems, high-performance clusters and The Grid. © Springer-Verlag Berlin Heidelberg 2002. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-030-02671-4_4,Lecture Notes in Computer Science,"The growing impact of IoT and Blockchain platforms on business applications has increased interest in leveraging large enterprise systems as Cloud-enabled microservices. However, large and monolithic enterprise systems are unsuitable for flexible integration with such platforms. This paper presents a technique to support the re-engineering of an enterprise system based on the fundamental mechanisms for structuring its architecture, i.e., business objects managed by software functions and their relationships which influence business object interactions via the functions. The technique relies on a heuristic for deriving business object exclusive containment relationships based on analysis of source code and system logs. Furthermore, the paper provides an analysis of distributing enterprise systems based on the business object containment relationships using the NSGA II software clustering and optimization technique. The heuristics and the software clustering and optimization techniques have been validated against two open-source enterprise systems: SugarCRM and ChurchCRM. The experiments demonstrate that the proposed approach can identify microservice designs which support multiple desired microservice characteristics, such as high cohesion, low coupling, high scalability, high availability, and processing efficiency. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-030-25748-4_2,"Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST","5G networks will provide the platform for deploying large number of tenant-associated management, control and end-user applications having different resource requirements at the infrastructure level. In this context, the 5G infrastructure provider must optimize the infrastructure resource utilization and increase its revenue by intelligently admitting network slices that bring the most revenue to the system. In addition, it must ensure that resources can be scaled dynamically for the deployed slices when there is a demand for them from the deployed slices. In this paper, we present a neural networks-driven policy agent for network slice admission that learns the characteristics of the slices deployed by the network tenants from their resource requirements profile and balances the costs and benefits of slice admission against resource management and orchestration costs. The policy agent learns to admit the most profitable slices in the network while ensuring their resource demands can be scaled elastically. We present the system model, the policy agent architecture and results from simulation study showing an increased revenue for infra-structure provider compared to other relevant slice admission strategies. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-030-33246-4_30,Lecture Notes in Computer Science,"A key impediment towards maturing microservice architecture conceptions is the uncertainty about what it means to design fine-grained functionality for microservices. Under a traditional service-oriented architecture (SOA), the unit of functionality for software components concerns individual business domain objects and encapsulated operations, enabling desirable architectural properties such as high cohesion and loose-coupling of its components. However, at present it is not clear how this SOA design strategy should be refined for microservices nor, more generally, how design considerations for different degrees of granularity apply, in a consistent and systematic way, for large SOA systems to smaller microservices. This paper proposes microservice patterns, as a contribution to the maturity of microservice architectures, through the refinement of the functional structure of SOAs. The patterns are derived by considering the splitting of business object (BO) operations and salient types of BO relationships, which influence software structure (as captured in UML): object association, exclusive containment, inclusive containment and specialisation (i.e., subtyping). The viability of the patterns for evolving large SOA systems into microservices is demonstrated through automated microservices discovery algorithms, on two open-source enterprise systems used widely in practice, Dolibarr and SugarCRM. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-030-33246-4_31,Lecture Notes in Computer Science,"Microservices have been introduced to industry as a novel architectural design for software development in cloud-based applications. This development has increased interest in finding new methodologies to migrate existing enterprise systems into microservices to achieve desirable performance characteristics such as high scalability, high availability, high cohesion and low coupling. A key challenge in this context is discovering microserviceable components with promising characteristics from a complex monolithic code base while predicting their resulting characteristics. This paper presents a technique to support such re-engineering of an enterprise system based on the fundamental mechanisms for structuring its architecture, i.e., business objects managed by software functions and their interactions. The technique relies on queuing theory and business object relationship analysis. A prototype for microservice discovery and characteristic analysis was developed using the NSGA II software clustering and optimization technique and has been validated against two open-source enterprise systems, SugarCRM and ChurchCRM. Our experiments demonstrate that the proposed approach can recommend microservice design which improves scalability, availability and execution efficiency of the system while achieving high cohesion and low coupling in software modules. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-030-34356-9_2,Lecture Notes in Computer Science,"In a virtualized computing server (node) with multiple Virtual Machines (VMs), it is necessary to dynamically allocate memory among the VMs. In many cases, this is done only considering the memory demand of each VM without having a node-wide view. There are many solutions for the dynamic memory allocation problem, some of which use machine learning in some form. This paper introduces CAVMem (Continuous-Action Algorithm for Virtualized Memory Management), a proof-of-concept mechanism for a decentralized dynamic memory allocation solution in virtualized nodes that applies a continuous-action reinforcement learning (RL) algorithm called Deep Deterministic Policy Gradient (DDPG). CAVMem with DDPG is compared with other RL algorithms such as Q-Learning (QL) and Deep Q-Learning (DQL) in an environment that models a virtualized node. In order to obtain linear scaling and be able to dynamically add and remove VMs, CAVMem has one agent per VM connected via a lightweight coordination mechanism. The agents learn how much memory to bid for or return, in a given state, so that each VM obtains a fair level of performance subject to the available memory resources. Our results show that CAVMem with DDPG performs better than QL and a static allocation case, but it is competitive with DQL. However, CAVMem incurs significant less training overheads than DQL, making the continuous-action approach a more cost-effective solution. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-030-50371-0_6,Lecture Notes in Computer Science,"Reinforcement learning is a very active field of research with many practical applications. Success in many cases is driven by combining it with Deep Learning. In this paper we present the results of our attempt to use modern advancements in this area for automated management of resources used to host distributed software. We describe the use of an autonomous agent that employs a policy trained with use of Proximal Policy Optimization algorithm. The agent is managing a cloud infrastructure used to process a sample workload. We present the design and architecture of a complete autonomous management system and explain how the management policy was trained. Finally, we compare the performance to the traditional automatic management approach exploited in AWS stack and discuss feasibility to use the presented approach in other scenarios. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-030-51924-7_2,Lecture Notes in Computer Science,"Online social networks are known to lack adequate multi-user privacy support. In this paper we present EXPRI, an agent architecture that aims to assist users in managing multi-user privacy conflicts. By considering the personal utility of sharing content and the individually preferred moral values of each user involved in the conflict, EXPRI identifies the best collaborative solution by applying practical reasoning techniques. Such techniques provide the agent with the cognitive process that is necessary for explainability. Furthermore, the knowledge gathered during the practical reasoning process allows EXPRI to engage in contrastive explanations. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-030-52791-4_17,Communications in Computer and Information Science,"Late gadolinium enhanced (LGE) cardiac magnetic resonance (CMR) imaging is the current gold standard for assessing myocardium viability for patients diagnosed with myocardial infarction, myocarditis or cardiomyopathy. This imaging method enables the identification and quantification of myocardial tissue regions that appear hyper-enhanced. However, the delineation of the myocardium is hampered by the reduced contrast between the myocardium and the left ventricle (LV) blood-pool due to the gadolinium-based contrast agent. The balanced-Steady State Free Precession (bSSFP) cine CMR imaging provides high resolution images with superior contrast between the myocardium and the LV blood-pool. Hence, the registration of the LGE CMR images and the bSSFP cine CMR images is a vital step for accurate localization and quantification of the compromised myocardial tissue. Here, we propose a Spatial Transformer Network (STN) inspired convolutional neural network (CNN) architecture to perform supervised registration of bSSFP cine CMR and LGE CMR images. We evaluate our proposed method on the 2019 Multi-Sequence Cardiac Magnetic Resonance Segmentation Challenge (MS-CMRSeg) dataset and use several evaluation metrics, including the center-to-center LV and right ventricle (RV) blood-pool distance, and the contour-to-contour blood-pool and myocardium distance between the LGE and bSSFP CMR images. Specifically, we showed that our registration method reduced the bSSFP to LGE LV blood-pool center distance from 3.28 mm before registration to 2.27 mm post registration and RV blood-pool center distance from 4.35 mm before registration to 2.52 mm post registration. We also show that the average surface distance (ASD) between bSSFP and LGE is reduced from 2.53 mm to 2.09 mm, 1.78 mm to 1.40 mm and 2.42 mm to 1.73 mm for LV blood-pool, LV myocardium and RV blood-pool, respectively. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-030-58523-5_30,Lecture Notes in Computer Science,"We introduce a learning-based approach for room navigation using semantic maps. Our proposed architecture learns to predict top-down belief maps of regions that lie beyond the agent’s field of view while modeling architectural and stylistic regularities in houses. First, we train a model to generate amodal semantic top-down maps indicating beliefs of location, size, and shape of rooms by learning the underlying architectural patterns in houses. Next, we use these maps to predict a point that lies in the target room and train a policy to navigate to the point. We empirically demonstrate that by predicting semantic maps, the model learns common correlations found in houses and generalizes to novel environments. We also demonstrate that reducing the task of room navigation to point navigation improves the performance further. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-030-58986-8_14,Lecture Notes in Computer Science,"When training a machine learning model, it is standard procedure for the researcher to have full knowledge of both the data and model. However, this engenders a lack of trust between data owners and data scientists. Data owners are justifiably reluctant to relinquish control of private information to third parties. Privacy-preserving techniques distribute computation in order to ensure that data remains in the control of the owner while learning takes place. However, architectures distributed amongst multiple agents introduce an entirely new set of security and trust complications, including data poisoning and model theft. This paper outlines a distributed infrastructure which can be used to facilitate peer-to-peer trust between entities; collaboratively performing a privacy-preserving workflow. Our outlined prototype enables the initialisation of industry gatekeepers and governance bodies as credential issuers under a certain application domain. Before participating in the distributed learning workflow, malicious actors must first negotiate valid credentials from these gatekeepers. We detail a proof of concept using Hyperledger Aries, Decentralised Identifiers (DIDs) and Verifiable Credentials (VCs) to establish a distributed trust architecture during a privacy-preserving machine learning experiment. Specifically, we utilise secure and authenticated DID communication channels in order to facilitate a federated learning workflow related to mental health care data. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-030-59277-6_2,Lecture Notes in Computer Science,"Parental influence plays an important role in the mental development of a child. In the early years of childhood, a parent acts as a role model to a child, so most of the children try to mimic their parents. In our work, we address a complex network model of a child who is influenced by a narcissistic parent from his/her childhood to his/her adolescence. This concept of mimicking in childhood is represented by social contagion. Later on, he/she can learn to develop his/her own personality based on experience and learning. This model can be used to predict the influence of a parent over the personality of a child. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-030-66770-2_22,Communications in Computer and Information Science,"The severe on-chip memory limitations are currently preventing the deployment of the most accurate Deep Neural Network (DNN) models on tiny MicroController Units (MCUs), even if leveraging an effective 8-bit quantization scheme. To tackle this issue, in this paper we present an automated mixed-precision quantization flow based on the HAQ framework but tailored for the memory and computational characteristics of MCU devices. Specifically, a Reinforcement Learning agent searches for the best uniform quantization levels, among 2, 4, 8 bits, of individual weight and activation tensors, under the tight constraints on RAM and FLASH embedded memory sizes. We conduct an experimental analysis on MobileNetV1, MobileNetV2 and MNasNet models for Imagenet classification. Concerning the quantization policy search, the RL agent selects quantization policies that maximize the memory utilization. Given an MCU-class memory bound of 2 MB for weight-only quantization, the compressed models produced by the mixed-precision engine result as accurate as the state-of-the-art solutions quantized with a non-uniform function, which is not tailored for CPUs featuring integer-only arithmetic. This denotes the viability of uniform quantization, required for MCU deployments, for deep weights compression. When also limiting the activation memory budget to 512 kB, the best MobileNetV1 model scores up to 68.4% on Imagenet thanks to the found quantization policy, resulting to be 4% more accurate than the other 8-bit networks fitting the same memory constraints. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-030-66843-3_18,Lecture Notes in Computer Science,"Accurate detection of anatomical landmarks is an essential step in several medical imaging tasks. We propose a novel communicative multi-agent reinforcement learning (C-MARL) system to automatically detect landmarks in 3D medical scans. C-MARL enables the agents to learn explicit communication channels, as well as implicit communication signals by sharing certain weights of the architecture among all the agents. The proposed approach is evaluated on two brain imaging datasets from adult magnetic resonance imaging (MRI) and fetal ultrasound scans. Our experiments show that involving multiple cooperating agents by learning their communication with each other outperforms previous approaches using single agents. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-030-78114-9_21,Lecture Notes in Computer Science,"Six significant new methodological developments of the previously-presented “metastimuli architecture” for human learning through machine learning of spatially correlated structural position within a user’s personal information management system (PIMS), providing the basis for haptic metastimuli, are presented. These include architectural innovation, recurrent (RNN) artificial neural network (ANN) application, a variety of atom embedding techniques (including a novel technique we call “ ∇ ” embedding inspired by linguistics), ANN hyper-parameter (one that affects the network but is not trained, e.g. the learning rate) optimization, and meta-parameter (one that determines the system performance but is not trained and not a hyper-parameter, e.g. the atom embedding technique) optimization for exploring the large design space. A technique for using the system for automatic atom categorization in a user’s PIMS is outlined. ANN training and hyper- and meta-parameter optimization results are presented and discussed in service of methodological recommendations. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-030-82017-6_5,Lecture Notes in Computer Science,"Recently, the Deep Learning (DL) research community has focused on developing efficient and highly performing Neural Networks (NN). Meanwhile, the eXplainable AI (XAI) research community has focused on making Machine Learning (ML) and Deep Learning methods interpretable and transparent, seeking explainability. This work is a preliminary study on the applicability of Neural Architecture Search (NAS) (a sub-field of DL looking for automatic design of NN structures) in XAI. We propose Shallow2Deep, an evolutionary NAS algorithm that exploits local variability to restrain opacity of DL-systems through NN architectures simplification. Shallow2Deep effectively reduces NN complexity – therefore their opacity – while reaching state-of-the-art performances. Unlike its competitors, Shallow2Deep promotes variability of localised structures in NN, helping to reduce NN opacity. The proposed work analyses the role of local variability in NN architectures design, presenting experimental results that show how this feature is actually desirable. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-030-85099-9_13,Lecture Notes in Computer Science,"A change of the prevalent supervised learning techniques is foreseeable in the near future: from the complex, computational expensive algorithms to more flexible and elementary training ones. The strong revitalization of randomized algorithms can be framed in this prospect steering. We recently proposed a model for distributed classification based on randomized neural networks and hyperdimensional computing, which takes into account cost of information exchange between agents using compression. The use of compression is important as it addresses the issues related to the communication bottleneck, however, the original approach is rigid in the way the compression is used. Therefore, in this work, we propose a more flexible approach to compression and compare it to conventional compression algorithms, dimensionality reduction, and quantization techniques. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-030-86517-7_29,Lecture Notes in Computer Science,"Nowadays, live video streaming events have become a mainstay in viewer’s communication in large international enterprises. Provided that viewers are distributed worldwide, the main challenge resides on how to schedule the optimal event’s time so as to improve both the viewer’s engagement and adoption. In this paper we present a multi-task deep reinforcement learning model to select the time of a live video streaming event, aiming to optimize the viewer’s engagement and adoption at the same time. We consider the engagement and adoption of the viewers as independent tasks and formulate a unified loss function to learn a common policy. In addition, we account for the fact that each task might have different contribution to the training strategy of the agent. Therefore, to determine the contribution of each task to the agent’s training, we design a Transformer’s architecture for the state-action transitions of each task. We evaluate our proposed model on four real-world datasets, generated by the live video streaming events of four large enterprises spanning from January 2019 until March 2021. Our experiments demonstrate the effectiveness of the proposed model when compared with several state-of-the-art strategies. For reproduction purposes, our evaluation datasets and implementation are publicly available at https://github.com/stefanosantaris/merlin. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-030-87234-2_11,Lecture Notes in Computer Science,"Breast cancer is the most common malignancy in women. Mammographic findings such as microcalcifications and masses, as well as morphologic features of masses in sonographic scans, are the main diagnostic targets for tumor detection. However, improved specificity of these imaging modalities is required. A leading alternative target is neoangiogenesis. When pathological, it contributes to the development of numerous types of tumors, and the formation of metastases. Hence, demonstrating neoangiogenesis by visualization of the microvasculature may be of great importance. Super resolution ultrasound localization microscopy enables imaging of the microvasculature at the capillary level. Yet, challenges such as long reconstruction time, dependency on prior knowledge of the system Point Spread Function (PSF), and separability of the Ultrasound Contrast Agents (UCAs), need to be addressed for translation of super-resolution US into the clinic. In this work we use a deep neural network architecture that makes effective use of signal structure to address these challenges. We present in vivo human results of three different breast lesions acquired with a clinical US scanner. By leveraging our trained network, the microvasculature structure is recovered in a short time, without prior PSF knowledge, and without requiring separability of the UCAs. Each of the recoveries exhibits a different structure that corresponds with the known histological structure. This study demonstrates the feasibility of in vivo human super resolution, based on a clinical scanner, to increase US specificity for different breast lesions and promotes the use of US in the diagnosis of breast pathologies. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-030-95467-3_20,Lecture Notes in Computer Science,"While reinforcement learning (RL) has proven to be the approach of choice for tackling many complex problems, it remains challenging to develop and deploy RL agents in real-life scenarios successfully. This paper presents pH-RL (personalization in e-Health with RL), a general RL architecture for personalization to bring RL to health practice. pH-RL allows for various levels of personalization in health applications and allows for online and batch learning. Furthermore, we provide a general-purpose implementation framework that can be integrated with various healthcare applications. We describe a step-by-step guideline for the successful deployment of RL policies in a mobile application. We implemented our open-source RL architecture and integrated it with the MoodBuster mobile application for mental health to provide messages to increase daily adherence to the online therapeutic modules. We then performed a comprehensive study with human participants over a sustained period. Our experimental results show that the developed policies learn to select appropriate actions consistently using only a few days’ worth of data. Furthermore, we empirically demonstrate the stability of the learned policies during the study. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-030-98388-8_5,Lecture Notes in Computer Science,"Several of the United Nations’ Sustainable Development Goals (SDGs) are directly or indirectly concerned with improving health and well-being of the world population. This paper presents an informatics-based approach to the management and monitoring of infectious diseases, in the context of one of these SDGs focusing on the eradication of vector-borne diseases such as malaria, Zika and other neglected tropical diseases. Here we outline the challenges faced by many conventional approaches to ecoepidemiological modelling and proposes a distributed interactive architecture for teamwork coordination, and data integration at different levels of information, and across disciplines. This approach is illustrated by an application to the surveillance of Leishmaniasis, a neglected tropical disease, in remote regions. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-031-21065-5_23,Lecture Notes in Networks and Systems,"Recent advances in disaster robotics have improved perceptual intelligence and maneuverability of unmanned ground (UGV) and aerial (UAV) vehicles for search and rescue (SAR) missions. Nevertheless, effective deployment of disaster robots in complex SAR scenarios poses additional mission-level challenges regarding operation and monitoring. These challenges include building maps for generating safe paths for the robots, designing reliable communication schemes, and integrating the robotic platforms and human responders through a mission control center. In this paper, we address these problems by applying a mission-oriented Internet of robotic things (IoRT) architecture that integrates robotic and human agents through ROS-based communications. This architecture has been validated in an urban SAR scenario from a remote (440 km) mission control center through a commercial mobile network. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-031-22216-0_50,Lecture Notes in Networks and Systems,"In this work, we study neural network architectures that will reduce the number of infractions made by autonomous-driving agents. These agents control vehicles by providing future waypoints directly from a forward-facing camera. Building on top of the teacher-student approach of Cheating by Segmentation, we investigate the impact of Pyramid Pooling Module and Feature Pyramid Network with the aim to learn more representative features. We run our experiment with CARLA simulator and show that pyramid perception modules have a positive impact in reducing the number of traffic light infractions and collisions. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-031-24349-3_20,Lecture Notes in Computer Science,"In agent-based social simulations (ABSS), an artificial population of intelligent agents that imitate human behavior is used to investigate complex phenomena within social systems. This is particularly useful for decision makers, where ABSS can provide a sandpit for investigating the effects of policies prior to their implementation. During the Covid-19 pandemic, for instance, sophisticated models of human behavior enable the investigation of the effects different interventions can have and even allow for analyzing why a certain situation occurred or why a specific behavior can be observed. In contrast to other applications of simulation, the use for policy making significantly alters the process of model building and assessment, and requires the modelers to follow different paradigms. In this chapter, we report on a tutorial that was organized as part of the ACAI 2021 summer school on AI in Berlin, with the goal of introducing agent-based social simulation as a method for facilitating policy making. The tutorial pursued six Intended Learning Outcomes (ILOs), which are accomplished by three sessions, each of which consists of both a conceptual and a practical part. We observed that the PhD students participating in this tutorial came from a variety of different disciplines, where ABSS is mostly applied as a research method. Thus, they do often not have the possibility to discuss their approaches with ABSS experts. Tutorials like this one provide them with a valuable platform to discuss their approaches, to get feedback on their models and architectures, and to get impulses for further research. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-031-56855-8_3,Lecture Notes in Computer Science,"Animals often demonstrate a remarkable ability to adapt to their environments during their lifetime. They do so partly due to the evolution of morphological and neural structures. These structures capture features of environments shared between generations to bias and speed up lifetime learning. In this work, we propose a computational model for studying a mechanism that can enable such a process. We adopt a computational framework based on meta reinforcement learning as a model of the interplay between evolution and development. At the evolutionary scale, we evolve reservoirs, a family of recurrent neural networks that differ from conventional networks in that one optimizes not the synaptic weights, but hyperparameters controlling macro-level properties of the resulting network architecture. At the developmental scale, we employ these evolved reservoirs to facilitate the learning of a behavioral policy through Reinforcement Learning (RL). Within an RL agent, a reservoir encodes the environment state before providing it to an action policy. We evaluate our approach on several 2D and 3D simulated environments. Our results show that the evolution of reservoirs can improve the learning of diverse challenging tasks. We study in particular three hypotheses: the use of an architecture combining reservoirs and reinforcement learning could enable (1) solving tasks with partial observability, (2) generating oscillatory dynamics that facilitate the learning of locomotion tasks, and (3) facilitating the generalization of learned behaviors to new tasks unknown during the evolution phase. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-031-72069-7_25,Lecture Notes in Computer Science,"The Magnetic Resonance Fingerprinting (MRF) approach aims to estimate multiple MR or physiological parameters simultaneously with a single fast acquisition sequence. Most of the MRF studies proposed so far have used simple MR sequence types to measure relaxation times (T<inf>1</inf>, T<inf>2</inf>). In that case, deep learning algorithms have been successfully used to speed up the reconstruction process. In theory, the MRF concept could be used with a variety of other MR sequence types and should be able to provide more information about the tissue microstructures. Yet, increasing the complexity of the numerical models often leads to prohibited simulation times, and estimating multiple parameters from one sequence implies new dictionary dimensions whose sizes become too large for standard computers and DL architectures. In this paper, we propose to analyze the MRF signal coming from a complex balanced Steady-State Free Precession (bSSFP) type sequence to simultaneously estimate relaxometry maps (T<inf>1</inf>, T<inf>2</inf>), Field maps (B<inf>1</inf>, B<inf>0</inf>) as well as microvascular properties such as the local Cerebral Blood Volume (CBV) or the averaged vessel Radius (R). To bypass the curse of dimensionality, we propose an efficient way to simulate the MR signal coming from numerical voxels containing realistic microvascular networks as well as a Bidirectional Long Short-Term Memory network that replaces the matching process. On top of standard MRF maps, our results on 3 human volunteers suggest that our approach can quickly produce high-quality quantitative maps of microvascular parameters that are otherwise obtained using longer dedicated sequences and intravenous injection of a contrast agent. This approach could be used for the management of multiple pathologies and could be tuned to provide other types of microstructural information. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-031-72848-8_6,Lecture Notes in Computer Science,"Multi-agent trajectory prediction is crucial to autonomous driving and understanding the surrounding environment. Learning-based approaches for multi-agent trajectory prediction, such as primarily relying on graph neural networks, graph transformers, and hypergraph neural networks, have demonstrated outstanding performance on real-world datasets in recent years. However, the hypergraph transformer-based method for trajectory prediction is yet to be explored. Therefore, we present a MultiscAle Relational Transformer (MART) network for multi-agent trajectory prediction. MART is a hypergraph transformer architecture to consider individual and group behaviors in transformer machinery. The core module of MART is the encoder, which comprises a Pair-wise Relational Transformer (PRT) and a Hyper Relational Transformer (HRT). The encoder extends the capabilities of a relational transformer by introducing HRT, which integrates hyperedge features into the transformer mechanism, promoting attention weights to focus on group-wise relations. In addition, we propose an Adaptive Group Estimator (AGE) designed to infer complex group relations in real-world environments. Extensive experiments on three real-world datasets (NBA, SDD, and ETH-UCY) demonstrate that our method achieves state-of-the-art performance, enhancing ADE/FDE by 3.9%/11.8% on the NBA dataset. Code is available at https://github.com/gist-ailab/MART. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-031-75390-9_6,Lecture Notes in Computer Science,"The concept of Digital Twin (DT) has gained enormous momentum over the past years in many fields with a variety of purposes. We investigated the usage of DTs for the development and testing of automated driving functions. In this context, we wanted to train an agent to challenge the automated driving function of a vehicle via reinforcement learning (RL). For this, we build both, a miniature Vehicle in a loop (ViL) testbed and its digital shadow. The idea is to use the digital shadow as the training environment for the agent resulting in reduced cost and time for training. We decided specifically to build a miniature version of a testbed to accelerate development, reduce resource consumption and increase adaptability. This paper contributed to the engineering of DTs by reporting our approach regarding the development of a digital shadow of a miniature ViL testbed and the lessons learned. First, we motivate the decision for a miniature testbed. Secondly, we describe the high-level architecture and the technical implementation including both the digital shadow and its physical counterpart. Third, we describe the application of the DT for RL and the experiments enabled by our setup. We conclude with the lessons learned. The main takeaway is that DTs are an excellent means to develop, disseminate and present new methods for the validation of automated vehicles. Here the benefits outweigh the effort of DT construction. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-319-07767-3_19,Communications in Computer and Information Science,"Information fusion studies theories and methods to effectively combine data from multiple sensors and related information to achieve more specific inferences that could be achieved by using a single, independent sensor. Information fused from sensors and data mining analysis has recently attracted the attention of the research community for real-world applications. In this sense, the deployment of an Intelligent Offshore Oil Industry Environment will help to figure out a risky scenario based on the events occurred in the past related to anomalies and the profile of the current employee (role, location, etc.). In this paper we propose an information fusion model for an intelligent oil environment in which employees are alerted about possible risk situations while their are moving around their working place. The layered architecture, implements a reasoning engine capable of intelligently filtering the context profile of the employee (role, location) for the feature selection of an inter-transaction mining process. Depending on the employee contextual information he will receive intelligent alerts based on the prediction model that use his role and his current location. This model provides the big picture about risk analysis for that employee at that place in that moment. © Springer International Publishing Switzerland 2014. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-319-11457-6_8,Advances in Intelligent Systems and Computing,"Goal of the present paper is providing support to operations planning and management in complex scenarios. The authors are mainly focused on South Asia region, which is subject of experimental analysis by running an Intelligent Agents driven HLA Federation. Simulation of investments and operations over an asymmetric mission environment with several parties, insurgents, terrorists and dynamic social framework is the aim. The scenario has various degrees of freedom and M&S enables evaluation of human behavior evolution and socio-psychological aspects. The presented models include Computer Generated Forces (CGF) driven by Intelligent Agents (IAs) that represents not only units on the battlefield, but also people and interest groups (i.e. Middle Class, Nomads, Clans). The study is focused on Civil Military Co-operations (CIMIC) and Psychological Operations (PSYOPs). The simulation is based on specific architecture that involves various federates playing different roles. Verification, Validation and Accreditation (VV&A) has been applied along the whole life cycle of the research, in order to determine the correctness and effectiveness of the results. The paper proposes experimental results obtained during the dynamic test of the federations. © 2016 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-319-20615-8_22,Lecture Notes in Computer Science,"LeoPARD supports the implementation of knowledge representation and reasoning tools for higher-order logic(s). It combines a sophisticated data structure layer (polymorphically typed λ-calculus with nameless spine notation, explicit substitutions, and perfect term sharing) with an ambitious multi-agent blackboard architecture (supporting prover parallelism at the term, clause, and search level). Further features of LeoPARD include a parser for all TPTP dialects, a command line interpreter, and generic means for the integration of external reasoners. © 2015 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-319-24132-6_18,Lecture Notes in Computer Science,"The collaborative architectural design process can be difficult to generate and maintain, especially when consisting of large teams, time constraints and long distance as it requires a higher sense of working together. However, a formal description of collaborative design as a system made of elements, agents, sub-systems and relationships could open a path to potentially improve production efficiency and stream collective intelligence. The CISP is a first attempt methodology to support collaborative design based on the empirical analysis of a single case study involving a multi-disciplinary team competing in an international architectural idea competition. The methodology operates through interdependencies on three layers: organization, planning and shared workspace. By articulating methods, tools, team members and project phases, the CISP fosters an integrated design system and a fluent design process. © 2016 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-319-24571-3_30,Lecture Notes in Computer Science,"Assessment of structural connectivity patterns of brains can be an important avenue for better understanding mechanisms of structural and functional brain architectures. Therefore, many efforts have been made to estimate and validate axonal pathways via a number of techniques, such as myelin stain, tract-tracing and diffusion MRI (dMRI). The three modalities have their own advantages and are complimentary to each other. From myelin stain data, we can infer rich in-plane information of axonal orientation at micro-scale. Tracttracing data is considered as ‘gold standard’ to estimate trustworthy meso-scale pathways. dMRI currently is the only way to estimate global macro-scale pathways given further validation. We propose a framework to take advantage of these three modalities. Information of the three modalities is integrated to determine the optimal tractography parameters for dMRI fibers and identify crossvalidated fiber bundles that are finally used to construct atlas. We demonstrate the effectiveness of the framework by a collection of experimental results. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-319-41649-6_33,Lecture Notes in Computer Science,"One of the most critical properties of a versatile intelligent agent is its capacity to adapt autonomously to any change in the environment without overly complexifying its cognitive architecture. In this paper, we propose that understanding the role of neuromodulation in the brain is of central interest for this purpose. More precisely, we propose that an accurate estimation of the nature of uncertainty present in the environment is performed by specific brain regions and broadcast throughout the cerebral network by neuromodulators, resulting in appropriate changes in cerebral functioning and learning modes. Better understanding the principles of these mechanisms in the brain might tremendously inspire the field of Artificial General Intelligence. The original contribution of this paper is to relate the four major neuromodulators to four fundamental dimensions of uncertainty. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-319-46475-6_1,Lecture Notes in Computer Science,"What is the right supervisory signal to train visual representations? Current approaches in computer vision use category labels from datasets such as ImageNet to train ConvNets. However, in case of biological agents, visual representation learning does not require millions of semantic labels. We argue that biological agents use physical interactions with the world to learn visual representations unlike current vision systems which just use passive observations (images and videos downloaded from web). For example, babies push objects, poke them, put them in their mouth and throw them to learn representations. Towards this goal, we build one of the first systems on a Baxter platform that pushes, pokes, grasps and observes objects in a tabletop environment. It uses four different types of physical interactions to collect more than 130K datapoints, with each datapoint providing supervision to a shared ConvNet architecture allowing us to learn visual representations. We show the quality of learned representations by observing neuron activations and performing nearest neighbor retrieval on this learned representation. Quantitatively, we evaluate our learned ConvNet on image classification tasks and show improvements compared to learning without external data. Finally, on the task of instance retrieval, our network outperforms the ImageNet network on recall@1 by 3%. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-319-47665-0_30,Lecture Notes in Computer Science,"This paper introduces a new research work that aims to improve embodied conversational agents with tutor behavior by endowing them with the capability to generate feedback in pedagogical interactions with learners. The virtual agent feedback and the interpretation of the user’s feedback are based on the knowledge of the environment (informed virtual environment), the interaction and the pedagogical strategies structured around classical intelligent tutoring system models. We present our first steps to implement our proposed architecture based on a model of informed virtual environment. We also describe the ideas that will guide the design of the Tutor Behavior. The planned evaluation method and a first application are also presented. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-319-50182-6_12,Lecture Notes in Computer Science,"Several serious games have been proposed to practice communication strategies in formal contexts. Intelligent virtual agents (IVA) can be used to show the player the effects of a conversational move. In this paper we discuss the key role of using social context for the virtual agents in these serious games. Social practices are exploited to bundle social interactions into standard packages and as a basis to model the deliberation processes of IVAs. We describe a social practice oriented IVA architecture used in the implementation of a serious game for the practicing of communication in medical interviews. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-319-57969-6_6,Communications in Computer and Information Science,"We train a number of neural networks to play the games Bowling, Breakout and Seaquest using information stored in the mem-ory of a video game console Atari 2600. We consider four models of neural networks which differ in size and architecture: two networks which use only information contained in the RAM and two mixed networks which use both information in the RAM and information from the screen. As the benchmark we used the convolutional model proposed in [17] and received comparable results in all considered games. Quite surpris-ingly, in the case of Seaquest we were able to train RAM-only agents which behave better than the benchmark screen-only agent. Mixing screen and RAM did not lead to an improved performance comparing to screen-only and RAM-only agents. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-319-58515-4_27,Lecture Notes in Computer Science,"This paper describes the use of Intelligent Agents and Ontologies to implement knowledge navigation and learner choice when interacting with complex information locations. The paper is in two parts: the first looks at how Agent Based Semantic Technology can be used to give users a more personalised experience as an individual. The paper then looks to generalise this technology to allow users to work with agents in hybrid group scenarios. In the context of University Learners, the paper outlines how we employ an Ontology of Student Characteristics to personalise information retrieval specifically suited to an individual’s needs. Choice is not a simple “show me your hand and make me a match” but a deliberative artificial intelligence (AI) that uses an ontologically informed agent society to consider the weighted solution paths before choosing the appropriate best. The aim is to enrich the student experience and significantly re-route the student’s journey. The paper uses knowledge-level interoperation of agents to personalise the learning space of students and deliver to them the information and knowledge to suite them best. The aim is to personalise their learning in the presentation/format that is most appropriate for their needs. The paper then generalises this Semantic Technology Framework using shared vocabulary libraries that enable individuals to work in groups with other agents, which might be other people or actually be AIs. The task they undertake is a formal assessment but the interaction mode is one of informal collaboration. Pedagogically this addresses issues of ensuring fairness between students since we can ensure each has the same experience (as provided by the same set of Agents) as each other and an individual mark may be gained. This is achieved by forming a hybrid group of learner and AI Software Agents. Different agent architectures are discussed and a worked example presented. The work here thus aims at fulfilling the student’s needs both in the context of matching their needs but also in allowing them to work in an Agent Based Synthetic Group. This in turn opens us new areas of potential collaborative technology. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-319-60285-1_15,Communications in Computer and Information Science,"Prediction models are widely used in insurance companies and health services. Even when 120 million people are at risk of suffering poverty or social exclusion in the EU, this kind of models are surprisingly unusual in the field of social services. A fundamental reason for this gap is the difficulty in labeling and annotating social services data. Conditions such as social exclusion require a case-by-case debate. This paper presents a multi-agent architecture that combines semantic web technologies, exploratory data analysis techniques, and supervised machine learning methods. The architecture offers a holistic view of the main challenges involved in labeling data and generating prediction models for social services. Moreover, the proposal discusses to what extent these tasks may be automated by intelligent agents. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-319-61578-3_13,Advances in Intelligent Systems and Computing,"Nowadays, when it comes to achieving goals in business environments or educational environments, the performance successfully has an important role in performing a task. However, this performance can be affected by several factors. One of the most common is the lack of attention. The individual’s attention in performing a task can be determinant for the final quality or even at the task’s conclusion. In this paper is intended to design a solution that can reduce or even eliminate the lack of attention on performing a task. The idea consist on develop an architecture that capture the user behavior through the mouse and keyboard usage. Furthermore, the system will analyze how the devices are used. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-319-68792-6_31,Lecture Notes in Computer Science,"In this paper, decentralized reinforcement learning is applied to a control problem with a multidimensional action space. We propose a decentralized reinforcement learning architecture for a mobile robot, where the individual components of the commanded velocity vector are learned in parallel by separate agents. We empirically demonstrate that the decentralized architecture outperforms its centralized counterpart in terms of the learning time, while using less computational resources. The method is validated on two problems: an extended version of the 3-dimensional mountain car, and a ball-pushing behavior performed with a differential-drive robot, which is also tested on a physical setup. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-319-70136-3_95,Lecture Notes in Computer Science,"Spiking neural networks (SNNs) enable power-efficient implementations due to their sparse, spike-based coding scheme. This paper develops a bio-inspired SNN that uses unsupervised learning to extract discriminative features from speech signals, which can subsequently be used in a classifier. The architecture consists of a spiking convolutional/pooling layer followed by a fully connected spiking layer for feature discovery. The convolutional layer of leaky, integrate-and-fire (LIF) neurons represents primary acoustic features. The fully connected layer is equipped with a probabilistic spike-timing-dependent plasticity learning rule. This layer represents the discriminative features through probabilistic, LIF neurons. To assess the discriminative power of the learned features, they are used in a hidden Markov model (HMM) for spoken digit recognition. The experimental results show performance above 96% that compares favorably with popular statistical feature extraction methods. Our results provide a novel demonstration of unsupervised feature acquisition in an SNN. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-319-70887-4_7,Lecture Notes in Computer Science,"Prediction models are widely used in insurance companies and health services. Even when 120 million people are at risk of suffering poverty or social exclusion in the EU, this kind of models are surprisingly unusual in the field of social services. A fundamental reason for this gap is the difficulty in labeling and annotating social services data. Conditions such as social exclusion require a case-by-case debate. This paper presents a multi-agent architecture that combines semantic web technologies, exploratory data analysis techniques, and supervised machine learning methods. The architecture offers a holistic view of the main challenges involved in labeling data and generating prediction models for social services. Moreover, the proposal discusses to what extent these tasks may be automated by intelligent agents. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-319-71649-7_17,Lecture Notes in Computer Science,"We introduce the Adaptation and Assessment (TwoA) component, an open-source tool for serious games, capable of adjusting game difficulty to player skill level. Technically, TwoA is compliant with the RAGE (Horizon 2020) game component architecture, which offers seamless portability to a variety of popular game development platforms. Conceptually, TwoA uses a modified version of the Computer Adaptive Practice algorithm. Our version offers two improvements over the original algorithm. First, TwoA improves the balancing of a player’s motivation and game challenge. Second, TwoA reduces the selection bias that may arise for items of similar difficulty by adopting a fuzzy selection rule. The improvements are validated using multi-agent simulations. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-319-72905-3_11,IFIP Advances in Information and Communication Technology,"During the execution of manufacturing processes, problems arise and they have to be solved systematically to reach and exceed production targets. Normally, a production team analyzes and solves these problems, with the support of different methodologies and working directly on the shop floor. This paper presents an ontology-based approach to easily capture and reuse the knowledge generated in such a process of Manufacturing Problem Solving (MPS). The proposed ontology is used as basis in an ad-hoc MPS software system. The architecture of the MPS system is based on the integration of three technologies: PLM (Product Lifecycle Management), CBR (Case-Based Reasoning) and software agents. The PLM system is used as an automatic source of the problem context information. The CBR system is used as repository of cases and artificial intelligence tool to support the efficient reuse of knowledge during the resolution of new problems. A software agent platform allows developing an integrated prototype of an ad-hoc software system. This paper shows the architecture of the MPS system prototype. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-319-95972-6_4,Lecture Notes in Computer Science,"During sleep and wakeful rest, the hippocampus replays sequences of place cells that have been activated during prior experiences. These replays have been interpreted as a memory consolidation process, but recent results suggest a possible interpretation in terms of reinforcement learning. The Dyna reinforcement learning algorithms use off-line replays to improve learning. Under limited replay budget, prioritized sweeping, which requires a model of the transitions to the predecessors, can be used to improve performance. We investigate if such algorithms can explain the experimentally observed replays. We propose a neural network version of prioritized sweeping Q-learning, for which we developed a growing multiple expert algorithm, able to cope with multiple predecessors. The resulting architecture is able to improve the learning of simulated agents confronted to a navigation task. We predict that, in animals, learning the transition and reward models should occur during rest periods, and that the corresponding replays should be shuffled. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-540-24677-0_77,Lecture Notes in Computer Science,"This paper describes a multiagent system for delivering adaptive m-learning services. It provides a discussion of many questions related to adaptivity and mobility in e-learning: course content adaptation, wireless access to learning services using PDA, and openness to external learning resources (learning object repositories). The paper provides a short overview of some related works and provides a detailed description of the architecture and components of the proposed multiagent framework. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-540-24677-0_88,Lecture Notes in Computer Science,"This paper presents an application of Chemical Reaction Metaphor (CRM) in agent-based distributed learning systems. The suitability of using CRM to model multi-agent systems is justified by CRM's capacity in catching dynamic features of multi-agent systems in an e-learning environment. A case study in course material updating demonstrates how the CRM based language, Gamma language, can be used to specify the architecture of the learning environment. Finally, a discussion on the implementation of Gamma language in a distributed system is given. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-540-68234-9_6,Lecture Notes in Computer Science,"Ontology-Driven Software Development (ODSD) advocates using ontologies for capturing knowledge about a software system at development time. So far, ODSD approaches have mainly focused on the unambiguous representation of domain models during the system analysis phase. However, the design and implementation phases can equally benefit from the logical foundations and reasoning facilities provided by the Ontology technological space. This applies in particular to Model-Driven Software Development (MDSD) which employs models as first class entities throughout the entire software development process. We are currently developing a tool suite called HybridMDSD that leverages Semantic Web technologies to integrate different domain-specific modeling languages based on their ontological foundations. To this end, we have defined a new upper ontology for software models that complements existing work in conceptual and business modeling. This paper describes the structure and axiomatization of our ontology and its underlying conceptualization. Further, we report on the experiences gained with validating the integrity and consistency of software models using a Semantic Web reasoning architecture. We illustrate practical solutions to the implementation challenges arising from the open-world assumption in OWL and lack of nonmonotonic queries in SWRL. © 2008 Springer-Verlag Berlin Heidelberg. © 2008 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-540-79547-6_33,Lecture Notes in Computer Science,"We experiment a vision architecture for object matching based on a hierarchy of independent agents running asynchronously in parallel. Agents communicate through bidirectional signals, enabling the mix of top-down and bottom-up influences. Following the so-called a contrario principle, each signal is given a strength according to the statistical relevance of its associated visual data. By handling most important signals first, the system focuses on most promising hypotheses and provides relevant results as soon as possible. Compared to an equivalent feed-forward and sequential algorithm, our architecture is shown capable of handling more visual data and thus reach higher detection rates in less time. © 2008 Springer-Verlag Berlin Heidelberg. © 2011 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-02121-3_70,Lecture Notes in Computer Science,"We present GiaBATA, a system for storing, aggregating, and querying Semantic Web data, based on declarative logic programming technology, namely on the dlvhex system, which allows us to implement a fully SPARQL compliant semantics, and on DLV DB , which extends the DLV system with persistent storage capabilities. Compared with off-the-shelf RDF stores and SPARQL engines, we offer more flexible support for rule-based RDFS and other higher entailment regimes by enabling custom reasoning via rules, and the possibility to choose the reference ontology on a per query basis. Due to the declarative approach, GiaBATA gains the possibility to apply well-known logic-level optimization features of logic programming (LP) and deductive database systems. Moreover, our architecture allows for extensions of SPARQL by non-standard features such as aggregates, custom built-ins, or arbitrary rulesets. With the resulting system we provide a flexible toolbox that embeds Semantic Web data and ontologies in a fully declarative LP environment. © 2009 Springer Berlin Heidelberg. © 2009 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-02818-2_53,Lecture Notes in Computer Science,"Rules and ontologies are widely used in software development since they provide semantic web applications with meaning and reasoning features. This demonstration paper presents InSCo-Gen, a Model-Driven Development (MDD) tool for Web rule-based applications, which constructs a functional Web architecture integrating a rule engine for reasoning tasks. Development process is based on conceptual models composed of ontologies and production rules. These models are the source for the MDD process, which automatically generates implementation of the Web application. © 2009 Springer Berlin Heidelberg. © 2009 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-02921-9_30,Lecture Notes in Computer Science,"Both self-learning architecture (embedded structure) and explicit/implicit teaching from other agents (environmental design issue) are necessary not only for one behavior learning but more seriously for life-time behavior learning. This paper presents a method for a robot to understand unfamiliar behavior shown by surrounding players through the collaboration between behavior acquisition and recognition of observed behavior, where the state value has an important role not simply for behavior acquisition (reinforcement learning) but also for behavior recognition (observation). That is, the state value updates can be accelerated by observation without real trials and errors while the learned values enrich the recognition system since it is based on estimation of the state value of the observed behavior. The validity of the proposed method is shown by applying it to a soccer robot domain. © 2009 Springer Berlin Heidelberg. © 2012 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-04146-4_27,Lecture Notes in Computer Science,"Multi-modality is a fundamental feature that characterizes biological systems and lets them achieve high robustness in understanding skills while coping with uncertainty. Relatively recent studies showed that multi-modal learning is a potentially effective add-on to artificial systems, allowing the transfer of information from one modality to another. In this paper we propose a general architecture for jointly learning visual and motion patterns: by means of regression theory we model a mapping between the two sensorial modalities improving the performance of artificial perceptive systems. We present promising results on a case study of grasp classification in a controlled setting and discuss future developments. © 2009 Springer Berlin Heidelberg. © 2013 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-12433-4_42,Advances in Intelligent Systems and Computing,"This paper presents the BRENHET application, which introduces a new concept in searching for educational resources by using a learning object paradigm that describes these resources. The application is composed of a complete agent-based architecture that implements the concept of federated search. It can search different repositories in parallel, and is based on abstraction layers between the repositories and the search clients. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-12433-4_84,Advances in Intelligent Systems and Computing,"This paper presents an improvement of the SCMAS architecture aimed at securing SQL-run databases. The main goal of such architecture is the detection and prevention of SQL injection attacks. The improvement consists in the incorporation of unsupervised projection models for the visual inspection of SQL traffic. Through the obtained projections, SQL injection queries can be identified and subsequent actions can be taken. The proposed approach has been tested on a real dataset, and the obtained results are shown. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-13803-4_8,Lecture Notes in Computer Science,"The rapid evolution within the context of e-learning is closely linked to international efforts on the standardization of learning object metadata, which provides learners in a web-based educational system with ubiquitous access to multiple distributed repositories. This article presents a hybrid agent-based architecture that enables the recovery of learning objects tagged in Learning Object Metadata (LOM) and provides individualized help with selecting learning materials to make the most suitable choice among many alternatives. © 2010 Springer-Verlag. © 2010 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-14435-6_1,Studies in Computational Intelligence,"Multi-agent systems is a subfield of Distributed Artificial Intelligence that has experienced rapid growth because of the flexibility and the intelligence available solve distributed problems. In this chapter, a brief survey of multi-agent systems has been presented. These encompass different attributes such as architecture, communication, coordination strategies, decision making and learning abilities. The goal of this chapter is to provide a quick reference to assist in the design of multi-agent systems and to highlight the merit and demerits of the existing methods. © 2010 Springer-Verlag Berlin Heidelberg. © 2010 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-14883-5_13,Advances in Intelligent and Soft Computing,"This paper presents a multiagent architecture that covers the new requirements for the new control systems such as the distribution and decentralisation of system elements, the definition of communications between these elements, the fast adaptation in the control and organizational changes. The agents in this architecture can cooperate and coordinate to achieve a global goal, encapsulate the hardware interfaces and make the control system easily adapt to different requirements through configuration. Finally, the proposed architecture is applied to a control system of a solar power plant, obtaining a preliminary system that achieve the goals of simplicity, scalability, flexibility and optimization of communications system. © 2010 Springer-Verlag Berlin Heidelberg. © 2011 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-15286-3_2,IFIP Advances in Information and Communication Technology,"The paper presents an architecture for an autonomous robotic agent, which carries on a plan in a partially observable environment. A Supervisor module is in charge of assuring the correct execution of the plan, possibly by inferring alternative recovery plans when unexpected contingencies occur. In the present paper we describe a control strategy where a human user is directly involved in the control loop, and plays the role of advisor by helping the robotic agent both for reducing ambiguity in the robot's observations, and for selecting the preferred recovery plan. © 2010 IFIP. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-19170-1_8,IFIP Advances in Information and Communication Technology,"In this paper a holistic approach to automated service composition in Service Oriented Architecture is presented. The model described allows to specify both functional and non-functional requirements for the complex service. In order to do so a decomposition of the complex service composition process into three stages is proposed, in which a structure, a scenario and an execution plan of a complex service is built. It is believed that service composition tool based on the proposed model will be able to create complex services satisfying efficiently both functional and nonfunctional requirements. © 2011 IFIP International Federation for Information Processing. © 2012 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-19875-5_15,Advances in Intelligent and Soft Computing,"In this paper, an innovative approach to perform distributed Bayesian inference using a multi-agent architecture is presented. The final goal is dealing with uncertainty in network diagnosis, but the solution can be of applied in other fields. The validation testbed has been a P2P streaming video service. An assessment of the work is presented, in order to show its advantages when it is compared with traditional manual processes and other previous systems. © 2011 Springer-Verlag Berlin Heidelberg. © 2011 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-20077-9_10,Communications in Computer and Information Science,"A novel approach to efficiently plan and execute effective transport solutions is presented. It provides agent-based support for key tasks, such as, finding the best sequence of transport services for a particular goods transport, monitoring the execution of the transport, as well as the interaction between the involved actors. The approach is based on the FREIGHTWISEframework in which a minimal set of information packages is defined. The purpose is to capture all the information that needs to be communicated between the actors involved in a transport, such as, transport users, transport providers, and infrastructure managers, during the complete process from planning to termination. The approach is inspired by the concepts of virtual enterprises and breeding environments. We analyse the requirements of such an approach and describe a multi-agent system architecture meeting these requirements. © 2011 Springer-Verlag Berlin Heidelberg. © 2013 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-21616-9_31,Lecture Notes in Computer Science,"Recently, the interest of using agent-based model combined with GIS to perform simulations that seek solutions to problems in the study of tourism services and planning is expanding. However, few scientific studies or systematic methodologies in tourism research have been conducted to support the design and development of such simulations. This research intends to develop a general framework for agent-based simulations in tourism and present its possibility in practical tourism planning process. By developing an agent-based simulation combined with GIS under the protocol, planning supports to tourism bureaus and policy makers to help them assess different tourism policy scenarios and improve tourism services. © 2011 Springer-Verlag. © 2011 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-21869-9_108,Lecture Notes in Computer Science,"Concept maps are often used in inquiry learning as tools for conceptual modelling, but also as a means to externalise and diagnose conceptual understanding. The latter use is closely related to intelligent feedback and scaffolding. Previous approaches used an expert concept map as a reference to generate intelligent feedback. This paper describes an approach that takes a domain ontology as its only input. © 2011 Springer-Verlag Berlin Heidelberg. © 2011 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-22636-6_13,Lecture Notes in Computer Science,"Collaborative robotic systems have much to gain by leveraging results from the area of multi-agent systems and in particular agent-oriented software engineering. Agent-oriented software engineering has much to gain by using collaborative robotic systems as a testbed. In this article, we propose and specify a formally grounded generic collaborative system shell for robotic systems and human operated ground control systems. Collaboration is formalized in terms of the concept of delegation and delegation is instantiated as a speech act. Task Specification Trees are introduced as both a formal and pragmatic characterization of tasks and tasks are recursively delegated through a delegation process implemented in the collaborative system shell. The delegation speech act is formally grounded in the implementation using Task Specification Trees, task allocation via auctions and distributed constraint problem solving. The system is implemented as a prototype on Unmanned Aerial Vehicle systems and a case study targeting emergency service applications is presented. © 2011 Springer-Verlag. © 2011 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-23780-5_5,Lecture Notes in Computer Science,"In this talk, I propose a functional framework to understand the emergence of intelligence in agents exposed to examples and knowledge granules. The theory is based on the abstract notion of constraint, which provides a representation of knowledge granules gained from the interaction with the environment. I give a picture of the “agent body” in terms of representation theorems by extending the classic framework of kernel machines in such a way to incorporate logic formalisms, like first-order logic. This is made possible by the unification of continuous and discrete computational mechanisms in the same functional framework, so as any stimulus, like supervised examples and logic predicates, is translated into a constraint. The learning, which is based on constrained variational calculus, is either guided by a parsimonious match of the constraints or by unsupervised mechanisms expressed in terms of the minimization of the entropy. I show some experiments with different kinds of symbolic and sub-symbolic constraints, and then I give insights on the adoption of the proposed framework in computer vision. It is shown that in most interesting tasks the learning from constraints naturally leads to “deep architectures”, that emerge when following the developmental principle of focusing attention on “easy constraints”, at each stage. Interestingly, this suggests that stage-based learning, as discussed in developmental psychology, might not be primarily the outcome of biology, but it could be instead the consequence of optimization principles and complexity issues that hold regardless of the “body.”. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-23954-0_16,Lecture Notes in Computer Science,"The paper addresses the problem of supervising the execution of a plan with durative actions in a just partially known world, where discrepancies between the expected conditions and the ones actually found may arise. The paper advocates a control architecture which exploits additional knowledge to prevent (when possible) action failures by changing the execution modality of actions while these are still in progress. Preliminary experimental results, obtained in a simulated space exploration scenario, are reported. © 2011 Springer-Verlag Berlin Heidelberg. © 2011 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-24088-1_33,Lecture Notes in Computer Science,"Many works in literature have demonstrated the superiority of multibiometric systems compared to single-biometrics ones, in terms of both accuracy and robustness. Most current multibiometric systems implement a static architecture, which does not change in time. However, the ability to progressively add more modules, either to process more biometrics or to exploit additional algorithms, might contribute to further enhance recognition performance. The addition of a new module (agent) to an already fully operational multiagent system usually requires its preliminary setup and training. In particular, it must be provided with a brand-new gallery, whose templates are suitably labeled according to the represented identities; alternatively, an existing database of templates, formerly built according to the suited feature extraction procedure, might be updated to include better quality items. It would be of paramount importance if the new agent can ""inherit"" the ""experience that was already acquired by the other agents, including the creation of its gallery without having to undergo a full enrolling phase in its turn. We present here an algorithm to align a new module to the already existing ones in an automatic and unsupervised way. Experimental results show that our algorithm is effective both when the new database must be created from scratch (sample labeling), as well as when it is pre-existing and must be updated (sample updating). The latter operation can also be iteratively performed in running modules to dynamically update their galleries. In particular, we present here results achieved for face recognition. © 2011 Springer-Verlag. © 2011 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-27549-4_23,Lecture Notes in Computer Science,"In recent years researchers have been working to develop tools to filter the information available and give the users the content that is relevant to them. This paper presents a recommendation system developed on an agent architecture software based on a management content model in blended learning environments. It also uses clustering algorithms to find relevant information in the content, building a search space tailored to the interests of the learner. To validate the architecture proposed we worked with Action Research methodology and was developed a prototype system called SisMA in order to retrieve the information in the educational setting. To measure the effectiveness of the application and its impact on the learning process the system was tested in two scenarios. The results showed that the relevance of content and the profile generated by its work plan have had a positive effect on the learning process. © 2012 Springer-Verlag. © 2012 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-28801-2_14,Advances in Intelligent and Soft Computing,"A major challenge in searching and retrieval digital content is to efficiently find the most suitable for the users. This paper proposes a new approach to filter the educational content retrieved based on Case-Based Reasoning (CBR). AIREH (Architecture for Intelligent Recovery of Educational content in Heterogeneous Environments) is a multi-agent architecture that can search and integrate heterogeneous educational content within the CBR model proposes. The recommendation model and the technologies reported in this research applied to educational content are an example of the potential for personalizing labeled educational content recovered from heterogeneous environments. © 2012 Springer-Verlag. © 2012 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-30864-2_12,Advances in Intelligent Systems and Computing,"Wireless Sensor Networks is a key technology for gathering relevant information from different sources. In this sense, Multi-Agent Systems can facilitate the integration of heterogeneous sensor networks and expand the sensors' capabilities changing their behavior dynamically and personalizing their reactions. Both Wireless Sensor Networks and Multi-Agent Systems can be successfully applied to different management scenarios, such as logistics, supply chain or production. The Hardware-Embedded Reactive Agents (HERA) platform allows developing applications where agents are directly embedded in heterogeneous wireless sensor nodes with reduced computational resources. This paper presents the reasoning mechanism included in HERA to provide HERA Agents with Case-Based Planning features that allow solving problems considering past experiences. © 2012 Springer-Verlag. © 2015 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-31254-0_12,Lecture Notes in Computer Science,"Selecting the appropriate operators with the optimal values for their parameters represents a big challenge for users. In this paper we present a solution for this problem. This solution uses a multi-agent architecture based on reinforcement learning to automate the process of operator selection and parameter adjustment. The architecture consists of three types of agents: the User Agent, the Operator Agent and the Parameter Agent. The User Agent determines the phases of treatment, and for each phase it determines a library of possible operators and possible values of their parameters. The Operator Agent constructs all possible combinations of operators and decides for the best one. The Parameter Agent, the core of the architecture, adjusts the parameters of each combination of operators by processing a large number of images. Towards the end, the agents must offer the best combination of operators and the best values of their parameters. © 2012 Springer-Verlag. © 2012 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-31525-1_16,Lecture Notes in Computer Science,"From using forks to eat to maneuvering high-tech gadgets of modern times, humans are adept in swiftly learning to use a wide range of tools in their daily lives. The essence of 'tool use' lies in our gradual progression from learning to act 'on' objects to learning to act 'with' objects in ways to counteract limitations of 'perceptions, actions and movements' imposed by our bodies. At the same time, to learn both ""cumulatively"" and ""swiftly"" a cognitive agent (human or humanoid) must be able to efficiently integrate multiple streams of information that aid to the learning process itself. Most important among them are social interaction (for example, imitating a teacher's demonstration), physical interaction (or practice) and ""recycling"" of previously learnt knowledge (experience) in new contexts. This article presents the skill learning architecture being developed for the humanoid iCub that dynamically integrates multiple streams of learning, multiple task specific constraints and incorporates novel principles that we believe are crucial for constructing a growing motor vocabulary in acting/learning robots. A central feature further is our departure from the well known notion of 'trajectory formation' and introduction of the idea of 'shape' in the domain of movement. The idea is to learn in an abstract fashion, hence allowing both ""task independent"" knowledge reuse and task specific ""compositionality"" to coexist. The scenario of how iCub learns to bimanually coordinate a new tool (a toy crane) to pick up otherwise unreachable objects in its workspace (recycling its past experience of learning to draw) is used to both illustrate central ideas and ask further questions. © 2012 Springer-Verlag. © 2012 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-33409-2_29,IFIP Advances in Information and Communication Technology,"This paper describes the design and implementation of a modular hybrid intelligent model and system, for monitoring and forecasting of air pollution in major urban centers. It is based on Multiagent technologies, Artificial Neural Networks (ANN), Fuzzy Rule Based sub-systems and it uses a Reinforcement learning approach. A multi level architecture with a high number of agent types was employed. Multiagent's System modular and distributed nature, allows it's interconnection with existing systems and it reduces its functional cost, allowing its extension by incorporating decision functions and real time imposing actions capabilities. © 2012 IFIP International Federation for Information Processing. © 2013 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-33542-6_9,Lecture Notes in Computer Science,"To many people, philosophy seems to be a difficult and daunting subject. Our research seeks to make the esoteric philosophical ideas and concepts more accessible to people in the modern world, and make philosophy learning an entertaining activity by allowing people to directly interact with virtual philosophers from the past. With Artificial Intelligence technology, we have created a virtual philosopher that can automatically respond to user's input in natural language text. It is hoped that the added interactivity can help to increase the appeal of philosophical subject to the users, and the users can have a better idea of the philosophy after an entertaining experience talking with the virtual philosopher. In this paper, we share our considerations for designing the system, the system architecture, and our preliminary user study on the interaction with the virtual philosopher. © 2012 Springer-Verlag Berlin Heidelberg. © 2013 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-33783-3_62,Lecture Notes in Computer Science,"In this paper we promote the idea of using pixel-based models not only for low level vision, but also to extract high level symbolic representations. We use a deep architecture which has the distinctive property of relying on computational units that incorporate classic computer vision invariances and, especially, the scale invariance. The learning algorithm that is proposed, which is based on information theory principles, develops the parameters of the computational units and, at the same time, makes it possible to detect the optimal scale for each pixel. We give experimental evidence of the mechanism of feature extraction at the first level of the hierarchy, which is very much related to SIFT-like features. The comparison shows clearly that, whenever we can rely on the massive availability of training data, the proposed model leads to better performances with respect to SIFT. © 2012 Springer-Verlag. © 2012 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-38490-5_1,Lecture Notes in Business Information Processing,"We present a case study of business architecture development by students working in socially networked groups. In this case study we emulated a self-development of an evolutionary information system. The ""client system"" in this emulated project was medical laboratory information system. In the role of the ""change agent"" were students of two different specialties: medical technology students (one group) and IT students (another group). We describe the process and results of the first (finished) phase of strategic analysis where the initial business architecture was developed. Later on this business architecture will be utilized as a platform for (social, self-) development of business processes and software. Medical technology students (knowing the problem) played the business process owner/analyst dual role. IT students (knowing IT-related solution patterns for the problem and processes) played the business designer role. The relationships between (and inside) the two groups/communities were managed using Google Sites (social) software. © 2013 Springer-Verlag. © 2014 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-38715-9_6,Lecture Notes in Computer Science,"This paper shows that learning by imitation leads to a positive effect not only in human behavior but also in the behavior of the autonomous agents (AA) in the field of self-organized creation deposits. Indeed, for each agent, the individual discoveries (i.e. goals) have an effect on the performance of the population level and therefore they induce a new learning capability at the individual level. Particularly, we show through a set of experiments that adding a simple imitation capability to our bio-inspired architecture allows increasing the ability of agents to share more information and improving the overall performance of the whole system. We will conclude with robotics' experiments which will feature how our approach applies accurately to real life environments. © 2013 Springer-Verlag Berlin Heidelberg. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-39802-5_17,Lecture Notes in Computer Science,"Passive sensory processing is often insufficient to guide biological organisms in complex environments. Rather, behaviourally relevant information can be accessed by performing so-called epistemic actions that explicitly aim at unveiling hidden information. However, it is still unclear how an autonomous agent can learn epistemic actions and how it can use them adaptively. In this work, we propose a definition of epistemic actions for POMDPs that derive from their characterizations in cognitive science and classical planning literature. We give theoretical insights about how partial observability and epistemic actions can affect the learning process and performance in the extreme conditions of model-free and memory-free reinforcement learning where hidden information cannot be represented. We finally investigate these concepts using an integrated eye-arm neural architecture for robot control, which can use its effectors to execute epistemic actions and can exploit the actively gathered information to efficiently accomplish a seek-and-reach task. © 2013 Springer-Verlag Berlin Heidelberg. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-40511-2_7,Lecture Notes in Computer Science,"The extraction of metadata used during the planning phase in mediation systems assumes the existence of a metadata repository that in most cases must be created with high human involvement. This dependency rises complexity of maintenance of the system and therefore the reliability of the metadata itself. This article presents MetaExtractor, a system which extracts structure, quality, capability and content metadata of structured data sources available on a mediation system. MetaExtractor is designed as a Multi-Agent System(MAS) where each agent specializes in the extraction of a particular type of metadata. The MAS cooperation capability allows the creation and maintenance of the metadata repository. MetaExtractor is useful to reduce the number of data sources selected during query planning in large scale mediation systems due to its ability to prioritize data sources that better contribute to answer a query. The work reported in this paper presents the general architecture of MetaExtractor and emphasizes on the extraction logic of content metadata and the strategy used to prioritize data sources accordingly to a given query. © 2013 IFIP International Federation for Information Processing. © 2013 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-41142-7_21,IFIP Advances in Information and Communication Technology,"In this paper we discuss how to design a simple motivated learning agent with symbolic I/O using a simulation environment within the NeoAxis game engine. The purpose of this work is to explore autonomous development of motivations and memory of agents in a virtual environment. The approach we took should speed up the development process, bypassing the need to create a physical embodied agent as well as reducing the learning effort. By rendering low-level motor actions such as grasping or walking into symbolic commands we remove the need to learn elementary motions. Instead, we use several basic primitive motor procedures, which can form more complex procedures. Furthermore, by simulating the agent's environment, we both improve and simplify the learning process. There are a few adaptive learning variables associated with both the agent and its environment, and learning takes less time, than it would in a more complex real world environment. © IFIP International Federation for Information Processing 2013. © 2014 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-642-54420-0_58,Lecture Notes in Computer Science,"The explanatory and predictive power of social simulations is more and more connected with the development of models accounting for the complexity of real (inter-individual and intra-individual) social dynamics. From this perspective, a promising research path is complementing very simple models, more suitable to illuminate core dynamics of social phenomena, with increasingly more complex and empirically grounded simulations (big data-driven models, higher number of agents, more detailed and realistic description of cognitive and communication mechanisms underlying individual and group behaviors). The choice has two strictly intertwined effects: not only a different modeling approach, but also the need for more powerful tools. The paper presents a distributed implementation of an agent-based model exploring the interplay between damaging behaviors, sanctions and social mechanisms of learning and imitation, a topic investigated in many areas of social science from economics to legal science. Taking cue from a previous work based on a simple NetLogo simulation, the work shows how distributed solutions can help in developing more complex, wide and semantically rich models. © 2014 Springer-Verlag Berlin Heidelberg. © 2016 Elsevier B.V., All rights reserved.",TOPIC
10.1007/978-3-662-44468-9_31,Lecture Notes in Computer Science,"We propose parallel computing to simulate crowd evacuation behavior. It allows evacuation of ten thousands of agents to be simulated faster than does the existing system. Our prototype system consists of a new traffic simulator and scenario generator. The traffic simulation system uses a general purpose graphics processing unit (GPGPU) and simulates the agents' movements in a three-dimensional map. Our proposal enables realistic evacuation simulations and provides a platform that widens the applications of RoboCup Rescue Simulation to, for example, crowd evacuation from buildings. The evacuation simulations help security offices to prepare manuals for emergencies. © 2014 Springer-Verlag Berlin Heidelberg. © 2014 Elsevier B.V., All rights reserved.",TOPIC
10.1007/bf03194509,Journal of the Brazilian Computer Society,"This article introduces an open-source module responsible for the presentation of verbal (speech) and corporal (animation) behaviors of animated pedagogical agents. This module can be inserted into any learning environment regardless of application domain and platform, being executable under different operating systems. It was implemented in Java as a reactive agent (named Body agent) that communicates with the agent's Mind through a language known as FIPA-ACL. Therefore, it may be inserted into any intelligent learning environment that is also capable to communicate using FIPA-ACL. Persistence of information is ensured by XML files, increasing the agent's portability. The agent also includes a mechanism for automatically updating new behaviors and characters once available in the server. A simulation environment was conceived to test the proposed agent. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s00422-013-0562-6,Biological Cybernetics,"In a large variety of situations one would like to have an expressive and accurate model of observed animal or human behavior. While general purpose mathematical models may capture successfully properties of observed behavior, it is desirable to root models in biological facts. Because of ample empirical evidence for reward-based learning in visuomotor tasks, we use a computational model based on the assumption that the observed agent is balancing the costs and benefits of its behavior to meet its goals. This leads to using the framework of reinforcement learning, which additionally provides well-established algorithms for learning of visuomotor task solutions. To quantify the agent's goals as rewards implicit in the observed behavior, we propose to use inverse reinforcement learning, which quantifies the agent's goals as rewards implicit in the observed behavior. Based on the assumption of a modular cognitive architecture, we introduce a modular inverse reinforcement learning algorithm that estimates the relative reward contributions of the component tasks in navigation, consisting of following a path while avoiding obstacles and approaching targets. It is shown how to recover the component reward weights for individual tasks and that variability in observed trajectories can be explained succinctly through behavioral goals. It is demonstrated through simulations that good estimates can be obtained already with modest amounts of observation data, which in turn allows the prediction of behavior in novel configurations. © 2013 Springer-Verlag Berlin Heidelberg. © 2013 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s00422-015-0644-8,Biological Cybernetics,"The ultimate navigation efficiency of mobile robots in human environments will depend on how we will appraise them: merely as impersonal machines or as human-like agents. In the latter case, an agent may take advantage of the cooperative collision avoidance, given that it possesses recursive cognition, i.e., the agent’s decisions depend on the decisions made by humans that in turn depend on the agent’s decisions. To deal with this high-level cognitive skill, we propose a neural network architecture implementing Prediction-for-CompAction paradigm. The network predicts possible human–agent collisions and compacts the time dimension by projecting a given dynamic situation into a static map. Thereby emerging compact cognitive map can be readily used as a “dynamic GPS” for planning actions or mental evaluation of the convenience of cooperation in a given context. We provide numerical evidence that cooperation yields additional room for more efficient navigation in cluttered pedestrian flows, and the agent can choose path to the target significantly shorter than a robot treated by humans as a functional machine. Moreover, the navigation safety, i.e., the chances to avoid accidental collisions, increases under cooperation. Remarkably, these benefits yield no additional load to the mean society effort. Thus, the proposed strategy is socially compliant, and the humanoid agent can behave as “one of us.” © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s00521-021-05888-w,Neural Computing and Applications,"Sophisticated trajectory prediction models that effectively mimic team dynamics have many potential uses for sports coaches, broadcasters and spectators. However, through experiments on soccer data we found that it can be surprisingly challenging to train a deep learning model for player trajectory prediction which outperforms linear extrapolation on average distance between predicted and true future trajectories. We propose and test a novel method for improving training by predicting a sparse trajectory and interpolating using constant acceleration, which improves performance for several models. This interpolation can also be used on models that are not trained with sparse outputs, and we find that this consistently improves performance for all tested models. Additionally, we find that the accuracy of predicted trajectories for a subset of players can be improved by conditioning on the full trajectories of the other players, and that this is further improved when combined with sparse predictions. We also propose a novel architecture using graph networks and multi-head attention (GraN–MA) which achieves better performance than other tested state-of-the-art models on our dataset and is trivially adapted for both sparse trajectories and full-trajectory conditioned trajectory prediction. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s00521-023-08537-6,Neural Computing and Applications,"Steam injection is a popular technique to enhance oil recovery in mature oil fields. However, the conventional approach of using a constant steam rate over an extended period can lead to sub-optimal performance due to the complex nature of the problem and reservoir heterogeneity. To address this issue, the Markov decision process can be employed to formulate the problem for reinforcement learning (RL) applications. The RL agent is trained to optimize the steam injection rate by interacting with a reservoir simulation model and receives rewards for each action. The agent’s policy and value functions are updated through continuous interaction with the environment until convergence is achieved, leading to a more efficient steam injection strategy for enhancing oil recovery. In this study, an actor-critic RL architecture was employed to train the agent to find the optimal strategy (i.e., policy). The environment was represented by a reservoir simulation model, and the agent’s actions were based on the observed state. The policy function gave a probability distribution of the actions that the agent could take, while the value function determined the expected yield for an agent starting from a given state. The agent interacted with the environment for several episodes until convergence was achieved. The improvement in net present value (NPV) achieved by the agent was a significant indication of the effectiveness of the RL-based approach. The NPV reflects the economic benefits of the optimized steam injection strategy. The agent was able to achieve this improvement by finding the optimal policies. One of the key advantages of the optimal policy was the decrease in total field heat losses. This is a critical factor in the efficiency of the steam injection process. Heat loss can reduce the efficiency of the process and lead to lower oil recovery rates. By minimizing heat loss, the agent was able to optimize the steam injection process and increase oil recovery rates. The optimal policy had four regions characterized by slight changes in a stable injection rate to increase the average reservoir pressure, increasing the injection rate to a maximum value, steeply decreasing the injection rate, and slightly changing the injection rate to maintain the average reservoir temperature. These regions reflect the different phases of the steam injection process and demonstrate the complexity of the problem. Overall, the results of this study demonstrate the effectiveness of RL in optimizing steam injection in mature oil fields. The use of RL can help address the complexity of the problem and improve the efficiency of the oil recovery process. This study provides a framework for future research in this area and highlights the potential of RL for addressing other complex problems in the energy industry. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10009-020-00558-z,International Journal on Software Tools for Technology Transfer,"Smart system applications (SSAs)—a heterogeneous landscape of applications of Internet of things, cyber-physical systems, and smart sensing systems—are composed of autonomous yet inherently cooperating components. An important problem in this area is how to hoist the cooperation of software components forming dynamic groups—ensembles—at the architectural level of an SSA. This is hard since ensembles can overlap, be nested, and be dynamically formed and dismantled based on several criteria. A related problem is how to combine component and ensemble specification with a well-established language supported on multiple platforms. To target these problems, we propose a specification and implementation language Trait-based COmponent Ensemble Language (TCOEL) based on Scala internal DSL, to describe both the architecture and formation of dynamic ensembles of components and their functional internals. To raise the level of expressivity, we introduce the concept of domain-specific extensions (traits) to the TCOEL core to reflect different paradigms’ concerns—such as movement in a 2D map, state-space modeling of physical processes, and statistical reasoning about uncertainty. This allows for configuring TCOEL for the needs of a specific SSA use case and, at the same time, facilitates reuse. To evaluate TCOEL, we show how it can be beneficially used in addressing the coordination of agents in a RoboCup Rescue Simulation application. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10115-024-02128-0,Knowledge and Information Systems,"Road safety remains a critical issue in contemporary society, where the sudden deterioration of road conditions due to weather-related natural phenomena poses significant risks. These abrupt changes can lead to severe safety hazards on the roads, making real-time monitoring and control essential for maintaining road safety. In this context, technological advancements, especially in sensor networks and intelligent systems, play a fundamental role in efficiently managing these challenges. This study introduces an innovative approach that leverages a sophisticated sensor platform coupled with a multi-agent system. This integration facilitates the collection, processing, and analysis of data to preemptively determine the appropriate chemical treatments for roads during severe winter conditions. By employing advanced data analysis and machine learning techniques within a multi-agent framework, the system can predict and respond to adverse weather effects swiftly and with a high degree of accuracy. The proposed system has undergone rigorous testing in a real-world environment, which has verified its operational effectiveness. The results from the deployment of the multi-agent architecture and its predictive capabilities are encouraging, suggesting that this approach could significantly enhance road safety in extreme weather conditions. Furthermore, the proposed architecture allows the system to evolve and scale over time. This paper details the design and implementation of the system, discusses the results of its field tests, and explores potential improvements. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10270-021-00952-4,Software and Systems Modeling,"Modern software systems are increasingly expected to show higher degrees of autonomy and self-management to cope with uncertain and diverse situations. As a consequence, autonomous systems can exhibit unexpected and surprising behaviours. This is exacerbated due to the ubiquity and complexity of Artificial Intelligence (AI)-based systems. This is the case of Reinforcement Learning (RL), where autonomous agents learn through trial-and-error how to find good solutions to a problem. Thus, the underlying decision-making criteria may become opaque to users that interact with the system and who may require explanations about the system’s reasoning. Available work for eXplainable Reinforcement Learning (XRL) offers different trade-offs: e.g. for runtime explanations, the approaches are model-specific or can only analyse results after-the-fact. Different from these approaches, this paper aims to provide an online model-agnostic approach for XRL towards trustworthy and understandable AI. We present ETeMoX, an architecture based on temporal models to keep track of the decision-making processes of RL systems. In cases where the resources are limited (e.g. storage capacity or time to response), the architecture also integrates complex event processing, an event-driven approach, for detecting matches to event patterns that need to be stored, instead of keeping the entire history. The approach is applied to a mobile communications case study that uses RL for its decision-making. In order to test the generalisability of our approach, three variants of the underlying RL algorithms are used: Q-Learning, SARSA and DQN. The encouraging results show that using the proposed configurable architecture, RL developers are able to obtain explanations about the evolution of a metric, relationships between metrics, and were able to track situations of interest happening over time windows. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10270-025-01306-0,Software and Systems Modeling,"Insufficient data volume and quality are particularly pressing challenges in the adoption of modern subsymbolic AI. To alleviate these challenges, AI simulation uses virtual training environments in which AI agents can be safely and efficiently developed with simulated, synthetic data. Digital twins open new avenues in AI simulation, as these high-fidelity virtual replicas of physical systems are equipped with state-of-the-art simulators and the ability to further interact with the physical system for additional data collection. In this article, we report on our systematic survey of digital twin-enabled AI simulation. By analyzing 22 primary studies, we identify technological trends and derive a reference framework to situate digital twins and AI components. Based on our findings, we derive a reference framework and provide architectural guidelines by mapping it onto the ISO 23247 reference architecture for digital twins. Finally, we identify challenges and research opportunities for prospective researchers. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10458-021-09499-6,Autonomous Agents and Multi-Agent Systems,"Microscopic agent-based traffic simulation is an important tool for the efficient and safe resolution of various traffic challenges accompanying the introduction of autonomous vehicles on the roads. Both the variety of questions that can be asked and the quality of answers provided by simulations, however, depend on the underlying models. In mixed traffic, the two most critical models are the models describing the driving behaviour of humans and AVs, respectively. This paper presents AVDM (Autonomous Vehicle Driving Model), a hierarchical AV behaviour model that allows the holistic evaluation of autonomous and mixed traffic by unifying a wide spectrum of AV functionality, including long-term planning, path planning, complex platooning manoeuvres, and low-level longitudinal and lateral control. The model consists of hierarchically layered modules bidirectionally connected by messages and commands. On top, a high-level planning module makes decisions whether to join/form platoons and how to follow the vehicle’s route. A platooning manoeuvres layer guides involved AVs through the manoeuvres chosen to be executed, assisted by the trajectory planning layer, which, after finding viable paths through complex traffic conditions, sends simple commands to the low-level control layer to execute those paths. The model has been implemented in the BEHAVE mixed traffic simulation tool and achieved a 92% success rate for platoon joining manoeuvres in mixed traffic conditions. As a proof of concept, we conducted a mixed traffic simulation study showing that enabling platooning on a highway scenario shifts the velocity-density curve upwards despite the additional lane changing and manoeuvring it induces. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10458-021-09513-x,Autonomous Agents and Multi-Agent Systems,"We present a novel negotiation model that allows an agent to learn how to negotiate during concurrent bilateral negotiations in unknown and dynamic e-markets. The agent uses an actor-critic architecture with model-free reinforcement learning to learn a strategy expressed as a deep neural network. We pre-train the strategy by supervision from synthetic market data, thereby decreasing the exploration time required for learning during negotiation. As a result, we can build automated agents for concurrent negotiations that can adapt to different e-market settings without the need to be pre-programmed. Our experimental evaluation shows that our deep reinforcement learning based agents outperform two existing well-known negotiation strategies in one-to-many concurrent bilateral negotiations for a range of e-market settings. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10462-024-10933-w,Artificial Intelligence Review,"Recently, machine learning has been very useful in solving diverse tasks with drones, such as autonomous navigation, visual surveillance, communication, disaster management, and agriculture. Among these machine learning, two representative paradigms have been widely utilized in such applications: supervised learning and reinforcement learning. Researchers prefer to use supervised learning, mostly based on convolutional neural networks, because of its robustness and ease of use but yet data labeling is laborious and time-consuming. On the other hand, when traditional reinforcement learning is combined with the deep neural network, it can be a very powerful tool to solve high-dimensional input problems such as image and video. Along with the fast development of reinforcement learning, many researchers utilize reinforcement learning in drone applications, and it often outperforms supervised learning. However, it usually requires the agent to explore the environment on a trial-and-error basis which is high cost and unrealistic in the real environment. Recent advances in simulated environments can allow an agent to learn by itself to overcome these drawbacks, although the gap between the real environment and the simulator has to be minimized in the end. In this sense, a realistic and reliable simulator is essential for reinforcement learning training. This paper investigates various drone simulators that work with diverse reinforcement learning architectures. The characteristics of the reinforcement learning-based drone simulators are analyzed and compared for the researchers who would like to employ them for their projects. Finally, we shed light on some challenges and potential directions for future drone simulators. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10462-025-11381-w,Artificial Intelligence Review,"Conventional treatment methods make even the most basic healthcare issues more complicated, which in turn increases the number of parties involved. Classical computing lacks the speed and accuracy needed for effective stakeholder collaboration in COVID-19 healthcare solutions, such as patients, insurance agents, healthcare practitioners, pharmaceutical suppliers, etc. The research uses organizational information processing theory (OIPT) to examine how quantum computing which is applications of artificial intelligence (AI) could transform the healthcare business, creating a more sustainable and less burdened system. The study of quantum computing (QC) has the potential to bring about “quantum leaps,” which might have unforeseen consequences for healthcare. The discovery of new medications, the personalization of medicinal treatments, and the acceleration of DNA sequencing are just a few of the many possible applications of this method. The potential of QC to transform compute-intensive healthcare tasks like drug-discovery, personalized-medicine, DNA-sequencing, medical-imaging, and operational-optimization is the primary focus of this survey paper, which offers the first comprehensive analysis of QCs diverse capabilities in improving healthcare systems. After a thorough literature study, we created taxonomies on the healthcare QC paradigm’s history and supporting technologies, applications, needs, architectures, security, outstanding questions, and future research prospects. We hope that by conducting this survey, researchers with varying levels of experience in quantum computing and healthcare will better understand the state of the art, assess opportunities and threats, and make informed decisions as they develop novel architectures and applications for this emerging field. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10489-020-01674-8,Applied Intelligence,"Configuring databases for efficient querying is a complex task, often carried out by a database administrator. Solving the problem of building indexes that truly optimize database access requires a substantial amount of database and domain knowledge, the lack of which often results in wasted space and memory for irrelevant indexes, possibly jeopardizing database performance for querying and certainly degrading performance for updating. In this paper, we develop the SmartIX architecture to solve the problem of automatically indexing a database by using reinforcement learning to optimize queries by indexing data throughout the lifetime of a database. We train and evaluate SmartIX performance using TPC-H, a standard, and scalable database benchmark. Our empirical evaluation shows that SmartIX converges to indexing configurations with superior performance compared to standard baselines we define and other reinforcement learning methods used in related work. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10489-021-03145-0,Applied Intelligence,"This research work introduces a new intelligent framework for infectious disease detection by exploring various emerging and intelligent paradigms. We propose new deep learning architectures such as entity embedding networks, long-short term memory, and convolution neural networks, for accurately learning heterogeneous medical data in identifying disease infection. The multi-agent system is also consolidated for increasing the autonomy behaviours of the proposed framework, where each agent can easily share the derived learning outputs with the other agents in the system. Furthermore, evolutionary computation algorithms, such as memetic algorithms, and bee swarm optimization controlled the exploration of the hyper-optimization parameter space of the proposed framework. Intensive experimentation has been established on medical data. Strong results obtained confirm the superiority of our framework against the solutions that are state of the art, in both detection rate, and runtime performance, where the detection rate reaches 98% for handling real use cases. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10489-022-03564-7,Applied Intelligence,"Semi-supervised learning (SSL) can utilize a large amount of unlabeled data for self-training and continuous evolution with only a few annotations. This feature makes SSL a potential candidate for dealing with data from changing and real-time environments, where deep-learning models need to be adapting to evolving and nonstable (non-i.i.d.) data streams from the real world, i.e., online evolutive scenarios. However, state-of-the-art SSL methods often have complex model design mechanisms and may cause performance degradation in a generalized and open environment. In an edge computing setup, e.g., typical in modern Internet of Things (IoT) applications, a multi-agent SSL architecture can help resolve generalization problems by sharing knowledge between models. In this paper, we introduce Mutual Match (MM), an online-evolutive SSL algorithm that integrates mutual interactive learning and soft-supervision consistency regularization, as well as unsupervised sample mining. By leveraging extra knowledge in the training process and the interactive collaboration between models, MM surpasses multiple top SSL algorithms in accuracy and convergence efficiency under the same online-evolutive experiment setup. MM simplifies the complexity of model design and follows a unified and easy-to-expandable pipeline, which can be beneficial to tasks with insufficient labeled data and frequently changing data distribution. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10489-022-03631-z,Applied Intelligence,"Analyzing tactical patterns in invasion games using multi-agent spatiotemporal data is a challenging task at the intersection of computer and sports science. A fundamental yet understudied problem in this area is finding an optimal data representation for processing athlete trajectories using machine learning algorithms. In the present work, we address this gap by discussing common representations in use and propose Tactical Graphs, an alternative graph-based format capable of producing integrative, contextualized models for machine learning applications. We provide an in-depth, domain-specific motivation of the proposed data representation scheme and show how this approach exploits inherent data traits. We propose Tactical Graph Networks (TGNets), a light-weight, hybrid machine learning architecture sensitive to player interactions. Our method is evaluated with an extensive ablation study and the first comprehensive state of the art comparison between standard feature, state vector, and image-based methods on the same dataset. Experiments were conducted using real-world football data containing short sequences of defensive play labelled according to the outcome of ball winning attempts. The results indicate that TGNets are on par with state-of-the-art deep learning models while exhibiting only a fraction of their complexity. We further demonstrate that selecting the right data representation is crucial as it has a significant influence on model performance. The theoretical findings and the proposed method provide insights and a strong methodological alternative for all classification, prediction or pattern recognition applications in the areas of collective movement analysis, automated match analysis, and performance analysis. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10489-024-05733-2,Applied Intelligence,"As the use of drones continues to increase, their capabilities pose a threat to airspace safety when they are misused. Deploying AI models for intercepting these unwanted drones becomes crucial. However, these AI models, such as deep learning models, often operate as “black boxes”, making it hard to trust their decision-making system. This also affects end-users’ confidence in these AI systems. In this paper, the explainability of deep reinforcement learning is investigated and a deep reinforcement learning (DRL) method, double deep Q-network with dueling architecture and prioritized experience replay is applied to train the AI models. To make the AI model decisions more transparent and to understand the reasoning behind the AI decisions for counter-drone systems, Shapley Additive Explanations (SHAP) method is implemented. After training the DRL agent, experience replay is visualized, and the absolute SHAP values are calculated to explain the key factors that influence the deep reinforcement learning agent’s choices. The integration of DRL with explainable AI methods such as SHAP demonstrates significant potential for the advancement of robust and efficient counter-drone systems. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10506-007-9033-5,Artificial Intelligence and Law,"In this paper, we present an approach to commonsense causal explanation of stories that can be used for automatically determining the liable party in legal case descriptions. The approach is based on LRICore, a core ontology for law that takes a commonsense perspective. Aside from our thesis that in the legal domain many terms still have a strong commonsense flavour, the descriptions of events in legal cases, as e.g. presented at judicial trials, are cast in commonsense terms as well. We present design principles for representing commonsense causation, and describe a process-based approach to automatic identification of causal relations in stories, which are described in terms of the core ontology. The resulting causal explanation forms a necessary condition for determining the liability and responsibility of agents that play a role in the case. We describe the basic architecture and working of DIRECT, the demonstrator we are constructing to test the validity of our process oriented view on commonsense causation. This view holds that causal relations are in fact abstractions constructed on the basis of our commonsense understanding of physical and mental processes. © 2007 Springer Science+Business Media B.V. © 2008 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10514-017-9660-y,Autonomous Robots,"In this paper, we consider a networked multi-robot system operating in an obstacle populated planar workspace under a single leader-multiple followers architecture. We propose a distributed reconfiguration strategy of the set of connectivity and formation specifications that assures convergence to the desired point, while guaranteeing global connectivity. In particular, we construct a low-level distributed navigation functions based controller that encodes the goals and safety requirements of the system. However, owing to topological obstructions, stable critical points other than the desired one may appear. In such case, we employ a high-level distributed discrete procedure which attempts to solve a distributed constraint satisfaction problem on a local Voronoi partition, providing the necessary reconfiguration for the system to progress towards its goal. Eventually, we show that the system either converges to the desired point or attains a tree configuration with respect to the formation topology, in which case the system switches to a novel controller based on the prescribed performance control technique, that eventually guarantees convergence. Finally, multiple simulation studies clarify and verify the approach. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10514-019-09853-4,Autonomous Robots,"Teleoperating a robot for complex and intricate tasks demands a high mental workload from a human operator. Deploying multiple operators can mitigate this problem, but it can be also a costly solution. Learning from Demonstrations can reduce the human operator’s burden by learning repetitive teleoperation tasks. Yet, the demonstrations via teleoperation tend to be inconsistent compared to other modalities of human demonstrations. In order to handle less consistent and asynchronous demonstrations effectively, this paper proposes a learning scheme based on Dynamic Movement Primitives. In particular, a new Expectation Maximization algorithm which synchronizes and encodes demonstrations with high temporal and spatial variances is proposed. Furthermore, we discuss two shared teleoperation architectures, where, instead of multiple human operators, a learned artificial agent and a human operator share authority over a task while teleoperating cooperatively. The agent controls the more mundane and repetitive motion in the task whereas human takes charge of the more critical and uncertain motion. The proposed algorithm together with the two shared teleoperation architectures (human-synchronized and agent-synchronized shared teleoperation) has been tested and validated through simulation and experiments on 3 Degrees-of-Freedom Phantom-to-Phantom teleoperation. Conclusively, the both proposed shared teleoperation architectures have shown superior performance when compared with the human-only teleoperation for a peg-in-hole task. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10514-022-10078-1,Autonomous Robots,"Self-assembly of modular robotic systems enables the construction of complex robotic configurations to adapt to different tasks. This paper presents a framework for SMORES types of modular robots to efficiently self-assemble into tree topologies. These modular robots form kinematic chains that have been shown to be capable of a large variety of manipulation and locomotion tasks, yet they can reconfigure using a mobile reconfiguration. A desired kinematic topology can be mapped onto a planar pattern with the optimal module assignment based on the modules’ locations, then the mobile reconfiguration assembly process can be executed in parallel. A docking controller is developed to guarantee the success of docking processes. A hybrid control architecture is designed to handle a large number of modules and complex behaviors of each individual, and achieve efficient and robust self-assembly actions. The framework is demonstrated in both hardware and simulation on the SMORES-EP platform. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10514-023-10127-3,Autonomous Robots,"Decentralized multi-robot systems typically perform coordinated motion planning by constantly broadcasting their intentions to avoid collisions. However, the risk of collision between robots varies as they move and communication may not always be needed. This paper presents an efficient communication method that addresses the problem of “when” and “with whom” to communicate in multi-robot collision avoidance scenarios. In this approach, each robot learns to reason about other robots’ states and considers the risk of future collisions before asking for the trajectory plans of other robots. We introduce a new neural architecture for the learned communication policy which allows our method to be scalable. We evaluate and verify the proposed communication strategy in simulation with up to twelve quadrotors, and present results on the zero-shot generalization/robustness capabilities of the policy in different scenarios. We demonstrate that our policy (learned in a simulated environment) can be successfully transferred to real robots. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10586-025-05584-7,Cluster Computing,"Machine learning (ML) transitioned from a purely academic discipline to an applied field, gaining strategic importance in various industries. Meanwhile, Machine Learning Operations (MLOps) has been widely adopted by enterprises as a comprehensive approach for developing and managing machine learning applications. Despite its advantages, challenges remain. The rising demand for flexibility and scalability has led organizations to embrace multi-cloud and hybrid cloud architectures as preferred solutions. However, the autonomous and distributed nature of modern application development, combined with the complexity of training and deploying machine learning models, makes unified operational management impractical, and this will further affect application quality and efficiency. To address these challenges, this paper proposes a framework to manage model training and deployment in a multi-cloud environment. This framework uses a policy-based resource provisioning approach, agent-based application topology reconstruction, and a visualization dashboard. It aims to provide a cloud provider-neutral solution that enhances the quality of application operations. The framework design is introduced, followed by the implementation of a proof-of-concept prototype. Experiments conducted in various empirical scenarios demonstrate that the proposed framework effectively manages deployment resources while providing clear visibility and control across multiple clouds. The results confirm that this framework enhances control over deployment resources and optimizes model deployment efficiency in multi-cloud infrastructure. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10614-016-9607-y,Computational Economics,"This paper studies the emergence of contrarian behavior in information networks in an asset pricing model. Financial traders coordinate on similar behavior, but have heterogeneous price expectations and are influenced by friends. According to a popular belief, they are prone to herding. However, in laboratory experiments subjects use contrarian strategies. Theoretical literature on learning in networks is scarce and cannot explain this conundrum (Panchenko et al. in J Econ Dyn Control 37(12):2623–2642, 2013). The paper follows Anufriev et al. (CeNDEF Working paper 15–07, 2015) and investigates an agent-based model, in which agents forecast price with a simple general heuristic: adaptive and trend extrapolation expectations, with an additional term of (dis-)trust towards their friends’ mood. Agents independently use Genetic Algorithms to optimize the parameters of the heuristic. The paper considers friendship networks of symmetric (regular lattice, fully connected) and asymmetric architecture (random, rewired, star). The main finding is that the agents learn contrarian strategies, which amplifies market turn-overs and hence price oscillations. Nevertheless, agents learn similar behavior and their forecasts remain well coordinated. The model therefore offers a natural interpretation for the difference between the experimental stylized facts and market surveys. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10776-016-0327-y,International Journal of Wireless Information Networks,"Mobile agent data aggregation routing forwards mobile agents in wireless sensor network to collect and aggregate data. The key objective of data aggregation routing is to maximise the number of collected data samples at the same time as minimising network resource consumption and data collection delay. This paper proposes a mobile agent routing protocol, called zone-based mobile agent aggregation. This protocol utilises a bottom-up mobile agent migration scheme in which the mobile agents start their journeys from the centre of the event regions to the sink aiming to reduce the MA itinerary cost and delay and increase data aggregation routing accuracy. In addition, the proposed protocol reduces the impact of network architecture, event source distribution model and/or data heterogeneity on the performance of data aggregation routing. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10845-025-02643-z,Journal of Intelligent Manufacturing,"Fasteners such as screws or nuts play an essential role in product design due to their non-permanent joint behavior. In this context, the search and engagement phase during the automated disassembly of fasteners is crucial since position errors due to the inaccuracy of a fully automated robot cell must be compensated. Additional inaccuracy appears in product-specific mounting situation fasteners, where computer vision cannot capture the situation. This might leads to a time-consuming spiral search. In this regard, a deep reinforcement learning (DRL) approach is proposed to solve the search and engagement task. A deep Q-network (DQN) agent has been trained by using external force–torque sensor values and the intrinsic motor currents of the robot itself. The training has been conducted virtually and continued on the robot to improve the success rate. To find the optimal DQN architecture, we have combined a multilayer perceptron with convolutional neural networks with long short-term memory as feature extractors. Our proposed DRL-based approach is 2 s faster to engage than a spiral search for an initial error of 3 mm. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10846-010-9515-7,Journal of Intelligent and Robotic Systems: Theory and Applications,"A real-time hybrid control architecture for biped humanoid robots is proposed. The architecture is modular and hierarchical. The main robot's functionalities are organized in four parallel modules: perception, actuation, world-modeling, and hybrid control. Hybrid control is divided in three behavior-based hierarchical layers: the planning layer, the deliberative layer, and the reactive layer, which work in parallel and have very different response speeds and planning capabilities. The architecture allows: (1) the coordination of multiple robots and the execution of group behaviors without disturbing the robot's reactivity and responsivity, which is very relevant for biped humanoid robots whose gait control requires real-time processing. (2) The straightforward management of the robot's resources using resource multiplexers. (3) The integration of active vision mechanisms in the reactive layer under control of behavior-dependant value functions from the deliberative layer. This adds flexibility in the implementation of complex functionalities, such as the ones required for playing soccer in robot teams. The architecture is validated using simulated and real Nao humanoid robots. Passive and active behaviors are tested in simulated and real robot soccer setups. In addition, the ability to execute group behaviors in real- time is tested in international robot soccer competitions. © 2010 Springer Science+Business Media B.V. © 2011 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10846-011-9624-y,Journal of Intelligent and Robotic Systems: Theory and Applications,"Shared attention is a type of communication very important among human beings. It is sometimes reserved for the more complex form of communication being constituted by a sequence of four steps: mutual gaze, gaze following, imperative pointing and declarative pointing. Some approaches have been proposed in Human-Robot Interaction area to solve part of shared attention process, that is, the most of works proposed try to solve the first two steps. Models based on temporal difference, neural networks, probabilistic and reinforcement learning are methods used in several works. In this article, we are presenting a robotic architecture that provides a robot or agent, the capacity of learning mutual gaze, gaze following and declarative pointing using a robotic head interacting with a caregiver. Three learning methods have been incorporated to this architecture and a comparison of their performance has been done to find the most adequate to be used in real experiment. The learning capabilities of this architecture have been analyzed by observing the robot interacting with the human in a controlled environment. The experimental results show that the robotic head is able to produce appropriate behavior and to learn from sociable interaction. © 2011 Springer Science+Business Media B.V. © 2012 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10846-015-0304-1,Journal of Intelligent and Robotic Systems: Theory and Applications,"This paper presents a completely autonomous solution to participate in the Indoor Challenge of the 2013 International Micro Air Vehicle Competition (IMAV 2013). Our proposal is a multi-robot system with no centralized coordination whose robotic agents share their position estimates. The capability of each agent to navigate avoiding collisions is a consequence of the resulting emergent behavior. Each agent consists of a ground station running an instance of the proposed architecture that communicates over WiFi with an AR Drone 2.0 quadrotor. Visual markers are employed to sense and map obstacles and to improve the pose estimation based on Inertial Measurement Unit (IMU) and ground optical flow data. Based on our architecture, each robotic agent can navigate avoiding obstacles and other members of the multi-robot system. The solution is demonstrated and the achieved navigation performance is evaluated by means of experimental flights. This work also analyzes the capabilities of the presented solution in simulated flights of the IMAV 2013 Indoor Challenge. The performance of the CVG_UPM team was awarded with the First Prize in the Indoor Autonomy Challenge of the IMAV 2013 competition. © 2016 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10846-022-01747-5,Journal of Intelligent and Robotic Systems: Theory and Applications,"Deep reinforcement learning (DRL) requires large samples and a long training time to operate optimally. Yet humans rarely require long periods of training to perform well on novel tasks, such as computer games, once they are provided with an accurate program of instructions. We used perceptual control theory (PCT) to construct a simple closed-loop model which requires no training samples and training time within a video game study using the Arcade Learning Environment (ALE). The model was programmed to parse inputs from the environment into hierarchically organised perceptual signals, and it computed a dynamic error signal by subtracting the incoming signal for each perceptual variable from a reference signal to drive output signals to reduce this error. We tested the same model across three different Atari games Breakout, Pong and Video Pinball to achieve performance at least as high as DRL paradigms, and close to good human performance. Our study shows that perceptual control models, based on simple assumptions, can perform well without learning. We conclude by specifying a parsimonious role of learning that may be more similar to psychological functioning. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10846-024-02085-4,Journal of Intelligent and Robotic Systems: Theory and Applications,"Navigation and planning for unmanned aerial vehicles (UAVs) based on visual-inertial sensors has been a popular research area in recent years. However, most visual sensors are prone to high error rates when exposed to disturbances such as excessive brightness and blur, which can lead to catastrophic performance drops in perception and motion planning systems. This study proposes a novel framework to address the coupled perception-planning problem in high-risk environments. This achieved by developing algorithms that can automatically adjust the agility of the UAV maneuvers based on the predicted error rate of the pose estimation system. The fundamental idea behind our work is to demonstrate that highly agile maneuvers become infeasible to execute when visual measurements are noisy. Thus, agility should be traded-off with safety to enable efficient risk management. Our study focuses on navigating a quadcopter through a sequence of gates on an unknown map, and we rely on existing deep learning methods for visual gate-pose estimation. In addition, we develop an architecture for estimating the pose error under high disturbance visual inputs. We use the estimated pose errors to train a reinforcement learning agent to tune the parameters of the motion planning algorithm to safely navigate the environment while minimizing the track completion time. Simulation results demonstrate that our proposed approach yields significantly fewer crashes and higher track completion rates compared to approaches that do not utilize reinforcement learning. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10916-025-02255-3,Journal of Medical Systems,"This paper presents a trust-aware architecture for personalized digital health that combines user modeling, symbolic reasoning, and adaptive trust mechanisms. The proposed system uses Blueprint Personas to capture detailed patient profiles, including clinical, behavioral, and emotional traits. These profiles guide an intelligent agent that interacts with patients and healthcare professionals to provide context-sensitive support. Personalization is achieved through an ontology-based reasoning layer that interprets user needs and integrates real-time data from electronic health records, wearable devices, and environmental sources. To promote transparency and foster long-term user engagement, the system includes a formal trust modeling component based on a Reference Ontology of Trust (ROT), allowing the system to flexibly tailor communication strategies in response to user feedback and evolving trust levels. A simulated scenario involving a patient with chronic obstructive pulmonary disease demonstrates how the system delivers proactive and personalized healthcare interventions, such as medication reminders and air quality alerts. While the architecture is modular and designed for scalability, it has not yet been deployed in real-world clinical settings. Empirical validation and integration with clinical platforms remain part of future work. Nevertheless, this ongoing work contributes to the development of explainable and ethically aligned AI systems that enhance autonomy, accessibility, and trust in digital health environments through explainable reasoning. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10994-017-5666-0,Machine Learning,"This article provides the first survey of computational models of emotion in reinforcement learning (RL) agents. The survey focuses on agent/robot emotions, and mostly ignores human user emotions. Emotions are recognized as functional in decision-making by influencing motivation and action selection. Therefore, computational emotion models are usually grounded in the agent’s decision making architecture, of which RL is an important subclass. Studying emotions in RL-based agents is useful for three research fields. For machine learning (ML) researchers, emotion models may improve learning efficiency. For the interactive ML and human–robot interaction community, emotions can communicate state and enhance user investment. Lastly, it allows affective modelling researchers to investigate their emotion theories in a successful AI agent class. This survey provides background on emotion theory and RL. It systematically addresses (1) from what underlying dimensions (e.g. homeostasis, appraisal) emotions can be derived and how these can be modelled in RL-agents, (2) what types of emotions have been derived from these dimensions, and (3) how these emotions may either influence the learning efficiency of the agent or be useful as social signals. We also systematically compare evaluation criteria, and draw connections to important RL sub-domains like (intrinsic) motivation and model-based RL. In short, this survey provides both a practical overview for engineers wanting to implement emotions in their RL agents, and identifies challenges and directions for future emotion-RL research. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10994-023-06413-x,Machine Learning,"In this paper we investigate the use of reinforcement-learning based prediction approaches for a real drinking-water treatment plant. Developing such a prediction system is a critical step on the path to optimizing and automating water treatment. Before that, there are many questions to answer about the predictability of the data, suitable neural network architectures, how to overcome partial observability and more. We first describe this dataset, and highlight challenges with seasonality, nonstationarity, partial observability, and heterogeneity across sensors and operation modes of the plant. We then describe General Value Function (GVF) predictions—discounted cumulative sums of observations–and highlight why they might be preferable to classical n-step predictions common in time series prediction. We discuss how to use offline data to appropriately pre-train our temporal difference learning (TD) agents that learn these GVF predictions, including how to select hyperparameters for online fine-tuning in deployment. We find that the TD-prediction agent obtains an overall lower normalized mean-squared error than the n-step prediction agent. Finally, we show the importance of learning in deployment, by comparing a TD agent trained purely offline with no online updating to a TD agent that learns online. This final result is one of the first to motivate the importance of adapting predictions in real-time, for non-stationary high-volume systems in the real world. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10994-024-06601-3,Machine Learning,"Mobile wireless networks present several challenges for any learning system, due to uncertain and variable device movement, a decentralized network architecture, and constraints on network resources. In this work, we use deep reinforcement learning (DRL) to learn a scalable and generalizable forwarding strategy for such networks. We make the following contributions: (i) we use hierarchical RL to design DRL packet agents rather than device agents to capture the packet forwarding decisions that are made over time and improve training efficiency; (ii) we use relational features to ensure generalizability of the learned forwarding strategy to a wide range of network dynamics and enable offline training; and (iii) we incorporate both forwarding goals and network resource considerations into packet decision-making by designing a weighted reward function. Our results show that the forwarding strategy used by our DRL packet agent often achieves a similar delay per packet delivered as the oracle forwarding strategy and almost always outperforms all other strategies (including state-of-the-art strategies) in terms of delay, even on scenarios on which the DRL agent was not trained. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s10994-024-06647-3,Machine Learning,"Automatically labeling trajectories of multiple agents is key to behavioral analyses but usually requires a large amount of manual annotations. This also applies to the domain of team sport analyses. In this paper, we specifically show how pretraining transformer models improves the classification performance on tracking data from professional soccer. For this purpose, we propose a novel self-supervised masked autoencoder for multiagent trajectories to effectively learn from only a few labeled sequences. Our approach builds upon a factorized transformer architecture for multiagent trajectory data and employs a masking scheme on the level of individual agent trajectories. As a result, our model allows for a reconstruction of masked trajectory segments while being permutation equivariant with respect to the agent trajectories. In addition to experiments on soccer, we demonstrate the usefulness of the proposed pretraining approach on multiagent pose data from entomology. In contrast to related work, our approach is conceptually much simpler, does not require handcrafted features and naturally allows for permutation invariance in downstream tasks. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s11063-020-10399-1,Neural Processing Letters,"The application of traditional 3D reconstruction methods such as structure-from-motion and simultaneous localization and mapping are typically limited by illumination conditions, surface textures, and wide baseline viewpoints in the field of robotics. To solve this problem, many researchers have applied learning-based methods with convolutional neural network architectures. However, simply utilizing convolutional neural networks without taking other measures into account is computationally intensive, and the results are not satisfying. In this study, to obtain the most informative images for reconstruction, we introduce a residual block to a 2D encoder for improved feature extraction, and propose an attentive latent unit that makes it possible to select the most informative image being fed into the network rather than choosing one at random. The recurrent visual attentive network is injected into the auto-encoder network using reinforcement learning. The recurrent visual attentive network pays more attention to useful images, and the agent will quickly predict the 3D volume. This model is evaluated based on both single- and multi-view reconstructions. The experiment results show that the recurrent visual attentive network increases prediction performance in a way that is superior to other alternative methods, and our model has desirable capacity for generalization. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s11063-022-11023-0,Neural Processing Letters,"Covid-19 is now one of the most incredibly intense and severe illnesses of the twentieth century. Covid-19 has already endangered the lives of millions of people worldwide due to its acute pulmonary effects. Image-based diagnostic techniques like X-ray, CT, and ultrasound are commonly employed to get a quick and reliable clinical condition. Covid-19 identification out of such clinical scans is exceedingly time-consuming, labor-intensive, and susceptible to silly intervention. As a result, radiography imaging approaches using Deep Learning (DL) are consistently employed to achieve great results. Various artificial intelligence-based systems have been developed for the early prediction of coronavirus using radiography pictures. Specific DL methods such as CNN and RNN noticeably extract extremely critical characteristics, primarily in diagnostic imaging. Recent coronavirus studies have used these techniques to utilize radiography image scans significantly. The disease, as well as the present pandemic, was studied using public and private data. A total of 64 pre-trained and custom DL models concerning imaging modality as taxonomies are selected from the studied articles. The constraints relevant to DL-based techniques are the sample selection, network architecture, training with minimal annotated database, and security issues. This includes evaluating causal agents, pathophysiology, immunological reactions, and epidemiological illness. DL-based Covid-19 detection systems are the key focus of this review article. Covid-19 work is intended to be accelerated as a result of this study. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s11063-024-11640-x,Neural Processing Letters,"The development of high-stakes decision-making neural agents that interact with complex environments, such as video games, is an important aspect of AI research with numerous potential applications. Reinforcement learning combined with deep learning architectures (DRL) has shown remarkable success in various genres of games. The performance of DRL is heavily dependent upon the neural networks resides within them. Although these algorithms perform well in offline testing but the performance deteriorates in noisy and sub-optimal conditions, creating safety and security issues. To address these, we propose a hybrid deep learning architecture that combines a traditional convolutional neural network with worm brain-inspired neural circuit policies. This allows the agent to learn key coherent features from the environment and interpret its dynamics. The obtained DRL agent was not only able to achieve an optimal policy quickly, but it was also the most noise-resilient with the highest success rate. Our research indicates that only 20 control neurons (12 inter-neurons and 8 command neurons) are sufficient to achieve competitive results. We implemented and analyzed the agent in the popular video game Doom, demonstrating its effectiveness in practical applications. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s11227-022-04484-6,Journal of Supercomputing,"This paper presents a new technique for contextual item-to-item Collaborative Filtering-based Recommender System, an improved version popularised by e-commerce giant Amazon two decades back. The concept is based on items also-viewed under the same browsing session. Users’ browsing patterns, locations, and timestamps are considered as the context and latent factors for each user. The algorithm computes recommendations based on users’ implicit endorsements by clicks. The algorithm does not enforce the user to log in to provide recommendations and is capable of providing accurate recommendations for non-logged-in users and with a setting where the system is unaware of users’ preferences and profile data (non-logged-in users). This research takes the cue from human lifelong incremental learning experience applied to machine learning on a large volume of the data pool. First, all historical data is gathered from collectable sources in a distributed manner through big data tools. Then, a long-running batch job creates the initial model and saves it to Hadoop Distributed File System (HDFS). An ever-running streaming job loads the model from HDFS and builds on top of it in an incremental fashion. At the architectural level, this resembles the big data mix processing Lambda Architecture. The recommendation is computed based on a proposed equation for a weighted sum between near real-time and historical batch data. Real-time and batch processing engines act as autonomous Multi-agent systems in collaboration. We propose an ensemble method for batch-stream the recommendation engine. We introduce a novel Lifelong Learning Model for recommendation through Multi-agent Lambda Architecture. The recommender system incrementally updates its model on streaming datasets to improve over time. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s11235-010-9411-2,Telecommunication Systems,"Broadband access to the Internet at home was the first step in the emergence of so called Home Networks. In a close future, the number of appliance connected will rise and the network will become the home backbone. Its architecture has to evolve to tackle those new challenges. After a study of the network requirements, this paper introduces a complete system to pilot the forwarding ensuring a proper QoS. This is achieved by a knowledge plane composed of agents embedded on devices, which are optimizing the Ethernet layer. © 2011 Springer Science+Business Media, LLC. © 2012 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s11263-021-01437-z,International Journal of Computer Vision,"Embodied computer vision considers perception for robots in novel, unstructured environments. Of particular importance is the embodied visual exploration problem: how might a robot equipped with a camera scope out a new environment? Despite the progress thus far, many basic questions pertinent to this problem remain unanswered: (i) What does it mean for an agent to explore its environment well? (ii) Which methods work well, and under which assumptions and environmental settings? (iii) Where do current approaches fall short, and where might future work seek to improve? Seeking answers to these questions, we first present a taxonomy for existing visual exploration algorithms and create a standard framework for benchmarking them. We then perform a thorough empirical study of the four state-of-the-art paradigms using the proposed framework with two photorealistic simulated 3D environments, a state-of-the-art exploration architecture, and diverse evaluation metrics. Our experimental results offer insights and suggest new performance metrics and baselines for future work in visual exploration. Code, models and data are publicly available. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s11277-020-07657-9,Wireless Personal Communications,"In this paper we present an original adaptive task scheduling system, which optimizes the energy consumption of mobile devices using machine learning mechanisms and context information. The system learns how to allocate resources appropriately: how to schedule services/tasks optimally between the device and the cloud, which is especially important in mobile systems. Decisions are made taking the context into account (e.g. network connection type, location, potential time and cost of executing the application or service). In this study, a supervised learning agent architecture and service selection algorithm are proposed to solve this problem. Adaptation is performed online, on a mobile device. Information about the context, task description, the decision made and its results such as power consumption are stored and constitute training data for a supervised learning algorithm, which updates the knowledge used to determine the optimal location for the execution of a given type of task. To verify the solution proposed, appropriate software has been developed and a series of experiments have been conducted. Results show that as a result of the experience gathered and the learning process performed, the decision module has become more efficient in assigning the task to either the mobile device or cloud resources. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s11517-010-0652-8,Medical and Biological Engineering and Computing,"Due to spectral overlap, the number of fluorescent labels for imaging cryomicrotome detection was limited to 4. The aim of this study was to increase the separation of fluorescent labels. In the new imaging cryomicrotome, the sample is cut in slices of 40 μm. Six images are taken for each cutting plane. Correction for spectral overlap is based on linear combinations of fluorescent images. Locations of microspheres are determined by using the system point spread function. Five differently colored microspheres were injected in vivo distributed over two major coronaries, the left anterior descending and left circumflex artery. Under absence of collateral flow, microspheres outside of target perfusion territories were not found and the procedure did not generate false positive detection when spectral overlap was relevant. In silico-generated microspheres were used to test the effect of background image, transparency correction, and color separation. The percentage of microspheres undetected was 2.3 ± 0.8% in the presence and 1.5 ± 0.4% in the absence of background structures with a density of 900 microspheres per color per cm3. The image analysis method presented here, allows for an increased number of experimental conditions that can be investigated in studies of regional myocardial perfusion. © 2010 The Author(s). © 2010 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s11548-018-01911-z,International Journal of Computer Assisted Radiology and Surgery,"Purpose: Glioblastoma multiforme treatment is a challenging task in clinical oncology. Convection- enhanced delivery (CED) is showing encouraging but still suboptimal results due to drug leakages. Numerical models can predict drug distribution within the brain, but require retrieving brain physical properties, such as the axon diameter distribution (ADD), through axon architecture analysis. The goal of this work was to provide an automatic, accurate and fast method for axon segmentation in electronic microscopy images based on fully convolutional neural network (FCNN) as to allow automatic ADD computation. Methods: The segmentation was performed using a residual FCNN inspired by U-Net and Resnet. The FCNN training was performed exploiting mini-batch gradient descent and the Adam optimizer. The Dice coefficient was chosen as loss function. Results: The proposed segmentation method achieved results comparable with already existing methods for axon segmentation in terms of Information Theoretic Scoring (0.98 %) with a faster training (5 h on the deployed GPU) and without requiring heavy post-processing (testing time was 0.2 s with a non-optimized code). The ADDs computed from the segmented and ground-truth images were statistically equivalent. Conclusions: The algorithm proposed in this work allowed fast and accurate axon segmentation and ADD computation, showing promising performance for brain microstructure analysis for CED delivery optimization. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s11548-023-02843-z,International Journal of Computer Assisted Radiology and Surgery,"Purpose: Minimally invasive treatments for renal carcinoma offer a low rate of complications and quick recovery. One drawback of the use of computed tomography (CT) for needle guidance is the use of iodinated contrast agents, which require an increased X-ray dose and can potentially cause adverse reactions. The purpose of this work is to generalise the problem of synthetic contrast enhancement to allow the generation of multiple phases on non-contrast CT data from a real-world, clinical dataset without training multiple convolutional neural networks. Methods: A framework for switching between contrast phases by conditioning the network on the phase information is proposed and compared with separately trained networks. We then examine how the degree of supervision affects the generated contrast by evaluating three established architectures: U-Net (fully supervised), Pix2Pix (adversarial with supervision), and CycleGAN (fully adversarial). Results: We demonstrate that there is no performance loss when testing the proposed method against separately trained networks. Of the training paradigms investigated, the fully adversarial CycleGAN performs the worst, while the fully supervised U-Net generates more realistic voxel intensities and performed better than Pix2Pix in generating contrast images for use in a downstream segmentation task. Lastly, two models are shown to generalise to intra-procedural data not seen during the training process, also enhancing features such as needles and ice balls relevant to interventional radiological procedures. Conclusion: The proposed contrast switching framework is a feasible option for generating multiple contrast phases without the overhead of training multiple neural networks, while also being robust towards unseen data and enhancing contrast in features relevant to clinical practice. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s11548-025-03339-8,International Journal of Computer Assisted Radiology and Surgery,"Purpose: Autonomous systems in mechanical thrombectomy (MT) hold promise for reducing procedure times, minimizing radiation exposure, and enhancing patient safety. However, current reinforcement learning (RL) methods only reach the carotid arteries, are not generalizable to other patient vasculatures, and do not consider safety. We propose a safe dual-device RL algorithm that can navigate beyond the carotid arteries to cerebral vessels. Methods: We used the Simulation Open Framework Architecture to represent the intricacies of cerebral vessels, and a modified Soft Actor-Critic RL algorithm to learn, for the first time, the navigation of micro-catheters and micro-guidewires. We incorporate patient safety metrics into our reward function by integrating guidewire tip forces. Inverse RL is used with demonstrator data on 12 patient-specific vascular cases. Results: Our simulation demonstrates successful autonomous navigation within unseen cerebral vessels, achieving a 96% success rate, 7.0 s procedure time, and 0.24 N mean forces, well below the proposed 1.5 N vessel rupture threshold. Conclusion: To the best of our knowledge, our proposed autonomous system for MT two-device navigation reaches cerebral vessels, considers safety, and is generalizable to unseen patient-specific cases for the first time. We envisage future work will extend the validation to vasculatures of different complexity and on in vitro models. While our contributions pave the way toward deploying agents in clinical settings, safety and trustworthiness will be crucial elements to consider when proposing new methodology. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s12243-021-00872-w,Annales des Telecommunications/Annals of Telecommunications,"This paper studies the multi-agent resource allocation problem in vehicular networks using non-orthogonal multiple access (NOMA) and network slicing. Vehicles want to broadcast multiple packets with heterogeneous quality-of-service (QoS) requirements, such as safety-related packets (e.g., accident reports) that require very low latency communication, while raw sensor data sharing (e.g., high-definition map sharing) requires high-speed communication. To ensure heterogeneous service requirements for different packets, we propose a network slicing architecture. We focus on a non-cellular network scenario where vehicles communicate by the broadcast approach via the direct device-to-device interface (i.e., sidelink communication). In such a vehicular network, resource allocation among vehicles is very difficult, mainly due to (i) the rapid variation of wireless channels among highly mobile vehicles and (ii) the lack of a central coordination point. Thus, the possibility of acquiring instantaneous channel state information to perform centralized resource allocation is precluded. The resource allocation problem considered is therefore very complex. It includes not only the usual spectrum and power allocation, but also coverage selection (which target vehicles to broadcast to) and packet selection (which network slice to use). This problem must be solved jointly since selected packets can be overlaid using NOMA and therefore spectrum and power must be carefully allocated for better vehicle coverage. To do so, we first provide a mathematical programming formulation and a thorough NP-hardness analysis of the problem. Then, we model it as a multi-agent Markov decision process. Finally, to solve it efficiently, we use a deep reinforcement learning (DRL) approach and specifically propose a deep Q learning (DQL) algorithm. The proposed DQL algorithm is practical because it can be implemented in an online and distributed manner. It is based on a cooperative learning strategy in which all agents perceive a common reward and thus learn cooperatively and distributively to improve the resource allocation solution through offline training. We show that our approach is robust and efficient when faced with different variations of the network parameters and compared to centralized benchmarks. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s12257-020-0383-0,Biotechnology and Bioprocess Engineering,"Viral nanoparticles (VNPs) comprise a variety of mammalian viruses, plant viruses, and bacteriophages, that have been adopted as building blocks and supra-molecular templates in nanotechnology. VNPs demonstrate the dynamic, monodisperse, polyvalent, and symmetrical architectures which represent examples of such biological templates. These programmable scaffolds have been exploited for genetic and chemical manipulation for displaying of targeted moieties together with encapsulation of various payloads for diagnosis or therapeutic intervention. The drug delivery system based on VNPs offer diverse advantages over synthetic nanoparticles, including biocompatibility, biodegradability, water solubility, and high uptake capability. Here we summarize the recent progress of VNPs especially as targeted anticancer vehicles from the encapsulation and surface modification mechanisms, involved viruses and VNPs, to their application potentials. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s12530-017-9178-8,Evolving Systems,"Clustering is a fundamental data processing technique. While clustering of static (vector based) data and of fixed window size time series have been well explored, dynamic clustering of spatiotemporal data has been little researched if at all. Especially when patterns of changes (events) in the data across space and time have to be captured and understood. The paper presents novel methods for clustering of spatiotemporal data using the NeuCube spiking neural network (SNN) architecture. Clusters of spatiotemporal data were created and modified on-line in a continuous, incremental way, where spatiotemporal relationships of changes in variables are incrementally learned in a 3D SNN model and the model connectivity and spiking activity are incrementally clustered. Two clustering methods were proposed for SNN, one performed during unsupervised and one—during supervised learning models. Before submitted to the models, the data is encoded as spike trains, a spike representing a change in the variable value (an event). During the unsupervised learning, the cluster centres were predefined by the spatial locations of the input data variables in a 3D SNN model. Then clusters are evolving during the learning, i.e. they are adapted continuously over time reflecting the dynamics of the changes in the data. In the supervised learning, clusters represent the dynamic sequence of neuron spiking activities in a trained SNN model, specific for a particular class of data or for an individual instance. We illustrate the proposed clustering method on a real case study of spatiotemporal EEG data, recorded from three groups of subjects during a cognitive task. The clusters were referred back to the brain data for a better understanding of the data and the processes that generated it. The cluster analysis allowed to discover and understand differences on temporal sequences and spatial involvement of brain regions in response to a cognitive task. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s12652-019-01439-3,Journal of Ambient Intelligence and Humanized Computing,"The numerous applications of internet of things (IoT) and sensor networks combined with specialized devices used in each has led to a proliferation of domain specific middleware, which in turn creates interoperability issues between the corresponding architectures and the technologies used. But what if we wanted to use a machine learning algorithm to an IoT application so that it adapts intelligently to changes of the environment, or enable a software agent to enrich with artificial intelligence (AI) a smart home consisting of multiple and possibly incompatible technologies? In this work we answer these questions by studying a framework that explores how to simplify the incorporation of AI capabilities to existing sensor-actuator networks or IoT infrastructures making the services offered in such settings smarter. Towards this goal we present eVATAR+, a middleware that implements the interactions within the context of such integrations systematically and transparently from the developers’ perspective. It also provides a simple and easy to use interface for developers to use. eVATAR+ uses JAVA server technologies enhanced by mediator functionality providing interoperability, maintainability and heterogeneity support. We exemplify eVATAR+ with a concrete case study and we evaluate the relative merits of our approach by comparing our work with the current state of the art. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s12652-021-03606-x,Journal of Ambient Intelligence and Humanized Computing,"The COVID-19 outbreak has stimulated the digital transformation of antiquated healthcare system to a smart hospital, enabling the personalised and remote healthcare services. To augment the functionalities of these intelligent healthcare systems, 5G & B5G heterogeneous network has emerged as a robust and reliable solution. But the pivotal challenge for 5G & B5G connectivity solutions is to ensure flexible and agile service orchestration with acknowledged Quality of Experience (QoE). However, the existing radio access technology (RAT) selection strategies are incapacitated in terms of QoE provisioning and Quality of Service (QoS) maintenance. Therefore, an intelligent QoE aware RAT selection architecture based on software-defined wireless networking (SDWN) and edge computing has been proposed for 5G-enabled healthcare network. The proposed model leverages the principles of invalid action masking and multi-agent reinforcement learning to allow faster convergence to QoE optimised RAT selection policy. The analytical evaluation validates that the proposed scheme outperforms the other existing schemes in terms of enhancing personalised user-experience with efficient resource utilisation. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s13042-023-01815-8,International Journal of Machine Learning and Cybernetics,"This work focuses on the operation of picking an object on a table with a mobile manipulator. We use deep reinforcement learning (DRL) to learn a positioning policy for the robot’s base by considering the reachability constraints of the arm. This work extends our first proof-of-concept with the ultimate goal of validating the method on a real robot. Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm is used to model the base controller, and is optimised using the feedback from the MoveIt! based arm planner. The idea is to encourage the base controller to position itself in areas where the arm reaches the object. Following a simulation-to-reality approach, first we create a realistic simulation of the robotic environment in Unity, and integrate it in Robot Operating System (ROS). The drivers for both the base and the arm are also implemented. The DRL-based agent is trained in simulation and, both the robot and target poses are randomised to make the learnt base controller robust to uncertainties. We propose a task-specific setup for TD3, which includes state/action spaces, reward function and neural architectures. We compare the proposed method with the baseline work and show that the combination of TD3 and the proposed setup leads to a 11 % higher success rate than with the baseline, with an overall success rate of 97 %. Finally, the learnt agent is deployed and validated in the real robotic system where we obtain a promising success rate of 75 %. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s13204-022-02422-9,Applied Nanoscience (Switzerland),"Antibacterial agents with low toxicity to normal cells, redox activity and free radical scavenging property are urgently needed to address the global health crisis. The phenomenal conducting nature of graphene is a best fit to enhance the antibacterial properties of metal oxides. In this work, CeO<inf>2</inf> nanotiles and graphene nanoplatelets/CeO<inf>2</inf> nanotiles nanocomposites (G/CeO<inf>2</inf>) have been synthesized by a solvothermal method. The prepared materials have been characterized using XRD, FE-SEM, EDX, and UV–visible spectroscopy techniques to investigate their crystallinity, morphology, composition, and optical bandgap energies. The CeO<inf>2</inf> and G/CeO<inf>2</inf> nanocomposites have also been tested for antibacterial applications. The neat CeO<inf>2</inf> nanotiles sample inhibits the bacterial growth of Pseudomonas aeruginosa and Staphylococcus aureus up to 14.21% and 39.53% respectively. The antibacterial activity was tremendously enhanced using 25% graphene-loaded sample (G/CeO<inf>2</inf>-II) i.e., approximately 83% loss of P. aeruginosa and 89% in case of S. aureus has been observed. This can be attributed to the unique nano-architecture, oxidative stress due to the excellent ability of reversible conversion between the two electronic states of CeO<inf>2</inf> and the stress exerted by the planar graphene and CeO<inf>2</inf> nanotiles. Therefore, the G/CeO<inf>2</inf> nanocomposites can find potential application as nano-antibiotics for controlling pathogens. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s13272-023-00665-y,CEAS Aeronautical Journal,"The novel aircraft architectures for Urban Air Mobility (UAM), combined with pure on-demand operations, mean a significant change in aircraft operation and maintenance compared to traditional airliners. Future flight missions and related variables such as the aircraft position or utilisation are unknown for on-demand operation. Consequently, existing methods to optimise aircraft assignment and maintenance planning cannot be transferred. This study examines the behaviour of an aircraft fleet in an on-demand UAM transport system regarding the interlinking between operation and maintenance. Initially, a potential maintenance schedule for UAM vehicles is deduced. A transport and maintenance simulation is introduced where aircraft are modelled as agents servicing a simple network. As aircraft reach their maintenance intervals, they transfer to one of the maintenance bases and compete for that resource. Since that competition can result in avoidable waiting times, the maintenance costs are extended by running costs for the bases and opportunity costs for missed revenue during these waiting periods. Opportunity costs are cost drivers. To reduce the waiting times, two operational approaches are examined: Extending the opening hours of the maintenance facilities and checking the aircraft earlier to reduce simultaneous maintenance demand. While an extension of operating hours reduces the overall maintenance costs, the adjustment of tasks is more effective to lower waiting times. Thus, an improved system needs to use a combined approach. That combination results in overall maintenance costs of approximately $ 58 per flight hour of which about seven percent account for the opportunity costs. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s41060-017-0088-4,International Journal of Data Science and Analytics,"Today, there are a large number of online discussion fora on the internet which are meant for users to express, discuss and exchange their views and opinions on various topics. For example, news portals, blogs, social media channels such as youtube. typically allow users to express their views through comments. In such fora, it has been often observed that user conversations sometimes quickly derail and become inappropriate such as hurling abuses, passing rude and discourteous comments on individuals or certain groups/communities. Similarly, some virtual agents or bots have also been found to respond back to users with inappropriate messages. As a result, inappropriate messages or comments are turning into an online menace slowly degrading the effectiveness of user experiences. Hence, automatic detection and filtering of such inappropriate language has become an important problem for improving the quality of conversations with users as well as virtual agents. In this paper, we propose a novel deep learning-based technique for automatically identifying such inappropriate language. We especially focus on solving this problem in two application scenarios—(a) Query completion suggestions in search engines and (b) Users conversations in messengers. Detecting inappropriate language is challenging due to various natural language phenomenon such as spelling mistakes and variations, polysemy, contextual ambiguity and semantic variations. For identifying inappropriate query suggestions, we propose a novel deep learning architecture called “Convolutional Bi-Directional LSTM (C-BiLSTM)"" which combines the strengths of both Convolution Neural Networks (CNN) and Bi-directional LSTMs (BLSTM). For filtering inappropriate conversations, we use LSTM and Bi-directional LSTM (BLSTM) sequential models. The proposed models do not rely on hand-crafted features, are trained end-end as a single model, and effectively capture both local features as well as their global semantics. Evaluating C-BiLSTM, LSTM and BLSTM models on real-world search queries and conversations reveals that they significantly outperform both pattern-based and other hand-crafted feature-based baselines. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s41095-019-0135-2,Recurrent 3D attentional networks for end-to-end active object recognition,"Active vision is inherently attention-driven: an agent actively selects views to attend in order to rapidly perform a vision task while improving its internal representation of the scene being observed. Inspired by the recent success of attention-based models in 2D vision tasks based on single RGB images, we address multi-view depth-based active object recognition using an attention mechanism, by use of an end-to-end recurrent 3D attentional network. The architecture takes advantage of a recurrent neural network to store and update an internal representation. Our model, trained with 3D shape datasets, is able to iteratively attend the best views targeting an object of interest for recognizing it. To realize 3D view selection, we derive a 3D spatial transformer network. It is differentiable, allowing training with backpropagation, and so achieving much faster convergence than the reinforcement learning employed by most existing attention-based models. Experiments show that our method, with only depth input, achieves state-of-the-art next-best-view performance both in terms of time taken and recognition accuracy.",TOPIC
10.1007/s41095-021-0210-3,See clearly on rainy days: Hybrid multiscale loss guided multi-feature fusion network for single image rain removal,"The quality of photos is highly susceptible to severe weather such as heavy rain; it can also degrade the performance of various visual tasks like object detection. Rain removal is a challenging problem because rain streaks have different appearances even in one image. Regions where rain accumulates appear foggy or misty, while rain streaks can be clearly seen in areas where rain is less heavy. We propose removing various rain effects in pictures using a hybrid multiscale loss guided multiple feature fusion de-raining network (MSGMFFNet). Specially, to deal with rain streaks, our method generates a rain streak attention map, while preprocessing uses gamma correction and contrast enhancement to enhanced images to address the problem of rain accumulation. Using these tools, the model can restore a result with abundant details. Furthermore, a hybrid multiscale loss combining L1 loss and edge loss is used to guide the training process to pay attention to edge and content information. Comprehensive experiments conducted on both synthetic and real-world datasets demonstrate the effectiveness of our method.",TOPIC
10.1007/s41109-023-00542-x,Applied Network Science,"Problem setting: Stochastic dynamical systems in which local interactions give rise to complex emerging phenomena are ubiquitous in nature and society. This work explores the problem of inferring the unknown interaction structure (represented as a graph) of such a system from measurements of its constituent agents or individual components (represented as nodes). We consider a setting where the underlying dynamical model is unknown and where different measurements (i.e., snapshots) may be independent (e.g., may stem from different experiments). Method: Our method is based on the observation that the temporal stochastic evolution manifests itself in local patterns. We show that we can exploit these patterns to infer the underlying graph by formulating a masked reconstruction task. Therefore, we propose GINA (Graph Inference Network Architecture), a machine learning approach to simultaneously learn the latent interaction graph and, conditioned on the interaction graph, the prediction of the (masked) state of a node based only on adjacent vertices. Our method is based on the hypothesis that the ground truth interaction graph—among all other potential graphs—allows us to predict the state of a node, given the states of its neighbors, with the highest accuracy. Results: We test this hypothesis and demonstrate GINA’s effectiveness on a wide range of interaction graphs and dynamical processes. We find that our paradigm allows to reconstruct the ground truth interaction graph in many cases and that GINA outperforms statistical and machine learning baseline on independent snapshots as well as on time series data. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s42452-025-06515-2,Discover Applied Sciences,"Conversational agents play a crucial role in advising clients and providing treatment for mental health issues. In Ethiopia, a developing country with a high prevalence of mental health issues, an AI text-based chatbot has been developed to assist users in addressing these cases. The bot recognizes features such as general knowledge queries, potential mental disorders, auto-generated advice, and client stories. The syntactic and semantic structure of data and user chat's memory network were investigated. Four neural networks (LSTM, single GRU, transposed GRU and double GRU) were experimented with to find the best-fitting deep learning model. The approach uses Amharic word2vec word embedding techniques (skip gram and CBOW) for semantic extraction of Amharic words and a seq2seq model for response generation. An ensemble architecture of generative-based and retrieval-based approaches was employed to handle user dialogue. The scruffy technique was used to generate word embedding, which was then used to extract semantically comparable terms. The model also embedded custom rules for smoothness and error handling. The performance and outcomes of the chatbot were evaluated using cross-validation, data organization, perplexity, accuracy measurement, f-1 score (precision and recall), and human-evaluation methods. The model's accuracy was 79.62%, with a 79.62% likelihood of delivering relevant responses. The results show that the ensemble architecture based on seq2seq modeling with embedded custom rules and Amharic word vector implementation provides pertinent responses for user utterances. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s42484-024-00181-0,Quantum Machine Intelligence,"In the field of quantum computing, variational quantum algorithms (VQAs) represent a pivotal category of quantum solutions across a broad spectrum of applications. These algorithms demonstrate significant potential for realising quantum computational advantage. A fundamental aspect of VQAs involves formulating expressive and efficient quantum circuits (namely ansatz), and automating the search of such ansatz is known as quantum architecture search (QAS). Recently reinforcement learning (RL) techniques is utilized to automate the search for ansatzes, know as RL-QAS. This study investigates RL-QAS for crafting ansatz tailored to the variational quantum state diagonalisation problem. Our investigation includes a comprehensive analysis of various dimensions, such as the entanglement thresholds of the resultant states, the impact of initial conditions on the performance of RL-agent, the phase transition behaviour of correlation in concurrence bounds, and the discrete contributions of qubits in deducing eigenvalues through conditional entropy metrics. We leverage these insights to devise an entanglement-guided admissible ansatz in QAS to diagonalise random quantum states using optimal resources. Furthermore, the methodologies presented herein offer a generalised framework for constructing reward functions within RL-QAS applicable to variational quantum algorithms. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s42484-025-00306-z,Quantum Machine Intelligence,"Recent progress in quantum machine learning has sparked interest in using quantum methods to tackle classical control problems via quantum reinforcement learning. However, the classical reinforcement learning environments often scale to high-dimensional problem spaces, which represents a challenge for the limited and costly resources available for quantum agent implementations. We propose to solve this dimensionality challenge by a classical autoencoder and a quantum agent together, where a compressed representation of observations is jointly learned in a hybrid training loop. The latent representation of such an autoencoder will serve as a tailored observation space best suited for both the control problem and the QPU architecture, aligning with the agent’s requirements. A series of numerical experiments are designed for a performance analysis of the latent space learning method. Results are presented for different control problems and for both photonic (continuous-variable) and qubit-based agents, to show how the QNN learning process is improved by the joint training. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s43503-025-00072-8,AI in Civil Engineering,"The expansion of rail transport infrastructures necessitates accurate and efficient soil surveys to ensure long-term stability and performance, particularly in regions prone to soil heaving. This study aimed to demonstrate the potential of non-destructive spectral analysis combined with Agentic Artificial Intelligence for automating the identification of soil heaving potential, providing a transformative approach to soil assessment in railway construction. A robust AI-agent was developed to predict soil heaving potential across temperature regimes (ranging from 0°C to -5°C and back), enabling characterization of the relative acoustic compressibility coefficient (β) based on the physical and mechanical properties of the soil. The main objective was to develop a framework that integrated spectral reflectance data with machine learning algorithms to predict soil heaving potential and reduce the reliance on traditional invasive methods. The experimental setup employed digital techniques to process and record longitudinal and transverse acoustic pulse signals reflected from piezoelectric sensors mounted on soil specimens. The processed signals were automatically transferred via a USB adapter to a PC for further analysis by the AI-agent. Acoustic diagnostics of the soils were performed using Fast-Fourier Transform (FFT) Spectral Analysis, followed by correlation of waveform spectra with heaving deformation. The AI-agent utilized a hybrid architecture combining Convolutional Neural Network (CNN), Support Vector Machine (SVM), and Random Forest (RF) algorithms to address the complexities of heterogeneous soil data and multifaceted prediction tasks—including heaving classification and deformation regression—while mitigating overfitting. Soil heaving potential was accurately predicted by the AI agent, with minor variations attributed to equipment sensitivity. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s44443-025-00248-3,Journal of King Saud University - Computer and Information Sciences,"To address the challenges of local congestion and imbalanced resource allocation in UAV-assisted air-ground integrated networks, this study constructs a three-layer network architecture comprising ground edge servers, UAVs, and users. A two-stage optimization framework is proposed, incorporating the node selection and task offloading strategies. First, to mitigate the computational resource limitations arising from the dynamic distribution of multiple users, an evolutionary game-based node selection algorithm is developed to achieve effective dynamic load balancing across offloading nodes. Subsequently, the joint task offloading and power allocation problem is formulated as a Markov decision process, and a reinforcement learning algorithm based on MATD3 is designed to attain the joint optimal control of user offloading ratios and transmission power levels. Simulation results demonstrate that the proposed framework reduces total delay and energy consumption by approximately 33.4% and 29.4%, respectively, outperforming the existing strategies. The framework demonstrates superior scalability and energy efficiency in task-intensive scenarios. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.aei.2023.102185,Advanced Engineering Informatics,"Industry 4.0 is helping to unleash a new age of digitalization across industries, leading to a data-driven, interoperable, and decentralized production process. To achieve this major transformation, one of the main requirements is to achieve interoperability across various systems and multiple devices. Ontologies have been used in numerous industrial projects to tackle the interoperability challenge in digital manufacturing. However, there is currently no semantic model in the literature that can be used to represent the industrial production workflow comprehensively while also integrating digitalized information from a variety of systems and contexts. To fill this gap, this paper proposed industrial production workflow ontologies (InPro) for formalizing and integrating production process information. We implemented the 5 M model (manpower, machine, material, method, and measurement) for InPro partitioning and module extraction. The InPro comprises seven main domain ontology modules including Entities, Agents, Machines, Materials, Methods, Measurements, and Production Processes. The Machines ontology module was developed leveraging the OPC Unified Architecture (OPC UA) information model. The presented InPro ontology was further evaluated by a hybrid combination of approaches. Additionally, the InPro ontology was implemented with practical use cases to support production planning and failure analysis by retrieving relevant information via SPARQL queries. The validation results also demonstrated that using the proposed InPro ontology allows for efficiently formalizing, integrating, and retrieving information within the industrial production process context. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.arcontrol.2022.01.001,Annual Reviews in Control,"The rapid growth in the number of devices and their connectivity has enlarged the attack surface and made cyber systems more vulnerable. As attackers become increasingly sophisticated and resourceful, mere reliance on traditional cyber protection, such as intrusion detection, firewalls, and encryption, is insufficient to secure the cyber systems. Cyber resilience provides a new security paradigm that complements inadequate protection with resilience mechanisms. A Cyber-Resilient Mechanism (CRM) adapts to the known or zero-day threats and uncertainties in real-time and strategically responds to them to maintain the critical functions of the cyber systems in the event of successful attacks. Feedback architectures play a pivotal role in enabling the online sensing, reasoning, and actuation process of the CRM. Reinforcement Learning (RL) is an important gathering of algorithms that epitomize the feedback architectures for cyber resilience. It allows the CRM to provide dynamic and sequential responses to attacks with limited or without prior knowledge of the environment and the attacker. In this work, we review the literature on RL for cyber resilience and discuss the cyber-resilient defenses against three major types of vulnerabilities, i.e., posture-related, information-related, and human-related vulnerabilities. We introduce moving target defense, defensive cyber deception, and assistive human security technologies as three application domains of CRMs to elaborate on their designs. The RL algorithms also have vulnerabilities themselves. We explain the major vulnerabilities of RL and present develop several attack models where the attacker target the information exchanged between the environment and the agent: the rewards, the state observations, and the action commands. We show that the attacker can trick the RL agent into learning a nefarious policy with minimum attacking effort. The paper introduces several defense methods to secure the RL-enabled systems from these attacks. However, there is still a lack of works that focuses on the defensive mechanisms for RL-enabled systems. Last but not least, we discuss the future challenges of RL for cyber security and resilience and emerging applications of RL-based CRMs. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.artint.2024.104100,Artificial Intelligence,"In this paper we investigate the properties of representations learned by deep reinforcement learning systems. Much of the early work on representations for reinforcement learning focused on designing fixed-basis architectures to achieve properties thought to be desirable, such as orthogonality and sparsity. In contrast, the idea behind deep reinforcement learning methods is that the agent designer should not encode representational properties, but rather that the data stream should determine the properties of the representation—good representations emerge under appropriate training schemes. In this paper we bring these two perspectives together, empirically investigating the properties of representations that support transfer in reinforcement learning. We introduce and measure six representational properties over more than 25,000 agent-task settings. We consider Deep Q-learning agents with different auxiliary losses in a pixel-based navigation environment, with source and transfer tasks corresponding to different goal locations. We develop a method to better understand why some representations work better for transfer, through a systematic approach varying task similarity and measuring and correlating representation properties with transfer performance. We demonstrate the generality of the methodology by investigating representations learned by a Rainbow agent that successfully transfers across Atari 2600 game modes. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.artint.2024.104201,Artificial Intelligence,"Many autonomous systems are safety-critical, making it essential to have a closed-loop control system that satisfies constraints arising from underlying physical limitations and safety aspects in a robust manner. However, this is often challenging to achieve for real-world systems. For example, autonomous ships at sea have nonlinear and uncertain dynamics and are subject to numerous time-varying environmental disturbances such as waves, currents, and wind. There is increasing interest in using machine learning-based approaches to adapt these systems to more complex scenarios, but there are few standard frameworks that guarantee the safety and stability of such systems. Recently, predictive safety filters (PSF) have emerged as a promising method to ensure constraint satisfaction in learning-based control, bypassing the need for explicit constraint handling in the learning algorithms themselves. The safety filter approach leads to a modular separation of the problem, allowing the use of arbitrary control policies in a task-agnostic way. The filter takes in a potentially unsafe control action from the main controller and solves an optimization problem to compute a minimal perturbation of the proposed action that adheres to both physical and safety constraints. In this work, we combine reinforcement learning (RL) with predictive safety filtering in the context of marine navigation and control. The RL agent is trained on path-following and safety adherence across a wide range of randomly generated environments, while the predictive safety filter continuously monitors the agents' proposed control actions and modifies them if necessary. The combined PSF/RL scheme is implemented on a simulated model of Cybership II, a miniature replica of a typical supply ship. Safety performance and learning rate are evaluated and compared with those of a standard, non-PSF, RL agent. It is demonstrated that the predictive safety filter is able to keep the vessel safe, while not prohibiting the learning rate and performance of the RL agent. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.artmed.2008.03.006,Artificial Intelligence in Medicine,"Objective: Evaluate KNAVE-II, a knowledge-based framework for visualization, interpretation, and exploration of longitudinal clinical data, clinical concepts and patterns. KNAVE-II mediates queries to a distributed temporal-abstraction architecture (IDAN), which uses a knowledge-based problem-solving method specializing in on-the-fly computation of clinical queries. Methods: A two-phase, balanced cross-over study to compare efficiency and satisfaction of a group of clinicians when answering queries of variable complexity about time-oriented clinical data, typical for oncology protocols, using KNAVE-II, versus standard methods: both paper charts and a popular electronic spreadsheet (ESS) in Phase I; an ESS in Phase II. The measurements included the time required to answer and the correctness of answer for each query and each complexity category, and for all queries, assessed versus a predetermined gold standard set by a domain expert. User satisfaction was assessed by the Standard Usability Score (SUS) tool-specific questionnaire and by a ""Usability of Tool Comparison"" comparative questionnaire developed for this study. Results: In both evaluations, subjects answered higher-complexity queries significantly faster using KNAVE-II than when using paper charts or an ESS up to a mean of 255 s difference per query versus the ESS for hard queries (p = 0.0003) in the second evaluation. Average correctness scores when using KNAVE-II versus paper charts, in the first phase, and the ESS, in the second phase, were significantly higher over all queries. In the second evaluation, 91.6% (110/120) of all of the questions asked within queries of all levels produced correct answers using KNAVE-II, opposed to only 57.5% (69/120) using the ESS (p < 0.0001). User satisfaction with KNAVE-II was significantly superior compared to using either a paper chart or the ESS (p = 0.006). Clinicians ranked KNAVE-II superior to both paper and the ESS. Conclusions: An evaluation of the functionality and usability of KNAVE-II and its supporting knowledge-based temporal-mediation architecture has produced highly encouraging results regarding saving of physician time, enhancement of accuracy of clinical assessment, and user satisfaction. © 2008 Elsevier B.V. All rights reserved. © 2008 Elsevier B.V., All rights reserved.; MEDLINE® is the source for the MeSH terms of this document.",TOPIC
10.1016/j.asej.2021.04.025,Ain Shams Engineering Journal,"Unmanned Aerial Vehicle/Unmanned Ground Vehicle heterogeneous collaborative system can complete complex tasks. In order to monitor and control the two agents simultaneously, a comprehensive ground station is designed. First, the preliminary work is introduced. Then, the architecture of the ground station of the system is proposed. In data communication module, since the amount of data from the system is large, the data of structure and multi-threaded processing are designed in detail. In data display module, the ground station provides various ways for displaying data. In image display module, in order to balance the accuracy and real-time performance of the system, an Efficient Convolution Operators tracking algorithm is improved for tracking moving target. In digital map module, a three-dimensional path planning method based on improved Ant Colony is proposed. The experiment results show that the ground station works well in real-time performance and accuracy. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.asej.2025.103595,Ain Shams Engineering Journal,"Reinforcement Learning (RL)-based control plays a pivotal role in developing adaptive robotic systems capable of optimal decision-making in dynamic and uncertain environments. Its ability to learn directly from interaction makes RL particularly effective for handling complex control tasks where traditional model-based approaches often fall short. However, conventional RL algorithms typically suffer from slow convergence rates and may lack stability guarantees, especially in continuous control applications. To address these limitations, this paper proposes a novel RL-based control framework for a 4-DOF robotic manipulator, leveraging an improved Physics-Informed Deep Deterministic Policy Gradient (PI-DDPG) agent for precise trajectory tracking. The proposed agent integrates Physics-Informed Neural Networks (PINNs) into the RL architecture, allowing it to exploit prior knowledge of the system's dynamics to significantly accelerate convergence. Furthermore, a Lyapunov-based reward shaping strategy is introduced to enhance the stability and reliability of the learning process without compromising optimality. An adaptive noise generation technique is also proposed to dynamically regulate exploration, improving the agent's ability to discover effective control actions. The effectiveness of the PI-DDPG framework is validated through both simulation and real-world experiments. Results show a 20–30% improvement in tracking accuracy and a threefold (x3) reduction in convergence time compared to baseline RL approaches, demonstrating the potential of physics-informed reinforcement learning for high-performance and robust robotic control. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.asoc.2010.12.003,Applied Soft Computing,"Security is a major concern when service environments are implemented. This has led to the proposal of a variety of specifications and proposals based on soft computing methods to provide the necessary security for these environments. However, most proposed approaches focus only on ensuring confidentiality and integrity, without putting forward mechanisms that ensure the availability of services and resources offered. A considerable number of attack mechanisms can lead to a web service system crash. As a result, the web service cannot allow access to authorized users. This type of attack is a so-called denial of service attack (DoS) which affects the availability of the services and recourses available. This article presents a novel soft computing-based approach to cope with DoS attacks, but unlike existing solutions, our proposal takes into account the different soft computing mechanisms that can lead to a DoS attack. Our approach is based on a real time classifier agent that incorporates a mixture of experts to choose a specific classification technique depending on the feature of the attack and the time available to solve the classification. With this scheme it is possible to divide the problem into subproblems, solving the classification of the web service requests in a more simple and effective way and always within a time bound interval. This research presents a case study to evaluate the effectiveness of the approach and also presents the preliminary results obtained with an initial prototype. © 2010 Elsevier B.V. All rights reserved. © 2011 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.asoc.2022.109382,Applied Soft Computing,"Mechanical discontinuity embedded in a material determines the bulk mechanical, physical, and chemical properties. Under external forces, mechanical discontinuity undergo spatiotemporal propagation; thereby altering various properties of the material. This paper is a proof-of-concept development and deployment of a reinforcement learning framework, based on deep deterministic policy gradient, to precisely control both the direction and rate of the fatigue crack growth. The ability to control mechanical discontinuity in essence determines the key material properties. The desired control is relatively hard to achieve considering the large, continuous state and action spaces along with the exponential relationship between crack growth and stress cycle. The reinforcement-learning scheme is capable of learning an optimal and computational tractable control strategy. In the proposed approach, the reinforcement learning framework is integrated into an OpenAI-Gym-based environment that implements the mechanistic equations governing the fatigue crack growth. The learning agent does not explicitly know about the underlying physics, nonetheless, the learning agent can infer the control strategy by continuously interacting the numerical environment. The paper formulates an adaptive reward function involving reward shaping that can be generalized to similar control problems to improve the training efficiency. The reinforcement learning framework can successfully control the fatigue crack growth in a material despite the complexity of the propagation/growth pathway determined by multiple goal points. The paper provides the mathematical/physical basis of the reward function and the effect of neural network size and architecture and the state and action space that boosts the training speed while preserving the stability of the RL agents for the desired control problem. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.asoc.2023.110631,Applied Soft Computing,"Multi-objective optimisation (MOO) is a popular approach for finding solutions to many types of complex problems with large search spaces and conflicting search objectives. In the past, MOO algorithms have been shown to reliably produce good optimisation results. With the rise of cyber–physical systems, however, emerges the new challenge of non-deterministic system executions, caused by e.g. imperfect sensor readings or synchronisation in multi-process/multi-agent system architectures. These systems produce varying output on each execution, causing the algorithms’ observations to be noisy. Naturally, MOO algorithms favour the fittest solutions, which may have been measured with great inaccuracy. The end results are therefore not trustworthy. In this paper, we propose kNN-averaging, a new method to address this issue by identifying the k-nearest neighbours (kNN) of a solution, and using their weighted average as an estimate for its true fitness. Our experiments demonstrate the viability of kNN-averaging on 40 synthetic benchmark problems and on a real-world case study system. In the process, we compare kNN-averaging to the noisy baseline as well as two resampling-based methods and one spectral sampling approach on a range of algorithm settings. The results show that kNN-averaging approximates the fitness of solutions more accurately than the noisy baseline, leading to more trustworthy results. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.asoc.2024.111843,Applied Soft Computing,"This paper proposes a novel Reinforcement Learning (RL) approach for sim-to-real policy transfer of Vertical Take-Off and Landing Unmanned Aerial Vehicle (VTOL-UAV). The proposed approach is designed for VTOL-UAV landing on offshore docking stations in maritime operations. VTOL-UAVs in maritime operations encounter limitations in their operational range, primarily stemming from constraints imposed by their battery capacity. The concept of autonomous landing on a charging platform presents an intriguing prospect for mitigating these limitations by facilitating battery charging and data transfer. However, current Deep Reinforcement Learning (DRL) methods exhibit drawbacks, including lengthy training times, and modest success rates. In this paper, we tackle these concerns comprehensively by decomposing the landing procedure into a sequence of more manageable but analogous tasks in terms of an approach phase and a landing phase. The proposed architecture utilizes a model-based control scheme for the approach phase, where the VTOL-UAV is approaching the offshore docking station. In the Landing phase, DRL agents were trained offline to learn the optimal policy to dock on the offshore station. The Joint North Sea Wave Project (JONSWAP) spectrum model has been employed to create a wave model for each episode, enhancing policy generalization for sim2real transfer. A set of DRL algorithms have been tested through numerical simulations including value-based agents and policy-based agents such as Deep Q Networks (DQN) and Proximal Policy Optimization (PPO) respectively. The numerical experiments show that the PPO agent can learn complicated and efficient policies to land in uncertain environments, which in turn enhances the likelihood of successful sim-to-real transfer. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.asr.2022.11.048,Advances in Space Research,"The growing ferment towards enhanced autonomy on-board spacecrafts is driving the research of leading space agencies. Concurrently, the rapid developments of Artificial Intelligence (AI) are strongly influencing the aerospace researches, regarding on-orbit servicing (OOS) activities above all. Within the wide spectrum of OOS and proximity operations, this work focuses on autonomous guidance of a chaser spacecraft for the map reconstruction of an artificial uncooperative target. Adaptive guidance is framed as an active Simultaneous Localization and Mapping (SLAM) problem and modeled as a Partially Observable Markov Decision Process (POMDP). A state-of-the-art Deep Reinforcement Learning (DRL) method, Proximal Policy Optimization (PPO), is investigated to develop an agent capable of cleverly planning the shape reconstruction of the uncooperative space object. The guidance algorithm performance are evaluated in terms of target map reconstruction, by rendering the space object with a triangular mesh and then considering the number of quality images for each face. A major differentiation in the algorithm implementation is provided by the employment of either a discrete or a continuous action space. The main differences between the two cases are critically commented and the benefits of a continuous action space are highlighted. The proposed model is trained and then extensively tested, always starting from random initial conditions, to verify the generalizing capabilities of the DRL agent, by means of the neural network architecture. On this note, a comparison analysis between a Feed-forward Neural Networks (FFNN) and a Recurrent Neural Network (RNN) is performed. The better performing model is retrieved from the aforementioned comparisons, and its robustness and sensitivity are sharply analyzed. This work confirms and develops further the applicability of DRL techniques for autonomous guidance, highlighting in a critical way its possible implementation in future close proximity scenarios. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.autcon.2021.103701,Automation in Construction,"Reinforcement learning (RL) - a branch of machine learning - refers to the process of an agent learning to achieve a certain goal by interaction with its environment. The process of conventional tunneling shows many similarities, where a geotechnician (agent) tries to achieve a breakthrough (goal) by excavating the rockmass (environment) in an optimum way. In this paper we present a novel RL based framework for strategy development for conventional tunneling. We developed a virtual environment with the goal of a tunnel breakthrough and with a deep Q-network as the agent's architecture. It can choose from different excavation sequences to reach that goal and learns to do so in an economical and safe way by getting feedback from a specially designed reward system. Result analyses show that the optimal policies have great similarities to current practices of sequential tunneling and the framework has the potential to discover new tunneling strategies. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.automatica.2013.08.006,Automatica,"This paper considers a network of vehicles moving in a two dimensional plane. The overall network, described by a collection of double integrator dynamics, is controlled by a novel distributed static output feedback methodology to maintain a desired formation. The distributed control architecture stabilizes the network using static output feedback of position information only, by exploiting delays in communication of the relative information. An optimization algorithm, based on Linear Matrix Inequalities together with the DIRECT search algorithm, is used to synthesize the controller gains and the delay.© 2013 Elsevier Ltd. All rights reserved. © 2013 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.bios.2022.114750,Biosensors and Bioelectronics,"Brain organoids are powerful experimental models to study fundamental neurodevelopmental processes and the pathology of neurological disorders. Brain organoids can now be generated from human-induced pluripotent stem cells, which pave the way for using them to investigate effective therapies for various neurodegenerative disorders and diseases. However, brain organoids possess complex cellular architecture, various unknown functionalities, and a lack of vascular networks, which have limited their use in biomedicine and clinical research. Micro/nanoscale devices and technologies can help overcome these limitations. This review critically examines recently developed micro/nano devices for integration with brain organoids. The review focuses on devices designed to achieve several key aims: to improve methodologies for in vitro culture; to enable electrophysiological recordings from organoids; to screen drugs for chemotherapy and new treatments; to understand the effects of psychoactive drugs; and to enable development of vascular networks in organoids. Along with the specific device features and their relevance for these applications, we also discuss the current challenges to overcome and future strategies to advance the use of brain organoids in clinical research. The interdisciplinary convergence of brain organoids research with materials science, device engineering, neuroscience, and stem cell biology holds remarkable potential for replicating the human brain in vitro. Micro/nano devices are an important part of realizing this potential that will afford both fundamental insights into the mechanisms underlying brain function and a pathway for developing novel treatments for neurophysiological and neurodegenerative disorders. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.buildenv.2021.108495,Building and Environment,"Recent evidence suggests that SARS-CoV-2, which is the virus causing a global pandemic in 2020, is predominantly transmitted via airborne aerosols in indoor environments. This calls for novel strategies when assessing and controlling a building's indoor air quality (IAQ). IAQ can generally be controlled by ventilation and/or policies to regulate human–building-interaction. However, in a building, occupants use rooms in different ways, and it may not be obvious which measure or combination of measures leads to a cost- and energy-effective solution ensuring good IAQ across the entire building. Therefore, in this article, we introduce a novel agent-based simulator, ArchABM, designed to assist in creating new or adapt existing buildings by estimating adequate room sizes, ventilation parameters and testing the effect of policies while taking into account IAQ as a result of complex human–building interaction patterns. A recently published aerosol model was adapted to calculate time-dependent carbon dioxide (CO<inf>2</inf>) and virus quanta concentrations in each room and inhaled CO<inf>2</inf> and virus quanta for each occupant over a day as a measure of physiological response. ArchABM is flexible regarding the aerosol model and the building layout due to its modular architecture, which allows implementing further models, any number and size of rooms, agents, and actions reflecting human–building interaction patterns. We present a use case based on a real floor plan and working schedules adopted in our research center. This study demonstrates how advanced simulation tools can contribute to improving IAQ across a building, thereby ensuring a healthy indoor environment. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.cad.2011.06.011,CAD Computer Aided Design,"With the development of computer applications in ship design, optimization, as a powerful approach, has been widely used in the design and analysis process. However, the running time, which often varies from several weeks to months in the current computing environment, has been a bottleneck problem for optimization applications, particularly in the structural design of ships. To speed up the optimization process and adjust the complex design environment, ship designers usually rely on their personal experience to assist the design work. However, traditional experience, which largely depends on the designer's personal skills, often makes the design quality very sensitive to the experience and decreases the robustness of the final design. This paper proposes a new machine-learning-based ship design optimization approach, which uses machine learning as an effective tool to give direction to optimization and improves the adaptability of optimization to the dynamic design environment. The natural human learning process is introduced into the optimization procedure to improve the efficiency of the algorithm. Q-learning, as an approach of reinforcement learning, is utilized to realize the learning function in the optimization process. The multi-objective particle swarm optimization method, multi-agent system, and CAE software are used to build an integrated optimization system. A bulk carrier structural design optimization was performed as a case study to evaluate the suitability of this method for real-world application. © 2011 Elsevier Ltd. All rights reserved. © 2012 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.cej.2018.11.235,Chemical Engineering Journal,"Hard carbon powders with hierarchical mesoporous structure from resorcinol-formaldehyde polymer were successfully prepared by use of double pore forming method. Poly-diallyldimethylammonium chloride (pDADMAC) and commercial silica (Sipernat® 50) were used as structuring agent and hard template, respectively. Through the proposed procedure carbon powder with bimodal mesoporous size distribution (around 4–5 nm and 20–40 nm) and different pore volume ratios can be obtained, by changing the ratio pDADMAC/silica used in the synthesis. Pore volumes between 0.70 and 2.10 cm3·g−1, and specific surface areas between 662 and 998 m2·g−1 were obtained. Raman spectroscopy and X-Ray diffraction analysis showed that all the carbons presented a non-ordered mesopore structure, and a hard carbon micro-structure with roughly 40% of single-layer microstructures, an average of 2.6 stacked graphene layers, and an in-plane graphitic crystallite size around 3.4 nm. We have evaluated the adsorption of methylene blue, as a model of a pollutant dye, on the mesoporous carbons with different pore size distribution, and we found that carbons with bimodal pore size distribution exhibit a remarkable and irreversible adsorption capacity. Microporosity can help to enhance the adsorption capacity, provided that micropores are connected to mesopores, allowing the adsorbate to get deep into the carbon structure. The adsorption kinetic is very fast for carbons with such pore architecture, and can be well described by a three-stage intraparticle diffusion model. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.cie.2025.111464,Computers and Industrial Engineering,"This paper addresses the online 2D Strip Packing Problem (2D-SPP), where rectangular items must be packed sequentially into a strip of fixed width, with the objective of minimizing the total height of packing. We propose a novel reinforcement learning (RL) approach based on a transformer encoder–decoder architecture, optimized using Proximal Policy Optimization (PPO). Unlike traditional heuristic methods, which often lack adaptability, our model dynamically selects candidate placements by analyzing spatial relationships between packed items and available free spaces, represented using variants of the MaxRects heuristic. This design enables the agent to generalize across different problem instances with varying lengths. Extensive experiments on a variety of synthetic and real-world datasets, including NGCUT and recursive slicing scenarios, demonstrate that our model consistently outperforms classic heuristics such as MaxRectsBL, MaxRectsBSSF, MaxRectsBAF, and MaxRectsBLSF. In particular, our method achieves up to 73% improvement in packing efficiency on longer episodes and maintains high performance even in generalization settings. The study also introduces the Algorithm Selection Problem to the 2D-SPP domain, showing that transformer-based RL agents can effectively learn heuristic strategies for online combinatorial optimization. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.clsr.2023.105924,Computer Law and Security Review,"Understandable privacy information builds trust with users and therefore provides an important competitive advantage for the provider. However, designing privacy information that is both truthful and easy for users to understand is challenging. There are many complex balancing decisions to be made, not only with respect to legal but also visual and user experience design issues. This is why designing understandable privacy information requires combining at least three disciplines that have had little to do with each other in current practice: law, visual design, and user experience design research. The challenges of combining all three disciplines actually culminate in the design and use of Privacy Icons, which are expected to make lengthy legal texts clear and easy to understand (see Art. 12 sect. 7 of the EU General Data Protection Regulation). However, that is much easier said than done. In this paper, we summarise our key learnings from a five years research process on how to design Privacy Icons as a component of effective transparency and user controls. We will provide examples of information and control architectures for privacy policies, forms of consent (especially in the form of cookie banners), privacy dashboards and consent agents in which Privacy Icons may be embedded, 2) a non-exhaustive set of more than 150 Privacy Icons, and above all 3) a concept and process model that can be used to implement the requirements of the GDPR in terms of transparency and user controls in an effective way, according to the data protection by design approach in Art. 25 sect. 1 GDPR. The paper will show that it is a rocky road to the stars and we still haven't arrived – but at least we know how to go. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.cmpb.2023.107373,Computer Methods and Programs in Biomedicine,"Personalized support and assistance are essential for cancer survivors, given the physical and psychological consequences they have to suffer after all the treatments and conditions associated with this illness. Digital assistive technologies have proved to be effective in enhancing the quality of life of cancer survivors, for instance, through physical exercise monitoring and recommendation or emotional support and prediction. To maximize the efficacy of these techniques, it is challenging to develop accurate models of patient trajectories, which are typically fed with information acquired from retrospective datasets. This paper presents a Machine Learning-based survival model embedded in a clinical decision system architecture for predicting cancer survivors’ trajectories. The proposed architecture of the system, named PERSIST, integrates the enrichment and pre-processing of clinical datasets coming from different sources and the development of clinical decision support modules. Moreover, the model includes detecting high-risk markers, which have been evaluated in terms of performance using both a third-party dataset of breast cancer patients and a retrospective dataset collected in the context of the PERSIST clinical study. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.cmpb.2023.107428,Computer Methods and Programs in Biomedicine,"Background:A reliable anticipation of a difficult airway may notably enhance safety during anaesthesia. In current practice, clinicians use bedside screenings by manual measurements of patients’ morphology. Objective:To develop and evaluate algorithms for the automated extraction of orofacial landmarks, which characterize airway morphology. Methods:We defined 27 frontal + 13 lateral landmarks. We collected n=317 pairs of pre-surgery photos from patients undergoing general anaesthesia (140 females, 177 males). As ground truth reference for supervised learning, landmarks were independently annotated by two anaesthesiologists. We trained two ad-hoc deep convolutional neural network architectures based on InceptionResNetV2 (IRNet) and MobileNetV2 (MNet), to predict simultaneously: (a) whether each landmark is visible or not (occluded, out of frame), (b) its 2D-coordinates (x,y). We implemented successive stages of transfer learning, combined with data augmentation. We added custom top layers on top of these networks, whose weights were fully tuned for our application. Performance in landmark extraction was evaluated by 10-fold cross-validation (CV) and compared against 5 state-of-the-art deformable models. Results:With annotators’ consensus as the ‘gold standard’, our IRNet-based network performed comparably to humans in the frontal view: median CV loss L=1.277·10−3, inter-quartile range (IQR) [1.001, 1.660]; versus median 1.360, IQR [1.172, 1.651], and median 1.352, IQR [1.172, 1.619], for each annotator against consensus, respectively. MNet yielded slightly worse results: median 1.471, IQR [1.139, 1.982]. In the lateral view, both networks attained performances statistically poorer than humans: median CV loss L=2.141·10−3, IQR [1.676, 2.915], and median 2.611, IQR [1.898, 3.535], respectively; versus median 1.507, IQR [1.188, 1.988], and median 1.442, IQR [1.147, 2.010] for both annotators. However, standardized effect sizes in CV loss were small: 0.0322 and 0.0235 (non-significant) for IRNet, 0.1431 and 0.1518 (p<0.05) for MNet; therefore quantitatively similar to humans. The best performing state-of-the-art model (a deformable regularized Supervised Descent Method, SDM) behaved comparably to our DCNNs in the frontal scenario, but notoriously worse in the lateral view. Conclusions:We successfully trained two DCNN models for the recognition of 27 + 13 orofacial landmarks pertaining to the airway. Using transfer learning and data augmentation, they were able to generalize without overfitting, reaching expert-like performances in CV. Our IRNet-based methodology achieved a satisfactory identification and location of landmarks: particularly in the frontal view, at the level of anaesthesiologists. In the lateral view, its performance decayed, although with a non-significant effect size. Independent authors had also reported lower lateral performances; as certain landmarks may not be clear salient points, even for a trained human eye. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.cmpb.2023.107966,Computer Methods and Programs in Biomedicine,"Background: In Diffuse Large B-Cell Lymphoma (DLBCL), several methodologies are emerging to derive novel biomarkers to be incorporated in the risk assessment. We realized a pipeline that relies on autoencoders (AE) and Explainable Artificial Intelligence (XAI) to stratify prognosis and derive a gene-based signature. Methods: AE was exploited to learn an unsupervised representation of the gene expression (GE) from three publicly available datasets, each with its own technology. Multi-layer perceptron (MLP) was used to classify prognosis from latent representation. GE data were preprocessed as normalized, scaled, and standardized. Four different AE architectures (Large, Medium, Small and Extra Small) were compared to find the most suitable for GE data. The joint AE-MLP classified patients on six different outcomes: overall survival at 12, 36, 60 months and progression-free survival (PFS) at 12, 36, 60 months. XAI techniques were used to derive a gene-based signature aimed at refining the Revised International Prognostic Index (R-IPI) risk, which was validated in a fourth independent publicly available dataset. We named our tool SurvIAE: Survival prediction with Interpretable AE. Results: From the latent space of AEs, we observed that scaled and standardized data reduced the batch effect. SurvIAE models outperformed R-IPI with Matthews Correlation Coefficient up to 0.42 vs. 0.18 for the validation-set (PFS36) and to 0.30 vs. 0.19 for the test-set (PFS60). We selected the SurvIAE-Small-PFS36 as the best model and, from its gene signature, we stratified patients in three risk groups: R-IPI Poor patients with High levels of GAB1, R-IPI Poor patients with Low levels of GAB1 or R-IPI Good/Very Good patients with Low levels of GPR132, and R-IPI Good/Very Good patients with High levels of GPR132. Conclusions: SurvIAE showed the potential to derive a gene signature with translational purpose in DLBCL. The pipeline was made publicly available and can be reused for other pathologies. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.cmpb.2024.108377,Computer Methods and Programs in Biomedicine,"Background and Objectives: Artificial intelligence (AI) is revolutionizing Magnetic Resonance Imaging (MRI) along the acquisition and processing chain. Advanced AI frameworks have been applied in various successive tasks, such as image reconstruction, quantitative parameter map estimation, and image segmentation. However, existing frameworks are often designed to perform tasks independently of each other or are focused on specific models or single datasets, limiting generalization. This work introduces the Advanced Toolbox for Multitask Medical Imaging Consistency (ATOMMIC), a novel open-source toolbox that streamlines AI applications for accelerated MRI reconstruction and analysis. ATOMMIC implements several tasks using deep learning (DL) models and enables MultiTask Learning (MTL) to perform related tasks in an integrated manner, targeting generalization in the MRI domain. Methods: We conducted a comprehensive literature review and analyzed 12,479 GitHub repositories to assess the current landscape of AI frameworks for MRI. Subsequently, we demonstrate how ATOMMIC standardizes workflows and improves data interoperability, enabling effective benchmarking of various DL models across MRI tasks and datasets. To showcase ATOMMIC's capabilities, we evaluated twenty-five DL models on eight publicly available datasets, focusing on accelerated MRI reconstruction, segmentation, quantitative parameter map estimation, and joint accelerated MRI reconstruction and segmentation using MTL. Results: ATOMMIC's high-performance training and testing capabilities, utilizing multiple GPUs and mixed precision support, enable efficient benchmarking of multiple models across various tasks. The framework's modular architecture implements each task through a collection of data loaders, models, loss functions, evaluation metrics, and pre-processing transformations, facilitating seamless integration of new tasks, datasets, and models. Our findings demonstrate that ATOMMIC supports MTL for multiple MRI tasks with harmonized complex-valued and real-valued data support while maintaining active development and documentation. Task-specific evaluations demonstrate that physics-based models outperform other approaches in reconstructing highly accelerated acquisitions. These high-quality reconstruction models also show superior accuracy in estimating quantitative parameter maps. Furthermore, when combining high-performing reconstruction models with robust segmentation networks through MTL, performance is improved in both tasks. Conclusions: ATOMMIC advances MRI reconstruction and analysis by leveraging MTL and ensuring consistency across tasks, models, and datasets. This comprehensive framework serves as a versatile platform for researchers to use existing AI methods and develop new approaches in medical imaging. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.cmpb.2025.108920,Computer Methods and Programs in Biomedicine,"Background and Objectives: Multidrug Resistance has been identified by the World Health Organization as a major global health threat. It leads to severe social and economic consequences, including extended hospital stays, increased healthcare costs, and higher mortality rates. In response to this challenge, this study proposes a novel interpretable Machine Learning (ML) approach for predicting MDR, developed with two primary objectives: accurate inference and enhanced explainability. Methods: For inference, the proposed method is based on patient-to-patient similarity representations to predict MDR outcomes. Each patient is modeled as a Multivariate Time Series (MTS), capturing both clinical progression and interactions with similar patients. To quantify these relationships, we employ MTS-based similarity metrics, including feature engineering using descriptive statistics, Dynamic Time Warping, and the Time Cluster Kernel. These methods are used as inputs for MDR classification through Logistic Regression, Random Forest, and Support Vector Machines, with dimensionality reduction and kernel transformations applied to enhance model performance. For explainability, we employ graph-based methods to extract meaningful patterns from the data. Patient similarity networks are generated using the MTS-based similarity metrics mentioned above, while spectral clustering and t-SNE are applied to identify MDR-related subgroups, uncover clinically relevant patterns, and visualize high-risk clusters. These insights improve interpretability and support more informed decision-making in critical care settings. Results: We validate our architecture on real-world Electronic Health Records from the Intensive Care Unit (ICU) dataset at the University Hospital of Fuenlabrada, achieving a Receiver Operating Characteristic Area Under the Curve of 81%. Our framework surpasses ML and deep learning models on the same dataset by leveraging graph-based patient similarity. In addition, it offers a simple yet effective interpretability mechanism that facilitates the identification of key risk factors—such as prolonged antibiotic exposure, invasive procedures, co-infections, and extended ICU stays—and the discovery of clinically meaningful patient clusters. For transparency, all results and code are available at https://github.com/oscarescuderoarnanz/DM4MTS. Conclusions: This study demonstrates the effectiveness of patient similarity representations and graph-based methods for MDR prediction and interpretability. The approach enhances prediction, identifies key risk factors, and improves patient stratification, enabling early detection and targeted interventions, highlighting the potential of interpretable ML in critical care. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.cogpsych.2008.11.001,Cognitive Psychology,"The present research examined whether 5- to 6.5-month-old infants would hold different expectations about various physical events involving a box after receiving evidence that it was either inert or self-propelled. Infants were surprised if the inert but not the self-propelled box: reversed direction spontaneously (Experiment 1); remained stationary when hit or pulled (Experiments 3 and 3A); remained stable when released in midair or with inadequate support from a platform (Experiment 4); or disappeared when briefly hidden by one of two adjacent screens (the second screen provided the self-propelled box with an alternative hiding place; Experiment 5). On the other hand, infants were surprised if the inert or the self-propelled box appeared to pass through an obstacle (Experiment 2) or disappeared when briefly hidden by a single screen (Experiment 5). The present results indicate that infants as young as 5 months of age distinguish between inert and self-propelled objects and hold different expectations for physical events involving these objects, even when incidental differences between the objects are controlled. These findings are consistent with the proposal by Gelman, R. (1990). First principles organize attention to and learning about relevant data: Number and the animate-inanimate distinction as examples. Cognitive Science, 14, 79-106, Leslie, A. M. (1994). ToMM, ToBY, and Agency: Core architecture and domain specificity. In L. A. Hirschfeld & S. A. Gelman (Eds.), Mapping the mind: Domain specificity in cognition and culture (pp. 119-148). New York: Cambridge University Press, and others that infants endow self-propelled objects with an internal source of energy. Possible links between infants' concepts of self-propelled object, agent, and animal are also discussed. © 2009 Elsevier B.V., All rights reserved.; MEDLINE® is the source for the MeSH terms of this document.",TOPIC
10.1016/j.cogsys.2011.11.001,Cognitive Systems Research,"There has been a recent flurry of activity in consciousness research. Although an operational definition of consciousness has not yet been developed, philosophy has come to identify a set of features and aspects that are thought to be associated with the various elements of consciousness. On the other hand, there have been several recent attempts to develop computational models of consciousness that are claimed to capture or illustrate one or more aspects of consciousness. As a plausible substitute to evaluating how well the current computational models model consciousness, this study examines how the current computational models fare in modeling those aspects and features of consciousness identified by philosophy. Following a review of the literature on the philosophy of consciousness, this study constructs a list of features and aspects that would be expected in any successful model of consciousness. The study then evaluates, from the viewpoint of that list, some of the current self-claimed and implemented computational models of consciousness. The computational models studied are evaluated with respect to each identified aspect and feature of consciousness. © 2011 Elsevier B.V. © 2012 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.cogsys.2021.12.005,Cognitive Systems Research,"The mental rotation ability is an essential spatial reasoning skill in human cognition and has proven to be an essential predictor of mathematical and STEM skills, critical and computational thinking. Despite its importance, little is known about when and how mental rotation processes are activated in games explicitly targeting spatial reasoning tasks. In particular, the relationship between spatial abilities and TetrisTM has been analysed several times in the literature. However, these analyses have shown contrasting results between the effectiveness of Tetris-based training activities to improve mental rotation skills. In this work, we studied whether, and under what conditions, such ability is used in the TetrisTM game by explicitly modelling mental rotation via an ACT-R based cognitive model controlling a virtual agent. The obtained results show meaningful insights into the activation of mental rotation during game dynamics. The study suggests the necessity to adapt game dynamics in order to force the activation of this process and, therefore, can be of inspiration to design learning activities based on TetrisTM or re-design the game itself to improve its educational effectiveness. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.comcom.2019.09.002,Computer Communications,"To meet the growing mobile data traffic demand, Mobile Network Operators (MNOs) are deploying dense infrastructures of small cells as a solution for capacity enhancement. This densification increases the power consumption of mobile networks, thus impacting the environment. As a result, we have seen a recent trend of powering base stations with ambient energy sources to achieve both environmental sustainability and cost reductions. In addition, flexible functional split in Cloud Radio Access Network (CRAN) is a promising solution to overcome the capacity and latency challenges in the fronthaul. In such architecture, local base stations perform partial baseband processing while the remaining part will take place at the central cloud. As the cells become smaller and deployed in a densified manner, it is evident that baseband processing power consumption has a huge share in the total base station power consumption breakdown. In this paper, we propose a network scenario where the baseband processes of the virtual small cells powered solely by energy harvesters and batteries can be opportunistically executed in a grid-connected edge computing server, co-located at the macro base station site. We state the corresponding energy minimization problem and propose multi-agent Reinforcement Learning (RL) to solve it. Distributed Fuzzy Q-Learning and Q-Learning on-line algorithms are tailored for our purposes. Coordination among the multiple agents is favored by broadcasting system level information to the independent learners. The evaluation of the network performance confirms that favoring coordination among the agents via broadcasting may achieve higher system level gains and cumulative rewards closer to the off-line bounds than solutions that are unaware of system level information. Finally, our analysis permits to evaluate the benefits of continuous state/action representation for the learning algorithms in terms of faster convergence, higher cumulative reward and adaptivity to changing environments. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.comcom.2024.107937,Computer Communications,"The current trend in user services places an ever-growing demand for higher data rates, near-real-time latencies, and near-perfect quality of service. To meet such demands, fundamental changes were made to the traditional radio access network (RAN), introducing Open RAN (O-RAN). This new paradigm is based on a virtualized and intelligent RAN architecture. However, with the increased complexity of 5G applications, traditional application-specific placement techniques have reached a bottleneck. Our paper presents a Transfer Learning (TL) augmented Reinforcement Learning (RL) based networking slicing (NS) solution targeting more effective placement and improving downtime for prolonged slice deployments. To achieve this, we propose an approach based on creating a robust and dynamic repository of specialized RL agents and network slices geared towards popular user service types such as eMBB, URLLC, and mMTC. The proposed solution consists of a heuristic-controlled two-module-based ML Engine and a repository. The objective function is formulated to minimize the downtime incurred by the VNFs hosted on the commercial-off-the-shelf (COTS) servers. The performance of the proposed system is evaluated compared to traditional approaches using industry-standard 5G traffic datasets. The evaluation results show that the proposed solution consistently achieves lower downtime than the traditional algorithms. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.comcom.2025.108342,Computer Communications,"Large-scale low earth orbit (LEO) satellite networks constitute a core component of future sixth-generation (6G) communication systems. To address the challenges of resource scarcity and highly dynamic topologies, the integration of software-defined networking (SDN) and network function virtualization (NFV) technologies into LEO satellite networks has become imperative. We proposes a hybrid centralized-distributed software-defined LEO satellite network architecture. Within this framework, This study focuses on the service function chain (SFC) deployment problem in LEO space-ground integrated networks. time-expanded graphs (TEGs) are employed to model satellite networks with dynamic topological variations, aiming to satisfy diverse user requirements while jointly optimizing resource consumption costs and service latency. The problem is formulated as a weighted sum minimization of resource consumption costs and service latency, and this problem is proven to be NP-complete. Subsequently, we integrate the twin delayed deep deterministic policy gradient method with multi-agent techniques to design a multi-agent deep reinforcement learning SFC deployment (MADRL-D) framework for optimizing our objectives. Experimental results demonstrate that the proposed MADRL-D framework outperforms existing alternatives in terms of resource utilization efficiency, resource consumption costs, and service latency. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.commtr.2025.100165,Communications in Transportation Research,"Designing an optimal departure trajectory for an airport can minimize fuel emissions within the surrounding airspace and noise perceived by nearby populations, which brings positive sociological and economic implications in addition to environmental benefits. Yet, designing a trajectory that considers realistic operational constraints could be complex and, consequently, computationally expensive. Traditional trajectory optimization methods often simplify the problem to manage computational costs, which leads to compromised accuracy. To overcome this challenge, we propose a reinforcement learning (RL) approach that can satisfy multidisciplinary constraints by leveraging accurately modeled flight dynamics, high-fidelity population data, and topological data. This is achieved by establishing a comprehensive, physically-consistent simulated environment for the learning algorithm, while keeping the computational cost low. Instead of directly designing the trajectory itself, we train an RL agent to control the aircraft, whose trajectory is then considered as optimal. We model the RL problem as a continuous Markov decision process and employ the soft actor-critic architecture. By changing the relative importance of fuel consumption and noise in the optimization objective, we can obtain different optimum trajectories that are well-suited to the specific region of interest. Not surprisingly, a trade-off between fuel consumption and noise impact is observed in our results. This developed framework provides a more accurate and sophisticated approach for departure trajectory optimization, whose results are beneficial for future airspace design and can support sustainable aviation efforts. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.commtr.2025.100203,Communications in Transportation Research,"This study presents an adaptive traffic signal control (ATSC) method for managing multiple intersections at the corridor level by proposing a novel multi-agent masked deep reinforcement learning (DRL) framework. The method extends the hybrid soft-actor-critic architecture to optimize green light timings for intersections across a corridor network, fostering a balance between vehicle flow and pedestrian movements with an emphasis on humanism, fairness, and equality. By integrating an innovative phase mask mechanism, our model dynamically adapts to the fluctuating demand of different transportation modalities by discovering new states or actions that could avoid local optima and achieve higher rewards. We comprehensively test our method using five naturalistic traffic scenarios in Melbourne, Australia. The results demonstrate a significant improvement in reducing the number of impacted travellers compared to existing DRL and other baseline methods. Furthermore, the inclusion of the phase mask mechanism enhances our model's performance through ablation analyses. The proposed framework not only supports a fairer traffic signal system but also provides a scalable, adaptable solution for diverse urban traffic conditions.. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.comnet.2019.05.013,Computer Networks,"Intrusion detection is a crucial service in today's data networks, and the search for new fast and robust algorithms that are capable of detecting and classifying dangerous traffic is essential to deal with changing threats and increasing detection difficulty. In this work, we present a new intrusion detection algorithm with an excellent prediction performance. The prediction is based on a classifier which is a simple and extremely fast neural network. The classifier implements a policy function that is trained with a novel reinforcement learning model, where the behavior of the environment is adjusted in parallel with the learning process. Intrusion detection frameworks are based on a supervised learning paradigm that uses a training dataset composed of network features and associated intrusion labels. In this work, we integrate this paradigm with a reinforcement learning algorithm that is normally based on interaction with a live environment (not a pre-recorded dataset). To perform the integration, the live environment is replaced by a simulated one. The principle of this approach is to provide the simulated environment with an intelligent behavior by, first, generating new samples by randomly extracting them from the training dataset, generating rewards that depend on the goodness of the classifier's predictions, and, second, by further adjusting this initial behavior with an adversarial objective in which the environment will actively try to increase the difficulty of the prediction made by the classifier. In this way, the simulated environment acts as a second agent in an adversarial configuration against the original agent (the classifier). We prove that this architecture increases the final performance of the classifier. This work presents the first application of adversarial reinforcement learning for intrusion detection, and provides a novel technique that incorporates the environment's behavior into the learning process of a modified reinforcement learning algorithm. We prove that the proposed algorithm is adequate for a supervised learning problem based on a labeled dataset. We validate its performance by comparing it with other well-known machine learning models for two datasets. The proposed model outperforms the other models in the weighted Accuracy (>0.8) and F1 (>0.79) metrics, and especially excels in the results for the under-represented labels. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.comnet.2021.108254,Computer Networks,"Network slicing and mixed-numerology access schemes cover a central role to enable the flexible multi-service connectivity that characterizes 5G radio access networks (RAN). However, the interference generated by the simultaneous multiplexing of radio slices having heterogeneous subcarrier spacing can hinder the isolation of the different slices sharing the RAN and their effectiveness in meeting the application requirements. To overcome these issues, we design a radio resource allocation scheme that accounts for the inter-numerology interference and maximizes the aggregate network throughput. To overcome the computationally complexity of the optimal formulation, we leverage deep reinforcement learning (DRL) to design an agent capable of approximating the optimal solution exploiting a model-free environment formulation. We propose a multi-branch agent architecture, based on Branching Dueling Q-networks (BDQ), which ensures the agent scalability as the number of spectrum resources and network slices increases. In addition, we augment the agent learning performance by including an action mapping procedure designed to enforce the selection of feasible actions. We compare the agent performance to several benchmarks schemes. Results show that the proposed solution provides a good approximation of the optimal allocation in most scenarios. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.comnet.2022.109476,Computer Networks,"The breakthrough in Machine Learning (ML) techniques and the popularity of the Internet of Things (IoT) has increased interest in applying Artificial Intelligence (AI) techniques to the new paradigm of Edge Computing. One of the challenges in edge computing architectures is the optimal distribution of the generated tasks between the devices in each layer (i.e., cloud-fog-edge). In this paper, we propose to use Reinforcement Learning (RL) to solve the Task Assignment Problem (TAP) at the edge layer and then we propose a novel multi-layer extension of RL (ML-RL) techniques that allows edge agents to query an upper-level agent with more knowledge to improve the performance in complex and uncertain situations. We first formulate the task assignment process considering the trade-off between energy consumption and execution time. We then present a greedy solution as a baseline and implement our multi-layer RL proposal in the PureEdgeSim simulator. Finally several simulations of each algorithm are evaluated with different numbers of devices to verify scalability. The simulation results show that reinforcement learning solutions outperformed the heuristic-based solutions and our multi-layer approach can significantly improve performance in high device density scenarios. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.comnet.2023.109998,Computer Networks,"The Cache Pollution Attack (CPA) is a recent threat that poses a significant risk to Named Data Networks (NDN). This attack can impact the caching process in various ways, such as causing increased cache misses for legitimate users, delays in data retrieval, and exhaustion of resources in NDN routers. Despite the numerous countermeasures suggested in the literature for CPA, many of them have detrimental effects on the NDN components. In this paper, we introduce Q-ICAN, a novel intelligent technique for detecting and mitigating cache pollution attacks in NDN. More specifically, Q-ICAN uses Q-Learning as an automated CPA prediction mechanism. Each NDN router integrates a reinforcement learning agent that utilizes impactful metrics such as the variation of the Cache Hit Ratio (CHR) and the interest inter-arrival time to learn how to differentiate between malicious and legitimate interests. We conducted several simulations using NDNSim to assess the effectiveness of our solution in terms of Cache Hit Ratio (CHR), Average Retrieval Delay (ARD) and multiple artificial intelligence evaluation metrics such as accuracy, precision, recall, etc. The obtained results confirm that Q-ICAN detects CPA attacks with a 95.09% accuracy rate, achieves a 94% CHR, and reduces ARD by 18%. Additionally, Q-ICAN adheres to the security policy of the NDN architecture and consumes fewer resources from NDN routers compared to existing state-of-the-art solutions. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.compag.2025.110571,Computers and Electronics in Agriculture,"Digital Twins are often intertwined with machine learning and, more recently, deep reinforcement learning methods in their architecture to process data and predict future outcomes based on input data. However, concerns about the trustworthiness of the output from deep learning models persist due to neural networks generally being regarded as a black box model. In our work, we developed crop rotation policies using explainable tabular reinforcement learning techniques. We compared these policies to those generated by a deep Q-learning approach by generating five-step rotations, i.e. producing a series of five consecutive crops. The aim of the rotations is to maximise crop yields while maintaining a healthy nitrogen level in the soil and adhering to established planting rules. Crop yields may vary due to external factors such as weather patterns or changes in market prices, so perturbations have been added to the reward signal to account for those influences. The deployed explainable tabular reinforcement learning methods collect, on average, at least as much reward over 100 crop rotation plans when randomly starting with any crop compared to the deep learning model. For the perturbed case, robust tabular reinforcement learning methods collect similar amounts of reward across 100 crop rotation plans compared to the non-random reward setting, whereas the deep reinforcement learning agent collects even fewer rewards compared to learning on non-perturbed rewards. Thus, we contribute a novel random rewards approach and a corresponding robustification to increase the resilience of the proposed crop rotation planning methodology. By consulting with farmers and crop rotation experts, we demonstrate that the derived policies are reasonable to use and more resilient towards external perturbations. Furthermore, the use of interpretable and explainable reinforcement learning techniques increases confidence in resulting policies, thereby increasing the likelihood that farmers will adopt the suggested policies. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.compag.2025.110591,Computers and Electronics in Agriculture,"Efficient and cost-effective automated detection systems are essential for mitigating the impact of aphid infections on cereal crops. However, the fine-grained, small-scale, and densely clustered nature of aphid targets, combined with the computational demands and large size of existing detection models, poses challenges in achieving high detection accuracy on resource-constrained devices. To address these issues, we propose RSCDet (RepGhostConv-Subpixel Fusion-Cascading Attention-Detection), a lightweight deep learning model built upon the YOLOv7s architecture (You Only Look Once, version 7, small), which was selected after evaluating YOLO versions 5 through 10. RSCDet is designed to identify three morphologically similar aphid species, i.e., sugarcane aphid (Melanaphis sacchari), cereal aphid (Macrosiphum avenae), and bird cherry-oat aphid (Rhopalosiphum padi). RepGhostConv and Subpixel Fusion were used for network lightening. We implemented channel alignment and updated the detection head to reduce model size. Additionally, the SF-CasAM (Subpixel Fusion-based Cascading Attention Module) was developed to improve the recognition of visually similar targets, and the RepBi-PAN neck network was constructed to enhance the localization of small targets. RSCDet outperformed the baseline model, with higher detection accuracy (mean average precision, mAP of 95.8 %, increased by 2.4 %), faster processing speed (frames per second, FPS increased by 45.0 %), and lower computational complexity (parameters reduced by 93.5 %, FLOPs by 68.7 %, and model size by 91.5 %). It also demonstrated superior performance over other state-of-the-art models. RSCDet facilitates real-time, high-accuracy aphid detection on low-cost, portable embedded devices, enabling direct field deployment of early-warning systems and timely, actionable control of aphid outbreaks in agricultural settings. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.compbiomed.2020.104040,Computers in Biology and Medicine,"Managing the risks arising from the actions and conditions of the various elements that make up an operating room is a major concern during a surgical procedure. One of the main challenges is to define alert thresholds in a non-deterministic context where unpredictable adverse events occur. In response to this problematic, this paper presents an architecture that couples a Multi-Agent System (MAS) with Case-Based Reasoning (CBR). The possibility of emulating a large number of situations thanks to MAS, combined with analytical data management thanks to CBR, is an original and efficient way of determining thresholds that are not defined a priori. We also compared different similarity calculation methods (Retrieve phase of CBR). The results presented in this article show that our model can manage alert thresholds in an environment that manages data as disparate as infectious agents, patient's vitals and human fatigue. In addition, they reveal that the thresholds proposed by the system are more efficient than the predefined ones. These results tend to prove that our simulator is an effective alert generator. Nevertheless, the context remains a simulation mode that we would like to enrich with real data from, for example, monitoring sensors (bracelet for human fatigue, monitoring, etc). © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.compbiomed.2021.104317,Computers in Biology and Medicine,"In the context of the recently emerging COVID-19 pandemic, we developed a deep learning model that can be used to predict the inhibitory activity of 3CLpro in severe acute respiratory syndrome coronavirus (SARS-CoV) for unknown compounds during the virtual screening process. This paper proposes a novel deep learning-based method to implement virtual screening with convolutional neural network (CNN) architecture. The descriptors represent chemical molecules, and these descriptors are input into the CNN framework to train a model and predict active compounds. When compared to other machine learning methods, including random forest, naive Bayes, decision tree, and support vector machine, the proposed CNN model's evaluation of the test set showed an accuracy of 0.86, a sensitivity of 0.45, a specificity of 0.96, a precision of 0.73, a recall of 0.45, an F-measure of 0.55, and a ROC of 0.71. The CNN model screened 17 out of 918 phytochemical compounds; 60 out of 423 from the natural product NCI divset IV; 17,831 out of 112,267 from the ZINC natural product database; and 315 out of 1556 FDA-approved drugs as anti-SARS-CoV agents. Further, to prioritize drug-like compounds, Lipinski's rule of five was applied to screen anti-SARS-CoV compounds (excluding FDA-approved drugs), resulting in 10, 59, and 14,025 hit molecules. Out of 10 phytochemical compounds, 9 anti-SARS-CoV agents belonged to the flavonoid group. In conclusion, the proposed CNN model can prove useful for developing novel target-specific anti-SARS-CoV compounds. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.compbiomed.2022.105451,Computers in Biology and Medicine,"Background: Automatic detection of atrial fibrillation (AF) by cardiac devices is increasingly common yet suboptimally groups AF, flutter or tachycardia (AT) together as ‘high rate events’. This may delay or misdirect therapy. Objective: We hypothesized that deep learning (DL) can accurately classify AF from AT by revealing electrogram (EGM) signatures. Methods: We studied 86 patients in whom the diagnosis of AF or AT was established at electrophysiological study (25 female, 65 ± 11 years). Custom DL architectures were trained to identify AF using N = 29,340 unipolar and N = 23,760 bipolar EGM segments. We compared DL to traditional classifiers based on rate or regularity. We explained DL using computer models to assess the impact of controlled variations in shape, rate and timing on AF/AT classification in 246,067 EGMs reconstructed from clinical data. Results: DL identified AF with AUC of 0.97 ± 0.04 (unipolar) and 0.92 ± 0.09 (bipolar). Rule-based classifiers misclassified ∼10–12% of cases. DL classification was explained by regularity in EGM shape (13%) or timing (26%), and rate (60%; p < 0.001), and also by a set of unipolar EGM shapes that classified as AF independent of rate or regularity. Overall, the optimal AF ‘fingerprint’ comprised these specific EGM shapes, >15% timing variation, <0.48 correlation in beat-to-beat EGM shapes and CL < 190 ms (p < 0.001). Conclusions: Deep learning of intracardiac EGMs can identify AF or AT via signatures of rate, regularity in timing or shape, and specific EGM shapes. Future work should examine if these signatures differ between different clinical subpopulations with AF. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.compbiomed.2022.106192,Computers in Biology and Medicine,"Motivation: Tumor heterogeneity, including genetic and transcriptomic characteristics, can reduce the efficacy of anticancer pharmacological therapy, resulting in clinical variability in patient response to therapeutic medications. Multi-omics integration can allow in silico models to provide an additional perspective on a biological system. Methods: In this study, we propose a gene-centric multi-channel (GCMC) architecture to integrate multi-omics for predicting cancer drug response. GCMC transformed multi-omics profiles into a three-dimensional tensor with an additional dimension for omics types. GCMC's convolutional encoders captures multi-omics profiles for each gene and yields gene-centric features to predict drug responses. Results: We evaluated GCMC on various datasets, including The Cancer Genome Atlas (TCGA) patients, patient-derived xenografts (PDX) mice models, and the Genomics of Drug Sensitivity in Cancer (GDSC) cell line datasets. GCMC achieved better performance than baseline models, including single-omics models, in more than 75% of 265 drugs from GDSC cell line datasets. Furthermore, as for the clinical applicability of GCMC, it achieved the best performance on TCGA and PDX datasets in terms of both AUPR and AUC. We also analyzed models’ capability of integrating multi-omics profiles by measuring the contribution ratio of omics types. GCMC can incorporate multi-omics profiles in various manners to enhance performance for each drug type. These results suggested that GCMC can improve performance and feature extraction capability by integrating multi-omics profiles in a gene-centric manner. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.compbiomed.2023.106882,Computers in Biology and Medicine,"Purpose: Automatic and accurate segmentation of lesions in images of metastatic castration-resistant prostate cancer has the potential to enable personalized radiopharmaceutical therapy and advanced treatment response monitoring. The aim of this study is to develop a convolutional neural networks-based framework for fully-automated detection and segmentation of metastatic prostate cancer lesions in whole-body PET/CT images. Methods: 525 whole-body PET/CT images of patients with metastatic prostate cancer were available for the study, acquired with the [18F]DCFPyL radiotracer that targets prostate-specific membrane antigen (PSMA). U-Net (1)-based convolutional neural networks (CNNs) were trained to identify lesions on paired axial PET/CT slices. Baseline models were trained using batch-wise dice loss, as well as the proposed weighted batch-wise dice loss (wDice), and the lesion detection performance was quantified, with a particular emphasis on lesion size, intensity, and location. We used 418 images for model training, 30 for model validation, and 77 for model testing. In addition, we allowed our model to take n = 0,2, …, 12 neighboring axial slices to examine how incorporating greater amounts of 3D context influences model performance. We selected the optimal number of neighboring axial slices that maximized the detection rate on the 30 validation images, and trained five neural networks with different architectures. Results: Model performance was evaluated using the detection rate, Dice similarity coefficient (DSC) and sensitivity. We found that the proposed wDice loss significantly improved the lesion detection rate, lesion-wise DSC and lesion-wise sensitivity compared to the baseline, with corresponding average increases of 0.07 (p-value = 0.01), 0.03 (p-value = 0.01) and 0.04 (p-value = 0.01), respectively. The inclusion of the first two neighboring axial slices in the input likewise increased the detection rate by 0.17, lesion-wise DSC by 0.05, and lesion-wise mean sensitivity by 0.16. However, there was a minimal effect from including more distant neighboring slices. We ultimately chose to use a number of neighboring slices equal to 2 and the wDice loss function to train our final model. To evaluate the model's performance, we trained three models using identical hyperparameters on three different data splits. The results showed that, on average, the model was able to detect 80% of all testing lesions, with a detection rate of 93% for lesions with maximum standardized uptake values (SUVmax) greater than 5.0. In addition, the average median lesion-wise DSC was 0.51 and 0.60 for all the lesions and lesions with SUVmax>5.0, respectively, on the testing set. Four additional neural networks with different architectures were trained, and they both yielded stronger performance of segmenting lesions whose SUVmax>5.0 compared to the rest of lesions. Conclusion: Our results demonstrate that prostate cancer metastases in PSMA PET/CT images can be detected and segmented using CNNs. The segmentation performance strongly depends on the intensity, size, and the location of lesions, and can be improved by using specialized loss functions. Specifically, the models performed best in detection of lesions with SUVmax>5.0. Another challenge was to accurately segment lesions close to the bladder. Future work will focus on improving the detection of lesions with lower SUV values by designing custom loss functions that take into account the lesion intensity, using additional data augmentation techniques, and reducing the number of false lesions by developing methods to better separate signal from noise. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.compbiomed.2023.107420,Computers in Biology and Medicine,"This paper tackles the challenge of automatically assessing physical rehabilitation exercises for patients who perform the exercises without clinician supervision. The objective is to provide a quality score to ensure correct performance and achieve desired results. To achieve this goal, a new graph-based model, the Dense Spatio-Temporal Graph Conv-GRU Network with Transformer, is introduced. This model combines a modified version of STGCN and transformer architectures for efficient handling of spatio-temporal data. The key idea is to consider skeleton data respecting its non-linear structure as a graph and detecting joints playing the main role in each rehabilitation exercise. Dense connections and GRU mechanisms are used to rapidly process large 3D skeleton inputs and effectively model temporal dynamics. The transformer encoder's attention mechanism focuses on relevant parts of the input sequence, making it useful for evaluating rehabilitation exercises. The evaluation of our proposed approach on the KIMORE and UI-PRMD datasets highlighted its potential, surpassing state-of-the-art methods in terms of accuracy and computational time. This resulted in faster and more accurate learning and assessment of rehabilitation exercises. Additionally, our model provides valuable feedback through qualitative illustrations, effectively highlighting the significance of joints in specific exercises. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.compbiomed.2025.110372,Computers in Biology and Medicine,"Background: Artificial Intelligence is transforming medical imaging, particularly in the analysis of bone metastases (BM), a serious complication of advanced cancers. Machine learning and deep learning techniques offer new opportunities to improve detection, recognition, and segmentation of bone metastasis. Yet, challenges such as limited data, interpretability, and clinical validation remain. Methods: Following PRISMA guidelines, we reviewed artificial intelligence methods and applications for bone metastasis analysis across major imaging modalities including CT, MRI, PET, SPECT, and bone scintigraphy. The survey includes traditional machine learning models and modern deep learning architectures such as CNNs and transformers. We also examined available datasets and their effect in developing artificial intelligence in this field. Results: Artificial intelligence models have achieved strong performance across tasks and modalities, with Convolutional Neural Network (CNN) and Transformer architectures showing particularly efficient performance across different tasks. However, limitations persist, including data imbalance, overfitting risks, and the need for greater transparency. Clinical translation is also challenged by regulatory and validation hurdles. Conclusion: Artificial intelligence holds strong potential to improve BM diagnosis and streamline radiology workflows. To reach clinical maturity, future work must address data diversity, model explainability, and large-scale validation, which are critical steps for being trusted to be integrated into the oncology care routines. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.compbiomed.2025.110500,Computers in Biology and Medicine,"Depression is a mental disorder that can lead to suicide and self-harm if left untreated. Predicting the outcomes of depression therapy is one of the most challenging tasks for psychiatrists and neurologists. Selective Serotonin Reuptake Inhibitors (SSRIs) and repetitive Transcranial Magnetic Stimulation (rTMS) are two well-established therapies for depression, commonly prescribed as first-line treatments for different levels of depression. However, the response rate is about 50%, which is not significantly high. In this paper, we propose a novel technique called the dynamical pattern of successive bits (DPSB) to extract distinctive features from Electroencephalography (EEG) signals to predict the outcome of different depression therapies and suggest the best course of treatment. Our novel feature extraction technique is built on the nonlinear fusion of variations in successive bits. Two features, amplitude (A) and phase (ϕ), are extracted from EEG signals using the DPSB technique. These features are utilized along with a feedforward neural network architecture to predict the outcome of depression therapy. The results show that our accuracy levels are 99.40% and 99.59% in predicting the outcomes of SSRI and rTMS therapies, respectively. The model is trained and tested using a 10-fold cross-validation technique to avoid bias in the results. The findings indicate that the temporal lobe exhibits a better capability for predicting the outcomes of depression therapies. Furthermore, the T3 channel shows the best performance in predicting these outcomes. Two biomarkers, A and ϕ, are proposed using the DPSB technique for the T3 channel to illustrate the brain's complex behaviors in a 2D plane. The proposed model is embedded in software that could assist neurologists in selecting the best course of treatment for depressed patients. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.compbiomed.2025.110668,Computers in Biology and Medicine,"Anticancer peptide (ACP) has emerged as potent therapeutic agents owing to its ability to selectively target cancer cells while minimising toxicity to healthy cells. However, the accurate computational prediction of ACP remains challenging because of the complex molecular mechanisms underlying cancer. In this study, we introduce EnsemPred-ACP, an innovative ensemble framework that combines machine learning (ML) and deep learning (DL) approaches to enhance ACP prediction. Our primary innovation is the introduction of binary profile features (BPF) to augment pre-trained protein embeddings, thereby capturing position-specific patterns crucial for ACP identification. The framework used a dual-pipeline architecture; ML models processed handcrafted sequence features and embeddings, whereas DL models handled BPF-enhanced embeddings. Upon evaluation with independent datasets, EnsemPred-ACP achieved an accuracy of 0.863, sensitivity of 0.897, and specificity of 0.830, notably outperforming existing methods. The model demonstrated a strong generalisation performance, achieving an area under the receiver operating characteristic curve of 0.93. Ablation studies on independent datasets further highlighted the substantial impact of BPF, enhancing the prediction accuracy by 2.5 % and 11.1 % when integrated with ESM2 and ProtT5 embeddings, respectively. These results demonstrate the effectiveness of our integrated approach in accurately identifying potential therapeutic peptides, thereby contributing to the advancement of peptide-based cancer therapeutics. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.compchemeng.2020.107027,Computers and Chemical Engineering,"Developing optimisation tools is a key target in supporting computer-aided process design as the complexity of the designed space grows beyond conventional unit operations. A process design problem can be formulated as a search of an optimal processing route in the thermodynamic state space, going from feedstock to products. This paper describes a design architecture that enables reinforcement learning agent to use trial-and-error to narrow its search to the most promising routes, rather than exhaustively enumerating solutions. In each iteration, the agent employs previously collected data to guide the search for new trajectories. This is successfully demonstrated in a hydrogen production process using both conventional and intensified process design principles. The agent outperformed standard nonlinear optimisation methods in competitive computational time. Limitations and future work are discussed. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.compchemeng.2022.107819,Computers and Chemical Engineering,"The operation of semi-batch reactors requires caution because the feeding reagents can accumulate, leading to hazardous situations due to the loss of control ability. This work aims to develop a method that explores the optimal operational strategy of semi-batch reactors. Since reinforcement learning (RL) is an efficient tool to find optimal strategies, we tested the applicability of this concept. We developed a problem-specific RL-based solution for the optimal control of semi-batch reactors in different operation phases. The RL-controller varies the feeding rate in the feeding phase directly, while in the mixing phase, it works as a master in a cascade control structure. The RL-controllers were trained with different neural network architectures to define the most suitable one. The developed RL-based controllers worked very well and were able to keep the temperature at the desired setpoint in the investigated system. The results confirm the benefit of the proposed problem-specific RL-controller. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.compeleceng.2025.110528,Computers and Electrical Engineering,"As the electrical grid integrates more variable renewable energy sources such as wind and solar, the demand for distributed and flexible systems to address this increased variability becomes critical. Nuclear-driven microgrids provide a promising solution by offering stable generation to complement intermittent renewables, ensuring grid reliability and operating efficiency. This paper proposes a recurrent deep reinforcement learning framework for optimal economic dispatch in a nuclear-powered microgrid integrating renewable energy sources, small modular reactors, battery storage systems, and balance-of-plant dynamics. A three-agent control architecture is developed, where demand and renewable energy agents act as forecasters, and a reinforcement learning-based dispatch agent performs real-time energy allocation. A nonlinear programming formulation is first used to generate an optimal baseline for benchmarking. The proposed dispatch controller, based on Proximal Policy Optimization enhanced with Long Short-Term Memory networks, exploits temporal correlations in system dynamics by taking advantage of the time series used as inputs to improve policy robustness under uncertainty. Comparative analysis against established deep reinforcement learning methods, including Proximal Policy Optimization with a feedforward architecture, Soft Actor-Critic, and Twin Delayed Deep Deterministic Policy Gradient, demonstrates superior performance. Numerical results indicate that the proposed controller achieves a 0.39% cost reduction relative to the nonlinear programming benchmark and outperforms other learning-based methods by generating additional revenue of up to 0.35%. All reinforcement learning controllers compute dispatch actions in less than 0.3 s, resulting in a computational speedup of more than three orders of magnitude over the nonlinear programming baseline. The findings of this paper highlight their applicability for real-time operation and control in nuclear-integrated microgrids under volatile operating conditions. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.compmedimag.2017.12.001,Computerized Medical Imaging and Graphics,"Mitosis detection is one of the critical factors of cancer prognosis, carrying significant diagnostic information required for breast cancer grading. It provides vital clues to estimate the aggressiveness and the proliferation rate of the tumour. The manual mitosis quantification from whole slide images is a very labor-intensive and challenging task. The aim of this study is to propose a supervised model to detect mitosis signature from breast histopathology WSI images. The model has been designed using deep learning architecture with handcrafted features. We used handcrafted features issued from previous medical challenges MITOS @ ICPR 2012, AMIDA-13 and projects (MICO ANR TecSan) expertise. The deep learning architecture mainly consists of five convolution layers, four max-pooling layers, four rectified linear units (ReLU), and two fully connected layers. ReLU has been used after each convolution layer as an activation function. Dropout layer has been included after first fully connected layer to avoid overfitting. Handcrafted features mainly consist of morphological, textural and intensity features. The proposed architecture has shown to have an improved 92% precision, 88% recall and 90% F-score. Prospectively, the proposed model will be very beneficial in routine exam, providing pathologists with efficient and – as we will prove – effective second opinion for breast cancer grading from whole slide images. Last but not the least, this model could lead junior and senior pathologists, as medical researchers, to a superior understanding and evaluation of breast cancer stage and genesis. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.csbj.2024.02.014,Computational and Structural Biotechnology Journal,"Objective: This paper introduces a privacy-preserving federated machine learning (ML) architecture built upon Findable, Accessible, Interoperable, and Reusable (FAIR) health data. It aims to devise an architecture for executing classification algorithms in a federated manner, enabling collaborative model-building among health data owners without sharing their datasets. Materials and methods: Utilizing an agent-based architecture, a privacy-preserving federated ML algorithm was developed to create a global predictive model from various local models. This involved formally defining the algorithm in two steps: data preparation and federated model training on FAIR health data and constructing the architecture with multiple components facilitating algorithm execution. The solution was validated by five healthcare organizations using their specific health datasets. Results: Five organizations transformed their datasets into Health Level 7 Fast Healthcare Interoperability Resources via a common FAIRification workflow and software set, thereby generating FAIR datasets. Each organization deployed a Federated ML Agent within its secure network, connected to a cloud-based Federated ML Manager. System testing was conducted on a use case aiming to predict 30-day readmission risk for chronic obstructive pulmonary disease patients and the federated model achieved an accuracy rate of 87%. Discussion: The paper demonstrated a practical application of privacy-preserving federated ML among five distinct healthcare entities, highlighting the value of FAIR health data in machine learning when utilized in a federated manner that ensures privacy protection without sharing data. Conclusion: This solution effectively leverages FAIR datasets from multiple healthcare organizations for federated ML while safeguarding sensitive health datasets, meeting legislative privacy and security requirements. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.csbj.2025.01.020,Computational and Structural Biotechnology Journal,"Deep Forest employs forest structures and leverages deep architecture to learn feature vector information adaptively. However, deep forest-based models have limitations such as manual hyperparameter optimization and time and memory usage inefficiencies. Bayesian optimization is a widely used model-based hyperparameter optimization method. Evolutionary algorithms such as Differential Evolution (DE) have recently been introduced to improve Bayesian optimization's acquisition function. Despite its effectiveness, DE has a significant drawback as it relies on randomly selecting indices from the population of target vectors to construct donor vectors in search of optimal solutions. This randomness is ineffective, as suboptimal or redundant indices may be selected. Therefore, in this research we developed a modified differential evolution (DE) acquisition function for improved host-pathogen protein-protein interaction prediction. The modified DE introduces a weighted and adaptive donor vector technique that selects the best-fitted donor vectors as opposed to the random approach. This modified optimization approach was implemented in a deep forest model for automatic hyperparameter optimization. The performance of the optimized deep forest model was evaluated on human-Plasmodium falciparum protein sequence datasets using 10-fold cross-validation. The results were compared with standard optimization methods such as traditional Bayesian optimization, genetic algorithms, evolutionary strategies, and other machine learning models. The optimized model achieved an accuracy of 89.3 %, outperforming other models across all metrics, including a sensitivity of 85.4 % and a precision of 91.6 %. Additionally, the optimized model predicted seven novel host-pathogen interactions. Finally, the model was implemented as a web application which is accessible at http://dfh3pi.covenantuniversity.edu.ng. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.csbj.2025.03.044,Computational and Structural Biotechnology Journal,"The genomic diversification of viral pathogens during viral epidemics and pandemics represents a major adaptive route for infectious agents to circumvent therapeutic and public health initiatives. Historically, strategies to address viral evolution have relied on responding to emerging variants after their detection, leading to delays in effective public health responses. Because of this, a long-standing yet challenging objective has been to forecast viral evolution by predicting potentially harmful viral mutations prior to their emergence. The promises of artificial intelligence (AI) coupled with the exponential growth of viral data collection infrastructures spurred by the COVID-19 pandemic, have resulted in a research ecosystem highly conducive to this objective. Due to the COVID-19 pandemic accelerating the development of pandemic mitigation and preparedness strategies, many of the methods discussed here were designed in the context of SARS-CoV-2 evolution. However, most of these pipelines were intentionally designed to be adaptable across RNA viruses, with several strategies already applied to multiple viral species. In this review, we explore recent breakthroughs that have facilitated the forecasting of viral evolution in the context of an ongoing pandemic, with particular emphasis on deep learning architectures, including the promising potential of language models (LM). The approaches discussed here employ strategies that leverage genomic, epidemiologic, immunologic and biological information. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.csite.2024.104974,Case Studies in Thermal Engineering,"This paper addresses the challenge of estimating heat transfer coefficients (HTCs) through the measured surface temperatures under large interference in the secondary cooling zone (SCZ) of continuous casting processes. Conventional methods for calculating HTCs, typically reliant on surface temperature data, face significant challenges in achieving accuracy. These challenges primarily stem from the limitations inherent in traditional methodologies and the distortions caused by temperature outliers, which are a consequence of large interference. To address these issues more effectively, we introduced a novel algorithm–multi-agent and dimensional learning based Jaya algorithm (MADL-Jaya)–specifically designed to estimate HTCs. Furthermore, a hybrid method that integrates weighted least squares (WLS) with the MADL-Jaya was proposed to mitigate the impact of outliers. Additionally, estimating HTCs entails substantial computational demands. Consequently, a double-deck parallel algorithm employing graphics processing unit (GPU) acceleration was presented. This architecture facilitates both parallel heat transfer models and parallel MADL-Jaya calculations, thus significantly reducing the computational time required for HTC estimation. The experimental results unequivocally affirm the efficacy of the proposed algorithm in the accurate estimation of HTCs within the SCZ of continuous casting, effectively neutralizing the detrimental influence of outlier values while markedly improving computational speed. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.cvdhj.2022.06.001,Cardiovascular Digital Health Journal,"Background and Objective: Postexercise heart rate recovery (HRR) is an important indicator of cardiac autonomic function and abnormal HRR is associated with adverse outcomes. We hypothesized that deep learning on resting electrocardiogram (ECG) tracings may identify individuals with impaired HRR. Methods: We trained a deep learning model (convolutional neural network) to infer HRR based on resting ECG waveforms (HRR<inf>pred</inf>) among UK Biobank participants who had undergone exercise testing. We examined the association of HRR<inf>pred</inf> with incident cardiovascular disease using Cox models, and investigated the genetic architecture of HRR<inf>pred</inf> in genome-wide association analysis. Results: Among 56,793 individuals (mean age 57 years, 51% women), the HRR<inf>pred</inf> model was moderately correlated with actual HRR (r = 0.48, 95% confidence interval [CI] 0.47–0.48). Over a median follow-up of 10 years, we observed 2060 incident diabetes mellitus (DM) events, 862 heart failure events, and 2065 deaths. Higher HRR<inf>pred</inf> was associated with lower risk of DM (hazard ratio [HR] 0.79 per 1 standard deviation change, 95% CI 0.76–0.83), heart failure (HR 0.89, 95% CI 0.83–0.95), and death (HR 0.83, 95% CI 0.79–0.86). After accounting for resting heart rate, the association of HRR<inf>pred</inf> with incident DM and all-cause mortality were similar. Genetic determinants of HRR<inf>pred</inf> included known heart rate, cardiac conduction system, cardiomyopathy, and metabolic trait loci. Conclusion: Deep learning–derived estimates of HRR using resting ECG independently associated with future clinical outcomes, including new-onset DM and all-cause mortality. Inferring postexercise heart rate response from a resting ECG may have potential clinical implications and impact on preventive strategies warrants future study. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.dcan.2022.12.024,Digital Communications and Networks,"Benefiting from the development of Federated Learning (FL) and distributed communication systems, large-scale intelligent applications become possible. Distributed devices not only provide adequate training data, but also cause privacy leakage and energy consumption. How to optimize the energy consumption in distributed communication systems, while ensuring the privacy of users and model accuracy, has become an urgent challenge. In this paper, we define the FL as a 3-layer architecture including users, agents and server. In order to find a balance among model training accuracy, privacy-preserving effect, and energy consumption, we design the training process of FL as game models. We use an extensive game tree to analyze the key elements that influence the players’ decisions in the single game, and then find the incentive mechanism that meet the social norms through the repeated game. The experimental results show that the Nash equilibrium we obtained satisfies the laws of reality, and the proposed incentive mechanism can also promote users to submit high-quality data in FL. Following the multiple rounds of play, the incentive mechanism can help all players find the optimal strategies for energy, privacy, and accuracy of FL in distributed communication systems. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.dcan.2023.03.006,Digital Communications and Networks,"With the rapid development of Intelligent Transportation Systems (ITS), many new applications for Intelligent Connected Vehicles (ICVs) have sprung up. In order to tackle the conflict between delay-sensitive applications and resource-constrained vehicles, computation offloading paradigm that transfers computation tasks from ICVs to edge computing nodes has received extensive attention. However, the dynamic network conditions caused by the mobility of vehicles and the unbalanced computing load of edge nodes make ITS face challenges. In this paper, we propose a heterogeneous Vehicular Edge Computing (VEC) architecture with Task Vehicles (TaVs), Service Vehicles (SeVs) and Roadside Units (RSUs), and propose a distributed algorithm, namely PG-MRL, which jointly optimizes offloading decision and resource allocation. In the first stage, the offloading decisions of TaVs are obtained through a potential game. In the second stage, a multi-agent Deep Deterministic Policy Gradient (DDPG), one of deep reinforcement learning algorithms, with centralized training and distributed execution is proposed to optimize the real-time transmission power and subchannel selection. The simulation results show that the proposed PG-MRL algorithm has significant improvements over baseline algorithms in terms of system delay. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.dcan.2024.10.003,Digital Communications and Networks,"With the development of the future Web of Healthcare Things (WoHT), there will be a trend of densely deploying medical sensors with massive simultaneous online communication requirements. The dense deployment and simultaneous online communication of massive medical sensors will inevitably generate overlapping interference. This will be extremely challenging to support data transmission at the medical-grade quality of service level. To handle the challenge, this paper proposes a hypergraph interference coordination-aided resource allocation based on the Deep Reinforcement Learning (DRL) method. Specifically, we build a novel hypergraph interference model for the considered WoHT by analyzing the impact of the overlapping interference. Due to the high complexity of directly solving the hypergraph interference model, the original resource allocation problem is converted into a sequential decision-making problem through the Markov Decision Process (MDP) modeling method. Then, a policy and value-based resource allocation algorithm is proposed to solve this problem under simultaneous online communication and dense deployment. In addition, to enhance the exploration ability of the optimal allocation strategy for the agent, we propose a resource allocation algorithm with an asynchronous parallel architecture. Simulation results verify that the proposed algorithms can achieve higher network throughput than the existing algorithms in the considered WoHT scenario. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.dche.2025.100261,Digital Chemical Engineering,"This study proposes a structured AutoRL framework for the development of deep reinforcement learning (DRL) controllers in chemical process systems. Focusing on the control of a 3× 3 MIMO yeast fermentation bioreactor, the methodology jointly optimizes three key internal components of the DRL agent: the reward function, the neural network architecture, and the hyperparameters of the algorithm. A parameterizable logistic reward formulation is introduced to encode control objectives, such as steady-state accuracy, minimalization of actuation effort, and control smoothness, into a flexible and tunable structure. A dual loop optimization strategy combines grid search and Bayesian optimization to systematically explore and refine the agent's design space. The resulting controller achieved average steady-state errors of 0.009 °C for reactor temperature and 0.19 g/L for ethanol concentration, while maintaining smooth and stable behavior under diverse operational scenarios. By formalizing reward design and integrating it with hyperparameter and architecture optimization, this work delivers a AutoRL methodology for DRL-based control, reducing reliance on expert heuristics and enhancing reproducibility in complex bioprocess applications. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.dt.2025.09.014,Defence Technology,"This study addresses the maneuver evasion problem for medium-to-long-range air-to-air missiles by proposing a KAN-λ-PPO-based evasion algorithm. The algorithm introduces Kolmogorov-Arnold Networks (KAN) to mitigate the catastrophic forgetting issue of Multilayer Perceptrons (MLP) in continual learning, while incorporating λ-return to resolve sparse reward challenges in evasion scenarios. First, we model the evasion problem with λ-return and present the KAN-λ-PPO algorithm. Subsequently, we establish game environments based on the segmented ballistic characteristics of medium and long range missiles. During training, a joint reward function is designed by combining the miss distance and positional advantages to train the agent. Experiments evaluate four dimensions: (1) Performance comparison between KAN and MLP in value function approximation; (2) Catastrophic forgetting mitigation of KAN-λ-PPO in dual-task scenarios; (3) Continual learning capabilities across multiple evasion scenarios; (4) Quantitative analysis of agent strategy evolution and positional advantages. Empirical results demonstrate that KAN improves value function approximation accuracy by an order of magnitude compared with traditional MLP architectures. In continual learning tasks, the KAN-λ-PPO scheme exhibits significant knowledge retention, achieving performance improvements of 32.7% and 8.6% over MLP baselines in Task1→2 and Task2→3 transitions, respectively. Furthermore, the learned maneuver strategies outperform High-G Barrel Rolls(HGB) and S-maneuver tactics in securing positional advantages while accomplishing evasion. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ecoinf.2010.11.004,Ecological Informatics,"Many plants reproduce clonally through vegetative extensions (spacers). This results in a patch of clones connected through a network of spacers. The resulting network has a nontrivial spatial pattern that can be an important determinant of survival and fitness of the clonal plant. Here, we develop general growth rules that dictate how individual clones under local density-dependent conditions add spacers, giving rise to emergent population-level spatial patterns. A population subject to these growth rules is simulated using a stochastic individual-based model. The dependence of network structure on various architectural parameters is explored. The growth rules generate networks similar to those observed in natural populations, and can replicate real-world phenomena such as central die-back with regeneration, 'fairy rings', and branch entrapment. A shorter spacer length results in higher population density (which may confer resistance to invasion in real populations), while longer spacer length allows the population to spread more quickly. The lateral branching angle, node-by-node angle, and spacer length appear to be the most influential parameters for determining the spatial architecture of the clonal patch. The number of daughter branches per mother branch follows a power law distribution in a diverse set of simulated networks. Continually growing computational power will make such simulation models increasingly useful for understanding the spatial growth of clonal plants, and power law behaviour may be a very common feature of both simulated and real clonal plant populations. © 2010 Elsevier B.V. © 2011 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ecoinf.2018.10.002,Ecological Informatics,"During an epidemic crisis, medical image analysis namely microscopic analyses are made to confirm or not the existence of the epidemic pathogen in suspected cases. Pathogen are all infectious agents such as a virus, bacterium, protozoa, prion etc. However, there is often a lack of specialists in the handling of microscopes, hence allowing the need to make the microscopic analysis abroad. This results in a considerable loss of time and in the meantime, the epidemic continues to spread. To save time in the analysis of samples, we propose to make the future microscopes more intelligent so that they will be able to indicate by themselves the existence or not of the pathogen of an epidemic in a sample. To have a smart microscope, we propose a methodology based on efficient Convolution Neural Network (CNN) architecture in order to classify epidemic pathogen with five deep learning phases: (1) Training dataset of provided images (2) CNN Training (3) Testing data preparation (4) CNN generated model on testing data and finally (5) Evaluation of images classified. The resulted classification process can be integrated in a mobile computing solution on future microscopes. CNN can improve the accuracy in pathogens diagnosis that are focused on hand-tuned feature extraction implying some human mistakes. For our study, we consider cholera and malaria epidemics for microscopic images classification with a relevant CNN, respectively Vibrio cholerae images and Plasmodium falciparum images. Image classification is the task of taking an input image and outputting a class or a probability of classes that best describes the image. Interesting results have been obtained from the CNN model generated achieving the classification accuracy of 94%, with 200 Vibrio cholera images and 200 Plasmodium falciparum images for training dataset and 80 images for testing data. Although this document addresses the classification of epidemic pathogen images using a CNN model, the underlying principles apply to the other fields of science and technology, because of its performance and its capability to handle more layers than the previous traditional neural networks. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.egyai.2020.100020,Energy and AI,"This paper proposes a novel reinforcement learning (RL) architecture for the efficient scheduling and control of the heating, ventilation and air conditioning (HVAC) system in a commercial building while harnessing its demand response (DR) potentials. With advances in automated building management systems, this can be achieved seamlessly by a smart autonomous RL agent which takes the best action, for example, a change in HVAC temperature set point, necessary to change the electricity usage pattern of a building in response to demand response signals, and with minimal thermal comfort impact to customers. Previous research in this area has tackled only individual aspects of the problem using RL. Specifically, due to the challenges in implementing demand response with whole-building models, simpler analytical models which poorly capture reality have been used instead. And where whole-building models are applied, RL is used for HVAC control mainly to achieve energy efficiency goals while demand response is neglected. Thus, in this research, we implement a holistic framework by designing an efficient RL controller for a whole-building model which learns to optimise and control the HVAC system for improved energy efficiency and thermal comfort levels in addition to achieving demand response goals. Our simulation results show that by applying reinforcement learning for normal HVAC operation, a maximum weekly energy reduction of up to 22% can be achieved compared to a handcrafted baseline controller. Furthermore, by employing a DR-aware RL controller during demand response periods, average power reductions or increases of up to 50% can be achieved on a weekly basis compared to the default RL controller, while keeping occupant thermal comfort levels within acceptable bounds. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.eij.2025.100737,Egyptian Informatics Journal,"Among the world's rarest and costliest coffee beans, luwak beans, after being extracted from the Asian palm civet, a small mammal native to Southeast Asia, and Traditionally beans are harvested, washed, and roasted. Previously cleaning process of luwak beans was a traditional and meticulous practice through hand wash which involves collection, sorting, and pre-washing with water to remove larger pieces of debris and clinging pulp. Cleaning hand-luwak beans with the traditional methods might cause inconsistent quality, potential hygiene concerns, time-consuming and labor intensive. Integrated cleaning units will delicately de-pulp, wash, and dry beans in the proposed method. Features may include color, size, shape, and texture, which are crucial indicators of bean quality. Machine learning algorithms and vision transformers built on picture data will assist the robot's arms in removing pulp without damaging beans delicately. Controlling drying settings precisely ensures quality and prevents over-drying. The proposed system leverages a Visual Transformer, a powerful image recognition architecture, enhanced with Feature Recombination and Distillation (FRD) for improved accuracy and efficiency. Combining RL with Proximal Policy Optimization (PPO) and a Visual Transformer with Feature Recombination and Distillation (FRD) for visual input processing. Training the RL agent to identify and select high-quality cleaned Kopi Luwak beans based on visual features. They achieved a purification accuracy of 97.57. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.energy.2022.125290,Energy,"This paper presents a novel framework for Offline Reinforcement Learning (RL) with online fine tuning for Heating Ventilation and Air-conditioning (HVAC) systems. The framework presents a method to do pre-training in a black box model environment, where the black box models are built on data acquired under a traditional control policy. The paper focuses on the application of Underfloor Heating (UFH) with an air-to-water-based heat pump. However, the framework should also generalize to other HVAC control applications. Because Black box methods are used is there little to no commissioning time when applying this framework to other buildings/simulations beyond the one presented in this study. This paper explores and deploys Artificial Neural Network (ANN) based methods to design efficient controllers. Two ANN methods are tested and presented in this paper; a Multilayer Perceptron (MLP) method and a Long Short Term Memory (LSTM) based method. It is found that the LSTM-based method reduces the prediction error by 45% when compared with a MLP model. Additionally, different network architectures are tested. It is found that by creating a new model for each time step, performance can be improved additionally 19%. By using these models in the framework presented in this paper, it is shown that a Multi-Agent RL algorithm can be deployed without ever performing worse than an industrial controller. Furthermore, it is shown that if building data from a Building Management System (BMS) is available, an RL agent can be deployed which performs close to optimally from the first day of deployment. An optimal control policy reduces the cost of heating by 19.4 % when compared to a traditional control policy in the simulation presented in this paper. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.eng.2022.05.017,Engineering,"Due to its limited intelligence and abilities, machine learning is currently unable to handle various situations thus cannot completely replace humans in real-world applications. Because humans exhibit robustness and adaptability in complex scenarios, it is crucial to introduce humans into the training loop of artificial intelligence (AI), leveraging human intelligence to further advance machine learning algorithms. In this study, a real-time human-guidance-based (Hug)-deep reinforcement learning (DRL) method is developed for policy training in an end-to-end autonomous driving case. With our newly designed mechanism for control transfer between humans and automation, humans are able to intervene and correct the agent's unreasonable actions in real time when necessary during the model training process. Based on this human-in-the-loop guidance mechanism, an improved actor-critic architecture with modified policy and value networks is developed. The fast convergence of the proposed Hug-DRL allows real-time human guidance actions to be fused into the agent's training loop, further improving the efficiency and performance of DRL. The developed method is validated by human-in-the-loop experiments with 40 subjects and compared with other state-of-the-art learning approaches. The results suggest that the proposed method can effectively enhance the training efficiency and performance of the DRL algorithm under human guidance without imposing specific requirements on participants’ expertise or experience. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.engappai.2023.106239,Engineering Applications of Artificial Intelligence,"Considering the importance of the energy management strategy for hybrid electric vehicles, this paper is aiming at addressing the energy optimization control issue using reinforcement learning algorithms. Firstly, this paper establishes a hybrid electric vehicle power system model. Secondly, a hierarchical energy optimization control architecture based on networked information is designed, and a traffic signal timing model is used for vehicle target speed range planning in the upper system. More specifically, the optimal vehicle speed is optimized by a model predictive control algorithm. Thirdly, a mathematical model of vehicle speed variation in connected and unconnected states is established to analyze the effect of vehicle speed planning on fuel economy. Finally, three learning-based energy optimization control strategies, namely Q-learning, deep Q network (DQN), and deep deterministic policy gradient (DDPG) algorithms, are designed under the hierarchical energy optimization control architecture. It is shown that the Q-learning algorithm is able to optimize energy control; however, the agent will meet the ”dimension disaster” once it faces a high-dimensional state space issue. Then, a DQN control strategy is introduced to address the problem. Due to the limitation of the discrete output of DQN, the DDPG algorithm is put forward to achieve continuous action control. In the simulation, the superiority of the DDPG algorithm over Q-learning and DQN algorithms in hybrid electric vehicles is illustrated in terms of its robustness and faster convergence for better energy management purposes. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.engappai.2025.112222,Engineering Applications of Artificial Intelligence,"The degradation of fuel cell systems (FCS) affects the energy management performance of fuel cell hybrid electric vehicles (FCHEVs), especially in the case of severe degradation. This study develops a novel predictive energy management architecture, which consists of the Extended Long Short-Term Memory (xLSTM) and Soft Actor-Critic (SAC). Specifically, the speed predictor is built using xLSTM network and leverages the speed and position information of the preceding and following vehicles. In order to provide a reliable basis for energy management in degradation scenarios, an FCS degradation model is developed, which enables the dynamic mapping of output efficiency curves under varying state-of-health (SOH) conditions. Sequentially, a SAC-based agent is employed as the energy management strategy (EMS), which innovatively takes full account of the impact of the FCS SOH on energy allocation, achieving proactive degradation-aware energy allocation. Simulation results demonstrate that the developed xLSTM architecture achieves a 71 % improvement in speed prediction accuracy compared to Transformer-based models within the Next Generation Simulation validated scenario. Moreover, at SOH = 90 %, the newly designed EMS reduces operational costs by 8.7 % and 10.7 % compared to conventional methods under the New European Driving Cycle and Worldwide Harmonized Light Vehicles Test Procedure, while decreasing FCS degradation costs by 17 % and 51 %, respectively. The innovative approach not only elevates energy efficiency but also prolongs FCS operational longevity via intelligent SOH-aware, which establishes a new paradigm for lifecycle-optimized energy management in FCHEVs. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.epsr.2024.110528,Electric Power Systems Research,"Active distribution grids can experience voltage fluctuations and violations due to the high penetration of variable distributed energy resources (DERs). These problems might occur because of the uncertain and variable generation natures of these resources, especially solar photovoltaic resources, during panel shadowing scenarios. Volt-VAR control (VVC) is an efficient method that controls the reactive power set-points of the inverters to regulate the voltage of distribution grids. Although several VVC approaches have been proposed recently, the performance of these approaches degrades significantly if behind-the-meter solar generation data are unobservable/missing. Therefore, it is necessary to impute missing/unobservable PV data accurately to be utilized in VVC approaches. This paper proposes a model-free, data-driven, centrally trained, and decentrally executed multi-agent deep reinforcement learning-based VVC architecture to regulate the voltage of distribution networks. A generative adversarial network (GAN) is incorporated to impute the unobservable PV data accurately, which improves the performance of the proposed control architecture. The proposed multi-agent-soft-actor–critic algorithm (MASAC)-based VVC technique utilizes the actual PV dataset as well as the imputed dataset from the GAN framework to learn the optimal coordinated control policy for controlling the optimal reactive power set-points of PV inverters. The effectiveness of the proposed approach is analyzed on a modified IEEE 34-bus test case with added PV inverters. The results are compared and analyzed with a base case model with no VVC and VVC with a local droop control approach, genetic algorithm optimization, and a centralized soft actor–critic-based approach. Moreover, the performance of the proposed approach is compared with that of a multi-agent VVC framework without using the PV generation data and load information as the system state. The results illustrate that the proposed method with more state input improves the voltage profile and reduces the power loss of the network across various loading and PV generation scenarios. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.foar.2016.01.003,Frontiers of Architectural Research,"Driven by globalization and market openings, many architecture and engineering firms have become global. By focusing on the urban megaprojects in the Gulf, a particular cultural and political context, this paper argues that such firms have a major role in the rapid urban transformation of Gulf countries and act as transfer agents of an international knowledge in the urban planning domain. However, the transfer is adapted by several context-related characteristics, such as local governance, urban knowledge, and regulatory framework. This paper explores the procedural adaptation of these firms to the Gulf Cooperation Council (GCC) in terms of internal structure, methodology, adopted tools, and interaction with the context. The level of learning that results from this transfer is also investigated. © 2016 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ifacol.2018.11.577,IFAC-PapersOnLine,"The paper presents a reinforcement learning based solution for the control design problem of a gearbox actuator. The system is operated by an electro-pneumatic, three-state, floating piston cylinder. Besides the primary goals of positioning the piston, the nonlinear system's quality objectives are to minimize switching time and overshoot. The control strategy based on the measurable parameters of the system is realized by a dense feedforward neural network. With the utilization of the policy based reinforcement learning architecture, the learning agent develops the optimal strategy for fast and smooth switching, under different and changing conditions. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ifacol.2021.08.167,IFAC-PapersOnLine,"The new generation of steel manufacturing processes shaped by Industry 4.0 are more digitalized, networked, flexible and adaptable. Production processes use distributed information and communication structures, are more autonomous and capable to react to dynamic changings of the environment. Agent-based systems represent a paradigm, which is well suited to address these new generation of smart processes. The paper presents a hybrid peer-to-peer architecture for agent-based steel production processes. The architecture exploits a central database server for storing and retrieving updated information from peers about a cold rolling manufacturing process. The cold rolling process is modeled as a multi-agent system composed of four types of autonomous agents, each playing a different role in the steel production chain. Agents are designed to take autonomous decisions, and to coordinate and collaborate with each other, by ensuring the dynamic plant resources allocation even if unforeseen interruptions of the production flow may happen. The proposed approach is designed for the steel strip manufacturing process but can be easily readapted to any flat production process. The test of the design multi-agent system with the proposed architecture is supported though the simulation of the dynamic plant resources allocation under changing dynamic conditions. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ifacol.2021.11.178,IFAC-PapersOnLine,"In this paper, a car-like Unmanned Ground Vehicle (UGV) is simulated and trained as an intelligent agent to navigate and exit unknown obstacle filled environments given no prior knowledge of environment characteristics, using a Reinforcement Learning (RL) algorithm tailored for continuous action spaces. This is achieved using Deep Deterministic Policy Gradient (DDPG), an Actor-Critic network that combines multiple cutting-edge Artificial Intelligence methods including continuous Deep-Q learning, policy gradient methods and actor-critic networks. A combination of two feedforward neural networks with Rectified Linear Units (ReLU) is used for the critic and actor representations which combine both policy and value based methods to learn continuous action space policies via approximation functions. The role of the actor network in this architecture is to decide linear and angular velocity outputs from a continuous action space given current state inputs, to then be evaluated by the critic network to learn and estimate Q-values by minimizing a loss function. The proposed DDPG RL network is trained and evaluated in two obstacle filled environments for a car-like UGV with wheelbase, l of 0.3 m. During the 10,000 episode training period, the agent converges to a maximum reward value of 180 after 1100 training episodes in the first environment, and a maximum reward value of 80 after 7500 training episodes in the second, more complex environment. The agent is shown to exhibit intelligent human-like learning behavior to learn optimal policies and adapt to new environments at the end of each training period with no changes to network architecture. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ifacol.2022.07.239,IFAC-PapersOnLine,"Distributed model predictive control (DMPC) is often used to tackle path planning for unmanned aerial vehicle (UAV) swarms. However, it requires considerable computations on-board the UAV, leading to increased weight and power consumption. In this work, we propose to offload path planning computations to multiple ground-based computation units. As simultaneously communicating and recomputing all trajectories is not feasible for a large swarm with tight timing requirements, we develop a novel event-Triggered DMPC that selects a subset of most relevant UAV trajectories to be replanned. The resulting architecture reduces UAV weight and power consumption, while the active redundancy provides robustness against computation unit failures. Moreover, the DMPC guarantees feasible and collision-free trajectories for UAVs with linear dynamics. In simulations, we demonstrate that our method can reliably plan trajectories, while saving 60% of network traffic and required computational power. Hardware-in-The-loop experiments show that it is suitable to control real quadcopter swarms. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ifacol.2022.09.412,IFAC-PapersOnLine,"This paper presents an agent-based framework for reconfiguring modular assembly systems using machine learning and system performance estimates based on previous reconfigurations. During a reconfiguration, system integrators and engineers make changes to the machine to meet new production requirements by increasing capacity or manufacturing new product variants. The framework provides a method for automatically evaluating these changes in terms of impact on the performance of the production system, and building a knowledge base. Such knowledge is used to support future reconfigurations by recommending changes that are likely to improve the performance based on previous reconfigurations. The agent architecture of the framework has two levels, one for individual assembly stations and one for the entire production line. Knowledge bases of changes are built and utilised at both levels using machine learning and performance estimates. A prototype implementation of the proposed framework has been evaluated on an assembly production system in an industrial scenario. Preliminary results show that framework helps to reduce the time and resources required to complete a system reconfiguration and reach the desired production objectives. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ifacol.2022.09.681,IFAC-PapersOnLine,"Many optimal algorithms, heuristics, metaheuristics, simulation approaches, agent-based models, and machine learning tools attempt to solve the job shop scheduling problem (JSSP). This article proposed a model of artificial intelligence with agents representing intelligent products from the perspective of product-driven systems (PDS) to solve this problem at different scales. The intelligent products make all decisions in a distributed way aiming to minimize the makespan and increase the computational efficiency for the JSSP. The agents embed the intelligence function using a based shifting bottleneck heuristic (SBH) approach. The novelty of the proposed approach lies in the automation of decisions in a highly distributed architecture to increase manufacturing flexibility. The results are compared with an optimal integer programming model (IP), SBH, and two conventional heuristics considering instances commonly used in the literature. Concerning the makespan, the proposed approach obtains a fast solution near optimal in instances with a low number of resources and better results than IP and conventional heuristic in instances with a more significant number of resources, increasing the response capacity with a similar computational time. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ifacol.2022.10.270,IFAC-PapersOnLine,"Eco-driving strategies have been shown to provide significant reductions in fuel consumption. This paper outlines an active driver assistance approach that uses a residual policy learning (RPL) agent trained to provide residual actions to default power train controllers while balancing fuel consumption against other driver-accommodation objectives. Using previous experiences, our RPL agent learns improved traction torque and gear shifting residual policies to adapt the operation of the powertrain to variations and uncertainties in the environment. For comparison, we consider a traditional reinforcement learning (RL) agent trained from scratch. Both agents employ the off-policy Maximum A Posteriori Policy Optimization algorithm with an actor-critic architecture. By implementing on a simulated commercial vehicle in various car-following scenarios, we find that the RPL agent quickly learns significantly improved policies compared to a baseline source policy but in some measures not as good as those eventually possible with the RL agent trained from scratch. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ifacol.2023.10.1481,IFAC-PapersOnLine,"A reinforcement learning (RL) enabled intelligent motion planning for collision-free autonomous docking manoeuvre explicitly designed for a robotic floating satellite emulation platform is presented in this article. The Twin Delayed Deep Deterministic Policy Gradient-based RL algorithm involving deep neural network architecture in the actor-critic framework is considered to obtain the collision-free safe docking policy. The RL agents have been trained to perform a resilient target acquisition, ensuring its terminal position and velocity requirements while enabling the capability to avoid both static and dynamic obstacles. The resulting optimal policy is implemented as a feedback control law to enable computationally efficient onboard reactive motion planning for autonomous safe docking of the robotic floating satellite platform in a complex dense debris environment. The efficacy of the proposed motion planning scheme is validated with numerous simulation studies, where it is depicted that the trained RL-based planner has the potential to address the target acquisition with a sufficient degree of accuracy in the presence of both static and dynamic obstacle scenarios. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ifacol.2023.10.1673,IFAC-PapersOnLine,"Consensus of multi-agent systems has recently been studied in the context of Federated Learning (FL), an emerging branch of distributed machine learning. The present paper proposes a two-level hierarchical algorithm for FL in the context of edge computing, developing a fully decentralized solution that relies on results obtained for discrete-time consensus of dynamical systems. The proposed architecture and algorithm are validated on a test case and compared to current solutions, which require a centralized server. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ifacol.2023.10.1844,IFAC-PapersOnLine,"In this work, deep neural network trained by the model-free reinforcement learning method is proposed as a negotiation agent in multi-agent distributive model predictive control. The negotiation agent is implemented in the upper layer of a hierarchical control architecture based on distributed model predictive controller with pairwise negotiation fuzzy logic. The proposed is data-driven in order to achieve the minimization of any dynamic behavior index and the specification of constraints. Specifically, the deep neural network provides consensus coefficients to address the final control action applied by each agent. The proposed is successfully applied to a hydraulic system composed of eight interconnected tanks that are very difficult to control due to non-linearities nature and high interaction between its subsystems. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ifacol.2023.10.376,IFAC-PapersOnLine,"Distributed ledger technologies, together with AI, smart systems and robotics could provide a scalable and robust platform for the smart underwater and surface marine infrastructures of the close future. They will be harbours or ports, marine farms or remote tourism facilities - only accessible through robotic avatars - for protected areas or for the elders. Autonomous Marine Vehicles, IoT networks, and humans will coexist in highly heterogeneous multivendor multiplatform environments where market transactions and complex administrative procedures will be ubiquitous. Some blockchains such as the Ethereum network are able to provide distributed scalable computing and trustable functionalities, capable of managing both technical interactions and market transactions among very diversified autonomous agents. For these reasons they seem to provide a valuable backbone for the smart marine infrastructure of the coming decades. In this paper we outline our research and innovation strategy and present our results showing the potential benefits of a subsidiary architecture integrating distributed ledger technologies with swarms of autonomous surface robots implemented by a Belief Space Planning approach. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ifacol.2023.10.670,IFAC-PapersOnLine,"In the emerging Physical Internet, hyperconnected freight transportation allows using multiple short-haul drivers through hyperconnected meshed hub networks to deliver long-haul freight in multiparty multimodal relay mode. One of its core challenges lies in dynamic operational planning associated with the flows of freight, containers, carriers, and drivers to ensure agile, efficient, resilient, and sustainable performances given demand knowledge and state monitoring. In this paper, we focus on large-scale hyperconnected freight transportation, with testbed as the road-based tractor-hauler delivery of vehicles in the Southeastern USA. We propose an autonomous operating system for dynamic operational decision making from sources through hubs to destinations, including freight shipment consolidation, assignment of freight to haulers and haulers to tractors, multi-hop routing, coordination and scheduling of drivers, tractors and haulers, as well as driver-task matching based on individual prefrences. The system is based on a multi-agent network architecture, where each agent is responsible for different key operational decisions by running heuristic optimization algorithms and interacts with one another through information exchange. We provide preliminary results from simulation-based experiments encompassing vehicle delivery of a major automotive manufacturer from multiple sources, including factories, ports, and railheads, to 500+ dealers across the Southeastern United States. The analysis of results proves that each of agents can effectively and efficiently cope with the large-scale decision making and the overall proposed system is capable of operating hyperconnected freight transportation with reliable order-to-delivery performance, high hauler filling rates, and desirable environemnt friendliness, while improving quality of life by enabling truckers to be back home daily and alleviate truck driver shortage issues. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ifacol.2023.10.870,IFAC-PapersOnLine,"In this work, we propose a novel policy network architecture for model-free Reinforcement Learning (RL)-based path-following and collision avoidance in marine surface vessels. By applying convolutional neural networks (CNNs) for mapping LiDAR-like distance measurements to Collision Risk Indices (CRIs), we evaluate the utility of risk-based pretraining of CNN feature extractors prior to RL. Where previous works required hand-crafted preprocessing of high-resolution distance measurements to train an autonomous RL agent successfully, the proposed approach achieves this goal in a data-driven fashion. Ultimately, we propose future directions to improve CNN-based perception models for collision avoidance in range sensing applications. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ifacol.2023.12.054,IFAC-PapersOnLine,"Reinforcement learning (RL) can improve control performance by seeking to learn optimal control policies in the end-use environment for vehicles and other systems. To accomplish this, RL algorithms need to sufficiently explore the state and action spaces. This presents inherent safety risks, and applying RL on safety-critical systems like vehicle powertrain control requires safety enforcement approaches. In this paper, we seek control-barrier function (CBF)-based safety certificates that demarcate safe regions where the RL agent could optimize the control performance. In particular, we derive optimal high-order CBFs that avoid conservatism while ensuring safety for a vehicle in traffic. We demonstrate the workings of the high-order CBF with an RL agent which uses a deep actor-critic architecture to learn to optimize fuel economy and other driver accommodation metrics. We find that the optimized high-order CBF allows the RL-based powertrain control agent to achieve higher total rewards without any crashes in training and evaluation while achieving better accommodation of driver demands compared to previously proposed exponential barrier function filters and model-based baseline controllers. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ifacol.2024.07.231,IFAC-PapersOnLine,"The increasing emphasis on system safety and reliability has heightened the demand for fault-tolerant ability of control systems. Fault-tolerant cooperative control (FTCC) is one of the safety issues in multi-agent systems (MASs). This paper studies the leader-following consensus control of MASs in the presence of actuator and sensor faults. A unified framework of active FTCC is proposed under a dynamic event-triggered mechanism (DETM) by employing the virtual actuator and virtual sensor approach. The proposed DETM serves to reduce the communication cost among agents. The FTCC issue is formulated by linear matrix inequalities (LMIs) and can be implemented in a distributed architecture. Without the need of re-tuning the pre-designed observer-based controller, the FTCC exhibits a notable efficiency for fault compensation and plant reconfiguration. Numerical simulations demonstrate the validity of the proposed methods. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ifacol.2024.11.044,IFAC-PapersOnLine,"Calculating mealtime insulin doses poses a significant challenge for individuals with Type 1 Diabetes (T1D). Doses should perfectly compensate for expected post-meal glucose excursions, requiring a profound understanding of the individual's insulin sensitivity and the meal macronutrients'. Usually, people rely on intuition and experience to develop this understanding. In this work, we demonstrate how a reinforcement learning agent, employing a self-attention encoder network, can effectively mimic and enhance this intuitive process. Trained on 80 virtual subjects from the FDA-approved UVA/Padova T1D adult cohort and tested on twenty, self-attention demonstrates superior performance compared to other network architectures. Results reveal a significant reduction in glycemic risk, from 16.5 to 9.6 in scenarios using sensor-augmented pump and from 9.1 to 6.7 in scenarios using automated insulin delivery. This new paradigm bypasses conventional therapy parameters, offering the potential to simplify treatment and promising improved quality of life and glycemic outcomes for people with T1D. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ifacol.2024.12.005,IFAC-PapersOnLine,"Modeling human trajectories in crowded environments is challenging due to the complex nature of pedestrian behavior and interactions. This paper proposes a geometric graph neural network (GNN) architecture that integrates domain knowledge from psychological studies to model pedestrian interactions and predict future trajectories. Unlike prior studies using complete graphs, we defne interaction neighborhoods using pedestrians' field of view, motion direction, and distance-based kernel functions to construct graph representations of crowds. Evaluations across multiple datasets demonstrate improved prediction accuracy through reduced average and final displacement error metrics. Our findings underscore the importance of integrating domain knowledge with data-driven approaches for effective modeling of human interactions in crowds. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ifacol.2025.01.153,IFAC-PapersOnLine,"As interactions with autonomous agents - ranging from robots in physical settings to avatars in virtual and augmented realities - become more prevalent, developing advanced cognitive architectures is critical for enhancing the dynamics of human-avatar groups. This paper presents a reinforcement-learning-based cognitive architecture, trained via a sim-to-real approach, designed to improve synchronization in periodic motor tasks, crucial for applications in group rehabilitation and sports training. Extensive numerical validation consistently demonstrates improvements in synchronization. Theoretical derivations and numerical investigations are complemented by preliminary experiments with real participants, showing that our avatars can integrate seamlessly into human groups, often being indistinguishable from humans. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ifacol.2025.07.014,IFAC-PapersOnLine,"Enhancing the mobility and maneuverability of Unmanned Wheeled Ground Vehicles (UGVs) in off-road environments faces many challenges from the diversity of terrain conditions and their engendered uncertainties. Further, the architecture of the wheeled vehicle (skid-steered vs Ackermann-steered) plays a crucial role in developing and successfully executing motion plans. A growing literature showcases the better ability of Ackermann-steered wheeled mobile platforms to regulate their terrain-ground interactions and overall mobility & maneuverability performance in autonomous settings. However, these gains come with requirements to manage the wheel-Terrain interactions via more complex planning/navigation to realize the benefits. This is in contrast to the skid-steered platforms that passively accommodate kinematic and dynamic incompatibility via their (uncontrolled) wheel slip. To this end, we present an end-To-end Deep Reinforcement Learning (DRL) framework for an Ackermann-steered wheeled robot in an off-road uneven terrain setting. Within this framework, we explore various facets, multi-objective rewards, varying agent and policy choices to enable better rapid autonomy planning and control of high-speed offroad terrain traversal by Ackermann-steered vehicles. The initial results reported here show promise that the DRL approach can autonomously create dynamically feasible trajectories without explicitly requiring complex user-crafted first-principles modeling. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ifacol.2025.07.016,IFAC-PapersOnLine,"Connected autonomous electric vehicles promise improved fuel efficiency and traffic flow through informed decision-making. However, vehicular networks present a wider cyberattack surface for malicious agents and increase the likelihood of simultaneous physical faults. Existing methods for health monitoring and fault diagnosis are inadequate to address this new environment. We propose a two-stage machine learning-based method to diagnose cyberphysical faults-our architecture consists of a lightweight binary classifier to perform the preliminary task of localization, and a multi-head attention module to perform classification. To generalize to arbitrary platoon sizes, we leverage the platoon topology and consider measurements from vehicle pairs. We develop a simulation framework utilizing low-level EV dynamics for the simulation and study of simultaneous faults. On a dataset generated using this framework, we show that our method achieves good performance compared with baseline methods, and we additionally demonstrate robustness to measurement noise. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ifacol.2025.07.150,IFAC-PapersOnLine,"This paper presents a hierarchical framework for demand response optimization in air separation units (ASUs) that combines reinforcement learning (RL) with linear model predictive control (LMPC). We investigate two control architectures: a direct RL approach and a control-informed methodology where an RL agent provides setpoints to a lower-level LMPC. The proposed RL-LMPC framework demonstrates improved sample efficiency during training and better constraint satisfaction compared to direct RL control. Using an industrial ASU case study, we show that our approach successfully manages operational constraints while optimizing electricity costs under time-varying pricing. Results indicate that the RL-LMPC architecture achieves comparable economic performance to direct RL while providing better robustness and requiring fewer training samples to converge. The framework offers a practical solution for implementing flexible operation strategies in process industries, bridging the gap between data-driven methods and traditional control approaches. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ifacol.2025.08.103,IFAC-PapersOnLine,"The shift towards decentralised energy systems has given rise to Virtual Power Plants (VPPs), essential for managing Distributed Energy Resources. This study proposed a distributed management architecture for VPPs that resiliently provides aggregated power production to the main grid, irrespective of uncertainties in non-dispatchable resources. Exploiting a scenario optimisation formulation and a Lagrangian decomposition of the problem, we develop a distributed stochastic optimisation framework for VPP management that scales with the number of agents. The method's performance is tested across various network sizes and real generation and consumption data, showing that the constraint violation probability on the minimum service level remains constant as the number of agents increases, while maintaining a fixed amount of considered scenarios. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ifacol.2025.09.225,IFAC-PapersOnLine,"Sustainability and digitalization fundamentally change how production is planned and controlled. One of the central parts of production control is job scheduling, which has the potential to include vast amounts of data to improve the quality of solutions. However, solving the scheduling problem is not limited to financial or operational aspects anymore; solutions must also include social and environmental aspects. While this issue is increasingly recognized among a plethora of other aspects in literature, many approaches still only consider small subproblems leading to a strong fragmentation. This study, therefore, develops a holistic framework for intelligent scheduling to integrate sustainability and social responsibility objectives while simultaneously offering a solution to bringing together the multitude of influencing factors in the domain of scheduling. The development of the concept is based on a structured literature review and an expert questionnaire. The Scalable Modular Architecture for Scheduling is a module-based software solution that connects to the real production system based on asset administration shells and graph-based problem modeling. The graph is transformed into a vectorized representation using a heterogenous graph neural network and combined with energy and maintenance-related information to be fed to a scheduling agent. This module utilizes a proximal policy optimization architecture to select the next best action based on mutliple criteria regarding economical and sustainable aspects and feed this information back to the real system, closing the loop. The framework is validated on benchmark data sets. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ijepes.2021.107628,International Journal of Electrical Power and Energy Systems,"In this paper, a Reinforcement Learning (RL)-based approach to optimally dispatch PV inverters in unbalanced distribution systems is presented. The proposed approach exploits a decentralized architecture in which PV inverters are operated by agents that perform all computational processes locally; while communicating with a central agent to guarantee voltage magnitude regulation within the distribution system. The dispatch problem of PV inverters is modeled as a Markov Decision Process (MDP), enabling the use of RL algorithms. A rolling horizon strategy is used to avoid the computational burden usually associated with continuous state and action spaces, coupled with a computationally efficient learning algorithm to model the action-value function for each PV inverter. The effectiveness of the proposed decentralized RL approach is compared with the optimal solution provided by a centralized nonlinear programming (NLP) formulation. Results showed that within several executions, the proposed approach converges either to the optimal solution or to solutions with a PV curtailment excess of less than 2.5% while still enforcing voltage magnitude regulation. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ijepes.2023.109641,International Journal of Electrical Power and Energy Systems,"With the recent rapid uptake of photovoltaic (PV) resources, the overvoltage condition during low load periods or intermittent renewable generation is one of the most critical challenges for electricity distribution networks. Traditional model-based local or centralized control methods that rely on proper system parameters are difficult to mitigate rapid changes in power systems. Utilizing model-free/data-driven multiagent deep reinforcement learning (MADRL) has been recognized as an effective solution to active voltage control. However, existing MADRL-based control approaches trained solely on data are agnostic to the underlying real-world physics principles. Therefore, this paper aims to incorporate physical knowledge of regional distribution networks into MADRL's decision-making. The main contributions of this paper are summarized as follows. First, a novel physics-informed MADRL -based distributed voltage control method is proposed, which is still under a centralized training and distributed execution framework and only requires local measurements. Second, graph neural networks are employed to help MADRL agents learn graph knowledge (node features and topological information). Further, transformer is introduced to extract discriminative representations and ensure agents’ cooperative control. Third, we adopt a physics-guided architecture of neural networks in the actor network to stabilize the training process and improve sample efficiency. Finally, simulation results based upon modified IEEE 33-bus and 141-bus networks validate the proposed method's effectiveness, robustness and computation efficiency. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ijepes.2024.110022,International Journal of Electrical Power and Energy Systems,"Deep Reinforcement Learning (DRL) is effective in solving complex, non-linear optimization problems, which is particularly relevant in energy management within Integrated Energy Systems (IESs). However, DRL approaches conventionally focus on single-objective policy learning, which is inadequate for the multi-objective optimization tasks commonly encountered in IESs energy management. To improve this, these approaches typically combine multi-objectives, such as operating cost objective and safety objective into a single reward function using scalarization techniques. This reduces the fidelity and interpretability of the objective space and limits its applicability to a wide range of IESs energy management. To address these challenges, this paper presents a novel framework called Multi-Agent and Multi-Objective DRL (MAMODRL). This framework combines value function decomposition and policy gradient methods to achieve a Pareto-optimal solution. The IESs energy management is initially formulated as a multi-objective Markov decision process. Then, an advanced MAMODRL architecture is developed, which includes objective value function networks to facilitate policy optimization. Finally, based on the definition of dominance, Pareto frontier is approximated of IESs energy management. A case study suggests that the proposed approach is effective in solving the Pareto frontier for IESs energy management. To ensure the safe operation of the system, safety threshold is set at the Pareto frontier forming a Pareto optimization with safety conditions. Compared to traditional DRL approaches, the proposed approach is more flexible, interpretable, and capable of making multi-dimensional decisions. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ijepes.2025.110749,International Journal of Electrical Power and Energy Systems,"In order to achieve real-time active power dispatch (RAPD) efficiently and economically in a large-scale power system with high proportion of renewable energy, deep reinforcement learning (DRL) based dispatching agent is constructed for dynamic decision-making of RAPD. However, existing DRL methods have a deficiency in reasonably responding to the relatively long time-scale power schedule at the dispatching level, which undermines the cooperativity between the expected schedule and RAPD and also results in the incapability of well-tracking the operation preferences. In this paper, we present an improved DRL algorithm, called distributed partial-modulation proximal policy optimization (DPMPPO), to address this issue. In DPMPPO, a deep modulation network (DMN) is integrated into the proximal policy optimization (PPO) module, where DMN is designed to capture the operation preferences from historical operation data and correct the policy generated by the PPO module through specific partial modulation mechanism. In addition, we devise a distributed learning architecture suitable for DPMPPO to improve the efficiency of network training. The experiment is conducted in a modified IEEE-300 case. Compared with the existing DRL methods, the proposed DPMPPO allows the optimized dispatching policy to have reasonable cross-time-scale collaboration with the schedules and achieve the online decision-making of RAPD flexibly and economically. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ijin.2025.09.001,International Journal of Intelligent Networks,"In recent years, as the frequency and types of network attacks increase, Intrusion Detection Systems (IDSs) have become essential components of most organizations’ security infrastructure. Although the use of machine learning methods shows great promise for the design of effective IDSs, existing methods still have several limitations. Single classifiers are never able to recognize all types of attacks, regardless of the underlying algorithm. This paper proposes MIDES, a novel multi-layer IDS that integrates binary, multi-class, and meta-classifiers into a flexible architecture. MIDES employs a fast binary classifier to filter clearly benign traffic, an ensemble of specialized multi-class classifiers to analyze suspicious events, and a meta-classification layer to refine decisions. A self-adaptive agent dynamically selects the most appropriate decision strategy for each input using both static and dynamic heuristics. The system is designed to be extensible, adaptable to evolving threats, and efficient in real-time scenarios. The proposed system has been extensively evaluated on the well-known CIC-IDS2017 and CSE-CIC-IDS2018 public datasets and compared against state-of-the-art works, showing that MIDES achieves high accuracy across all 14 attack classes while significantly reducing classification time, outperforming the compared systems. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.inffus.2009.09.002,Information Fusion,"In this paper we present a Cooperative Surveillance Multi-Agent System (CS-MAS) architecture extended to incorporate dynamic coalition formation. We illustrate specific coalition formation using fusion skills. In this case, the fusion process is divided into two layers: (i) a global layer in the fusion center, which initializes the coalitions and (ii) a local layer within coalitions, where a local fusion agent is dynamically instantiated. There are several types of autonomous agent: surveillance-sensor agents, a fusion center agent, a local fusion agent, interface agents, record agents, planning agents, etc. Autonomous agents differ in their ability to carry out a specific surveillance task. A surveillance-sensor agent controls and manages individual sensors (usually video cameras). It has different capabilities depending on its functional complexity and limitations related to sensor-specific aspects. In the work presented here we add a new autonomous agent, called the local fusion agent, to the CS-MAS architecture, addressing specific problems of on-line sensor alignment, registration, bias removal and data fusion. The local fusion agent is dynamically created by the fusion center agent and involves several surveillance-sensor agents working in a coalition. We show how the inclusion of this new dynamic local fusion agent guarantees that, in a video-surveillance system, objects of interest are successfully tracked across the whole area, assuring continuity and seamless transitions. © 2009 Elsevier B.V. All rights reserved. © 2010 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.inffus.2023.102197,Information Fusion,"Wearable devices and smart sensors are increasingly adopted to monitor the behaviors of human and artificial agents. Many applications rely on the capability of such devices to recognize daily life activities performed by the monitored users in order to tailor their behaviors with respect to the occurring situations. Despite the constant evolution of smart sensing technologies and the numerous research in this field, an accurate recognition of in-the-wild situations still represents an open research challenge. This work proposes a novel approach for situation identification capable of recognizing the activities and the situations in which they occur in different environments and behavioral contexts, processing data acquired by wearable and environmental sensors. An architecture of a situation-aware wearable computing system is proposed, inspired by Endsley's situation-awareness model, consisting of a two-step approach for situation identification. The approach first identifies the daily life activities via a learning-based technique. Simultaneously, the context in which the activities are performed is recognized using Context Space Theory. Finally, the fusion between the context state and the activities allows identifying the complex situations in which the user is acting. The knowledge regarding the situations forms the basis on which novel and smarter applications can be realized. The approach has been evaluated on the ExtraSensory public dataset and compared with state-of-the-art techniques, achieving an accuracy of 96% for the recognition of situations and with significantly low computational time, demonstrating the efficacy of the two-step situation identification approach. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.inffus.2024.102226,Information Fusion,"Late gadolinium enhancement (LGE) is a specialized imaging technique used in cardiovascular magnetic resonance (CMR) imaging to detect and characterize areas of scar tissue or fibrosis within the heart muscle. After a heart attack, the affected region of the heart muscle becomes scarred due to insufficient blood supply. LGE CMR enhances the infarcted myocardium to appear with distinctive brightness compared to healthy tissues. It is primarily used to assess various heart conditions and can identify the extent and location of scar tissue, helping in risk stratification and guiding treatment decisions. Automated myocardium segmentation in LGE CMR poses challenges due to intensity heterogeneity caused by the accumulation of contrast agents in infarcted areas. Furthermore, LGE CMR images with gold standard labels are particularly scarce compared to other sequences, making the task even more demanding. Besides, the heart's motion involves complex non-rigid deformations, including regional wall thickening, circumferential, and longitudinal ventricular shortening, making it challenging to model. This work presents an unsupervised unpaired domain adaptive scar tissue segmentation framework aided with the self-attention generative adversarial network. Besides, we proposed a novel segmentation architecture based on a parallel transformer for scar segmentation and compared the results with and without style transfer GAN and unpaired style self-supervised attention GAN. Besides, to model longitudinal changes in scare, we used eight days’ time points as a source and 1 month and 12 as a target and applied our proposed attention-generative network to transfer style from one-time point to another time. Experiments on four different LGE MICCAI datasets from 2019 to 2023 achieved significantly better performance than state-of-the-art segmentation methods. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.infsof.2023.107325,Information and Software Technology,"Context: Software testing is applied to validate the behavior of the software system and identify flaws and bugs. Different machine learning technique types such as supervised and unsupervised learning were utilized in software testing. However, for some complex software testing scenarios, neither supervised nor unsupervised machine learning techniques were adequate. As such, researchers applied Reinforcement Learning (RL) techniques in some cases. However, a systematic overview of the state-of-the-art on the role of reinforcement learning in software testing is lacking. Objective: The objective of this study is to determine how and to what extent RL was used in software testing. Methods: In this study, a Systematic Literature Review (SLR) was conducted on the use of RL in software testing, and 40 primary studies were investigated. Results: This study highlights different software testing types to which RL has been applied, commonly used RL algorithms and architecture for learning, challenges faced, advantages and disadvantages of using RL, and the performance comparison of RL-based models against other techniques. Conclusions: RL has been widely used in software testing but has almost narrowed to two applications. There is a shortage of papers using advanced RL techniques in addition to multi-agent RL. Several challenges were presented in this study. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ins.2011.06.020,Information Sciences,"This study presents a multiagent architecture aimed at detecting SQL injection attacks, which are one of the most prevalent threats for modern databases. The proposed architecture is based on a hierarchical and distributed strategy where the functionalities are structured on layers. SQL-injection attacks, one of the most dangerous attacks to online databases, are the focus of this research. The agents in each one of the layers are specialized in specific tasks, such as data gathering, data classification, and visualization. This study presents two key agents under a hybrid architecture: a classifier agent that incorporates a Case-Based Reasoning engine employing advanced algorithms in the reasoning cycle stages, and a visualizer agent that integrates several techniques to facilitate the visual analysis of suspicious queries. The former incorporates a new classification model based on a mixture of a neural network and a Support Vector Machine in order to classify SQL queries in a reliable way. The latter combines clustering and neural projection techniques to support the visual analysis and identification of target attacks. The proposed approach was tested in a real-traffic case study and its experimental results, which validate the performance of the proposed approach, are presented in this paper. © 2013 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.ins.2017.05.050,Information Sciences,"This paper presents a new spiking neural network architecture with a meta-neuron which envelopes all the pre- and postsynaptic neurons in the network. The concept of the meta-neuron is inspired by the role of astrocytes in modulating synaptic plasticity in biological neural networks. The meta-neuron utilizes the global information stored in the network (synaptic weights) and the local information present in the input spike pattern to determine a weight sensitivity modulation factor for a given synapse. Based on the weight sensitivity modulation factor and the postsynaptic potential of a neuron, the meta-neuron based learning rule updates the synaptic weights in the network to produce precise shifts in the spike times of the postsynaptic neurons. Using this learning rule, an Online Meta-neuron based Learning Algorithm (OMLA) is presented for an evolving spiking neural classifier. The learning algorithm employs heuristic learning strategies for learning each input spike pattern. It can choose to add a neuron, update the network parameters or delete a spike pattern depending on the spike times of the output neurons. OMLA employs a meta-neuron with memory that stores only those spike patterns which are used to add a neuron to the network. These spike patterns (spike patterns in meta-neuron memory) are used as representative of past information stored in the network during subsequent neuron additions. The performance of OMLA has been compared with both the existing online learning and batch learning algorithms for spiking neural networks using the UCI machine learning benchmark data sets. The statistical comparison clearly indicates that the OMLA performs better than other existing online learning algorithms for spiking neural networks. Since, OMLA uses both, the global as well as the local information in the network, it is also able to perform better than other batch learning algorithms. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.iot.2023.100978,Internet of Things (The Netherlands),"The advent of the Internet of Things (IoT) has resulted in significant technical development in the healthcare sector, enabling the establishment of Medical Cyber–Physical Systems (MCPS). The increased number of MCPS generates a massive amount of privacy-sensitive data, hence it is important to enhance the security of devices and data transmission in MCPS. Earlier several research studies were undertaken in order to enhance security in healthcare, but none of them could adapt to changing behaviors of data attacks. Here the role of blockchain and Reinforcement Learning (RL) comes into play since it can adjust itself to the nature of changing attacks, thus preventing any kind of attacks. This work proposes a solution, named Cogni-Sec, which employs a decentralized cognitive blockchain and Reinforcement Learning architecture and addresses the security issue. Blockchain is incorporated in the approach for data storage and transmission to increase the degree of security in the MCPS modules. Hyperledger Fabric is applied as the blockchain base which shows transaction query results with nearly 10% increased throughput, 69% less memory consumption, and 15% lower CPU usage when compared to Ethereum. Further security risk at the block mining level within a blockchain network is reduced by introducing distributed Reinforcement Learning architecture in replacement for the miner nodes, which imitates the cognitive behavior of miners in a distributed environment. Different multi-agent learning systems have been evaluated for building the mining agent. Among these, the a3c agent in distributed learning setup yields the optimum cumulative reward with a median value of 54.5 and minimizes the maximum number of data threats. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.iot.2024.101131,Internet of Things (The Netherlands),"The rapid advancement in sensors and communications has led to the expansion of the Internet of Things (IoT) services, where many devices need access to the transport network using fixed or wireless access technologies and mobile Radio Access Networks (RAN). However, supporting IoT in RAN is challenging as IoT services may produce many short and variable sessions, impacting the performance of mobile users sharing the same RAN. To address this issue, network slicing is a promising solution to support heterogeneous service segments sharing the same RAN, which is a crucial requirement of the upcoming fifth-generation (5G) mobile network. This paper proposes a two-level network slicing mechanism for enhanced mobile broadband (eMBB) and Ultra-Reliable and Low Latency communications (URLLC) in order to provide end-to-end slicing at the core and edge of the network with the aim of reducing latency for IoT services and mobile users sharing the same core and RAN using the O-RAN architecture. The problem is modeled at both levels as a Markov decision process (MDP) and solved using hierarchical reinforcement learning. At a high level, an SDN controller using an agent that has been trained by a Double Deep Q-network (DDQN) allocates radio resources to gNodeBs (next-generation NodeB, a 5G base station) based on the requirements of eMBB and URLLC services. At a low level, each gNodeB using an agent that has been trained by a DDQN allocates its pre-allocated resources to its end-users. The proposed approach has been demonstrated and validated through a real testbed. Notably, it surpasses the prevalent approaches in terms of end-to-end latency. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.iswa.2023.200181,Intelligent Systems with Applications,"A large amount of assets characterizes high-dimensional portfolio selection problems compared to temporal observation. In such a high-dimensional framework, the asset allocation is unfeasible because the covariance matrix obtained with the usual sample estimators cannot be inverted. This paper proposes a new shrinkage estimator based on reinforcement learning for large covariance matrices that is optimal in the context of portfolio selection. The resulting estimator is entirely data-driven since the optimal shrinkage intensity is given by optimizing neural network weights. This paper presents two different architectures: a standard fully connected network for a classical Policy Gradient Agent (PGA) and a Gated Recurrent Unit for a Recurrent Policy Gradient Agent (RPGA). To show the validity of the proposal, an application to asset allocation with Industry portfolios is provided. The results indicate that the RPGA-based approach in shrinkage estimation provides the best performance in out-of-sample comparison. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.iswa.2023.200216,Intelligent Systems with Applications,"The Industrial Internet of Things (IIoT) revolution has emerged as a promising network that enhanced information dissemination about the city's resources. This city's resources are wirelessly connected to different constrained devices (such as sensors, robotics, and actuators). However, the communication of this wireless information is threatened by several malicious attacks, cyber-attacks, and hackers. This is due to unsecured IIoT networks that were exposed as a potential back door entry point for the attacks. Consequently, this study aims to develop a security framework for the smart cities’ sustainability edge computing vulnerabilities using Petri Net and Genetic Algorithm-Based Reinforcement Learning (GARL). First, a common trust model for addressing information outflows in the network using a distributed authorization algorithm is proposed. This algorithm is implemented on a secure framework modeling in Petri Net called secure trust-aware philosopher privacy and authentication (STAPPA) for mitigation of the privacy breach in the networks. Genetic Algorithm-based Reinforcement Learning (GARL) is used to optimize the search, detect anomalies, and shortest route during the agent learning in the environment. The detection and accuracy rate results obtained over a secure framework using reinforcement learning are 98.75, 99, 99.50, 99.75, and 100% during simulation in the network environment. The average sensitivity of the detection rate is 1.000, while the average specificity outcome is 0.868. The result of the GARL simulation model obtained shows the best distance of 238.84 * 10−3 fitness when the search space is optimized by reducing the number of chromosomes to 10 in the model. These approaches help to detect anomalies and prevent unauthorized users from accessing edge computing components in the city architecture. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.jai.2025.01.001,Journal of Automation and Intelligence,"This paper presents an optimized shared control algorithm for human–AI interaction, implemented through a digital twin framework where the physical system and human operator act as the real agent while an AI-driven digital system functions as the virtual agent. In this digital twin architecture, the real agent acquires an optimal control strategy through observed actions, while the AI virtual agent mirrors the real agent to establish a digital replica system and corresponding control policy. Both the real and virtual optimal controllers are approximated using reinforcement learning (RL) techniques. Specifically, critic neural networks (NNs) are employed to learn the virtual and real optimal value functions, while actor NNs are trained to derive their respective optimal controllers. A novel shared mechanism is introduced to integrate both virtual and real value functions into a unified learning framework, yielding an optimal shared controller. This controller adaptively adjusts the confidence ratio between virtual and real agents, enhancing the system's efficiency and flexibility in handling complex control tasks. The stability of the closed-loop system is rigorously analyzed using the Lyapunov method. The effectiveness of the proposed AI–human interactive system is validated through two numerical examples: a representative nonlinear system and an unmanned aerial vehicle (UAV) control system. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.jallcom.2019.05.139,Journal of Alloys and Compounds,"Conductive ceramic films, such as indium tin oxide (ITO)and zinc oxide (ZnO)thin films, are expected to be used as core semiconducting materials for applications for the Internet of Things (IoT). In this study, we focused on a nonequilibrium excitation reaction field as a bottom-up architecture, and we successfully found the basis of a technology for fabricating the above films using a plasma atmosphere and an electron beam that uniformly emits electrons within a plane as a nonequilibrium reaction field. In particular, the ZnO thin film obtained in this study exhibited good electrical properties, such as a high Hall mobility of 128.3 cm2/V, even though it was formed on a polyethylene terephthalate (PET)film substrate at room temperature. This achievement may contribute to clarifying the mechanism behind the fabrication of highly functional oxide thin films by a two-dimensional simple process without thermal treatment of the substrate during the film formation. Moreover, this technique will also enable us to provide elements for next-generation nanodevices in IoT by controlling the surface and interface of nanostructures as well as highly functional properties using complexes of metals, ceramics, and semiconductors. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.jbi.2020.103483,Journal of Biomedical Informatics,"Monitoring patients through robotics telehealth systems is an interesting scenario where patients’ conditions, and their environment, are dynamic and unknown variables. We propose to improve telehealth systems’ features to include the ability to serve patients with their needs, operating as human caregivers. The objective is to support the independent living of patients at home without losing the opportunity to monitor their health status. Application scenarios are several, and they spread from simple clinical assisting scenarios to an emergency one. For instance, in the case of a nursing home, the system would support in continuously monitoring the elderly patients. In contrast, in the case of an epidemic diffusion, such as COVID-19 pandemic, the system may help in all the early triage phases, significantly reducing the risk of contagion. However, the system has to let medical assistants perform actions remotely such as changing therapies or interacting with patients that need support. The paper proposes and describes a multi-agent architecture for intelligent medical care. We propose to use the beliefs-desires-intentions agent architecture, part of it is devised to be deployed in a robot. The result is an intelligent system that may allow robots the ability to select the most useful plan for unhandled situations and to communicate the choice to the physician for his validation and permission. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.jbi.2020.103531,Journal of Biomedical Informatics,"This paper considers the problems of modeling and predicting a long-term and “blurry” relapse that occurs after a medical act, such as a surgery. We do not consider a short-term complication related to the act itself, but a long-term relapse that clinicians cannot explain easily, since it depends on unknown sets or sequences of past events that occurred before the act. The relapse is observed only indirectly, in a “blurry” fashion, through longitudinal prescriptions of drugs over a long period of time after the medical act. We introduce a new model, called ZiMM (Zero-inflated Mixture of Multinomial distributions) in order to capture long-term and blurry relapses. On top of it, we build an end-to-end deep-learning architecture called ZiMM Encoder-Decoder (ZiMM ED) that can learn from the complex, irregular, highly heterogeneous and sparse patterns of health events that are observed through a claims-only database. ZiMM ED is applied on a “non-clinical” claims database, that contains only timestamped reimbursement codes for drug purchases, medical procedures and hospital diagnoses, the only available clinical feature being the age of the patient. This setting is more challenging than a setting where bedside clinical signals are available. Our motivation for using such a non-clinical claims database is its exhaustivity population-wise, compared to clinical electronic health records coming from a single or a small set of hospitals. Indeed, we consider a dataset containing the claims of almost all French citizens who had surgery for prostatic problems, with a history between 1.5 and 5 years. We consider a long-term (18 months) relapse (urination problems still occur despite surgery), which is blurry since it is observed only through the reimbursement of a specific set of drugs for urination problems. Our experiments show that ZiMM ED improves several baselines, including non-deep learning and deep-learning approaches, and that it allows working on such a dataset with minimal preprocessing work. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.jbi.2020.103634,Journal of Biomedical Informatics,"Warfarin is an effective preventative treatment for arterial and venous thromboembolism, but requires individualised dosing due to its narrow therapeutic range and high individual variation. Many machine learning techniques have been demonstrated in this domain. This study evaluated the accuracy of the most promising algorithms on the International Warfarin Pharmacogenetics Consortium dataset and a novel clinical dataset of South African patients. Support vectors and linear regression were amongst the top performers in both datasets and performed comparably to recent stacked ensemble approaches, whilst neural networks were one of the worst performers in both datasets. We also introduced genetic programming to automatically optimise model architectures and hyperparameters without human guidance. Remarkably, the generated models were found to match the performance of the best models hand-crafted by human experts. Finally, we present a novel software framework (Warfit-learn) for warfarin dosing research. It leverages the most successful techniques in preprocessing, imputation, and parallel evaluation, with the goal of accelerating research and making results in this domain more reproducible. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.jestch.2023.101434,"Engineering Science and Technology, an International Journal","Plug-in Hybrid Electric Vehicles offer a promising solution for the increasing CO<inf>2</inf> emission problem. However, the improved economy strongly depends on the energy management strategy. Traditional rule-based strategies are no more practical considering the increasing complexity in control objectives. In this study, an adaptive online Reinforcement Learning (RL) agent is developed, which learned an energy management strategy with a near-optimal performance. A novel hybrid approach is proposed to integrate the agent into the existing rule-based hybrid control unit architecture with a limited operation domain for more practicality and suitability to series-production control systems. Dynamic Programming (DP) and rule-based strategy are used to benchmark the developed RL agent performance. The objective is to minimize the vehicle's total fuel consumption and the frequent engine on/off switching to improve driver comfort and vehicle drivability. Several RL-based algorithms have been experimented and as a result, an Extended-Deep Q-Network (E-DQN) agent is proposed by this paper, trained on one cycle, and deployed on two other cycles with different onboard energy levels to evaluate the performance. The paper findings showed that E-DQN outperformed the rule-based strategy achieving up to 10.46% improvement in fuel economy closer to the DP performance alongside providing adequate compliance with the vehicle drivability and driver comfort objectives. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.jestch.2025.102054,"Engineering Science and Technology, an International Journal","Based on the overall Field Oriented Control (FOC) control strategy of a Permanent Magnet Synchronous Motor (PMSM), a flexible and efficient control system architecture is developed in this work to achieve superior control performance. Sliding Mode Control (SMC) laws are utilized for both the inner and outer loop, but the typical cascade control characteristic of the system is maintained. Thus, the inner loop (IL) control laws are designed to provide increased flexibility by using fractional order (FO) computation and a response speed that is an order of magnitude higher than that of the outer loop (OL). The optimization of the tuning parameters of these controllers is performed by a computational intelligence (CI) algorithm, more specifically the Improved Grey Wolf Optimizer-Cuckoo Search Optimization (IGWO-CSO). The minimization of the computation time in the implementation of control algorithms is achieved by using a neural network (NN) that estimates the derivative value of the sliding surface in the structure of the SMC type speed controller. A term is added to the control law to cancel global perturbations of the system model, estimated with a Disturbance Observer (DO). Mitigation of the numerical stability problems of the derivative computation is achieved by using a Levant observer tracking differentiator. The use of Multi-Agent Reinforcement Learning (MARL) based on three properly trained Twin-Delayed Deep Deterministic (TD3) RL agents, which provide correction signals overlapping the control signals, contributes to the superior performance of the sensorless control system of the PMSM (SCS-PMSM). These include both parametric robustness to parameter and load torque variations, but also the use of an adaptation law to estimate the stator resistance, which can vary significantly. The superiority of the proposed SCS-PMSM over a benchmark control system based on Proportional Integrator (PI) controllers is demonstrated by following both the Software-in-the-Loop (SIL) and Hardware-in-the-Loop Simulated-Rapid Control Prototyping (HILS-RCP) phases. The realization of an RCP for the proposed RCP SCS-PMSM at different sampling periods corresponding to the implementation in both high performance and low/medium performance Digital Signal Processors (DSPs) is achieved using a SpeedGoat Performance Real-Time Target Machine platform. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.jfds.2023.100101,Journal of Finance and Data Science,"The construction of replication strategies for contingent claims in the presence of risk and market friction is a key problem of financial engineering. In real markets, continuous replication, such as in the model of Black, Scholes and Merton (BSM), is not only unrealistic but is also undesirable due to high transaction costs. A variety of methods have been proposed to balance between effective replication and losses in the incomplete market setting. With the rise of Artificial Intelligence (AI), AI-based hedgers have attracted considerable interest, where particular attention is given to Recurrent Neural Network systems and variations of the Q-learning algorithm. From a practical point of view, sufficient samples for training such an AI can only be obtained from a simulator of the market environment. Yet if an agent is trained solely on simulated data, the run-time performance will primarily reflect the accuracy of the simulation, which leads to the classical problem of model choice and calibration. In this article, the hedging problem is viewed as an instance of a risk-averse contextual k-armed bandit problem, which is motivated by the simplicity and sample-efficiency of the architecture, which allows for realistic online model updates from real-world data. We find that the k-armed bandit model naturally fits to the Profit and Loss formulation of hedging, providing for a more accurate and sample efficient approach than Q-learning and reducing to the Black-Scholes model in the absence of transaction costs and risks. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.jisa.2024.103856,Journal of Information Security and Applications,"The emerging Internet of Things (IoT) landscape is characterized by a high number of heterogeneous smart devices and services often provided by third parties. Although machine-based Service Level Agreements (SLA) have been recently leveraged to establish and share policies in this scenario, system owners do not always give full transparency regarding the security and privacy of the offered features. Hence, the issue of making end users aware of the overall system security levels and the fulfillment of their privacy requirements through the provision of the requested service remains a challenging task. To tackle this problem, we propose a complete framework that allows users to choose suitable levels of privacy and security requirements for service acquisition in IoT. Our approach leverages a Deep Reinforcement Learning solution in which a user agent, inside the environment, is trained to select the best encountered smart objects providing the user target services on behalf of its owner. This strategy is designed to allow the agent to learn from experience by moving in a complex, multi-dimensional environment and reacting to possible changes. During the learning phase, a key task for the agent is to adhere to deadlines while ensuring user security and privacy requirements. Finally, to assess the performance of the proposed approach, we carried out an extensive experimental campaign. The obtained results also show that our solution can be successfully deployed on very basic and simple devices typically available in an IoT setting. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.jksuci.2013.08.002,Journal of King Saud University - Computer and Information Sciences,"Distributed applications provide challenging environment in today's advancing technological world. To enhance the aspects of better performance and efficiency in real scenario mobile agent's concept has been brought forward. As every technological movement is aligned with its repercussions, the mobile agent technology also has its inherent security loopholes. Usage of agent technology poses various security threats over networked infrastructure. Moreover numerous researches have already been proposed to take the edge off inherent security risk faced by mobile agent, but all these approaches did not resolve the malicious execution environment problem in permissible and effectual conduct. Gaining the understanding of mobile agent architecture and the security concerns, in this paper, we proposed a security protocol which addresses security with mitigated computational cost. The protocol is a combination of self decryption, co-operation and obfuscation technique. To circumvent the risk of malicious code execution in attacking environment, we have proposed fragmentation based encryption technique. Our encryption technique suits the general mobile agent size and provides hard and thorny obfuscation increasing attacker's challenge on the same plane providing better performance with respect to computational cost as compared to existing AES encryption. © 2016 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.jksuci.2023.101836,Journal of King Saud University - Computer and Information Sciences,"In recent years, autonomous electric vehicles (A-EVs) have attracted the attention of academia and industry. In urban mobility, this topology requires consensus to control behaviours under swarm robotics. Although several model-based solutions have successfully enhanced accuracy and overcome some limitations, specific technological, methodological, and security issues remain. In this study, we systematically reviewed existing research related to swarm intelligence and multi-agent systems in urban mobility. Based on the obtained results, we propose a new directed acyclic graph-based multilayer architecture model. Furthermore, we propose a long short-term memory recurrent neural network model to make predictions. To validate the model, available data based on real traffic in Madrid (Spain) were considered. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.jksuci.2024.102182,Journal of King Saud University - Computer and Information Sciences,"Artificial intelligence (AI) research on video games primarily focused on the imitation of human-like behavior during the past few years. Moreover, to increase the perceived worth of amusement and gratification, there is an enormous rise in the demand for intelligent agents that can imitate human players and video game characters. However, the agents developed using the majority of current approaches are perceived as rather more mechanical, which leads to frustration, and more importantly, failure in engagement. On that account, this study proposes an imitation learning framework to generate human-like behavior for more precise and accurate reproduction. To build a computational model, two learning paradigms are explored, artificial neural networks (ANN) and adaptive neuro-fuzzy inference systems (ANFIS). This study utilized several variations of ANN, including feed-forward, recurrent, extreme learning machines, and regressions, to simulate human player behavior. Furthermore, to find the ideal ANFIS, grid partitioning, subtractive clustering, and fuzzy c-means clustering are used for training. The results demonstrate that ANFIS hybrid intelligence systems trained with subtractive clustering are overall best with an average accuracy of 95%, followed by fuzzy c-means with an average accuracy of 87%. Also, the believability of the obtained AI agents is tested using two statistical methods, i.e., the Mann–Whitney U test and the cosine similarity analysis. Both methods validate that the observed behavior has been reproduced with high accuracy. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.jnlest.2024.100290,Journal of Electronic Science and Technology,"This paper presents a novel approach to dynamic pricing and distributed energy management in virtual power plant (VPP) networks using multi-agent reinforcement learning (MARL). As the energy landscape evolves towards greater decentralization and renewable integration, traditional optimization methods struggle to address the inherent complexities and uncertainties. Our proposed MARL framework enables adaptive, decentralized decision-making for both the distribution system operator and individual VPPs, optimizing economic efficiency while maintaining grid stability. We formulate the problem as a Markov decision process and develop a custom MARL algorithm that leverages actor-critic architectures and experience replay. Extensive simulations across diverse scenarios demonstrate that our approach consistently outperforms baseline methods, including Stackelberg game models and model predictive control, achieving an 18.73% reduction in costs and a 22.46% increase in VPP profits. The MARL framework shows particular strength in scenarios with high renewable energy penetration, where it improves system performance by 11.95% compared with traditional methods. Furthermore, our approach demonstrates superior adaptability to unexpected events and mis-predictions, highlighting its potential for real-world implementation. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.jnlssr.2023.06.001,Journal of Safety Science and Resilience,"China's natural disaster situation presents a complex and severe scenario, resulting in substantial human and material losses as a result of large-scale emergencies. Recognizing the significance of aviation emergency rescue, the state provides strong support for its development. However, China's current aviation emergency rescue system is still under construction and encounters various challenges; one such challenge is to match the dynamically changing multi-point rescue demands with the limited availability of aircraft dispatch. We propose a dynamic task assignment model and a trainable model framework for aviation emergency rescue based on multi-agent reinforcement learning. Combined with a targeted design, the scheduling matching problem is transformed into a stochastic game process from the rescue location perspective. Subsequently, an optimized strategy model with high robustness can be obtained by solving the training framework. Comparative experiments demonstrate that the proposed model is able to achieve higher assignment benefits by considering the dynamic nature of rescue demands and the limited availability of rescue helicopter crews. Additionally, the model is able to achieve higher task assignment rates and average time satisfaction by assigning tasks in a more efficient and timely manner. The results suggest that the proposed dynamic task assignment model is a promising approach for improving the efficiency of aviation emergency rescue. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.jocs.2014.01.004,Journal of Computational Science,"The paper presents the potential of using interoperable agent driven simulation to support development planning; indeed the use of simulation represents a strong benefit to improve planning of infrastructures and plants devoted to disaster relief, civil protection and/or support to country development; the paper describes models used to face these challenges and last updates in population modeling for these applications. The proposed models include population characteristics, need as well as their social networks. In humanitarian support operations and country reconstruction there is a huge potential to use simulators; the paper describes how these models should be designed to support training as well operational planning. The models should be able to consider the impacts of contingencies as well as to guarantee the quick responsiveness requirements for humanitarian crisis management. The authors propose a simulator to be shared and used among Armed Forces and Civil Agencies for addressing Crisis Management, Humanitarian Missions, Country Reconstruction and Development considering joint operations (i.e. Civil Military Cooperation); indeed the paper outlines the importance of training people devoted to guarantee interoperability among civil organization and military units in this sector. The paper describes the models based on interoperable simulation as well as the agents driving the entities during the simulation to create quickly complex scenarios able to consider the impact on population and communities of the different actions by including human behavioral models. The proposed approach guarantees interoperability among different simulators within an HLA (High Level Architecture) federation in order to recreate crisis scenarios combining detailed simulation of multiple factors. The proposed approach is verified and validated by proposing an experimental analysis where it is evaluated a set of construction projects (i.e. digging wells) in a stabilization area and their effectiveness both in terms of direct result (i.e. water availability) as well as of population consensus and disaster relief (i.e. stress mitigation, trustiness respect supporting players). © 2014. © 2014 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.jocs.2023.102171,Journal of Computational Science,"For active flow control (AFC), several frameworks have been developed to enable dynamic interactions between deep reinforcement learning (DRL) agents and computational fluids dynamics (CFD) environments. However, the highly coupled modules in the existing frameworks require massive development efforts to be applied to different flow scenarios. Moreover, these frameworks do not support applications to run flexibly on multiple nodes in high-performance computing (HPC) systems. Herein, we propose a new framework named as DRLFluent coupling an open-source DRL package with a well-developed general CFD solver, Ansys-Fluent. The distributed HPC deployment of DRLFluent is achieved by a broker architecture which enables the DRL client and CFD server written in different languages to communicate across different nodes via a pair of standardized interfaces. We have evaluated DRLFluent along with two other representative frameworks using a benchmark case in which a laminar flow around a circular cylinder (Re=100) is controlled by two synthetic jets. The strategy discovered in DRLFluent is capable of neutralizing the small asymmetry of the shedding vortices, yielding a higher drag reduction than the other two frameworks. When the number of parallel environments exceeds 20, DRLFluent exhibits the largest speedup among the frameworks evaluated. Capable of distributing workload across multiple nodes, DRLFluent is suitable for implementing DRL for AFC of complex flow scenarios which requires hundreds of cores or more. Benefitting from a loose coupling between DRL and CFD, the standardized interfaces and the user-friendly CFD solver, DRLFluent is readily applicable to a wide range of flow scenarios without laborious low-level programming efforts. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.jtbi.2023.111613,Journal of Theoretical Biology,"Cells rely on their cytoskeleton for key processes including division and directed motility. Actin filaments are a primary constituent of the cytoskeleton. Although actin filaments can create a variety of network architectures linked to distinct cell functions, the microscale molecular interactions that give rise to these macroscale structures are not well understood. In this work, we investigate the microscale mechanisms that produce different branched actin network structures using an iterative classification approach. First, we employ a simple yet comprehensive agent-based model that produces synthetic actin networks with precise control over the microscale dynamics. Then we apply machine learning techniques to classify actin networks based on measurable network density and geometry, identifying key mechanistic processes that lead to particular branched actin network architectures. Extensive computational experiments reveal that the most accurate method uses a combination of supervised learning based on network density and unsupervised learning based on network symmetry. This framework can potentially serve as a powerful tool to discover the molecular interactions that produce the wide variety of actin network configurations associated with normal development as well as pathological conditions such as cancer. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.knosys.2005.05.001,Knowledge-Based Systems,"An important ingredient in agent-mediated electronic commerce is the presence of intelligent mediating agents that assist electronic commerce participants (e.g. individual users, other agents, organisations). These mediating agents are in principle autonomous agents that interact with their environments (e.g. other agents and web-servers) on behalf of participants who have delegated tasks to them. For mediating agents a (preference) model of participants is indispensable. In this paper, a generic mediating agent architecture is introduced. Furthermore, we discuss our view of user preference modelling and its need in agent-mediated electronic commerce. We survey the state of the art in the field of preference modelling and suggest that the preferences of electronic commerce participants can be modelled by learning from their behaviour. In particular, we employ an existing machine learning method called inductive logic programming (ILP). We argue that this method can be used by mediating agents to detect regularities in the behaviour of the involved participants and induce hypotheses about their preferences automatically. Finally, we discuss some advantages and disadvantages of using inductive logic programming as a method for learning user preferences and compare this method with other approaches. © 2005 Elsevier B.V. All rights reserved. © 2008 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.knosys.2006.06.004,Knowledge-Based Systems,"Despite the rigour and ability of game theory to cope with oligopolistic electric markets, it fails to model many existing behaviours in the real-world circumstances. The traditional models such as statistical extrapolation or econometrics are not capable to anticipate the changes in the pattern of the market prices due to the future structural changes. Furthermore, in such free and open markets, there is a more intense need for each participant to benefit from a certain level of autonomy, while keeping some capabilities to interact, communicate, collaborate and negotiate with other participants in an efficient way. As a result, there is a need for a novel framework of modelling that could include game theoretical assumptions as well as other more complex assumptions. Agent technologies in general and agent-based simulation in particular offer this possibility. This paper proposes, in a decision-making perspective, a new multi-agent architecture specifically designed to support planning activities in decentralized electricity markets, with a certain level of flexibility. In this model, synthetic agents are created allowing flexible representations of the multi-functional market players and possible mergers and coalitions in the electricity market. © 2006 Elsevier B.V. All rights reserved. © 2008 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.knosys.2022.108304,Knowledge-Based Systems,"Traffic signal control (TSC) is an established yet challenging engineering solution that alleviates traffic congestion by coordinating vehicles’ movements at road intersections. Theoretically, reinforcement learning (RL) is a promising method for adaptive TSC in complex urban traffic networks. However, current TSC systems still rely heavily on simplified rule-based methods in practice. In this paper, we propose: (1) two game theory-aided RL algorithms leveraging Nash Equilibrium and RL, namely Nash Advantage Actor–Critic (Nash-A2C) and Nash Asynchronous Advantage Actor–Critic (Nash-A3C); (2) a distributed computing Internet of Things (IoT) architecture for traffic simulation, which is more suitable for distributed TSC methods like the Nash-A3C deployment in its fog layer. We apply both methods in our computing architecture and obtain better performance than benchmark TSC methods by 22.1% and 9.7% reduction of congestion time and network delay, respectively. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.knosys.2023.110440,Knowledge-Based Systems,"Intelligent Transportation Systems are essential due to the increased number of traffic congestion problems and challenges nowadays. Traffic Signal Control (TSC) plays a critical role in optimizing the traffic flow and mitigating the congestion within the urban areas. Various research works have been conducted to enhance the behavior of TSCs at intersections and subsequently reduce the traffic congestion. Researchers recently leveraged Deep Learning (DL) and Reinforcement Learning (RL) techniques to optimize TSCs. In RL framework, the agent interacts with surrounding world through states, rewards and actions. The formulation of these key elements is crucial as they impact the way the RL agent behaves and optimizes its policy. However, most of existing frameworks rely on hand-crafted state and reward designs, restricting the RL agent from acting optimally. In this paper, we propose a novel approach to better formulate state and reward definitions in order to boost the performance of the traffic signal controller agent. The intuitive idea is to define both state and reward in a consistent and straightforward manner. We advocate that such a design approach helps achieving training stability and hence provides a rapid convergence to derive best policies. We consider the double deep Q-Network (DDQN) along with prioritized experience replay (PER) for the agent architecture. To evaluate the performance of our approach, we conduct series of simulations using the Simulation of Urban MObility (SUMO) environment. The statistical analysis of our results show that the performance of our proposal outperforms the state-of-the-art state and reward design approaches. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.knosys.2024.112402,Knowledge-Based Systems,"Dynamic obstacle avoidance (DOA) is a fundamental challenge for any autonomous vehicle, independent of whether it operates in sea, air, or land. This paper proposes a two-step architecture for handling DOA tasks by combining supervised and reinforcement learning (RL). In the first step, we introduce a data-driven approach to estimate the collision risk (CR) of an obstacle using a recurrent neural network, which is trained in a supervised fashion and offers robustness to non-linear obstacle movements. In the second step, we include these CR estimates into the observation space of an RL agent to increase its situational awareness. We illustrate the power of our two-step approach by training different RL agents in a challenging environment that requires to navigate amid multiple obstacles. The non-linear movements of obstacles are exemplarily modeled based on stochastic processes and periodic patterns, although our architecture is suitable for any obstacle dynamics. The experiments reveal that integrating our CR metrics into the observation space doubles the performance in terms of reward, which is equivalent to halving the number of collisions in the considered environment. We also perform a generalization experiment to validate the proposal in an RL environment based on maritime traffic and real-world vessel trajectory data. Furthermore, we show that the architecture's performance improvement is independent of the applied RL algorithm. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.media.2019.02.007,Medical Image Analysis,"Automatic detection of anatomical landmarks is an important step for a wide range of applications in medical image analysis. Manual annotation of landmarks is a tedious task and prone to observer errors. In this paper, we evaluate novel deep reinforcement learning (RL) strategies to train agents that can precisely and robustly localize target landmarks in medical scans. An artificial RL agent learns to identify the optimal path to the landmark by interacting with an environment, in our case 3D images. Furthermore, we investigate the use of fixed- and multi-scale search strategies with novel hierarchical action steps in a coarse-to-fine manner. Several deep Q-network (DQN) architectures are evaluated for detecting multiple landmarks using three different medical imaging datasets: fetal head ultrasound (US), adult brain and cardiac magnetic resonance imaging (MRI). The performance of our agents surpasses state-of-the-art supervised and RL methods. Our experiments also show that multi-scale search strategies perform significantly better than fixed-scale agents in images with large field of view and noisy background such as in cardiac MRI. Moreover, the novel hierarchical steps can significantly speed up the searching process by a factor of 4–5 times. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.media.2022.102417,Medical Image Analysis,"Morphological abnormalities of the femoroacetabular (hip) joint are among the most common human musculoskeletal disorders and often develop asymptomatically at early easily treatable stages. In this paper, we propose an automated framework for landmark-based detection and quantification of hip abnormalities from magnetic resonance (MR) images. The framework relies on a novel idea of multi-landmark environment analysis with reinforcement learning. In particular, we merge the concepts of the graphical lasso and Morris sensitivity analysis with deep neural networks to quantitatively estimate the contribution of individual landmark and landmark subgroup locations to the other landmark locations. Convolutional neural networks for image segmentation are utilized to propose the initial landmark locations, and landmark detection is then formulated as a reinforcement learning (RL) problem, where each landmark-agent can adjust its position by observing the local MR image neighborhood and the locations of the most-contributive landmarks. The framework was validated on T1-, T2- and proton density-weighted MR images of 260 patients with the aim to measure the lateral center-edge angle (LCEA), femoral neck-shaft angle (NSA), and the anterior and posterior acetabular sector angles (AASA and PASA) of the hip, and derive the quantitative abnormality metrics from these angles. The framework was successfully tested using the UNet and feature pyramid network (FPN) segmentation architectures for landmark proposal generation, and the deep Q-network (DeepQN), deep deterministic policy gradient (DDPG), twin delayed deep deterministic policy gradient (TD3), and actor-critic policy gradient (A2C) RL networks for landmark position optimization. The resulting overall landmark detection error of 1.5 mm and angle measurement error of 1.4° indicates a superior performance in comparison to existing methods. Moreover, the automatically estimated abnormality labels were in 95% agreement with those generated by an expert radiologist. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.media.2025.103688,Medical Image Analysis,"We present a method for estimating, in real time, a 3D displacement field from a single fluoroscopic image. Our approach uses a fully convolutional network architecture to solve the associated inverse problem. Supervised learning is performed on synthetic data, using Digitally Reconstructed Radiographs as input and displacement fields as output. We use randomized Gaussian kernels to produce a synthetic training dataset with displacement fields that are smooth and diffeomorphic. In contrast to other 2D-3D registration methods, our novel data generation approach does not rely on a statistical motion model. This enables our model to accurately predict deformations unrelated to breathing or other predetermined motion patterns. As an example of clinical application, we show that our model is able to predict deformations related to percutaneous needle insertions accurately, potentially removing the need for contrast agent injection. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.neucom.2014.08.085,Neurocomputing,"Currently, there are many intelligent agent models that provide a number of components or abstractions to solve different types of problems. However, few of them provide abstractions or concepts that allow considering how to deal with complex dynamic environments (an environment that changes continuously in terms of available resources, global behavioral rules, etc.). In this work, we propose two abstractions that provide the developer with a new way of modeling reactive agent capabilities in dynamic environments. The first abstraction focuses on how to process the environmental stimuli as events; the second abstraction specifies how to launch tasks in response to events, which is an approach that is based on event-condition-action rules. Moreover, we present an example that is based on a call center CBR-based application, and a performance evaluation of the proposal is also provided. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.neucom.2017.01.120,Neurocomputing,"In this paper we propose to combine speech-based and linguistic classification in order to obtain better emotion recognition results for user spoken utterances. Usually these approaches are considered in isolation and even developed by different communities working on emotion recognition and sentiment analysis. We propose modeling the users emotional state by means of the fusion of the outputs generated with both approaches, taking into account information that is usually neglected in the individual approaches such as the interaction context and errors, and the peculiarities of transcribed spoken utterances. The fusion approach allows to employ different recognizers and can be integrated as an additional module in the architecture of a spoken conversational agent, using the information generated as an additional input for the dialog manager to decide the next system response. We have evaluated our proposal using three emotionally-colored databases and obtained very positive results. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.neucom.2019.09.112,Neurocomputing,"Quality of life (QoL) is an effective index of well-being, including physical health, aspect of social activity, and mental state of individuals. A new approach that uses a deep-learning architecture to estimate the score of a user's QoL is presented. This system was built using a combination of a 3D convolutional neural network and a support vector machine for multimodal data. In order to evaluate the accuracy of the estimation system, three experiments were conducted. Before these experiments, ten hours of audio and video data were collected from healthy participants during a natural-language conversation with a conversational agent we implemented. In the first experiment, the QoL question-answer estimation experiment, the accuracy of “Physical functioning,” which is one of the eight scales that constitute QoL, reached 84.0%. In the second experiment, the QoL-score-regression experiment, in which the scores of each scale were directly estimated, the distribution of the difference between the actual score and the estimated results, known as error, was investigated. These results imply that the features necessary for QoL estimation can be extracted from audio and video data, except for the “Mental Health” domain. One of the reasons why it was difficult to estimate the “Mental Health” scale may be that the learning framework could not extract an appropriate feature for estimation. Therefore, we estimated “Mental Health” by focusing on eye movement. From the result, it was proven that estimation is possible, and the proposed system using multimodal data demonstrated its effectiveness for estimation for all eight scales that constitute QoL and for extracting high-dimensional information regarding the QoL of a human, including their satisfaction level towards daily life and social activities. Finally, suggestions and discussions regarding the plausible behavior of the estimation results were made from the viewpoint of human–agent interaction in the field of elderly welfare. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.neucom.2020.05.117,Neurocomputing,"The optimization of energy use in family homes and public buildings is an ongoing topic of discussion. State-of-the-art research has almost always focused on reducing the consumption of heating systems, air-conditioning or lighting. Despite their importance, user-related variables, such as comfort, are normally not included in the optimization process. These aspects should be considered to be able to effectively minimize energy consumption. Thus, there is a need for a comprehensive energy optimization approach, one that will consider both climatological factors and user behaviour. Learning about user behaviour is key to effective optimization. In this work, the proposed architecture's capacity to organize Virtual Agent Organizations (VAO) allows it to adapt to highly variable user behavior and preferences. This agent methodology has the ability to manage Wireless Sensor Networks (WSNs), Artificial Neural Networks (ANN) and Case-Based Reasoning (CBR) to obtain user preferences and predict their behaviour in the home or building. The proposed approach has been tested in two different buildings, a traditional-construction house and a modular home, obtaining savings of 30.16% and 13.43%, respectively. These results validate the proposed mixed approach of temperature adjustment algorithms together with the extraction of user behavior patterns for the establishment of a threshold based on preferences. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.neucom.2024.127874,Neurocomputing,"This paper presents a shallow end-to-end vision-based deep learning approach for autonomous vehicle driving in traffic scenarios. The primary objectives include lane keeping and maintaining a safe distance from preceding vehicles. This study leverages an imitation learning approach, creating a supervised dataset for robot control from expert agent demonstrations using the state-of-the-art Carla simulator in different traffic conditions. This dataset encompasses three different versions complementary to each other and we have made it publicly available along with the rest of the materials. The PilotNet neural model is utilized in two variants: the first one with complementary outputs for brake and throttle control commands along with dropout; the second one incorporates these improvements and adds the vehicle speed. Both models have been trained with the aforementioned dataset. The experimental results demonstrate that the models, despite their simplicity and shallow architecture, including only small-scale changes, successfully drive in traffic conditions without sacrificing performance in free-road environments, broadening their area of application widely. Additionally, the second model adeptly maintains a safe distance from leading cars and exhibits satisfactory generalization capabilities to diverse vehicle types. A new evaluation metric to measure the distance to the front vehicle has been created and added to Behavior Metrics; an open-source autonomous driving assessment tool built on CARLA that performs experimental validations of autonomous driving solutions. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.neunet.2006.02.004,Neural Networks,"Many of our daily activities are supported by behavioural goals that guide the selection of actions, which allow us to reach these goals effectively. Goals are considered to be important for action observation since they allow the observer to copy the goal of the action without the need to use the exact same means. The importance of being able to use different action means becomes evident when the observer and observed actor have different bodies (robots and humans) or bodily measurements (parents and children), or when the environments of actor and observer differ substantially (when an obstacle is present or absent in either environment). A selective focus on the action goals instead of the action means furthermore circumvents the need to consider the vantage point of the actor, which is consistent with recent findings that people prefer to represent the actions of others from their own individual perspective. In this paper, we use a computational approach to investigate how knowledge about action goals and means are used in action observation. We hypothesise that in action observation human agents are primarily interested in identifying the goals of the observed actor's behaviour. Behavioural cues (e.g. the way an object is grasped) may help to disambiguate the goal of the actor (e.g. whether a cup is grasped for drinking or handing it over). Recent advances in cognitive neuroscience are cited in support of the model's architecture. © 2006 Elsevier Ltd. All rights reserved. © 2008 Elsevier B.V., All rights reserved.; MEDLINE® is the source for the MeSH terms of this document.",TOPIC
10.1016/j.neunet.2017.12.005,Neural Networks,"Previous studies have shown that spike-timing-dependent plasticity (STDP) can be used in spiking neural networks (SNN) to extract visual features of low or intermediate complexity in an unsupervised manner. These studies, however, used relatively shallow architectures, and only one layer was trainable. Another line of research has demonstrated – using rate-based neural networks trained with back-propagation – that having many layers increases the recognition robustness, an approach known as deep learning. We thus designed a deep SNN, comprising several convolutional (trainable with STDP) and pooling layers. We used a temporal coding scheme where the most strongly activated neurons fire first, and less activated neurons fire later or not at all. The network was exposed to natural images. Thanks to STDP, neurons progressively learned features corresponding to prototypical patterns that were both salient and frequent. Only a few tens of examples per category were required and no label was needed. After learning, the complexity of the extracted features increased along the hierarchy, from edge detectors in the first layer to object prototypes in the last layer. Coding was very sparse, with only a few thousands spikes per image, and in some cases the object category could be reasonably well inferred from the activity of a single higher-order neuron. More generally, the activity of a few hundreds of such neurons contained robust category information, as demonstrated using a classifier on Caltech 101, ETH-80, and MNIST databases. We also demonstrate the superiority of STDP over other unsupervised techniques such as random crops (HMAX) or auto-encoders. Taken together, our results suggest that the combination of STDP with latency coding may be a key to understanding the way that the primate visual system learns, its remarkable processing speed and its low energy consumption. These mechanisms are also interesting for artificial vision systems, particularly for hardware solutions. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.neunet.2022.03.041,Neural Networks,"Conversational gestures have a crucial role in realizing natural interactions with virtual agents and robots. Data-driven approaches, such as deep learning and machine learning, are promising in constructing the gesture generation model, which automatically provides the gesture motion for speech or spoken texts. This study experimentally analyzes a deep learning-based gesture generation model from spoken text using a convolutional neural network. The proposed model takes a sequence of spoken words as the input and outputs a sequence of 2D joint coordinates representing the conversational gesture motion. We prepare a dataset consisting of gesture motions and spoken texts by adding text information to an existing dataset and train the models using specific speaker's data. The quality of the generated gestures is compared with those from an existing speech-to-gesture generation model through a user perceptual study. The subjective evaluation shows that the model performance is comparable or superior to those by the existing speech-to-gesture generation model. In addition, we investigate the importance of data cleansing and loss function selection in the text-to-gesture generation model. We further examine the model transferability between speakers. The experimental results demonstrate successful model transferability of the proposed model. Finally, we show that the text-to-gesture generation model can produce good quality gestures even when using a transformer architecture. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.patrec.2019.11.035,Pattern Recognition Letters,"Within the area of intelligent User Interfaces, we propose what we call Sentient Embodied Conversational Agents (SECAs): virtual characters able to engage users in complex conversations and to incorporate sentient capabilities similar to the ones humans have. This paper introduces SECAs together with their architecture and a publicly available software library that facilitates their inclusion in applications –such as educational and elder-care– requiring proactive and sensitive agent behaviours. In fact, we illustrate our proposal with a virtual tutor embedded in an educational application for children. The evaluation was performed in two stages: firstly, we tested a version with basic textual processing capabilities; and secondly, we evaluated a SECA with Machine-Learning-enhanced user understanding capabilities. The results show a significant improvement in users’ perception of the agent's understanding capability. Indeed, the Response Error Rate decreased from 22.31% to 11.46% using ML techniques. Moreover, 99.33% of the participants consider the global experience of talking with the virtual tutor with sentient capabilities to be satisfactory. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2010.12.135,Procedia Computer Science,"The majority of Intelligent Tutoring System architectures are focused on supporting learners through content retrieval or in one or more given subject matters; examples of this can be found in Baghera [1], MyClass, Andes [2], Gramy, Advanced Geometry Tutor [7]. The implementation of such architectures are time-consuming and are generally not interoperable with other domains [3]. The presented research describes the experimentation of a Open Source, LMS enhanced with elements of AI aiming at supporting online teachers' and tutors' work by using a KB specific to relational and pedagogical aspects, not connected to a specific subject matter. Such implementation needs to be provided of an authoring tool easily and readily usable by tutors and teachers of different subjects and with medium level IT training. Starting point of our investigation has been a preliminary analysis of machine-mediated, human-human interactions (MM-HHI) and communications by using the Teachers' thinking approach [4] [5] [6]. We considered messages exchanged between teachers/tutors and online students in three post-graduate, online courses running at the University of Macerata during 2008 - 2010 by the Faculty of Education. The study showed that about 30% of messages concerned structured information that could be straightforwardly retrieved by an artificial agent; almost all remaining messages were instead deeply bound to student's learning path or required a significant input by the teacher/tutor, while the residual part of messages could - to some extents - be delegated to an intelligent agent having access to students' tracking data in order to display visual information to users or trigger alarms to tutors. The investigation carried out prompted us for the deployment of an Open Source chat-bot system that would retrieve information already coded into the courses or originated by students through the analysis of their activity logs; the chat-bot agent uses this structured information in order to answer students' most common questions hence relieving teachers and tutors from doing this repetitive task. The system is being implemented on a OLAT ver. 6.3 LMS loosely coupled to a JADE-based Multi Agent System in charge of processing user tracking data and running the ALICE chat-bot integrated with the platform messaging system. © 2010 Published by Elsevier Ltd. © 2011 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2012.04.203,Procedia Computer Science,"In this work, we describe a simple and powerful method to implement real-time multi-agent path-finding on Graphics Processor Units (GPUs). The technique aims to find potential paths for many thousands of agents, using the A* algorithm and an input grid map partitioned into blocks. We propose an implementation for the GPU that uses a search space decomposition approach to break down the forward search A* algorithm into parallel independently forward sub-searches. We show that this approach fits well with the programming model of GPUs, enabling planning for many thousands of agents in parallel in real-time applications such as computer games and robotics. The paper describes this implementation using the Compute Unified Device Architecture programming environment, and demonstrates its advantages in GPU performance compared to GPU implementation of Real-Time Adaptive A *. © 2012 Published by Elsevier Ltd. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2012.09.129,Procedia Computer Science,"Distal reward refers to a class of problems where reward is temporally distal from actions that lead to reward. The difficulty for any biological neural system is that the neural activations that caused an agent to achieve reward may no longer be present when the reward is experienced. Therefore in addition to the usual reward assignment problem, there is the additional complexity of rewarding through time based on neural activations that may no longer be present. Although this problem has been thoroughly studied over the years using methods such as reinforcement learning, we are interested in a more biologically motivated neural architectural approach. This paper introduces one such architecture that exhibits rudimentary distal reward learning based on associations of bottom-up visual sensory sequences with bottom-up proprioceptive motor sequences while an agent explores an environment. After sufficient learning, the agent is able to locate the reward through chaining together of top-down motor command sequences. This paper will briefly discuss the details of the neural architecture, the agent-based modeling system in which it is embodied, a virtual Morris water maze environment used for training and evaluation, and a sampling of numerical experiments characterizing its learning properties. © 2012 Published by Elsevier B.V. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2014.03.001,Procedia Computer Science,"Negotiation and collaboration issues in large organizations, with centralized control, across the globe, are becoming more complex with each passing day. The Acknowledged System of Systems (SoS) is a new approach that addresses some of these issues in a systematic, efficient manner. This paper proposes a hierarchical architectural framework to support Acknowledged SoS architecting and analysis for a Department of Defense (DoD) Acquisition process. A major challenge of the successful planning and evolution of an Acknowledged SoS is the lack of understanding of the impact of presence or absence of a system and its interface with another constituent system on the overall architecture. The agent based model (ABM) structure developed here provides Acknowledged SoS manager that has both ability to address the managerial issues as well as a decision making tool for SoS architecting. This paper offers a complete integration of the techniques used to represent SoS architectures. The work illustrates the modeling approach through a domain setting. © 2014 The Authors. Published by Elsevier B.V. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2014.03.050,Procedia Computer Science,"Acknowledged systems of systems (SoS) lie on a continuum between authoritarian central control and anarchy. The constituent systems are independent, with a life and purpose of their own. The systems require not only technical interfaces, but also social interactions, to create the SoS. A fuzzy optimization process may be used to select a desirable SoS configuration, but it may be unachievable due to the inability to persuade the systems to cooperate in the plan. Modeling the systems' internal decision processes could help understand how to design better SoS architectures. This research used generic, modular modeling processes to examine two proposed SoS architectures and the impact of degree of cooperation on the suitability of the achieved SoS. © 2014 The Authors. Published by Elsevier B.V. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2014.05.095,Procedia Computer Science,"In this paper we propose an agent-based system for Service-Oriented Architecture selfadaptation. Services are supervised by autonomous agents which are responsible for deciding which service should be chosen for interoperation. Agents learn the choice strategy autonomously using supervised learning. In experiments we show that supervised learning (Näive Bayes, C4.5 and Ripper) allows to achieve much better efficiency than simple strategies such as random choice or round robin. What is also important, supervised learning generates a knowledge in a readable form, which may be analyzed by experts. © The Authors. Published by Elsevier B.V. © 2015 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2014.05.397,Procedia Computer Science,"Supply chain coordination has emerged as one of the major areas for companies to gain a competitive edge in a globalized world. Business organizations are increasingly located at the intersection of multiple supply chain networks. Managing such networks is hugely dependent on automation through combining advanced technologies such as software agent technologies, service oriented technologies, Internet of Things etc. This paper presents a multi agent and web service framework for Collaborative Material Procurement System (CMPS) in a supply chain. The information used in CMPS is used in two forms: business service rules and service description cases. It utilizes this hybrid information in order to form appropriate service, by using rule-based reasoning (RBR) and case-based reasoning (CBR). This paper outlines the CMPS architecture, designed to automatically retrieve software-based services for the agents that coordinate the supply chain form a service repository using a semantics-driven service similarity assessment algorithm. © 2014 Published by Elsevier B.V. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2014.05.522,Procedia Computer Science,"Offices, factories and even private housings are more and more endowed with building management systems (BMS) targeting an increase of comfort as well as lowering energy costs. This expansion is made possible by the progress realized in pervasive computing, providing small sized and affordable sensing devices. However, current BMS are often based on proprietary tech-nologies, making their interoperability and evolution more difficult. For example, we observe the emergence of new applications based on intelligent data analysis able to compute more complex models about the use of the building. Such applications rely on heterogeneous sets of sensors, web data, user feedback and self-learning algorithms. In this position paper, we discuss the role of Web technologies for standardizing the application layer, and thus providing a framework for developing advanced building applications. We present our vision of TASSo, a layered Web model facing actual and future challenges for building management systems. © 2014 Published by Elsevier B.V. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2014.07.086,Procedia Computer Science,"The number of interruptions people experience on a daily basis has grown considerably over the last decade and this growth has not shown any signs of subsiding. In fact, with the In this work, an architecture for a cloud-based interruption management system for mobile device users is presented. The system draws from rich contextual information from the mobile device (i.e., user, task and environment dimensions) and real-time observations of the user's activities and then reasons about ideal times to interact with the user. The reasoning component (interruption algorithm) is situated in the cloud and implemented using a novel machine learning technique (an Adaptive Neuro Fuzzy Inference System). This research addresses the complex problem of determining the precise time to interact with a mobile device user and in so doing aims to reduce the negative aspects of interruptions. This paper also presents a new interruption taxonomy built on an existing framework, and a report on the current prototype developed. © 2014 Elsevier B.V. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2014.08.135,Procedia Computer Science,"The article presents the principles for creating intelligent tutoring systems, which are active in dynamically growing repositories of e-learning contents. To make such a system work it is necessary to give the contents appropriate structure to enable it to be used in numerous educational contexts. The architecture of intelligent tutoring system is based on wordnet based ontology with expert knowledge, which has been used for repository resource indexing, and which is a basic component of domain model. The solution in its entirety has been supplemented with software agent, responsible for linking the most relevant content in repository to predefined educational strategy. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2015.03.024,Procedia Computer Science,"Architecting large complex systems is a challenging task due to the presence of uncertainty, ambiguity, and subjectivity as well as the extremely large space of candidate architectures. While the traditional approach to system architecting is a 100% human process, there has been a relatively recent trend to incorporate computational tools to different degrees in the process, thus making it more interactive. Tradespace exploration and optimization tools are among the most frequently used decision-support tools for systems architecting. From a mathematical perspective, architecture optimization problems are usually non-linear, non-convex, and multi-objective combinatorial optimization problems that are at least NP-hard. For these reasons, heuristics are often used to solve architecture optimization problems. These heuristics can be domain-specific, leveraging human knowledge or experience about the problem, or domain-independent, utilizing very little or no domain knowledge. Most applications of optimization in systems architecting consist of a single heuristic or meta-heuristic. However, this approach often results in suboptimal performance and premature convergence, in many cases due to the inability of a single heuristic to adapt to the changing environment of the search space. Humans, on the other hand, can also be considered as heuristics that may be able to adapt more easily to new situations and can naturally recognize patterns in information that can contribute to creating high performing architectures. A hyper-heuristic approach is proposed to combine multiple heuristics, including the human, and adapt the search strategy over time by applying heuristics that display good performance. In order to achieve a beneficial cooperation between humans and computers, this paper discusses and compares two different modes of a multi-agent optimization framework (asynchronous and sequential) that attempt to integrate human and computational agents in a hyper-heuristic architecture optimization algorithm. Experiments are conducted on a real-world problem to architect an Earth observing satellite system with a focus on gathering climate data. © 2016 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2015.05.399,Procedia Computer Science,"Urban areas are characterised by high population densities and the resulting complex social dynamics. For urban planners to evaluate, analyse, and predict complex urban dynamics, a lot of scenarios and a large parameter space must be explored. In urban disasters, complex situations must be assessed in short notice. We propose the concept of an assisted decision support system to aid in these situations The system interactively runs a scenario exploration, which evaluates scenarios and optimize for desired properties. We introduce the SIM-CITY architecture to run such interactive scenario explorations and highlight a use case for the architecture, an urban fire emergency response simulation in Bangalore. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2015.07.182,Procedia Computer Science,"Healthcare is a broad subject with many different challenges, yet it is important and relatable to everyone. The aging Baby Boomer generation is an important healthcare issue today. In Canada, and many other developed nations, the number of citizens reaching the age of retirement and seniority is growing faster than the rate of citizens working and providing health related services. As people age they tend to require more frequent checkups and health services, ultimately putting a bigger resource drain on healthcare infrastructure. New advancements in Computer Science and Engineering are allowing the development of next generation applications with the purpose of providing healthcare services in a cost effective and efficient way. This paper proposes a multi-agent system for tracking and monitoring health data for patients. Furthermore, agents within the system use reinforcement learning techniques to build an adaptive user interface for each human user. The actions and behaviour of users are monitored and used to modify their respective user interface over time. To demonstrate the feasibility of the architecture, two scenarios are provided. We conclude with several possible future directions for this research. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2015.07.325,Procedia Computer Science,"This paper describes a reinforcement learning architecture that is capable of incorporating deeply learned feature representation of a robot's unknown working environment. An autoencoder is used along with convolutional and pooling layers to deduce the reduced feature representation based on a set of images taken by the agent. This representation is used to discover and learn the best route to navigate to a goal. The features are fed to an actor layer that can learn from a value function calculated by a second output layer. The policy is e-greedy and the effect is similar to actor-critic architecture where temporal difference error is back propagated from the critic to the actor. This compact architecture helps in reducing the overhead of setting up a desired fully fledged actor-critic architecture that typically needs extra processing time. Hence, the model is ideal for dealing with lots of data coming from visual sensor that needs speedy processing. The processing is accomplished off board due to the limitation of the used robot but latency was compensated by the speedy processing. Adaptability for the different data sizes, critical to big data processing, is realized by the ability to shrink or expand the whole architecture to fit different deeply learned feature dimensions. This added flexibility is crucial for setting up such model since the space dimensionality is not known prior to operating in the environment. Initial experimental results on real robot show that the agent accomplished good level of accuracy and efficacy in reaching the goal. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2015.08.354,Procedia Computer Science,"Canadian healthcare is a fundamental part of society. Challenges such as the aging baby boomer generation require the healthcare industry to meet higher demands while using fewer resources. Computer systems designed to record and report physical health properties of an individual person can be used in part to accomplish this task. In this paper, we present the architecture of a hypothetical multi-agent system designed to provide healthcare information about specific patients through continuous monitoring. The resulting data from the system is accessible by the patient to whom it belongs as well as his or her healthcare professional. Furthermore, the proposed system utilizes an adaptive user interface for the purpose of improving the overall experience for users with poor vision or motor skills. Specifically, we focus on the implementation of several of the key components involved in the adaptive user interface: learning component and the user model. To demonstrate the feasibility of the implementation two scenarios are provided. We conclude with several possible future directions for this research. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2015.09.019,Procedia Computer Science,"This study addresses the e-inclusion problem that relates to the inclusion of as many individuals as possible to enjoy benefits of information and communication technology. Despite the fact that European Union accepted e-inclusion declaration in 2006 which aims to reduce disparities that exist among individuals and to improve the level of e-skills among people, nowadays e-inclusion problem still exists. Therefore it is necessary to find out new approach to promote e-inclusion in society. We propose a more nuanced design approach that takes into account student's satisfaction with e-learning environment and e-materials, student's ability to learn, instructor willingness to share knowledge and others factors. Moreover we believe that e-inclusion means not only high level of digital skills but also the usage of these digital skills to benefit from technologies. To obtain predictors for algorithms we did e-inclusion data domain study based on knowledge management theory. The aim of proposed work is to present e-inclusion theoretical model which is based on integration of several algorithms as multiply linear regression and cluster analysis. These algorithms were calculated based on statistical data obtained on evaluating a group of five hundred blended e-course learners. In this paper we propose architecture designed to predict e-inclusion degree of student based on machine learning and intelligent agent approach. We identified two main processes in the e-inclusion prediction system. The first process consists of agent learning activities. Intelligent agents learn the most appropriate algorithm to predict e-inclusion degree of student based on linear regression or cluster analysis. The second process includes activities to predict e-inclusion degree of student. This process covers analysis of e-inclusion risks and communication between student and instructor also. Proposed e-inclusion model consists of goal diagram, use cases diagrams and main algorithms of the system. As the result of the e-inclusion model is prediction of e-inclusion degree of person as well as e-inclusion risk factors for person, for instance inappropriate e-learning materials or no interest to learn, or dissatisfaction with e-learning environment, or others factors. © 2016 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2015.12.033,Procedia Computer Science,"One of the most relevant topics in warehouse management system (WMS) is the security issue and concerns the optimal placement allocation of products with respect of product and human safety in a sustainable system. Knowing that differences often exist between virtual view of products placements in centralized WMS and the real situation in the facility due to unplanned movements resulting from human errors or products' misplacements, we propose a reactive and compatibility constraint approach for product storage allocation. Our aim is to reduce the size of floating locations largely used in WMS and to avoid the inherent risks of hazardous accidents which can be generated by incompatibility between products and then to minimize the total logistic costs and to guarantee higher warehousing service levels in a safety monitored environment. This work proposes a multi-agent architecture for product allocation planning with compatibility constraints (PAP/CC), which uses a decision mechanism for product's placement, based on negotiations between agents associated to compatibility tests. This approach represents an improvement key for decentralized management of warehouses in a dynamic and reactive environment. Negotiations mechanisms relying on an Internet of Things (IoT) infrastructure and multi agent systems are defined in order to solve security problem of product allocation operations. Industrial deployment of IoT platform represents an ideal solution for decentralized management and to support collaboration between products and shelves. A simulation case of the proposed interactions mechanisms is provided with the use of NetLogo environment which offers many advantages to control agents and to describe their interactions in a graphical environment. © 2016 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2016.04.226,Procedia Computer Science,"In the last five years, electricity markets have undergone an important transformation. The main reasons behind are the development of more competitive and profitable environments. Thus in many economies around the world it has gone from big monopolies to oligopolies, where competition laws of supply and demand govern their behavior. On the other hand, the experience of the agents involved in these markets are increasing regarding their level of knowledge of the environment and the facility for accessing information. Consequently, more robust models for measuring risk are required, allowing them to implement the operation planning in the short and medium terms. Agents have defined objectives that in most cases are focused on profit maximization under internal or external constraints. In this type of scenarios with open markets and free competition, it is very complex to consider all the variables involved. Previous research has been pursued in order to manage the operation of the power systems, smart grids, blackouts, stability, and prediction. There are also developed models that aim of establishing the best strategy in the energy auctions, which optimizes the profitability of generators. However, they exclude income from traders whose main function is brokering with a different risk exposure. In order to tackle this issue, in this paper we present a complex model that targets to obtain the financial equilibrium between agents to ensure the compliance of transactions (purchases and sales of energy), considering key risk indicators. We implemented a proof-of-concept service platform based on the proposed model called Risker and its architecture and features are depicted. © 2016 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2016.08.230,Procedia Computer Science,"In the paper we present a new original approach to a complex multi-phase process optimization problem that relies on dividing the optimization task into partial tasks related to the implementation of individual phases. To implement this concept, we propose a multi-agent approach. Its practical realization is shown on the example of manufacturing process for auto body parts made of the Advanced High Strength Steels (AHSS). Although it is a rather simple process consisting of only two phases, we assumed, however, that the results obtained will allow to extend further research to more complex problems. We present the operating principles of a multi-agent model, the flow of the messages between agents, and the architecture of the system. To ensure the proper speed of the whole system a simple and flexible multi-agent framework called Eve was used to develop a prototype of the system. Research performed, as well as preliminary tests have shown that a multi-agent approach can be successfully applied to reduce complexity of the whole optimization processes. Due to splitting a single, complex optimization process into several, partially independent optimization processes, delegating them to autonomous agents, and application of a knowledge-based reasoning system, significant advantage could be observed over to the solutions described so far in the literature. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2016.09.085,Procedia Computer Science,"Nowadays, novel architectures like Cloud and Internet of Things (IoT) make available several resources like computing nodes, environmental sensors etc. that enable the introduction of more and more intelligent systems able to face complex situations. In particular management of critical and dangerous situations may take advantage of those systems whose complexity is growing up faster and faster. In this scenario, it is difficult to orchestrate different autonomous systems in order to face with new, previously unmanaged emergencies. In this work we present a modeling methodology and a planning techniques based on a multi-agent model. Agents describe capabilities of each available IoT element in an area where a critical situation has occurred; the planning methodology exploit both classical and a new counter-example based approaches to build a coordination plan of resources in order to achieve given goals like traffic management or people flight during a terrorist attack.. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2017.01.127,Procedia Computer Science,"The paper studies the problem of scheduling a group of Earth remote sensing satellites. The following idea is proved: development of Earth remote sensing systems needs changing of approach to planning of their application. Problem statement is described. As criteria of efficiency, information delivery time, resolution and cost of request execution are used. The schedule has to comply with the following constraints: visibility between satellites, observation areas and data receiving points, storage capacity of the memory unit as well as coordination of operations on shooting, storing, transmitting and receiving data. Review of ways of problem solution is provided. Implementation of the approach has been suggested, where the sought schedule is built as dynamic balancing of interests of satellites, data receiving points and observation area agents. Multi-agent planning system is developed. Architecture of the system is described as well as functions of the modules it includes. Dynamically occurring events are taken into account when planning, including introduction of a new task or change of task options, failure of a satellite or means of communication. The experimental assessment of time spent on recovery of the damaged schedule is given. In conclusion benefits of the multi-agent approach at management of swarm of Earth remote sensing satellites are provided. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2017.05.034,Procedia Computer Science,"This paper presents an idea of a multi-agent decision support system. Agent-based technology allows for decentralized problem solving and creating complex decision support systems, mixing various processing techniques, such as simulation, reasoning and machine learning and allows for distributed knowledge. Our main contribution is an agent-based architecture for decision support systems which is an agent-based implementation of a labeled deductive system. Such approach allows to decompose an inference algorithm into separate modules and distribute knowledge base into parts. The system is tested on a domain of material choice support for casting. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2017.05.078,Procedia Computer Science,"With the continuous development of seaports, problems related to the storage of containers in terminals have emerged. Unfortunately, existing systems suffer limitations related to the distributed monitoring and control, real-time stacking strategies efficiency and their ability to handle dangerous containers. In this paper, we suggest a multi-agent architecture based on a set of knowledge models and learning mechanisms for disturbance and reactive decision making management. The suggested system is able to capture, store and reuse knowledge in order to detect disturbances and select the most appropriate container location by using a Case Based Reasoning (CBR) approach. The proposed system takes into account the storage of dangerous containers and combines Multi-Agent Systems (MAS) and case based reasoning to handle different types of containers. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2017.05.374,Procedia Computer Science,"In this paper, we address the problem of collaboration between logistics objects. This collaboration aims to effectively plan, implement, and control the flow of services and goods between a point of origin and a point of destination while ensuring their secure, optimized, and efficient distributions to consumers anytime, anywhere. To this end, we propose a multi-agent based solution where the architecture of each agent includes concurrent individual and collective Belief-Desire-Intension (BDI) structures to support and balance self and collaborative objectives. Our solution, which is adapted and applied to the context of smart logistics, puts a special focus on the important issue of logistics risk management. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2017.06.131,Procedia Computer Science,"Security threats are becoming very sophisticated and pervasive everywhere. Phishing threats in particular has a changeable nature and short life cycle that complicates the detection process. In this paper, we introduce a Multi-Agent System (MAS) as an adaptive intelligent technique that acts on top of distributed Case-Based Reasoning (CBR) Phishing Detection Systems (CBR-PDSs) as a Phishing Detection System Architecture (PDSA) that runs on large scale globally to constitute a robust worldwide Phishing Threat Intelligence (PTI) environment. The global collaborations of PTI introduces a proactive phishing detection technique, quarantines phishing threats via global threats sharing, and minimizes users' susceptibilities to hard-to-detect spear or advanced phishing attacks. Also, combining two intelligent systems in a unified interactive architecture facilitates the prediction process, increases the accuracy rate, easily tackles the dynamic and changeable behaviors of advanced phishing threats, and minimizes the false negative rate as well. The proposed architecture illustrates the consolidated interaction between intelligent agents and distributed CBR-PDSs in a PTI framework. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2017.08.092,Procedia Computer Science,"ACSM (Hayashida et al., 2014) consists of a method of discerning the aliased states in a POMDP (Partially Observable Markov Decision Process) which is one of Markov decision process such that an agent observes local information about the environment, and choosing the appropriate action based on the internal memory and the sensory information which an agent obtains from the environment. Though ACSM achieves the highest performance in the existing methods based on classifier systems, it requires a huge number of memories for the internal memories, and spends long time for some large scaled problems. This paper improves a classifier system, ACSM (Anticipatory Classifier System with Memory) focused on the process of learning of ACSM, and the aim of this paper is to make the system more efficient. The improved method is named ACSMr in this paper, and some numerical experiments using 5 kinds of maze problems which are well used as benchmark problems for POMDPs are executed. ACSMr achieves greater experimental result than the existing classifier systems for the maze problems. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2018.01.054,Procedia Computer Science,"Single-shot grid-based path finding is an important problem with the applications in robotics, video games etc. Typically in AI community heuristic search methods (based on A And its variations) are used to solve it. In this work we present the results of preliminary studies on how neural networks can be utilized to path planning on square grids, e.g. how well they can cope with path finding tasks by themselves within the well-known reinforcement problem statement. Conducted experiments show that the agent using neural Q-learning algorithm robustly learns to achieve the goal on small maps and demonstrate promising results on the maps have ben never seen by him before. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2018.09.013,Procedia Computer Science,"The proliferation of ontologies and multilingual data available on the Web has motivated many researchers to contribute to multilingual and cross-lingual ontology enrichment. Cross-lingual ontology enrichment greatly facilitates ontology learning from multilingual text/ontologies in order to support collaborative ontology engineering process. This article proposes a cross-lingual ontology enrichment (CLOE) approach based on a multi-agent architecture in order to enrich ontologies from a multilingual text or ontology. This has several advantages: 1) an ontology is used to enrich another one, written in a different natural language, and 2) several ontologies could be enriched at the same time using a single chunk of text (Simultaneous Ontology Enrichment). A prototype for the proposed approach has been implemented in order to enrich several ontologies using English, Arabic and German text. Evaluation results are promising and showing that CLOE performs well in comparison with four state-of-the-art approaches. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2019.04.098,Procedia Computer Science,"This paper describes the ongoing development of GEMSim, a GPU-based mobility simulator that is systematically designed for generic large-scale networks and population samples. In order to fully exploit the benefits of the massively parallel architecture of GPU hardware, in GEMSim, the structure of the overall simulation loop, the organisation of memory transactions on GPU, data structures on both GPU and host, and the learning process are considered carefully. First results for a large-scale scenario of Switzerland are presented, and show that a whole simulation loop of GEMSim is more than 12 times faster than MATSim, and mobility simulations run up to 58 times faster in GEMSim compared to MATSim. Thus, this GPU-based mobility simulator makes practical advanced traffic simulation and forecasting tools more accessible to planners and decision makers. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2019.08.039,Procedia Computer Science,"This research investigates the impact of edge agents on industrial plants in the era of the Internet of Things (IoT) and the increasing availability of internet connection. This paper proposes 'Edge Agent' a holistic solution to managing many devices on the edge and will give a brief introduction to the communication between agents and existing machinery as well as present results which were extracted from experiments performed with our solution under low load in terms of data and with a small number of devices in terms of distribution. As result of extensive architecture investigation for an optimal edge solution and its possible correlation to industrial applications, this paper will introduce edge agents, communication between agents and machinery and industrial applications. The paper will present some important findings on edge computing, compare main architectural aspects and will provide a broad view of how edge solutions might be built for this particular scenario. Having discussed how the ideal architecture works and having provided an overview about how it may be applied to industrial plants, the final section of this paper addresses how artificial intelligence will fit into edge solutions, introducing important trends like the one-shot-learning technique, forming a new source of “smart capabilities” to existing environments. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2020.02.212,Procedia Computer Science,"The creation and training of a smart conversational agent has long been a dream of the human race and a huge challenge for scientists and programmers. Until recently, it was still just a dream. However, state-of-the-art technologies, like deep learning and neural networks, give language teachers a new hope, providing them with smart chatbots able to learn through communication just like humans. Today, the availability of chatbots helps to create a new educational scenario for foreign language learners. It suits well their fast-paced lives, allowing multitasking and making the work of ESL educators a lot easier and a way more effective. In that way chatbots could represent one of the basic components of microlearning. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2020.02.222,Procedia Computer Science,"The present article deals with data collection in a given field using the agent-based technologies from various information sources of the Internet with the aim to ob-tain reliable and up-to-date data. The agent-based approach is illustrated by the data collection on the nuclear power plants operating all over the world. Three open information sources have been selected for data extraction. The information sources concerned have been analyzed and the features of data provision structure identified. In the course of the present work the following tools for the develop-ment of the software agents have been described: The browser control for human behavior simulation, HTML markup analysis using the XPath query language and data extraction from PDF-documents using regular expressions. Above all, the article considers the software architecture and the database scheme. In the re-sult of the software operation, data regarding 789 nuclear power plants has been obtained. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2021.01.061,Procedia Computer Science,"Generally, Online Travel Agent (OTA) has a review element where clients can give reviews of the facilities they have used. Availability of a huge volume of reviews makes it troublesome for service executives to know the percent of reviews that have an effect on their services. Thus, it is essential to develop a sentiment assessment technique with respect to hotel reviews, particularly in Indonesian language. This research makes use of Long-Short Term Memory (LSTM) model as well as the Word2Vec model. The integration of Word2Vec and LSTM variables used in this research are Word2Vec architecture, Word2Vec vector dimension, Word2Vec evaluation method, pooling technique, dropout value, and learning rate. On the basis of an experimental research performed through 2500 review texts as dataset, the best performance was obtained that had accuracy of 85.96%. The parameter combinations for Word2Vec are Skip-gram as architecture, Hierarchical Softmax as evaluation method, and 300 as vector dimension. Whereas the parameter combinations for LSTM are dropout value is 0.2, pooling type is average pooling, and learning rate is 0.001. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2021.07.048,Procedia Computer Science,"A Chatbot is a conversational agent that simulate human conversation, through text or voice messages. One of the first goals of a Chatbot is to interact with the user just like a human. When it comes to Health Chatbots, another main goal is to be able to get the correct answer to the user request. In this paper we propose a general Architecture of an AI-Powered Health Chatbot with Four components to reach the two goals, which integrates dialogue and communication part in natural language understanding (NLU) and natural language generation (NLG), and the expert part based on deep learning whose function is to give appropriate response from pre-formatted data. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2022.04.013,Procedia Computer Science,"UAV base station platform has become the current research hotspot of assisting ground base station for wireless coverage.At present, the most important issue is how to make path planning to provide the stable communication guarantee for multiple mobile users. In this article, we model the air-to-ground channel to describe the path loss between the UAV platform and the user and build a simulation environment for training based on the OpenAI-GYM architecture. In addition, this paper proposes a reinforcement learning algorithm based on intrinsic rewards, which uses the mean square error of the state prediction results to quantify the novelty of the state. Algorithms enable agents to efficiently carry out strategy iterations. Experiments results showed that our algorithm has a higher score and takes less time. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2022.09.091,Procedia Computer Science,"Motivational interviewing (MI) improves readiness for smoking cessation but can be time-intensive, require substantial expertise, and patients must still be linked with evidence-based cessation programs sensitive to local resources and patient preferences. Technology-assisted MI may provide a more efficient way to promote readiness and facilitate behavior change. This study developed the Technology Assisted Motivational Interviewing Coach (TAMI), a digital conversational agent that incorporates machine learning models to deliver MI for tobacco cessation and create tailored quit plans. This manuscript describes and evaluates the architecture and nested machine learning models within TAMI leveraged during the pilot clinical trial. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2022.12.218,Procedia Computer Science,"Products global demand constantly grows, along with drifts of the volume of waste produced, thus having a negative impact on the environment. Besides the advancement of artificial intelligence and cutting-edge sensing and actuation systems, allow for traditional recycling procedures to be digitised and become more efficient. Among these, automated sorting machines allow such efficacy, by using multiple recognition technologies to categorise items, instead of relying on humans to separate them. In this sense, this paper presents a new approach being included in the Cyber-Physical Sorting System (CPSS) capable to be adapted in different industries such as urban wastes, construction & demolition wastes as well as mineral sorting. The materials are laid out over a conveyor belt, where multi-purpose visual sensors (hyper-spectral, industrial and short-wave infrared) acquire images in order to classify and sort them in different bins using robotic arms. The architecture of the proposed CPSS allows the integration of additional sensors, increasing the interoperability with upcoming sensing devices. Furthermore, an intelligent hyper-spectral component adapted to urban wastes was developed that classifies glass, metal, paper, and plastic using multi-spectral data in visual and near-infrared ranges between 470nm - 975nm. Scatter-correction methods and derivatives were applied to extract noise-free features, while an exploratory analysis based on simple and robust Principal component analysis (PCA) was performed to identify the most significant principal components for the training phase. During the evaluation, the neural network performed better when normalisation and Savtizky and Golay (SG) filtering was applied to the dataset against other classifiers. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2023.01.205,Procedia Computer Science,"As of August 2022, the COVID-19 pandemic has accounted for over six million deaths globally. The urban population has been severely affected by this viral pandemic and the ensuing lockdowns, resulting in increased poverty and inequality, slowed economic growth, and a general decline in quality of life. This paper proposes a framework to evaluate the effects of the pandemic by combining agent-based simulations - based on Susceptible-Infectious-Recovered (SIR) model - with a hybrid neural network. A baseline agent-based model (ABM) incorporating various epidemiological parameters of a viral pandemic was developed, followed by an additional functional layer that integrates factors like agent mobility restrictions and isolation. It is inferred from the results that low population densities of agents and high restrictions on agent mobility could inhibit the rapid spread of the pandemic. This framework also envisages a hybrid neural network that combines the layers of convolutional neural network (CNN) and long-short-term memory (LSTM) architecture for predicting the spatiotemporal probability of infection spread using real-world pandemic data for future pandemics. This framework could aid designers, regulators, urban planners, and policymakers develop resilient, healthy, and sustainable urban spaces in post-COVID smart cities. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2023.12.206,Procedia Computer Science,"Conversational agents (CA) are software programs that can converse with users using natural language. They are now widely used in various domains, such as tourism, healthcare, and others, to perform tasks and provide permanent assistance to users by interacting with them in natural language. The development of such applications is a task that requires expertise in several fields, such as software engineering, machine learning, deep learning, and natural language processing (NLP). However, several platforms and frameworks on the market facilitate the building of CA, such as Dialogflow, Rasa, and others. Recently, several research studies have proposed solutions to reduce the workload of developers and designers by offering their model-driven development approaches using domain-specific languages (DSLs), which facilitate the automation of the development of CA. This work aims to provide an Overview of CA to identify and describe their architecture and the details of its key components. and discuss the tools and technologies for their development. At the same time, discover the research topics that focus on using DSLs for model-driven development to automate and speed up the creation of these agents and discover approaches and technologies employed to implement each of these DSLs. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.procs.2025.03.086,Procedia Computer Science,"The issue of building evacuation in the event of a fire is a significant concern in urban planning and architecture. In the absence of appropriate measures, an emergency situation can potentially result in disastrous outcomes. In this review article, we explore the application of agent-based modeling (ABM) in the simulation of building evacuations in the event of a free breakout. To address this issue, we present a synthesis of findings from several studies, highlighting the advantages of ABM in modeling complex evacuation dynamics such as crowd behavior, consideration of multiple parameters, and decision-making processes. Additionally, we provide insight into the simulation tools and techniques used in studies that demonstrate the practical applications of ABM in enhancing evacuation strategies. Furthermore, we identify current challenges, research gaps, and propose future directions to enhance the accuracy and effectiveness of fire evacuation modeling and simulations. This study aims to contribute to the improvement of proposed solutions and models for the development of successful, effective, and reliable evacuation plans to enhance the safety of occupants in buildings. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.proeng.2016.11.652,Procedia Engineering,"Variability embedded in the architecture, engineering, and construction industry often results from inefficient planning strategies, sub-optimal levels of coordination, and poor flow of information and resources. This inherent variability disrupts workflow in design, results in longer cycle times, increased costs, and rework; thus undermining design, as well as, construction performance. This paper addresses design workflow at the intersection of the social and process aspects of the design phase. These aspects have been studied separately in previous research works, which prevented capturing a comprehensive and realistic understanding of the design process. Accordingly, this study develops a new approach to qualitatively and quantitatively model the exchange of information between design players and pave the way to assessing the impacts of Building Information Modeling and new project procurement strategies on improving design workflow. Agent-based modeling is used to dynamically represent the relationship between social interactions and the diffusion of information between individuals and teams. The study presents a novel design workflow management approach that bridges the gaps in previous studies as it focuses on team structures, interaction dynamics, and information diffusion. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.promfg.2020.01.030,Procedia Manufacturing,"The purpose of this paper is to introduce a new framework for training and testing Reinforcement Learning (RL) algorithms for robotic unscrewing tasks. The paper investigates current disassembly technologies through a state-of-the-art analysis, and the basic concepts of reinforcement learning are studied. A comparable framework exists as an extension for OpenAI gym called Gym-Gazebo, which is tested and analysed. Based on this analysis, a design for a new framework is made to specifically support unscrewing operations in robotics disassembly of electronics waste. The proposed simulation architecture uses ROS as data middleware, Gazebo (with the ODE physics solver) for simulating the robot environment, and MoveIt as a controller. The Gazebo simulation consists of a minimalistic setup in order to stay focused on the architecture and usability of the framework. The simulation world interfaces with the RL-agent, using OpenAI Gym and ROS-topics, which can be adapted to interface with a real robot. Lastly, the work demonstrates the functionality of the system by implementing an application example using a Q-learning algorithm, and the results of this are presented. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.reth.2025.01.023,Regenerative Therapy,"The ovary provides an ideal environment for egg survival due to its distinct structure that directly contributes to the growth and maintenance of the follicle. The purpose of this study is to compare ovarian decellularization with herbal and chemical detergents. Sheep ovarian was used in this study. 1 % sodium dodecyl sulfate (SDS) as a chemical detergent and 1, 2.5, and 5 % Acanthophyllum (ACP) were used as herbal agents for decellularization. DNA content, histological characteristics, attenuated total reflection Fourier transform infrared spectroscopy (ATR-FTIR), biocompatibility, antibacterial test, hemocompatibility, and scanning electron microscope (SEM) were investigated. The results showed the DNA content in decellularization scaffolds with 1 % SDS and 5 % ACP was reduced suitably. Also, histological observations confirmed this finding, and the nuclei were completely removed in these two groups. Disorganization of collagen fibers and tissue architecture was observed more in the SDS group than in the ACP group. No group reported cytotoxicity and the best blood compatibility in decellularization with herbal agents was reported. Protein bands are largely conserved in all methods. Higher antibacterial properties were observed in the decellularization technique with ACP. Decellularization with 5%ACP, in addition to being able to completely remove cells in the tissue, can help preserve the ultrastructure of the ovary. Therefore, this plant agent can be introduced as a decellularization method for studies in this field. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.rineng.2025.104450,Results in Engineering,"This research focuses on the unified topology governance and connectivity challenge in wireless sensor networks (WSNs). We use a multilayered topology and transportation architecture containing numerous sources and develop a topology control mechanism based on the useful energy consumption at the sensors with the aid of a discrete fractional calculus approach. We design and test three topologies in mathematical frameworks, and results provide an agent-based model for assessing worm attacks on these networks, agent characteristics, parameters, and changeover criteria. We examined the network design model (NDM) and the accompanying characteristic polynomial, which delivers sufficient requirements for local stability of non-negative equilibria. The study demonstrates that the suggested approach expresses chaotic behaviors by the stability of fixed points. Dynamics are implemented for researching the behavior of network topologies in delayed parameters. The center manifold theorem applies to figure out the features of expanding recurring fluctuations. The elements in the framework are deliberately selected on their most significant attributes, the examination of topologies in observing worm behavior in more authentic settings. We create an optimal mitigation plan for the prior framework using the Pontryagin maximum principle (PMP) to broaden the vicinity of equilibrium while lowering the proportion of infested nodes in WSNs and prolonging network life. According to computation testimony, the unpredictable features of the NDM are strongly connected to the impermeable duration of the permitted node and staying steady for points that transform into vulnerable again upon recovery. We observe that the optimum influence technique dramatically enhances the efficiency of networks. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.robot.2025.104917,Robotics and Autonomous Systems,"This work presents improvements on BDI agent architectures towards expedited behaviour. Standard and even real-time BDI architectures, due the characteristics of their deliberative processes, can take considerable time deciding what to do, and this can present a significant delay when a prompt reaction is required in a critical situation. To address this issue without simply adding a pure reaction layer, we introduce a novel, expedited, BDI architecture capable of maintaining effective reasoning while providing adequate and fast reaction to perceptions that occur in a critical situation (E2BA). By ‘adequate’ we mean that a proper action is promptly decided and that the agent temporarily enters into an exceptional operation mode. In this paper we present a concrete implementation for our proposal as a variation of Jason, the leading BDI programming framework. Considering that our main target applications lay in the domain of robotics, we also make our implementation suitable to be used in conjunction with the Robot Operating System (ROS). We evaluate the proposed mechanism through two experiments. The first experiment shows significant (at least 2.7x) reaction-time improvements obtained from using our expedited Jason in comparison with ‘standard’ Jason. Moreover, the results show that expedited Jason reaction-times are not significantly affected as the agent gets busier (it is constant), in contrast to the exponentially increasing response-time of standard Jason. The second experiment addresses the usage of the proposed architecture within a realistic software-in-the-loop (SIL) application scenario: controlling an uncrewed aerial vehicle (UAV) on a fire-fighting mission. This second experiment is not only important for its realistic nature and for reinforcing the reaction-time improvements, but also because it illustrates the importance of changing the agent's operation mode when performing a failsafe procedure. The permanent overhead introduced by EB2A is very small, not more than 0.5% of the standard BDI reasoning cycle time. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.robot.2025.105131,Robotics and Autonomous Systems,"Cooperative mission planning for heterogeneous teams of mobile robots presents a unique set of challenges, particularly when operating under communication constraints and limited computational resources. To address these challenges, we propose the Cooperative and Asynchronous Transformer-based Mission Planning (CATMiP) framework, which leverages multi-agent reinforcement learning (MARL) to coordinate distributed decision making among agents with diverse sensing, motion, and actuation capabilities, operating under sporadic ad hoc communication. A Class-based Macro-Action Decentralized Partially Observable Markov Decision Process (CMacDec-POMDP) is also formulated to effectively model asynchronous decision-making for heterogeneous teams of agents. The framework utilizes an asynchronous centralized training and distributed execution scheme, enabled by the proposed Asynchronous Multi-Agent Transformer (AMAT) architecture. This design allows a single trained model to generalize to larger environments and accommodate varying team sizes and compositions. We evaluate CATMiP in a 2D grid-world simulation environment and compare its performance against planning-based exploration methods. Results demonstrate CATMiP's superior efficiency, scalability, and robustness to communication dropouts and input noise, highlighting its potential for real-world heterogeneous mobile robot systems. The code is available at https://github.com/mylad13/CATMiP. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.sca.2025.100166,Supply Chain Analytics,"Timely delivery is a critical performance metric in supply chain management, yet achieving consistent on-time delivery has become increasingly challenging in the face of global uncertainties and complex logistics networks. Recent disruptions, such as pandemics, extreme weather events, and geopolitical conflicts, have exposed vulnerabilities in supply chains, resulting in frequent delivery delays. While traditional heuristics and simple statistical methods have proven inadequate to capture the myriad factors that contribute to delays in modern supply chains, Machine learning (ML) and Deep Learning (DL) approaches have emerged as powerful tools to improve the accuracy and reliability of delivery delay prediction. Consequently, this study presents a hybrid predictive framework that integrates DL models with Reinforcement Learning (RL) to improve binary classification of order status (on-time vs. late). We first benchmark several DL architectures, Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), Bi-LSTM, and Stacked LSTM, enhanced with regularization and extended training epochs, alongside a fine-tuned eXtreme Gradient Boost (XGBoost) model. These models are evaluated using accuracy, precision, recall, and the F1-score, with Bi-LSTM and Stacked LSTM achieving strong generalization performance. Building on this, we deploy a Proximal Policy Optimization (PPO) agent that incorporates deep learning outputs as part of its observation space. The RL agent uses a reward-based feedback loop to improve adaptability under dynamic conditions. Experimental results show that the hybrid DL-RL model achieves superior classification accuracy and an F1-score greater than 0.99, outperforming standalone methods. Although the PPO agent alone struggled with detecting minorities due to imbalance, integrating DL features mitigated this limitation. The findings support the use of hybrid architectures for real-time order status prediction and provide a scalable pathway for intelligent supply chain decision making. Future work will address class imbalance and enhance policy robustness through cost-sensitive and explainable RL strategies. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.scico.2018.09.002,Science of Computer Programming,"Assessing the impacts of a mobility initiative prior to deployment is a complex task for both urban planners and transport companies. Computational models like Tangramob offer an agent-based framework for simulating the evolution of urban traffic after the introduction of new mobility services. However, simulations can be computationally expensive to perform due to their iterative nature and the microscopic representation of traffic. To address this issue, we designed a simplified model architecture of Tangramob in Timed Rebeca (TRebeca) and we developed a tool-chain for the generation runnable instances of this model starting from the same input files of Tangramob. Running TRebeca models allows users to get an idea of how the mobility initiatives under study affect the traveling experience of commuters, in a short time and without the need to use the simulator during this first experimental step. Then, once a subset of these initiatives is identified according to user's criteria, it is reasonable to simulate them with Tangramob in order to get more detailed results. To validate this approach, we compared the output of both the simulator and the TRebeca model on a collection of mobility initiatives. The correlation between the results demonstrates the usefulness of using TRebeca models for unconventional contexts of application. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.scs.2017.01.014,Sustainable Cities and Society,"The ongoing decentralization of the electrical power system encompasses the installation of residential electrical loads and generators, such as electro-thermal heating devices. Clusters of these devices in combination with thermal storage can play a significant role in future power system control as they introduce load and generation flexibility into the system. Hence, control concepts which are attractive for both power system level and end user side are required. This work proposes a novel decentralized scheduling approach for electro-thermal heating devices based on a multi-agent system architecture. As a major novelty, the approach addresses both of the aforementioned appeals on two levels without central control. First, local planning with individual objectives is performed. Second, the heating devices cooperate to find the combination of local plans serving best a given energy system objective. This approach is fully decentralized and has a strong end user involvement. The performance of the proposed approach related to end user and system level objectives is compared to that of centralized approaches. Simulation results show that the new method can successfully satisfy end user objectives and provide energy fluctuation balancing. Finally, drawbacks compared to centralized scheduling are analyzed. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.segan.2025.101790,"Sustainable Energy, Grids and Networks","This paper proposes a decentralized learning-based control scheme for solving the charging/discharging coordination problem of multiple electric vehicles (EVs) operating in a residential community, with a point of common coupling, a time-of-use tariff rate, and the uncertainty in the daily routine of the EV owners. In the proposed methodology, we model the interaction of the EV owners as a Markov Game and approach the problem through the lens of multi-agent reinforcement learning (MARL). To this end, we propose a novel belief-based Q-learning algorithm (BBQL), based on the distributed training and decentralized execution architecture. In BBQL, while training the agents form a belief about their neighbours (connected over a communication network) and simultaneously use it to better approximate their optimal action-value function. As for testing, each agent acts in a “pure” decentralized manner by playing its best-response to the developed belief. The proposed algorithm holds merit in addressing the typical key-aspects of MARL algorithms, i.e., scalability, privacy and fairness. Finally, we perform numerical simulations by using “real” historical demand, photovoltaic generation, electricity tariff and EV specification data. We compare the proposed BBQL with state-of-the-art Independent Learners. In particular, BBQL achieves a better trade-off between minimizing the electricity bill and maximizing the satisfaction of the range anxiety. Speaking statistically, BBQL results in ≈5 % increase in the number of days the range anxiety constraint is satisfied (with ≈11 % reduction in the standard deviation), while simultaneously reducing the average bill of the households by ≈4 % (with ≈13 % reduction in the standard deviation). © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.segy.2024.100163,Smart Energy,"This research work introduces a novel approach to energy management in Smart Energy Systems (SES) using Deep Reinforcement Learning (DRL) to optimize the management of flexible energy systems in SES, including heating, cooling and electricity storage systems along with District Heating and Cooling Systems (DHCS). The proposed approach is applied on Meridia Smart Energy (MSE), a french demonstration project for SES. The proposed DRL framework, based on actor–critic architecture, is first applied on a Modelica digital twin that we developed for the MSE SES, and is benchmarked against a rule-based approach. The DRL agent learnt an effective strategy for managing thermal and electrical storage systems, resulting in optimized energy costs within the SES. Notably, the acquired strategy achieved annual cost reduction of at least 5% compared to the rule-based benchmark strategy. Moreover, the near-real time decision-making capabilities of the trained DRL agent provides a significant advantage over traditional optimization methods that require time-consuming re-computation at each decision point. By training the DRL agent on a digital twin of the real-world MSE project, rather than hypothetical simulation models, this study lays the foundation for a pioneering application of DRL in the real-world MSE SES, showcasing its potential for practical implementation. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.simpa.2024.100615,Software Impacts,"Ant-based Topology Search (ANTS) is a Neural Architecture Search (NAS) inspired by ant colony optimization (ACO). ANTS encodes the neural structure search space within a highly interconnected structure. Optimization agents, like ants, navigate this structure in search of an optimal neural topology. Continuous Ant-based Topology Search (CANTS) builds upon ANTS by replacing the discrete search space with a 3D continuous one. CANTS introduces a fourth dimension for potential neural synaptic weights, transitioning from NAS to NeuroEvolution (NE). This automates artificial neural network design without relying on backpropagation, reducing optimization time and offering a promising approach for machine learning applications. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.simpat.2022.102620,Simulation Modelling Practice and Theory,"Named Entity Recognition and Intent Classification are among the most important subfields of the field of Natural Language Processing. Recent research has lead to the development of faster, more sophisticated and efficient models to tackle the problems posed by those two tasks. In this work we explore the effectiveness of two separate families of Deep Learning networks for those tasks: Bidirectional Long Short-Term networks and Transformer-based networks. The models were trained and tested on the ATIS benchmark dataset for both English and Greek languages. The purpose of this paper is to present a comparative study of the two groups of networks for both languages and showcase the results of our experiments. The models, being the current state-of-the-art, yielded impressive results and achieved high performance. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.softx.2025.102176,SoftwareX,"Electricity markets are undergoing transformative changes driven by integrating renewable energy and emerging technologies, and evolving market conditions such as shifting demand patterns, regulatory reforms, and increased price volatility. To address the complexity of electricity markets and their interactions, we present ASSUME, an open-source agent-based simulation framework that incorporates multi-agent deep reinforcement learning for modeling adaptive market participants. ASSUME offers a modular architecture for representing generator and demand-side agents, bidding strategies, and diverse market configurations. ASSUME has been proven effective in multiple research studies, demonstrating its ability to analyze complex bids, demand-side flexibility, and other market scenarios. By incorporating adaptive strategies through deep reinforcement learning, ASSUME supports dynamic strategy exploration, enabling a deeper understanding of electricity market behaviors. With its flexible architecture, documentation, tutorials, and broad accessibility, ASSUME ensures usability across different user groups, minimizing technical overhead and freeing up human resources for deeper insights into operational, economic, and policy-related challenges in this critical sector. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.softx.2025.102312,SoftwareX,"Cybersecurity demands increasingly adaptive techniques to detect and mitigate sophisticated threats. This paper presents MininetGym, a Software Defined Network (SDN)-based simulation framework with a modular architecture based on Mininet, offering high configurability for experiments aimed at evaluating Reinforcement Learning (RL) strategies in network traffic classification and attack detection tasks. Three use cases are implemented: (i) traffic classification, (ii) detection of Denial of Service attacks in real-time, and (iii) the extension of the simulator with custom environments. The framework supports tabular and deep RL agents and includes modular components for network emulation, traffic generation, and agent interaction. The framework generates evaluation metrics and visualizations, enabling users to analyze agent performance and understand their behavior in dynamic network conditions. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.swevo.2021.101017,Swarm and Evolutionary Computation,"This paper presents a novel grammar-based evolutionary approach which allows autonomous emergence of heterogeneity in collective behaviours. The approach adopts a context-free grammar to describe the syntax of evolving rules, which facilitates an evolutionary algorithm to evolve rule structures without manual intervention. We propose modifications to the genome structure to address the requirements of heterogeneity, and two cooperative learning architectures based on team learning and cooperative coevolution. Experimental evaluations with four behaviours illustrate that both architectures are successful in evolving heterogeneous collective behaviours. Both heterogeneous architectures surpass a homogeneous model in performance for deriving a flocking macro behaviour, however the homogeneous model is superior for evolving micro behaviours such as cohesion and alignment. The results infer that by placing the entire set of agent rules and their syntax under evolutionary control, effective solutions to complex problems can be evolved when human knowledge and intuition becomes insufficient. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.sysconle.2013.02.007,Systems and Control Letters,"This paper proposes a control scheme for distributed sensing using a leader/follower multi-agent architecture. The control objective is to make a group of mobile agents cover and sense a sequence of regions of interest. More specifically, when the leaders reach a new target region, they stop until the followers have performed a sensing task. Furthermore, the followers must be contained inside the convex-hull of the leaders' positions during the motion. Key features of our method, that combines hybrid control with Model Predictive Control (MPC) techniques, are the possibility to take into account input constraints in order to plan the sensing maneuver and the ability of the followers to detect containment violations by simple computation based on the available information about the leaders' positions. © 2013 Elsevier B.V. All rights reserved. © 2013 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.tcs.2011.06.017,Theoretical Computer Science,"In this paper we consider the problem of connected edge searching of weighted trees. Barrire et al. claim in [L. Barrire, P. Flocchini, P. Fraigniaud, N. Santoro, Capture of an intruder by mobile agents, in: SPAA'02: Proceedings of the Fourteenth Annual ACM Symposium on Parallel Algorithms and Architectures, ACM, New York, NY, USA, 2002, pp. 200209] that there exists a polynomial-time algorithm for finding an optimal search strategy, that is, a strategy that minimizes the number of used searchers. However, due to some flaws in their algorithm, the problem turns out to be open. It is proven in this paper that the considered problem is strongly NP-complete even for node-weighted trees (the weight of each edge is 1) with one vertex of degree greater than 2. It is also shown that there exists a polynomial-time algorithm for finding an optimal connected search strategy for a given bounded degree tree with arbitrary weights on the edges and on the vertices. This is an FPT algorithm with respect to the maximum degree of a tree. © 2011 Elsevier B.V. All rights reserved. © 2011 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.trc.2019.07.006,Transportation Research Part C: Emerging Technologies,"Population synthesis is concerned with the generation of synthetic yet realistic representations of populations. It is a fundamental problem in the modeling of transportation where the synthetic populations of micro-agents represent a key input to most agent-based models. In this paper, a new methodological framework for how to ‘grow’ pools of micro-agents is presented. The model framework adopts a deep generative modeling approach from machine learning based on a Variational Autoencoder (VAE). Compared to the previous population synthesis approaches, including Iterative Proportional Fitting (IPF), Gibbs sampling and traditional generative models such as Bayesian Networks or Hidden Markov Models, the proposed method allows fitting the full joint distribution for high dimensions. The proposed methodology is compared with a conventional Gibbs sampler and a Bayesian Network by using a large-scale Danish trip diary. It is shown that, while these two methods outperform the VAE in the low-dimensional case, they both suffer from scalability issues when the number of modeled attributes increases. It is also shown that the Gibbs sampler essentially replicates the agents from the original sample when the required conditional distributions are estimated as frequency tables. In contrast, the VAE allows addressing the problem of sampling zeros by generating agents that are virtually different from those in the original data but have similar statistical properties. The presented approach can support agent-based modeling at all levels by enabling richer synthetic populations with smaller zones and more detailed individual characteristics. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.trc.2023.104405,Transportation Research Part C: Emerging Technologies,"Motion prediction systems play a crucial role in enabling autonomous vehicles to navigate safely and efficiently in complex traffic scenarios. Graph Neural Network (GNN)-based approaches have emerged as a promising solution for capturing interactions among dynamic agents and static objects. However, they often lack transparency, interpretability and explainability — qualities that are essential for building trust in autonomous driving systems. In this work, we address this challenge by presenting a comprehensive approach to enhance the explainability of graph-based motion prediction systems. We introduce the Explainable Heterogeneous Graph-based Policy (XHGP) model based on an heterogeneous graph representation of the traffic scene and lane-graph traversals. Distinct from other graph-based models, XHGP leverages object-level and type-level attention mechanisms to learn interaction behaviors, providing information about the importance of agents and interactions in the scene. In addition, capitalizing on XHGP's architecture, we investigate the explanations provided by the GNNExplainer and apply counterfactual reasoning to analyze the sensitivity of the model to modifications of the input data. This includes masking scene elements, altering trajectories, and adding or removing dynamic agents. Our proposal advances towards achieving reliable and explainable motion prediction systems, addressing the concerns of users, developers and regulatory agencies alike. The insights gained from our explainability analysis contribute to a better understanding of the relationships between dynamic and static elements in traffic scenarios, facilitating the interpretation of the results, as well as the correction of possible errors in motion prediction models, and thus contributing to the development of trustworthy motion prediction systems. The code to reproduce this work is publicly available at https://github.com/sancarlim/Explainable-MP/tree/v1.1. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.tre.2025.104180,Transportation Research Part E: Logistics and Transportation Review,"Urban rail transit systems exhibit substantial energy consumption, underpinning the significance of energy-saving optimization strategies for train timetables. Conventionally, trains operate according to an energy-efficient timetable formulated offline. However, station incidents and disturbances often result in deviations from the planned schedule, leading to additional energy expenditure. To address this challenge, the current study introduces a distributed multi-agent reinforcement learning approach(DMARL) for real-time energy-efficient optimization of train timetables. Initially, trains are conceptualized as agents, adopting the Actor-Critic network structure as the learning paradigm, with a distributed deployment architecture facilitating the training of the model. During the interaction phase between agents and the subway system, a progressive reward mechanism is designed to encourage efficient exploratory actions by the agents. In the final case study, data from Shanghai Metro Line 1(SML1) was utilized to demonstrate the effectiveness of the proposed method. The results indicate that when disturbances occur at stations, necessitating extended stop times, the method presented in this paper exhibited stable performance and faster convergence rates in both two-train and three-train systems. Compared to the energy consumption without any action, the energy savings were enhanced by 14.11 % and 11 %, respectively. The timetable updates were completed within milliseconds, confirming the efficacy of the method and its compliance with real-time updating requirements. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.trip.2025.101540,Transportation Research Interdisciplinary Perspectives,"Background: Autonomous vehicles (AVs) are hailed as having the potential to improve road safety. However, they may also encourage engagement in more sedentary transport. This modeling paper aims to explore how the uptake of AVs may lead to increased sedentary behaviour and to explore potential policy interventions. Methods: An Agent-Based Model was developed using survey responses and domain expertise to simulate humans’ transport mode choices. 250 ‘human’ agents were distributed into an imagined future environment containing AVs. Agents’ decision-making was based on the Theory of Planned Behaviour. Effects on mode choice and sedentary behaviour associated with transport modal choice were observed. Six policy scenarios related to the introduction of AVs were then explored, including policies designed to both incentivise and disincentivise AV use. Results: Baseline results showed rapid adoption of autonomous transport mode choice across both private AVs and autonomous ‘ride hail’ options, driven by decreasing costs of AVs and increasing acceptance of AV technology over time. Changes in agents’ transport behaviours coincided with a decrease in active transport trips and increase in sedentary transport behaviour. Additional fees for ride-hail AV trips disincentivised their use. Up-front financial discounts for the purchase of AVs increased adoption more than post-purchase rebates. Conclusion: Increases in autonomous transport are expected to be accompanied by greater sedentary transport behaviour. Financial incentives to restrict AV adoption may be effective in mitigating adverse consequences. The model framework provides a flexible platform upon which to test a variety of future policy transport and technology adoption scenarios. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.trip.2025.101544,Transportation Research Interdisciplinary Perspectives,"Land Use and Transport Integration (LUTI) models are critical tools for understanding the complex interactions between land use dynamics and transport systems. While extensively applied at local and metropolitan levels, their implementation at broader spatial scales remains limited and fragmented. This systematic review examines 115 peer-reviewed studies to trace the evolution of LUTI models across spatial levels—from cities to national contexts. Using bibliometric, content, and thematic analyses, the study identifies key modelling approaches, integration mechanisms, and application domains. Findings reveal a progression from aggregate spatial interaction models to disaggregate agent-based and microsimulation frameworks, with accessibility-activity feedback loops serving as the core integration mechanism. Despite methodological advancements, the review highlights persistent challenges in scaling up LUTI models, including data harmonization, computational complexity, and inter-jurisdictional policy coordination. Building on insights from large-scale implementations, the paper proposes a conceptual framework to guide future model development, focusing on data organization, hybrid model architectures, and long-term strategic functionality. By synthesizing evolving practices and identifying pathways to overcome scaling barriers, this review contributes to both academic research and professional practice. For researchers, the study offers a refined spatial scale typology and a structured framework for large-scale LUTI model development. For practitioners, it presents actionable strategies to address real-world implementation challenges, including data harmonization, model usability, and inter-jurisdictional coordination. These insights support the broader application of LUTI models in regional and national strategic planning. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/S0167-9236(03)00026-5,Decision Support Systems,"For the effective implementation of an inter-organizational supply chain on the Web, many optimization model agents need to be embedded in the distributed software agents. For instance, many suppliers make requests to a delivery scheduler who manages a model warehouse at the e-hub. The scheduler deals with the scheduling of many truckers and each trucker's agent must have its own routing optimization models. Since the formulations in the model warehouse vary depending upon the requirements, it is impossible to formulate all combinations in advance. Therefore, we need a case-based model modification scheme that can generate the required formulation from the semantically specified requirement in the agent communication language. This research deals with the issues of the architecture of an optimization model agent system AGENT-OPT, modeling request language in XML, optimization model representation in semantic-level objects using UNIK-OPT, a method of selecting a base model, an optimization model modification language (OMML), and rule-based modification reasoning. The approach is applied to the delivery scheduling to study the effect of base model selection policies on the modification effort. To determine whether to start with a primitive model, full model, or the most similar model, we experimented with the sensitivity of proximity to the primitive model on 24 cases and discovered the threshold for choosing the most efficient base model. © 2003 Elsevier B.V. All rights reserved. © 2008 Elsevier B.V., All rights reserved.",TOPIC
10.1016/S0730-725X(01)00468-4,Magnetic Resonance Imaging,"MRI was applied to investigate the transport pathways in Morning Glory plant stems. The study was carried out on living plants without affecting their integrity. The architecture of a dicotyledonous plant was deeply characterized: the root system structure and the vascular bundle location were identified, the presence of central voids caused by cell maturation and loss were observed in the stem. Molecular transport components were recognized, by observing the concentration profile of a tracer, which changed with time after its absorption by the plant roots. MRI analysis revealed the presence of an axial transport as the progress of the tracer front through the vascular bundles and a radial molecular transport from the vascular bundles toward the surface of the stem. As a result, the tracer molecular transport formed the parabolic tracer front (PTF). A model was built up through the analysis of the PTF that consisted of an axial front at the peak position and a radial front at the width of the parabolic tail. PTF analysis revealed differences between the tracer transport velocities in the axial and the radial directions in the plant stem. The model revealed that the width of the parabolic tail reflected the magnitudes of diffusion and permeation of the tracer in the plant stem. © 2001 Elsevier Science Inc. All rights reserved. © 2008 Elsevier B.V., All rights reserved.; MEDLINE® is the source for the MeSH terms of this document.",TOPIC
10.1016/S0952-1976(01)00025-2,Engineering Applications of Artificial Intelligence,"Multi-agent systems have been successfully applied to the scheduling problem for some time. However, their use often leads to poorly unsatisfactory disappointing results. A new multi-agent model, called supervisor, customers, environment, producers (SCEP), is suggested in this paper. This model, developed for all types of planning activities, introduces a dialogue between two communities of agents leading to a high level of co-operation. Its two main interests are the following: first it provides a more efficient control of the consequences generated by the local decisions than usual systems to each agent, then the adopted architecture and behaviour permit an easy co-operation between the different SCEP models, which can represent different production functions such as manufacturing, supply management, maintenance or different workshops. As a consequence, the SCEP model can be adapted to a great variety of scheduling/planning problems. This model is applied to the basic scheduling problem of flexible manufacturing systems, and it permits a natural co-habitation between infinite capacity scheduling processes, performed by the manufacturing orders, and finite capacity scheduling processes, performed by the machines. It also provides a framework in order to react to the disturbances occurring at different levels of the workshop. © 2002 Elsevier Science Ltd. All rights reserved. © 2008 Elsevier B.V., All rights reserved.",TOPIC
10.1016/S1665-6423(14)71631-1,Journal of Applied Research and Technology,"The growing importance of cooperation among organizations, as a result of globalization, current market opportunities and technological advances, encourages organizations to dynamically establish inter-organizational collaborations. These collaborations are carried out by executing collaborative business processes among the organizations. In this work we propose an agent-based software architecture for managing inter-organizational collaborations. Two types of agents are provided: the Collaboration Administrator Agent and the Process Administrator Agent. The former allows organizations setting up collaborations. The latter allows organizations executing collaborative business processes. A Colored Petri Net model specifying the role, which an organization fulfills in a collaborative process, is used to carry out the behavior of the Process Administrator Agent that represents the organization. Planning and execution of the actions of the Process Administrator Agents are driven by a Colored Petri Net machine embedded to them. Thus, Process Administrator Agents do not require to have defined at design-time the protocols they can support. In addition, we propose a model-driven development method for generating Colored Petri Net models from a collaborative process model defined as interaction protocol. Finally, an implementation of the agent-based software architecture and methods based on model-driven development are presented. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1017/dce.2020.6,Data-Centric Engineering,"This paper presents Parallel World Framework as a solution for simulations of complex systems within a time-varying knowledge graph and its application to the electric grid of Jurong Island in Singapore. The underlying modeling system is based on the Semantic Web Stack. Its linked data layer is described by means of ontologies, which span multiple domains. The framework is designed to allow what-if scenarios to be simulated generically, even for complex, inter-linked, cross-domain applications, as well as conducting multi-scale optimizations of complex superstructures within the system. Parallel world containers, introduced by the framework, ensure data separation and versioning of structures crossing various domain boundaries. Separation of operations, belonging to a particular version of the world, is taken care of by a scenario agent. It encapsulates functionality of operations on data and acts as a parallel world proxy to all of the other agents operating on the knowledge graph. Electric network optimization for carbon tax is demonstrated as a use case. The framework allows to model and evaluate electrical networks corresponding to set carbon tax values by retrofitting different types of power generators and optimizing the grid accordingly. The use case shows the possibility of using this solution as a tool for CO2 reduction modeling and planning at scale due to its distributed architecture. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1021/acs.jcim.3c01973,Journal of Chemical Information and Modeling,"Drug resistance to chemotherapeutic agents remains a formidable challenge in cancer treatment, significantly impacting treatment efficacy. Extensive research has exposed the intimate involvement of noncoding RNAs (ncRNAs) in conferring resistance to cancer drugs. Understanding the intricate associations between ncRNAs and drug resistance is of pivotal importance in advancing clinical interventions and expediting drug development. However, traditional biological experimental methods are hampered by limitations, such as labor intensiveness, time consumption, and constraints in scalability. Addressing these challenges necessitates the development of efficient computational methods for the accurate prediction of potential ncRNA-drug resistance associations (NDRA). However, most existing predictive models primarily focus on known ncRNA-drug resistance associations, often neglecting the critical aspect of similarity information between ncRNAs and drug resistance. This oversight may hinder the accuracy of characterizing these associations. To overcome the limitations of existing computational models, we proposed B-NDRA, a computational framework designed for the discovery of drug resistance-related ncRNA. Initially, we constructed a heterogeneous graph that integrates ncRNA-drug resistance pairs, leveraging both known associations and similarity fusion information between ncRNAs and drug resistance. Subsequently, we employed an attention mechanism to aggregate local features of graph nodes following a dimensionality reduction of node features. Further, a graph neural network (GNN) facilitated the learning of global node embeddings. Notably, the integration of dual adaptive deep adjustment architectures, encompassing intrablock and interblock methodologies, enabled efficient extraction of global features while balancing local and global features. Finally, B-NDRA employed a multilayer perceptron to predict associations between ncRNAs and drug resistance. Through rigorous 5-fold cross-validation, B-NDRA achieved average AUC, AUPR, Accuracy, Precision, Recall, and F1-score values of 92.2%, 91.9%, 84.88%, 86.9%, 82.37%, and 84.44%, respectively. Furthermore, comparative evaluations were conducted on established models, namely, GAEMDA, GRPAMDA, and LRGCPND. The results, obtained through three distinct 5-fold cross-validation strategies, demonstrated a notable performance improvement across almost all metrics for our B-NDRA. Specific case studies targeting Doxorubicin and Imatinib further validated the practicality of our B-NDRA in discovering potential NDRA. These results confirm the potential of our B-NDRA as a valuable tool in advancing cancer research and therapeutic development. The source code and data set of B-NDRA can be found at https://github.com/XuanLi1145/B-NDRA. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1021/acs.jcim.4c01749,Journal of Chemical Information and Modeling,"Antimicrobial peptides (AMPs) are a promising alternative for combating bacterial drug resistance. While current computer prediction models excel at binary classification of AMPs based on sequences, there is a lack of regression methods to accurately quantify AMP activity against specific bacteria, making the identification of highly potent AMPs a challenge. Here, we present a deep learning method, BERT-AmPEP60, based on the fine-tuned Bidirectional Encoder Representations from Transformers (BERT) architecture to extract embedding features from input sequences. Using the transfer learning strategy, we built regression models to predict the minimum inhibitory concentration (MIC) of peptides for Escherichia coli (EC) and Staphylococcus aureus (SA). In five independent experiments with 10% leave-out sequences as the test sets, the optimal EC and SA models outperformed the state-of-the-art regression method and traditional machine learning methods, achieving an average mean squared error of 0.2664 and 0.3032 (log μM), respectively. They also showed a Pearson correlation coefficient of 0.7955 and 0.7530, and a Kendall correlation coefficient of 0.5797 and 0.5222, respectively. Our models outperformed existing deep learning and machine learning methods that rely on conventional sequence features. This work underscores the effectiveness of utilizing BERT with transfer learning for training quantitative AMP prediction models specific for different bacterial species. The web server of BERT-AmPEP60 can be found at https://app.cbbio.online/ampep/home. To facilitate development, the program source codes are available at https://github.com/janecai0714/AMP_regression_EC_SA. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1021/acs.jcim.5c00032,Journal of Chemical Information and Modeling,"Skin sensitization, or allergic contact dermatitis, represents a critical end point in toxicity assessment, with profound implications for drug safety and regulatory decision-making. This study aims to develop a robust deep-learning-based quantitative structure-activity relationship framework for accurately predicting skin sensitization toxicity, particularly in the context of natural-product-derived compounds. To achieve this, we explored advanced recurrent neural network architectures, including long short-term memory (LSTM), bidirectional LSTM (BiLSTM), gated recurrent unit (GRU), and bidirectional GRU, to model the intricate structure-toxicity relationships inherent in molecular compounds. We aim to optimize and improve predictive performance by training a cohort of 55 models with a diverse set of molecular fingerprints. Notably, the BiLSTM model, which integrates SMILES tokens with RDKit fingerprints, achieved superior predictive performance, underscoring its capability to effectively capture key molecular determinants of skin sensitization. An extensive applicability domain analysis coupled with an in-depth evaluation of feature importance provided new insights into the key molecular attributes that influence sensitization propensity. We further evaluated the BiLSTM model using a natural product data set, where it demonstrated exceptional generalization capabilities. The model achieved an accuracy of 86.5%, a Matthews correlation coefficient of 75.2%, a sensitivity of 100%, an area under the curve of 88%, a specificity of 75%, and an F1-score of 88.8%. Remarkably, the model effectively categorized natural products by discriminating sensitizing from non-sensitizing agents across various natural product subcategories. These results underscore the potential of BiLSTM-based models as powerful in silico tools for modern drug discovery efforts and regulatory assessments, especially in the field of natural products. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1021/acsbiomaterials.2c00284,ACS Biomaterials Science and Engineering,"Despite advances in laparoscopic surgery combined with neoadjuvant and adjuvant therapy, colon cancer management remains challenging in oncology. Recurrence of cancerous tissue locally or in distant organs (metastasis) is the major problem in colon cancer management. Vaccines and immunotherapies hold promise in preventing cancer recurrence through stimulation of the immune system. We and others have shown that nanoparticles from plant viruses, such as cowpea mosaic virus (CPMV) nanoparticles, are potent immune adjuvants for cancer vaccines and serve as immunostimulatory agents in the treatment or prevention of tumors. While being noninfectious toward mammals, CPMV activates the innate immune system through recognition by pattern recognition receptors (PRRs). While the particulate structure of CPMV is essential for prominent immune activation, the proteinaceous architecture makes CPMV subject to degradation in vivo; thus, CPMV immunotherapy requires repeated injections for optimal outcome. Frequent intraperitoneal (IP) injections however are not optimal from a clinical point of view and can worsen the patient's quality of life due to the hospitalization required for IP administration. To overcome the need for repeated IP injections, we loaded CPMV nanoparticles in injectable chitosan/glycerophosphate (GP) hydrogel formulations, characterized their slow-release potential, and assessed the antitumor preventative efficacy of CPMV-in-hydrogel single dose versus soluble CPMV (single and prime-boost administration). Using fluorescently labeled CPMV-in-hydrogel formulations, in vivo release data indicated that single IP injection of the hydrogel formulation yielded a gel depot that supplied intact CPMV over the study period of 3 weeks, while soluble CPMV lasted only for one week. IP administration of the CPMV-in-hydrogel formulation boosted with soluble CPMV for combined immediate and sustained immune activation significantly inhibited colon cancer growth after CT26 IP challenge in BALB/c mice. The observed antitumor efficacy suggests that CPMV can be formulated in a chitosan/GP hydrogel to achieve prolonged immunostimulatory effects as single-dose immunotherapy against colon cancer recurrence. The present findings illustrate the potential of injectable hydrogel technology to accommodate plant virus nanoparticles to boost the translational development of effective antitumor immunotherapies. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1021/acsbiomaterials.6b00060,ACS Biomaterials Science and Engineering,"Multiple administrations of nanoparticle-based formulations are often a clinical requirement for drug delivery and diagnostic imaging applications. Steady pharmacokinetics of nanoparticles is desirable to achieve efficient therapeutic or diagnostic outcomes over such repeat administrations. While clearance through mononuclear phagocytic system is a key determinant of nanoparticle persistence in vivo, multiple administrations could potentially result in altered pharmacokinetics by evoking innate or adaptive immune responses. Plant viral nanoparticles (VNPs) represent an emerging class of programmable nanoparticle platform technologies that offer a highly organized proteinaceous architecture and multivalency for delivery of large payloads of drugs and molecular contrast agents. These very structural features also render them susceptible to immune recognition and subsequent accelerated systemic clearance that could potentially affect overall efficiency. While the biodistribution and pharmacokinetics of VNPs have been reported, the biological response following repeat administrations remains an understudied area of investigation. Here, we demonstrate that weekly administration of filamentous plant viruses results in the generation of increasing levels of circulating, carrier-specific IgM and IgG antibodies. Furthermore, PVX specific immunoglobulins from the serum of immunized animals quickly form aggregates when incubated with PVX in vitro. Such aggregates of VNP-immune complexes are also observed in the mouse vasculature in vivo following repeat injections when imaged in real time using intravital two-photon laser scanning microscopy (2P-LSM). The size of aggregates diminishes at later time points, coinciding with antibody class switching from IgM to IgG. Together, our results highlight the need for careful in vivo assessment of (viral) nanoparticle-based platform technologies, especially in studying their performance after repeat administration. We also demonstrate the utility of intravital microscopy to aid in this evaluation. © 2016 Elsevier B.V., All rights reserved.",TOPIC
10.1021/acsnano.6b06979,ACS Nano,"With the global rise in incidence of cancer and infectious diseases, there is a need for the development of techniques to diagnose, treat, and monitor these conditions. The ability to efficiently capture and isolate cells and other biomolecules from peripheral whole blood for downstream analyses is a necessary requirement. Graphene oxide (GO) is an attractive template nanomaterial for such biosensing applications. Favorable properties include its two-dimensional architecture and wide range of functionalization chemistries, offering significant potential to tailor affinity toward aromatic functional groups expressed in biomolecules of interest. However, a limitation of current techniques is that as-synthesized GO nanosheets are used directly in sensing applications, and the benefits of their structural modification on the device performance have remained unexplored. Here, we report a microfluidic-free, sensitive, planar device on treated GO substrates to enable quick and efficient capture of Class-II MHC-positive cells from murine whole blood. We achieve this by using a mild thermal annealing treatment on the GO substrates, which drives a phase transformation through oxygen clustering. Using a combination of experimental observations and MD simulations, we demonstrate that this process leads to improved reactivity and density of functionalization of cell capture agents, resulting in an enhanced cell capture efficiency of 92 ± 7% at room temperature, almost double the efficiency afforded by devices made using as-synthesized GO (54 ± 3%). Our work highlights a scalable, cost-effective, general approach to improve the functionalization of GO, which creates diverse opportunities for various next-generation device applications. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1021/acssynbio.1c00290,ACS Synthetic Biology,"Biofilms are three-dimensional (3D) bacterial communities that exhibit a highly self-organized nature in terms of their composition and complex architecture. Bacteria in biofilms display emergent biological properties, such as resistance to antimicrobials and disinfectants that the individual planktonic cells lack. Bacterial biofilms possess specialized architectural features including unique extracellular matrix compositions and a distinct spatially patterned arrangement of cells and matrix components within the biofilm. It is unclear which of these architectural elements of bacterial biofilms lead to the development of their emergent biological properties. Here, we report a 3D printing-based technique for studying the emergent resistance behaviors ofEscherichia colibiofilms as a function of their architecture. Cellulose and curli are the major extracellular-matrix components inE. colibiofilms. We show that 3D-printed biofilms expressing either curli alone or both curli and cellulose in their extracellular matrices show higher resistance to exposure against disinfectants than 3D prints expressing either cellulose alone or no biofilm-matrix components. The 3D-printed biofilms expressing cellulose and/or curli also show thicker anaerobic zones than nonbiofilm-formingE. coli3D prints. Thus, the matrix composition plays a crucial role in the emergent spatial patterning and biological endurance of 3D-printed biofilms. In contrast, initial spatial distribution of bacterial density or curli-producing cells does not have an effect on biofilm resistance phenotypes. Further, these 3D-printed biofilms could be reversibly attached to different surfaces (bacterial cellulose, glass, and polystyrene) and display resistance to physical distortions by retaining their shape and structure. This physical robustness highlights their potential in applications including bioremediation, protective coatings against pathogens on medical devices, or wastewater treatment, among many others. This new understanding of the emergent behavior of bacterial biofilms could aid in the development of novel engineered living materials using synthetic biology and materials science approaches. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1023/A:1025701325275,Journal of Intelligent Manufacturing,"Steel production is a complex process and finding coherent and effective schedules for the wide variety of production steps, in a dynamic environment, is a challenging task. In this paper, we propose a multi-agent architecture for integrated dynamic scheduling of the hot strip mill (HSM) and the continuous caster. The scheduling systems of these processes have very different objectives and constraints, and operate in an environment where there is a substantial quantity of real-time information concerning production failures and customer requests. Each process is assigned to an agent which independently, seeks an optimal dynamic schedule at a local level taking into account local objectives, real-time information and information received from other agents. Each agent can react to real-time events in order to fix any problems that occur. We focus here, particularly, on the HSM agent which uses a tabu search heuristic to create good predictive-reactive schedules quickly. The other agents simulate the production of the coil orders and the real-time events, which occur during the scheduling process. When real-time events occur on the HSM, the HSM agent might decide whether to repair the current schedule or reschedule from scratch. To address this problem, a range of schedule repair and complete rescheduling strategies are investigated and their performance is assessed with respect to measures of utility, stability and robustness, using an experimental simulation framework. © 2008 Elsevier B.V., All rights reserved.",TOPIC
10.1038/s41746-021-00480-x,npj Digital Medicine,"Accurate prediction of blood glucose variations in type 2 diabetes (T2D) will facilitate better glycemic control and decrease the occurrence of hypoglycemic episodes as well as the morbidity and mortality associated with T2D, hence increasing the quality of life of patients. Owing to the complexity of the blood glucose dynamics, it is difficult to design accurate predictive models in every circumstance, i.e., hypo/normo/hyperglycemic events. We developed deep-learning methods to predict patient-specific blood glucose during various time horizons in the immediate future using patient-specific every 30-min long glucose measurements by the continuous glucose monitoring (CGM) to predict future glucose levels in 5 min to 1 h. In general, the major challenges to address are (1) the dataset of each patient is often too small to train a patient-specific deep-learning model, and (2) the dataset is usually highly imbalanced given that hypo- and hyperglycemic episodes are usually much less common than normoglycemia. We tackle these two challenges using transfer learning and data augmentation, respectively. We systematically examined three neural network architectures, different loss functions, four transfer-learning strategies, and four data augmentation techniques, including mixup and generative models. Taken together, utilizing these methodologies we achieved over 95% prediction accuracy and 90% sensitivity for a time period within the clinically useful 1 h prediction horizon that would allow a patient to react and correct either hypoglycemia and/or hyperglycemia. We have also demonstrated that the same network architecture and transfer-learning methods perform well for the type 1 diabetes OhioT1DM public dataset. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1038/s42256-022-00583-4,Nature Machine Intelligence,"Humans are well versed in reasoning about the behaviours of physical objects and choosing actions accordingly to accomplish tasks, while this remains a major challenge for artificial intelligence. To facilitate research addressing this problem, we propose a new testbed that requires an agent to reason about physical scenarios and take an action appropriately. Inspired by the physical knowledge acquired in infancy and the capabilities required for robots to operate in real-world environments, we identify 15 essential physical scenarios. We create a wide variety of distinct task templates, and we ensure that all the task templates within the same scenario can be solved by using one specific strategic physical rule. By having such a design, we evaluate two distinct levels of generalization, namely local generalization and broad generalization. We conduct an extensive evaluation with human players, learning agents with various input types and architectures, and heuristic agents with different strategies. Inspired by how the human intelligence quotient is calculated, we define the physical reasoning quotient (Phy-Q score) that reflects the physical reasoning intelligence of an agent using the physical scenarios we considered. Our evaluation shows that (1) all the agents are far below human performance, and (2) learning agents, even with good local generalization ability, struggle to learn the underlying physical reasoning rules and fail to generalize broadly. We encourage the development of intelligent agents that can reach the human-level Phy-Q score. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1038/s42256-023-00687-5,Nature Machine Intelligence,"Quantum many-body control is a central milestone en route to harnessing quantum technologies. However, the exponential growth of the Hilbert space dimension with the number of qubits makes it challenging to classically simulate quantum many-body systems and, consequently, to devise reliable and robust optimal control protocols. Here we present a framework for efficiently controlling quantum many-body systems based on reinforcement learning (RL). We tackle the quantum-control problem by leveraging matrix product states (1) for representing the many-body state and (2) as part of the trainable machine learning architecture for our RL agent. The framework is applied to prepare ground states of the quantum Ising chain, including states in the critical region. It allows us to control systems far larger than neural-network-only architectures permit, while retaining the advantages of deep learning algorithms, such as generalizability and trainable robustness to noise. In particular, we demonstrate that RL agents are capable of finding universal controls, of learning how to optimally steer previously unseen many-body states and of adapting control protocols on the fly when the quantum dynamics is subject to stochastic perturbations. Furthermore, we map our RL framework to a hybrid quantum–classical algorithm that can be performed on noisy intermediate-scale quantum devices and test it under the presence of experimentally relevant sources of noise. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1039/d1tb00458a,Journal of Materials Chemistry B,"Two-dimensional (2D) nanomaterials (NM) have emerged as promising platforms for antibacterial applications. However, the inherent “flatness” of 2D NM often limits the loading of antimicrobial components needed for synergistic bactericidal actions. Here, inspired by the highly ornamented siliceous frustules of diatoms, we prepared 2D ultrathin (<20 nm) and rigid “nanofrustule” platesviathe out-of-plane growth of cetyltrimethylammonium bromide (CTAB) directed silica mesostructures on the surfaces of 2D graphene oxide nanosheets. The nanofrustules were characterized by the presence of mesoporous channels with a pore size of 3 nm and a high specific surface area of 674 m2g−1.S-nitrosothiol-modification on the silica surfaces enables the development of a novel anti-infective nitric oxide (NO) releasing NO-nanofrustule system. The cage-like mesoporous silica architecture enabled a controlled and sustainable release of NO from the NO-nanofrustules under physiological conditions. The NO-nanofrustules displayed broad antibacterial effects againstStaphylococcus aureusandEscherichia coliwith a minimum inhibitory concentration of 250 μg ml−1. Mechanistic studies revealed that the antibacterial property of NO-nanofrustules was attainedviaa unique “capture-and-release” mode-of-action. The first step entailed the capture of the bacteria by the NO-nanofrustules to form micro-aggregates. This was followed by the release of high levels of NO to the captured bacteria to elicit a potent anti-infective effect. In combination with the lack of cytotoxicity in human dermal cells, the 2D hybrid NO-nanofrustules may be utilized to combat wound infections in clinical settings. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1039/d4lc00659c,Lab on a Chip,"Plants respond to environmental stressors with adaptive changes in growth and development. Central to these responses is the role of calcium (Ca2+) as a key secondary messenger. Here, the bi-directional dual-flow RootChip (bi-dfRC) microfluidic platform was used to study defence signalling and root growth. By introducing salinity as sodium chloride (NaCl) treatment via a multiplexed media delivery system (MMDS), dynamic gradients were created, mimicking natural environmental fluctuations. Signal analysis in Arabidopsis thaliana plants showed that the Ca2+ burst indicated by the G-CaMP3 was concentration dependent. A Ca2+ burst initiated in response to salinity increase, specifically within the stele tissue, for 30 seconds. The signal then intensified in epidermal cells directly in contact with the stressor, spreading directionally towards the root tip, over 5 minutes. Inhibition of propidium iodide (PI) stain transport through the xylem was observed following salinity increase, contrasting with flow observed under control conditions. The interaction of Phytophthora capsici zoospores with A. thaliana roots was also studied. An immediate directional Ca2+ signal was observed during early pathogen recognition, while a gradual, non-directional increase was observed in Orp1_roGFP fluorescent H<inf>2</inf>O<inf>2</inf> levels, over 30 min. By adjusting the dimensions of the bi-dfRC, plants with varying root architectures were subjected to growth analysis. Growth reduction was observed in A. thaliana and Nicotiana benthamiana roots when exposed to salinity induced by 100 mM NaCl, while Solanum lycopersicum exhibited growth increase over 90 minutes at the same NaCl concentration. Furthermore, novel insights into force sensing in roots were gained through the engineering of displaceable pillars into the bi-dfRC channel. These findings highlight the vital role of controlling fluid flow in microfluidic channels in advancing our understanding of root physiology under stress conditions. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1049/2024/7855250,IET Computers and Digital Techniques,"The asynchronous advantage actor-critic (A3C) algorithm is widely regarded as one of the most effective and powerful algorithms among various deep reinforcement learning algorithms. However, the distributed and asynchronous nature of the A3C algorithm brings increased algorithm complexity and computational requirements, which not only leads to an increased training cost but also amplifies the difficulty of deploying the algorithm on resource-limited field programmable gate array (FPGA) platforms. In addition, the resource wastage problem caused by the distributed training characteristics of A3C algorithms and the resource allocation problem affected by the imbalance between the computational amount of inference and training need to be carefully considered when designing accelerators. In this paper, we introduce a deployment strategy designed for distributed algorithms aimed at enhancing the resource utilization of hardware devices. Subsequently, a FPGA architecture is constructed specifically for accelerating the inference and training processes of the A3C algorithm. The experimental results show that our proposed deployment strategy reduces resource consumption by 62.5% and decreases the number of agents waiting for training by 32.2%, and the proposed A3C accelerator achieves 1.83× and 2.39× improvements in speedup compared to CPU (Intel i9-13900K) and GPU (NVIDIA RTX 4090) with less power consumption respectively. Furthermore, our design shows superior resource efficiency compared to existing works. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1049/blc2.12041,IET Blockchain,"In a networked microgrid system (NMS), various heterogeneous microgrids are interconnected. A networked microgrid system facilitates a new kind of physical design that provides numerous advantages such as distributed economic optimization, reliability, resiliency, and focusing on distributed generations and customers. Designing the secure and privacy-protected smart power contract between electricity suppliers and consumers, considered as agents, of different microgrids, is a challenging task in the networked- microgrid system. Each microgrid implements a heterogeneous or isomorphic blockchain based platform. The blockchain interoperability, inherently, presents in different blockchains implemented by various microgrids. This paper reviews the interoperability issues and smart contract designs in blockchain-based systems and proposes new mechanisms to cater blockchain interoperability challenges to facilitate the design of secure and seamless smart contracts among different blockchains of microgrids. A network hub of heterogeneous blockchains of network microgrids has been proposed. A methodology has been developed to transfer tokens between interoperable blockchains. A distributed identity-based microgrid (DIBM) scheme is incorporated to make the networked microgrid system secure and trustworthy. This paper suggests an effective consensus protocol for cross-chain architecture that improves the tokenization system and smart power contract designs. Asynchronous blockchain based federated learning for peer-to-peer smart power exchange has been implemented in learning process of interoperable and heterogeneous blockchain based network hub of microgrid. For simulation purposes, MATLAB and python programming have been used with real-time data of microgrids. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1049/iet-cvi.2019.0546,IET Computer Vision,"Predicting distant future trajectories of agents in a dynamic scene is challenging because the future trajectory of an agent is affected not only by their past trajectory but also the scene contexts. To tackle this problem, the authors propose a model based on recurrent neural networks, and a novel method for training this model. The proposed model is based on an encoder-decoder architecture where the encoder encodes inputs (past trajectory and scene context information), while the decoder produces a future trajectory from the context vector given by the encoder. To make the proposed model better utilise the scene context information, the authors let the encoder predict the positions in the past trajectory and a reward function evaluate the positions along with the scene context information generated by the positions. The reward function, which is simultaneously trained with the proposed model, plays the role of a regulariser for the model during the simultaneous training. The authors evaluate the proposed model on several public benchmark datasets. The experimental results show that the prediction performance of the proposed model is greatly improved by the proposed regularisation method, which outperforms the-state-of-the-art models in terms of accuracy. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1049/itr2.12201,IET Intelligent Transport Systems,"In the application of deep learning to realize intelligent train operation, there are some problems, such as the single learning task. Especially when using the gradient descent approach to optimize the structure, weight and threshold of a deep network, it is easy in this task to fall into a local optimum. This leads to excessive reliance on manual tuning experience. Aiming at the above issues, this paper proposes a new approach of train manipulation and prediction based on a long short-term memory (LSTM) deep network. From the perspective of automatic hyper-parameter optimization, the gradient-free intelligent search method is principally chosen to optimize the architecture and parameters of a LSTM deep network, so as to improve the manipulation accuracy based on learning from excellent drivers. This method first selects excellent driver data through the Pareto dominance principle and crowding distance calculation; on this basis, a step-by-step method is used to optimize the structure, weight and threshold of the LSTM network. Particularly, in the first step, we adopt a genetic algorithm to search for the optimal deep network structure, which overcomes the problem that the structure is difficult to determine. In the second step, we optimize the parameters of the deep network, a process that is divided into two stages of ‘rough learning’ and ‘precise learning’. In the ‘rough learning’ stage, we use the multi-population chained multi-agent (MPCMA) algorithm to preliminarily optimize the LSTM network parameters. In the ‘precise learning’ stage, the Adam algorithm is applied to further finely optimize the network parameters. Finally, through simulation experiments, it is verified that the proposed method improves the accuracy of train manipulation and prediction, and shows strong robustness in situations of multiple manipulation sequences and different temporary speed limits. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1049/itr2.12207,IET Intelligent Transport Systems,"Predicting the future behaviour of neighbouring agents is crucial for autonomous driving. This task is challenging, largely because of the diverse unobservable intent of each agent which is further complicated by the complex interaction possibilities between them. The authors propose a multi-future Transformer framework that implicitly models the multi-modal joint distribution by capturing the diverse interaction modes of the scene. To this end, a parallel interaction module is constructed, whereby each interaction block learns the joint agent–agent and agent–map interactions for possible future evolution. The model can perform likelihood estimation from the perspective of both the joint distribution of the scene and marginal distribution of each agent. Combined with the proposed scene-level winner-take-all loss strategy complementary to the model architecture, the best performance is achieved for both target agent prediction and scene prediction tasks in a single model. To better utilise the scene context, comprehensive control experiments were conducted highlighting the importance of fine-grained scene representation with content-adaptive aggregation and late fusion of semantic attributes. The method, evaluated on the popular Argoverse forecasting dataset, outperformed previous methods while maintaining low model complexity. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1049/itr2.70104,IET Intelligent Transport Systems,"Pedestrian crossing prediction, which involves anticipating whether a pedestrian will cross the street or not, is a crucial function in autonomous driving systems. This is also a safety requirement for the interaction of highly automated vehicles and pedestrians. The endeavours in this research domain heavily rely on processing videos captured by the frontal cameras of autonomous vehicles using advanced computer vision techniques and deep learning methods. While recent studies focus on the model architecture for crossing prediction by utilising pre-trained visual feature extractors, they often encounter challenges stemming from inaccurate input features such as pedestrian body pose and/or scene semantic information. In this study, we aim to enhance pose estimation and semantic segmentation algorithms by using synthetic data augmentation (SDA) and domain randomisation (DR) techniques. SDA allows for automatic annotations through predefined agents and objects in a simulated urban environment. However, it creates a domain gap between synthetic and real-world data. To tackle this, we introduce a DR technique to generate synthetic data mimicking various weather and ambient illumination conditions. We evaluated two training strategies on six algorithms for both pose estimation and semantic segmentation algorithms, and ultimately, we target four deep learning architectures for crossing prediction, including convolutional, recurrent, graph, and transformer neural networks. The proposed technique improves the extraction of pedestrian body pose and categorical semantic information, which in turn enhances the state-of-the-art. This results in effective feature selection as the input for the PIP task, improving prediction accuracy by 3.2%, 4.2%, and 6.3% to reach 87.6%, 92.2%, and 73.6% against the JAAD, PIE, and FU-PIP datasets, respectively. The study indicates that using a simulated environment with structural randomised properties can enhance the resilience of the pedestrian crossing prediction to variations in the input data. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1057/jba.2008.26,Journal of Building Appraisal,"Lahore is the city of Mughal heritage in the true sense of the word. Grand buildings with a delicate touch of landscaping express the story of a splendid era of building construction. Some chapters of this monumental architecture have been torn or distorted by subsequent rulers and others are fading away due to the aggressiveness of the environment but still stand as a witness of Mughal grandeur. This paper describes the impact of aggressiveness of the environment on the gradual destruction of the three gems of Mughal architectural treasures: Lahore Fort, Jehangir's tomb and Shalimar Gardens. The main emphasis is on structural damages. Out of the three aforementioned sites, two, the Lahore Fort and Shalimar Gardens, were declared UNESCO World Heritage Sites in 1981, but this status is depleting swiftly due to the ill-planned rehabilitation works funded by UNESCO. This negligence in the refurbishment is aggravating the destruction by environmental agents and these buildings are still struggling with the fate keeping a hope of reappraisal of its past in the form of restoration. © 2008 PALGRAVE MACMILLAN 1742-8262. © 2011 Elsevier B.V., All rights reserved.",TOPIC
10.1063/5.0047641,APL Materials,"In our brain, information is exchanged among neurons in the form of spikes where both the space (which neuron fires) and time (when the neuron fires) contain relevant information. Every neuron is connected to other neurons by synapses, which are continuously created, updated, and stimulated to enable information processing and learning. Realizing the brain-like neuron/synapse network in silicon would enable artificial autonomous agents capable of learning, adaptation, and interaction with the environment. Toward this aim, the conventional microelectronic technology, which is based on complementary metal-oxide-semiconductor transistors and the von Neumann computing architecture, does not provide the desired energy efficiency and scaling potential. A generation of emerging memory devices, including resistive switching random access memory (RRAM) also known as the memristor, can offer a wealth of physics-enabled processing capabilities, including multiplication, integration, potentiation, depression, and time-decaying stimulation, which are suitable to recreate some of the fundamental phenomena of the human brain in silico. This work provides an overview about the status and the most recent updates on brain-inspired neuromorphic computing devices. After introducing the RRAM device technologies, we discuss the main computing functionalities of the human brain, including neuron integration and fire, dendritic filtering, and short- and long-term synaptic plasticity. For each of these processing functions, we discuss their proposed implementation in terms of materials, device structure, and brain-like characteristics. The rich device physics, the nano-scale integration, the tolerance to stochastic variations, and the ability to process information in situ make the emerging memory devices a promising technology for future brain-like hardware intelligence. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1063/5.0077432,Biomicrofluidics,"Mechanical properties of cells are important features that are tightly regulated and are dictated by various pathologies. Deformability cytometry allows for the characterization of the mechanical properties at a rate of hundreds of cells per second, opening the way to differentiating cells via mechanotyping. A remaining challenge for detecting and classifying rare sub-populations is the creation of a combined experimental and analysis protocol that approaches the maximum potential classification accuracy for single cells. In order to find this maximum accuracy, we designed a microfluidic channel that subjects each cell to repeated deformations and relaxations and provides a comprehensive set of mechanotyping parameters. We track the shape dynamics of individual cells with high time resolution and apply sequence-based deep learning models for feature extraction. In order to create a dataset based solely on differing mechanical properties, a model system was created with treated and untreated HL60 cells. Treated cells were exposed to chemical agents that perturb either the actin or microtubule networks. Multiple recurrent and convolutional neural network architectures were trained using time sequences of cell shapes and were found to achieve high classification accuracy based on cytoskeletal properties alone. The best model classified two of the sub-populations of HL60 cells with an accuracy over 90%, significantly higher than the 75% we achieved with traditional methods. This increase in accuracy corresponds to a fivefold increase in potential enrichment of a sample for a target population. This work establishes the application of sequence-based deep learning models to dynamic deformability cytometry. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1080/08839514.2022.2094446,Applied Artificial Intelligence,"This study aimed to develop a novel deep learning model for reliable quantification of dentinal tubule occlusions instead of manual assessment techniques, and the performance of the model was compared to other methods in the literature. Ninety-six dentin samples were cut and prepared with desensitizing agents to occlude dentinal tubules on different levels. After obtaining images via scanning electron microscope (SEM), 2793 single dentinal tubule images with 48 × 48 resolution were segmented and labeled. Data augmentation techniques were applied for improvement in the learning rate. The augmented data having a total of 10700 images belonging to five classes were used as the network training dataset. The proposed convolutional neural network (CNN) is a class of deep learning model and was able to classify the degree of dentinal tubule occlusions into five classes with an overall accuracy rate of 90.24%. This paper primarily focuses on developing a CNN architecture for detecting the level of dentin tubule occlusions imaged by SEM. The results showed that the proposed CNN architecture is an immensely successful alternative and allowed for objective and automatic classification of segmented dentinal tubule images. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1080/10408398.2024.2437573,Critical Reviews in Food Science and Nutrition,"Pectin, a complex dietary fiber, constitutes a key structural component of the cell walls of numerous edible plant products. It is resistant to digestion by human enzymes and undergoes depolymerization and saccharification in the gastrointestinal tract through the action of carbohydrate-active enzymes (CAZymes) produced by gut microbiota. This enzymatic breakdown generates intermediate structural fragments, which are subsequently converted into pectin oligosaccharides (POS) and monosaccharides. POS exhibit prebiotic properties and have demonstrated potential health benefits, including anti-carcinogenic effects, mucoadhesive capabilities, and the promotion of beneficial gut bacterial growth. However, the current understanding of the molecular structure of pectin and its degradation dynamics remains fragmented within the literature, impeding progress in dietary fiber intervention research and the development of personalized nutrition approaches. This review aims to provide a comprehensive overview of the structural features of pectin and the intricate breakdown mechanisms orchestrated by CAZymes. It underscores the complex architecture of pectin that influences its breakdown dynamics and specifies the enzymatic requirements for the cleavage of its diverse structural components. These insights complement our accompanying review on the structure-function relationships between pectin and the human gut microbiota, previously published in this journal. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1080/13467581.2022.2145205,Journal of Asian Architecture and Building Engineering,"Industrial dwelling construction (IDC) combines offsite and onsite construction methods. The current work proposes a multiple-criteria decision-making assistant system (DMAS) approach for evaluating home buildings, selecting decision agents, and determining acceptable IDC types and characteristics for large-scale housing enhancement. Using the analytical hierarchy process (AHP), a multicriteria DMAS was planned. Literature reviews and expert interviews were used to assess thirty decision agents. To validate the procedure, five IDCs were analyzed as case studies. Thirty professionals analyzed decision agents' and housing systems' priority vectors using questionnaires. Three decision agents were identified: (1) user needs, (2) the building industry, and (3) the supply chain. Consequently, Prefabricated Reinforced Concrete Slab, Beam, and Column Blocks (PRCSBCB) and Light Steel Frame Wall Panels (LSFWP) can be used to construct suitable dwellings. These construction options are low-cost, lightweight, and easy to install. They also use inexperienced local workers. Results showed the method's potential and usefulness with so many choices and decision agents. This research examines knowledge and skill gaps in Iran's IDC and encounters a shortage of IDC specialists and mass-construction variants. The study identifies key decision-agents and housing options for quick, appropriate, and cost-efficient mass housing and helps professionals, entrepreneurs, and decision-makers make better decisions. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1080/16168658.2021.1978803,Distributed Probabilistic Fuzzy Rule Mining for Clinical Decision Making,"INTRODUCTION: With the growing size, complexity, and distributivity of databases, efficiency and scalability have become highly desirable attributes of data mining algorithms in decision support systems. OBJECTIVES: This study aims for a computational framework for clinical decision support systems that can handle inconsistent dataset while also being interpretable and scalable. METHODS: This paper proposes a Distributed Probabilistic Fuzzy Rule Mining (DPFRM) algorithm that extracts probabilistic fuzzy rules from numerical data using a self-organizing multi-agent approach. This agent-based method provides better scalability and fewer rules through agent interactions and rule-sharing. RESULTS: The performance of the proposed approach is investigated on several UCI medical datasets. The DPFRM is also used for predicting the mortality rate of burn patients. Statistical analysis confirms that the DPFRM significantly improves burn mortality prediction by at least 3%. Also, the training time is improved by 17% if implemented by a parallel computer. However, this speedup decreases with increased distributivity, due to the added communication overhead. CONCLUSION: The proposed approach can improve the accuracy of decision making by better handling of inconsistencies within the datasets. Furthermore, noise sensitivity analysis demonstrates that the DPFRM deteriorates more robustly as the noise levels increase.",TOPIC
10.1080/16583655.2019.1595358,Journal of Taibah University for Science,"Background: Prostate cancer has become the most common cancer among African–American men and the second leading cause of cancer death in men worldwide. Many anti-malignant agents have been isolated from different plant species with minimal or no side effects thus it holds future promise as a resort as cancer biotherapeutics when compared with other treatment methods including synthetic drugs. Aim: This current investigation was aimed at evaluating the anti-proliferative efficacy of the ethanolic extract of Annonamuricata leaf on annexin 7 gene of malignant prostatic hyperplasia induced male wistar rats. Materials and Methods: Sub-chronic daily oral gavage exposure of the test substances to experimental animals lasted for a period of 28 days. Monosodium glutamate and L-arginine (90:22.5 mg/kg/b.wt) with purity 98% were administered concomitantly to the male wistar rats in various treatment groups. A total of 25 male wistar rats of about 6 weeks old weighing between 250–282 grams were used for this investigation. Quantitative and qualitative phytochemicals screening of ethanolic extract of Annona muricata leaf were also carried out. Hematoxylin and eosin staining were used in the histological assay of the prostate tissues. The prostate specific antigen (PSA) values were determined using standard protocol and polymerase chain reaction (PCR) was used to amplify annexin-7 gene. 1.5% agarose gel was used to separate the amplicons into bands of varying patterns. Result: Qualitative analysis demonstrated the presence of alkaloids, Saponins, flavonoids, tannins, cardiac glycoside, reducing sugar, phenol and triterpenes. Quantitative screening of the extract unveiled that alkaloid was present in the highest amount while Cardiac glycosides had the least concentration. The prostate histological assessment revealed a dose-dependent disruption in normal prostate tissue architecture. There was statistically significant difference P ≤ 0.05 in the body weight and prostate specific antigen (PSA) values of the male wistar rats in the experimental groups during the period of this investigation. The varying amplicon band patterns obtained from the treatment groups indicates possible MSG and L-ARG induced mutation in annexin 7 gene. The DNA amplicon bands observed in the positive control without treatments had some degree of similarity with bands obtained from the amplicons in the various treatment groups that were administered with both carcinogens and ethanolic leaf extract while thin bands were observed for the negative control group that was administered with carcinogens alone. Conclusion: This investigation has demonstrated that ethanolic extract of A. muricata leaf could be used as a potent ethno-chemopreventive agent against L-arginine and monosodium glutamate induced malignant prostatic hyperplasia in male wistar rats. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1080/21691401.2025.2494796,"Artificial Cells, Nanomedicine and Biotechnology","Toxoplasma gondii, a protozoan parasite found in water sources, causes toxoplasmosis, with no current protocols for inactivating its oocysts in water. Staphylococcus aureus, a significant bacterial pathogen, is known for causing various illnesses, including skin infections and biofilm-related diseases. This study investigated the antibacterial and antiparasitic properties of Ipomoea palmata leaf extract, rich in phenolics, against T. gondii tachyzoites and S. aureus. I. palmata extract significantly reduced tachyzoites count in peritoneal fluids and liver smears of infected mice with alleviation of toxoplasmosis-induced hepatitis. SEM showed surface irregularities in tachyzoites from treated groups. The extract demonstrated antibacterial action against S. aureus with a minimum inhibitory concentration of 128 to 512 µg/mL, reduced biofilm formation from 69.23% to 15.38% of tested isolates, and downregulated biofilm genes (cna, fnbA, and ica) in 53.85% of isolates. Treatment with I. palmata extract improved liver architecture, reduced inflammation, and eliminated blood vessel congestion. The main phenolic acids identified by HPLC/UV analysis were chlorogenic acid, gallic acid, ellagic acid, and methyl gallate, while the predominant flavonoids were apigenin, quercetin, and naringenin. These findings highlight the potential of I. palmata extract as a natural antimicrobial and antiparasitic agent, warranting further research to isolate and evaluate its active compounds. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1080/24751839.2020.1833137,Journal of Information and Telecommunication,"The manual tuning of controller parameters, for example, tuning proportional integral derivative (PID) gains often relies on tedious human engineering. To curb the aforementioned problem, we propose an artificial intelligence-based deep reinforcement learning (RL) PID controller (three variants) compared with genetic algorithm-based PID (GA-PID) and classical PID; a total of five controllers were simulated for controlling and trajectory tracking of the ball dynamics in a linearized ball-and-plate ((Formula presented.)) system. For the experiments, we trained novel variants of deep RL-PID built from a customized deep deterministic policy gradient (DDPG) agent (by modifying the neural network architecture), resulting in two new RL agents (DDPG-FC-350-R-PID & DDPG-FC-350-E-PID). Each of the agents interacts with the environment through a policy and a learning algorithm to produce a set of actions (optimal PID gains). Additionally, we evaluated the five controllers to assess which method provides the best performance metrics in the context of the minimum index in predictive errors, steady-state-error, peak overshoot, and time-responses. The results show that our proposed architecture (DDPG-FC-350-E-PID) yielded the best performance and surpasses all other approaches on most of the evaluation metric indices. Furthermore, an appropriate training of an artificial intelligence-based controller can aid to obtain the best path tracking. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1088/0964-1726/25/10/10LT02,Smart Materials and Structures,"The programmable sequential actuation of two-dimensional hydrogel membranes into three-dimensional folded architectures has been achieved by combining ionoprinting and redox chemistry; this methodology permits the programmed evolution of complex architectures triggered through localized out-of-plane deformations. In our study we describe a soft actuator which utilizes ionoprinting of iron and vanadium, with the selective reduction of iron through a mild reducing agent, to achieve chemically controlled sequential folding. Through the optimization of solvent polarity and ionoprinting variables (voltage, duration and anode composition), we have shown how the actuation pathways, rate-of-movement and magnitude of angular rotation can be controlled for the design of a 4D sequential actuator. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1088/1361-6528/aae81c,Nanotechnology,"Spiking neural networks (SNNs) employing memristive synapses are capable of life-long online learning. Because of their ability to process and classify large amounts of data in real-time using compact and low-power electronic systems, they promise a substantial technology breakthrough. However, the critical issue that memristor-based SNNs have to face is the fundamental limitation in their memory capacity due to finite resolution of the synaptic elements, which leads to the replacement of old memories with new ones and to a finite memory lifetime. In this study we demonstrate that the nonlinear conductance dynamics of memristive devices can be exploited to improve the memory lifetime of a network. The network is simulated on the basis of a spiking neuron model of mixed-signal digital-analogue sub-threshold neuromorphic CMOS circuits, and on memristive synapse models derived from the experimental nonlinear conductance dynamics of resistive memory devices when stimulated by trains of identical pulses. The network learning circuits implement a spike-based plasticity rule compatible with both spike-timing and rate-based learning rules. In order to get an insight on the memory lifetime of the network, we analyse the learning dynamics in the context of a classical benchmark of neural network learning, that is hand-written digit classification. In the proposed architecture, the memory lifetime and the performance of the network are improved for memristive synapses with nonlinear dynamics with respect to linear synapses with similar resolution. These results demonstrate the importance of following holistic approaches that combine the study of theoretical learning models with the development of neuromorphic CMOS SNNs with memristive devices used to implement life-long on-chip learning. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1088/1757-899X/245/3/032049,IOP Conference Series: Materials Science and Engineering,"The paper presents the influence of the ageing on viscoelastic properties of the bitumen at road pavement operating temperatures. The ageing process of bituminous binders causes changes in physical and mechanical properties of the bitumen. This phenomenon takes place in all stages of bituminous mixtures manufacturing, namely: mixing, storage, transport, placing. Nevertheless, during the service life it occurs the increase in stiffness of asphalt binder that is caused by the physical hardening of bitumen as well as the influence of oxidation. Therefore, it is important to identify the binder properties at a high and low operating temperatures of asphalt pavement after simulation of an ageing process. In the experiment as a reference bitumen, the polymer modified bitumen PMB 45/80-65 was used. The liquid surface active agent FA (fatty amine) was used as a bitumen viscosity-reducing modifier. It was added in the amount of 0,2%, 0,4% and 0,6% by the bitumen mass. All binder properties have been determined before ageing (NEAT) and after long-term ageing simulated by the Pressure Ageing Vessel method (PAV). To determine the binder properties at high temperatures the dynamic viscosity at 60°C was tested. On the basis of test results coming from the dynamic viscosity test it was calculated the binder hardening index. The properties at a low temperature were determined by measuring the creep modulus using Bending Beam Rheometer (BBR) at four temperatures: -10°C, -16°C, -22°C and -28°C. The stiffness creep modulus ""S"" and parameter ""m"" were determined. On the basis of dynamic viscosity test it was found that the ageing process caused a slight decrease in a dynamic viscosity. The level of a hardening index considerably increased at 0.6% fatty amine content. The long-term ageing process had a minor effect on stiffening of a polymer modified bitumen with FA additive regardless of a low temperature and an amount of fatty amine content. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1088/1757-899X/245/5/052004,IOP Conference Series: Materials Science and Engineering,"Recently, an expanded understanding of building performance acknowledges that all forces acting on buildings (climate, energies, information, and human agents) are not static and fixed, but rather mutable and transient. With the use of parametric and multi-criteria optimization digital tools, buildings' envelopes can be designed to respond to various requirements. This paper explores the possibilities of architectural design to benefit human conditions, which encompasses mental well-being, environmental quality of life during the Climate Change era. The first part of the paper defines the main factors (such as: lack of green nature and sunlight, noise and pollution) which are influencing the formation of psychological disorder in big cities. The negative impact of these factors is constantly increasing in the time of Climate Change progressing. The second part presents results of the research program undertaken at West Pomeranian University of Technology in Szczecin by author. The program goes on to attempt to solve the problem through architectural design. This study highlights a social problem, such as mental well-being, resulting from urbanization or effects of the climate change, and serves as a useful background for further research on the possibilities of redefining sustainable and human friendly design. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1088/1757-899X/245/5/052086,IOP Conference Series: Materials Science and Engineering,"This article discusses the use of information and communication technologies (ICT) at the local level of governance in the field of urban planning. It is based on a literature review, in order to define a set of considerations about their use in the urban context and the challenges ahead on this domain. As a starting point, there is the need of rethinking the local governance through the use of ICT related to cities, focused on the modernization of the processes associated with urban planning. Nowadays, in several societies the paradigm about cities if shifting, from an expansionist way of acting towards a regeneration and rehabilitation approach. In the case of Portugal, the local authorities; the municipalities; are the main responsible for the coordination, and integration of policies with territorial impacts. However, these policies are generally onerous and inefficient, triggering communication and information failures in between local administration and citizens. In this sense, governance should support the decision-making process related to cities' policies, engaging citizens and socio-economic agents. As the main result in this scenario, the use of ICT demonstrates the ability to play an important role in urban planning, by contributing as a simplifying tool, regarding the information and knowledge sharing, gathering local authorities, citizens and socio-economic agents. On the one hand, they promote the reduction of inefficiencies associated to the urban planning process. On the other hand, they boost the development of networks, and consequently the social and territorial cohesion. In summary, the use of ICT infrastructures works as a glue allowing the integration of several intelligence elements of the city, and operating as their base platform. Finally, the literature has revealed that the use of ICT in urban planning should be seen as a means to a wider social goal, and not as an end by itself. With the use of ICT, urban planning authorities are more likely to be aware of the city features in their multiple aspects, being able to define and monitoring the public policies, suitable to each situation, reinforcing the democracy and transparency of local governance. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1088/1757-899X/471/3/032047,IOP Conference Series: Materials Science and Engineering,"The mechanism and conditions of surface modification of wood by phosphorous-containing and siliceous organic compounds have been studied. Wood has the ability to absorb moisture from the air, and the moisture content of wood produces a significant effect on the physical and mechanical properties of wood. Traditional water-repellent agents of lignocellulosic materials are Organic Silicon Compounds (OSC). Our research is aimed at developing a ""soft"" silylation technology, in which the degree of chemical modification is negligible, and the content of chemically bound Si amounts to ∼ 1%. As silylating agents, alkylhydride siloxanes, alkoxysilanes were used. From alkylhydride siloxanes, polyethylhydride siloxane (PEHS) and polymethylhydride siloxane (PMS) with different n-polymerization degrees were used. Activating hydrophilic additives were ammonium fluoride, potassium fluoride and titanates. The treatment of wood with salts, with the subsequent treatment with OSCs facilitated the penetration of OSCs into the wood while the processes of ""soft"" silylation proceeded. ""Soft"" silylation of wood with polyalkylhydride siloxanes proceeds in the presence of catalyst additives, the degree of silylation is low and depends on the nature of the additives. The dependence of distribution of OSCs in the wood on the nature of the additives is evidenced by the method of scanning electron microscopy. Phosphorous-containing organic compounds (FOC) have a high penetrating ability, while completely filling the intercellular structure of the wood. With the sequential impregnation of the wood with FOCs and OSCs, organic silicon compounds enter the intercellular space of the wood, with dense spongy OSC deposits, which in some places completely fill the internal cavities of cellular tubes of the wood. As FOC, for example, a 40% solution of trichloroethylphosphate (TCEP) was used. Decaying of wood over time starts from the surface, since there are no diffusive limitations in the sorption process. Surface modification of wood can increase its durability due to increased biological stability and hydrophobic behaviour, which will ensure a long-lasting protection. Long-lasting protection is due to the formation of covalent bonds of wood (cellulose) with a modifier. Wood samples after surface ""soft"" modification with FOCs and OSCs were tested for hydrophobic behaviour and biological stability. The samples were tested in the climate chamber with irrigation of the samples with water in a mode of -30°C to +40°C. To determine the hydrophobic behaviour, the limiting wetting angle was determined. The biological stability was determined by the growth of testing cultures of the fungi Aspergillus, Penicillium, Trihoderma and some others according to GOST 9.048-89. The amount of the data obtained allows to make a conclusion about the nondurable decrease in water absorption capacity during surface modification of wood with OSCs. Long-lasting biological and water resistance is achieved only in cases when surface application of OSCs is carried out on the pre-phosphorylated wood. Phosphorylation thus leads to the formation of covalent bonds. The compounds developed were successfully used for 10-15 years to preserve the monuments both of wooden architecture and the buildings and structures made of stone, bricks, and concrete. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1088/1757-899X/603/5/052097,IOP Conference Series: Materials Science and Engineering,"Achieving suitable and comfortable indoor environmental quality comfort via innovative, sustainable, energy efficient approaches is a contemporary research aim world-wide. The indoor space and its perception are influenced by three basic components: The surrounding factors (temperature, noise, odor, noise and lighting), the structural factors (architecture, color, materials, pattern, and structure) and the social factors (occupants). The relationship between IEQ and wellbeing is complicated. A range of indoor factors such as thermal, visual, acoustic, and chemical can impact the wellbeing, performance and health of the occupants. Colors are an interesting and well-studied psychological phenomenon. Colors, combinations, saturation and shades are the focus of advertising creators, interior designers and exteriors, architects, psychologists and many others. Specific colors and patterns have a direct influence on health, emotions, behavior, and performance of building users. Color is one of the basic properties of objects and environments. Colors have a great impact on our perception and evaluation. For example, it is proven that long-term stay in a deeply painted room is very nervous on the nervous system or that red and yellow tend to be seen as warning signals. A color's hue is determined by its wavelength [nm]. Long wavelengths are associated with warm colors, with red (∼ 625-800 nm) being most extreme followed by orange (∼ 590-625 nm). Short wavelengths are associated with cold colors, with violet (∼ 430-500 nm] being most extreme followed by blue (∼ 430-500 nm). In this study, the impact of indoor coloŕs use and indoor environmental quality is examined. The focus of this contribution is to establish a link between the color as IEQ parameter and health and well-being of occupants. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1088/1758-5090/ad38df,Biofabrication,"High-throughput drug screening is crucial for advancing healthcare through drug discovery. However, a significant limitation arises from available in vitro models using conventional 2D cell culture, which lack the proper phenotypes and architectures observed in three-dimensional (3D) tissues. Recent advancements in stem cell biology have facilitated the generation of organoids—3D tissue constructs that mimic human organs in vitro. Kidney organoids, derived from human pluripotent stem cells, represent a significant breakthrough in disease representation. They encompass major kidney cell types organized within distinct nephron segments, surrounded by stroma and endothelial cells. This tissue allows for the assessment of structural alterations such as nephron loss, a characteristic of chronic kidney disease. Despite these advantages, the complexity of 3D structures has hindered the use of organoids for large-scale drug screening, and the drug screening pipelines utilizing these complex in vitro models remain to be established for high-throughput screening. In this study, we address the technical limitations of kidney organoids through fully automated 3D imaging, aided by a machine-learning approach for automatic profiling of nephron segment-specific epithelial morphometry. Kidney organoids were exposed to the nephrotoxic agent cisplatin to model severe acute kidney injury. An U.S. Food and Drug Administration (FDA)-approved drug library was tested for therapeutic and nephrotoxicity screening. The fully automated pipeline of 3D image acquisition and analysis identified nephrotoxic or therapeutic drugs during cisplatin chemotherapy. The nephrotoxic potential of these drugs aligned with previous in vivo and human reports. Additionally, Imatinib, a tyrosine kinase inhibitor used in hematological malignancies, was identified as a potential preventive therapy for cisplatin-induced kidney injury. Our proof-of-concept report demonstrates that the automated screening process, using 3D morphometric assays with kidney organoids, enables high-throughput screening for nephrotoxicity and therapeutic assessment in 3D tissue constructs. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1088/2043-6254/aa8536,Advances in Natural Sciences: Nanoscience and Nanotechnology,"Synthesis of nanoparticles from various biological systems has been reported, but among all such systems, biosynthesis of nanoparticles from plants is considered the most suitable method. The use of plant material not only makes the process eco-friendly, but also the abundance makes it more economical. The aim of this study was to biologically synthesize silver nanoparticle using Piliostigma thonningii aqueous leaf extract and applied in the purification of laboratory stimulated waste with optimization using the different conditions of silver nanoparticle production such as time, temperature, pH, concentration of silver nitrate and volume of the aqueous extract. The biosynthesized silver nanoparticles were characterized by UV-visible spectrophotometry, nanosizer, energy dispersive x-ray analysis (EDX), transmission electron microscopy (TEM) and Fourier transform infrared (FTIR) spectroscopy. The time intervals for the reaction with aqueous silver nitrate solution shows an increase in the absorbance with time and became constant giving a maximum absorbance at 415 nm at 60 min of incubation. The pH of 6.5, temperature 65 °C, 1.25 mM of silver nitrate and 5 ml of plant extract was the best condition with maximum absorbance. The results from nanosizer, UV-vis and TEM suggested the biosynthesis silver nanoparticle to be spherical ranging from 50 nm to 114 nm. The EDX confirmed the elemental synthesis of silver at 2.60 keV and FTIR suggested the capping agent to be hydroxyl (OH) group with-C=C stretching vibrations. The synthesized silver nanoparticle also shows heavy metal removal activity in laboratory simulated waste water. The safety toxicity studies show no significant difference between the orally administered silver nanoparticles treated water group and control group, while the histopathological studies show well preserved hepatic architecture for the orally administered silver nanoparticle treated waste water group when compared with the control group. Therefore, it can be concluded that the biosynthesized silver nanoparticles have efficient ability in heavy metal removal without sub chronic adverse effects in experimental rats. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1089/pho.2012.3341,Photomedicine and Laser Surgery,"Objective: The aim of this study was to test photodynamic therapy (PDT) as an alternative approach to biofilm disruption on dental hard tissue, We evaluated the effect of methylene blue and a 660 nm diode laser on the viability and architecture of Gram-positive and Gram-negative bacterial biofilms. Materials and methods: Ten human teeth were inoculated with bioluminescent Pseudomonas aeruginosa or Enterococcus faecalis to form 3 day biofilms in prepared root canals. Bioluminescence imaging was used to serially quantify and evaluate the bacterial viability, and scanning electron microscopic (SEM) imaging was used to assess architecture and morphology of bacterial biofilm before and after PDT employing methylene blue and 40 mW, 660 nm diode laser light delivered into the root canal via a 300 μm fiber for 240 sec, resulting in a total energy of 9.6 J. The data were statistically analyzed with analysis of variance (ANOVA) followed by Tukey test. Results: The bacterial reduction showed a dose dependence; as the light energy increased, the bioluminescence decreased in both planktonic suspension and in biofilms. The SEM analysis showed a significant reduction of biofilm on the surface. PDT promoted disruption of the biofilm and the number of adherent bacteria was reduced. Conclusions: The photodynamic effect seems to disrupt the biofilm by acting both on bacterial cells and on the extracellular matrix. © Mary Ann Liebert, Inc. © 2013 Elsevier B.V., All rights reserved.",TOPIC
10.1093/bib/bbab271,Briefings in Bioinformatics,"Drug combinations have exhibited promising therapeutic effects in treating cancer patients with less toxicity and adverse side effects. However, it is infeasible to experimentally screen the enormous search space of all possible drug combinations. Therefore, developing computational models to efficiently and accurately identify potential anti-cancer synergistic drug combinations has attracted a lot of attention from the scientific community. Hypothesis-driven explicit mathematical methods or network pharmacology models have been popular in the last decade and have been comprehensively reviewed in previous surveys.With the surge of artificial intelligence and greater availability of large-scale datasets,machine learning especially deep learning methods are gaining popularity in the field of computational models for anti-cancer drug synergy prediction.Machine learning-based methods can be derived without strong assumptions about underlying mechanisms and have achieved state-of-the-art prediction performances, promoting much greater growth of the field. Here, we present a structured overview of available large-scale databases and machine learning especially deep learning methods in computational predictive models for anti-cancer drug synergy prediction.We provide a unified framework for machine learning models and detail existing model architectures as well as their contributions and limitations, shedding light into the future design of computational models. Besides, unbiased experiments are conducted to provide in-depth comparisons between reviewed papers in terms of their prediction performance. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1093/bib/bbae227,Briefings in Bioinformatics,"Predicting cancer drug response using both genomics and drug features has shown some success compared to using genomics features alone. However, there has been limited research done on how best to combine or fuse the two types of features. Using a visible neural network with two deep learning branches for genes and drug features as the base architecture, we experimented with different fusion functions and fusion points. Our experiments show that injecting multiplicative relationships between gene and drug latent features into the original concatenation-based architecture DrugCell significantly improved the overall predictive performance and outperformed other baseline models. We also show that different fusion methods respond differently to different fusion points, indicating that the relationship between drug features and different hierarchical biological level of gene features is optimally captured using different methods. Considering both predictive performance and runtime speed, tensor product partial is the best-performing fusion function to combine late-stage representations of drug and gene features to predict cancer drug response. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1093/bib/bbaf403,Briefings in Bioinformatics,"The advancement of traditional Chinese medicine (TCM) faces challenges, due to the absence of a deep understanding of TCM mechanism at the perspective of modern biomedical practices. This results in how TCM selects herbs to treat diseases or symptoms prevailingly rely on clinicals’ experience or TCM ancient books, at least in part lacking scientific basis. Herein, we present a novel deep learning–based approach, named Negative-Correlation-based TCM Architecture for Reversal (NeCTAR), to optimize the generation and combination of TCM formulas for guiding empiric therapy, by which we could, to some degree, narrow the gap between TCM and modern biomedical science. Our approach builds on a hypothesis that pathway alterations may serve as a proxy for the corresponding physiological changes induced by a certain disease, and ‘inverse-fit’ those alterations would provide a feasible therapeutic strategy to treat the disease. We leveraged ribonucleic acid sequencing (RNA-seq) data with Gene Set Enrichment Analysis to establish herb-pathway associations, integrating these insights into a multilayer perceptron model that incorporates top-k sparse projection and pathway reconstruction loss to predict the most therapeutically promising herbal components. NeCTAR demonstrated high concordance with experimental data across various disease models, including fatty liver disease, type 2 diabetes mellitus, and premature ovarian failure. Notably, NeCTAR could equally apply to single cell RNA-seq data. Overall, our study put forwards a novel interpretive framework underlying TCM mechanisms using modern biomedical foundation, by which we could prioritize herbal components based on existing TCM formulas treating diseases. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1093/bib/bbaf500,Briefings in Bioinformatics,"The development of antimicrobial peptides (AMPs) presents a promising approach to addressing antibiotic-resistant pathogens. Computational methods, such as Feedback Generative Adversarial Networks (FBGANs), have demonstrated strong performance in optimizing AMP design. FBGAN operates as a classifier-guided Generative Adversarial Network (GAN), refining training data by replacing them with the classifier’s most accurate predictions based on a predefined threshold. However, this method may introduce bias and constrain the diversity and quality of the generated peptides. To address these limitations, we propose a novel classifier-driven GAN (cdGAN) framework that seamlessly integrates classifier predictions into the generative model’s loss function. This enables an adaptive, end-to-end learning process that enhances AMP generation without requiring explicit data modifications. By embedding classifier guidance within the loss computation, cdGAN dynamically optimizes both peptide diversity and functionality. Comparative studies indicate that cdGAN outperforms conventional guided-GAN architectures, such as Conditional GANs and Auxiliary Classifier GANs, while achieving performance comparable to or exceeding established AMP design methods. Additionally, cdGAN’s flexible architecture allows for the simultaneous optimization of multiple peptide attributes. To demonstrate this capability, we introduce a multi-task classifier based on the Evolutionary Scale Modeling 2 (ESM2) model, enabling cdGAN to assess both antimicrobial activity and peptide structural properties in parallel. This enhancement improves the likelihood of generating viable therapeutic candidates with enhanced antimicrobial effectiveness and reduced toxicity. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1093/bib/bbp073,Briefings in Bioinformatics,"Driven by the availability of experimental data and ability to simulate a biological scale which is of immediate interest, the cellular scale is fast emerging as an ideal candidate for middle-out modelling. As with 'bottom-up' simulation approaches, cellular level simulations demand a high degree of computational power, which in large-scale simulations can only be achieved through parallel computing. The flexible large-scale agent modelling environment (FLAME) is a template driven framework for agent-based modelling (ABM) on parallel architectures ideally suited to the simulation of cellular systems. It is available for both high performance computing clusters (www.flame.ac.uk) and GPU hardware (www.flamegpu.com) and uses a formal specification technique that acts as a universal modelling format. This not only creates an abstraction from the underlying hardware architectures, but avoids the steep learning curve associated with programming them. In benchmarking tests and simulations of advanced cellular systems, FLAME GPU has reported massive improvement in performance over more traditional ABM frameworks. This allows the time spent in the development and testing stages of modelling to be drastically reduced and creates the possibility of real-time visualisation for simple visual face-validation. © The Author 2010. Published by Oxford University Press. © 2010 Elsevier B.V., All rights reserved.; MEDLINE® is the source for the MeSH terms of this document.",TOPIC
10.1093/bioinformatics/btab336,Bioinformatics,"Motivation: Anti-cancer drug sensitivity prediction using deep learning models for individual cell line is a significant challenge in personalized medicine. Recently developed REFINED (REpresentation of Features as Images with NEighborhood Dependencies) CNN (Convolutional Neural Network)-based models have shown promising results in improving drug sensitivity prediction. The primary idea behind REFINED-CNN is representing high dimensional vectors as compact images with spatial correlations that can benefit from CNN architectures. However, the mapping from a high dimensional vector to a compact 2D image depends on the a priori choice of the distance metric and projection scheme with limited empirical procedures guiding these choices. Results: In this article, we consider an ensemble of REFINED-CNN built under different choices of distance metrics and/or projection schemes that can improve upon a single projection based REFINED-CNN model. Results, illustrated using NCI60 and NCI-ALMANAC databases, demonstrate that the ensemble approaches can provide significant improvement in prediction performance as compared to individual models. We also develop the theoretical framework for combining different distance metrics to arrive at a single 2D mapping. Results demonstrated that distance-averaged REFINED-CNN produced comparable performance as obtained from stacking REFINED-CNN ensemble but with significantly lower computational cost. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1093/bioinformatics/btac711,Bioinformatics,"Motivation: Antimicrobial peptides (AMPs) have the potential to inhibit multiple types of pathogens and to heal infections. Computational strategies can assist in characterizing novel AMPs from proteome or collections of synthetic sequences and discovering their functional abilities toward different microbial targets without intensive labor. Results: Here, we present a deep learning-based method for computer-aided novel AMP discovery that utilizes the transformer neural network architecture with knowledge from natural language processing to extract peptide sequence information. We implemented the method for two AMP-related tasks: the first is to discriminate AMPs from other peptides, and the second task is identifying AMPs functional activities related to seven different targets (gram-negative bacteria, gram-positive bacteria, fungi, viruses, cancer cells, parasites and mammalian cell inhibition), which is a multi-label problem. In addition, asymmetric loss was adopted to resolve the intrinsic imbalance of dataset, particularly for the multi-label scenarios. The evaluation showed that our proposed scheme achieves the best performance for the first task (96.85% balanced accuracy) and has a more unbiased prediction for the second task (79.83% balanced accuracy averaged across all functional activities) when compared with that of strategies without imbalanced learning or deep learning. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1093/bioinformatics/btad478,Bioinformatics,"Motivation: Understanding drug-response differences in cancer treatments is one of the most challenging aspects of personalized medicine Recently, graph neural networks (GNNs) have become state-of-The-Art methods in many graph representation learning scenarios in bioinformatics However, building an optimal handcrafted GNN model for a particular drug sensitivity dataset requires manual design and fine-Tuning of the hyperparameters for the GNN model, which is time-consuming and requires expert knowledge Results: In this work, we propose AutoCDRP, a novel framework for automated cancer drug-response predictor using GNNs Our approach leverages surrogate modeling to efficiently search for the most effective GNN architecture AutoCDRP uses a surrogate model to predict the performance of GNN architectures sampled from a search space, allowing it to select the optimal architecture based on evaluation performance Hence, AutoCDRP can efficiently identify the optimal GNN architecture by exploring the performance of all GNN architectures in the search space Through comprehensive experiments on two benchmark datasets, we demonstrate that the GNN architecture generated by AutoCDRP surpasses state-of-The-Art designs Notably, the optimal GNN architecture identified by AutoCDRP consistently outperforms the best baseline architecture from the first epoch, providing further evidence of its effectiveness © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1093/bioinformatics/btae708,Bioinformatics,"Motivation: Peptides and their derivatives hold potential as therapeutic agents. The rising interest in developing peptide drugs is evidenced by increasing approval rates by the FDA of USA. To identify the most potential peptides, study on peptide-protein interactions (PepPIs) presents a very important approach but poses considerable technical challenges. In experimental aspects, the transient nature of PepPIs and the high flexibility of peptides contribute to elevated costs and inefficiency. Traditional docking and molecular dynamics simulation methods require substantial computational resources, and the predictive accuracy of their results remain unsatisfactory. Results: To address this gap, we proposed TPepPro, a Transformer-based model for PepPI prediction. We trained TPepPro on a dataset of 19,187 pairs of peptide-protein complexes with both sequential and structural features. TPepPro utilizes a strategy that combines local protein sequence feature extraction with global protein structure feature extraction. Moreover, TPepPro optimizes the architecture of structural featuring neural network in BN-ReLU arrangement, which notably reduced the amount of computing resources required for PepPIs prediction. According to comparison analysis, the accuracy reached 0.855 in TPepPro, achieving an 8.1% improvement compared to the second-best model TAGPPI. TPepPro achieved an AUC of 0.922, surpassing the second-best model TAGPPI with 0.844. Moreover, the newly developed TPepPro identify certain PepPIs that can be validated according to previous experimental evidence, thus indicating the efficiency of TPepPro to detect high potential PepPIs that would be helpful for amino acid drug applications. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1093/bioinformatics/btaf069,Bioinformatics,"Motivation: The widespread use of antibiotics has led to the emergence of resistant pathogens. Antimicrobial peptides (AMPs) combat bacterial infections by disrupting the integrity of cell membranes, making it challenging for bacteria to develop resistance. Consequently, AMPs offer a promising solution to addressing antibiotic resistance. However, the limited availability of natural AMPs cannot meet the growing demand. While deep learning technologies have advanced AMP generation, conventional models often lack stability and may introduce unforeseen side effects. Results: This study presents a novel denoising VAE-based model guided by desirable physicochemical properties for AMP generation. The model integrates key features (e.g. molecular weight, isoelectric point, hydrophobicity, etc.), and employs position encoding along with a Transformer architecture to enhance generation accuracy. A customized loss function, combining reconstruction loss, KL divergence, and property preserving loss ensure effective model training. Additionally, the model incorporates a denoising mechanism, enabling it to learn from perturbed inputs, thus maintaining performance under limited training data. Experimental results demonstrate that the proposed model can generate AMPs with desirable functional properties, offering a viable approach for AMP design and analysis, which ultimately contributes to the fight against antibiotic resistance. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1093/bioinformatics/btaf255,Bioinformatics,"Motivation Anti-cancer drug response prediction (DRP) using cancer cell lines (CLs) is crucial in stratified medicine and drug discovery. Recently, new deep learning models for DRP have improved performance over their predecessors. However, different models use different input data types and architectures making it hard to find the source of these improvements. Here we consider published DRP models that report state-of-the-art performance predicting continuous response values. These models take chemical structures of drugs and omics profiles of CLs as input. Results By experimenting with these models and comparing with our simple baselines, we show that no performance comes from drug features, instead, performance is due to the transcriptomics CL profiles. Furthermore, we show that, depending on the testing type, much of the current reported performance is a property of the training target values. We address these limitations by creating BinaryET and BinaryCB that predict binary drug response values, guided by the hypothesis that this reduces the noise in the drug efficacy data. Thus, better aligning them with biochemistry that can be learnt from the input data. BinaryCB leverages a chemical foundation model, while BinaryET is trained from scratch using a transformer-type architecture. We show that these models learn useful chemical drug features, which is the first time this has been demonstrated for multiple testing types to our knowledge. We further show binarizing the drug response values causes the models to learn useful chemical drug features. We also show that BinaryET improves performance over BinaryCB, and the published models that report state-of-the-art performance. Availability and implementation Code is available from https://github.com/Nik-BB/Understanding-DRP-models. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1093/database/baac021,Database : the journal of biological databases and curation,"Fungi are the major decomposers in terrestrial and aquatic ecosystems, playing essential roles in biogeochemical cycles and food webs. The Fungi kingdom encompasses a diverse array of taxa that often form intimate relationships with other organisms, including plants, insects, algae, cyanobacteria and even other fungi. Fungal parasites of insects are known as entomopathogenic fungi and are the causative agents of serious disease and/or mortality of their hosts. Entomopathogens produce distinct metabolic compounds with roles in pathogenicity, virulence and host-parasite interactions. Thus, the potential of discovering new bioactive compounds useful in biocontrol and pharmaceutical industries is high. Given the significance of entomopathogenic fungi, the rapid research advances and the increased interest, it has become necessary to organize all available and incoming data. The website https://invertebratefungi.org/ has been developed to serve this purpose by gathering and updating entomopathogenic genera/species information. Notes of entomopathogenic genera will be provided with emphasis on their taxonomic status. Information on other invertebrates, such as rotifers, will also be included. Descriptions, photographic plates, information on distribution and host (where applicable) along with molecular data and other interesting details will also be provided. The website is easily and freely accessible to users. Instructions concerning the platform architecture and functionality of the website are introduced herein. The platform is currently being expanded and will be continuously updated as part of the effort to enrich knowledge on this group of fungi. Database URL: https://invertebratefungi.org/ © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1093/gigascience/giaf080,GigaScience,"Motivation: Drug combination therapy plays a pivotal role in addressing the molecular heterogeneity of cancer, improving treatment efficacy, minimizing resistance, and reducing toxicity. Deep learning approaches have significantly advanced drug combination discovery by addressing the limitations of conventional laboratory experiments, which are time-consuming and costly. While most existing models rely on the molecular structure of drugs and gene expression data, incorporating protein-level expression provides a more accurate representation of cellular behavior and drug responses. In this study, we introduce SynProtX, an enhanced deep learning model that explicitly integrates large-scale proteomics with deep neural networks (DNNs) and the molecular structure of drugs with graph neural networks (GNNs). Results: The SynProtX-GATFP model, which combines molecular graphs and fingerprints through a graph attention network architecture, demonstrated superior predictive performance for the FRIEDMAN study dataset. We further evaluated its cell line–specific performance, which achieved accuracy across diverse tissue and study datasets. By incorporating protein expression data, the model consistently enhanced predictive performance over gene expression–only models, reflecting the functional state of cancer cells. The generalizability of SynProtX was rigorously validated using cold-start prediction, including leave-drug-combination-out, leave-drug-out, and leave-cell-line-out validation strategies, highlighting its robust performance and potential for clinical applicability. Additionally, SynProtX identified key cancer-associated proteins and molecular substructures, offering novel insights into the biological mechanisms underlying drug synergy. These findings highlight the potential of integrating large-scale proteomics and multiomics data to advance anticancer drug design and combination therapy strategies for personalized medicine. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1093/nargab/lqab004,NAR Genomics and Bioinformatics,"Viruses evolve extremely quickly, so reliable methods for viral host prediction are necessary to safeguard biosecurity and biosafety alike. Novel human-infecting viruses are difficult to detect with standard bioinformatics workflows. Here, we predict whether a virus can infect humans directly from next-generation sequencing reads. We show that deep neural architectures significantly outperform both shallow machine learning and standard, homology-based algorithms, cutting the error rates in half and generalizing to taxonomic units distant from those presented during training. Further, we develop a suite of interpretability tools and show that it can be applied also to other models beyond the host prediction task. We propose a new approach for convolutional filter visualization to disentangle the information content of each nucleotide from its contribution to the final classification decision. Nucleotide-resolution maps of the learned associations between pathogen genomes and the infectious phenotype can be used to detect regions of interest in novel agents, for example, the SARS-CoV-2 coronavirus, unknown before it caused a COVID-19 pandemic in 2020. All methods presented here are implemented as easy-to-install packages not only enabling analysis of NGS datasets without requiring any deep learning skills, but also allowing advanced users to easily train and explain new models for genomics. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1098/rsif.2014.1174,Journal of the Royal Society Interface,"Glioblastoma multiforme (GBM) is a highly invasive primary brain tumour that has poor prognosis despite aggressive treatment. A hallmark of these tumours is diffuse invasion into the surrounding brain, necessitating a multi-modal treatment approach, including surgery, radiation and chemotherapy. We have previously demonstrated the ability of our model to predict radiographic response immediately following radiation therapy in individual GBM patients using a simplified geometry of the brain and theoretical radiation dose. Using only two pre-treatment magnetic resonance imaging scans, we calculate net rates of proliferation and invasion as well as radiation sensitivity for a patient's disease. Here, we present the application of our clinically targeted modelling approach to a single glioblastoma patient as a demonstration of our method. We apply our model in the full threedimensional architecture of the brain to quantify the effects of regional resistance to radiation owing to hypoxia in vivo determined by [18F]-fluoromisonidazole positron emission tomography (FMISO-PET) and the patientspecific three-dimensional radiation treatment plan. Incorporation of hypoxia into our model with FMISO-PET increases the model-data agreement by an order of magnitude. This improvementwas robust to our definition of hypoxia or the degree of radiation resistance quantified with the FMISO-PET image and our computational model, respectively. This work demonstrates a useful application of patient-specific modelling in personalized medicine and how mathematical modelling has the potential to unify multi-modality imaging and radiation treatment planning. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1098/rsif.2015.0226,Journal of the Royal Society Interface,"Bioadhesives have drawn increasing interest in recent years, owing to their eco-friendly, biocompatible and biodegradable nature. As a typical bioadhesive, sticky exudate observed on the stalked glands of sundew plants aids in the capture of insects and this viscoelastic adhesive has triggered extensive interests in revealing the implied adhesion mechanisms. Despite the significant progress that has been made, the structural traits of the sundew adhesive, especially the morphological characteristics in nanoscale, which may give rise to the viscous and elastic properties of this mucilage, remain unclear. Here, we show that the sundew adhesive is a naturally occurring hydrogel, consisting of nano-network architectures assembled with polysaccharides. The assembly process of the polysaccharides in this hydrogel is proposed to be driven by electrostatic interactions mediated with divalent cations. Negatively charged nanoparticles, with an average diameter of 231.9 ± 14.8 nm, are also obtained from this hydrogel and these nanoparticles are presumed to exert vital roles in the assembly of the nano-networks. Further characterization via atomic force microscopy indicates that the stretching deformation of the sundew adhesive is associated with the flexibility of its fibrous architectures. It is also observed that the adhesion strength of the sundew adhesive is susceptible to low temperatures. Both elasticity and adhesion strength of the sundew adhesive reduce in response to lowering the ambient temperature. The feasibility of applying sundew adhesive for tissue engineering is subsequently explored in this study. Results show that the fibrous scaffolds obtained from sundew adhesive are capable of increasing the adhesion of multiple types of cells, including fibroblast cells and smooth muscle cells, a property that results from the enhanced adsorption of serum proteins. In addition, in light of the weak cytotoxic activity exhibited by these scaffolds towards a variety of mammal cells, evidence is sufficient to propose that sundew adhesive is a promising nanomaterial worth further exploitation in the field of tissue engineering. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1098/rsif.2021.0140,Journal of the Royal Society Interface,"Multi-scale structural assessment of biological soft tissue is challenging but essential to gain insight into structure-function relationships of tissue/organ. Using the human placenta as an example, this study brings together sophisticated sample preparation protocols, advanced imaging and robust, validated machine-learning segmentation techniques to provide the first massively multi-scale and multi-domain information that enables detailed morphological and functional analyses of both maternal and fetal placental domains. Finally, we quantify the scale-dependent error in morphological metrics of heterogeneous placental tissue, estimating the minimal tissue scale needed in extracting meaningful biological data. The developed protocol is beneficial for high-throughput investigation of structure-function relationships in both normal and diseased placentas, allowing us to optimize therapeutic approaches for pathological pregnancies. In addition, the methodology presented is applicable in the characterization of tissue architecture and physiological behaviours of other complex organs with similarity to the placenta, where an exchange barrier possesses circulating vascular and avascular fluid spaces. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1098/rsif.2021.0872,Journal of the Royal Society Interface,"Wheat and other staple crops are devastated by fungal diseases. Many fungal plant pathogens are spread via active or passive discharge of microscopic spores. Here, we described the unique transport of spores of the fungal pathogen Epicoccum tritici, causal agent of black sooty mould, on wheat awns. The unique multi-scale architecture of wheat awns, coupled with condensation and evaporation of dew droplets, facilitated the transport and agglomeration of spores of the fungus. First, dew droplets spontaneously transported spores from the tips of awn hairs to the neighbouring stomatal ridges, driven by gradients in Laplace pressure and surface wettability. Subsequently, spores agglomerated into dry clusters due to the Cheerios effect and evaporation, increasing the likelihood of passive spore removal viawind shear and/or rainsplash. Future plant breeding approaches should consider the development of modified spike structures, such as those without awns or awn hairs, to reduce the potential for spread of fungal plant pathogens. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1098/rsif.2022.0890,Journal of the Royal Society Interface,"Contact structure among livestock populations influences the transmission of infectious agents among them. Models simulating realistic contact networks therefore have important applications for generating insights relevant to livestock diseases. This systematic review identifies and compares such models, their applications, data sources and how their validity was assessed. From 52 publications, 37 models were identified comprising seven model frameworks. These included mathematical models (n = 8; including generalized random graphs, scale-free, Watts-Strogatz and spatial models), agent-based models (n = 8), radiation models (n = 1) (collectively, considered 'mechanistic'), gravity models (n = 4), exponential random graph models (n = 9), other forms of statistical model (n = 6) (statistical) and random forests (n = 1) (machine learning). Overall, nearly half of the models were used as inputs for network-based epidemiological models. In all models, edges represented livestock movements, sometimes alongside other forms of contact. Statistical models were often applied to infer factors associated with network formation (n = 12). Mechanistic models were commonly applied to assess the interaction between network structure and disease dissemination (n = 6). Mechanistic, statistical and machine learning models were all applied to generate networks given limited data (n = 13). There was considerable variation in the approaches used for model validation. Finally, we discuss the relative strengths and weaknesses of model frameworks in different use cases. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1108/ACI-10-2020-0094,Applied Computing and Informatics,"Purpose: Machine Learning is an intelligent methodology used for prediction and has shown promising results in predictive classifications. One of the critical areas in which machine learning can save lives is diabetes prediction. Diabetes is a chronic disease and one of the 10 causes of death worldwide. It is expected that the total number of diabetes will be 700 million in 2045; a 51.18% increase compared to 2019. These are alarming figures, and therefore, it becomes an emergency to provide an accurate diabetes prediction. Design/methodology/approach: Health professionals and stakeholders are striving for classification models to support prognosis of diabetes and formulate strategies for prevention. The authors conduct literature review of machine models and propose an intelligent framework for diabetes prediction. Findings: The authors provide critical analysis of machine learning models, propose and evaluate an intelligent machine learning-based architecture for diabetes prediction. The authors implement and evaluate the decision tree (DT)-based random forest (RF) and support vector machine (SVM) learning models for diabetes prediction as the mostly used approaches in the literature using our framework. Originality/value: This paper provides novel intelligent diabetes mellitus prediction framework (IDMPF) using machine learning. The framework is the result of a critical examination of prediction models in the literature and their application to diabetes. The authors identify the training methodologies, models evaluation strategies, the challenges in diabetes prediction and propose solutions within the framework. The research results can be used by health professionals, stakeholders, students and researchers working in the diabetes prediction area. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1108/IJCS-11-2019-0034,An implementation architecture for crowd network simulations,"Purpose – Crowd network systems have been deemed as a promising mode of modern service industry and future economic society, and taking crowd network as the research object and exploring its operation mechanism and laws is of great significance for realizing the effective governance of the government and the rapid development of economy, avoiding social chaos and mutation. Because crowd network is a large-scale, dynamic and diversified online deep interconnection, its most results cannot be observed in real world, and it cannot be carried out in accordance with traditional way, simulation is of great importance to put forward related research. To solve above problems, this paper aims to propose a simulation architecture based on the characteristics of crowd network and to verify the feasibility of this architecture through a simulation example. Design/methodology/approach – This paper adopts a data-driven architecture by deeply analyzing existing large-scale simulation architectures and proposes a novel reflective memory-based architecture for crowd network simulations. In this paper, the architecture is analyzed from three aspects: implementation framework, functional architecture and implementation architecture. The proposed architecture adopts a general structure to decouple related work in a harmonious way and gets support for reflection storage by connecting to different devices via reflection memory card. Several toolkits for system implementation are designed and connected by data-driven files (DDF), and these XML files constitute a persistent storage layer. To improve the credibility of simulations, VV&A (verification, validation and accreditation) is introduced into the architecture to verify the accuracy of simulation system executions. Findings – Implementation framework introduces the scenes, methods and toolkits involved in the whole simulation architecture construction process. Functional architecture adopts a general structure to decouple related work in a harmonious way. In the implementation architecture, several toolkits for system implementation are designed, which are connected by DDF, and these XML files constitute a persistent storage layer. Crowd network simulations obtain the support of reflective memory by connecting the reflective memory cards on different devices and connect the interfaces of relevant simulation software to complete the corresponding function call. Meanwhile, to improve the credibility of simulations, VV&A is introduced into the architecture to verify the accuracy of simulation system executions. Originality/value – This paper proposes a novel reflective memory-based architecture for crowd network simulations. Reflective memory is adopted as share memory within given simulation execution in this architecture; communication efficiency and capability have greatly improved by this share memory-based architecture. This paper adopts a data-driven architecture; the architecture mainly relies on XML files to drive the entire simulation process, and XML files have strong readability and do not need special software to read.",TOPIC
10.1109/ACCESS.2016.2517072,Assessment of Urban Fabric for Smart Cities,"Comprehensive understandings to the built environment especially the urban form is a prerequisite for building a smart city. This paper is based on computational methods to examine the urban fabric of Hankou, China, as a case study. Quantitative and comparative analyses are involved to understand the characteristics on the block scale, where massive demolition and new construction coincide with the existing historical context. Five urban fabric indicators are defined (i.e., density, compactness, fragmentation, variance, and cohesion) to conduct a case study for the 83 selected blocks using geographic information system tools and statistical analysis. Distribution patterns and correlations between these indicators are analyzed. Comparisons are made between typical blocks with high, median, and low fabric densities using comprehensive fabric indicators. The research results indicate that the organic order of the original urban fabric is facing damage, especially from arbitrary demolition, overinfilling, and spontaneous encroachment. Finally, this paper discusses how retaining the urban fabric makes the city a vibrant place to live. The sustainable development of a city should attach great importance to the protection and continuation of local characteristics of integrity and authenticity. The described analytical methods could contribute to the optimization of urban design strategies for future smart cities.",TOPIC
10.1109/ACCESS.2016.2576286,A Cloud-Based Architecture for the Internet of Spectrum Devices Over Future Wireless Networks,"The dramatic increase in data rates in wireless networks has caused radio spectrum usage to be an essential and critical issue. Spectrum sharing is widely recognized as an affordable, near-term method to address this issue. This paper first characterizes the new features of spectrum sharing in future wireless networks, including heterogeneity in sharing bands, diversity in sharing patterns, crowd intelligence in sharing devices, and hyperdensification in sharing networks. Then, to harness the benefits of these unique features and promote a vision of spectrum without bounds and networks without borders, this paper introduces a new concept of the Internet of spectrum devices (IoSDs) and develops a cloud-based architecture for IoSD over future wireless networks, with the prime aim of building a bridging network among various spectrum monitoring devices and massive spectrum utilization devices, and enabling a highly efficient spectrum sharing and management paradigm for future wireless networks. Furthermore, this paper presents a systematic tutorial on the key enabling techniques of the IoSD, including big spectrum data analytics, hierarchal spectrum resource optimization, and quality of experience-oriented spectrum service evaluation. In addition, the unresolved research issues are also presented.",TOPIC
10.1109/ACCESS.2016.2613122,Route Selection for Multi-Hop Cognitive Radio Networks Using Reinforcement Learning: An Experimental Study,"Cognitive radio (CR) enables unlicensed users to explore and exploit underutilized licensed channels (or white spaces). While multi-hop CR network has drawn significant research interest in recent years, majority work has been validated through simulation. A key challenge in multi-hop CR network is to select a route with high quality of service (QoS) and lesser number of route breakages. In this paper, we propose three route selection schemes to enhance the network performance of CR networks, and investigate them using a real testbed environment, which consists of universal software radio peripheral and GNU radio units. Two schemes are based on reinforcement learning (RL), while a scheme is based on spectrum leasing (SL). RL is an artificial intelligence technique, whereas SL is a new paradigm that allows communication between licensed and unlicensed users in CR networks. We compare the route selection schemes with an existing route selection scheme in the literature, called highest-channel (HC), in a multi-hop CR network. With respect to the QoS parameters (i.e., throughput, packet delivery ratio, and the number of route breakages), the experimental results show that RL approaches achieve a better performance in comparison with the HC approach, and also achieve close to the performance achieved by the SL approach.",TOPIC
10.1109/ACCESS.2017.2777438,Trustworthiness Modeling and Analysis of Cyber-physical Manufacturing Systems,"Cyber-physical manufacturing systems (CPMSs) are a new paradigm of manufacturing systems that integrate cyber systems and physical systems to aid smart manufacturing. CPMSs can improve the system's flexibility and productivity and adapt to new market demands. However, CPMSs are susceptible to cyber-attacks, which can modify manufacturing intents to produce parts incorrectly and cause hazards to equipment, employees, and consumers. Therefore, the trustworthiness of CPMSs is critical to the entire systems. In order to describe and analyze the trustworthiness of CPMSs, generalized stochastic Petri nets are adopted to model CPMSs and the trustworthiness is measured from three metrics, i.e., the reliability, availability and security. To study the trustworthiness evolution of CPMSs, a malicious software spreading dynamics model is presented, and its dynamic behaviors are analyzed. Finally, the CPMS trustworthiness evolution model is constructed depending on the proposed dynamics model. The simulation results demonstrate that the proposed approach is effective to model and analyze the CPMS trustworthiness.",TOPIC
10.1109/ACCESS.2018.2868236,IEEE Access,"This paper presents a novel scalable algorithm, Gradient Population Optimization (GPO), which is specifically designed to optimize cost functions with extremely high dimensionality. GPO uses the Tensorflow platform, a non-von-Neumann computation model, which implements dataflow graphs on heterogeneous computing hardware (e.g., multi-core central processing unit, graphics processing unit (GPU), and field-programmable gate array) in order to perform massively parallel processing tasks on scalable platforms, such as the cloud. GPO is based on the combination of population-based dynamics with gradient-based determinism, in which a coupling term is introduced between the local and global corrections to the positions of population's agents' positions. The GPO exhibited excellent performance in most of the standard benchmark functions that were tested. In particular, GPO demonstrated superb scalability in solving large-scale optimization problems using GPU-hardware-accelerated computing platform, positing the algorithm as an effective strategy for real-life massive scale problems, such as machine learning, data mining, and modeling wireless communication systems, such as 5G and massive MIMO. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ACCESS.2018.2889999,QoE-Oriented Rate Adaptation for DASH With Enhanced Deep Q-Learning,"With the popularity of handheld devices, the development of wireless communication technology and the proliferation of multimedia resources, mobile video has become the main business in LTE networks with explosive traffic demands. How to improve the quality of experience (QoE) of mobile video in the dynamic and complex network environment has become a research focus. Dynamic adaptive streaming over HTTP technology introduces adaptive bitrate (ABR) requests at the client side to improve video QoE and various rate adaptation algorithms are also constantly proposed. In view of the limitations of the existing heuristic or learning-based ABR methods, we propose redirecting enhanced Deep Q-learning toward DASH video QoE (RDQ), a QoE-oriented rate adaptation framework based on enhanced deep Q-learning. First, we establish a chunkwise subjective QoE model and utilize it as the reward function in reinforcement learning so that the strategy can converge toward the direction of maximizing the subjective QoE score. Then, we apply several effective improvements of deep Q-learning to the RDQ agent’s neural network architecture and learning mechanism to achieve faster convergence and higher average reward than other learning-based methods. The proposed RDQ agent has been thoroughly evaluated using trace-based simulation on the real-time LTE network data. For disparate network scenarios and different video contents, the RDQ agent can outperform the existing methods in terms of the QoE score. The breakdown analysis shows that RDQ can suppress the number and the duration of the stalling events to the minimum while maintaining high video bitrate, thus achieving better QoE performance than other methods.",TOPIC
10.1109/ACCESS.2019.2894345,Simulation of the Separating Crowd Behavior in a T-Shaped Channel Based on the Social Force Model,"The separating behavior defines the division of a crowd from a single flow into two distributary flows due to the different pedestrians' destinations. Nevertheless, in the existing literature on pedestrian flow, there is a lack of simulation research on the separating crowd behavior in a T-shaped channel. By conducting a series of controlled experiments, we analyzed the moving trajectories and the spatial and temporal distribution characteristics of pedestrians in the separation process. Based on an analysis of the controlled experiments, we proposed an improved social force model that fully considers the characteristics of pedestrians' swapping locations, and refines the directions of pedestrians' expected speeds in three stages of the pedestrian separation process. During the simulation, we applied the improved model to explore the effects of the pedestrians' swapping locations on the macroscopic phenomena, microscopic individual behavior, and traffic efficiency within a T-shaped channel. The simulation results show that if pedestrians' swapping locations are concentrated in a certain area close to the entrance, the traffic efficiency in the T-shaped channel will be higher than that if the pedestrians' swapping locations are dispersed. Moreover, as the flow rate at the entrance increases, the swapping location becomes more concentrated closer to the entrance, the mean speed increases, and fewer conflicts occur between the pedestrians.",TOPIC
10.1109/ACCESS.2019.2924255,IEEE Access,"We proposed a method of label-free segmentation of cell nuclei by exploiting a deep learning (DL) framework. Over the years, fluorescent proteins and staining agents have been widely used to identify cell nuclei. However, the use of exogenous agents inevitably prevents from long-term imaging of live cells and rapid analysis and even interferes with intrinsic physiological conditions. Without any agents, the proposed method was applied to label-free optical diffraction tomography (ODT) of human breast cancer cells. A novel architecture with optimized training strategies was validated through cross-modality and cross-laboratory experiments. The nucleus volumes from the DL-based label-free ODT segmentation accurately agreed with those from fluorescent-based. Furthermore, the 4D cell nucleus segmentation was successfully performed for the time-lapse ODT images. The proposed method would bring out broad and immediate biomedical applications with our framework publicly available. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ACCESS.2019.2935545,Resource Allocation in Information-Centric Wireless Networking With D2D-Enabled MEC: A Deep Reinforcement Learning Approach,"Recently, information-centric wireless networks (ICWNs) have become a promising Internet architecture of the next generation, which allows network nodes to have computing and caching capabilities and adapt to the growing mobile data traffic in 5G high-speed communication networks. However, the design of ICWN is still faced with various challenges with respect to capacity and traffic. Therefore, mobile edge computing (MEC) and device-to-device (D2D) communications can be employed to aid offloading the core networks. This paper investigates the optimal policy for resource allocation in ICWNs by maximizing the spectrum efficiency and system capacity of the overall network. Due to unknown and stochastic properties of the wireless channel environment, this problem was modeled as a Markov decision process. In continuous-valued state and action variables, the policy gradient approach was employed to learn the optimal policy through interactions with the environment. We first recognized the communication mode according to the location of the cached content, considering whether it is D2D mode or cellular mode. Then, we adopt the Gaussian distribution as the parameterization strategy to generate continuous stochastic actions to select power. In addition, we use softmax to output channel selection to maximize system capacity and spectrum efficiency while avoiding interference to cellular users. The numerical experiments show that our learning method performs well in a D2D-enabled MEC system.",TOPIC
10.1109/ACCESS.2019.2940445,Flow Splitter: A Deep Reinforcement Learning-Based Flow Scheduler for Hybrid Optical-Electrical Data Center Network,"Hybrid optical-electrical switching based data center network (HOE-DCN) has been regarded as a promising architecture for the next generation data center network (DCN). To achieve traffic optimization, the main superiority of HOE-DCN is its capability to offload the long-lived `elephant' flows by optical interconnections, and transmit the latency-sensitive `mice' flows by electrical switching. However, most previous works identify and schedule the flows according to a fixed flow size threshold, which can hardly handle the highly dynamic network conditions in recent DCN. In order to achieve more effective flow scheduling in HOE-DCN, in this paper, we propose Flow Splitter (FS), a deep reinforcement learning (DRL) based flow scheduler which enables HOE-DCN to make instant flow scheduling according to the runtime network conditions. To train a more effective DRL agent, we upgrade the DRL method named Deep Deterministic Policy Gradient (DDPG) and propose DDPG-FS, which is capable of learning a high-performance flow scheduling policy in the complex network environment. Through simulation, we prove that our FS can significantly improve the performance of HOE-DCN. Compared with the recent flow scheduling approaches for HOE-DCN, our FS can obviously reduce the average flow complete time of arrival flows, especially the latency-sensitive mice flows.",TOPIC
10.1109/ACCESS.2019.2940767,Sample and Structure-Guided Network for Road Crack Detection,"As an indispensable task for traffic management department, road maintenance has attracted much attention during the last decade due to the rapid development of traffic network. As is known, crack is the early form of many road damages, and repair it in time can significantly save the maintenance cost. In this case, how to detect crack regions quickly and accurately becomes a huge demand. Actually, many image processing technique based methods have been proposed for crack detection, but their performances can not meet our expectations. The reason is that, most of these methods use bottom features such as color and texture to detect the cracks, which are easily influenced by the varied conditions such as light and shadow. Inspired by the great successes of machine learning and artificial intelligence, this paper presents a sample and structure guided network for detecting road cracks. Specifically, the proposed network is based on U-Net architecture, which remains the details from input to output by using skip connection strategy. Then, because the scale of crack samples is much smaller than that of non-crack ones, directly using the conventional cross entropy loss can not optimize the network effectively. In this case, the Focal loss is utilized to address the model optimization problem. Additionally, we incorporate the self-attention strategy into the proposed network, which enhances its stability by encoding the 2-order information among different local regions into the final features. Finally, we test the proposed method on four datasets, three public ones with labels and a photographed one without labels, to validate its effectiveness. It is noteworthy that, for the photographed dataset, we design a series of image processing strategies such as contrast enhancement to improve the generalization capability of the proposed method.",TOPIC
10.1109/ACCESS.2019.2943880,A Compact Circularly Polarized MIMO Dielectric Resonator Antenna Over Electromagnetic Band-Gap Surface for 5G Applications,"We present a wideband circularly polarized (CP) multiple-input multiple-output (MIMO) dielectric resonator antenna (DRA) with enhanced diversity. In the DRA element, two diagonal edges of the DR were truncated at 45° to obtain a wider axial ratio larger than 0.65 GHz. The DRA element was excited by a cross-ring slot with specific slot-arm ratio through microstrip-line (MSTL) implemented at the backside of the FR4 substrate to generate CP fields. Small triangular stands at the edge of the DR were employed to hold it in place to avoid any degradation from the uncontrollable bonding agent used for attaching DR onto the FR4 substrate. The DRA achieved an impedance bandwidth better than 0.8 GHz with an antenna gain of 4.83 dBi. Using the DRA with the MSTL feed, two-element CP-DRA array was implemented with electromagnetic band-gap (EBG) structure etched onto the ground plane of the MSTL. The proposed architecture achieves isolation better than 26 dB over the desired frequency band without any performance degradation while maintaining its compact size in the array. Various diversity analysis was carried out on the implemented circularly polarized MIMO DRA. The measured results demonstrated that the proposed singly fed DRA with EBG on the ground plate is suitable for implementing wideband circular polarized MIMO antennas in a compact size.",TOPIC
10.1109/ACCESS.2019.2947699,Urban Traffic Routing Using Weighted Multi-Map Strategies,"Urban traffic routing has to deal with individual mobility and collective wellness considering citizens, multi-modal transport, and fleet traffic with conflicting interests such as electric vehicles, local distribution, public transport, and private vehicles. Different interests, goals, and regulations, suggest the development of new multi-objective routing mechanisms which may improve traffic flow. In this work, Traffic Weighted Multi-Maps (TWM) is presented as a novel traffic routing mechanism based on the strategical generation and distribution of complementary cost maps for traffic fleets, oriented towards the application of differentiated traffic planning and control policies. TWM is built upon a centralized control architecture, where a Traffic Management Center generates and distributes customized cost maps of the road network. These maps are used individually to calculate routes. In this research, we present the TWM theoretical model and experimental results based on microscopic simulations over a real city traffic network under multiple scenarios, including traffic incidents management. Experimental evaluation takes into account driver's adherence to the system and considers a multi-objective analysis both for the global network parameters (congestion, travel time, and route length) and for the subjective driving experience. Experimental results deliver performance improvements from 20% to 50%. TWM is fully compatible with existing traffic routing systems and has promising future evolution applying new algorithms, policies and network profiles.",TOPIC
10.1109/ACCESS.2019.2952242,A Real-Time Software Defined Networking Framework for Next-Generation Industrial Networks,"Industry 4.0 brings in a whole set of new requirements to engineering industrial systems, with notorious impact at the networking layer. A key challenge posed by Industry 4.0 is the operational flexibility needed to support on-the-fly reconfiguration of production cells, stations, and machines. At the networking layer, this flexibility implies dynamic packet handling, scheduling, and dispatching. SoftwareDefined Networking (SDN) provides this level of flexibility in the general Local Area Network (LAN) domain. However, its application in the industry has been hindered by a lack of support for real-time services. This paper addresses this limitation, proposing an extended SDN OpenFlow framework that includes realtime services, leveraging existing real-time data plane Ethernet technologies. We show the OpenFlow enhancements, a real-time SDN controller, and experimental validation and performance assessment. Using a proof-of-concept prototype with 3 switches and cycles of 250μs, we could achieve 1μs jitter on timetriggered traffic and a reconfiguration time between operational modes below 10ms.",TOPIC
10.1109/ACCESS.2019.2957429,Feature Selection for Malware Detection Based on Reinforcement Learning,"Machine learning based malware detection has been proved great success in the past few years. Most of the conventional methods are based on supervised learning, which relies on static features with labels. While selecting static features requires both human expertise and labor. New selections, which fix features from a wide range, are handcrafted by careful manual experimentation or modified from existing methods. Despite their success, the static features are still hard to be determined. In this paper, a Deep Q-learning based Feature Selection Architecture (DQFSA) is introduced to cover the deficiencies of traditional methods. The proposed architecture automatically selects a small set of highly differentiated features for malware detection task without human intervention. DQFSA trains an agent through Q-learning to maximize the expected accuracy of the classifiers on a validation dataset by sequentially interacting with the features space. The agent, based on an  $\epsilon $ -greedy exploration strategy and experience replay, explores a large but finite space of possible actions and iteratively discovers selections with improved performance on the learning task. Actions are a set of reasonable choices, which indicate whether a feature is chosen or not. Extensive experimental results indicate that the proposed DQFSA outperforms existing baseline approaches for feature selection on malware detection with minimum features, improves the generalization performance of the learning model and reduces human intervention. More specifically, the proposed architecture’s underlying representation is robust enough for re-calibrating models to other domains of information security.",TOPIC
10.1109/ACCESS.2019.2961174,An Efficient Hardware Implementation of Reinforcement Learning: The Q-Learning Algorithm,"In this paper we propose an efficient hardware architecture that implements the Q-Learning algorithm, suitable for real-time applications. Its main features are low-power, high throughput and limited hardware resources. We also propose a technique based on approximated multipliers to reduce the hardware complexity of the algorithm. We implemented the design on a Xilinx Zynq Ultrascale+ MPSoC ZCU106 Evaluation Kit. The implementation results are evaluated in terms of hardware resources, throughput and power consumption. The architecture is compared to the state of the art of Q-Learning hardware accelerators presented in the literature obtaining better results in speed, power and hardware resources. Experiments using different sizes for the Q-Matrix and different wordlengths for the fixed point arithmetic are presented. With a Q-Matrix of size 8 × 4 (8 bit data) we achieved a throughput of 222 MSPS (Mega Samples Per Second) and a dynamic power consumption of 37 mW, while with a Q-Matrix of size 256 × 16 (32 bit data) we achieved a throughput of 93 MSPS and a power consumption 611 mW. Due to the small amount of hardware resources required by the accelerator, our system is suitable for multi-agent IoT applications. Moreover, the architecture can be used to implement the SARSA (State-Action-Reward-StateAction) Reinforcement Learning algorithm with minor modifications.",TOPIC
10.1109/ACCESS.2020.2980298,IEEE Access,"Intelligent Connected Vehicles (ICVs) can provide smart, safe, and efficient transportation services and have attracted intensive attention recently. Obtaining timely and accurate traffic information is one of the most important problems in transportation systems, which would allow people to select fast routes and avoid congestions, thus saving their travel time on the road. Currently, the most popular ways to obtain traffic information is to inquire navigation agents, e.g., Apple map, and Google map. However, these navigation agents are essentially centralized systems, which are vulnerable to service congestions, a single point of failure, and attacks. Furthermore, users' privacy gets compromised as the agents can know their home and work addresses and hence their identities, track them in real-time, etc. In this paper, we propose TrafficChain, a secure and privacy-preserving decentralized traffic information collection system on the blockchain, by taking advantage of fog/edge computing infrastructure. In particular, we employ a two-layer blockchain architecture in TrafficChain to improve system efficiency, design a privacy-preserving scheme to protect users' identities and travel traces, and devise LSTM based deep learning mechanisms that can defend against Byzantine attacks and Sybil attacks in our system. Furthermore, an incentive mechanism is designed to motivate users to participate in the system. Simulation results show that TrafficChain works very efficiently and is resilient to both Byzantine attacks and Sybil attacks. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ACCESS.2020.2983300,IEEE Access,"The private insurance sector is recognized as one of the fastest-growing industries. This rapid growth has fueled incredible transformations over the past decade. Nowadays, there exist insurance products for most high-value assets such as vehicles, jewellery, health/life, and homes. Insurance companies are at the forefront in adopting cutting-edge operations, processes, and mathematical models to maximize profit whilst servicing their customers claims. Traditional methods that are exclusively based on human-in-the-loop models are very time-consuming and inaccurate. In this paper, we develop a secure and automated insurance system framework that reduces human interaction, secures the insurance activities, alerts and informs about risky customers, detects fraudulent claims, and reduces monetary loss for the insurance sector. After presenting the blockchain-based framework to enable secure transactions and data sharing among different interacting agents within the insurance network, we propose to employ the extreme gradient boosting (XGBoost) machine learning algorithm for the aforementioned insurance services and compare its performances with those of other state-of-the-art algorithms. The obtained results reveal that, when applied to an auto insurance dataset, the XGboost achieves high performance gains compared to other existing learning algorithms. For instance, it reaches 7% higher accuracy compared to decision tree models when detecting fraudulent claims. The obtained results reveal that, when applied to an auto insurance dataset, the XGboost achieves high performance gains compared to other existing learning algorithms. For instance, it reaches 7% higher accuracy compared to decision tree models when detecting fraudulent claims. Furthermore, we propose an online learning solution to automatically deal with real-time updates of the insurance network and we show that it outperforms another online state-of-the-art algorithm. Finally, we combine the developed machine learning modules with the hyperledger fabric composer to implement and emulate the artificial intelligence and blockchain-based framework. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ACCESS.2020.2984130,Automatic DenseNet Sparsification,"As a classic and well-performed deep convolutional neural network, DenseNet links every layer to each of its preceding layers via skip connections. However, the dense connectivity of the links leads to much redundance, consuming lots of computational resources. In this paper, to automatically prune redundant skip connections in DenseNet, we introduce a novel reinforcement learning method called automatic DenseNet sparsification (ADS). In ADS, we use adjacent matrix to represent dense connections in DenseNet, and design an agent using recurrent neural networks (RNNs) to sparsify the matrix, i. e. removing redundant skip connections in DenseNet. The validation accuracies of the sparsified DenseNets are used as rewards to update the agent, which promotes the agent to generate sparsified DenseNets with high performance. Extensive experiments demonstrate the effectiveness of ADS: The performance of the sparsified DenseNet surpasses not only the original DenseNet but related models; Moreover, the sparsified DenseNet has strong transferability when it is applied to new tasks. More importantly, ADS is very efficient. For the compression of a 40-layer DenseNet, it takes less than 1 day on a single GPU.",TOPIC
10.1109/ACCESS.2020.2985498,A Novel Ant Colony Optimization Algorithm With Levy Flight,"Ant Colony Optimization (ACO) is a widely applied meta-heuristic algorithm. Little researches focused on the candidate selection mechanism, which was developed based on the simple uniform distribution. This paper employs the Levy flight mechanism based on Levy distribution to the candidate selection process and takes advantage of Levy flight that not only guarantees the search speed but also extends the searching space to improve the performance of ACO. Levy ACO incorporating with Levy flight developed on the top of Max-min ACO. According to the computational experiments, the performance of Levy ACO is significantly better than the original Max-min ACO and some latest Traveling Salesman Problem (TSP) solvers.",TOPIC
10.1109/ACCESS.2020.2986132,IEEE Access,"A software-defined networking (SDN) architecture is capable of integrating all radio frequency and optical wireless small cell networks (e.g. fifth generation (5G), long-term evolution (LTE) femtocell, wireless fidelity (WiFi), light fidelity (LiFi)) in one network domain. This paper considers a SDN-enabled heterogeneous network (HetNet) comprised of LiFi, LTE femtocell and WiFi access points (APs). The HetNet control plane maintains the state of the network topology and wireless resources, which can support the development of intelligent service provisioning and efficient data communications in x generation (xG) wireless networks. The SDN applications use the network state to provide services in the data plane. However, when the state of network and wireless resources constantly changes, the SDN applications cannot provide reliable and guaranteed services to the wireless user equipments. This paper develops a queuing theoretic framework, which provides a performance evaluation for the SDN-enabled HetNet and applications convergence. A traffic engineering (TE) scheme is developed to support dynamic agnostic downlink flows routing to APs and differentiated granular services across the HetNet. Network and user centric policies are developed to make applications aware of network resource availability on the northbound and southbound interfaces of a SDN controller. Numerical models are introduced to study the impact of the computation and communication resources of northbound and southbound interfaces on the SDN-enabled HetNet scalability and the quality-of-service (QoS) guarantee of applications. Also, simulation scenarios are conducted to evaluate the performance of the TE scheme in provisioning effective and reliable services for subscribers. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ACCESS.2020.2987324,Driven by Data or Derived Through Physics? A Review of Hybrid Physics Guided Machine Learning Techniques With Cyber-Physical System (CPS) Focus,"A multitude of cyber-physical system (CPS) applications, including design, control, diagnosis, prognostics, and a host of other problems, are predicated on the assumption of model availability. There are mainly two approaches to modeling: Physics/Equation based modeling (Model-Based, MB) and Machine Learning (ML). Recently, there is a growing consensus that ML methodologies relying on data need to be coupled with prior scientific knowledge (or physics, MB) for modeling CPS. We refer to the paradigm that combines MB approaches with ML as hybrid learning methods. Hybrid modeling (HB) methods is a growing field within both the ML and scientific communities, and are recognized as an important emerging but nascent area of research. Recently, several works have attempted to merge MB and ML models for the complete exploitation of their combined potential. However, the research literature is scattered and unorganized. So, we make a meticulous and systematic attempt at organizing and standardizing the methods of combining ML and MB models. In addition to that, we outline five metrics for the comprehensive evaluation of hybrid models. Finally, we conclude by shedding some light on the challenges of hybrid models, which we, as a research community, should focus on for harnessing the full potential of hybrid models. An additional feature of this survey is that the hybrid modeling work has been discussed with a focus on modeling cyber-physical systems.",TOPIC
10.1109/ACCESS.2020.2989150,A Spatiotemporal Agent for Robust Multimodal Registration,"Multimodal image registration is a crucial step for a variety of medical applications to provide complementary information from the combination of various data sources. Conventional image registration methods aim at finding a suited similarity metric as well as a descriptive image feature, which is quite challenging due to the high diversity of tissue appearance across modalities. In this paper, we present a novel approach to register images via an asynchronously trained reinforcement learning agent automatically. Within this approach, convolutional gated recurrent units (ConvGRU) is incorporated after stacked convolutional layers to extract both spatial and temporal features of the neighboring frames and implicitly learn the similarity metric. Moreover, we propose a customized reward function driven by fixed points error (FPE) to guide the agent to the correct registration direction. A Monte Carlo rollout strategy is also leveraged to perform a look-ahead inference to the elimination of jitter in the test stage. Evaluation is performed on paired CT and MR images from patients diagnosed as nasopharyngeal carcinoma. The results demonstrate that our method achieves state-of-the-art performance in medical image registration.",TOPIC
10.1109/ACCESS.2020.2992853,Energy-Efficient IoT Sensor Calibration With Deep Reinforcement Learning,"The modern development of ultra-durable and energy-efficient IoT based communication sensors has much application in modern telecommunication and networking sectors. Sensor calibration to reduce power usage is beneficial to minimizing energy consumption in sensors as well as improve the efficiency of devices. Reinforcement learning (RL) has been received much attention from researchers and now widely applied in many study fields to achieve intelligent automation. Though various types of sensors have been widely used in the field of IoT, rare researches were conducted in resource optimizing. In this novel research, a new style of power conservation has been explored with the help of RL to make a new generation of IoT devices with calibrated power sources to maximize resource utilization. A closed grid multiple power source based control for sensor resource utilization has been introduced. Our proposed model using Deep Q learning (DQN) enables IoT sensors to maximize its resource utilization. This research focuses solely on the energy-efficient sensor calibration and simulation results show promising performance of the proposed method.",TOPIC
10.1109/ACCESS.2020.3011015,Neighbor Cell List Optimization in Handover Management Using Cascading Bandits Algorithm,"Frequent handover is a key challenge in 5G Ultra-Dense Networks (UDN). In this paper, we show the significance of configuring Neighbor Cell List (NCL) in handover procedure. To cope with the high dynamic of UDN, we propose an online-learning method, namely the Cost-aware Cascading Bandits NCL configuration (CCB-NCL) algorithm, which applies the cascading model and Multi-Armed Bandits (MAB) theory to configure the efficient Neighbor Cell List (eNCL) and improves the handover performance by assisting the User Equipment (UE) to choose the optimal target Base Station (BS). We provide rigorous proof of regret bound to show the asymptotic convergence of the proposed CCB-NCL algorithm. The robustness and efficiency of the proposed algorithm are both demonstrated in different network scenarios, where varies BS densities, BS dynamic and network heterogeneity are considered respectively. In the simulation work, we reproduce two existing methods of configuring NCL in handover management, named dynamic threshold based solution and received signal strength based solution. In comparison with the existing solutions, the proposed algorithm can reduce the overlarge signaling cost and unnecessary delay in the preparation phase of handover procedure by significantly shortening the length of NCLs and reducing the number of scanned BSs. Extensive simulations are conducted in different scenarios to validate the robustness of the proposed algorithm and the results show that the proposed CCB-NCL algorithm is a superior approach to efficient handover management.",TOPIC
10.1109/ACCESS.2020.3011472,Optimization of the Deployment of Relay Nodes in Cellular Networks,"Significant and continuous contributions related to 4G/5G cellular networks are still accelerating the investigation of the approaches that can boost the cell characteristics following the new aspirations of the users. The challenge of achieving sufficient coverage at the cell edge; represents a constant concern for both users and operators; in addition to ensuring a reasonable cost, are the most important search fields and in our scope of interest. As relay nodes can provide a solution, a scenario for a plan of relay nodes deployment at the cell edge is proposed, taking into account the interference due to the relay nodes. Since optimization algorithms are effective in terms of planning, an advanced hybrid particle swarm optimization and gravitational search algorithm (PSOGSA) is applied to the proposed scenario to detect the optimum solution. The optimum solution represents the optimum plan that attains the best coverage with the minimum cost. We submit cost analysis depends on three trails of construction cost, power and channel cost efficiency. To highlight that the optimal plan has been revealed, another recently developed optimization algorithm, a simplified adaptive bat algorithm based on frequency (FSABA) and a classic particle swarm optimization (PSO) algorithm are also applied to the suggested scenario. The obtained results are compared with the related findings of the PSOGSA. From the simulations, it is found that the PSOGSA achieves better performance than the other two algorithms with fruitful and promising results, and the optimal plan featuring great coverage at the cell edge and cost-saving is attained.",TOPIC
10.1109/ACCESS.2020.3019667,Investigating Impacts of Telemedicine on Emergency Department Through Decreasing Non-Urgent Patients in Spain,"In this paper, a new method is presented to study the impacts of telemedicine on the performance of an emergency department in Spain. Spain's Demographics indicate that this country is experiencing population aging, resulting in overcrowding of emergency departments and significant demand on the healthcare system. However, it has been reported that most patients visiting emergency departments are not in an urgent clinical condition, thus they causing hospital overcrowding, high medical expenses, delays in clinical service delivery and low service efficiency for urgent patients who truly need emergency care. Telemedicine and e-health are considered as solutions for remote delivery of health services to care seekers in order to decrease hospital visits for patients who are in less of an emergency condition. In this study, by using detailed computational modeling and clinical data, we have investigated the impacts of telemedicine on the performance of an emergency department through estimations of Length of Stay as a quantitative index for evaluation of quality of service in the emergency department. Specifically, an agent-based modeling and simulation system was developed and used to study the behavior of the emergency department by taking detailed modeling parameters, including varying the number of non-urgent arrivals as a result of telemedicine, into account as inputs of the model. The inputs were provided through collection and analysis of clinical data that enabled us to predict how telemedicine changes emergency department visits. Our results indicated that emergency departments would experience decreases equal to 41.14% in total Length of Stay if eliminating all non-urgent visits and decreases of up to 10.48% if restricting the non-urgent visits. The developed computational tool in this study and the corresponding results obtained can provide decision makers and health care providers with objective information on the impacts of e-health services on the efficiency of emergency department and they can have also implications for care delivery, optimizing resources, planning, and improving the quality of care.",TOPIC
10.1109/ACCESS.2020.3021192,Simulation-Based Evolutionary Optimization of Air Traffic Management,"In the context of aerospace engineering, the optimization of processes may often require to solve multi-objective optimization problems, including mixed variables, multi-modal and non-differentiable quantities, possibly involving highly-expensive objective function evaluations. In Air Traffic Management (ATM), the optimization of procedures and protocols becomes even more complicated, due to the involvement of human controllers, which act as final decision points in the control chain. In this article, we propose the use of computational intelligence techniques, such as Agent-Based Modelling and Simulation (ABMS) and Evolutionary Computing (EC), to design a simulation-based distributed architecture to optimize control plans and procedures in the context of ATM. We rely on Agent-Based fast-time simulations to carry out offline what-if analysis of multiple scenarios, also taking into account human-related decisions, during the strategic or pre-tactical phases. The scenarios are constructed using real-world traffic data traces, while multiple optimization variables governed by an EC algorithm allow to explore the search space to identify the best solutions. Our optimization approach relies on ad-hoc multi-objective performance metrics which allow to assess the goodness of the control of aircraft and air traffic regulations. We present experimental results which prove the viability of our approach, comparing them with real-world data traces, and proving their meaningfulness from an Air Traffic Control perspective.",TOPIC
10.1109/ACCESS.2020.3022842,"IoT Vulnerability Assessment for Sustainable Computing: Threats, Current Solutions, and Open Challenges","Over the last few decades, sustainable computing has been widely used in areas like social computing, artificial intelligence-based agent systems, mobile computing, and Internet of Things (IoT). There are social, economic, and commercial impacts of IoT on human lives. However, IoT nodes are generally power-constrained with data transmission using an open channel, i.e., Internet which opens the gates for various types of attacks on them. In this context, several efforts are initiated to deal with the evolving security issues in IoT systems and make them self-sufficient to harvest energy for smooth functioning. Motivated by these facts, in this paper, we explore the evolving vulnerabilities in IoT devices. We provide a state-of-the-art survey that addresses multiple dimensions of the IoT realm. Moreover, we provide a general overview of IoT, Sustainable IoT, its architecture, and the Internet Engineering Task Force (IETF) protocol suite. Subsequently, we explore the open-source tools and datasets for the proliferation in research and growth of IoT. A detailed taxonomy of attacks associated with various vulnerabilities is also presented in the text. Then we have specifically focused on the IoT Vulnerability Assessment techniques followed by a case study on sustainability of Smart Agriculture. Finally, this paper outlines the emerging challenges related to IoT and its sustainability, and opening the doors for the beginners to start research in this promising area.",TOPIC
10.1109/ACCESS.2020.3028241,A Hybrid Meta-Heuristic Feature Selection Method for Identification of Indian Spoken Languages From Audio Signals,"With the recent advancements in the fields of machine learning and artificial intelligence, spoken language identification-based applications have been increasing in terms of the impact they have on the day-to-day lives of common people. Western countries have been enjoying the privilege of spoken language recognition-based applications for a while now, however, they have not gained much popularity in multi-lingual countries like India owing to various complexities. In this paper, we have addressed this issue by attempting to identify different Indian languages based on various well-known features like Mel-Frequency Cepstral Coefficient (MFCC), Linear Prediction Coefficient (LPC), Discrete Wavelet Transform (DWT), Gammatone Frequency Cepstral Coefficient (GFCC) as well as a few deep learning architecture based features like i-vector and x-vector extracted from the audio signals. After comparing the initial results, it is observed that the combination of MFCC and LPC produces the best results. Then we have developed a new nature-inspired feature selection (FS) algorithm by hybridizing Binary Bat Algorithm (BBA) with Late Acceptance Hill-Climbing (LAHC) to select the optimal subset from the said feature vectors in order to reduce the model complexity and help it train faster. Using Random Forest (RF) classifier, we have achieved an accuracy of 92.35% on Indic TTS database developed by IIT-Madras, and an accuracy of 100% on the Indic Speech database developed by the Speech and Vision Laboratory (SVL) IIIT-Hyderabad. The proposed algorithm is also found to outperform many standard meta-heuristic FS algorithms. The source code of this work is available at: https://github.com/CodeChef97dotcom/Feature-Selection.",TOPIC
10.1109/ACCESS.2020.3034217,StomachNet: Optimal Deep Learning Features Fusion for Stomach Abnormalities Classification,"A fully automated design is proposed in this work employing optimal deep learning features for classifying gastrointestinal infections. Here, three prominent infections– ulcer, bleeding, polyp and a healthy class are considered as class labels. In the initial stage, the contrast is improved by fusing bi-directional histogram equalization with top-hat filtering output. The resultant fusion images are then passed to ResNet101 pre-trained model and trained once again using deep transfer learning. However, there are challenges involved in extracting deep learning features including impertinent information and redundancy. To mitigate this problem, we took advantage of two metaheuristic algorithms– Enhanced Crow Search and Differential Evolution. These algorithms are implemented in parallel to obtain optimal feature vectors. Following this, a maximum correlation-based fusion approach is applied to fuse optimal vectors from the previous step to obtain an enhanced vector. This final vector is given as input to Extreme Learning Machine (ELM) classifier for final classification. The proposed method is evaluated on a combined database. It accomplished an accuracy of 99.46%, which shows significant improvement over preceding techniques and other neural network architectures.",TOPIC
10.1109/ACCESS.2020.3037276,Exploring and Exploiting Conditioning of Reinforcement Learning Agents,"The outcome of Jacobian singular values regularization was studied for supervised learning problems. In supervised learning settings for linear and nonlinear networks, Jacobian regularization allows for faster learning. It also was shown that Jacobian conditioning regularization can help to avoid the “mode-collapse” problem in Generative Adversarial Networks. In this paper, we try to answer the following question: Can information about policy network Jacobian conditioning help to shape a more stable and general policy of reinforcement learning agents? To answer this question, we conduct a study of Jacobian conditioning behavior during policy optimization. We analyze the behavior of the agent conditioning on different policies under the different sets of hyperparameters and study a correspondence between the conditioning and the ratio of achieved rewards. Based on these observations, we propose a conditioning regularization technique. We apply it to Trust Region Policy Optimization and Proximal Policy Optimization (PPO) algorithms and compare their performance on 8 continuous control tasks. Models with the proposed regularization outperformed other models on most of the tasks. Also, we showed that the regularization improves the agent’s generalization by comparing the PPO performance on CoinRun environments. Also, we propose an algorithm that uses the condition number of the agent to form a robust policy, which we call Jacobian Policy Optimization (JPO). It directly estimates the condition number of an agent’s Jacobian and changes the policy trend. We compare it with PPO on several continuous control tasks in PyBullet environments and the proposed algorithm provides a more stable and efficient reward growth on a range of agents.",TOPIC
10.1109/ACCESS.2020.3037531,A Social Media Based Approach for Route Planning During Urban Events,"Traffic congestion is a major issue in most big cities, resulting in longer travel time and increased greenhouse gas emission. Various factors can cause traffic congestion, and includes not only traffic events on roads (e.g., car accidents) but also urban events (e.g., football games, concerts, and festivals), where a large number of human activities happen in a certain place and at a certain time. The technology of connected vehicles (CV) has provided a crowd-souring platform enabling communication between vehicles and surrounding information share to be more timely and effective. Taking the advantage of that, in this paper we focus on navigation during urban events, and present an approach to find feasible routes avoiding traffic congestion caused by the different types of events. Using 12-month geo-tagged tweets, we create a human activity network to capture certain types of human activities across cities. Based on that, an event estimation algorithm is developed to find the possible events that would occur in the near future, and to estimate their probabilities. These detected events are represented in the form of obstacle polygons with timestamps, and are used by the routing algorithm to generate congestion avoidance routes. We apply our approach to the road network of Toronto, Ontario, Canada, and the experimental results show the capability of our approach in supporting routing during urban events.",TOPIC
10.1109/ACCESS.2020.3039512,Converging Technologies for Safety Planning and Inspection Information System of Portable Firefighting Equipment,"Many construction workers are getting injured or killed in fires and explosion accidents each year. The workers are prone to severe fatal accidents due to unavailability of permanent firefighting system in many construction sites, thus they typically rely on portable firefighting equipment (PFE) to minimize fire damage. Many occupational health and safety agencies have developed safety regulations for PFE installation and monitoring in construction. However, in the traditional construction fire safety management process, the installation spots for PFE's are visually identified in a 2D floor plan and then top-down supervisory approach is used to inspect the active availability of the PFE's. Such manually operated conventional methods of PFE installation and monitoring are expensive, prone to manipulation, and do not provide sufficient motivation for voluntarily following fire safety policies. Therefore, this research study develops a fire safety rule-based PFE installation approach and proposes an alternative method for shifting the top-down inspection approach to the bottom-up voluntarily approach for convenient, transparent, and automated safety inspection information delivery. To validate the bottom-up approach concept, a visual language algorithm is initially developed for PFE installation planning system (PFE-IPS) in BIM, followed by an optical character recognition (OCR) and blockchain -based android application for safety inspection information system (SIIS). This article also presents two case studies to evaluate the feasibility and practicality of the developed systems. The proposed approach out-turn reduces the safety manager's manual efforts and burdens of government safety auditors while enhancing efficiency and reliability.",TOPIC
10.1109/ACCESS.2020.3042994,A Biologically Constrained Cerebellar Model With Reinforcement Learning for Robotic Limb Control,"The cerebellum is known to be critical for accurate adaptive control and motor learning. It has long been recognized that the cerebellum acts as a supervised learning machine. However, recent evidence shows that cerebellum is integral to reinforcement learning. This paper proposes a biologically plausible cerebellar model with reinforcement learning based on the cerebellar neural circuitry to eliminate the need for explicit teacher signals. The learning capacity of cerebellar reinforcement learning is first demonstrated by constructing a simulated cerebellar neural network agent and a detailed model of the human arm and muscle system in the Emergent virtual environment. Next, the cerebellar model is incorporated in both a simulated arm and a Geomagic Touch device to further verify the effectiveness of the cerebellar model in reaching tasks. Results from these experiments indicate that the cerebellar simulation is capable of driving the “arm plant” to arrive at the target positions accurately. Moreover, by examining the effect of the number of basic units, we find the results are consistent with previous findings that the central nervous system may recruit the muscle synergies to realize motor control. The study described here prompts several hypotheses about the relationship between motor control and learning and may be useful in the development of general-purpose motor learning systems for machines.",TOPIC
10.1109/ACCESS.2020.3048104,Designing RBFNs Structure Using Similarity-Based and Kernel-Based Fuzzy C-Means Clustering Algorithms,"The RBF networks belong to a set of artificial neural network architectures. RBF networks have been successfully applied for solving various data mining tasks including classification, and regression. Successful implementation of the RBF network depends on numerous factors among which, the crucial is its structure. The decision on the network structure has to be taken at the network initialization stage. It requires calculating or inducing the number of centroids, and their respective locations. The above problem is known to be NP-hard, and hence, not easily solvable. The traditional approach for deciding on the number of hidden units is based on applying the k-means algorithm for calculating cluster centroids. Unfortunately, the procedure guarantees neither a satisfactory accuracy nor the required generalization level of the RBF network under development. To alleviate the problem for cluster determination, i.e. number of centroids, we propose the similarity-based algorithm (SCA) for the RBF networks initialization, as well as an alternative method for initializing RBFNs using the kernel-based fuzzy clustering algorithm (KFCM-K). In both cases, the number of resulting centroids and their initial locations are provided automatically. The next step involves applying the optimization procedure resulting in the selection of the final centroids' location. The procedure is integrated with the output weights determination. Since the discussed optimization problem is computationally difficult it has been decided to apply the agent-based population learning algorithm (PLA) which belongs to the class of metaheuristics. A comparative study of approaches based on SCA and KFCM-K is included in the paper. Their effectiveness is demonstrated experimentally using artificial and real benchmark datasets. The results of the computational experiment have shown that both proposed approaches for designing RBFNs perform significantly better than other algorithms used for this task.",TOPIC
10.1109/ACCESS.2021.3054420,Multi-Level Resource Sharing Framework Using Collaborative Fog Environment for Smart Cities,"Fog computing has proved its importance over legacy cloud architectures for computation, storage, and communication where edge devices are used to facilitate the delay-sensitive applications. The inception of fog nodes has brought computing intelligence close to the end-devices. Many fog computing frameworks have been proposed where edge devices are used for computation. In this paper, we proposed a simulation framework for fog devices that can use end devices to handle the peak computation load to provide better Quality of Services (QoS). The regional fog nodes are deployed at network edge locations which are used as an intelligent agent to handle the computation requests by either scheduling them on local servers, cloud data centers, or at the under-utilized end-user devices. The proposed device-to-device resource sharing model relies on Ant Colony Optimization (ACO) and Earliest Deadline First(EDF) Algorithm to provide a better quality of service using device available at multi-layer design. The concept of using IoT devices as fog nodes has improved the performance of legacy fog based systems. The proposed work is benchmarked in terms of system cost, efficiency, energy, and quality of service. Further, the proposed framework is with xFogSim in terms of task efficiency.",TOPIC
10.1109/ACCESS.2021.3062493,DeepKneeExplainer: Explainable Knee Osteoarthritis Diagnosis From Radiographs and Magnetic Resonance Imaging,"Osteoarthritis (OA) is a degenerative joint disease, which significantly affects middle-aged and elderly people. Although primarily identified via hyaline cartilage change based on medical images, technical bottlenecks like noise, artifacts, and modality impose an enormous challenge on high-precision, objective, and efficient early quantification of OA. Owing to recent advancements, approaches based on neural networks (DNNs) have shown outstanding success in this application domain. However, due to nested non-linear and complex structures, DNNs are mostly opaque and perceived as black-box methods, which raises numerous legal and ethical concerns. Moreover, these approaches do not have the ability to provide the reasoning behind diagnosis decisions in the way humans would do, which poses an additional risk in the clinical setting. In this paper, we propose a novel explainable method for knee OA diagnosis based on radiographs and magnetic resonance imaging (MRI), which we called DeepKneeExplainer. First, we comprehensively preprocess MRIs and radiographs through the deep-stacked transformation technique against possible noises and artifacts that could contain unseen images for domain generalization. Then, we extract the region of interests (ROIs) by employing U-Net architecture with ResNet backbone. To classify the cohorts, we train DenseNet and VGG architectures on the extracted ROIs. Finally, we highlight class-discriminating regions using gradient-guided class activation maps (Grad-CAM++) and layer-wise relevance propagation (LRP), followed by providing human-interpretable explanations of the predictions. Comprehensive experiments based on the multicenter osteoarthritis study (MOST) cohorts, our approach yields up to 91% classification accuracy, outperforming comparable state-of-the-art approaches. We hope that our results will encourage medical researchers and developers to adopt explainable methods and DNN-based analytic pipelines towards an increasing acceptance and adoption of AI-assisted applications in the clinical practice for improved knee OA diagnoses.",TOPIC
10.1109/ACCESS.2021.3064799,Teaching Learning-Based Optimization With Evolutionary Binarization Schemes for Tackling Feature Selection Problems,"Machine learning techniques heavily rely on available training data in a data set. Certain features in the data can interfere with the learning process, so it is required to remove irrelevant and redundant features to build a robust training model. As such, several feature selection techniques are usually applied in a pre-processing phase to obtain the most appropriate set of features and improve the overall learning process. In this paper, a new feature selection approach is proposed based on a modified Teaching-Learning-based Optimization (TLBO) combined with four new binarization methods: the Elitist, the Elitist Roulette, the Elitist Tournament, and the Rank-based method. The influence of these binarization methods is studied and compared to other state-of-the-art techniques. The experimental results such as Shapiro-Wilk normality and Wilcoxon ranksum test show that both transfer functions and binarization approaches have a significant influence on the effectiveness of the binary TLBO. The experiments show that choosing a fitting transfer function along with a suitable binarization method has a substantial impact on the exploratory and exploitative potentials of the feature selection technique.",TOPIC
10.1109/ACCESS.2021.3074180,A Survey on Applications of Deep Learning in Cloud Radio Access Network,"The necessity for high-speed and low-latency connectivity of the vast number of mobile users is rising with the immense usage of mobile applications. A cloud radio access network (C-RAN) is a promising framework for next-generation cellular communication, which can satisfy the requirements of significantly increasing data traffic and user demands. In C-RAN, the data processing unit can be centralized and virtualized in data centers and can be shared among distributed base stations. Deep learning (DL) appears to be a feasible approach for facilitating the data processing capability, resource management in the cloud, and predicting dynamic traffic in cellular communication. The convergence of C-RAN and DL is expected to bring new prospects to both interdisciplinary research and industrial applications. In this regard, different approaches have been proposed for DL-based C-RAN in the literature. This article provides a comprehensive survey of the state-of-the-art DL techniques applied in C-RAN. A brief introduction of the C-RAN architecture and DL techniques is given to provide insights into these two emerging technologies. Existing surveys are also discussed to highlight the research gap. The reviewed works are categorized into power consumption optimization, network performance maximization, and QoS maximization based on their optimization objectives. The key ideas of DL applied in the reviewed schemes are also mentioned, and the performance evaluation techniques used in the research are discussed and compared. Lastly, research challenges and open research issues are highlighted to provide future research directions.",TOPIC
10.1109/ACCESS.2021.3082430,A Review on Communication Aspects of Demand Response Management for Future 5G IoT- Based Smart Grids,"In recent power grids, the need for having a two-way flow of information and electricity is crucial. This provides the opportunity for suppliers and customers to better communicate with each other by shifting traditional power grids to smart grids (SGs). In this paper, demand response management (DRM) is investigated as it plays an important role in SGs to prevent blackouts and provide economic and environmental benefits for both end-users and energy providers. In modern power grids, the development of communication networks has enhanced DRM programmes and made the grid smarter. In particular, with progresses in the 5G Internet of Things (IoT), the infrastructure for DRM programmes is improved with fast data transfer, higher reliability, increased security, lower power consumption, and a massive number of connections. Therefore, this paper provides a comprehensive review of potential applications of 5G IoT technologies as well as the computational and analytical algorithms applied for DRM programmes in SGs. The review holistically brings together sensing, communication, and computing (optimization, prediction), areas usually studied in a scattered way. A broad discussion on various DRM programmes in different layers of enhanced 5G IoT based SGs is given, paying particular attention to advances in machine learning (ML) and deep learning (DL) algorithms alongside challenges in security, reliability, and other factors that have a role in SGs’ performance.",TOPIC
10.1109/ACCESS.2021.3085861,Generating Cryptographic S-Boxes Using the Reinforcement Learning,"Substitution boxes (S-boxes) are essential components of many cryptographic primitives. The Dijkstra algorithm, SAT solvers, and heuristic methods have been used to find bitsliced implementations of S-boxes. However, it is difficult to apply these methods for 8-bit S-boxes because of their size. Therefore, to implement these S-boxes so that the countermeasure of side-channel attack can be applied efficiently, using structures such as Feistel, Lai-Massey, and MISTY that can be bitsliced implemented with a small number of nonlinear operations has been widely used. Since S-boxes constructed with structures consist of small S-boxes and have specific designs, there are limitations to their cryptographic security and efficiency. In this paper, we propose a new method for generating S-boxes by stacking bitwise operations from the identity function, an approach that is different from existing methods. This method can be expressed in Markov decision process, and reinforcement learning is a suitable solver for Markov decision process. Our goal is to train this method to an agent through reinforcement learning to generate S-boxes to which the masking scheme, which is a countermeasure of side-channel attack, can be efficiently applied. In particular, our method provided various S-boxes superior or comparable to existing S-boxes. We produced 8-bit S-boxes with differential uniformity 16 (resp. 32) and linearity 128 (resp. 128), generated with nine (resp. eight) nonlinear operations, for the first time. To our best knowledge, this is the first study to construct cryptographic S-Box by incorporating reinforcement learning.",TOPIC
10.1109/ACCESS.2021.3092304,"Energy Management in Smart Buildings and Homes: Current Approaches, a Hypothetical Solution, and Open Issues and Challenges","Energy plays a pivotal role for economic development of a country. A reliable energy source is needed to improve the living standards of people. To achieve such a goal, governments and industries are trying to install a new energy infrastructure called the “Smart Grid”. This helps to manage the electricity generation and distribution in an efficient manner. Buildings and other structures are the biggest consumers of electricity. There is a need to reduce the energy consumption so that the resources can be utilized efficiently. Therefore, in this paper, we give a comprehensive state-of-the-art on various recent techniques and solutions which provide energy savings in smart homes and buildings. This includes statistical models, cloud computing based solutions, fog computing and smart metering based architectures, and several other IoT (internet of things) inspired solutions. We also present a hypothetical model that treats energy supply and usage in buildings as a self-managing energy system (SES). This paper is concluded by highlighting several open issues and challenges related to energy management in buildings.",TOPIC
10.1109/ACCESS.2021.3101975,Exploring Neural Architecture Search Space via Deep Deterministic Sampling,"Recent developments in Neural Architecture Search (NAS) resort to training the supernet of a predefined search space with weight sharing to speed up architecture evaluation. These include random search schemes, as well as various schemes based on optimization or reinforcement learning, in particular policy gradient, that aim to optimize a parametric architecture distribution and the shared model weights simultaneously. In this paper, we focus on efficiently exploring the important region of a neural architecture search space with reinforcement learning. We propose Deep Deterministic Architecture Sampling (DDAS) based on deep deterministic policy gradient and the actor-critic framework, to selectively sample important architectures in the supernet for training. Through balancing exploitation and exploration, DDAS is designed to combat the disadvantages of prior random supernet warm-up schemes and optimization schemes. Gradient-based NAS approaches require the execution of multiple short experiments in order to combat the random stochastic nature of gradient descent, while still only producing a single architecture. Contrary to this approach, DDAS employs a reinforcement learning-based agent and focuses on discovering a Pareto frontier containing many architectures over the course of a single experiment requiring 1 GPU day. Experimental results for CIFAR-10 and CIFAR-100 on the DARTS search space show that DDAS can depict in a single search, the accuracy-FLOPs (or model size) Pareto frontier, which outperforms random sampling and search. With a test accuracy of 97.27%, the best architecture found on CIFAR-10 outperforms the original second-order DARTS while using 600M fewer parameters. Additionally, DDAS finds an architecture capable of achieving 82.00% test accuracy on CIFAR-100 while using only 3.14M parameters and outperforming GDAS.",TOPIC
10.1109/ACCESS.2021.3102740,BHCNet: Neural Network-Based Brain Hemorrhage Classification Using Head CT Scan,"Brain Hemorrhage is the eruption of the brain arteries due to high blood pressure or blood clotting that could be a cause of traumatic injury or death. It is the medical emergency in which a doctor also need years of experience to immediately diagnose the region of the internal bleeding before starting the treatment. In this study, the deep learning models Convolutional Neural Network (CNN), hybrid models CNN + LSTM and CNN + GRU are proposed for the Brain Hemorrhage classification. The 200 head CT scan images dataset is used to boost the accuracy rate and computational power of the deep learning models. The major aim of this study is to use the abstraction power of deep learning on a set of fewer images because in most crucial cases extensive datasets are not available on the spot. The image augmentation and imbalancing the dataset methods are adopted with CNN model to design a unique architecture and named as Brain Hemorrhage Classification based on Neural Network (BHCNet). The performance of the proposed approach are analyzed in terms of accuracy, precision, sensitivity, specificity and F1-score. Further, the experimental results are evaluated by comparative analyses of the balanced and imbalanced dataset with CNN, CNN + LSTM and CNN + GRU models. The promising results are achieved with CNN by imbalancing the dataset and gain highest accuracy that outperforms the hybrid CNN + LSTM and CNN + GRU models. The results reveals the effectiveness of the proposed model for accurate prediction to save the life of the patient in the meantime and fast employment in the real life scenario.",TOPIC
10.1109/ACCESS.2021.3109216,IEEE Access,"An appropriate management of the available resources within oceans and coastal regions is vital to guarantee their sustainable development and preservation, where water quality is a key element. Leveraging on a combination of cross-disciplinary technologies including Remote Sensing (RS), Internet of Things (IoT), Big Data, cloud computing, and Artificial Intelligence (AI) is essential to attain this aim. In this paper, we review methodologies and technologies for water quality assessment that contribute to a sustainable management of marine environments. Specifically, we focus on Deep Leaning (DL) strategies for water quality estimation and forecasting. The analyzed literature is classified depending on the type of task, scenario and architecture. Moreover, several applications including coastal management and aquaculture are surveyed. Finally, we discuss open issues still to be addressed and potential research lines where transfer learning, knowledge fusion, reinforcement learning, edge computing and decision-making policies are expected to be the main involved agents. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ACCESS.2021.3114389,Keeping Children Safe Online With Limited Resources: Analyzing What is Seen and Heard,"It is every parent’s wish to protect their children from online pornography, cyber bullying and cyber predators. Several existing approaches analyze a limited amount of information stemming from the interactions of the child with the corresponding online party. Some restrict access to websites based on a blacklist of known forbidden URLs, others attempt to parse and analyze the exchanged multimedia content between the two parties. However, new URLs can be used to circumvent a blacklist, and images, video, and text can individually appear to be safe, but need to be judged jointly. We propose a highly modular framework of analyzing content in its final form at the user interface, or Human Computer Interaction (HCI) layer, as it appears before the child: on the screen and through the speakers. Our approach is to produce Children’s Agents for Secure and Privacy Enhanced Reaction (CASPER), which analyzes screen captures and audio signals in real time in order to make a decision based on all of the information at its disposal, with limited hardware capabilities. We employ a collection of deep learning techniques for image, audio and text processing in order to categorize visual content as pornographic or neutral, and textual content as cyberbullying or neutral. We additionally contribute a custom dataset that offers a wide spectrum of objectionable content for evaluation and training purposes. CASPER demonstrates an average accuracy of 88% and an F1 score of 0.85 when classifying text, and an accuracy of 95% when classifying pornography.",TOPIC
10.1109/ACCESS.2021.3136647,A Reinforced Active Learning Algorithm for Semantic Segmentation in Complex Imaging,"Semantic segmentation annotation helps train computer vision based Artificial Intelligence models where each image pixel is assigned to a specific object class. The model developers try to identify the features helpful for determining the objects of interest by using various supervised deep learning techniques. However, this is a difficult task due to the complexity of object structures. Two difficulties arise in the current approaches for semantic segmentation. The pixel-wise label approach is costly to obtain and is time consuming. Second, the datasets taken for the semantic segmentation task are not balanced since certain classes are present more than the others. This biases the model performance to the most represented ones. We propose a new reinforced active learning strategy based on a deep reinforcement learning algorithm. This work presents a modified Deep  $Q$  Learning formulation for active learning. An agent learns the strategy of selecting a subset of small image regions, which are more knowledgeable than the whole set of images from an unlabeled data pool. The decision on the area of selection is dependent on the assumptions and segmentation model uncertainties taken for training purposes. We use the CamVid and RGB indoor test scenes dataset to evaluate the proof of concept. Our results infer that our approach demands more labels from under-represented groups than the baselines, thus enhancing their efficiency and mitigating the class imbalance. Our method’s performance is superior to the conventional deep learning models in detecting 8 out of 11 classes on the Camvid road segmentation scene dataset. It achieves an accuracy of 90.56%, a mIoU score of 87.17%, and a BF score of 93.14%. On the SUNRGB indoor scenes dataset, it gives an accuracy of around 75.82% and a BF score of 77.25%, thus outperforming the current state-of-the-art methods.",TOPIC
10.1109/ACCESS.2021.3137797,Analysis of Depth and Semantic Mask for Perceiving a Physical Environment Using Virtual Samples Generated by a GAN,"Micro aerial vehicles (MAVs) can make explorations in 3D environments using technologies capable of perceiving the environment to map and estimate the location of objects that could cause collisions, such as Simultaneous Localization and Mapping (SLAM). Nevertheless, the agent needs to move during the environment mapping, reducing the flying time to employ additional activities. It has to be noted that adding more devices (sensors) to MAVs implies more power consumption. Since more energy to perform tasks is required, growing the dimensions of MAVs limits the flying time. Contrarily, Generative Adversarial Networks (GAN) have demonstrated the usefulness of creating images from one domain to another, but the GAN domain changes require a large number of samples. Therefore, an interoperability coefficient is employed to determine a minimum number of samples to connect the different domains. In order to prove the coefficient, the performance to estimate the depth and semantic mask between authentic and virtual samples with the number limited of samples is analyzed. Consequently, an RGB-D sensor can be replaced by a few samples of a real scenario based on GANs. Although GAN allows creating images with depth and semantic mask information, there is an additional problem to be tackled: the presence of intrinsic noise, where a simple GAN architecture is not enough. In this proposal, the performance of this solution against a physical RGB-D sensor (Microsoft Kinect V1) and other state-of-the-art approaches is compared. Experimental results allow us to affirm that this proposal is a viable option to replace a physical RGB-D sensor with limited information.",TOPIC
10.1109/ACCESS.2022.3145955,IEEE Access,"Physical servers are available as-a-service in bare-metal public and private cloud platforms, and their demand has been proliferating because of the high levels of privacy and security guarantees they provide to the tenants. This raises the need for efficient management of bare-metal clouds to keep operational costs low such as by reducing energy consumption. For efficiently managing the cloud infrastructure, bare-metal cloud operators need to monitor the utilization of servers. However, the privacy and security concerns prohibit the installation of third-party monitoring agents on the servers; thus, finding the server-utilization becomes a challenge. In this work, we present NASCENT, a scalable machine-learning (ML) based non-invasive solution for finding the utilization of servers without compromising the privacy and security of bare-metal cloud tenants. Our key idea is to infer utilization from various sensor readings accessible via a server's baseboard management controller (BMC) hardware. We evaluate the proposed solution with three regression based supervised ML algorithms in a Bare-metal-as-a-service (BMaaS) cloud. Our experimental evaluation shows that one of the ML algorithms employed in NASCENT infers the utilization with a root-mean-square error (RMSE) between 2.9 to 9.3 for different workloads. Also, the proposed solution uses minimal memory resources (19 KB) and can even run on BMC hardware which has very limited memory. We also propose a BMaaS cloud architecture that seamlessly integrates automated training and deployment of the ML algorithm in our solution into the life-cycle of bare-metal servers. NASCENT's codebase can be found at https://github.com/iithcandle/dhi-ojas © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ACCESS.2022.3150924,Malignancy Detection in Lung and Colon Histopathology Images Using Transfer Learning With Class Selective Image Processing,"Cancer accounts for a huge mortality rate due to its aggressiveness, colossal potential of metastasis, and heterogeneity (causing resistance against chemotherapy). Lung and colon cancers are among the most prevalent types of cancer around the globe that can occur in both males and females. Early and accurate diagnosis of these cancers can substantially improve the quality of treatment as well as the survival rate of cancer patients. We propose a highly accurate and computationally efficient model for the swift and accurate diagnosis of lung and colon cancers as an alternative to current cancer detection methods. In this study, a large dataset of lung and colon histopathology images was employed for training and the validation process. The dataset is comprised of 25000 histopathology images of lung and colon tissues equally divided into 5 classes. A pretrained neural network (AlexNet) was tuned by modifying the four of its layers before training it on the dataset. Initial classification results were promising for all classes of images except for one class with an overall accuracy of 89%. To improve the overall accuracy and keep the model computationally efficient, instead of implementing image enhancement techniques on the entire dataset, the quality of images of the underperforming class was improved by applying a contrast enhancement technique which is fairly simple and efficient. The implementation of the proposed methodology has not only improved the overall accuracy from 89% to 98.4% but has also proved computationally efficient.",TOPIC
10.1109/ACCESS.2022.3159715,Architecture of an Artificial Intelligence Model Manager for Event-Driven Component-Based SCADA Systems,"This paper analyzes Hat, an open-source framework for developing event-driven component-based SCADA applications, and discusses possibilities to add various analytical tools to such platforms. As a part of the contribution, an open-source component called Artificial Intelligence Model Manager (AIMM) has been developed and integrated into a Hat-based SCADA platform. AIMM is extensible through various plugins, allowing the addition of various models for advanced analytics e.g., machine learning tools, statistical tools, etc. The paper describes AIMM architecture and provides a use case in which state estimation was performed in a medium-voltage distribution grid. This case study demonstrates that it is possible to extend component-based SCADA systems with components for advanced analytics with minimal fundamental system changes.",TOPIC
10.1109/ACCESS.2022.3161661,IEEE Access,"This paper presents an analysis of the implementation and performance of a deep learning model based on Recurrent layers and Variational Auto Encoder model (VAE) architecture for prediction of future local trajectory and maneuver. The proposed method uses the encoder part of the VAE to represent the vehicle's surroundings agents behavior in time, taking advantage on the fact that VAE encodes similar situations or states close in the latent space and the generative properties of the VAE decoder, that is used to generate naturalistic driving trajectories. Furthermore, the variance of the predicted trajectory is estimated using the statistical properties of VAE model, increasing it if the input data is noisy or unrealistic and decreasing it if the model is certain about the prediction. The model is trained and evaluated with a public dataset. The results show that the proposed architecture outperforms state of the art methods in trajectory prediction error and provides a variance estimation that depends on input quality. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ACCESS.2022.3168992,Reinforcement Learning Based Fault-Tolerant Routing Algorithm for Mesh Based NoC and Its FPGA Implementation,"Network-on-Chip (NoC) has emerged as the most promising on-chip interconnection framework in Multi-Processor System-on-Chips (MPSoCs) due to its efficiency and scalability. In the deep sub-micron level, NoCs are vulnerable to faults, which leads to the failure of network components such as links and routers. Failures in NoC components diminish system efficiency and reliability. This paper proposes a Reinforcement Learning based Fault-Tolerant Routing (RL-FTR) algorithm to tackle the routing issues caused by link and router faults in the mesh-based NoC architecture. The efficiency of the proposed RL-FTR algorithm is examined using System-C based cycle-accurate NoC simulator. Simulations are carried out by increasing the number of links and router faults in various sizes of mesh. Followed by simulations, real-time functioning of the proposed RL-FTR algorithm is observed using the FPGA implementation. Results of the simulation and hardware shows that the proposed RL-FTR algorithm provides an optimal routing path from the source router to the destination router.",TOPIC
10.1109/ACCESS.2022.3172712,Active Inference Integrated With Imitation Learning for Autonomous Driving,"Classical imitation learning methods suffer substantially from the learning hierarchical policies when the imitative agent faces an unobserved state by the expert agent. To address these drawbacks, we propose an online active learning through active inference approach that encodes the expert’s demonstrations based on observation-action to improve the learner’s future motion prediction. For this purpose, we provide a switching Dynamic Bayesian Network based on the dynamic interaction between the expert agent and another object in its surrounding as a reference model, which we exploit to initialize an incremental probabilistic learning model. This learning model grows and matures based on the free-energy formulation and message passing of active inference dynamically at discrete and continuous levels in an online active learning phase. In this scheme, generalized states of the learning world are represented as distance-vector, where it is the learner’s observation concerning its interaction with a moving object. Considering the distance vector entail intentions, it enables action prediction evaluation in a prospective sense. We illustrate these points using simulations of driving intelligent agents. The learning agent is trained by using long-term predictions from the generative learning model to reproduce the expert’s motion while learning how to select a suitable action through new experiences. Our results affirm that a Dynamic Bayesian optimal approach provides a principled framework and outperforms conventional reinforcement learning methods. Furthermore, it endorses the general formulation of action prediction as active inference.",TOPIC
10.1109/ACCESS.2022.3180844,dropCyclic: Snapshot Ensemble Convolutional Neural Network Based on a New Learning Rate Schedule for Land Use Classification,"The ensemble learning method is a necessary process that provides robustness and is more accurate than the single model. The snapshot ensemble convolutional neural network (CNN) has been successful and widely used in many domains, such as image classification, fault diagnosis, and plant image classification. The advantage of the snapshot ensemble CNN is that it combines the cyclic learning rate schedule in the algorithm to snap the best model in each cycle. In this research, we proposed the dropCyclic learning rate schedule, which is a step decay to decrease the learning rate value in every learning epoch. The dropCyclic can reduce the learning rate and find the new local minimum in the subsequent cycle. We evaluated the snapshot ensemble CNN method based on three learning rate schedules: cyclic cosine annealing, max-min cyclic cosine learning rate scheduler, and dropCyclic then using three backbone CNN architectures: MobileNetV2, VGG16, and VGG19. The snapshot ensemble CNN methods were tested on three aerial image datasets: UCM, AID, and EcoCropsAID. The proposed dropCyclic learning rate schedule outperformed the other learning rate schedules on the UCM dataset and obtained high accuracy on the AID and EcoCropsAID datasets. We also compared the proposed dropCyclic learning rate schedule with other existing methods. The results show that the dropCyclic method achieved higher classification accuracy compared with other existing methods.",TOPIC
10.1109/ACCESS.2022.3181595,Neural Networks for Energy-Efficient Self Optimization of eNodeB Antenna Tilt in 5G Mobile Network Environments,"In this paper, we present an energy-efficient Self Organizing Network (SON) architecture based on a tunable eNodeB (eNB) antenna tilt design for macrocells in a mobile network environment. This is an imperative element of mobility management in high speed and low latency wireless networks. The SON architecture follows a fully distributed approach with optional network information exchange with neighboring cells and core network. Antenna tilt directly affects its radiation pattern thus changes in eNB antenna tilt can be used to optimize cell coverage and reduce interference in mobile networks. We apply and compare two reinforcement machine learning techniques for optimizing the eNB antenna tilts, i.e., Deep Q-learning using Artificial Neural Network (ANN) and a simple Stochastic Cellular Learning Automata (SCLA). ANN is well known for its ability to learn from a vast number of inputs, while the stochastic learning technique relies on a simple action based probability vector updated based on system feedback. Neighboring cells for any one cell in the network environment are selected based on their separation distance and antenna orientation. We validate the data call performance of the network for edge users as they directly impact the Quality of Service (QoS) in the mobile environment. Our simulated results show that ANN performs better for edge users as compared to SCLA. The model also satisfies the SON requirement of scalability and agility. This work is a follow-up to our earlier work, where we showed that SCLA performs better than Q-learning in a similar network environment and optimizing strategy due to its low complexity, but within the same Q-learning algorithm more input learning parameters gave better performance.",TOPIC
10.1109/ACCESS.2022.3182009,Deep Reinforcement Learning Based Routing in IP Media Broadcast Networks: Feasibility and Performance,"The media broadcast industry has evolved from Serial Digital Interface (SDI) based infrastructures to IP networks. While IP based video broadcast is well established in the data plane, the use of IP networks to transport media flows still poses challenges in terms of resource management and orchestration. Software Defined Networking (SDN) based orchestration architectures have emerged in the industry that use SDN to route the media flows of a broadcast service across the provider IP network. Several approaches to multimedia flow routing in IP based SDN networks have been proposed in the context of streaming applications over the Internet. These range from model based linear optimization solutions that have high complexity to simple shortest path based routing with either Static Link Costs (SLC) or Dynamic Link Costs (DLC). More recently model-free optimization methods such as Deep Reinforcement Learning (DRL) have been proposed for routing and Traffic Engineering (TE) of multimedia flows in SDN networks. The media broadcast scenario however has specific requirements, with services like Master Control Room (MCR) operation and live broadcasting of events, and it has been rarely addressed in the literature. In this work we propose a DRL based routing method for this scenario and compare it to SLC and DLC algorithms based on Dijkstra shortest paths. This is, to our knowledge, the first work to follow this approach in the context of media broadcast services in IP infrastructures. The algorithm is designed considering the specifications and capabilities of one of the leading SDN orchestrators in the market and considers the more common Service Level Agreement (SLA) requirements in the industry. Three different DRL algorithms are implemented and compared and we evaluate them using a real service provider network topology. The results indicate that DRL based routing is applicable in real production scenarios and that it achieves considerable performance gains when compared to the SLC and DLC shortest path algorithms commonly used today.",TOPIC
10.1109/ACCESS.2022.3182500,Deep Reinforcement Learning Enabled Self-Configurable Networks-on-Chip for High-Performance and Energy-Efficient Computing Systems,"Network-on-Chips (NoC) has been the superior interconnect fabric for multi/many-core on-chip systems because of its scalability and parallelism. On-chip network resources can be dynamically configured to improve the energy efficiency and performance of NoC. However, large and complex design space in heterogeneous NoC architectures becomes difficult to explore within a reasonable time for optimal trade-offs of energy and performance. Furthermore, reactive resource management is not effective in preventing problems, such as thermal hotspots, from happening in adaptive systems. Therefore, we propose machine learning (ML) techniques to provide proactive solutions within an instant in NoC-based computing systems. We present a deep reinforcement learning (deep RL) technique to configure voltage/frequency levels of NoC routers and links for both high performance and energy efficiency while meeting the global energy budget constraint. Distributed RL agents technique has been proposed, where an RL agent configures a NoC router and associated links intelligently based on system utilization and application demands. Additionally, neural networks are used to approximate the actions of distributed RL agents. Simulations results for NoC sizes ranging from 16 to 256 cores under real applications and synthetic traffic show that the proposed self-configurable and scalable approach, on average, improves energy-delay product (EDP) by 30-40% (up to 80%) and by 8% (up to 17%) compared to existing non-ML and ML based solutions, respectively.",TOPIC
10.1109/ACCESS.2022.3185732,PlaneLoc2: Indoor Global Localization Using Planar Segments and Passive Stereo Camera,"This paper introduces PlaneLoc2 - a novel indoor global localization system designed to harness the potential of stereo cameras. A need for robust global localization that does not produce incorrect results (false positives) is present in almost every life-long autonomy task. We show that planar segments extracted from stereo vision data by a neural network enable such robust localization. Planar segments are easier to discriminate than keypoint features and provide easy-to-use geometric constraints. We propose an architecture that exploits a single deep neural network (DNN) to detect planar segments, produce appearance descriptors, and estimate segment geometry. Moreover, we introduce a novel view-based segment map and a novel pose retrieval procedure that considers the uncertainty of features to efficiently use the geometric constraints provided by them. We also show that the new learned descriptor provides better discrimination than the hand-crafted one. Finally, we present experimental results that show that our solution outperforms other state-of-the-art global localization methods and does not produce incorrect agent poses. For both test scenes it recognizes at least 15% more poses than the second best method without incorrect recognitions.",TOPIC
10.1109/ACCESS.2022.3200066,Multimodal Pedestrian Trajectory Prediction Based on Relative Interactive Spatial-Temporal Graph,"Predicting and understanding pedestrian intentions is crucial for autonomous vehicles and mobile robots to navigate in a crowd. However, the movement of pedestrian is random. Pedestrian trajectory modeling needs to consider not only the past movement of pedestrians, the interaction between different pedestrians, the constraints of static obstacles in the scene, but also multi-modal of the human trajectory, which brings challenges to pedestrian trajectory prediction. Most of the existing trajectory prediction methods only consider the interaction between pedestrians in the scene, ignoring the static obstacles in the scene can also have impacts on the trajectory of pedestrian. In this paper, a scalable relative interactive spatial-temporal graph generation adversarial network architecture (RISTG-GAN) is proposed to generate a reasonable multi-modal prediction trajectory by considering the interaction effects of all agents in the scene. Our method extends recent work on trajectory prediction. First, LSTM nodes are flexibly used to model the spatial-temporal graph of human-environment interactions, and the spatial-temporal graph is converted into feed-forward differentiable feature coding, and the time attention module is proposed to capture the trajectory information in time domain and learn the time dependence in long time range. Then, we capture the relative importance of the interaction of all agents in the scene on the pedestrian trajectory through the improved relative scaled dot product attention and use the generative adversarial network architecture for training to generate reasonable pedestrian future trajectory distribution. Experiments on five commonly used real public datasets show that RISTG-GAN is better than previous work in terms of reasoning speed, accuracy and the rationality of trajectory prediction.",TOPIC
10.1109/ACCESS.2022.3201560,DeblurGAN-CNN: Effective Image Denoising and Recognition for Noisy Handwritten Characters,"Many problems can reduce handwritten character recognition performance, such as image degradation, light conditions, low-resolution images, and even the quality of the capture devices. However, in this research, we have focused on the noise in the character images that could decrease the accuracy of handwritten character recognition. Many types of noise penalties influence the recognition performance, for example, low resolution, Gaussian noise, low contrast, and blur. First, this research proposes a method that learns from the noisy handwritten character images and synthesizes clean character images using the robust deblur generative adversarial network (DeblurGAN). Second, we combine the DeblurGAN architecture with a convolutional neural network (CNN), called DeblurGAN-CNN. Subsequently, two state-of-the-art CNN architectures are combined with DeblurGAN, namely DeblurGAN-DenseNet121 and DeblurGAN-MobileNetV2, to address many noise problems and enhance the recognition performance of the handwritten character images. Finally, the DeblurGAN-CNN could transform the noisy characters to the new clean characters and recognize clean characters simultaneously. We have evaluated and compared the experimental results of the proposed DeblurGAN-CNN architectures with the existing methods on four handwritten character datasets: n-THI-C68, n-MNIST, THI-C68, and THCC-67. For the n-THI-C68 dataset, the DeblurGAN-CNN achieved above 98% and outperformed the other existing methods. For the n-MNIST, the proposed DeblurGAN-CNN achieved an accuracy of 97.59% when the AWGN+Contrast noise method was applied to the handwritten digits. We have evaluated the DeblurGAN-CNN on the THCC-67 dataset. The result showed that the proposed DeblurGAN-CNN achieved an accuracy of 80.68%, which is significantly higher than the existing method, approximately 10%.",TOPIC
10.1109/ACCESS.2022.3206364,Connected and Autonomous Vehicle Cohort Speed Control Optimization via Neuroevolution,"Predictive Energy Management (PrEM) research is at the forefront of modern transportation’s energy consumption reduction efforts. The development of PrEM optimization algorithms has been tailored to selfish vehicle operation and implemented in the form of vehicle dynamics and/or adaptive powertrain control functions. With the progress in vehicle automation, this paper focuses on extending PrEM into the realm of a System of Systems (SoS). The proposed approach uses the shared information among Connected and Automated Vehicles (CAV) and the infrastructure to synthesize a reduced energy speed trajectory at the cohort level within urban environments. Neuroevolution is employed to incorporate a generalized optimum controller, robust to the emergent behaviors typical of multi-agents SoS. The authors demonstrated the use of heuristics and systems engineering processes in abstracting and integrating the resulting neural network within the control architecture, which enables novel added-value features such as green wave pass/fail classification and e-Horizon velocity prediction. The resulting controller is faster than real-time and was validated with a multi-agent simulation environment and on a real-world closed-loop track at the American Center for Mobility (ACM). The GM Bolt and Volt CAV mixed cohort testing at ACM demonstrated energy reductions from 7% to 22% depending on scenarios.",TOPIC
10.1109/ACCESS.2022.3210993,Adaptive Routing in Wireless Mesh Networks Using Hybrid Reinforcement Learning Algorithm,"Wireless mesh networks are popular due to their adaptability, easy-setup, flexibility, cost, and transmission time-reductions. The routing algorithm plays a vital role in transferring the data between the nodes. The network’s performance is significantly impacted by the route opted by the algorithm. The router takes the decision to send the packet to the next router as per the policy of that algorithm. So even though that decision does not favor the right path selection, the router tends to follow its policy. This can be avoided by having intelligent routers that can make routing decisions on the fly. This paper presents the QL-Feed Forward routing algorithm (QFFR), a new generation of routing algorithms that combines reinforcement learning based on the Q-learning algorithm with a Feed Forward neural network. This algorithm (QFFR) can learn from the network environment and make routing decisions based on the algorithm’s learnings. The AI agent’s ability to select the fastest path, which enhances the efficiency of the routing operation, is demonstrated by the working of the suggested QFFR algorithm. This paper also evaluates the performance of traditional algorithms, namely, Ad-hoc On-Demand Distance-Vector, Optimized-Link-State-routing, Destination-Sequenced Distance-Vector and Distance Source routing. The evaluation parameters include throughput, packet delivery ratio, and delay. The parameters are the outcomes of the time the information takes to reach from source to destination. This analysis highlights the improvement in the routing decision ability of a router. As per analysis, Ad hoc On-Demand Distance Vector Algorithm outperforms with throughput 723.13 Kbps, delay 343.73 ns. Q-learning agent identifies the route and reaches the destination in average of 3.7s in non-grid architecture. The Q-learning agent takes 0.49sec with a grid size ten by ten and 0.53sec in three by four grid size. The suggested QFFR takes 7.62s score-over time with stable, consistent performance.",TOPIC
10.1109/ACCESS.2022.3213652,ViGAT: Bottom-Up Event Recognition and Explanation in Video Using Factorized Graph Attention Network,"In this paper a pure-attention bottom-up approach, called ViGAT, that utilizes an object detector together with a Vision Transformer (ViT) backbone network to derive object and frame features, and a head network to process these features for the task of event recognition and explanation in video, is proposed. The ViGAT head consists of graph attention network (GAT) blocks factorized along the spatial and temporal dimensions in order to capture effectively both local and long-term dependencies between objects or frames. Moreover, using the weighted in-degrees (WiDs) derived from the adjacency matrices at the various GAT blocks, we show that the proposed architecture can identify the most salient objects and frames that explain the decision of the network. A comprehensive evaluation study is performed, demonstrating that the proposed approach provides state-of-the-art results on three large, publicly available video datasets (FCVID, MiniKinetics, ActivityNet). Source code is made publicly available at: https://github.com/bmezaris/ViGAT",TOPIC
10.1109/ACCESS.2022.3217511,RLOps: Development Life-Cycle of Reinforcement Learning Aided Open RAN,"Radio access network (RAN) technologies continue to evolve, with Open RAN gaining the most recent momentum. In the O-RAN specifications, the RAN intelligent controllers (RICs) are software-defined orchestration and automation functions for the intelligent management of RAN. This article introduces principles for machine learning (ML), in particular, reinforcement learning (RL) applications in the O-RAN stack. Furthermore, we review the state-of-the-art research in wireless networks and cast it onto the RAN framework and the hierarchy of the O-RAN architecture. We provide a taxonomy for the challenges faced by ML/RL models throughout the development life-cycle: from the system specification to production deployment (data acquisition, model design, testing and management, etc.). To address the challenges, we integrate a set of existing MLOps principles with unique characteristics when RL agents are considered. This paper discusses a systematic model development, testing and validation life-cycle, termed: RLOps. We discuss fundamental parts of RLOps, which include: model specification, development, production environment serving, operations monitoring and safety/security. Based on these principles, we propose the best practices for RLOps to achieve an automated and reproducible model development process. At last, a holistic data analytics platform rooted in the O-RAN deployment is designed and implemented, aiming to embrace and fulfil the aforementioned principles and best practices of RLOps.",TOPIC
10.1109/ACCESS.2022.3224808,Deep Reinforcement Learning-Based Scheduling for Multiband Massive MIMO,"Fifth-generation (5G) cellular communication systems have embraced massive multiple-input-multiple-output (MIMO) in the low- and mid-band frequencies. In a multiband system, the base station can serve different users in each band, while the user equipment can operate only in a single band simultaneously. This paper considers a massive MIMO system where channels are dynamically allocated in different frequency bands. We treat multiband massive MIMO as a scheduling and resource allocation problem and propose deep reinforcement learning (DRL) agents to perform user scheduling. The DRL agents use buffer and channel information to compose their observation space, and the agent’s reward function maximizes the transmitted throughput and minimizes the packet loss rate. We compare the proposed DRL algorithms with traditional baselines, such as maximum throughput and proportional fairness. The results show that the DRL models outperformed baselines obtaining a 20% higher network sum rate and an 84% smaller packet loss rate. Moreover, we compare different DRL algorithms focusing on training time to assess the online implementation of the DRL agents, showing that the best agent needs about 50K training steps to converge.",TOPIC
10.1109/ACCESS.2022.3226484,IEEE Access,"Depth estimation is an important computer vision task, useful in particular for navigation in autonomous vehicles, or for object manipulation in robotics. Here, we propose to solve it using StereoSpike, an end-To-end neuromorphic approach, combining two event-based cameras and a Spiking Neural Network (SNN) with a modified U-Net-like encoder-decoder architecture. More specifically, we used the Multi Vehicle Stereo Event Camera Dataset (MVSEC). It provides a depth ground-Truth, which was used to train StereoSpike in a supervised manner, using surrogate gradient descent. We propose a novel readout paradigm to obtain a dense analog prediction-The depth of each pixel-from the spikes of the decoder. We demonstrate that this architecture generalizes very well, even better than its non-spiking counterparts, leading to near state-of-The-Art test accuracy. To the best of our knowledge, it is the first time that such a large-scale regression problem is solved by a fully spiking neural network. Finally, we show that very low firing rates (< 5%) can be obtained via regularization, with a minimal cost in accuracy. This means that StereoSpike could be efficiently implemented on neuromorphic chips, opening the door for low power and real time embedded systems. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ACCESS.2022.3231491,Device Agent Assisted Blockchain Leveraged Framework for Internet of Things,"Blockchain (BC) is a burgeoning technology that has emerged as a promising solution to peer-to-peer communication security and privacy challenges. As a revolutionary technology, blockchain has drawn the attention of academics and researchers. Cryptocurrencies have already effectively utilized BC technology. Many researchers have sought to implement this technique in different sectors, including the Internet of Things. To store and manage IoT data, we present in this paper a lightweight BC-based architecture with a modified raft algorithm-based consensus protocol. We designed a Device Agent that executes a novel registration procedure to connect IoT devices to the blockchain. We implemented the framework on Docker using the Go programming language. We have simulated the framework on a Linux environment hosted in the cloud. We have conducted a detailed performance analysis using a variety of measures. The results demonstrate that our suggested solution is suitable for facilitating the management of IoT data with increased security and privacy. In terms of throughput and block generation time, the results indicate that our solution might be 40% to 45% faster than the existing blockchain.",TOPIC
10.1109/ACCESS.2022.3232853,FARANE-Q: Fast Parallel and Pipeline Q-Learning Accelerator for Configurable Reinforcement Learning SoC,"This paper proposes a FAst paRAllel and pipeliNE Q-learning accelerator (FARANE-Q) for a configurable Reinforcement Learning (RL) algorithm implemented in a System on Chip (SoC). The proposed work offers flexibility, configurability, and scalability while maintaining computation speed and accuracy to overcome the challenges of a dynamic environment and increasing complexity. The proposed method includes a Hardware/Software (HW/SW) design methodology for the SoC architecture to achieve flexibility. We also propose joint optimizations on the algorithm, architecture, and implementation to obtain optimum (high efficiency) performance, specifically in energy and area efficiency. Furthermore, we implemented the proposed design in a real-time Zynq Ultra96-V2 FPGA platform to evaluate the functionality with an actual use case of smart navigation. Experimental results confirm that the proposed accelerator FARANE-Q outperforms state-of-the-art works by achieving a throughput of up to 148.55 MSps. It corresponds to the energy efficiency of 1747.64 MSps/W per agent for 32-bit and 2424.33 MSps/W per agent for 16-bit FARANE-Q. Moreover, the proposed 16-bit FARANE-Q outperforms other related works by an improvement of at least  $1.23\times $  in energy efficiency. The designed system also maintains an error accuracy of less than 0.4% with optimized bit precision for more than eight fraction bits. The proposed FARANE-Q also offers a speed up of processing time up to  $1795\times $  compared to embedded SW computation executed on ARM Zynq processor and  $280\times $  of computation of full software executed on i7 processor. Hence, the proposed work has the potential to be used for smart navigation, robotic control, and predictive maintenance.",TOPIC
10.1109/ACCESS.2023.3234021,Proactive Random-Forest Autoscaler for Microservice Resource Allocation,"Cloud service providers have been shifting their workloads to microservices to take advantage of their modularity, flexibility, agility, and scalability. However, numerous obstacles remain to achieving the most out of microservice deployments, especially in terms of a Quality of Service (QoS). One possible approach to overcoming these obstacles is to perform autoscaling, which is the ability of cloud infrastructure and services to scale themselves up or down by changing their resource pool. There are two major categories of autoscaling: reactive and proactive. In reactive autoscaling, a feedback loop based on current workload resource usage is implemented to guide resource scaling. One disadvantage of reactive autoscaling is that it may result in inconsistencies between workload demand and resource allocation. In proactive autoscaling, a prediction model is used to guide the future allocation of resources according to current workload metrics. In this paper, a novel proactive autoscaling method is introduced where a two-state, machine-learning Random Forest (RF) model is designed to forecast the future CPU and memory utilization values required by the microservice workload. These predicted values are then used to adjust the resource pool both vertically (hardware resources) and horizontally (microservice replicas). The RF proactive autoscaler has been implemented on a home-grown, open-source microservice prototyping platform and verified using real-world workloads. The experiments show that the RF proactive autoscaler outperforms state-of-the-art ones in terms of allocated resources and latency. The increase in the utilization of allocated resources can reach 90% and the improvement in end-to-end latency, measured by the  $95^{th}$  percentile, can reach 95%.",TOPIC
10.1109/ACCESS.2023.3244388,A Configurable Model-Based Reinforcement Learning Framework for Disaggregated Storage Systems,"With the rapid growth of data-intensive jobs and the use of different hardware in storage, disaggregated storage architecture systems are being used to improve the operational cost efficiency of data centers. The hardware heterogeneity and mixed configurations of disaggregated storage systems, along with the diversity of workloads, often make it difficult for administrators to operate them optimally. In this work, we investigate model-based reinforcement learning (RL) schemes to develop automated system operations and maintain the storage performance across various system settings and workloads in self-managed storage systems. Specifically, we propose a novel configurable model structure in which a system environment is abstracted with a two-level hierarchy of storage devices and a platform and thus the environment can be reconfigured according to a given system specification. Using that novel model structure, we implement a configurable model-based RL framework CoMoRL by which RL agents are trained through model variants that represent a variety of storage system specifications; thus, their learned management policy can be highly robust to the diverse operation conditions of real-world storage systems. We evaluate our CoMoRL framework using a storage cluster that relies on NVMe-oF devices and demonstrate that the framework can be adapted to different scenarios such as volume placement scenarios with Kubernetes and primary affinity control scenarios with Ceph. The learned management policy outperforms an IOPS-based heuristic method and a model-based method by 0.7%~5.1% and 11.8%~29.7%, respectively, for various Kubernetes system specifications, and by 1.6%~5.6% and 8.2%~16.5%, respectively, for various Ceph system specifications, without requiring model and policy retraining. This zero-shot adaptation superiority of our framework makes it possible to realize RL-based self-managing storage systems in data centers with frequent system changes.",TOPIC
10.1109/ACCESS.2023.3249151,Control Systems for Low-Inertia Power Grids: A Survey on Virtual Power Plants,"Virtual Power Plants (VPPs) have emerged as a modern real-time energy management architecture that seeks to synergistically coordinate an aggregation of renewable and non-renewable generation systems to overcome some of the fundamental limitations of traditional power grids dominated by synchronous machines. In this survey paper, we review the different existing and emerging feedback control mechanisms and architectures used for the real-time operation of VPPs. In contrast to other works that have mostly focused on the optimal dispatch and economical aspects of VPPs in the hourly and daily time scales, in this paper we focus on the dynamic nature of the system during the faster sub-hourly time scales. The virtual (i.e., software-based) component of a VPP, combined with the power plant (i.e., physics-based) components of the power grid, make VPPs prominent examples of cyber-physical systems, where both continuous-time and discrete-time dynamics play critical roles in the stability and transient properties of the system. We elaborate on this interpretation of VPPs as hybrid dynamical systems, and we further discuss open research problems and potential research directions in feedback control systems that could contribute to the safe development and deployment of autonomous VPPs.",TOPIC
10.1109/ACCESS.2023.3253388,Integrating Conversational Agents and Knowledge Graphs Within the Scholarly Domain,"In the last few years, chatbots have become mainstream solutions adopted in a variety of domains for automatizing communication at scale. In the same period, knowledge graphs have attracted significant attention from business and academia as robust and scalable representations of information. In the scientific and academic research domain, they are increasingly used to illustrate the relevant actors (e.g., researchers, institutions), documents (e.g., articles, patents), entities (e.g., concepts, innovations), and other related information. Following the same direction, this paper describes how to integrate conversational agents with knowledge graphs focused on the scholarly domain, a.k.a. Scientific Knowledge Graphs. On top of the proposed architecture, we developed AIDA-Bot, a simple chatbot that leverages a large-scale knowledge graph of scholarly data. AIDA-Bot can answer natural language questions about scientific articles, research concepts, researchers, institutions, and research venues. We have developed four prototypes of AIDA-Bot on Alexa products, web browsers, Telegram clients, and humanoid robots. We performed a user study evaluation with 15 domain experts showing a high level of interest and engagement with the proposed agent.",TOPIC
10.1109/ACCESS.2023.3258681,PolyVerif: An Open-Source Environment for Autonomous Vehicle Validation and Verification Research Acceleration,"Validation and Verification (V&V) of Artificial Intelligence (AI) based cyber physical systems such as Autonomous Vehicles (AVs) is currently a vexing and unsolved problem. AVs integrate subsystems in areas such as detection, sensor fusion, localization, perception, and path planning. Each of these subsystems contains significant AI content integrated with traditional hardware and software components. The complexity for validating even a subsystem is daunting and the task of validating the whole system is nearly impossible. Fundamental research in advancing the state-of-the-art for AV V&V is required. However, for V&V researchers, it is exceedingly difficult to make progress because of the massive infrastructure requirements to demonstrate the viability of any solution. This paper presents PolyVerif, the world’s first open-source solution focused on V&V researchers with the objective of accelerating the state-of-the-art for AV V&V research. PolyVerif provides an AI design and verification framework consisting of a digital twin creation process, an open-source AV engine, access to several open-source physics based simulators, and open-source symbolic test generation engines. PolyVerif’s objective is to arm V&V researchers with a framework which extends the state-of-the-art on any one of the many major axes of interest and use the remainder of the infrastructure to quickly demonstrate the viability of their solution. Given its open-source nature, researchers can also contribute their innovations to the project. Using this critical property of open-source environments, the innovation rate of the whole research community to solve these vexing issues can be greatly accelerated. Finally, the paper also presents results from several projects which have used PolyVerif.",TOPIC
10.1109/ACCESS.2023.3260147,A Survey on Microservices Trust Models for Open Systems,"The microservices architecture (MSA) is a form of distributed systems architecture that has been widely adopted in large-scale software systems in recent years. As with other distributed system architectures, one of the challenges that MSA faces is establishing trust between the microservices, particularly in the context of open systems. The boundaries of open systems are unlimited and unknown, which means that they can be applied to any use case. Microservices can leave or join an open system arbitrarily, without restriction as to ownership or origin, and MSA systems can scale extensively. The organisation of microservices (in terms of the roles they play and the communication links they utilise) can also change in response to changes in the environment in which the system is situated. The management of trust within MSAs is of great importance as the concept of trust is critical to microservices communication, and the operation of an open MSA system is highly reliant on communication between these fine-grained microservices. Thus, a trust model should also be able to manage trust in an open environment. Current trust management solutions, however, are often domain-specific and many are not specifically tailored towards the open system model. This motivates research on trust management in the context of open MSA systems. In this paper, we examine existing microservices trust models, identify the limitations of these models in the context of the principles of open microservices systems, propose a set of qualities for open microservices trust models that emerge from these limitations, and assess selected microservices trust models using the proposed qualities.",TOPIC
10.1109/ACCESS.2023.3267985,Machine Learning in Network Slicing—A Survey,"5G and beyond networks are expected to support a wide range of services, with highly diverse requirements. Yet, the traditional “one-size-fits-all” network architecture lacks the flexibility to accommodate these services. In this respect, network slicing has been introduced as a promising paradigm for 5G and beyond networks, supporting not only traditional mobile services, but also vertical industries services, with very heterogeneous requirements. Along with its benefits, the practical implementation of network slicing brings a lot of challenges. Thanks to the recent advances in machine learning (ML), some of these challenges have been addressed. In particular, the application of ML approaches is enabling the autonomous management of resources in the network slicing paradigm. Accordingly, this paper presents a comprehensive survey on contributions on ML in network slicing, identifying major categories and sub-categories in the literature. Lessons learned are also presented and open research challenges are discussed, together with potential solutions.",TOPIC
10.1109/ACCESS.2023.3268543,Optimal Learning Paradigm and Clustering for Effective Radio Resource Management in 5G HetNets,"Ultra-dense heterogeneous networks (UDHN) based on small cells are a requisite part of the future cellular networks as they are proposed as one of the enabling technologies to handle coverage and capacity problems. But co-tier and cross-tier interferences in UDHN severely degrade the quality of service due to K-tiered architecture. Machine learning based radio resource management either through independent learning or cooperative learning is a proven efficient scheme for interference mitigation and quality of service provision in UDHN in a both distributive and cooperative manner. However, an optimal learning paradigm selection, i.e., either independent or cooperative learning and optimal cooperative cluster size in cooperative learning for efficient radio resource management in UDHN is still an open research problem. In this article, a Q-learning based radio resource management scheme is proposed and evaluated for both distributive and cooperative schemes using independent and cooperative learning. The proposed Q-learning solution follows the  $\epsilon -$ greedy policy for optimal convergence. The simulation results for the UDHN in an urban setup show that in comparison to the independent learning paradigm, cooperative learning has no significant impact on macro cell user capacity. However, there is a significant improvement in small cell user capacity and the sum capacity of the cooperating small cells in the cluster. A significant increase of 48.57% and 37.9% is observed in the small cell user capacity, and sum capacity of the cooperating small cells, respectively, using cooperative learning as compared to independent learning which sets cooperative learning as an optimal learning strategy in UDHN. The improvement in small cell user capacity is at cost of increased computational time which is directly proportional to the number of cooperating small cells. To solve the issue of computational time in cooperative learning, an optimal clustering algorithm is proposed. The proposed optimal clustering reduced the computational time by four times in cooperative Q-learning.",TOPIC
10.1109/ACCESS.2023.3281558,IEEE Access,"Monitoring tumor volume changes in response to therapeutic agents is a critical step in preclinical drug development. Here, an automated magnetic resonance imaging (MRI)-based approach is proposed using a deep learning framework for tracking longitudinal tumor volume changes in an orthotopic breast cancer model treated with chemotherapy. Longitudinal magnetic resonance images are employed to track changes in tumor volume over time, using an untreated group and a doxorubicin-treated group as the dataset to evaluate treatment effects. Our approach, called Tumor Segmentation-Net (TS-Net), involves replacing the encoder of U-Net with a pre-trained ResNet34 to improve performance. The model was trained using a sample size of n=19 from the untreated group and then subsequently assessed on both the untreated group (n=5) and treated group (n=6). The correlation between the tumor volume determined from the ground truth and that obtained from the trained output was strong (R2 =0.984, slope=0.996). These results can lead to automated three-dimensional visualization of different longitudinal volume changes with and without treatment. Notably, for small tumors with volumes between 2 and 5 mm3, the proposed TS-Net demonstrated an average Dice similarity coefficient score of 0.85, indicating the ability to reliably detect early tumors that may often be missed. Our approach offers a promising tool for preclinical evaluation of tumor volume changes and treatment efficacy in animal models. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ACCESS.2023.3282182,Reinforcement Learning Environment for Cyber-Resilient Power Distribution System,"Recently, numerous data-driven approaches to control an electric grid using machine learning techniques have been investigated. Reinforcement learning (RL)-based techniques provide a credible alternative to conventional, optimization-based solvers especially when there is uncertainty in the environment, such as renewable generation or cyber system performance. Efficiently training an agent, however, requires numerous interactions with an environment to learn the best policies. There are numerous RL environments for power systems, and, similarly, there are environments for communication systems. Most cyber system simulators are based in a UNIX environment, while the power system simulators are based in the Windows operating system. Hence the generation of a cyber-physical, mixed-domain RL environment has been challenging. Existing co-simulation methods are efficient, but are resource and time intensive to generate large-scale data sets for training RL agents. Hence, this work focuses on the development and validation of a mixed-domain RL environment using OpenDSS for the power system and leveraging a discrete event simulator Python package, SimPy for the cyber system, which is operating system agnostic. Further, we present the results of co-simulation and training RL agents for a cyber-physical network reconfiguration and Volt-Var control problem in a power distribution feeder.",TOPIC
10.1109/ACCESS.2023.3284990,Transmission Control in NB-IoT With Model-Based Reinforcement Learning,"In Narrowband Internet of Things (NB-IoT), the control of uplink transmissions is a complex task involving device scheduling, resource allocation in the carrier, and the configuration of link-adaptation parameters. Existing heuristic proposals partially address the problem, but reinforcement learning (RL) seems to be the most effective approach a priori, given its success in similar control problems. However, the low sample efficiency of conventional (model-free) RL algorithms is an important limitation for their deployment in real systems. During their initial learning stages, RL agents need to explore the policy space selecting actions that are, in general, highly ineffective. In an NB-IoT access network this implies a disproportionate increase in transmission delays. In this paper, we make two contributions to enable the adoption of RL in NB-IoT: first, we present a multi-agent architecture based on the principle of task division. Second, we propose a new model-based RL algorithm for link adaptation characterized by its high sample efficiency. The combination of these two strategies results in an algorithm that, during the learning phase, is able to maintain the transmission delay in the order of hundreds of milliseconds, whereas model-free RL algorithms cause delays of up to several seconds. This allows our approach to be deployed, without prior training, in an operating NB-IoT network and learn to control it efficiently without degrading its performance.",TOPIC
10.1109/ACCESS.2023.3287491,IEEE Access,"Autonomous mobile robots use computational techniques of great complexity so that to allow navigation in various types of dynamic environments, avoiding collisions with obstacles and always seeking to optimize the best route, ultimately enabling them to operate in a safe and precise manner. In order for navigation at this level to be possible, a variety of computer vision and intelligent sensing techniques are used. The potential of an intelligent computer vision system to detect and predict the actions of dynamic agents on the streets is applied to increase traffic safety with intelligent robotic vehicles. In this paper we present a systematic review of computer vision models for the detection and tracking of obstacles in traffic environments. Specifically, we cover works involving 2D and 3D (stereo vision) data fusion for both internal and external perception, as well as current trends regarding efficient model design and temporally-aware architectures. We provide a thorough discussion on the main positive and negative points of the state-of-the-art in Visual Robotic Attention, as well as share our experience and contributions in applying visual perception for external obstacle detection and tracking, and internal (driver) monitoring. The results presented should serve as a compilation of the history of visual perception for autonomous mobile robots (specifically, Advanced Driver Assistance Systems (ADAS) and Autonomous Vehicles), thus providing the reader with a comprehensive basis on both the main contributions and the state-of-the-art in the field. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ACCESS.2023.3288698,Intelligent Resource Management for eMBB and URLLC in 5G and Beyond Wireless Networks,"In the era of 5G and beyond wireless networks, the simultaneous support of enhanced Mobile Broadband (eMBB) and Ultra-Reliable Low Latency Communications (URLLC) poses significant challenges in managing radio resources efficiently. By leveraging the puncturing technique, we propose an intelligent resource management framework for meeting the strict latency and reliability requirement of URLLC services and the high data rate for eMBB services. In particular, a semi-supervised learning and deep reinforcement learning (DRL) based architecture is proposed to manage the resources intelligently. We decompose the optimization problem into two subproblems: 1) resource block allocation (RBA) strategy for eMBB slice, and 2) URLLC scheduling. Through extensive simulations and performance evaluations, we demonstrate the effectiveness of the proposed technique in optimizing resource utilization, minimizing latency for URLLC users, and maximizing the throughput for eMBB services. Simulation findings demonstrate that the proposed methodology can ensure the URLLC reliability requirements while maintaining higher average sum rate for eMBB and higher convergence rate. The proposed framework paves the way for the efficient coexistence of diverse services, enabling wireless network operators to optimize resource allocation, improve user experience, and meet the specific requirements of eMBB and URLLC applications.",TOPIC
10.1109/ACCESS.2023.3302178,An Intelligent SDWN Routing Algorithm Based on Network Situational Awareness and Deep Reinforcement Learning,"To address the challenges of obtaining network state information, flexibly forwarding data, and improving the communication quality of service (QoS) in wireless network transmission environments in response to dynamic changes in network topology, this paper introduces an intelligent routing algorithm based on deep reinforcement learning (DRL) with network situational awareness under a software-defined wireless networking (SDWN) architecture. First, comprehensive network traffic information is collected under the SDWN architecture, and a graph convolutional network-gated recurrent unit (GCN-GRU) prediction mechanism is used to perceive future traffic trends. Second, a proximal policy optimization (PPO) DRL-based data forwarding mechanism is designed in the knowledge plane. The predicted network traffic matrix and topology information matrix are treated as the DRL environment, while next-hop adjacent nodes are treated as executable actions, and action selection policies are designed for different network conditions. To guide the learning and improvement of the DRL agent’s routing strategy, reward functions of different forms are designed by utilizing network link information and different penalty mechanisms. Additionally, importance sampling steps and gradient clipping methods are employed during gradient updating to enhance the convergence speed and stability of the designed intelligent routing method. Experimental results show that this solution outperforms traditional routing methods in network throughput, delay, packet loss rate, and wireless node distance. Compared to value-function-based Dueling Deep Q-Network (DQN) routing, the convergence of the proposed method is significantly faster and more stable. Simultaneously, hardware storage consumption is reduced, and real-time routing decisions can be made using the current network state information. The source code can be accessed at https://github.com/GuetYe/DRL-PPONSA.",TOPIC
10.1109/ACCESS.2023.3302895,Renewable Energy Maximization for Pelagic Islands Network of Microgrids Through Battery Swapping Using Deep Reinforcement Learning,"The study proposes an energy management system of pelagic islands network microgrids (PINMGs) based on reinforcement learning (RL) under the effect of environmental factors. Furthermore, the day-ahead standard scheduling proposes an energy-sharing framework across islands by presenting a novel method to optimize the use of renewable energy (RE). Energy sharing across islands is critical for powering isolated islands that need electricity owing to a lack of renewable energy supplies to fulfill local demand. A two-stage cooperative multi-agent deep RL solution based on deep Q-learning (DQN) with central RL and island agents (IA) spread over several islands has been presented to tackle this difficulty. Because of its in-depth learning potential, deep RL-based systems effectively train and optimize their behaviors across several epochs compared to other machine learning or traditional methods. As a result, the centralized RL-based problem of scheduling charge battery sharing from resource-rich islands (SI) to load island networks (LIN) was addressed utilizing dueling DQN. Furthermore, due to its precise tracking, the case study compared the accuracy of various DQN approaches and further scheduling based on the dueling DQN. The need for LIN is also stochastic because of variable demand and charging patterns. Hence, the simulation results, including energy scheduling through the ship, are confirmed by optimizing RE consumption via sharing across several islands, and the effectiveness of the proposed method is validated by state and action perturbation to guarantee robustness.",TOPIC
10.1109/ACCESS.2023.3303841,MixNet: Physics Constrained Deep Neural Motion Prediction for Autonomous Racing,"Reliably predicting the motion of contestant vehicles surrounding an autonomous racecar is crucial for effective and performant ego-motion planning. Although highly expressive, deep neural networks are black-box models, making their usage challenging in this safety-critical applications of autonomous racing. On the other hand, physics-based models provide high safety guarantees for the predicted trajectory but lack accuracy. The method presented in this paper targets this trade-off. We introduce a method to predict the trajectories of opposing racecars with deep neural networks considering physical constraints to restrict the output and to improve its feasibility. We report the method’s performance against an LSTM-based encoder-decoder architecture on data acquired from multi-agent racing simulations. The proposed method outperforms the baseline model in prediction accuracy and robustness. Still, it fulfills quality guarantees of smoothness and consistency of the predicted trajectory and prevents out-of-track predictions. Thus, a robust real-world application of the model with high prediction accuracy is proven. The presented model was deployed on the racecar of the Technical University of Munich for the Indy Autonomous Challenge 2021. The code used in this research is available as open-source software at https://www.github.com/TUMFTM/MixNet.",TOPIC
10.1109/ACCESS.2023.3303873,Logarithmic Potential Field: A New Leader– Follower Robotic Control Mechanism to Enhance the Execution Speed and Safety Attributes,"The leader-follower formation approach is a commonly used strategy in multi-robot systems, usually implemented with a hierarchical control architecture combining path planning and formation control. The leader robot determines the desired trajectory while the follower robots track the motion of the leader robot using a control system. However, this hierarchical architecture does not ensure successful obstacle avoidance for follower robots. Several solutions proposed adding an obstacle avoidance layer, but this can increase the system complexity and reduce the computational speed, hindering real-time performance. Improving the opposing attributes, namely the execution speed, path length, safety, and smoothness, together is a challenging path-planning problem in robotics. This paper proposes a novel leader-follower control mechanism that combines formation control and obstacle avoidance in one step. The new path planning technique focuses on enhancing execution speed and safety while ensuring the generation of smooth paths with acceptable path lengths. The main contribution of the proposed technique lies in the development of a novel potential field modeling approach specifically designed for follower robots in a multi-robot system. The proposed potential field model consists of three terms, namely, the Gaussian term, the Euclidean term, and the Logarithmic term, which are all optimized later using Particle Swarm Optimization (PSO) to generate the path. The Gaussian term, acting as a repulsive force, represents the Gaussian distance to each obstacle in the environment. It exhibits a strong value in close proximity to obstacles, while it gradually decays exponentially as the distance from the obstacles increases. The second term, the Euclidean term, which is the Euclidean distance to the leader robot, is responsible to find the shortest path to the leader robot. Finally, to ensure follower robot safety, a logarithmic term is integrated into the potential field model, facilitating automatic switching between attractive and repulsive forces generated by the leader robot. The incorporation of a logarithmic term into the potential field model stands as a significant innovation in the proposed technique. This inclusion enables the leader robot to generate an initial attractive force towards the followers, which dynamically transitions into a repulsive force as the follower robots approach. This automatic switching behavior enhances processing efficiency while ensuring collision avoidance. A kinematic control strategy is applied to the system in order to test the proposed path planning technique. The experimental results have proven the effectiveness of the proposed system, which has shown superior performance over the well-known techniques A*, RRT*, PRM, and also Hybrid-A* in terms of execution speed and the path length.",TOPIC
10.1109/ACCESS.2023.3313725,Procedural Content Generation Using Reinforcement Learning for Disaster Evacuation Training in a Virtual 3D Environment,"This research addresses the need for effective disaster evacuation training methods by proposing a virtual reality system that utilizes Reinforcement Learning Procedural Content Generation (RL-PCG) algorithms. The aim of this study is to provide a cost-effective and safe way to conduct disaster evacuation preparedness training, surpassing the limitations of traditional real-life drills. The paper’s objectives encompass the design of a novel 3-layer PCG architecture for generating realistic disaster simulations in virtual reality, the implementation of a working prototype for fire disaster scenarios, and the evaluation of the proposed system’s effectiveness through comparison with existing RL agents. Significant findings include the superiority of the RL-PCG agent in generating diverse and realistic disaster scenarios with faster training time and lesser number of steps, even with limited processor capabilities. In conclusion, this research establishes that the RL-PCG Scenario for Disaster Evacuation Training in VR is a more effective method, leading to improved disaster preparedness for individuals, and opens avenues for further advancements in disaster training using virtual reality and reinforcement learning technologies. For a video demo of this work, please visit https://youtu.be/3WZnQOfUP94.",TOPIC
10.1109/ACCESS.2023.3323220,Graph Learning in Robotics: A Survey,"Deep neural networks for graphs have emerged as a powerful tool for learning on complex non-euclidean data, which is becoming increasingly common for a variety of different applications. Yet, although their potential has been widely recognised in the machine learning community, graph learning is largely unexplored for downstream tasks such as robotics applications. To fully unlock their potential, hence, we propose a review of graph neural architectures from a robotics perspective. The paper covers the fundamentals of graph-based models, including their architecture, training procedures, and applications. It also discusses recent advancements and challenges that arise in applied settings, related for example to the integration of perception, decision-making, and control. Finally, the paper provides an extensive review of various robotic applications that benefit from learning on graph structures, such as bodies and contacts modelling, robotic manipulation, action recognition, fleet motion planning, and many more. This survey aims to provide readers with a thorough understanding of the capabilities and limitations of graph neural architectures in robotics, and to highlight potential avenues for future research.",TOPIC
10.1109/ACCESS.2023.3326883,Reward for Exploration Based on View Synthesis,"Research on embodied-AI has flourished in recent years to make AI accessible to real-world information. Visual exploration is a very fundamental task in embodied-AI applications such as object-goal navigation, embodied questioning and answering (EQA), and rearrangement. However, it is still a challenging task. The frontier-based method is successful but it is difficult to use for reinforcement learning (RL). Moreover, it heavily relies on two-dimensional grid-map representation, therefore difficult to apply free movement in three-dimensional environments. We propose a novel reward for RGB-D camera-based exploration to maximize the amount of new information contained in the observations obtained from the camera. The basic idea of our method is to predict the destination image by view synthesis using a point cloud obtained by back-projecting depth information. The more lacks in this predicted image, the more likely it is to contain unknown information. For efficient exploration, we also propose topological map implementation to prevent the agent from repetitively visiting the same states. Our method achieves a performance of coverage of area, objects and landmarks comparable to that of state-of-the-art visual exploration methods without using two-dimensional grid maps. Furthermore, we implement object-goal navigation through integration of object detection and simple point-goal navigation, and it outperforms the task-specific RL method with the same architecture on the success rate.",TOPIC
10.1109/ACCESS.2023.3327559,USV Port Oil Spill Cleanup Using Hybrid Multi-Destination RL-CPP,"Human activities are the principal contributors to oil pollution in marine ecosystems, thereby causing severe ecological damage. The high volume of vessel traffic operating in these areas contributes to the rapid contamination of the marine ecosystem, leading to frequent oil spill events, particularly near ports where congestion is prevalent. Addressing this issue today necessitates the involvement of numerous skilled personnel committed to the task. This team undertakes the repetitive and tedious work of surveying the area, detecting spills, and employing various techniques to address each oil slick. The emergence of Unmanned Surface Vehicle (USV) technology has introduced a promising alternative capable of alleviating the process of continuous monitoring and cleaning operations in proximal shoreline areas. This paper addresses the problem of USV cleaning operations near the port. The proposed method synthesizes a hierarchical architecture that integrates traditional global path planning for multi-destination oil spills, along with coverage path planning based on reinforcement learning, to adapt to dynamically changing oil spills. This combined architecture results in a comprehensive solution, allowing navigation within the port’s vicinity to address each occurrence of oil pollution. To evaluate the effectiveness of this approach, we conducted an elaborate simulation designed to replicate port activities. The findings of this paper indicate a significant reduction in pollution levels due to USV operation and underscore the ability to acquire complex policies for dynamic coverage planning through the use of a reinforcement learning framework.",TOPIC
10.1109/ACCESS.2023.3334434,Brain Tumor Categorization and Retrieval Using Deep Brain Incep Res Architecture Based Reinforcement Learning Network,"The categorization and retrieval of brain tumors using Magnetic Resonance Imaging (MRI) is a difficult but necessary process for brain tumor diagnosis. In this study, a reinforcement learning agent is proposed that can interact with an environment that includes brain tumor images and retrieve and categorize the most comparable images to an unknown query image. This article proposes a unique fuzzy and Deep Learning (DL)-based Reinforcement Learning (RL) strategy for categorizing three types of brain tumors as well as no tumors. Deep Brain Incep Res Architecture 2.0 based Reinforcement Learning Network (DBIRA2.0-RLN), the proposed Convolutional Neural Network (CNN)-based technique, benefits from a novel architecture in which brain tumor descriptors are established using the inception block and effective skip-connection mapping arrangement. To improve the efficiency of DBIRA2.0-RLN, improved samples are created by training and testing the system with a fuzzy logic-based technique. To lower the dimension of the descriptor vector for improved image categorization and retrieval, the descriptor vector obtained from DBIRA2.0 is binary coded using Multilinear Principal Component Analysis. DBIRA2.0 produces and preserves brain tumors and no tumor descriptors in several layers, which are then used sequentially in numerous units to construct the final brain tumor categorization and retrieval. The proposed method’s output is tested using a dataset, and the accuracy rates obtained for meningioma tumor, glioma tumor, pituitary tumor, and no tumor are 97.1%, 98.7%, 94.3%, and 100% respectively, indicating that the proposed approach outperforms the other brain tumor categorization and retrieval approaches used in the literature.",TOPIC
10.1109/ACCESS.2023.3337118,Navigating the Landscape of Deep Reinforcement Learning for Power System Stability Control: A Review,"The widespread penetration of inverter-based resources has profoundly impacted the electrical stability of power systems (PSs). Deepening grid integration of photovoltaic and wind systems is introducing unforeseen uncertainties for the electricity sector. As a cutting-edge machine learning technology, deep reinforcement learning (DRL) breakthroughs have been in the spotlight over the last few years with potential contributions to PS stability (PSS). The ubiquitous DRL architecture, by learning from the dynamism inherent in PSs, produces near-optimal actions for PSS. This article provides a rigorous review of the latest research efforts focused on DRL to derive PSS policies while accounting for the unique properties of power grids. Furthermore, this paper highlights the theoretical advantages and the key tradeoffs of the emerging DRL techniques as powerful tools for optimal power flow. For all methods outlined, a discussion on their bottlenecks, research challenges, and potential opportunities in large-scale PSS is also presented. This review aims to support research in this area of DRL algorithms to embrace PSS against unseen faults and different PS topologies.",TOPIC
10.1109/ACCESS.2023.3343620,Cooperative Multi-Agent Traffic Monitoring Can Reduce Camera Surveillance,"Smart mobility initiatives encompass innovative methods to support traffic management experts in decisions for how to improve urban infrastructures and reduce carbon footprint. Accurate and continuous information about traffic is necessary to implement effectively such decisions. This is not always possible because of the cost of the information: it is not possible to install sensor devices at large scale because of financial costs and privacy; employing a plethora of sensors requires significant computational capabilities to process the generated data. A centralized data analysis can hinder real-time applications, and limit their practical deployment in traffic management systems. This paper introduces a novel privacy-aware method for estimating traffic density using edge computing and without over-deploying privacy-intrusive surveillance technologies such as cameras. The objective is to reduce the cost of collecting data while providing accurate information to support traffic operators in decision making. We evaluate the proposed solution using a realistic traffic data of Bologna in Italy. Results shows that it yields a 45% lower average estimation error compared to standard prediction methods. Virtual traffic monitoring devices are associated with software agents that collect data from simulated traffic and estimate traffic density measurements when this information is not available. In our experiments, when we replace 50% of camera devices with cooperative low-cost edge devices, we obtain an average percentage error of just 22%. This result indicates that the cooperation between virtual traffic monitoring devices offers a means to avoid massive deployment of camera surveillance devices using low-cost information provided by connected vehicles. We also compared the results to those obtained by standard regression techniques.",TOPIC
10.1109/ACCESS.2023.3347350,IEEE Access,"Tor (The Onion Routing) network was designed to enable users to browse the Internet anonymously. It is known for its anonymity and privacy security feature against many agents who desire to observe the area of users or chase users' browsing conventions. This anonymity stems from the encryption and decryption of Tor traffic. That is, the client's traffic should be subject to encryption and decryption before the sending and receiving process, which leads to delay and even interruption in data flow. The exchange of cryptographic keys between network devices plays a pivotal and critical role in facilitating secure communication and ensuring the integrity of cryptographic procedures. This essential process is time-consuming, which causes delay and discontinuity of data flow. To overcome delay or interruption problems, we utilized the Software-Defined Network (SDN), Machine Learning (ML), and Blockchain (BC) techniques, which support the Tor network to intelligently speed up exchanging the public key via the proactive processing of the Tor network security management information. Consequently, the combination network (ITor-SDN) keeps data flow continuity to a Tor client. We simulated and emulated the proposed network by using Mininet and Shadow simulations. The findings of the performed analysis illustrate that the proposed network architecture enhances the overall performance metrics, showcasing a remarkable advancement of around 55%. This substantial enhancement is achieved through the seamless execution of the innovative ITor-SDN network combination approach. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ACCESS.2024.3350556,EdgeMatch: A Smart Approach for Scheduling IoT-Edge Tasks With Multiple Criteria Using Game Theory,"For an extended period, a technological architecture known as cloud IoT links IoT devices to servers located in cloud data centers. Real-time data analytic are made possible by this, enabling better, data-driven decision making, optimization, and risk reduction. Since cloud systems are often located at a considerable distance from IoT devices, the rise of time-sensitive IoT applications has driven the requirement to extend cloud architecture for timely delivery of critical services. Balancing the allocation of IoT services to appropriate edge nodes while guaranteeing low latency and efficient resource utilization remains a challenging task. Since edge nodes have lower resource capabilities than the cloud. The primary drawback of current methods in this situation is that they only tackle the scheduling issue from one side. Task scheduling plays a pivotal role in various domains, including cloud computing, operating systems, and parallel processing, enabling effective management of computational resources. In this research, we provide a multiple-factor autonomous IoT-Edge scheduling method based on game theory to solve this issue. Our strategy involves two distinct scenarios. In the first scenario, we introduced an algorithm containing choices for the IoT and edge nodes, allowing them to evaluate each other using factors such as delay and resource usage. The second scenario involves both a centralized and a distributed scheduling approach, leveraging the matching concept and considering each other. In addition, we also introduced a preference-based stable mechanism (PBSM) algorithm for resource allocation. In terms of the execution time for IoT services and the effectiveness of resource consolidation for edge nodes, the technique we use achieves better results compared with the two commonly used Min-Min and Max-Min scheduling algorithms.",TOPIC
10.1109/ACCESS.2024.3355269,Reinforcement Learning for Two-Stage Permutation Flow Shop Scheduling—A Real-World Application in Household Appliance Production,"Solving production scheduling problems is a difficult and indispensable task for manufacturers with a push-oriented planning approach. In this study, we tackle a novel production scheduling problem from a household appliance production at the company Miele & Cie. KG, namely a two-stage permutation flow shop scheduling problem (PFSSP) with a finite buffer and sequence-dependent setup efforts. The objective is to minimize idle times and setup efforts in lexicographic order. In extensive and realistic data, the identification of exact solutions is not possible due to the combinatorial complexity. Therefore, we developed a reinforcement learning (RL) approach based on the Proximal Policy Optimization (PPO) algorithm that integrates domain knowledge through reward shaping, action masking, and curriculum learning to solve this PFSSP. Benchmarking of our approach with a state-of-the-art genetic algorithm (GA) showed significant superiority. Our work thus provides a successful example of the applicability of RL in real-world production planning, demonstrating not only its practical utility but also showing the technical and methodological integration of the agent with a discrete event simulation (DES). We also conducted experiments to investigate the impact of individual algorithmic elements and a hyperparameter of the reward function on the overall solution.",TOPIC
10.1109/ACCESS.2024.3362293,Traffic Management of Multi-AGV Systems by Improved Dynamic Resource Reservation,"Automated guided vehicles (AGVs) are widely used for material handling in warehouses and automated production lines due to their high efficiency and low failure rate with respect to human operated load carriers. However, AGVs usually interact with each other because of the restricted capacity of the layout, and conflicts arise. Although many traffic scheduling algorithms have been proposed to address the AGV fleet control problem, most of them are inefficient for collision and deadlock avoidance in dynamic environments. This paper proposes an improved dynamic resource reservation (IDRR) based method which renders time-efficient task completion and deadlock-free movements of multiple AGVs in a manufacturing system. Unlike traditional approaches, most of which adopt a dynamic single agent reservation of the shared resource points and/or force path deviations, IDRR exploits dynamic multiple reservations of shared resource points. This is combined with a conflict detection and resolution method that accommodates the AGV motions when they meet at a resource point. Extensive, realistic simulation results demonstrate the feasibility and efficiency of the proposed collision and deadlock prevention method in productivity, travelled distance, and time completion of the assigned tasks. The proposal can be implemented on both central and local controllers.",TOPIC
10.1109/ACCESS.2024.3362353,SSDWSN: A Scalable Software-Defined Wireless Sensor Networks,"In multi-hop wireless sensor networks (WSNs), sensors operate autonomously and make routing decisions independently. However, these devices are often located in remote or inaccessible areas and have limited energy and memory resources. As the network scales, efficient management to conserve resources and extend its lifetime becomes increasingly challenging. Software-defined WSNs (SDWSNs) offer a solution by enabling centralized control of low-power WSNs. However, continuously updating the controller with the network state generates significant traffic, resulting in energy loss, increased overhead, and reduced scalability and network lifetime. This study proposes a scalable SDWSN framework (SSDWSN) to address these challenges. The proposed approach focuses on scheduling, balanced routing, aggregation, and reducing traffic overhead caused by periodic network state updates to the controller. This paper presents the architecture of the proposed framework, along with the Deep Reinforcement Learning (DRL) agent. It also proposes two Proximal Policy Optimization (PPO)-based learning policies, namely PPO-ATCP and PPO-NSFP. These policies are designed to efficiently utilize SDWSN network resources and accurately predict the network state by continuously monitoring the synchronized network state within the controller, taking appropriate actions, and updating the learning parameters based on reward functions. The simulation results demonstrate the effectiveness of PPO-ATCP and PPO-NSFP in reducing controller-bound traffic overhead by 57% and 85%, respectively, while improving energy efficiency by 28% and 53% in SDWSNs. Additionally, PPO-NSFP achieved a minimum accuracy of 85% in network state prediction under different network-size scenarios.",TOPIC
10.1109/ACCESS.2024.3364352,PersoNet: A Novel Framework for Personality Classification-Based Apt Customer Service Agent Selection,"Personality classification has garnered significant interest in psychology, computational social science, and Machine Learning (ML) due to its wide-ranging applications. This paper presents PersoNet, an innovative framework developed to identify personality types using the Myers-Briggs Type Indicator (MBTI), aimed at enhancing customer service experiences by matching customers with suitable support agents. PersoNet employs a Bidirectional Long Short-Term Memory (BiLSTM) neural network architecture and has achieved an impressive classification accuracy of over 93.98%. Our extensive experiments with the MBTI dataset reveal that the BiLSTM architecture effectively captures both temporal dependencies and semantic subtleties in textual data, contributing to this high level of accuracy. Consequently, PersoNet can accurately select customer service agents who match customer personalities, achieving a Customer Satisfaction Rate (CSR) of over 97.82%–a notable improvement of 20.25% in CSR based on our experimental data. These results establish PersoNet as a cutting-edge tool in personality classification, surpassing existing methods in both accuracy and computational efficiency and markedly enhancing customer service quality.",TOPIC
10.1109/ACCESS.2024.3370922,Optimization of a Cluster-Based Energy Management System Using Deep Reinforcement Learning Without Affecting Prosumer Comfort: V2X Technologies and Peer-to-Peer Energy Trading,"The concept of Prosumer has enabled consumers to actively participate in Peer-to-Peer (P2P) energy trading, particularly as Renewable Energy Source (RES)s and Electric Vehicle (EV)s have become more accessible and cost-effective. In addition to the P2P energy trading, prosumers benefit from the relatively high energy capacity of EVs through the integration of Vehicle-to-X (V2X) technologies, such as Vehicle-to-Home (V2H), Vehicle-to-Load (V2L), and Vehicle-to-Grid (V2G). Optimization of an Energy Management System (EMS) is required to allocate the required energy efficiently within the cluster, due to the complex pricing and energy exchange mechanism of P2P energy trading and multiple EVs with V2X technologies. In this paper, Deep Reinforcement Learning (DRL) based EMS optimization method is proposed to optimize the pricing and energy exchanging mechanisms of the P2P energy trading without affecting the comfort of prosumers. The proposed EMS is applied to a small-scale cluster-based environment, including multiple (6) prosumers, P2P energy trading with novel hybrid pricing and energy exchanging mechanisms, and V2X technologies (V2H, V2L, and V2G) to reduce the overall energy costs and increase the Self-Sufficiency Ratio (SSR)s. Multi Double Deep Q-Network (DDQN) agents based DRL algorithm is implemented and the environment is formulated as a Markov Decision Process (MDP) to optimize the decision-making process. Numerical results show that the proposed EMS reduces the overall energy costs by 19.18%, increases the SSRs by 9.39%, and achieves an overall 65.87% SSR. Additionally, numerical results indicates that model-free DRL, such as DDQN agent based Deep Q-Network (DQN) Reinforcement Learning (RL) algorithm, promise to eliminate the energy management complexities with multiple uncertainties.",TOPIC
10.1109/ACCESS.2024.3373786,Greenhouse Gas Emission Reduction Architecture in Computer Science: A Systematic Review,"Computer Science Architecture (CSA), encompassing data, application, technology, and business architecture, is a vital tool for addressing climate change challenges. It aims to reduce greenhouse gas emissions from sectors such as stationary energy, transportation, industry, product use, waste, and land use. CSA principles extend to advanced technologies like artificial intelligence (AI), the Internet of Things (IoT), Machine Learning (ML), data centers, blockchain, multi-agent systems, sensors, and smart grids. This review explores CSA’s role in mitigating greenhouse gas emissions for a sustainable environment. It analyzes implications, indicators, and methodologies for data, application, technology, and business architecture, highlighting their direct impact on creating an environmentally friendly technological landscape. The study also delves into emerging trends and suggestions for future research, contributing to the discourse on leveraging technology for a greener future.",TOPIC
10.1109/ACCESS.2024.3378749,Dandelion Optimizer-Based Reinforcement Learning Techniques for MPPT of Grid- Connected Photovoltaic Systems,"The integration of photovoltaic (PV) into electric power systems has been widely explored and adopted to address the problems associated with the depletion of fossil fuels and the release of greenhouse gases. PV panels convert sunlight into electricity, minimizing the reliance on fossil fuels and mitigating environmental pollution. It is crucial to optimally utilize the PV power in the system; hence maximum power point tracking (MPPT) algorithms have been developed to ensure optimal performance of grid-connected PV systems at the maximum power point (MPP) despite changes in weather conditions. Moreover, deep reinforcement learning (DRL) developments provide a promising approach for optimizing grid-connected PV systems, replacing the conventional proportional-integral-derivative (PID) controllers. However, there is limited research evaluating the efficiency of these systems using DRL techniques. This paper proposes a new dandelion optimizer (DO)-based DRL for MPPT of grid-connected photovoltaic systems and evaluates the proposed method for a 100-MW PV plant connected to a 33-kV distribution system. The proposed DRL technique uses proximal policy optimization (PPO) and deep deterministic policy gradient (DDPG) algorithms for continuous states and discrete or continuous action spaces to adjust the PV-measured voltage based on a reference one produced via DO-PPO and DO-DDPG methods. To test the effectiveness and practicality of the introduced methods, simulations were conducted using actual input data of a 100 MW PV plant connected to a 33-kV distribution system for typical days in summer and winter seasons using MATLAB/Simulink software. The proposed implemented methods were evaluated by comparing their simulation results with other techniques: DO-PID, particle swarm optimization (PSO), and incremental conductance (InC-PI). The findings revealed that the efficiencies of the DC-DC boost and the voltage source converters using the introduced methods were 84.25%- 85.90%, and 78.33%- 81.10% on a summer day while they were 92.77%- 95% and 86.70%- 89.50% on a winter day, respectively, which proves that these methods were efficient and effective, indicating their promising potential for future applications.",TOPIC
10.1109/ACCESS.2024.3383442,Improving the Computational Efficiency of the Unit Commitment Problem in Hydrothermal Systems by Using Multi-Agent Deep Reinforcement Learning,"In power systems with a significant hydroelectric component, instances of the Unit Commitment (UC) problem may be much more computationally intensive due to the longer decision horizons and the additional hydro constraints. Therefore, this paper presents a methodology to reduce the solution space to accelerate 168-hour-ahead UC formulated as a Mixed-Integer Linear Program (MILP). First, an offline model maps environment observations to actions in a Multi-Agent Deep Reinforcement Learning (MADRL) model. This mapping uses historical power system operation data to determine the on/off status of specific generation units. Then, the online model uses the binary variable solutions obtained by the offline model to solve a UC problem with a reduced solution space. The Multi-Agent approach allows each agent, based on Artificial Neural Networks (ANN) with a Temporal Convolutional Network (TCN) architecture, to group units that are located in the same region. A shared cumulative reward function is used to adjust simultaneously the different ANN weights during the learning phase. The effectiveness of our method is demonstrated using real operational data of the Chilean National Electricity System, achieving statistically significant lower computation times and a negligible error that is within the integrality gap of the solver.",TOPIC
10.1109/ACCESS.2024.3385857,A Generalist Reinforcement Learning Agent for Compressing Convolutional Neural Networks,"Over the years, researchers have proposed multiple approaches to reduce the number of parameters Deep Learning models have. Due to the complexity of compressing models, some authors have opted to train Reinforcement Learning agents that learn how to compress a particular model without losing considerable accuracy. Nonetheless, training an agent for each model can be time-consuming. We propose a methodology for training a generalist agent capable of compressing other convolutional neural networks that it was not trained to compress. Our generalist agent uses feature maps to select which compression technique to apply to convolutional and dense layers. Since the shape of the feature maps is reduced as it goes deeper into the network, we implemented a Dueling Deep Q-Network with a Region of Interest layer, allowing it to generate features of a fixed size for feature maps of various heights and widths. Our generalist agent trained to compress two LeNet models, one trained with fashion MNIST and the other with Kuzushiji-MNIST, compressed the same architecture trained on MNIST to less than 15% of its original size with an accuracy loss of less than 2.5%.",TOPIC
10.1109/ACCESS.2024.3397495,Application of Traffic Light Control in Oversaturated Urban Network Using Multi-Agent Deep Reinforcement Learning,"Adaptive traffic signal control techniques have been developed in numerous studies to increase traffic flow efficiency. Using traffic signals to design an adaptive traffic management system is ideal for reducing traffic congestion. Reinforcement learning is a branch of current approaches that try to learn a policy function through a trial-and-error process and maximize the reward through properly adjusted interaction with the learning agent’s environment. We propose a traffic signal control architecture for an oversaturated urban network using Deep Q-Network. We have enhanced the learning process by incorporating diverse state information through upstream and downstream detailed traffic states. We conduct experiments on the Simulation of Urban MObility, an open-source traffic simulator that supports large-scale traffic signal control.",TOPIC
10.1109/ACCESS.2024.3401016,Deployment of Unmanned Aerial Vehicles in Next-Generation Wireless Communication Network Using Multi-Agent Reinforcement Learning,"To address the challenges posed by a large number of disaster-waiver-affected users and the complexities of scaling centralized algorithms for rapidly restoring emergency communication services, the paper proposes a distributed intent-based optimization architecture based on multi-agent reinforcement learning. This approach aims to mitigate service discrepancies and dynamics among users. In the network feature layer, a distributed K-sums clustering algorithm considers variations in user services. Each UAV base station autonomously and minimally adjusts the local network structure based on user requirements. It selects user features from the cluster center as input states for the multi-agent reinforcement learning neural network. In the trajectory regulation layer, the paper introduces a multi-agent maximum entropy reinforcement learning (MASAC) algorithm. The UAV base station, acting as an intelligent node, governs its flight trajectory within the framework of “distributed training – distributed execution.” The paper incorporates techniques such as integrated learning and curriculum learning to enhance training stability and convergence speed. Simulation results demonstrate the effectiveness of our distributed K-sums clustering algorithm in terms of load efficiency and cluster balance, outperforming the traditional K-means algorithm. Additionally, the UAV base station trajectory control algorithm based on MASAC significantly reduces communication interruptions, enhances network spectral efficiency, and surpasses existing reinforcement learning methods.",TOPIC
10.1109/ACCESS.2024.3406148,A Reinforcement Learning Approach to Military Simulations in Command: Modern Operations,"This paper presents a Reinforcement Learning (RL) framework for Command: Modern Operations (CMO), an advanced Real Time Strategy (RTS) game that simulates military operations. CMO challenges players to navigate tactical, operational, and strategic decision-making, involving the management of multiple units, effective resource allocation, and concurrent action assignment. The primary objective of this research is automating and enhancing military decision-making, utilizing the capabilities of RL. To achieve this goal, a parameterized Proximal Policy Optimization (PPO) agent with a unique architecture has been developed, specifically designed to address the unique challenges presented by CMO. By adapting and extending methodologies from achievements in the domain, such as AlphaStar and OpenAI Five, the agent showcases the potential of RL in military simulations. Our model can handle a wide range of scenarios presented in CMO, marking a significant step towards the integration of Artificial Intelligence (AI) with military studies and practices. This research establishes the groundwork for future explorations in applying AI to defense and strategic analysis.",TOPIC
10.1109/ACCESS.2024.3412758,Energy Consumption of Machine Learning Enhanced Open RAN: A Comprehensive Review,"The Open Radio Access Network (RAN) emerges as a revolutionary architecture promising unprecedented levels of openness, flexibility, and intelligence within radio access networks. Central to this innovation is the integration of Machine Learning (ML) and Artificial Intelligence (AI) within the RAN Intelligent Controller (RIC), aimed at optimizing network operations and enhancing control mechanisms. This paper undertakes a thorough examination of Open RAN, particularly focusing on its energy consumption aspects, which are pivotal for ensuring the sustainability of future wireless networks. In this paper, we review and compare Open RAN architecture with previous network architectures. In particular we focus on O-RAN Alliance specifications. Additionally, we explore the deployment of ML across various facets of Open RAN and highlights how to estimate the energy consumption of ML models. Through constructing explicit energy consumption models for key O-RAN components, we provide a granular analysis of their energy profiles. Finally we compare the energy dynamics of O-RAN against traditional RAN architectures, delineating the impact of virtualization and disaggregation on energy efficiency.",TOPIC
10.1109/ACCESS.2024.3422073,Multi-Operator Spectrum and MEC Resource Sharing in Next Generation Cellular Networks,"Next-generation cellular networks offer enhanced-mobile broadband, ultra-reliable low latency, and massive machine-type communications. Conventional technology may not meet these demands due to complexity and dynamicity of the network and diverse traffic requirements. To overcome these limitations, resource sharing among network operators is widely studied. The service performance can be improved by leveraging multi-access edge computing (MEC) technology. A mobile user receiving service from virtual network function at the MEC, may experience performance degradation due to lack of resources. To meet the quality of service requirements of users, this paper proposes a multi-operator spectrum and MEC resource sharing scheme. We introduce a user plane function agent at main cloud of the mobile network operator (MNO) that enables inter-operator communications and manages resource sharing requests. Service continuity is enabled by relocating users’ associated VNFs considering current resources at the edge network. The proposed scheme has been evaluated using simulations and an experimental testbed. The results show that the proposed scheme reduces network delay, improves network throughput, increases spectrum utilization, increases successful VNF placement ratio, reduces the packet drop ratio, reduces load on edge nodes, and increases revenue for the operator, compared to that of the conventional scheme.",TOPIC
10.1109/ACCESS.2024.3422135,A Patient-Specific Registration of Coronary Angiogram-Fluoroscopy by Similarity- Based Transfer Learning,"Percutaneous coronary intervention (PCI) is an effective treatment for normalizing blood flow in coronary arteries narrowed by stent implantation. Guidewire insertion during PCI requires considerable precision and expertise, and two X-ray videos, a cine loop of angiography and a real-time video of live fluoroscopy, are used to aid guidewire navigation to the target location without entering the wrong blood vessel branches. However, simultaneously watching and interpreting two radiographic videos warrants increased mental effort and intervention time. Additionally, more contrast agents may have to be injected to verify the insertion. Although deep-learning-based dynamic coronary roadmapping (DCR) has been suggested to provide registered images from two different X-ray sources, existing methods may not be suitable for irregular heartbeats or may vary in effectiveness depending on the patient, posing challenges in time-critical situations. To address these challenges, we propose a patient-specific approach for DCR using similarity-based patient data matching in transfer learning with a residual U-Net. The proposed method leverages the anatomical similarities between newly acquired and pre-acquired angiograms by utilizing principal component analysis and cosine similarity to facilitate efficient transfer learning. Moreover, a residual U-Net architecture that incorporates residual blocks and leaky ReLU activation functions to accelerate patient-specific transfer learning is proposed. These advanced techniques resulted in significantly fast transfer learning of less than five minutes from a pre-trained model, as well as high registration image quality with over 30 dB in peak signal-to-noise ratio, while maintaining a registration error of  $1.04\pm 0.19$  mm.",TOPIC
10.1109/ACCESS.2024.3424474,InDS: Intelligent DRL Strategy for Effective Virtual Network Embedding of an Online Virtual Network Requests,"Network virtualization is a demanding feature in the evolution of future Internet architectures. It enables on-demand virtualized resource provision for heterogeneous Virtual Network Requests (VNRs) from diverse end users over the underlying substrate network. However, network virtualization provides various benefits such as service separation, improved Quality of Service, security, and more prominent resource usage. It also introduces significant research challenges. One of the major such issues is allocating substrate network resources to VNR components such as virtual machines and virtual links, also named as the virtual network embedding, and it is proven to be  $\mathbb {N}\mathbb {P}$ -hard. To address the virtual network embedding problem, most of the existing works are 1) Single-objective, 2) They failed to address dynamic and time-varying network states 3) They neglected network-specific features. All these limitations hinder the performance of existing approaches. This work introduces an embedding framework called Intelligent Deep Reinforcement Learning (DRL) Strategy for effective virtual network embedding of an online VNRs (InDS). The proposed InDS uses an actor-critic model based on DRL architecture and Graph Convolutional Networks (GCNs). The GCN effectively captures dependencies between the VNRs and substrate network environment nodes by extracting both network and system-specific features. In DRL, the asynchronous advantage actor-critic agents can learn policies from these features during the training to decide which virtual machines to embed on which servers over time. The actor-critic helps in efficiently learning optimal policies in complex environments. The suggested reward function considers multiple objectives and guides the learning process effectively. Evaluation of simulation results shows the effectiveness of InDS in achieving optimal resource allocation and addressing diverse objectives, including minimizing congestion, maximizing acceptance, and revenue-to-cost ratios. The performance of InDS exhibits superiority in achieving 28% of the acceptance ratio and 45% of the revenue-to-cost ratio by effectively managing the network congestion compared to other existing baseline works.",TOPIC
10.1109/ACCESS.2024.3430865,On-Policy Versus Off-Policy Reinforcement Learning for Multi-Domain SFC Embedding in SDN/NFV-Enabled Networks,"In the software defined network (SDN)/network function virtualization (NFV)-enabled networks, service function chains (SFCs) should typically be allocated to deploy these services, which not only entails meeting the service’s Quality of Service (QoS) requirements, but also considering the infrastructure’s limitations. Although this issue has received much attention in the literature, the dynamics, intricacy, complexity and unpredictability of the issue provide several difficulties for researchers and engineers. The traditional methods (e.g., exact, heuristic, meta-heuristic, and game, etc.) are subjected to the complexity of multi-domain cloud network scenarios with dynamic network states, high-speed computational requirements, and enormous service requests. Recent studies have shown that reinforcement learning (RL) is a promising way to deal with the limitations of the traditional methods. On-policy and off-policy are two key categories in the field of RL models, and they both have promising advantages in deal with dynamic resource allocation problems. This paper contains two innovative points at two levels. Firstly, in order to deal with SFC embedding problem in dynamic multi-domain networks, a mixed Markov model combining Markov decision process (MDP) and hidden Markov model (HMM) is constructed, and the corresponding RL model-solving algorithms are proposed. Secondly, in order to distinguish the appropriate model in a given network scenario, the on-policy RL based multiple domain SFC embedding algorithm is compared with the off-policy one. The obtained simulation results show that the proposed RL algorithms can outperform the current baselines in terms of delay, load balancing and response time. Furthermore, we also point out that the off-policy based algorithm is more suitable for small-scale dynamic network scenarios, while the on-policy based algorithm is more suitable for medium to large-scale network scenarios with high convergence requirements.",TOPIC
10.1109/ACCESS.2024.3430933,IEEE Access,"With traditional autonomy systems still far from achieving level 5 autonomy, Parallel Autonomy (PA) systems demonstrate increased potential to enable driving for all, regardless of the driver's ability to perform the dynamic driving task. Their major goal is not to take away driving responsibilities from the driver but to augment the driver's skills as needed to build safe and reliable autonomy systems. This paper presents a comprehensive review of PA systems, exploring their key concepts, architectures, functionalities, and existing challenges. Terminology related to PA system and how it is different from the concepts like Mixed Autonomy and Blended Control have been addressed first. A review of relevant standards follows, highlighting the current gap in specific PA regulations and identifying potential references from existing standards in related domains. The core of the paper delves into the architecture and concepts of PA systems. The paper discusses the various levels of autonomy applicable to PA, explores the different subsystems involved (perception, planning, control, human-machine interface), and analyzes hardware and software architecture considerations. There is also an examination of the research exploring decentralized control approaches for robust and safe PA systems. Safety considerations and Verification & Validation (V&V) methods are crucial aspects addressed in this review. It presents existing safety standards and considers customized test benches and V&V approaches from research projects. While specific findings and proof-of-concept implementations may be included depending on available information, the main focus lies on presenting a comprehensive overview of the current state of PA systems and identifying key areas for future research and development, especially the topics that would need guidelines and standardization related to PA systems. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ACCESS.2024.3433589,Intelligent Parent Change to Improve 6TiSCH Network Transmission Using Multi-Agent Q-Learning,"The 6TiSCH (IPv6 over the TSCH mode of IEEE 802.15.4e) architecture for wireless sensor networks merges the time-slotted channel hopping (TSCH) at the medium access control (MAC) layer with the routing protocols tailored for low-power and lossy networks (RPL). However, research often neglects the incorporation between TSCH MAC and RPL. Standard RPL strategies rely on an objective function (OF) using the expected transmission count (ETX) metric, which does not adequately reflect the traffic dynamics. Moreover, RPL’s hysteresis function employs a static threshold to control parent change decisions. This static setting disregarded the diverse traffic patterns within the network, leading to unnecessary parent node changes and preventing the node from selecting a better parent. To overcome these shortcomings, we introduce 3 advancements to standard RPL. First, an adaptive parent-changing mechanism based on cooperative Q-learning. Second, a cell usage and traffic load aware objective function. Third, an improved initial transmission cell allocation. Those methods are collectively termed ACI-RPL. We evaluated the performance of the proposed method through simulations using the 6TiSCH simulator and real-hardware tests on the FIT IoT-Lab testbed with OpenWSN firmware. The experiment result indicates that ACI-RPL performs better than the benchmark algorithms. In comparison to the standard RPL, ACI-RPL improves the packet delivery ratio and the total received packets by 12% and 17%, respectively. Additionally, ACI-RPL reduces energy consumption and latency by 23% and 9%.",TOPIC
10.1109/ACCESS.2024.3435949,MP-TD3: Multi-Pool Prioritized Experience Replay-Based Asynchronous Twin Delayed Deep Deterministic Policy Gradient Algorithm,"The prioritized experience replay mechanisms have achieved remarkable success in accelerating the convergence of reinforcement learning algorithms. However, applying traditional prioritized experience replay mechanisms directly to asynchronous reinforcement learning leads to slow convergence, due to the difficulty for an agent to utilize excellent experiences obtained by other agents interacting with the environment. To address the above issue, we propose a Multi-pool Prioritized experience replay-based asynchronous Twin Delayed Deep Deterministic policy gradient algorithm (MP-TD3). Specifically, a multi-pool prioritized experience replay mechanism is proposed to strengthen the experience interactions among different agents to accelerate the network convergence. Then, a global-pool self-cleaning mechanism based on sample diversity and a global-pool self-cleaning mechanism based on TD-errors are designed to overcome the deficiency that the samples suffer from high redundancy and low information content in the global-pool, respectively. Finally, a multi-batch sampling mechanism is investigated to further reduce the training time. Extensive experiments validate that the proposed MP-TD3 significantly improve the convergence speed and performance compared with state-of-the-art methods.",TOPIC
10.1109/ACCESS.2024.3441242,Massively High-Throughput Reinforcement Learning for Classic Control on GPUs,"This study presents a novel massively high-throughput reinforcement learning (RL) framework specifically designed for addressing classic control problems, leveraging our proposed architecture and algorithms optimized for efficient concurrent computations on GPUs. Our research demonstrates the effectiveness of our methods in efficiently training RL agents across various classic control problems, encompassing both discrete and continuous domains, while achieving rapid and stable performance up to 10K concurrent environment instances. Furthermore, we observe that RL exploration with a large number of parallel instances significantly enhances the stability of updating a shared model. For instance, we show that the stability of Deep Deterministic Policy Gradient (DDPG) training can be achieved without requiring experience replay, as evidenced in our study.",TOPIC
10.1109/ACCESS.2024.3454810,Task Offloading and Resource Allocation in an RIS-Assisted NOMA-Based Vehicular Edge Computing,"With the rise of intelligent transportation (ITS), autonomous cars, and on-the-road entertainment and computation, vehicular edge computing (VEC) has become a primary research topic in 6G and beyond communications. On the other hand, reconfigurable intelligent surfaces (RIS) are a major enabling technology that can help in the task offloading domain. This study introduces a novel VEC architecture that incorporates non-orthogonal multiple access (NOMA) and reconfigurable intelligent surfaces (RIS), where vehicles perform binary or partial computation offloading to edge nodes (eNs) for task execution. We construct a vehicle-to-infrastructure (V2I) transmission model by considering vehicular interference and formulating a joint task offloading and resource allocation (JTORA) problem with the goal of reducing total service latency and energy usage. Next, we decompose this problem into task offloading (TO) problem on the vehicle side and resource allocation (RA) problem on the eN side. Specifically, we describe offloading decisions and offloading ratios as a decentralized partially observable Markov decision process (Dec-POMDP). Subsequently, a multi-agent distributed distributional deep deterministic policy gradient (MAD4PG) is proposed to solve the TO problem, where every vehicular agent learns the global optimal policy and obtains individual decisions. Furthermore, a whale optimization algorithm (WOA) is used to optimize the phase shift coefficient of the RIS. Upon receiving offloading ratios and offloading decisions from vehicles, edge nodes utilize the Lagrange multiplier method (LMM) and Karush-Kuhn-Tucker (KKT) conditions to address the RA problem. Finally, we design a simulation model based on real-world vehicular movements. The numerical results demonstrate that, compared to previous algorithms, our proposed approach reduces the overall delay and energy consumption more effectively.",TOPIC
10.1109/ACCESS.2024.3457753,Robust Model Selection for Plant Leaf Image Recognition Based on Evolutionary Ant Colony Optimization With Learning Rate Schedule,"Selecting optimal deep learning models is often a time-consuming process. To address this challenge, we propose a novel variant of the ant colony optimization (ACO) algorithm. This approach is designed to enhance model selection across various deep learning architectures, with a particular focus on leaf classification tasks. We introduce a new ACO technique specifically tailored for selecting robust models within convolutional neural networks (CNNs). These models are then integrated into an ensemble learning framework known as ensemble CNNs. A distinguishing feature of our proposed evolutionary ACO algorithm is its ability to consistently identify a set of robust CNN models in each iteration. This capability is facilitated by an innovative fitness function and an adaptive learning rate schedule embedded within the ACO algorithm, which optimizes pheromone distribution. Unlike the original ACO algorithm, which consistently selects the same CNN model, our evolutionary approach enables the dynamic discovery of new CNN models. To validate our method, we conducted experiments on two plant leaf datasets: Mulberry and Turkey-plant. Our comparison with existing methods, specifically the ant colony system (ACS) and the max-min ant system (MMAS), demonstrated that the MMAS algorithm outperformed the ACS algorithm. Furthermore, we explored three ensemble learning techniques: unweighted average, weighted average, and cost-sensitive learning. The weighted average method emerged as the most effective ensemble approach, with its parameters determined through a grid search process. The results indicate that the evolutionary ACO algorithm not only facilitates the selection of robust deep learning models but also achieves superior performance compared to the original ACO algorithm when applied to the Mulberry leaf and Turkey-plant datasets.",TOPIC
10.1109/ACCESS.2024.3457863,A Generalist Reinforcement Learning Agent for Compressing Multiple Convolutional Networks Using Singular Value Decomposition,"Deep learning models have gained popularity in the last decade for computer vision tasks. Although these models are widely used, they process data in cloud services due to requiring large amounts of memory unavailable on consumer devices. Multiple techniques have been proposed to reduce the memory needed for these models. Nonetheless, finding the best method to compress each model can be a time-consuming process as the parameters of these techniques significantly affect the results. We propose a methodology for training a reinforcement learning model that exploits similarities between models to select how to compress other models it has not seen before. By reusing the generalist agent and exploiting the similarities, searching for how to compress a new model can be avoided. The agent receives a set of feature maps and compresses a model by choosing the percentage of singular values to use in a low-rank factorization of the weights of each layer. We chose the feature maps by generating an embedding for all the images and selecting the most representative image of each class. Our agent trained to compress two models, the first trained using fashion MNIST, whereas the second, using Kuzushiji-MNIST, reduced a model trained on MNIST to 15% of its original size with minimal accuracy loss. Reusing the generalist agent permitted us to skip 4.6 days of searching for a solution for MNIST.",TOPIC
10.1109/ACCESS.2024.3473611,End-to-End Autonomous Driving in CARLA: A Survey,"Autonomous Driving (AD) has evolved significantly since its beginnings in the 1980s, with continuous advancements driven by both industry and academia. Traditional AD systems break down the driving task into smaller modules—such as perception, localization, planning, and control– and optimizes them independently. In contrast, end-to-end models use neural networks to map sensory inputs directly to vehicle controls, optimizing the entire driving process as a single task. Recent advancements in deep learning have driven increased interest in end-to-end models, which is the central focus of this review. In this survey, we discuss how CARLA-based state-of-the-art implementations address various issues encountered in end-to-end autonomous driving through various model inputs, outputs, architectures, and training paradigms. To provide a comprehensive overview, we additionally include a concise summary of these methods in a single large table. Finally, we present evaluations and discussions of the methods, and suggest future avenues to tackle current challenges faced by end-to-end models.",TOPIC
10.1109/ACCESS.2024.3473792,Collaborative Autonomous Navigation of Quadrotors in Unknown Outdoor Environments: An Active Visual SLAM Approach,"The development of an integrated path-planning and Simultaneous Localization and Mapping (ASLAM) system, specifically designed for the autonomous and real-time guidance of quadrotors navigating through unexplored outdoor environments helps to map the generation of unknown natural resources. To achieve this goal, a path-planning methodology that leverages system observability is exploited for a quadrotor. This path-planning method is underpinned by the eigenvalues of the Gramian matrix, which are used as a measure of system observability degree, to increase the precision of the quadrotor’s estimated position. In SLAM, high accuracy in the quadrotor’s state estimation improves the accuracy of the map landmarks position estimation. To enhance the accuracy and fortify system robustness, implementing a centralized distributed architecture within a group of three quadrotors is advocated. In this setup, the role of a central hub for information fusion from all agents and determining the most observable path for the entire group is assigned to the leader quadrotor. An assessment of the proposed path-planning method against a random path-planning approach within a single-agent architecture is conducted across various scenarios. This evaluation compares the Root Mean Square Error (RMSE) of the quadrotor’s state estimation. The results illustrate a notable improvement in accuracy. Furthermore, a comparison is conducted to assess the performance of the multi-agent architecture in contrast to the single-agent architecture using the proposed method. The simulation and experimental results confirm a better accuracy in all scenarios and highlight the increased robustness of the cooperative architecture, particularly in fault scenarios, compared to a single-agent architecture.",TOPIC
10.1109/ACCESS.2024.3486354,Using Graph Neural Networks in Reinforcement Learning With Application to Monte Carlo Simulations in Power System Reliability Analysis,"This paper presents a novel method for power system reliability studies that combines graph neural networks with reinforcement learning. Monte Carlo methods are the backbone of probabilistic power system reliability analyses. Recent efforts from the authors indicate that optimal power flow solvers could potentially be replaced with the policies of deep reinforcement learning agents, to obtain significant speedups of Monte Carlo simulations while retaining close to optimal accuracies. However, a limitation of that reinforcement learning approach was that the training of the agent is tightly connected to the specific case being analyzed, and the agent cannot be used as is in new, unseen cases. In this paper, we seek to overcome these issues by representing the state and actions in the power reliability environment by features in a graph, where the adjacency matrix can vary from time step to time step. By combining this with a message-passing graph neural network-based reinforcement agent, we are able to train an agent where the agent model is independent of the power system grid structure. For the actor part of this architecture, we have implemented both a deterministic agent being a variant of the Twin Delayed DDPG-algorithm, and a stochastic agent with similarities to the Soft Actor Critic-algorithm. We show that the agent can solve small extensions of a test case without having seen the new parts of the power system during training. In all of our reliability Monte Carlo simulations using this graph neural network agent, the simulation time is competitive with that based on optimal power flow, while still retaining close to optimal accuracy.",TOPIC
10.1109/ACCESS.2024.3486916,A Consensus-Based Current Sharing Algorithm for Energy Storage Systems: An Application to Aeronautic Microgrids,"More Electric Aircraft (MEA) and All Electric Aircraft (AEA) require advanced autonomous electric Energy Management Systems (EMS) onboard the aircraft. The aircraft electric network can be considered as an islanded microgrid, and as such some approaches typical of the microgrid management can be used onboard the aircraft to design an effective EMS. In particular, distributed control with consensus techniques represents a promising approach due to the advantages in terms of reliability, computational simplicity and low-bandwidth requirement which are of great interest for implementation onboard. A consensus-based solution to the problem of coordinating and balancing several Energy Storage Systems (ESSs) coexisting in a generic aircraft architecture is proposed and analyzed. The proposed algorithm selects the current setpoints for each ESS according to their state of charge while ensuring safety of operations. Theoretical results and detailed simulations show the effectiveness of the proposed approach.",TOPIC
10.1109/ACCESS.2024.3487152,Hierarchical Reinforcement Learning for Submarine Torpedo Countermeasures and Evasive Manoeuvres,"Modern naval warfare environment is becoming increasingly complex, with acoustic-based torpedoes being the most significant threat to submarines. It is essential to develop advanced technologies to enhance submarine survival rates. In this paper, we propose a hierarchical multi-agent reinforcement learning scheme and a realistic underwater simulation environment for optimal submarine torpedo countermeasures and evasive manoeuvres. Our hierarchical model consists of high-level and low-level agents. The high-level agent decides on decoy launches, while the low-level agent executes specific torpedo countermeasures and evasive manoeuvres. We implement underwater simulation environment based on a 6-DOF motion model to realistically simulate underwater object movements and use PID control for accurate and stable physics. This database is used for active and passive SONAR detection of torpedoes and submarines, enhancing the realism of the acoustic environment. We designed 4-level metrics to systematically analyze model performance in static and dynamic environments with single and multiple torpedo scenarios. Also, we propose a new training methodology to address delayed and sparse reward problems by considering submarine manoeuvring characteristics. Experimental results show that our proposed hierarchical architecture demonstrates competitive performance, achieving a survival rate of 89.07% even in the most complex dynamic environment. We demonstrate improved submarine torpedo countermeasures and evasive manoeuvre performance through stable training in complex underwater environments.",TOPIC
10.1109/ACCESS.2024.3494872,Lightweight Self-Supervised Monocular Depth Estimation Through CNN and Transformer Integration,"Self-supervised monocular depth estimation is a promising research area due to its ability to train models without relying on expensive and difficult-to-obtain ground truth depth labels. In this domain, models often employ Convolutional Neural Networks (CNNs) and Transformers for feature extraction. While CNNs excel at capturing local features, they struggle with global information due to their limited receptive field. On the other hand, Transformers can capture global features but are computationally expensive. To balance performance and computational efficiency, this paper proposes a lightweight self-supervised monocular depth estimation model that integrates CNN and Transformer architectures. The model introduces an Agent Attention mechanism to effectively model global context while significantly reducing computational complexity. Furthermore, spatial and channel restructured convolution techniques are utilized to minimize the computational cost associated with redundant feature extraction in visual tasks. Validation on the KITTI dataset shows that the model reaches an Absolute Relative Error of 0.104 and a Squared Relative Error of 0.757 while maintaining a nearly constant number of parameters. The accuracy improved to 0.889, with computational complexity (FLOPs) reduced to 4.993G, and training time decreased from 15.5 hours to 13.5 hours. The model also demonstrated strong generalization on the Make 3D dataset, with only 3.0M parameters and low computational complexity, indicating its suitability for resource-constrained devices.",TOPIC
10.1109/ACCESS.2024.3497589,Knowledge Transfer in Deep Reinforcement Learning via an RL-Specific GAN-Based Correspondence Function,"Deep reinforcement learning has demonstrated superhuman performance in complex decision-making tasks, but it struggles with generalization and knowledge reuse—key aspects of true intelligence. This article introduces a novel approach that modifies Cycle Generative Adversarial Networks specifically for reinforcement learning, enabling effective one-to-one knowledge transfer between two tasks. Our method enhances the loss function with two new components: model loss, which captures dynamic relationships between source and target tasks, and Q-loss, which identifies states significantly influencing the target decision policy. Tested on the 2-D Atari game Pong, our method achieved 100% knowledge transfer in identical tasks and either 100% knowledge transfer or a 30% reduction in training time for a rotated task, depending on the network architecture. In contrast, using standard Generative Adversarial Networks or Cycle Generative Adversarial Networks led to worse performance than training from scratch in the majority of cases. The results demonstrate that the proposed method ensured enhanced knowledge generalization in deep reinforcement learning.",TOPIC
10.1109/ACCESS.2024.3505678,Leveraging Transfer Learning in Deep Reinforcement Learning for Solving Combinatorial Optimization Problems Under Uncertainty,"In recent years, addressing the inherent uncertainties within Combinatorial Optimization Problems (COPs) reveals the limitations of traditional optimization methods. Although these methods are often effective in deterministic settings, they may lack flexibility and adaptability to navigate the uncertain nature of real-world COP/s. Deep Reinforcement Learning (DRL) has emerged as a promising approach for dynamic decision-making within these complex environments. Yet, the application of DRL in solving COP/s highlights key limitations for the generalization process across various problem instances without extensive retraining and customization for each new variant, leading to notable computational costs and inefficiencies. To address these challenges, this paper introduces a novel framework that combines the adaptability and learning capabilities of DRL with the efficiency of Transfer Learning (TL) and Neural Architecture Search. This framework enables the leveraging of knowledge gained from solving COP/s to enhance the solving of different but related COP/s, thereby eliminating the necessity for retraining models from scratch for each new problem variant to be solved. The framework was evaluated on over 1,500 benchmark instances across 10 stochastic and deterministic variants of the vehicle routing problem. Across extensive experiments, the approach consistently improves solution quality and computational efficiency. On average, it achieves at least a 5% improvement in solution quality and a 20% reduction in CPU time compared to state-of-the-art methods, with some variants showing even more substantial gains. For large-scale instances over 200 customers, the TL process requires only 10-15% of the time needed to train models from scratch, while maintaining solution quality, laying the groundwork for future research in this area.",TOPIC
10.1109/ACCESS.2024.3507569,A Novel Multiagent Collaborative Learning Architecture for Automatic Recognition of Mudstone Rock Facies,"Recognizing mud rock lithofacies is essential for mapping the subsurface depositional environments and identifying oil and gas-bearing rock formations. Conventional well logs interpretation techniques are slow, costly and require high domain expertise. Machine learning (ML) techniques have been implemented to automate the recognition of lithofacies from the bulk of well logs generated. However, the reservoir heterogeneity and uneven thickness of rock layers result in imbalanced data conditions that make the ML models biased. This study proposes a novel multiagent collaborative learning architecture (MCLA) to handle the imbalanced data problem during the identification of lithofacies. This research investigates four popular data resampling techniques, i.e. oversampling, SMOTE and ADASYN. Also, resampling techniques are combined with nine different ML classifiers, including Decision tree, ExtraTree, Random Forest, Logistic regression, Support vector machine, K-nearest Neighbour, Naïve Bayes and Ensemble methods. Stacking and voting ensembles combine the outcomes of diverse classifiers working as team members in MCLA. ADASYN, in combination with Stacking, has produced impressive results in terms of accuracy (99.41%) along with MCC (0.98) and G-mean (0.98). The proposed MCLA shows an enhancement of 2% in lithofacies accuracy and an approximately 4% increment in reliability compared with the top-performing Extra Tree classifier considered in this study.",TOPIC
10.1109/ACCESS.2024.3507829,Intent-Based Network Resource Orchestration in Space-Air-Ground Integrated Networks: A Graph Neural Networks and Deep Reinforcement Learning Approach,"The Space-Air-Ground Integrated Network (SAGIN) offers a promising solution for seamless connectivity, high data rates, and wide-area coverage. However, its multi-segment architecture poses significant challenges in efficient resource management and Quality of Service assurance across diverse services. To address these challenges, we propose an Intent-Based Networking (IBN) system that streamlines network automation within the SAGIN ecosystem. Our system model integrates an IBN module with the SAGIN infrastructure, allowing network operators to express their service intents, such as Low-Latency Virtual Network Requests (LLVNRs) and High-Bandwidth Virtual Network Requests (HBVNRs), along with their respective QoS requirements. To tackle the inherent complexity, we employ a Deep Deterministic Policy Gradient (DDPG) based DRL-IBN framework. The DRL agent interacts with the SAGIN environment using a feature matrix extracted via Graph Neural Network (GNN), facilitating informed decision-making for resource allocation based on VNR acceptance. Through extensive simulations and numerical evaluations, we demonstrate the superiority of our proposed DRL-IBN algorithm over baseline approaches, such as LC-VNE and RW-MM-SP, in maximizing system utility, ensuring QoS satisfaction, and enabling efficient resource utilization in the dynamic and heterogeneous SAGIN environment. Our results indicate that the DRL-IBN framework achieves higher VNR acceptance ratios, better resource utilization, and more effective QoS assurance based on minimum QoS violation, proving its effectiveness and robustness in managing the complexities of the SAGIN network.",TOPIC
10.1109/ACCESS.2024.3508030,IEEE Access,"The unprecedented technological advancements in Artificial Intelligence (AI) and the Internet of Things (IoT) have given rise to ecosystems of intelligent, interconnected devices, forming the Artificial Intelligence of Things (AIoT). These systems, due to security and privacy concerns, necessitate solutions that adhere to the data-driven learning paradigm of Federated Learning (FL) while simultaneously addressing data and resource heterogeneity. This survey, which focuses on smart environments within the transportation, agriculture, manufacturing, and medical sectors, begins with an in-depth review of FL methods and multimodal data-driven learning methodologies. Subsequently, various sensor modalities employed in these environments are presented, as well as the most common multimodal data fusion strategies and their associated fusion operators. The study then explains its shift in focus from data-level to model-level cooperation, delving into multimodal FL (MMFL) systems by categorizing architectures, data processing methods, and model aggregation rules. Emphasis is given to the case of heterogeneous MMFL, as it is identified as the most promising and relatively novel direction that has received insufficient attention due to its recent emergence. The paper introduces a novel classification of the strategies employed when agents have different sensing modalities and model architectures, offering an in-depth analysis of how various fusion approaches can be adapted to accommodate the diversity in data and models. Finally, it examimes the utilization of MMFL in the four application domains and concludes with an analysis of open challenges and future research directions in this promising field. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ACCESS.2024.3514079,MathVision: An Accessible Intelligent Agent for Visually Impaired People to Understand Mathematical Equations,"2.2 billion people worldwide suffer from some form of vision impairment, according to the World Health Organization. Children with vision impairment and visual impairment may experience impaired physical, linguistic, and cognitive development, resulting in reduced levels of academic accomplishment. Many visually impaired people are working in the education sector whether they are students or teachers. Without external assistance reading of mathematical equations in images for visually impaired people is very challenging due to the complexity of notations, symbols, and variables. This paper presents a model named MathVision which converts the mathematical equation into voice. This voice is quite helpful for visually impaired people to understand mathematical equations. The proposed model is comprised of YOLOv7 object detection architecture to detect and categorize mathematical equations inside images into four distinct types: limits, trigonometry, integration, and an additional category. The input image is divided into a grid by the YOLOv7 model, and each grid cell is responsible for finding equations that fall into its respective category. bounding box coordinates, object labels, and probability scores are predicted for each equation. In the next stage, a fine-tuned DenseNet is utilized for detailed feature extraction from mathematical equation images. This involves optimizing a pre-trained DenseNet model to capture intricate patterns specific to equations. The fine-tuned DenseNet enhances overall accuracy in equation detection and categorization within the system. In the subsequent phase, an attention mechanism-based LSTM network is employed to generate natural language descriptions for mathematical equations. During the decoding process, the model is better able to focus on pertinent portions of the equation due to the integration of attention. The LSTM architecture, chosen for its effectiveness with sequential data, is trained on a dataset containing paired examples of equations and corresponding human-generated descriptions. Fine-tuning includes optimizing hyperparameters for the task, and evaluation metrics such as the BLEU score are used to assess the model’s performance in generating accurate and contextually relevant textual representations for the detected mathematical content. Our text-to-speech system takes input in the form of a natural language sentence generated by the LSTM model and converts it to the voice. This TTS using natural language processing analyzes and processes the text then it converts this processed text into speech using digital signal processing technology. A platform-independent pyttsx3 python library is used for converting text into speech. It also works offline which is the main reason for using this library in this research work. As there was no dataset available of mathematical equations with their natural language description, we created a custom dataset. We conducted real-world experiments in various visually impaired schools to see whether visually impaired students can understand mathematical equations by hearing the voice. These experiments prove that the MathVision Model is an efficient way for visually impaired students to read and write mathematical equations by listening to the voice of equations generated by proposed model.INDEX TERMS Mathematical equations, fine-tuned, YOLO v7, convolution neural network, attention mechanism, long short term memory, neural text to speech, technological development.",TOPIC
10.1109/ACCESS.2024.3516517,Efficient Integration of Reinforcement Learning in Graph Neural Networks-Based Recommender Systems,"Recommendation systems have advanced significantly in recent years, achieving greater accuracy and relevance. However, traditional approaches often suffer from a mismatch between the losses used during training and the metrics used for evaluation. Models are typically trained to minimize a loss function, while their effectiveness during testing is assessed using different ranking metrics, leading to suboptimal recommendation quality. To address this limitation, reinforcement learning (RL) has emerged as a promising solution. Although RL has been applied in recommendation systems, the integration of graph neural networks (GNNs) within this framework remains underexplored. In this study, we bridge this gap by integrating GNNs and RL to enhance ranking accuracy and recommendation quality. We propose two key innovations: 1) leveraging learnable graphs to embed user-item interactions, with RL optimizing user rewards to improve ranking quality, and 2) modifying GNN architectures with skip connections to enhance recommendation accuracy while reducing training time and improving convergence. Our comprehensive analysis on multiple real-world datasets demonstrates the impact of different GNN architectures and their modifications on the effectiveness of recommendation systems. Our findings demonstrate the potential of combining GNNs and RL to overcome the limitations of traditional recommendation models and achieve state-of-the-art performance, with XSimGCL-skip achieving an average improvement of approximately 2.5% over baseline methods.",TOPIC
10.1109/ACCESS.2024.3518562,DeepAir: A Multi-Agent Deep Reinforcement Learning-Based Scheme for an Unknown User Location Problem,"Unmanned Aerial Vehicles (UAVs) are a major component in next-generation network architecture proposals, playing a critical role in problems like dynamic capacity enhancement, user coverage, and task offloading. When smart utilization of the UAVs is missing, these proposals may require sophisticated approaches, including the deployment of additional edge servers and orchestration efforts. A typical challenge arises from the dynamic nature of real-world problems in which the required capacity should be provided at particular times when fixed infrastructure proves insufficient. One of those existing dynamic problems is the unknown user locations in an infrastructure-less environment in which users cannot connect to any communication device or computation-providing server, which is essential to task offloading in order to achieve the required quality of service (QoS). Therefore, in this study, we investigate this problem thoroughly and propose a novel deep reinforcement learning (DRL) based scheme, DeepAir. DeepAir uses four main phases including sensing, localization, resource allocation, and multi-access edge computing (MEC) to provide the corresponding QoS requirements for the offloaded tasks without violating the maximum tolerable delay. To this end, we use two types of UAVs including detector UAVs, and serving UAVs. We utilize detector UAVs as DRL agents which ensure the sensing, localization, and resource allocation phases. On the other hand, we utilize serving UAVs to provide MEC features. Our experiments show that DeepAir provides higher task success rates by deploying fewer detector UAVs in different scenarios with different numbers of users and user attraction points compared to benchmark methods. Thus, DeepAir achieves 59.65%, 86.06%, and 86.72% task success rates for 2, 4, and 6 detector UAVs, respectively, by using 12 serving UAVs, while the most successful benchmark method provides 28.62%, 41.39%, and 61.09% task success rates for the same configuration, respectively.",TOPIC
10.1109/ACCESS.2024.3521124,DeepTwin: A Deep Reinforcement Learning Supported Digital Twin Model for Micro-Grids,"This paper presents the development and application of a Digital Twin (DT) model for the optimization of micro-grid operations. With the increasing integration of renewable energy resources (RERs) into power grids, micro-grids are essential for enhancing grid resilience and sustainability. The proposed DT model, enhanced with Deep Reinforcement Learning (DRL), simulates and optimizes key micro-grid functions, such as battery scheduling and load balancing, to improve energy efficiency and reduce operational costs. The model incorporates real-time monitoring, service-oriented simulations, cloud-based deployments, “what-if” analyses, advanced data analytics, and security features to enable comprehensive management of DTs. An optimization scenario was conducted to evaluate the effectiveness of the DT and DRL in improving micro-grid performance. The results demonstrated significant revenue improvements: 81.7% for PPO and 56.12% for SAC compared to the baseline. These findings highlight both the promising potential of DT technology and the critical importance of incorporating DRL techniques into the DTs to improve system performance and resilience.",TOPIC
10.1109/ACCESS.2024.3523637,"Studying Forgetting in Faster R-CNN for Online Object Detection: Analysis Scenarios, Localization in the Architecture, and Mitigation","Online Object Detection (OOD) requires learning new object categories from a stream of images, similar to an agent exploring new environments. In this context, the widely used architecture Faster R-CNN (Region Convolutional Neural Network) faces catastrophic forgetting: the acquisition of new knowledge leads to the loss of previously learned information. In this paper, we investigate the learning and forgetting mechanisms of Faster R-CNN in OOD through three main contributions. First, we observe that the forgetting curves of the Faster R-CNN exhibit patterns similar to those described in human memory studies by Hermann Ebbinghaus: knowledge is lost exponentially over time and recall improves knowledge retention. Second, we present a new methodology to analyse the Faster R-CNN architecture and quantify forgetting across the Faster R-CNN components. We show that forgetting is mainly localised in the Softmax classification layer. Finally, we propose a new training strategy for OOD called Configurable Recall (CR). CR performs recalls on old data using images stored in a memory buffer with variable frequency and recall length to ensure efficient learning. CR also masks the logits of old objects in the softmax classification layer to mitigate forgetting. We evaluate our strategy against state-of-the-art methods on three OOD benchmarks. We analyse the effectiveness of different types of recall in mitigating forgetting and show that CR outperforms existing methods.",TOPIC
10.1109/ACCESS.2025.3526619,A Novel Attention-Guided Enhanced U-Net With Hybrid Edge-Preserving Structural Loss for Low-Dose CT Image Denoising,"Computed Tomography (CT) scan, pivotal for medical diagnostics, involves exposure to electromagnetic radiation, potentially elevating the risk of leukemia and cancer. Low-dose CT (LDCT) imaging has emerged to mitigate these risks, extensively reducing radiation exposure by up to 86%. However, it significantly reduces the quality of LDCT images and introduces noise and artifacts, degrading the diagnostic accuracy of the Computer Aided Diagnostic (CAD) system. This study presents a novel U-Net architecture, featuring several key enhancements. The model integrates residual blocks to improve feature representation and employs a custom hybrid loss function that combines structural loss with gradient regularization using the Euclidean norm, promoting superior CT image quality retention. Additionally, incorporating Attention Gates in the up-sampling layers of a proposed model optimizes the extraction of critical features, ensuring more precise denoising of CT images. The proposed model undergoes iterative training, using a custom loss function to refine its parameters and improve CT image denoising progressively. Its performance is rigorously evaluated both qualitatively and quantitatively on the ‘2016 Low-dose CT AAPM Grand Challenge dataset’. The results, assessed through the metrics Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index Measure (SSIM), and Root Mean Square Error (RMSE), demonstrated promising improvements compared to state-of-the-art techniques. The model effectively reduces noise while preserving critical fine details, establishing itself as a highly efficient solution for LDCT image denoising.",TOPIC
10.1109/ACCESS.2025.3528878,Exploration Degree Bias: The Hidden Influence of Node Degree in Graph Neural Network-Based Reinforcement Learning,"Graph Neural Networks (GNNs) have demonstrated remarkable performance in tasks involving graph-structured data, but they also exhibit biases linked to node degrees. This paper explores a specific manifestation of such bias, termed Exploration Degree Bias (EDB), in the context of Reinforcement Learning (RL). We show that EDB arises from the inherent design of GNNs, where nodes with high or low degrees disproportionately influence output logits used for decision-making. This phenomenon impacts exploration in RL, skewing it away from mid-degree nodes, potentially hindering the discovery of optimal policies. We provide a systematic investigation of EDB across widely used GNN architectures—GCN, GraphSAGE, GAT, and GIN—by quantifying correlations between node degrees and logits. Our findings reveal that EDB varies by architecture and graph configuration, with GCN and GIN exhibiting the strongest biases. Moreover, analysis of DQN and PPO RL agents illustrates how EDB can distort exploration patterns, with DQN exhibiting EDB under low exploration rates and PPO showing a partial ability to counteract these effects through its probabilistic sampling mechanism. Our contributions include defining and quantifying EDB, providing experimental insights into its existence and variability, and analyzing its implications for RL. These findings underscore the need to address degree-related biases in GNNs to enhance RL performance on graph-based tasks.",TOPIC
10.1109/ACCESS.2025.3530391,An Open-Source Multi-Robot Framework System for Collaborative Environments Based on ROS2,"Despite the rise of robotics and automation in industrial applications, the widespread adoption of collaborative robotics still needs to be improved due to the lack of interoperability between robots and the low adaptability of existing systems. Solving this problem would mean a significant advance in robotics and industrial automation. Under this context, an open-source MultiRobot Framework based on ROS2 was developed in the present research to effectively communicate and coordinate robotics agents and sensors in closed collaborative environments. A simulation-based control and software design was performed using the GAZEBO tool. A centralized architecture was obtained with an autonomous navigation module for the planning and robot routes monitoring, a computer vision module for the location and management of uncertainties, and a task controller module to assign mobilization mission objects. In conclusion, using ROS2 to communicate and coordinate various mechatronic systems effectively results in a robust, flexible, and scalable solution critical to industrial processes.",TOPIC
10.1109/ACCESS.2025.3532797,"Semantic Communication Empowered 6G Networks: Techniques, Applications, and Challenges","With the explosion of intelligent network applications and the prosperity of artificial intelligence (AI) technologies, the sixth generation (6G) wireless networks are not only expected to further improve network capacity, but also anticipated to establish a new architecture of “Intelligent Connectivity of Everything”. Semantic communication (SC) is a promising solution for future 6G networks due to its natural capability of integrating application requirements and information meaning into data transmission processes. In this paper, a comprehensive survey that overviews how SC can be applied for 6G networks and the key technologies of SC is presented. For this purpose, we first provide a detailed overview of the concepts of semantic information (SI) and SC, as well as the classifications of SC. Then, we present the vision of mutual support between SC technologies and 6G networks, as well as the potential benefits using SC for 6G applications. To achieve the benefits of SC, the fundamental theories and four important technologies in SC are thoroughly investigated, which are SC system architecture design, SI extraction, SI transmission, and SC performance evaluation. Then, we introduce open problems and potential research directions pertaining to SC. In a nutshell, this paper provides a holistic review of concepts, applications, fundamentals, key technologies, existing challenges, and open issues of SC tailored to the requirements of 6G networks.",TOPIC
10.1109/ACCESS.2025.3535870,IEEE Access,"In the Internet of Things (IoT) networks, sensors, gateways, and services interoperate at different levels to provide services to the end users. IoT networks are deployed in different domains for specific tasks that can be monitored from remote locations. The increase in the number of IoT-connected devices and their notable limited computational power calls for resource-efficient and in-between layers of task processing on the network. In this study, we utilized deep reinforcement learning to intelligently model the offloading policies as Markov Decision Process (MDP) for IoT devices in a distributed manner by considering IoT devices as agents that make offloading decisions taking into account the environmental dynamics. To attain optimal policy in the learning process that caters to high dimensionality, deep Q-network was employed to model the agents' interaction in a dynamic and environment-sensitive manner. The architecture allows local decision-making by IoT edge nodes for tasks offloading to edge servers based on connectivity, resource availability, and proximity. Extensive simulation under different learning rates, batch sizes, and memory sizes shows that the proposed scheme with the utilization of a CNN approximator generates optimal policy and higher convergence performance with lower latency than the conventional Q-learning model and several other existing algorithms. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ACCESS.2025.3543236,"A Multi-Phase DRL-Driven SDN Migration Framework Addressing Budget, Legacy Service Compatibility, and Dynamic Traffic","Software-Defined Networking (SDN) is a network architecture that offers enhanced flexibility, programmability, and more efficient traffic load management by decoupling the control plane from the data plane. However, complete migration to SDN is challenging for most organizations due to costs and operational complexities. Hybrid SDN has emerged as a practical incremental path where legacy and SDN-enabled nodes coexist, yet existing migration strategies typically address only individual challenges such as dynamic traffic patterns, legacy service compatibility, and budget constraints. This paper introduces SMART (SDN Migration Assisted by a Deep Reinforcement Learning (DRL) Technique), a comprehensive framework that simultaneously addresses dynamic traffic patterns, legacy service compatibility, and phased migration under budget constraints. By integrating a DRL model with a clustering algorithm, SMART determines the migration sequence to minimize link utilization and reduce the number of SDN-enabled nodes required for effective traffic load distribution under dynamic traffic patterns. Extensive evaluations on the Abilene and GEANT network topologies demonstrate that SMART outperforms three existing approaches, achieving most of the SDN benefits by migrating only 36% and 52% of legacy nodes, respectively. This approach can potentially lower migration costs by up to 64% while achieving network optimization objectives. These insights provide both a foundation for future research in network migration strategies and practical guidance for organizations planning cost-effective transitions from legacy to SDN-based architectures.",TOPIC
10.1109/ACCESS.2025.3544221,Reinforcement Learning-Based Voting for Feature Drift-Aware Intrusion Detection: An Incremental Learning Framework,"In Intrusion Detection Systems (IDS), stream data classification faces significant challenges due to concept drifts and feature evolution, where traditional methods struggle to maintain accuracy over time. One critical challenge is feature drift, which refers to changes in the relevance of features over time, directly impacting the model’s classification accuracy. This paper introduces the Incremental Feature Drift-Aware Genetic Programming Combiner (IFDA-GPC), which integrates a Voting Enhanced Deep Q-Network Multi-Agent Feature Selection (VE-DQN-MAFS) mechanism to address these challenges. The framework extends the existing IGPC architecture by incorporating dynamic feature selection and employing a multi-agent system with voting-based aggregation. This approach enhances feature selection decisions, especially in cases where agents provide conflicting assessments of feature relevance. By reconciling these variations, the framework ensures consistency and reliability in real-time classification tasks. The framework was evaluated using benchmark datasets, including KDD Cup ’99, CICIDS-2017, HIKARI-2021, and ISCX2012, under both evolving and non-evolving scenarios. Results demonstrate that GPC-KOS-DFS, derived from IFDA-GPC, significantly outperformed existing methods in accuracy, F1-score, recall, and AUC metrics. Notably, it achieved an accuracy of 93% on the CICIDS-2017 dataset, showcasing its effectiveness in handling feature drifts while maintaining high classification performance. These findings establish IFDA-GPC as a robust solution for managing evolving data streams in intrusion detection systems.",TOPIC
10.1109/ACCESS.2025.3550183,Transformer and Meta-Reinforcement Learning-Based Task Offloading for MEC Systems in Dynamic Environments,"In mobile edge computing systems, efficient decision-making for task offloading is crucial for enhancing system performance. Currently, existing reinforcement learning-based offloading methods face several primary challenges, including local feature perception, low sample efficiency, long training times, and poor stability. To address these issues, this paper proposes efficient task offloading methods based on transformer and meta-reinforcement learning. Firstly, a novel transformer architecture, Gated Transformer-XL is introduced, allowing the agent to adaptively capture various features and relationships in task offloading decisions and transform them into representations suitable for meta-reinforcement learning algorithms. Secondly, a meta-reinforcement learning framework, Gated Transformer-XL based Proximal policy optimization and Reptile (GTrXL-PR), is proposed, which offers high sample efficiency for new tasks. Even with limited computational resources, user devices can quickly train using local data combined with meta-policies. Finally, Reptile is combined with the proximal policy optimization algorithm to reduce training time by ignoring second-order derivatives, thereby enhancing the stability of the training process. The feasibility and effectiveness of the proposed algorithm are validated through experimental simulations. In experimental simulations, the proposed method achieved approximately a 1.96% reduction in task completion latency across varying rates and numbers of subtasks compared to conventional reinforcement learning methods. The initial latency was also reduced by approximately 0.12% relative to traditional algorithms, validating the feasibility and effectiveness of the proposed algorithm. For more details, the core code is available at https://github.com/liyintao23/Gtrxl_PR.",TOPIC
10.1109/ACCESS.2025.3554493,Visual Explanation With Action Query Transformer in Deep Reinforcement Learning and Visual Feedback via Augmented Reality,"Deep Reinforcement Learning (DRL) agents possess powerful control capabilities and have potential applications in robotics and other fields. However, the closed box properties of DRL agent models still make it difficult to interpret their decision-making processes. One research area that addresses this challenge is eXplainable Reinforcement Learning (XRL). Conventional visual explanation methods in XRL focus only on the rationale behind a single selected action and are insufficient for a more comprehensive analysis of an agent’s decision making. In addition, visualizing attention only as an image is problematic in real-world environments such as robotics because it does not clearly map attention to physical space, limiting user understanding. To overcome these limitations, we propose Action Q-Transformer (AQT), an XRL method that uses a transformer encoder-decoder architecture with action information as a query. In this way, AQT calculates explicit attentions for each action that an agent may select, resulting in a DRL agent model that is easier to interpret. Furthermore, we introduce a visual feedback method using augmented reality (AR) to project these attentions directly into the physical environment. Through experiments on the Atari 2600 video game strategy task and a robot control task in an indoor environment, we demonstrate that AQT can analyze agent decision making in detail. Also, user evaluation in a robot task confirms that AR-based visual feedback effectively improves the understanding of the agent’s behavior.",TOPIC
10.1109/ACCESS.2025.3555487,Design and Architecture for Anti-Hidden Faults Multiagent Protection System in Smart Grids,"The sensitivity of modern day smart devices and the continuously evolving power system into smart grid has raised the level of requirements from protection systems to zero-tolerance for hidden faults. Researchers have continuously proposed various protection schemes to enhance the performance of protection systems. However, high resistance hidden faults could still pass undetected for most of the proposed schemes or could be detected but suffer from high requirements of phasor measurement units (PMUs) or low confidence in the scheme decision. In this paper, an Anti-hidden fault multiagent protection system (AHF-MPS) is proposed that detects hidden faults with minimal PMU requirements and high confidence level in the detection decision. The AHF-MPS employs PMUs as primary agents which detects the periodic change in the phase angle of positive sequence currents that arises due to fault incidents. The second step of AHF-MPS is to initiate an accelerating factor to overcurrent protection devices acting as secondary agents. The system was tested upon IEEE 34 testing system and the results showed successful detection of hidden faults with operating times ranging from 77 ms up to 432 ms depending on fault location. That proved its ability in detecting hidden faults with minimal requirements proving its superiority to its peers.",TOPIC
10.1109/ACCESS.2025.3556976,Selective Reading for Arabic Sentiment Analysis,"This work introduces a novel deep learning method for Arabic sentiment analysis, arguing that reading the entire input sequence is not always necessary. Many texts can be accurately classified without processing all input tokens. The method employs a reinforcement learning agent that selects relevant tokens using a selection policy network. Instead of predicting sentiment polarity from the entire input, the model focuses only on tokens chosen by the policy network. To empirically evaluate the proposed method, experiments were carried out on three Arabic sentiment analysis datasets: Large Arabic Book Reviews (LABR), Hotels Arabic Reviews Data (HARD), and Arabic Sentiment Tweets Dataset (ASTD). The results demonstrate a significant improvement in Arabic sentiment classification with the selective reading method, achieving state-of-the-art accuracy while using only a fraction of the tokens. However, the approach introduces additional computational cost due to the reinforcement learning component, and its scalability to larger datasets might require further optimization.",TOPIC
10.1109/ACCESS.2025.3558439,Next-Gen Internet of Drones: Federated Learning and Digital Twin Synergy for Energy-Efficient Task Allocation and Seamless Service Migration,"The computing-intensive tasks generated by Internet of Things devices cannot be handled alone by themselves due to limitations in battery and processing power. An appropriate approach to this problem is the Internet of Drones (IoDs) with edge computing capabilities, which can offload the created tasks from IoT devices to IoDs. To improve sustainability by maximizing energy efficiency, minimizing duplicate service migrations, and guaranteeing dynamic task offloading in UAV-supported IoD networks, this paper proposes a Federated Digital aided Internet of Drones (FD-IoD) architecture. The proposed framework guarantees the long-term viability of IoD-based edge networks by combining digital twin technology with federated deep reinforcement learning. The FD-IoD framework integrates energy harvesting algorithms and optimizes mobility-aware resource management to extend drone lifespan and reduce unnecessary computational overheads. To adjust to various IoT environments, the framework uses a dual-layer optimization approach that combines local agent learning with global decision-making via digital twin. The framework outperforms current benchmarks by up to 40% in energy efficiency, lower service migration rates, and faster task completion rates, as shown by extensive simulations. Additionally, the proposed framework guarantees decreased latency, efficient resource use, and queue stability even in heavy demand.",TOPIC
10.1109/ACCESS.2025.3561151,An Automated Framework of Superpixels-Saliency Map and Gated Recurrent Unit Deep Convolutional Neural Network for Land Cover and Crops Disease Classification,"In this work, we proposed an automated deep learning and saliency map architecture for the segmentation of crops, leaf disease segmentation, and land cover classification. The proposed framework is based on two embedded steps. In the first step, crop leaf disease segmentation was performed using superpixel clustering-based saliency maps and Bayesian optimization. The contrast enhancement technique is designed in the first segmentation phase and is passed to the saliency technique for the disease segmentation. In the second phase, EfficientNet-b0 architecture is fine-tuned with hyperparameters optimized via Bayesian Optimization. Also, the fine-tuned model is embedded with a single self-attention residual block fused with an efficient average pool layer. Training has been performed on segmented and contrast-enhanced images that were later fused using a serial-embedded approach. The extracted features in the testing phase are further optimized using the modified moth flame-controlled bisection (MFcB) technique. Finally, the extracted features are classified using machine learning classifiers for the final classification. Experiments are performed on the publically available cucumber leaf dataset and Remote sensing dataset with an improved accuracy of 97.6% and 92.90%, respectively. A comparison with state-of-the-art techniques shows that the proposed architecture has improved performance.",TOPIC
10.1109/ACCESS.2025.3561456,ST-3DView: Multi-Scale Contrast-Enhanced 3D Point Cloud Reconstruction of Single-View Objects From Video Scene Transition,"3D object tracking in monocular video relies on understanding the scene content to improve the continuity of the tracking signal. Reconstructing 3D shapes of single-view objects is essential for capturing object depth, orientation, and position within the scene. While existing deep learning-based methods excel in 3D reconstruction and tracking, they primarily focus on object feature semantics in normal frames, neglecting scene transition (ST) frames. This limitation leads to object information loss and discontinuity during tracking. This paper proposes a novel method for 3D reconstruction of single-view objects in monocular video scenes, focusing on fade scene transitions. First, large video datasets are pre-processed and segmented into sequences using cut transition detection via adaptive histogram equalization (AHE), and Euclidean distance estimation (EDE). Second, fade transition sequences are detected and classified into fade-in, fade-out, and mixed-fade scene transitions using pixel intensity-based adaptive threshold. Third, contrast enhancement is applied to fade transition frames using contrast-limited adaptive histogram equalization (CLAHE) to improve object feature extraction. Fourth, a modified DeepLabv3+ network is employed to generate multi-scale features for semantic foreground object and background segmentation. Finally, the segmented objects are processed through the proposed Point-wise multilayer perceptron (MLP) network, which reconstructs 3D object point clouds from segmented 2D single-view object pixels. Experimental evaluations on object categories “Chair,” “Car,” and “Airplane” from the benchmark TRECVID, Pix3D, ShapeNet, and Multimedia datasets achieved an accuracy improvement of 6.52% for fade transition detection and satisfactory results in 3D point cloud reconstruction.",TOPIC
10.1109/ACCESS.2025.3565815,Adaptive Ruminant Optimization With LoRa-Based Communication for Formation Control of Multiple UAVs,"In a dynamic environment with mountains and hazardous peaks, avoiding collisions and maintaining the desired formation is a crucial problem. This paper addresses this problem by presenting a novel formation control strategy of a cluster of UAVs in three different scenarios. The first scenario is designed to test the designed algorithm and hence contains no obstacles. The second scenario introduces some obstacles in the form of mountains to see whether the proposed algorithm can avoid the obstacles while maintaining the formation. In the last scenario, all the UAVs join together in one big cluster and have to avoid the obstacles while maintaining the formation. To design the environment for the scenarios, this study uses graph theory. To address the aforementioned scenarios, this paper offers a novel strategy by integrating a bio-inspired algorithm called the Adaptive Ruminant Optimization Algorithm (AROA) with the Long Range (LoRa) communication to achieve the formation control of multiple UAVs. Initially, AROA offers the best agents of each of the swarm. Then, the proposed method helps choose the best agent to be the leader for each of the swarm. The leader of each swarm finds the best trajectory for each swarm. LoRa-based networking technique is used for the connectivity between the UAVs. In addition, this study uses basis splines (B-splines) to smooth the planned trajectories of UAVs. Lastly, simulations demonstrate the better convergence and efficiency of the designed strategy by comparing it with classic algorithms. The simulations also show that the proposed method successfully maintains formation control in all three scenarios.",TOPIC
10.1109/ACCESS.2025.3566389,Combined Multi-Agent and Centralized Resource Allocation in Cloud Radio Access Networks,"The fifth generation (5G) mobile network is designed to facilitate high data rates with massive connectivity with the benefit of small cell technology. The cloud radio access network (C-RAN) is a promising mobile network architecture that can meet the ever-increasing resource demand of a growing number of users. In C-RAN, base station functionalities are separated into baseband units (BBUs) and remote radio heads (RRHs), with BBUs centralized and virtualized via cloud computing. However, this architecture introduces new challenges in efficiently allocating resources to dynamic users. This paper aims to design a resource allocation scheme that improves system efficiency and satisfies dynamic user demands in C-RAN. We propose a hybrid resource allocation approach that combines centralized control and multi-agent-based decision-making. The centralized controller, located within the BBU pool, collaborates with virtual base stations (VBSs) acting as multi-agent system (MAS) agents. The resource allocation solution is derived by jointly considering the real-time resource requests from agents and the historical demand estimates generated by the centralized controller. Through simulation-based evaluation, we compare our proposed scheme with conventional random and fixed resource allocation methods. The results demonstrate improved performance in terms of resource utilization, reduced unfulfilled demand, and fairness among VBS agents. The proposed combined resource allocation strategy effectively meets dynamic user requirements while maintaining system efficiency in C-RAN. Our work highlights the importance of integrating historical demand trends with real-time agent requests for improved long-term resource planning.",TOPIC
10.1109/ACCESS.2025.3566472,Accurate and Efficient LiDAR SLAM by Learning Unified Neural Descriptors,"Point clouds generated by LiDAR sensors have been widely exploited in Simultaneous Localization and Mapping (SLAM). However, existing LiDAR SLAM approaches based on hand-crafted features easily suffer from being either overly sparse or dense, causing low-fidelity map construction or severe scalability problems. Recent deep learning-based features under the existing SLAM framework can be poorly affected by error accumulation problems over time. To address these issues, we propose a unified architecture named DeepPointMap++, which enables both memory-efficient map representation and accurate multi-scale localization. We design a deep encoder to extract highly representative unified neural descriptors from the input point clouds and propose a novel deep decoder to find their correspondences. It also incorporates a foreground-background classifier during feature extraction, effectively separating dynamic foreground objects from the static background to boost the final localization and mapping effects. In the experiment, DeepPointMap++ outperformed other state-of-the-art methods on multiple auto-driving benchmarks. We also showcase the versatility of our framework by extending it to more challenging multi-agent collaborative SLAM.",TOPIC
10.1109/ACCESS.2025.3569236,New Approaches for Network Topology Optimization Using Deep Reinforcement Learning and Graph Neural Network,"The exponential growth in Internet-connected devices has escalated the demand for optimized network topologies to ensure high performance. Traditional optimization methods often fall short in scalability and adaptability when it comes to network topology planning. In this paper, we address the challenge of transforming mesh topologies into tree topologies for wireless networks, with the objective of maximizing throughput. We propose two new methods: Path Selection with Rejection Strategy (PSRS), which leverages Message-Passing Neural Networks (MPNN), and Dual-Agent Tree Topology Exploration (DATTE), which employs Graph Attention Networks (GAT). These schemes integrate Deep Reinforcement Learning (DRL) and Graph Neural Networks (GNNs) to construct efficient tree topologies with the goal of maximizing the minimum throughput of the wireless network. Experimental results validate the scalability and performance gains of the proposed approaches, highlighting their potential for real-world applications.",TOPIC
10.1109/ACCESS.2025.3573419,Strategic Implementation of Super-Agents in Heterogeneous Multi-Agent Training for Advanced Military Simulation Adaptability,"This study focuses on the application of reinforcement learning in tactical military simulation environments involving heterogeneous multi-agent systems. Optimizing Heterogeneous Multi-Agent Training (HMAT) through scenario-specific adjustments to the Proximal Policy Optimization (PPO) algorithm, we tackle the complexity of tactical simulations. Utilizing an advanced simulation platform, a diverse range of Reinforcement Learning (RL) agents are rigorously trained across various combat scenarios. A ‘super-agent’, an Artificial Intelligence (AI) orchestrator for multi-agent systems, marks a significant advancement in collaborative AI, enhancing operational performance. Comparative analysis highlights the strengths of both traditional RL approaches and HMAT in a unified computational framework. While independent learning agents excel in predictable environments with fast training capabilities, HMAT stands out in dynamic scenarios for its adaptability and superior performance. The integration of HMAT with ‘super-agents’ is shown to markedly improve the fidelity and adaptive capacity of military simulations. Experimental results demonstrate that our fine-tuned super-agent framework achieves up to 92% mission success rate, outperforming scenario-specific baselines by 15–20% in complex Suppression of Enemy Air Defenses (SEAD) and air-to-ground tasks.These enhancements have far-reaching implications, potentially revolutionizing strategic military training and operational planning and underscoring AI’s critical role in modern defense strategies.",TOPIC
10.1109/ACCESS.2025.3574058,Radiation-Hardened—AI-Accelerated Custom IC Design Methodology,"In this work, a radiation hardened - AI accelerated custom IC design methodology is proposed. The methodology employs reinforcement learning (RL) to optimize the IC design process, integrating radiation dosage performance degradation assessments and radiation-hardened-by-design (RHBD) MOSFET cell implementations at both schematic and layout levels. This approach streamlines the development of radiation-immune silicon products by embedding artificial intelligence to accelerate the design process and advanced radiation hardening strategies directly into the standard design flow. To validate the proposed framework, a charge-sensitive amplifier (CSA) based on a folded-cascode architecture is designed and assessed in a 180 nm standard CMOS process, demonstrating the efficiency of the methodology in radiation-resilient analog front-end systems.",TOPIC
10.1109/ACCESS.2025.3574083,Advances and Challenges in Deep Learning for Automated Welding Defect Detection: A Technical Survey,"Automated welding defect detection has emerged as a pivotal aspect of quality assurance in high-stakes industries such as aerospace, oil and gas, and construction. This paper presents a comprehensive review of state-of-the-art Deep Learning (DL) models tailored for welding defect detection, segmentation, and classification, emphasizing technical advancements and persistent challenges. A critical analysis of single-stage and two-stage architectures is conducted to evaluate their ability to address issues like small defect sizes, low image contrast, and diverse defect geometries. The study also highlights the integration of advanced preprocessing techniques, such as noise reduction and contrast enhancement, within DL workflows to improve feature extraction and detection accuracy. Persistent challenges, such as the scarcity of large, labeled datasets, lack of real-time applicability, and limited model interpretability, are explored in depth. To address these gaps, the survey proposes future directions, including the use of self-supervised learning, domain adaptation, Generative Adversarial Networks (GANs), and explainable AI techniques to enhance the robustness, scalability, and transparency of welding defect detection systems. By synthesizing insights from more than a decade of research, this paper provides a detailed roadmap for advancing automated welding inspection technologies, enabling reliable deployment in real-world industrial environments.",TOPIC
10.1109/ACCESS.2025.3577266,A Resource-Efficient 3D U-Net for Hippocampus Segmentation Using CLAHE and SCE-3DWT Techniques,"Hippocampus segmentation on MRI (magnetic resonance imaging) plays a vital role in detecting, diagnosing, tracking, and monitoring neurodegenerative diseases, particularly Alzheimer’s disease. While larger datasets often provide an advantage in deep learning-based segmentation, smaller datasets pose unique challenges due to limited data variability and an increased risk of overfitting. This study addresses these challenges by developing a computationally efficient and accurate 3D U-Net model tailored for hippocampus segmentation. The proposed approach employs a preprocessing pipeline combining 3D Contrast Limited Adaptive Histogram Equalization (CLAHE) and Selective Coefficient-Enhanced 3D Wavelet Transform (SCE-3DWT), which enhances contrast and reduces noise for improved feature extraction. The experimental evaluation was conducted using the EADC-ADNI HarP dataset, comprising 135 hippocampal MRI scans with an input image size of  $64\times 64 \times 96$ . The model achieved a Dice coefficient of 0.8838 and a Jaccard Index of 0.7920, surpassing recent state-of-the-art methods. Comparative analysis highlights reduced Over-Segmentation Ratio (OSR = FP/(FP+TP), 0.0594) and Under-Segmentation Ratio (USR = FN/(FN+TP), 0.0569, reflecting its robustness and generalization. The lightweight architecture, designed with a maximum filter size of 512, operates efficiently without relying on transfer learning, making it accessible for broader applications. Future work will focus on integrating post processing techniques, leveraging larger and more diverse datasets, and exploring higher-resolution volumetric data to further improve segmentation accuracy and clinical utility. This study contributes to the advancement of medical image analysis, offering a resource-efficient framework for precise hippocampus segmentation, with potential implications for improved Alzheimer’s disease management.",TOPIC
10.1109/ACCESS.2025.3579926,Dynamic Fusion of LSTM Predictions Using Reinforcement Learning-Based GOWLA for Human Activity Recognition,"Human Activity Recognition (HAR) contributes significantly to vital areas in healthcare, IoT, and smart monitoring applications. Generally, the current models rely on deep learning and traditional machine learning techniques such as LSTM and SVM. However, these methods face considerable challenges, such as imbalanced data distribution, weak adaptation of weights to temporal changes, and a decline in classification performance in rare activities. In this paper, we propose a new method based on dynamic reinforcement learning to update GOWLA weights, which is entitled Dynamic RL-GOWLA. In this method, the LSTM outputs are combined using Weighted Logarithmic Averaging with a reinforcement learning agent for dynamically updating the weights based on the model’s performance in each training iteration. Experiments on WISDM database show that the proposed method outperforms traditional models such as LSTM, SVM, Bayesian Classifier, RNN, and CNN, achieving a F1-score of 96.58%. This approach improves the adaptability of models to imbalanced data, making it a promising solution for tasks that require accurate classification of dynamic human activities.",TOPIC
10.1109/ACCESS.2025.3581035,Sim-to-Real Transfer of Deep Reinforcement Learning Agents for Online Coverage Path Planning,"Coverage path planning (CPP) is the problem of finding a path that covers the entire free space of a confined area, with applications ranging from robotic lawn mowing to search-and-rescue. While for known environments, offline methods can find provably complete paths, and in some cases optimal solutions, unknown environments need to be planned online during mapping. We investigate the suitability of continuous-space reinforcement learning (RL) for this challenging problem, and propose a computationally feasible egocentric map representation based on frontiers, as well as a novel reward term based on total variation to promote complete coverage. Compared to existing classical methods, this approach allows for a flexible path space, and enables the agent to adapt to specific environment characteristics. Meanwhile, the deployment of RL models on real robot systems is difficult. Training from scratch may be infeasible due to slow convergence times, while transferring from simulation to reality, i.e. sim-to-real transfer, is a key challenge in itself. We bridge the sim-to-real gap through a semi-virtual environment, including a real robot and real-time aspects, while utilizing a simulated sensor and obstacles to enable environment randomization and automated episode resetting. We investigate what level of fine-tuning is needed for adapting to a realistic setting. Through extensive experiments, we show that our approach surpasses the performance of both previous RL-based approaches and highly specialized methods across multiple CPP variations in simulation. Meanwhile, our method successfully transfers to a real robot. Our code implementation can be found online (Link to code repository: https://github.com/arvijj/rl-cpp).",TOPIC
10.1109/ACCESS.2025.3581966,Artificial Intelligence in UAV Flight Controls: Deep Reinforcement Learning Based Altitude-Hold Strategies for Fixed-Wing UAVs,"This paper implements a deep reinforcement learning (DRL) based flight control system for a fixed-wing uncrewed aerial vehicle (UAV). Unlike conventional flight control methods, DRL does not require an exact mathematical system model for the design and can handle non-linear coupled dynamics of highly agile aerospace vehicles like small-size UAVs. The deep deterministic policy gradient (DDPG) method was chosen to suit environments with continuous action spaces. The key contribution of this research is the implementation of three distinct approaches that successfully replace traditional classical control systems with Reinforcement Learning (RL)-based controllers, each offering unique advantages and exploring different trade-offs between interpretability, complexity, and performance crucial for safety-critical aerospace applications. The classical Proportional-Integral-Derivative (PID) flight control architecture, consisting of an altitude controller followed by a pitch (theta) controller, was developed as a baseline. Subsequently, three approaches were investigated; First, the altitude hold controller was replaced by a Reinforcement Learning (RL) agent, while the PID control was maintained for pitch control. In the second approach, both the altitude and pitch control loops were substituted with RL agents. Finally, a single RL agent replaced both the altitude and pitch angle control loops, unifying control under a single agent. A comparative analysis has been made with the widely used conventional PID controls to assess the effectiveness of the each implemented control system. The RL controllers outperformed the baseline PID controllers, among which the unified RL controller achieved a steady-state error of 0.58 meters and a transient response time of 5 seconds, compared to the PID controller’s 1.11 meter steady-state error and transient response time of 16 seconds, thereby reducing the error by 48% and improving the response time by nearly 69%. These results demonstrate the superior accuracy and response efficiency of the proposed RL-based control strategies. Notably, the implementation featuring a single RL agent yields promising results, highlighting the capacity of RL agents to handle complex control challenges. This approach simplifies the control system design by eliminating the need for a multiple-loop architecture. The outcomes of this study underscore the potential of RL-based controllers to enhance the performance of UAVs. Furthermore, the results offer valuable insights for developing future UAV control systems, emphasizing the advantages of RL techniques over traditional PID controls.",TOPIC
10.1109/ACCESS.2025.3583701,RL-RTree: A Reinforcement Learning-Optimized Dynamic R-Tree for High-Dimensional Spatial Indexing,"Spatial indexing in high-dimensional dynamic environments faces critical challenges, including the curse of dimensionality and rapid distribution shifts, which degrade the performance of traditional indexes like R*-trees and static learned indexes. We propose RL-RTree, a dynamic R-tree optimization method that integrates Spatial Graph Attention Networks (SGAT) for density-aware embeddings and online reinforcement learning (RL) to adjust query strategies in real-time. The hybrid offline-online architecture decouples embedding learning from runtime policy optimization. Experiments on 10- to 100-dimensional data show that RL-RTree improves query speed by 75.2% and accuracy by 14.3% compared to R*-trees. For dynamic scenarios, it achieves  $3.7\times $  faster recovery than static indexes and maintains 91.3% accuracy under high noise ( $\sigma =0.5$ ). This work bridges the gap between learning-based indexing and real-time adaptive systems, enabling sub-second updates for mission-critical applications like autonomous vehicles and recommendation engines. The interpretable RL policies and SGAT embeddings set a new paradigm for robust high-dimensional indexing.",TOPIC
10.1109/ACCESS.2025.3583981,Multi-Unmanned Aerial Vehicles Cooperative Tactics: A Survey,"With recent advances in unmanned aerial vehicles (UAVs), there is a growing need for cooperation among multiple vehicles. One approach to enable cooperation is through tactics. However, there is a lack of consensus on how these tactics should be defined or applied to cooperative UAV systems. Moreover, the existing literature does not clearly identify the main challenges inherent in cooperative tactics. We survey recent contributions across both military and civilian domains to consolidate how the term cooperative tactics is employed. We propose a framework that clarifies the core components of multi-UAV cooperation and identifies the main research blocks addressed in the existing work.",TOPIC
10.1109/ACCESS.2025.3585445,Adaptive Defense: Zero-Day Attack Detection in NIDS With Deep Reinforcement Learning,"Zero-Day attack detection in Network Intrusion Detection Systems (NIDS) refers to the ability to identify previously unseen attack patterns during testing without having been explicitly trained on those specific attacks, utilizing learned features from other known attacks. In this paper, we propose a Deep Reinforcement Learning (DRL)-based NIDS designed for Zero-Day attack detection. We use a stacked LSTM architecture to extend the learning capabilities of the DRL agent. We apply several oversampling techniques to handle the issue of class imbalance since the zero-day attack datasets are not as abundant. We use some of the most widely available benchmark datasets in NIDS domain, which all together cover a wide range of attack types, such as reconnaissance, ddoS, infiltration, injection, password attacks, brute force, dos, backdoor, and benign traffic. For example, we converted attacks to 1 and benign traffic to 0, then excluded certain attack categories (DoS and Backdoor) from the training dataset while keeping them in the test dataset. This makes those attack types zero-day attacks, as they are entirely unseen during training. We also compare which data balancing technique works better among K-means SMOTE, SMOTE, Borderline-SMOTE and ADASYN on the performance of our DRL agent. We then demonstrate how powerful our agent is by validating many datasets for remarkable success in detecting both known and unknown attacks in a zero-day manner. Our work has been made publicly available on GitHub (https://github.com/codewithkhurshed/ZDAD) to support researchers in advancing zero-day attack detection in NIDS.",TOPIC
10.1109/ACCESS.2025.3585774,"COMIX: Generalized Conflict Management in O-RAN xApps—Architecture, Workflow, and a Power Control Case","Open Radio Access Network (O-RAN) is transforming the telecommunications landscape by enabling flexible, intelligent, and multi-vendor networks. Central to its architecture are xApps hosted on the Near-Real-Time RAN Intelligent Controller (Near-RT RIC), which optimize network functions in real time. However, the concurrent operation of multiple xApps with conflicting objectives can lead to suboptimal performance. This paper introduces a generalized Conflict Management scheme for Multi-Channel Power Control in O-RAN xApps (COMIX), designed to detect and resolve conflicts between xApps. To demonstrate COMIX, we focus on two Deep Reinforcement Learning (DRL)-based xApps for power control: one maximizes the data rare across UEs, and the other optimizes system-level energy efficiency. COMIX employs a standardized Conflict Mitigation Framework (CMF) for conflict detection and resolution and leverages the Network Digital Twin (NDT) to evaluate the impact of conflicting actions before applying them to the live network. We validate the framework using a realistic multi-channel power control scenario under various conflict resolution policies, demonstrating its effectiveness in balancing antagonistic objectives. Evaluation results show that COMIX achieves up to 60% energy savings across different Service-Level Agreement (SLA) policies compared to a baseline conflict-unaware system, with negligible impact (around 3%) on system throughput. While this study considers power control xApps, the COMIX framework is generalizable and can be applied to any xApp conflict scenario involving resource contention or KPI interdependence.",TOPIC
10.1109/ACCESS.2025.3585860,A Blockchain-Oriented Task Scheduling and Allocation System for ROS Enabled Mobile Robots,"In multi-mobile robot applications, the operational processes such as the management of robots, task assignment, monitoring of assigned tasks, communication and coordination between robots, and data storage are executed through a centralized server system. Therefore, most critical decisions are made on this centralized server rather than by the robots themselves. However, working in a centralized system has numerous disadvantages such as the obligation to maintain a server, routing all communication through a central unit, susceptibility to connectivity issues that render the system inoperable, and increased bandwidth requirements as the number of robots increases. Moreover, any communication issues between the server computers and any of the robots in centralized systems affect the entire system’s operation. To address these limitations, a blockchain-powered distributed communication system for inter-robot communication has been developed in this study. A task allocation application between robots has been implemented on this developed distributed communication system. In the application, Hyperledger Fabric (HLF) has been utilized as the blockchain platform due to its advantages. Each robot is a peer in the blockchain network in the proposed system. A cost function which is computed in all robots has been introduced to reduce the communication load in the blockchain network during task distribution and to enable optimal task allocation among robots. With the proposed system, robots compute and choose the most suitable tasks using the cost function, hence transactions on the blockchain network are kept at optimal level. After reaching consensus of peers on task allocations via HLF, task data are transmitted to robots by Robot Operating System (ROS) integration. With the proposed system, a dynamic and distributed architecture has been introduced and implemented where mobile robots can communicate with each other over a blockchain network without the need for a centralized server. In experimental studies conducted on real robots, the proposed system demonstrated optimal task allocation across multiple phases, effectively adapting to various task requirements in different scenarios. For instance, in one scenario, the system effectively allocated a total of 9 tasks, distributed across two phases: 3 tasks in the first phase and 6 tasks in the second phase. This study presents an innovative contribution to the literature on communication of robots and task allocation. Also, this study has a high potential to be adapted to industrial applications including robotic instruments.",TOPIC
10.1109/ACCESS.2025.3585989,New Energy and CCUS Thermal Power Synergistic Peaking Cost Model and Apportionment Optimization Strategy,"Driven by the global carbon neutral strategy, the large-scale application of Carbon Capture, Utilization and Storage (CCUS) technology has significantly weakened the peaking margin of thermal power units, and the traditional peaking cost allocation model fails to take into account the inequitable distribution of costs faced by the carbon capture power plants participating in peaking. This study proposes a peaking cost quantification method based on multidimensional characterization. In terms of temporal characteristics, the scenario substitution method is used to quantify the participation of different peaking entities in peaking; in terms of spatial characteristics, the initiative constraints of unit peaking are taken into account to ensure that each peaking entity actively participates in peaking and profits from it. Considering the impact of carbon capture power plants’ participation in peak shifting on carbon emission reduction and carbon cost, we constructed a dynamic peak shifting model for multiple subjects. We innovatively construct a two-layer architecture of “spatio-temporal two-dimensional quantization and dynamic game sharing”, and adopt the improved kernel method to establish a coalition reorganization trigger mechanism to solve the unfair sharing of peaking costs when carbon capture power plants participate in peaking. Taking the improved IEEE34 node as an example, the results show that the established cost calculation model can accurately calculate the peak shaving cost of each unit in different scenarios. The total cost of thermal power peak shaving using CCUS is 6.5% lower than that of conventional thermal power units, which significantly verifies the effectiveness of CCUS technology in reducing the economic burden of peak shaving. When the carbon price is 150-250 yuan/ton, the carbon emission is reduced by 40%-50%, which highlights the dual advantages of the model in deep emission reduction and carbon price co-optimization, and the cost increase is  $\le 5$ %, which proves the feasibility of achieving large-scale carbon emission reduction under the premise of strictly controlling the economic cost. On the basis of completing energy conservation and emission reduction, the peak regulation task is completed at the minimum cost, and the unity of economy and environmental protection is achieved. Compared with the Shapley value method, the correlation coefficient of the contribution of the kernel method is increased to 0.91, which indicates that the accuracy of the proposed method for the evaluation of multi-agent contribution is significantly improved, and the fairness of the peak-shifting cost-sharing model of the kernel method is significantly improved, which provides a reliable solution for solving the problem of cost allocation imbalance between traditional power supply and CCUS units.",TOPIC
10.1109/ACCESS.2025.3586378,Proactive Data Placement in Heterogeneous Storage Systems via Predictive Multi-Objective Reinforcement Learning,"Modern data-intensive applications demand efficient orchestration across heterogeneous storage tiers, ranging from high-performance DRAM to cost-effective cloud storage. Existing tiered storage systems predominantly employ reactive policies that respond to observed access patterns, leading to suboptimal performance under dynamic workloads and failing to address multi-objective optimization requirements. We propose a novel proactive data placement framework that integrates predictive deep learning with multi-objective reinforcement learning to anticipate future data access patterns and optimize placement decisions across storage hierarchies. Our method employs Long Short-Term Memory networks and Transformer architectures to model complex temporal dependencies in I/O traces, generating predictive access probability distributions for data blocks. A deep reinforcement learning agent subsequently leverages these predictions, along with application-specific metadata hints, to make proactive placement decisions that simultaneously optimize latency, throughput, and cost objectives. The system incorporates a sophisticated reward mechanism that balances performance gains against migration overhead, while employing prioritized experience replay and adaptive learning rates to handle non-stationary workload characteristics. Through comprehensive evaluation using both synthetic and real-world traces from deep learning training workloads, our method demonstrates substantial improvements over state-of-the-art algorithms: achieving up to 45.1% reduction in average I/O latency, 32.5% improvement in throughput for critical applications, and 28.8% reduction in storage costs. The framework’s ability to proactively adapt to evolving access patterns while maintaining computational efficiency makes it particularly suitable for large-scale machine learning and scientific computing environments where data placement critically impacts overall system performance.",TOPIC
10.1109/ACCESS.2025.3586465,Integrated Bidding and Battery Scheduling in a Microgrid for Sealed-Bid Double Auction Power Trading With Peer Microgrids Under Uncertainty and Its Blockchain-Based Implementation,"This paper proposes a novel framework for conducting sealed-bid double auctions in power trading for multi-microgrid networks, addressing the critical challenge of jointly optimizing bidding decisions and battery scheduling under uncertainty in renewable energy generation and load demand. In contrast to existing approaches that treat these components independently, our method explicitly models their interdependency for maximizing trading efficiency. We assume a normal distribution of prediction errors and introduce an uncertainty range and a bid buffer capacity to account for expected variations in forecasted generation and load, enabling more robust coordination between bidding and storage operations. While Q-learning determines the exact bid, the feasible power availability or demand is derived from the uncertainty range, ensuring consistency between learned bidding decisions and forecast-aware constraints. The Q-learning relies solely on its historical bidding outcomes without attempting to predict the bids of other participants. In parallel, battery operations are optimized using a hybrid method that combines Genetic Algorithm (GA) and Simulated Annealing (SA), explicitly incorporating the bid buffer capacity to align scheduling with market commitments. We also propose a fully decentralized and tamper-resistant execution architecture based on a consortium blockchain, where multiple aggregator agents within each microgrid, representing renewable sources, loads, storage systems, and the bid agent, function as independent blockchain nodes. Simulation results on a benchmark microgrid system with Monte-Carlo modeled prediction errors demonstrate that the proposed approach significantly enhances both economic benefits and trading robustness compared to conventional frameworks.",TOPIC
10.1109/ACCESS.2025.3586716,"Ten Years of Asset Administration Shell: Developments, Research Opportunities, and Adoption Challenges","Over the past decade, the Asset Administration Shell (AAS) has emerged as a cornerstone of digital transformation in Industry 4.0 (I4.0), providing a standardized approach to managing digital representations of industrial assets. With 2025 marking approximately ten years since its introduction, this article aims to provide a comprehensive analysis and discussion of AAS development over the past decade, potential research opportunities, and the challenges associated with its adoption. To this end, the study combines a literature survey with an examination of specifications from key organizations, such as the Plattform Industrie 4.0 and the Industrial Digital Twin Association (IDTA), which play a central role in the AAS standardization and development. A key insight from this survey is that AAS is progressing toward becoming a game-changer in realizing I4.0. Unlike a decade ago, AAS has now reached a level of maturity that enables its increasing adoption, supported by specifications and standards, dedicated development platforms for its implementation, and several examples in the literature showing a wide range of applications. Additionally, research opportunities for AAS align with emerging industrial trends and contribute to addressing them. However, several challenges must still be addressed to facilitate the widespread adoption of the AAS.",TOPIC
10.1109/ACCESS.2025.3586798,Hybrid Physics-LSTM Framework for Wind Power Prediction and Control in Virtual Microgrid Simulations,"Three-dimensional physical systems play a pivotal role in the development of cyber-physical infrastructures, particularly in the implementation of digital twins that enable the evaluation of hypothetical and adverse scenarios through high-fidelity simulation. This work presents a real-time 3D monitoring and feedback system designed for a custom transverse-axis wind turbine, integrating physical modeling principles with simulation engines developed initially for game environments. This hybrid architecture facilitates the virtual prototyping, testing, and validation of wind energy systems under near-operational conditions. The proposed framework combines two key components: 1) a physics-based model grounded in the mechanical and electromagnetic dynamics of wind turbine operation, and 2) a data-driven architecture composed of multiple layers. The physical layer interfaces directly with the sensors and actuators of the turbine, ensuring real-time synchronization between the physical and virtual systems. Data acquisition and communication are managed through the MQTT protocol, enabling low-latency streaming and robust interoperability. A long short-term memory neural network is integrated into the architecture to enhance predictive capabilities and trained to forecast wind energy production. An intelligent battery management system subsequently utilizes the output of the model to optimize charging strategies.",TOPIC
10.1109/ACCESS.2025.3587245,Early Warning of Nerve Agent Release in Large Indoor Environments Based on Encoder-Decoder Coupling Physics-Informed Neural Network,"Accurately perceiving spatial distribution patterns, detecting dynamic evolution characteristics, and issuing early warnings set higher standards for indoor safety and protection efforts. Computational fluid dynamics (CFD) methods provide accurate predictions but struggle with real-time performance, while neural networks offer rapid predictions, though their performance declines with high-dimensional fluid flow. Nerve agents were used in a subway attack in Japan. For counter-terrorism surveillance purposes, the real-time and accurate detection of nerve agents is critical for providing early warnings to the public and coordinating subsequent rescue operations. Therefore, in this work, a new model called Encoder-Decoder Coupling Physics-Informed Neural Network is proposed, which learns from concentration data generated by experimentally validated CFD simulations and the spatio-temporal information to solve high-dimensional partial differential equations and provide predictions of nerve agents distribution that more closely align with objective physical laws. Extensive experiments are conducted, and the results indicate that our model attains the highest performance among all the algorithms proposed in this paper. The difference between the actual and predicted results is small, and the scatter points are distributed around the fitted curves. In addition, it can make predictions with millisecond-level response time to achieve real-time monitoring. We propose a data-physics dual-driven surrogate model for real-time monitoring and early warning of the distribution of nerve agents in indoor environments.",TOPIC
10.1109/ACCESS.2025.3589931,Why Asset Administration Shells: A Survey on Uses and Challenges,"In the cadre of the Industry 4.0 initiative, and its proposed RAMI 4.0 reference architecture, the Asset Administration Shell (AAS) is gaining traction in the industrial sector, ushering production practices to new precedents and enabling the incorporation of the latest digital technologies. However, the task of instigating the new era of industry is not without difficulties. The current work performs a systematic literature review of AAS by thoroughly reviewing 86 recently published journal articles. The aim is to put in scope current use cases of the AAS, categorise them and, thus, paint a comprehensive picture of AAS usage, by synthesizing all recent journal literature. The second part of the work focuses on highlighting current challenges that appear at the intersection of AAS with necessities of the industrial sector, as well as with the AAS’s integration with novel concepts and technologies.",TOPIC
10.1109/ACCESS.2025.3591362,UResNet-Based Enhancement of Underwater Images Through Variational Contrast and Saturation,"Underwater imaging is an ever trending and evolving field in which the images obtained are subjected to enhancement to identify the critical features of the underwater world. Various enhancement approaches have evolved and certain issues have been identified in these techniques leading to a new technique. Generally, underwater images suffer from blurriness, color distortion, light absorption and scattering in water, low contrast issues which affect the overall clarity and visual appeal of the image. Our research demonstrates that hybrid preprocessing when combined with advanced deep learning models such as Underwater ResNet (UResNet) give high quality and visually appealing images. Three model variants have been explored in this work, the standard UResNet, UResNet augmented with a Sobel filter, and UResNet enhanced with a squeeze-and-excitation (SE) block. The models have employed on the EUVP (Enhancing Underwater Visual Perception) dataset. The core challenges such as color distortion, low contrast, and poor saturation have been overcome by the hybrid preprocessing pipeline, which combines Underwater White Balance (UWB) and Variational Contrast and Saturation Enhancement (VCSE) techniques that corrects the color imbalances, enhances the contrast, and amplifies the saturation before deep learning interference. The pre-processed images were given to all modified UResNet models and it was found that all models outperform the baseline model in both qualitative and quantitative evaluations. Among the three models that were modified, the SE-integrated model consistently delivered superior performance with all the metrics, highlighting significant improvements in color fidelity, contrast, edge definition, and overall image clarity. These results show the effectiveness of combining hybrid preprocessing with structure-aware deep learning architectures to improve underwater image quality and adaptability across diverse marine environments.",TOPIC
10.1109/ACCESS.2025.3592310,Big Data and I2X Communication Infrastructure for Traffic Optimization and Accident Prevention on Automated Roads,"This paper presents a scalable big data infrastructure designed to support traffic optimization and accident prevention in automated and connected road environments. The proposed system integrates real-time data acquisition from heterogeneous sources, including multichannel roadside camera gantries and IoT-enabled vehicle telemetry. The architecture is built upon technologies such as Apache Kafka, Apache Beam, and MongoDB, enabling high-throughput data ingestion, processing, and storage. To validate its performance, two experimental use-cases were developed: one for large-scale image ingestion and another for vehicle telemetry data streaming. The system successfully handled over 48 GB of image data and more than 3.4 million telemetry messages under real-time constraints. Results show that applying data compression techniques—such as resolution reduction and transmission throttling—reduced image upload durations by up to 77%, improving ingestion efficiency without compromising system robustness. These findings demonstrate the feasibility of deploying the proposed infrastructure as a foundational layer for future intelligent traffic management systems.",TOPIC
10.1109/ACCESS.2025.3592975,Toward Fairer and More Accurate Real-Time Pedestrian Attribute Recognition for Enhanced Women’s Safety: A Domain-Adversarial Multi-Head Model With Agent-Based Reporting,"Effective surveillance systems play a vital role in improving public security, most important among which are applications related to women’s security, where the capacity to correctly carry out Pedestrian Attribute Recognition (PAR) is of utmost importance. Current PAR models are susceptible to being thrown off by dataset bias, mainly gender bias due to training set imbalance, resulting in suboptimal generalization and incorrect prediction across groups. This paper solves the challenges above by creating a Domain-Adversarial Training for Multi-Head Pedestrian Attribute Recognition (DAMH-PAR) model. DAMH-PAR uses a domain-adversarial training method combined with a multi-head structure to provide specialized training to various sets of attributes. The model learns invariant domain features upon training independent “expert” heads per dataset, which are chosen during inference to produce detailed pedestrian descriptions. The usefulness of the model is established by its capacity to predict pedestrian attributes accurately from security feeds even under heavy lighting. Such details, combined with violence detection and proximity modules, forms critical contextual information for automated safety systems. Testing DAMH-PAR model on PETA and PA-100K datasets reveals significant performance improvement compared to existing top-performing benchmarks. The DAMH-PAR model achieves 90.50% Mean Accuracy on PETA and 94.31% accuracy on PA-100K, which is more than the previously established standards. The performance highlights the potential of the suggested methodology to develop more effective and unbiased PAR models for meaningful development in security and safety surveillance tasks.",TOPIC
10.1109/ACCESS.2025.3593064,A Custom Reinforcement Learning Environment for Hybrid Renewable Energy Systems: Design and Implementation,"We present HybridEnergyEnv, an open-source, Gym-style simulation environment designed for reinforcement learning (RL) research in hybrid renewable energy systems (HRES) combining wind, solar, and battery storage. The environment incorporates realistic component models, including intermittent renewable generation profiles, a synthetic electricity price signal inversely correlated with renewable availability, and a detailed Battery Energy Storage System (BESS) model accounting for state-of-charge (SoC) dynamics, self-discharge, efficiency losses, thermal derating, and rainflow-based capacity degradation. To validate the framework, we evaluate three dispatch strategies implemented with algorithms available in the Stable-Baselines3 (SB3) library: Proximal Policy Optimization (PPO), Advantage Actor-Critic (A2C), and Double Deep Q-Network (DDQN). Results show that DRL-based policies increase operational revenue by up to 10.05% and reduce curtailment by up to 84.60% compared to the no-storage baseline. Additionally, DDQN achieves the longest episode durations and highest rewards during training, indicating greater stability under strict curtailment constraints. We describe the environment architecture, component models, and API, demonstrating the potential of HybridEnergyEnv as a high-fidelity, extensible platform for the development of intelligent, degradation-aware dispatch strategies in modern power systems.",TOPIC
10.1109/ACCESS.2025.3593365,PRIVOT: Privacy-Resilient Intelligent DAG Blockchain Architecture for IoT,"The rapid growth of the Internet of Things (IoT) demands solutions that can secure massive streams of sensitive data without sacrificing performance. Traditional blockchains struggle in IoT environments, facing significant challenges with transaction speed, scalability, and privacy. This paper introduces PRIVOT, a novel blockchain architecture that integrates a Directed Acyclic Graph (DAG) for high-throughput consensus with lightweight zero-knowledge proofs (ZKPs) for confidential transactions, rateless coded computation for private analytics, and an AI-driven manager that dynamically balances security and efficiency. Our simulations show that PRIVOT significantly outperforms traditional blockchain approaches, achieving high transaction throughput (up to 480 TPS on a 500-device network) with confirmation latencies under 2.1 seconds, even under heavy load. The framework provides robust privacy, limiting data leakage to less than 0.1% against significant node collusion, while keeping computational overhead low enough for resource-constrained IoT devices. By unifying these techniques, PRIVOT offers a scalable and resilient solution ideal for large-scale IoT deployments where both high performance and strong privacy are paramount.",TOPIC
10.1109/ACCESS.2025.3593616,Multi-Agent Reinforcement Learning With Cross-Layered Adaptive Wireless Video Streaming for Road Traffic Monitoring,"This paper presents the design and implementation of a multi-agent reinforcement learning framework for adaptive wireless image sequence streaming in road traffic monitoring systems. This work extends previous research that utilizes Apache Kafka for real-time wireless image transmission. To promote cooperation and fairness among agents, a multi-agent architecture with independent learners employing a social welfare function as a joint reward is implemented. The learning agents are trained and evaluated under various scenarios, and their performance is compared to a baseline without learning agents. Experimental results show that, after sufficient training, the proposed approach outperforms the baseline by 3.98% to 31.55% in joint reward. An emulated software-defined wireless mesh network is built with Mininet-WiFi to test the scalability and convergence time. This study highlights the potential of multi-agent reinforcement learning for improving adaptive wireless image streaming in road traffic monitoring, with significant implications for future research and real-world applications.",TOPIC
10.1109/ACCESS.2025.3596045,OPTNet: Optimized Pixel-Transformer Model for Adaptive Retinal Fundus Image Enhancement,"Retinal low-quality images present significant challenges for accurate diagnosis and monitoring of eye diseases by obscuring critical anatomical features and reducing analytical precision. This study introduces OPTNet,1 an optimized pixel-wise transformer model designed to efficiently enhance degraded or low-quality retinal images. The proposed approach consists of three main stages: 1) pre-processing to standardize image dimensions and balance color channels, 2) model development, in which a lightweight ANN-based feature extractor learns retinal structures and generates self-measured quality labels, and 3) pixel-level transformation guided by these predicted labels to perform localized enhancement. The performance of OPTNet was evaluated using statistical metrics across various architectures during training and testing, and benchmarked on six public retinal datasets: DRIVE, CHASE-DB1, HRF, DRHAGIS, FIRE, and FIVES. A comprehensive evaluation was conducted using both full-reference and no-reference quality assessment (QA) metrics, supported by qualitative analysis. OPTNet achieved competitive results including a 21.3% improvement in NIQE and 17.8% reduction in BRISQUE compared with existing methods. The final scores included SSIM (0.1925), VIF (0.1911), BIF (1.3018), EME (11.1704), NIQE (4.0730), and BRISQUE (30.3003), indicating perceptual and structural enhancement. Additionally, it effectively preserved brightness and anatomical fidelity while minimizing distortion (CD = 0.4214), blur (0.0889), and artifacts (0.2903). In conclusion, OPTNet outperforms state-of-the-art enhancement techniques by striking a robust balance between quality improvement and artifact suppression, demonstrating its strong potential for integration into clinical ophthalmic diagnostic pipelines.1The term ""Pixel-Transformer"" in OPTNet does not refer to attention-based Transformer architectures. Rather, it denotes a convolutional module that performs pixel-wise transformations to enhance structural features, particularly in low-contrast retinal regions.",TOPIC
10.1109/ACCESS.2025.3598501,Vibration Control of Piezoelectric Cantilever Beam With Physics-Informed Neural Networks,"Intelligent actuators, particularly piezoelectric actuators, are widely used for vibration control of engineering structures like beams, plates, and shells due to their advantages of good linearity, high precision, and simple configuration. However, traditional control methods often suffer from limited adaptability to complex dynamic environments. This paper proposes a Physics-Informed Neural Networks (PINNs) enhanced Deep Reinforcement Learning (DRL) framework for high-precision vibration control of piezoelectric cantilever beams. Unlike conventional model-based methods, our approach integrates the Euler-Bernoulli beam dynamics directly into the DRL training process, generating voltage control strategies under physical constraints through joint optimization of data-driven loss and partial differential equation (PDE) residuals. A Double Deep Q-Network (DDQN) agent observes real-time tip displacement and velocity, then outputs voltage actions. In the paper, the fundamental electromechanical coupling mechanism is established based on the cantilever beam’s governing equations and sensor equations of general shell structures. Employing modal expansion methods, we derive both the modal voltage expression and the modal force formulation for the piezoelectric actuator. The architecture of the Deep Reinforcement Learning (DRL) controller—specifically a Physics-Informed Double Deep Q-Network and its underlying neural network structure are subsequently detailed. Evaluations across the first three vibration modes under free decay, sinusoidal excitation and white noise loads demonstrate that the PINNs-DRL controller significantly outperforms conventional negative velocity feedback (NVF) in suppressing transient oscillations and residual vibrations.",TOPIC
10.1109/ACCESS.2025.3598864,A Digital Twin-Empowered Framework for Interactive Consumers in Manufacturing Using Wearable Device,"In the cyber-physical world, human-robot interaction (HRI) plays an increasingly important role in digital twin (DT)-enabled development, particularly in smart manufacturing. This investigation introduces a novel DT-based robotic framework for HRI (DTbRF-HRI), aiming to further productivity, automation, and safety. Our framework includes major elements such as real-time data communication, a common digital model, and a simulation environment for obstacle avoidance and autonomous manipulation. One contribution of our works is the application of an enhanced A-star algorithm for motion planning to support fast generation of paths and avoiding collisions. The data exchange between the physical and virtual agent is supported through system architecture and communication protocols, which meet with being very fast. The resulting framework is validated using numerical simulation and physical experiments in a common electronic consumer manufacturing scenario. Findings demonstrate the effectiveness, robustness, and practicability of DTbRF-HRI in improving intelligent robotic process in a cyber-physical system.",TOPIC
10.1109/ACCESS.2025.3600319,Generation of Critical Information and Sharing Mechanism for Multi-Robot Mission Success,"This paper shows a real-time information-sharing mechanism and custom task allocation strategy for cooperative multi-robot systems operating in uncertain and dynamic environments. The proposed method is based on a decentralized, asynchronous architecture utilizing the Quality of Service (QoS) features of the Robot Operating System 2 (ROS2) framework and Data Distribution Service (DDS) middleware. To validate its practical applicability, extensive simulation experiments and real-world robot tests were conducted using mobile robot platforms under varying network conditions. Key performance metrics including message delay, reaction time, packet loss, and mission success rate were evaluated across multi-QoS configurations. Results show that Reliable and Transient Local settings provide the most consistent performance, ensuring stable obstacle information transmission and robust map updates even in environments with significant communication constraints. Additionally, comparisons between simulation and physical experiments reveal the impact of system-level variables such as synchronization error, network behavior, and sensor noise. The findings confirm the robustness and adaptability of the proposed approach and demonstrate its potential to serve as a scalable framework for future heterogeneous multi-robot deployments.",TOPIC
10.1109/ACCESS.2025.3600330,Intelligent Handover Management in Ultra-Dense 5G Networks: A Deep Q-Learning-Based Prediction Model,"Handover optimization is problematic in ultra-dense 5G networks because of the extremely high number of users and base stations. Unlike other methods, classical optimization approaches are not suitable for such technologies due to their complexity. In this context, a Machine Learning (ML)-based architecture using Deep Neural Networks (DNN) and Reinforcement Learning is proposed for handover and network optimization. The DNN model considers the temporal changes in the state of the network, and reinforcement learning is responsible for policy-based decision-making for proactive intervention, adaptive-driven interference suppression, and spectral efficiency improvement. These findings support the feasibility of the proposed resource allocation technique using ML in wireless communication systems.",TOPIC
10.1109/ACCESS.2025.3602476,IEEE Access,"Recently, autonomous systems in agriculture have garnered increased attention among research communities and industries due to their greater significance. With rapid technological advances, numerous autonomous systems have been actively deployed in agriculture to accomplish complex tasks, such as surveying agricultural fields, managing the water cycle, resolving soil compaction issues, etc. Swarm robotics, path planning, and task assignment systems play a crucial role in agricultural automation and pave the way for smart, sustainable agriculture. However, the major problem here is that this system depends on dynamic path planning activities, which are the most crucial task for autonomous robots. This is because in smart agriculture, multiple agents are associated with the system to perform various activities on their way to the destination, making the path planning actions more complicated than ever. To address these constraints, this paper presents a cost-efficient, reliable, and safe navigable swarm approach, called the Self-Supervised Learning Graphical Neural Network Driven Prediction Model (SGNN), for smart sustainable agriculture. The proposed SGNN approach enables swarm robots to select the most optimized paths, thereby reducing the distance travelled by the robots. The work’s prime focus is on developing a forecasting model for the efficient navigation and landing of swarm robots in innovative agricultural systems. The Semantic Drone Dataset is used for experimentation purposes. It is observed from the analysis that the proposed approach offers more than 85% percent accurate results in comparison to standard ResNet architectures. Additionally, this approach yields a score of around 0.8, indicating a good balance between precision and recall measures. Further, the result suggests a correlation coefficient factor of around 0.685, representing the effective classification of the target classes. Thus, the proposed SGNN approach has been experimentally proven to be more robust and efficient than existing approaches. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ACCESS.2025.3604095,A Cyber Resilient Framework for V2X Enabled Roundabouts in Intelligent Transportation Systems,"Vehicle-to-everything (V2X) communication systems are increasingly susceptible to cyber-physical threats that exploit trust assumptions, coordination latency, and semantic inconsistencies across agents. These vulnerabilities, particularly in dense or adversarial environments, undermine the reliability of cooperative perception, anomaly detection, and safety-critical maneuver execution. This paper presents CR-V2XR, a cross-layer, federated, and trust-aware coordination framework designed to enhance resilience in connected and autonomous vehicular networks. CR-V2XR integrates multi-modal anomaly detection with delay-sensitive trust estimation using features extracted from basic safety messages (BSMs), behavioral deviations, entropy shifts, and inter-vehicle trust validation. The architecture employs federated learning for distributed anomaly detection without centralized aggregation and uses a control layer that supports delay-aware trajectory selection. A multi-objective NSGA-III optimizer enables online trade-off adaptation across detection accuracy (DA), collision probability, and communication overhead. Simulations across eleven adversarial scenarios, including Sybil, wormhole, falsification, and replay attacks, demonstrate that CR-V2XR achieves 95% detection accuracy under worst-case attacks, reduces collision probability from 0.61 to 0.27 at 300 vehicles, maintains bounded delay, typically 45–60 ms under nominal load, and remains resilient under high-stress conditions with delays up to 180 ms and communication overhead ( $\leq 6.1$  MB/s). Compared to centralized IDS and stateless baselines, CR-V2XR improves detection fidelity, scalability, and robustness under non-IID data and partial synchronization. These results establish CR-V2XR as a viable architecture for delay-constrained, trust-centric coordination in federated V2X environments subject to persistent adversarial threats.",TOPIC
10.1109/ACCESS.2025.3604143,Optimization of Multi-Agent Scheduling Based on MA-ID3QN for the Riveting and Welding Work Cell,"In industrial manufacturing, multi-agent scheduling is one of the key technologies for improving production efficiency. Due to the complexity of multi-agent systems and the interference between tasks, achieving efficient task scheduling is faced with significant challenges. To solve this problem, this paper introduces the dueling double deep Q-network (D3QN) into the multi-robot scheduling scenario of a riveting and welding work cell for the first time. Considering the characteristics of this scenario, an improved D3QN is proposed, which is designed as a multi-agent independent dueling double deep Q-network algorithm (MA-ID3QN) based on a multi-agent cooperation mechanism. In this approach, robots in the work cell are treated as independent agents, with decentralized training and decentralized execution to accommodate varying robot numbers. Meanwhile, several mechanisms are employed to enhance the algorithm’s performance. Furthermore, a digital twin-based riveting and welding work cell platform is constructed for validation. First, the MA-ID3QN algorithm generates a scheduling strategy based on the state of the physical space of the riveting and welding work cell. Then, the scheduling strategy is verified on the digital twin platform. Finally, comparative experiments are conducted to validate the effectiveness of the proposed method. The experimental results demonstrate that the MA-ID3QN-based agent scheduling method exhibits better reliability, higher efficiency, and stronger generalization capability in multi-agent task scheduling. This approach improves the efficiency of the riveting and welding work cell and reduces the time required for welding tasks in mass production scenarios. Moreover, it has promising application prospects in industrial robot scheduling.",TOPIC
10.1109/ACCESS.2025.3605643,An Interpretable Deep Actor–Critic Framework for Automated Propofol Dosing During General Anesthesia,"Administering general anesthesia demands anesthesiologists to concurrently regulate various physiological functions, often under time-critical conditions. The automation of hypnotic drug delivery offers the potential to enhance precision in maintaining optimal sedation levels while allowing clinicians to focus on more complex intraoperative decisions. In this study, we propose a reinforcement learning (RL) framework to guide the real-time administration of propofol, a widely used anesthetic agent. Building upon earlier discrete-action approaches, our model adopts a continuous-action actor-critic architecture. It incorporates a policy network that generates a continuous probability distribution over infusion rates based on dynamic anesthetic state observations, along with a value network that evaluates the desirability of those states. The RL agent is trained on synthetic patient simulations derived from pharmacokinetic and pharmacodynamic (PK/PD) models with randomized parameter sets to ensure robustness across diverse patient profiles. We examine three distinct reward formulations tailored to different clinical objectives and evaluate agent performance in both simulated scenarios and retrospective clinical data from nine surgical cases. To enhance transparency and support clinical adoption, we apply Shapley Additive Explanations (SHAP) to interpret the agent’s dosing rationale. The analysis revealed that dosing decisions were primarily influenced by the level of unconsciousness (LoU) error and predicted effect-site concentration, with LoU target dominating steady-state control. These clinically consistent patterns demonstrate that the agent’s recommendations align with established pharmacological principles, thereby improving clinician trust and interpretability. Experimental results demonstrate that the proposed RL agent surpasses traditional PID controllers in maintaining target sedation levels and aligns closely with anesthesiologist-administered dosages in real cases. This work represents a novel advancement in automated anesthesia control, showcasing the adaptability of reward functions and the integration of interpretability tools to support the development of clinically relevant AI-based drug delivery system.",TOPIC
10.1109/ACCESS.2025.3605852,AnnotationGym: A Generic Framework for Automatic Source Code Annotation,"A common approach to code optimization is to insert compiler hints in the source code using annotations. Two major challenges with using annotations effectively are their complexity and lack of portability. This means, first, that significant developer expertise is required, and, second, that the supported annotations, as well as their syntax and use, can vary substantially. Moreover, there is not currently any tool that can output performant annotation-inserted codes for different back-ends. To address these challenges, we present AnnotationGym, an easy-to-use, open-source, generic infrastructure that supplements or replaces the developer in annotating source code. It demonstrates a novel application of AI methods to code annotation. In addition to improving code performance, the flexibility of AnnotationGym enables easy comparisons of performance and optimization strategies among compilers and target architectures and thus provides an extensible platform to facilitate further progress in this field. AnnotationGym automatically extracts structured information about the target code and compiler to generate a list of possible annotations. AI-based optimization algorithms then traverse this space to determine the best set of annotations depending on the developer goals. To demonstrate its effectiveness, we run AnnotationGym on popular, representative workloads from the Polybench suite, as well as targeting various compilers (GCC, AMD HLS, Intel HLS), optimization algorithms (Reinforcement Learning, Bayesian Optimization), and architectures (CPU, FPGA). We also test our approach on FPGA codes derived, e.g., from the Rodinia and OpenDwarfs benchmarks and that are hand-optimized using standard best practices. An interesting finding is that the best overall performance obtained by AnnotationGym was generally with unoptimized codes.",TOPIC
10.1109/ACCESS.2025.3605947,SPP-L²: A PPO-Enhanced Large Language Model Framework for Student Performance Prediction on Learner-Sourced Questions,"In response to the growing complexity and dynamism of learner-sourced education platforms, this paper presents SPP-L2, a unified student performance prediction framework that integrates semantic understanding with reinforcement learning. The framework leverages a signed bipartite graph to capture structured student–question interactions and employs a large language model to encode the nuanced semantics of natural language questions. These representations are fused and used as input to a Proximal Policy Optimization (PPO) agent, which dynamically learns to predict student responses while receiving feedback signals for policy refinement. A value-based feedback mechanism further enhances the system’s ability to adaptively recommend questions and personalize interventions. Extensive experiments conducted on five real-world PeerWise course datasets demonstrate that SPP-L2 outperforms existing methods in terms of prediction accuracy, robustness, and adaptability. The proposed framework provides a principled and scalable solution for intelligent learning platforms by bridging representation learning, policy optimization, and feedback-driven adaptation.",TOPIC
10.1109/ACCESS.2025.3606016,Energy-Aware MARL for Coordinated Data Collection in Multi-AUV Systems,"As the demand for adaptive and autonomous smart ocean systems continues to grow, multi-agent control strategies based on reinforcement learning for Autonomous Underwater Vehicles (AUVs) play a vital role in supporting data collection in challenging deep-sea environments. Unlike previous surveys, this paper presents a comprehensive review of Multi-Agent Reinforcement Learning (MARL) approaches with a specific emphasis on energy efficiency and inter-AUV coordination. We examine various MARL algorithms and their applications in real-world scenarios such as buffer overflow prevention, avoidance of Flight eXceedance (FX) violations, and adaptive path planning. As a supporting illustration, we include a case study based on the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm to demonstrate how coordinated policies can be formed under energy-constrained and partially observable scenarios. Additional experiments using MAPPO and MODDPG show that MODDPG excels in energy efficiency with low overflow, while MAPPO yields moderate rewards but lacks training stability. These results provide a conceptual foundation for validating energy-efficient reward strategies based on decentralized coordination. Scope note: the case study we included is a form of limited validation to complement the survey, not a new algorithmic contribution. Therefore, the experimental findings should be read as supporting the narrative (rather than as a claim of being the state-of-the-art method in this field). We also acknowledge that the simulation used is still limited to an idealistic 2D grid environment and does not fully represent real ocean dynamics. Therefore, we plan to extend it to a 3D particle-based or Computational Fluid Dynamics (CFD) framework, along with integration of ocean environmental data from historical sources such as NOAA, JAMSTEC, and Copernicus Marine. Major challenges such as non-stationarity in agent interactions, limitations of acoustic communication, and the simulation-to-reality gap are also discussed. Future research directions include Meta-Reinforcement Learning (Meta-RL), adaptive role assignment based on energy utility, large-scale decentralized MARL architectures, and training based on realistic ocean scenarios. This review and the supporting experiments are expected to serve as a strategic foundation for the development of efficient, robust, and scalable multi-agent AUV systems for future marine missions.",TOPIC
10.1109/ACCESS.2025.3606062,Research on Detection Optimization of the 3.0 Base Version of the Metering Automation System Based on Reinforcement Learning Algorithm,"In response to the problems of low detection efficiency and insufficient strategy optimization ability of the current base version detection tools in dynamic and complex scenarios, this paper proposes a detection optimization framework based on deep reinforcement learning. Firstly, by constructing a dual-mode dynamic testing model that integrates local detection and online detection, the base version quality assessment process is formalized as a Markov decision process, where the state space covers key indicators such as functional integrity, interface consistency, and storage throughput (refer to the GB/T 25000 standard). Secondly, an intelligent agent based on the Deep Q-Network (DQN) is designed to achieve adaptive optimization of detection dimension selection, feature index priority scheduling, and test case generation. A multi-objective hybrid reward mechanism (R =0.6 defect discovery rate +0.3 throughput gain - 0.1* time cost) is innovatively introduced to balance detection quality and resource consumption in dynamic interaction. Experiments show that this method improves detection efficiency by 37.2% compared to traditional schemes, with a feature index coverage rate of 98.5%, and its robustness in multi-unit detection scenarios is verified in third-party testing. The developed microservice architecture detection tool integrates a reinforcement learning decision interface, supporting real-time visualization of detection progress and automatic generation of electronic reports. This research provides an innovative solution for the full life cycle quality control of smart grid base versions.",TOPIC
10.1109/ACCESS.2025.3606121,UAV Swarm Trajectory Design for Wireless Networks Using Genetic Algorithm-Driven Repulsion Forces,"Uncrewed Aerial Vehicle (UAV) swarms are increasingly recognized for their versatility and affordability. These swarms have enhanced various applications, including agriculture, surveillance, delivery services, and monitoring. However, fully utilizing the capabilities of UAV swarms requires addressing challenges related to trajectory design, particularly the Multiple Traveling Salesman Problem (MTSP). It involves optimizing the paths of multiple UAVs while avoiding collisions, minimizing overlap and interference, and managing the overall size of the swarm. These challenges highlight the complexities involved in developing high-performance, organized UAV swarm operations. We propose a novel approach based on repulsion force in UAV swarm trajectory design to tackle these issues. Our method utilizes a Genetic Algorithm (GA) to generate a dynamic Repulsion Force (RF) that optimizes the distance between UAVs and the size of the swarm. This approach reduces interference and overlap while effectively navigating the limitations posed by the MTSP. Our proposed solution aims to design efficient trajectories that enhance the overall performance of UAV swarms. We compared our proposed method to existing algorithms, including the MTSPGA, Particle Swarm Optimization (PSO), 2-OPT, Ant Colony (AC) Optimization, and Simulated Annealing (SA), using simulations and evaluations. The results indicate that our proposed method effectively optimizes travel distances and times, reduces interference levels and overlapping, prevents collisions between UAVs, and enhances the size of the UAV swarm. Overall, our method outperforms current approaches, demonstrating its effectiveness for UAV-based applications.",TOPIC
10.1109/ACCESS.2025.3606914,Deep Reinforcement Learning for Intelligent Load Balancing in Smart Power Grids,"This study addresses the challenge of intelligent load balancing in modern power grids, which are increasingly characterized by renewable energy sources, electric vehicles, and decentralized generation. Traditional control mechanisms, often based on rule-based systems, fail to cope with the dynamic and stochastic nature of these grids. To overcome these limitations, we propose an innovative hierarchical reinforcement learning framework for load balancing, integrating Proximal Policy Optimization (PPO) within a dual-layer control architecture. This framework employs both local agent-based decision-making and a global critic network for system-wide optimization. The approach is designed to adapt to the temporal and spatial variability inherent in modern power grids, ensuring efficient load distribution and stability across various operating conditions. We introduce the Grid-aware Structured Embedding Network (GSEN), a novel model that enhances power grid state estimation by capturing multi-scale topological and temporal dependencies. GSEN integrates spectral graph convolutions and temporal attention mechanisms, providing robust, real-time predictions. The Stability-Aware Adaptive Inference Mechanism (SAIM) enhances the stability and adaptability of the model by dynamically adjusting inference pathways based on real-world grid conditions. Empirical evaluations demonstrate that the proposed framework outperforms traditional methods and state-of-the-art models, showing significant improvements in load balancing efficiency and energy dispatch precision. These findings underline the potential of reinforcement learning-based solutions to meet the growing complexity and demands of smart power grids, providing a scalable and adaptable solution for intelligent grid management.",TOPIC
10.1109/ACCESS.2025.3607672,IEEE Access,"Object navigation remains a fundamental challenge in robotics, particularly when agents must reach targets specified by semantic categories. While existing approaches often treat semantic understanding and navigation as separate components, we demonstrate that their tight coupling is crucial for robust performance. We present SegDT (Segmenting Decision Transformer), a novel architecture that jointly learns to predict semantic segmentation masks and navigation actions through a unified transformer-based model. Our key insight is that temporal information from sequential observations can simultaneously enhance both segmentation quality and navigation decisions. To address the inherent challenges of transformer-based navigation—notably poor sample efficiency and computational complexity—we introduce a two-phase training approach: offline pretraining on expert demonstrations followed by online policy refinement through knowledge transfer from a recurrent neural network. Extensive experiments in the Habitat simulator demonstrate that SegDT achieves higher results using predicted segmentation masks, outperforming a single-frame baseline with a pre-trained semantic segmentation model and approaching the performance of systems using ground truth semantic information. Our ablation studies reveal that SegDT’s temporal processing also improves segmentation quality, highlighting the synergistic benefits of joint optimization. When integrated into complete object navigation systems, SegDT enhances overall performance by 9.6% in path efficiency compared to the state-of-the-art method. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ACCESS.2025.3607760,Platform for Detecting Illegal Landfills Using Computer Vision and Satellite Imagery From Web Map Service,"This study addresses the environmental problems of landfills through an innovative solution that combines artificial vision, satellite image analysis and agent-based architecture. The detection of these sources of contamination is particularly complex due to the visual heterogeneity of the objects present in the aerial views. To this end, a proprietary dataset has been developed aimed at identifying irregular landfills from aerial and satellite images. The research focuses on the application and comparison of the latest generation algorithms YOLOv8, YOLOv11 and YOLOv12, deployed in a multi-agent system developed with PANGEA, which allows a distributed and efficient management of the detection process. In addition, a dynamic platform has been implemented that allows the user to select geographical areas within Spain and verify the existence of landfills in these areas. In the event of detection, the system cross-references the results with official public information to determine whether the landfill is legal or illegal. Experiments show that YOLOv8 achieves outstanding performance with an accuracy of 97.25%, recall of 89.59%, F1-score of 93.27%, mAP@50 of 94.74% and mAP@50-95 of 79.06%, evidencing its potential for automated landfill detection in a real operating environment.",TOPIC
10.1109/ACCESS.2025.3609317,Model-Free Reinforcement Learning in Microgrid Control: A Review,"The global shift toward distributed energy resources (DERs) has accelerated the deployment of microgrids (MGs), introducing unprecedented control challenges that traditional strategies often struggle to address. Model-free reinforcement learning (MFRL) has emerged as a promising paradigm for adaptive, intelligent control without the need for explicit system modeling. This paper presents a comprehensive review of MFRL applications in MG control, proposing a systematic taxonomy that classifies existing approaches by control hierarchy, architectural configuration, operational modes, and action spaces. We analyze critical design considerations—including reward function shaping, exploration strategies, and computational requirements—that influence practical deployment. Furthermore, we systematically evaluate key MFRL algorithms and map their suitability across primary, secondary, and tertiary control levels. By examining recent applications, we highlight that MFRL has reached considerable maturity across all control hierarchies, revealing clear trends: continuous-action methods excel in real-time primary control, distributed schemes enhance scalability in secondary coordination, and multi-agent frameworks enable complex tertiary-level optimization. Finally, the review identifies persistent implementation challenges and offers practical guidance for algorithm selection and deployment strategies in modern MG systems. This review aims to serve both researchers and practitioners seeking to deploy MFRL in modern MG systems.",TOPIC
10.1109/ACCESS.2025.3611650,IEEE Access,"This paper presents a novel fault-tolerant distributed control framework for integrated active/reactive power optimization in microgrids. The architecture employs Distributed Agent Controllers (DACs) equipped with -sensitivity-based gradient methods, establishing a dual-module control structure with separate but coordinated Active Power Control (APC) and Reactive Power Control (RPC) components. The framework introduces four key advances: 1) an intelligent priority-based load-shedding mechanism within APC that maintains service quality, 2) an adaptive generation dispatch scheme coordinated with RPC, 3) decentralized optimization algorithms enabling local decision-making at each DAC, and 4) a resilient communication architecture with self-healing capabilities for continuous operation during contingencies. Implementing a multi-layer real-time approach for load management, the system dynamically evaluates consumption priorities, grid conditions, and generation constraints. Comparative simulations demonstrate superior voltage stability maintenance, reduced unnecessary load shedding, and enhanced power distribution efficiency versus conventional methods. The solution’s distinctive advantages include: 1) Grid resilience through reduced central communication dependence, 2) operational adaptability across diverse scenarios, and 3) scalable architecture for modern microgrid applications. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ACCESS.2025.3614675,"Research on Personalized Recommendation Based on Matrix Factorization, Clustering, and Deep Reinforcement Learning","To address the challenges of data sparsity, cold start, and insufficient dynamic adaptability in traditional recommendation systems, this study proposes a personalized recommendation model named CDRL-MF, which integrates Matrix Factorization, multi-view clustering, and Deep Reinforcement Learning. The method achieves performance improvement through a three-stage collaborative optimization process: First, a dual-channel architecture employing Singular Value Decomposition and an Artificial Neural Network generates high-quality user and item embeddings. Second, multi-view K-means clustering is introduced to construct precise user interest clusters by synthesizing user rating patterns, statistical attributes, and content features. Finally, a Cluster-Guided Deep Reinforcement Recommendation framework is designed, where a DDPG-based agent integrates user states, item cluster features, and real-time feedback to achieve continuous dynamic optimization of recommendation policies. Experimental results on the MovieLens 1M dataset demonstrate that the CDRL-MF model significantly outperforms multiple baseline models across key evaluation metrics, including rating prediction (MAE, RMSE) and Top-N recommendation (Precision, Recall, F1, NDCG). Furthermore, the model exhibits excellent balancing capabilities in recommendation diversity, novelty, and user group fairness. By incorporating differential privacy and federated learning mechanisms, it maintains acceptable performance trade-offs while ensuring user privacy protection. Additional experiments on large-scale datasets such as Amazon Reviews and Netflix Prize further validate its robust generalization capability and practicality.",TOPIC
10.1109/ACCESS.2025.3615942,Construction of Knowledge Graph for Enterprise Mergers and Acquisitions: Cross-Domain Value Mining Method of Large Language Model (LLM) and Graph Neural Network,"Enterprise mergers and acquisitions (M&A) involve complex, cross-domain decision-making processes that rely on both structured and unstructured data sources. Traditional knowledge graph construction techniques, often rule-based or reliant on shallow learning, struggle with scalability, adaptability, and semantic generalization in such dynamic environments. A new framework for cross-domain value mining is introduced, which integrates Large Language Models and Graph Neural Networks to enable enterprise M&A knowledge graph construction and inference. Central to our approach is the E-GraphNet (Enterprise Graph Network), a modular graph-based neural architecture that models enterprises as asynchronous, multi-agent decision systems. Each node in E-GraphNet represents an enterprise entity, while edges encode organizational dependencies and communication delays. E-GraphNet introduces edge-conditioned message passing and policy-execution signatures to enable dynamic alignment with strategic directives, ensuring real-time and scalable inference across distributed enterprise contexts. To further enhance adaptability under uncertainty and partial observability, we introduce Decision-Aware Perturbation Routing (DAPR). DAPR injects controlled perturbations into decision pathways, simulates distributed decision shifts, and optimizes routing through attention-guided correction mechanisms. This enables the system to remain robust in the face of delayed feedback and external perturbations, improving resilience in real-world M&A scenarios. Evaluation across various enterprise datasets indicates that the LLM-GNN framework delivers superior performance compared to existing baselines in tasks related to knowledge extraction and graph inference. The framework offers a scalable, interpretable, and efficient solution for modeling enterprise structures and forecasting M&A outcomes, advancing the field of intelligent enterprise analytics.",TOPIC
10.1109/ACCESS.2025.3616179,Reinforcement Guided Genetic Algorithm for Application Mapping in Network-on-Chip Architectures: Toward Transparent and Efficient MPSoC Scheduling,"In this paper, we present a novel hybrid application mapping framework that integrates Genetic Algorithm (GA) with Reinforcement Learning (RL) to optimize task allocation in 2D Network-on-Chip based Multiprocessor System-on-Chip (NoC-based MPSoC) architectures. The goal is to reduce overall communication costs and improve runtime efficiency during the task-to-core mapping process. The RL agent is embedded within the GA loop to dynamically steer selection, crossover, and mutation operations using real-time feedback on mapping quality. Our methodology is evaluated on both real applications (e.g., PIP, MPEG, VOPD) and synthetic TGFF workloads across NoC mesh sizes from  $3\times 3$  to  $12\times 11$ . Experimental results demonstrate that GA+RL consistently outperforms the baseline GA. For instance, in the TGFF-G5 benchmark (80 cores), the GA+RL approach achieved a minimum communication cost of 116.354, compared to 244.645 with original GA, representing over 52% improvement. Across all trials, GA+RL also showed lower standard deviations and earlier convergence generations. To improve interpretability, we incorporate Explainable AI (XAI) techniques using SHapley Additive exPlanations (SHAP) to analyze feature contributions. Results reveal that average communication hops and total bandwidth are key factors influencing mapping efficiency. The GA+RL model demonstrates greater transparency and consistency, aiding design-time decisions. This work has direct implications for industrial platforms, including Kalray MPPA-256 (autonomous vehicles), Intel SCC (cloud/HPC), Adapteva Epiphany (IoT Edges), and Tilera TILE-Gx (Cybersecurity), where efficient and adaptive application mapping is critical. Aligned with UN SDG 2 (Zero Hunger), the framework also supports real-time scheduling in agriculture IoT systems, enabling energy-efficient deployment of smart technologies to enhance food production and sustainability.",TOPIC
10.1109/ACCESS.2025.3622382,Herbguard: An Ensemble Deep Learning Framework With Efficientnet and Vision Transformers for Fine-Grained Classification of Medicinal and Poisonous Plants,"Classifying whether a plant is herbal or poisonous is a significant challenge for trekkers, hikers, and nature enthusiasts, particularly in remote areas where several unfamiliar plant species are encountered. Consumption or even close contact with some poisonous plant species may lead to serious health risks, highlighting the need for an intelligent and real-time classification system. In this study, we propose an approach based on deep-learning to classify plants into several species under herbal and poisonous categories. The system employs Convolutional Neural Network (CNN) based EfficientNetV2-S, designed for local feature extraction, trained on segmented images, and transformer-based ViT-Tiny, capable of capturing global dependencies in images, fine-tuned on unsegmented raw images. Both models are trained using a two-stage fine-tuning strategy with label smoothing, MixUp, and CutMix augmentations. Preprocessing steps include CLAHE-based contrast enhancement, HSV masking and GrabCut segmentation, that are applied to training images to focus on relevant plant regions. The models are evaluated on 48 different plant species, consisting of 40 herbal and 8 poisonous species, ultimately achieving species-level accuracies of 95.86% (EfficientNet) and 96.69% (ViT) on the validation dataset. A soft-voting ensemble of the two models further improves species-level accuracy to 97.10% upon validation and 98.43% upon testing, while category-level accuracy remains consistently above 99.7% for all the models. These results demonstrate that combining convolutional and transformer-based approaches leads to a robust, highly accurate classification system that is capable of distinguishing varieties of medicinal and poisonous plants, offering a practical tool for safe trekking, biodiversity monitoring, and herbal medicine research.",TOPIC
10.1109/ACCESS.2025.3624285,PerceptNet-V2X: Perception Network for Vehicle to Everything Scenarios in Autonomous Driving,"Collaborative perception is essential for autonomous vehicles (AVs) to overcome individual sensing limitations in occluded or complex traffic environments. This paper introduces PerceptNet-V2X, a novel intermediate collaboration framework for scalable perception in Vehicle-to-Everything (V2X) settings. At its core is the Full Perspective View (FPV), a new compact 2D representation of 3D point clouds that preserves critical geometric structure while enabling effective multi-agent spatial reasoning. Unlike conventional Bird’s Eye View (BEV) projections, FPV mitigates data sparsity and enhances compatibility with modern 2D detection architectures. The framework integrates the FPV representation with state-of-the-art detectors such as YOLOV12 and RT-DETR, demonstrating flexible and modular deployment. Comprehensive evaluations on the OPV2V and V2X-Real datasets validate FPV’s impact on collaborative perception performance. On the OPV2V synthetic benchmark, PerceptNet-V2X achieves 95.63% AP@0.5 and 94.36% F1@0.5, representing improvements of up to 5.02% AP and 3.15% F1 over traditional BEV representations. On the V2X-Real real-world dataset, the framework delivers 61.55% mAP@0.3, a 16% gain over prior approaches. Overall, this work contributes a scalable, modular and effective collaborative perception solution centered on the FPV representation, advancing the reliability of multi-agent autonomous systems. Code available at: https://github.com/brumocas/PerceptNet_FuseNet_V2X",TOPIC
10.1109/ACCESS.2025.3624701,SwinMalle-UNet: A Hybrid U-Net Integrating Swin Transformer and Deformable Fusion Modules for Brachial Plexus Nerve Segmentation in Ultrasound Imaging,"Precise segmentation of brachial plexus nerves in ultrasound imaging is essential for clinical anesthesia guidance and neurological evaluation. However, achieving precise nerve boundary delineation remains challenging due to the inherently low contrast, speckle noise, and the complex, variable morphology of nerves in ultrasound data. While deep learning models have shown promise, traditional Convolutional Neural Networks (CNNs) are constrained by fixed receptive fields, limiting their adaptability to non-rigid nerve structures. Conversely, Transformer-based models, while excelling at global context modeling, often face challenges with fine-grained detail recovery in data-limited medical scenarios. To address these limitations, we propose SwinMalle-UNet, a novel hybrid segmentation network that innovatively integrates the Swin Transformer with a deformable fusion mechanism within the classic U-Net architecture. The encoder employs a hierarchical Swin Transformer to efficiently capture multi-scale global contextual information. The decoder, our core contribution, features a deformable fusion module that dynamically adjusts feature sampling positions in a data-driven manner. This design facilitates precise pixel-level feature alignment and enhances adaptability to the irregular morphology of brachial plexus nerves. We comprehensively evaluated our model on a core multi-target brachial plexus dataset (UBPD) and a large-scale public benchmark (USNS). Experimental results demonstrate that our approach achieves state-of-the-art performance, outperforming a wide range of baseline and state-of-the-art models such as U-Net, Attention U-Net, DeepLabV3+, TransUNet, an EfficientFormerV2-based model (EFv2-UNet), and a strong Swin-UNet baseline.",TOPIC
10.1109/ACCESS.2025.3624822,RegimeFolio: A Regime Aware ML System for Sectoral Portfolio Optimization in Dynamic Markets,"Financial markets are inherently non-stationary, with shifting volatility regimes that alter asset co-movements and return distributions. Standard portfolio optimization methods, typically built on stationarity or regime-agnostic assumptions, struggle to adapt to such changes. To address these challenges, we propose RegimeFolio, a novel regime-aware and sector-specialized framework that, unlike existing regime-agnostic models (e.g., DeepVol, DRL optimizers), integrates explicit volatility regime segmentation with sector-specific ensemble forecasting and adaptive mean–variance allocation. This modular architecture ensures forecasts and portfolio decisions remain aligned with current market conditions, enhancing robustness and interpretability in dynamic markets. RegimeFolio combines three components: i) an interpretable VIX-based classifier for market regime detection; ii) regime and sector-specific ensemble learners (Random Forest, Gradient Boosting) to capture conditional return structures; and iii) a dynamic mean–variance optimizer with shrinkage-regularized covariance estimates for regime-aware allocation. We evaluate RegimeFolio on 34 large cap U.S. equities from 2020 to 2024. The framework achieves a annualized return of 25.1%, a Sharpe ratio of 1.17, a 12% lower maximum drawdown, and a 15–20% improvement in forecast accuracy compared to conventional and advanced machine learning benchmarks. These results show that explicitly modeling volatility regimes in predictive learning and portfolio allocation enhances robustness and leads to more dependable decision-making in real markets.",TOPIC
10.1109/ACCESS.2025.3626953,GPS-Based Beam Prediction Using Lightweight Deep Learning Models for mmWave Networks,"Millimeter-wave (mmWave) communication systems use narrow, directional beams, but exhaustive beam training is costly in dynamic settings. Prior location-assisted methods often rely on synthetic data that ignores the noise of real-world GPS measurements. We propose a unified framework that first denoises GPS trajectories with Gaussian-process regression and then predicts beams using a bidirectional long short-term memory network with an attention mechanism. Across nine real-world scenarios, our approach improves Top-k accuracy by up to 36%, reduces received-power loss by more than 1 dB, and cuts beam-training overhead by up to 95%. These results highlight the effectiveness of the proposed framework in bridging the gap between simulation-driven research and real-world mmWave beam alignment.",TOPIC
10.1109/ACCESS.2025.3629128,Contrast-aware image enhancement network for low-light images,"Low-light image enhancement is a challenging problem in computer vision due the inherently fragile nature of low-light images, which suffer from low brightness, poor contrast, and color distortion. This study proposes a contrast-aware low-light image enhancement network in the wavelet domain. The contrast measure defined as the ratio of the high-frequency coefficient to the low-frequency coefficient serves as a key factor in restoring natural illumination. The proposed network includes U-shaped lightening and sharpening blocks, complemented by lightened and sharpened feature attention blocks. The lightening block, which uses wavelet low-frequency subbands as input, is employed to restore brightness. The lightened information is then transmitted to high-frequency subbands through the lightened feature attention block. The sharpening block is used to enhance image detail within high-frequency subbands. The sharpened information is then relayed to the lightened low-frequency subbands to balance the image contrast. The proposed network achieves balanced contrast by facilitating the exchange of enhancement information between the low- and high-frequency subbands. Additionally, we introduce a saturation guide block to restore image color effectively. This study restores each component through wavelet decomposition and uses the concept of contrast to restore it to a natural image. This could be further developed by combining color space decomposition. The effectiveness of the proposed network is evaluated through extensive experiments on well-known benchmarks. Simulation results confirm that the proposed low-light enhancement network surpasses other state-of-the-art approaches.",TOPIC
10.1109/ACCESS.2025.3630331,Enhanced Multi-Critic Deep Reinforcement Learning for Channel Estimation in 6G N2V or I2V Communications,"The need for self-adaptive systems is increasing with the growth in automation to improve accuracy and performance. Such self-adaptive systems can be built using Reinforcement Learning (RL) models with the help of simulated and recorded data. Deep Reinforcement Learning (DRL) is proposed by infusing NN into RL models and can be used to improve performance in use cases with sparse reward distributions. Traditional Actor-Critic DRL models act with a single critic and single actor network in case of on-policy execution. In contrast, the performance of the agent which makes decisions in the environment improves when considering the information exchange from multiple critics. In this work, the proposed Teacher Tutor Trainee a version of Multi Critic architecture provides the impact of information exchange from multiple critics for a channel estimation use case. Channel Estimation is a method of calculating the impact of the propagation medium and other external factors that deteriorate a signal and its optimization. The performance improvement can be observed from the increase in the explained variance. On implementation, it is observed that the Proximal Policy Optimization model has shown better performance than the Advantage Actor-Critic model.",TOPIC
10.1109/ACCESS.2025.3631513,Automated Diagnosis of Knee Osteoarthritis: A Stacked Ensemble Deep Learning Approach with Explainable AI Techniques,"Knee osteoarthritis (KOA) is a widespread degenerative joint disease that poses significant global challenges owing to delayed diagnosis and treatment, often resulting in severe disability. Despite extensive research on predicting KOA, many proposed methods lack reliability, because they fail to incorporate explainable AI (XAI) methodologies, robust preprocessing techniques, and appropriate hyperparameter tuning. This study introduces a deep learning framework for KOA classification, addressing both binary (diagnosis) and multi-class (severity prediction) classification tasks using the Osteoarthritis Initiative (OAI) dataset. Our approach is enhanced by a comprehensive image prepocessing pipeline that includes scaling, sharpening, denoising, histogram equalization, and contrast enhancement, which standardizes image quality and highlights crucial features for classification. The proposed stacked ensemble model, which integrates Xception, EfficientNetB5, and InceptionV3, surpasses individual models, achieving 86.29% accuracy in KOA diagnosis and 96.93% in KOA severity prediction. To ensure transparency and interpretability, we incorporated advanced explainability tools, including Gradient-weighted Class Activation Mapping (Grad-CAM), Faster Score-CAM, and Local Interpretable Model-agnostic Explanations (LIME), providing clear visual insights into the model’s decision-making process. Our findings present a balanced approach that combines performance with transparency, potentially leading to earlier and more accurate KOA diagnoses.",TOPIC
10.1109/ACCESS.2025.3631733,"Multimodal Graph-based Stacked Transformer Network for Brain Tumor Classification, Segmentation and Report Generation","Conventional artificial intelligence driven healthcare diagnostics tend to process medical images and clinical text in isolation, losing possible synergistic insights that emerge from their integration. This work presents a novel Multimodal Graph-Based Stacked Transformer Network (MM-GSTN) that combines both modalities of text and vision to create interpretable diagnostic reports. The MM-GSTN combines heterogeneous data through vision transformers and language models with a clinical knowledge graph to encode relationships among patient data, diseases, and symptoms. The proposed architecture, MM-GSTN, is powered by Meta’s Segment Anything Analysis (SAM) for accurate brain mapping, along with the EfficientNet-B0 model, which is combined with a multistacked transformer network, resulting in a classification accuracy of 99%. The system further produces a comprehensive diagnostic report from the finetuned Llama-3.2-11B Vision-Instruct language model utilizing Low-Rank Adaptation (LoRA) training technique, resulting in improved Rouge-1 and Rouge-L scores from 0.005 to 0.072 and BLEU score from 0.036 to 0.068. Integrating a graph network into the overall system maps the relationships between patient data, diseases, and symptoms, which significantly enhances the diagnostic accuracy and clinical decision-making. This work highlights the potential of MM-GSTN as a scalable and explainable AI tool for the diagnosis of brain tumors.",TOPIC
10.1109/ACCESS.2025.3632219,Deep Learning Approaches for Predicting Tourism Demand in Urban Destinations,"The increasing complexity of urban systems necessitates advanced computational frameworks to effectively model and predict dynamic phenomena. Traditional statistical models often fall short in capturing the intricate spatiotemporal patterns inherent in such systems, particularly when addressing multifaceted factors like environmental sustainability, infrastructural constraints, and policy interventions. To overcome these limitations, I propose a novel forecasting framework that combines the Tourism Flow-Response Network (TFRNet) with a Policy-Aware Equilibrium Routing (PAER) strategy. This integrated system models spatiotemporal tourism demand alongside policy feedback and system constraints. Our approach, termed the Tourism Flow-Response Network (TFRNet), models urban dynamics through a network where nodes represent distinct regions and edges encapsulate the flow between them. This structure allows for the incorporation of various factors, including congestion levels, environmental impacts, and policy-induced deterrents. Building upon TFRNet, we develop the Policy-Aware Equilibrium Routing (PAER) strategy, which employs game-theoretic principles to align individual agent behaviors with overarching system objectives. PAER facilitates adaptive policy adjustments, such as dynamic pricing and regulatory measures, to guide the system towards equilibrium states that balance utilityization with sustainability goals. Empirical evaluations demonstrate that our integrated framework outperforms traditional models in predictive accuracy and adaptability, offering a robust tool for urban planners and policymakers. The TFRNet + PAER framework represents the primary contribution of this work, providing both predictive accuracy and actionable policy integration for sustainable tourism forecasting. This research aligns with the scope of Frontiers in Computer Science by advancing computational methodologies that address complex, real-world challenges through interdisciplinary approaches.",TOPIC
10.1109/ACII52823.2021.9597427,,"Negotiation is a complex social interaction that encapsulates emotional encounters in human decision-making. Virtual agents that can negotiate with humans are useful in pedagogy and conversational AI. To advance the development of such agents, we explore the prediction of two important subjective goals in a negotiation - outcome satisfaction and partner perception. Specifically, we analyze the extent to which emotion attributes extracted from the negotiation help in the prediction, above and beyond the individual difference variables. We focus on a recent dataset in chat-based negotiations, grounded in a realistic camping scenario. We study three degrees of emotion dimensions - emoticons, lexical, and contextual by leveraging affective lexicons and a state-of-the-art deep learning architecture. Our insights will be helpful in designing adaptive negotiation agents that interact through realistic communication interfaces. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ACIIW52867.2021.9666315,,"Modern day conversational agents are trained to emulate the manner in which humans communicate. To emotionally bond with the user, these virtual agents need to be aware of the affective state of the user. Transformers are the recent state of the art in sequence-to-sequence learning that involves training an encoder-decoder model with word embeddings from utterance-response pairs. We propose an emotion-aware transformer encoder for capturing the emotional quotient in the user utterance in order to generate human-like empathetic responses. The contributions of our paper are as follows: 1) An emotion detector module trained on the input utterances determines the affective state of the user in the initial phase 2) A novel transformer encoder is proposed that adds and normalizes the word embedding with emotion embedding thereby integrating the semantic and affective aspects of the input utterance 3) The encoder and decoder stacks belong to the Transformer-XL architecture which is the recent state of the art in language modeling. Experimentation on the benchmark Facebook AI empathetic dialogue dataset confirms the efficacy of our model from the higher BLEU-4 scores achieved for the generated responses as compared to existing methods. Emotionally intelligent virtual agents are now a reality and inclusion of affect as a modality in all human-machine interfaces is foreseen in the immediate future. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/AERO.2004.1367716,IEEE Aerospace Conference Proceedings,"The Mobile Exploration System Project (MEX) at NASA Ames Research Center has been conducting studies into hybrid communication networks for future planetary missions. These networks consist of space-based communication assets connected to ground-based Internets and planetary surface-based mobile wireless networks. These hybrid mobile networks have been deployed in rugged field locations in the American desert and the Canadian arctic for support of science and simulation activities on at least six occasions. This work has been conducted over the past five years resulting in evolving architectural complexity, improved component characteristics and better analysis and test methods. A rich set of data and techniques have resulted from the development and field testing of the communication network during field expeditions such as the Haughton Mars Project and NASA Mobile Agents Project. This paper defines design, analysis and test methods for hybrid mobile communication networks, identifying the key issues and constraints that affect performance in both the radio frequency (RF) and network engineering disciplines. Previous work by the MEX team has addressed the architecture and detailed analysis of wireless networks including the results of field tests. We continue the analysis using a new 802.11b backbone utilizing two repeaters that significantly increase range and coverage but greatly increase latency, which reduces overall network throughput. The addition of a satellite link can result in significant additional throughput loss due to light-speed delays in the space segment interacting with variable latencies in the multi-hop wireless network. The paper analyzes and presents RF domain field test results combined with network performance metrics which describe a comprehensive approach for designing and optimizing future hybrid mobile networks. © 2012 Elsevier B.V., All rights reserved.",TOPIC
10.1109/AERO.2010.5446778,IEEE Aerospace Conference Proceedings,"This paper addresses various aspects of the design and development of the pilot interface for the exploitation of highly advanced flight plan capabilities specifically designed for Unmanned Aerial Systems (UAS). This flight plan capabilities are built on top a flexible and reusable hardware/ software architecture designed to facilitate the development of UAS-based applications. This flexibility is organized into an user-parameterizable UAS Service Abstraction Layer (USAL). The USAL defines a collection of standard services are their interrelations as a basic starting point for further development by UAS users. Previous research presented the advanced flying capabilities of a UAS as an extension of the Flight Control System (FCS) functionalities. Assuming a UAS with a FCS that ensures safe and stable maneuvers, we complement it with a highly capable flight plan management system. USAL flight plan is characterized by offering semantically much richer constructs than those present in most current UAS autopilots, which rely on simple lists of waypoints. This list of waypoints approach has several important limitations: it is difficult to specify complex trajectories and it does not support constructs such as conditional forks or iterations, small changes may imply having to deal with a considerable amount of waypoints and it provides no mechanism for adapting to mission time circumstances. To address these issues a new flight plan specification mechanism is proposed, that incorporates a leg concept extended to accommodate higher level constructs for specifying iterations and forks. Additional leg types, referred to as parametric leg, are also introduced. The trajectory defined by a parametric leg is automatically generated as a function of mission variables, enabling dynamic behavior and providing a very valuable means for adapting the flight to the mission evolution. Another level of adaption is provided by the conditions governing the decision-making in intersection legs and the finalization of iterative legs. In this work we will focus on the development of the pilot interface for the exploitation of the introduced flight plan capabilities. The interface design requirements address an increase level of automated operation and support to react to unexpected requirements due to mission changes. Therefore, this interaction includes the available mechanisms to update the flight-plan according to UAS mission requirements, skip parts of it, react to operational contingencies, etc. ©2010 IEEE. © 2010 Elsevier B.V., All rights reserved.",TOPIC
10.1109/AERO.2019.8741623,IEEE Aerospace Conference Proceedings,"There are benefits to be gained from combining the strengths of modeling frameworks that capture social, environmental and design-based considerations. Many of the important challenges of the next decade lie at the intersection of the natural environment, human decision making and the design of space technology to inform decision making. There are 17 Sustainable Development Goals outlined by the United Nations through 2030. Several of these Sustainable Development Goals can be addressed by asking: 1) What is happening in the natural environment? 2) How will humans be impacted by what is happening in the natural environment? 3) What decisions are humans making in response to environmental factors and why? and 4) What technology system can be designed to provide high quality information that supports human decision making? The answers to these questions are often interrelated in complex ways; thus it is helpful to use a framework from complex systems to integrate these questions. Within the list of Sustainable Development Goals, several fit the three questions above, including #2 Zero Hunger, #6 Clean Water and Sanitation, #13 Climate Action, #14 Life Below Water, and #15 Life on Land. This paper presents a research agenda to apply environmental modeling, complex systems modeling, and model-based systems engineering to inform the design of space systems in support of the Sustainable Development Goals. This work builds on previous research in the following areas: 1) physics-based environmental modeling; 2) complex systems modeling to simulate human decision making using agent-based models; and 3) model based systems engineering to inform the architecture of satellites or space-enabled data systems. This paper presents a review of the state of the art, shows examples of how these methods have been combined to inform space system design and presents a future research agenda. As an example, the paper discusses a project related to Sustainable Development Goal #15 to design an earth observation system using space-based and ground-based data collection regarding an invasive plant species in Benin, West Africa. In this example, insights are needed regarding natural variables (i.e. salinity, temperature and turbidity of local waterways), social variables (i.e. economic impact of the invasive plant on local communities), and design variables (i.e. the technical performance of existing imagery satellites and in-situ sensor networks). © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1109/APCASE.2015.8,,"In this paper is proposed an architecture of a Reflective Middleware, which aims to manage an Intelligent Environment of Learning based in cloud learning, which is modeled using a Multiagent system. The Middleware is able to monitor the environment consisting of physical and virtual objects, intelligent or not, based on the context. The middleware manages educational services in the cloud to enhance the learning experience of students, either collaboratively or individually. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1109/BigComp51126.2021.00080,,"Empathy is a fundamental mechanism of human interactions. As such, it should be an integral part of Human-Computer Interaction systems to make them more relatable. With this work, we focused on conversational scenarios where integrating empathy is crucial to perceive the computer like a human. As a result, we derived the high-level architecture of an Empathetic Conversational Agent we are willing to implement. We relied on theories about artificial empathy to derive the function approximating this mechanism and selected the conversational aspects to control for an empathetic interaction. In particular, we designed a core empathetic controller manages the empathetic responses, predicting, at each turn, the high-level content of the response. The derived architecture integrates empathy in a task-agnostic manner; hence we can employ it in multiple scenarios by changing the objective of the controller. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/CDC42340.2020.9303979,Proceedings of the IEEE Conference on Decision and Control,"We consider the problem of controlling a set of dynamically decoupled plants where the plants' subcontrollers communicate with each other according to a fixed and known network topology. We assume the communication to be instantaneous but there is a fixed processing delay associated with incoming transmissions. We provide explicit closed-form expressions for the optimal decentralized controller under these communication constraints and using standard LQG assumptions for the plants and cost function. Although this problem is convex, it is challenging due to the irrationality of continuous-time delays and the decentralized information-sharing pattern. We show that the optimal subcontrollers each have an observer-regulator architecture containing LTI and FIR blocks and we characterize the signals that subcontrollers should transmit to each other across the network. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/CIG.2017.8080425,,"We present and describe CiF-CK - a social agent architecture that models reasoning about persistent social interactions to improve narrative engagement and play experience for human interactors. The architecture is inspired by McCoy et al's Comme il-Faut (CiF) architecture that represented rich social interactions between agents that included emotions, social and relationship contexts, and longer term mood. The key contribution of this work is in adapting the richness of social interactions from CiF to a first-person interaction experience and a released distribution of its implementation on the Skyrim game engine. The released modification has been successful in the player community for the popular game. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1109/CIG.2018.8490399,"IEEE Conference on Computatonal Intelligence and Games, CIG","The design of serious games requires developers to tackle pedagogical challenges calling for advanced solutions that the entertainment industry might deem too risky to pursue. One such challenge is the creation of autonomous socially intelligent characters with whom players can practice different social skills. Although there are several architectures in the field of virtual agents that are designed specifically to enable more human-like interactions, they are still not widely adopted by game studios that develop serious games, in particular for learning. In this paper, we present a virtual agent toolkit that was specifically developed with the intent of making agent-based solutions more accessible and reliable to game developers. To this end, a collaborative effort was established with a game studio that has used the toolkit to develop two different serious games. Among other advantages, the toolkit facilitated the inclusion of a dynamic model of emotions that affects not just how the character looks and acts but also how the player's performance is determined. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1109/CISIS.2010.168,,"Resource planning and scheduling for a given job is a central issue in the scientific problem solving Grid oriented environments. The workflow oriented approach to this issue has the advantage of efficient allocation of resources at the workflow level by revising the allocation solution at the task level based on requirements of subsequent tasks. The PEGAF project aims at providing a platform for workflow oriented applications development, implementing adaptive scheduling strategies. After an overview of the adopted OGSA based conceptual framework, the paper presents the PEGAF platform functionality and the Service Infrastructure architecture being implemented as part of PEGAF project. © 2010 IEEE. © 2010 Elsevier B.V., All rights reserved.",TOPIC
10.1109/CLOUD.2010.45,,"Service-oriented architecture (SOA) paradigm for orchestrating large-scale distributed applications offers significant cost savings by reusing existing services. However, the high irregularity of client requests and the distributed nature of the approach may deteriorate service response time and availability. Static replication of components in datacenters for accommodating load spikes requires proper resource planning and underutilizes the cloud infrastructure. Moreover, no service availability guarantees are offered in case of datacenter failures. In this paper, we propose a cost-efficient approach for dynamic and geographically-diverse replication of components in a cloud computing infrastructure that effectively adapts to load variations and offers service availability guarantees. In our virtual economy, components rent server resources and replicate, migrate or delete themselves according to self-optimizing strategies. We experimentally prove that such an approach outperforms in response time even full replication of the components in all servers, while offering service availability guarantees under failures. © 2010 IEEE. © 2010 Elsevier B.V., All rights reserved.",TOPIC
10.1109/CloudNet55617.2022.9978863,,"Open Radio Access Network (O-RAN) is a novel architecture aiming to disaggregate the network components to reduce capital and operational costs and open the interfaces to ensure interoperability. In this work, we consider the problem of allocating computing resources to process the data of enhanced Mobile BroadBand (eMBB) users and Ultra-Reliable Low-Latency (URLLC) Users. Supposing the processing of users' frames from different base stations is done in a shared O-Cloud, we model the computing resources allocation problem as an Integer Linear Programming (ILP) problem that aims at fairly allocating computing resources to eMBB and URLLC users and optimizing the QoS of URLLC users without neglecting eMBB users. Due to the high complexity of solving an ILP problem, we model the problem using Reinforcement Learning (RL). Our results demonstrate the ability of our RL-based solution to perform close to the ILP solver while having much lower computational complexity. For a different number of Open Radio Units (O-RUs), the objective value of the RL agent does not deviate from the ILP objective by more than 6%. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1109/CSDE53843.2021.9718444,,"This paper implements a system of enhancing single channel night vision images using reinforcement learning approach and optimizing pixel prediction using q-table. We implemented some models to learn and process a small static images dataset using a reward bias q-table in a reinforcement learning architecture thus optimizing computational complexities and requirements of large dataset with the help of q-table. It also outperformed with respect to existing CNN models like SRCNN. Where SRCNN is observed to generate a PSNR of 24.813 on average at 256 batch size. Our system generated a PSNR of 24.1 on average with results in a 10.29% increase of relative efficiency at 3000 epoch. It has shown a 10.39% and 10.36% increase of efficiency with respect to VDSR (at 128 batch size) model and DRCN (at filter number 16) model respectively. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/CVPR46437.2021.01435,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,"Point cloud registration is a common step in many 3D computer vision tasks such as object pose estimation, where a 3D model is aligned to an observation. Classical registration methods generalize well to novel domains but fail when given a noisy observation or a bad initialization. Learning-based methods, in contrast, are more robust but lack in generalization capacity. We propose to consider iterative point cloud registration as a reinforcement learning task and, to this end, present a novel registration agent (ReAgent). We employ imitation learning to initialize its discrete registration policy based on a steady expert policy. Integration with policy optimization, based on our proposed alignment reward, further improves the agent's registration performance. We compare our approach to classical and learning-based registration methods on both ModelNet40 (synthetic) and ScanObjectNN (real data) and show that our ReAgent achieves state-of-the-art accuracy. The lightweight architecture of the agent, moreover, enables reduced inference time as compared to related approaches. Code is available at github.com/dornik/reagent. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/CVPR52688.2022.00221,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,"We propose a method for learning the posture and structure of agents from unlabelled behavioral videos. Starting from the observation that behaving agents are generally the main sources of movement in behavioral videos, our method, Behavioral Keypoint Discovery (B-KinD), uses an encoder-decoder architecture with a geometric bottleneck to reconstruct the spatiotemporal difference between video frames. By focusing only on regions of movement, our approach works directly on input videos without requiring manual annotations. Experiments on a variety of agent types (mouse, fly, human, jellyfish, and trees) demonstrate the generality of our approach and reveal that our discovered keypoints represent semantically meaningful body parts, which achieve state-of-the-art performance on key-point regression among self-supervised methods. Additionally, B-KinD achieve comparable performance to supervised keypoints on downstream tasks, such as behavior classification, suggesting that our method can dramatically reduce model training costs vis-a-vis supervised methods. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/DEVLRN.2015.7346139,,"We provide a computational model showing how turn-taking behaviors can self-organize out of sensorimotor interactions between vocalizing agents. Recent hypotheses propose that turn-taking behaviors in certain primate species emerge from a need to maintain vocal contact in a group (e.g. in dense environments preventing visual contact). In this context, vocalizations can convey information about the presence of each group member and taking turns allow to minimize the vocal signal interferences. We consider agents equipped with a cognitive architecture based on two coupled control loops: a reactive one implementing a basic regulatory behavior to maintain vocal listening and an adaptive one learning an action policy to maximize vocal contact among group members. We show that the reactive process bootstraps the adaptive learning to converge toward a collective turn-taking strategy. This model provides a computational support to the hypothesis that turn-taking can emerge from functional constraints related to group cohesion and inter-individual vocal signal interferences. We suggest future directions of research to understand how social behaviors can result from sensorimotor interactions. © 2016 Elsevier B.V., All rights reserved.",TOPIC
10.1109/DEVLRN.2016.7846800,,"We present an architecture for self-motivated agents to organize their behaviors according to possibilities of interactions proposed by the environment, and to modify the environment to construct new possibilities of interactions. The long-term goal is to design agents that construct their own knowledge of objects through experience, rather than exploiting pre-coded knowledge, and exploit this knowledge to generate complex behaviors that satisfy their intrinsic motivation principles. Self-motivation is defined here as a tendency, based on inborn behavioral preferences, to experiment and to respond to behavioral opportunities afforded by the environment. Over time, the agent integrates, through its experience, relations between interactions and object affording them in the form of data structures, called signatures of interaction, which encode the minimal spatial configurations affording an interaction. The agent then exploits these signatures to recognize distant possibilities of interactions (or affordances), but also incomplete affordances. These structures help the agent defining behaviors that can construct affordances from separated elements. Experiments with a simulated agent show that they learn to navigate in their environment, reaching, avoiding and constructing objects according to the valence of the interactions that they afford. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1109/DEVLRN.2016.7846820,,"We present an active learning architecture that allows a robot to actively learn which data collection strategy is most efficient for acquiring motor skills to achieve multiple outcomes, and generalise over its experience to achieve new outcomes for cumulative learning. In the present work, we consider the learning of tasks that are hierarchically organised, interrelated and more and more difficult. This paper proposes an algorithmic architecture, called Socially Guided Intrinsic Motivation with Active Choice of Task and Strategy for Cumulative Learning (SGIM-ACTSCL). It relies on hierarchical active decisions of what and how to learn, driven by empirical evaluation of learning progress for each learning strategy. Our learning agent uses both interactive learning and autonomous goal-babbling. It actively decides at the same time, which tasks to focus on, when to explore autonomously, and when and what to request for social guidance. We present experimental results on the physical humanoid robot Poppy that learns different types of motor skills, encoded by Dynamic Movement Primitives, in order to use a tablet (Fig. 1). We show that SGIM-ACTSCL learns significantly more efficiently than other algorithms. Moreover, it automatically organises its learning process focusing on easy tasks first, and difficult tasks afterwards. It coherently selects the best strategy with respect to the chosen outcome, manages to learn to associate the teacher with his competence domain in order to actively request social guidance for the appropriate tasks. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1109/DEVLRN.2017.8329825,,"In this paper, we argue that the future of Artificial Intelligence research resides in two keywords: integration and embodiment. We support this claim by analyzing the recent advances in the field. Regarding integration, we note that the most impactful recent contributions have been made possible through the integration of recent Machine Learning methods (based in particular on Deep Learning and Recurrent Neural Networks) with more traditional ones (e.g. Monte-Carlo tree search, goal babbling exploration or addressable memory systems). Regarding embodiment, we note that the traditional benchmark tasks (e.g. visual classification or board games) are becoming obsolete as state-of-the-art learning algorithms approach or even surpass human performance in most of them, having recently encouraged the development of first-person 3D game platforms embedding realistic physics. Building on this analysis, we first propose an embodied cognitive architecture integrating heterogeneous subfields of Artificial Intelligence into a unified framework. We demonstrate the utility of our approach by showing how major contributions of the field can be expressed within the proposed framework. We then claim that benchmarking environments need to reproduce ecologically-valid conditions for bootstrapping the acquisition of increasingly complex cognitive skills through the concept of a cognitive arms race between embodied agents. © 2023 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.1109/DIS.2006.63,,"One of the areas that needs more improvement within the E-Learning environments via Internet (in fact they suppose a very big effort to be accomplished) is allowing students to access and practice real experiments is a real laboratory, instead of using simulations [1]. Real laboratories allow students to acquire methods, skills and experience related to real equipment, in a manner that is very close to the way they are being used in industry. The purpose of the project is the study, development and implementation of an E-Learning environment to allow undergraduate students to practice subjects related to Robotics and Artificial Intelligence, The system, which is now at a preliminary stage, will allow the remote experimentation with real robotic devices (i.e. robots, cameras, etc.). It will enable the student to learn in a collaborative manner (remote participation with other students) where it will be possible to combine the onsite activities (performed ""in-situ"" within the real lab during the normal practical sessions), with the ""online"" one (performed remotely from home via the Internet). Moreover, the remote experiments within the E-Laboratory to control the real robots can be performed by both, students and even scientist. This project is under development and it is carried out jointly by two Universities (UPC and UJI). In this article we present the system architecture and the way students and researchers have been able to perform a Remote Programming of Multirobot Systems via web. © 2006 IEEE. © 2011 Elsevier B.V., All rights reserved.",TOPIC
10.1109/EAEEIE.2009.5335463,,"Learning contents adaptation has been a subject of interest in the research area of the adaptive hypermedia systems. Defining which variables and which standards can be considered to model adaptive content delivery processes is one of the main challenges in pedagogical design over e-learning environments. In this paper some specifications, architectures and technologies that can be used in contents adaptation processes considering characteristics of the context are described and a proposal to integrate some of these characteristics in the design of units of learning using adaptation conditions in a structure of IMS-Learning Design (IMS-LD) is presented. The key contribution of this work is the generation of instructional designs considering the context, which can be used in Learning Management Systems (LMSs) and diverse mobile devices. ©2009 IEEE. © 2010 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ECMR.2019.8870964,,"Deep reinforcement learning (RL) has been successfully applied to a variety of game-like environments. However, the application of deep RL to visual navigation with realistic environments is a challenging task. We propose a novel learning architecture capable of navigating an agent, e.g. a mobile robot, to a target given by an image. To achieve this, we have extended the batched A2C algorithm with auxiliary tasks designed to improve visual navigation performance. We propose three additional auxiliary tasks: predicting the segmentation of the observation image and of the target image and predicting the depth-map. These tasks enable the use of supervised learning to pre-train a major part of the network and to reduce the number of training steps substantially. The training performance has been further improved by increasing the environment complexity gradually over time. An efficient neural network structure is proposed, which is capable of learning for multiple targets in multiple environments. Our method navigates in continuous state spaces and on the AI2-THOR environment simulator surpasses the performance of state-of-the-art goal-oriented visual navigation methods from the literature. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/EDUCON.2010.5492574,,"This paper proposes an agent-based adaptive Architecture to extend Moodle in order to support instructional decisions and adaptive behaviour in engineering education. The paper describes the characteristics, functions, and interactions of the agents which take part in each module of the adaptive architecture. In addition, we describe the origin and function of ToDei, the proposed intelligent agent for Instructional Decisions Making. This agent is in charge of collecting information generated by the rest of agents and deciding what is best for the final users, tutors and students, taking into account their attitudes towards the learning environment. © 2010 IEEE. © 2010 Elsevier B.V., All rights reserved.",TOPIC
10.1109/EDUCON.2015.7096092,"IEEE Global Engineering Education Conference, EDUCON","The OER movement poses challenges inherent to discovering and reuse digital educational materials from highly heterogeneous and distributed digital repositories. Search engines on today's Web of documents are based on keyword queries. Search engines don't provide a sufficiently comprehensive solution to answer a query that permits personalization of open educational materials. To find OER on the Web today, users must first be well informed of which OER repositories potentially contain the data they want and what data model describes these datasets, before using this information to create structured queries. Learning analytics requires not only to retrieve the useful information and knowledge about educational resources, learning processes and relations among learning agents, but also to transform the data gathered in actionable e interoperable information. Linked Data is considered as one of the most effective alternatives for creating global shared information spaces, it has become an interesting approach for discovering and enriching open educational resources data, as well as achieving semantic interoperability and re-use between multiple OER repositories. In this work, an approach based on Semantic Web technologies, the Linked Data guidelines, and Social Network Analysis methods are proposed as a fundamental way to describing, analyzing and visualizing knowledge sharing on OER initiatives © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/EMBC.2016.7591352,Annual International Conference of the IEEE Engineering in Medicine and Biology - Proceedings,"Response to prescribed analgesic drugs varies between individuals, and choosing the right drug/dose often involves a lengthy, iterative process of trial and error. Furthermore, a significant portion of patients experience adverse events such as post-operative urinary retention (POUR) during inpatient management of acute postoperative pain. To better forecast analgesic responses, we compared conventional machine learning methods with modern neural network architectures to gauge their effectiveness at forecasting temporal patterns of postoperative pain and analgesic use, as well as predicting the risk of POUR. Our results indicate that simpler machine learning approaches might offer superior results; however, all of these techniques may play a promising role for developing smarter post-operative pain management strategies. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1109/EMBC44109.2020.9176596,Annual International Conference of the IEEE Engineering in Medicine and Biology - Proceedings,"Local drug delivery to the inner ear via micropump implants has the potential to be much more effective than oral drug delivery for treating patients with sensorineural hearing loss and to protect hearing from ototoxic insult due to noise exposure or cancer treatments. Designing micropumps to deliver appropriate concentrations of drugs to the necessary cochlear compartments is of paramount importance; however, directly measuring local drug concentrations over time throughout the cochlea is not possible. Recent approaches for indirectly quantifying local drug concentrations in animal models capture a series of magnetic resonance (MR) or micro computed tomography (μCT) images before and after infusion of a contrast agent into the cochlea. These approaches require accurately segmenting important cochlear components (scala tympani (ST), scala media (SM) and scala vestibuli (SV)) in each scan and ensuring that they are registered longitudinally across scans. In this paper, we focus on segmenting cochlear compartments from μCT volumes using V-Net, a convolutional neural network (CNN) architecture for 3-D segmentation. We show that by modifying the V-Net architecture to decrease the numbers of encoder and decoder blocks and to use dilated convolutions enables extracting local estimates of drug concentration that are comparable to those extracted using atlas-based segmentation (3.37%, 4.81%, and 19.65% average relative error in ST, SM, and SV), but in a fraction of the time. We also test the feasibility of training our network on a larger MRI dataset, and then using transfer learning to perform segmentation on a smaller number of μCT volumes, which would enable this technique to be used in the future to characterize drug delivery in the cochlea of larger mammals. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ENABL.2001.953441,"Proceedings of the Workshop on Enabling Technologies: Infrastructure for Collaborative Enterprises, WET ICE","Group learning at Internet scale is becoming more frequent in university courses. This complex process requires support by distributed computing learning infrastructures. This paper describes the design of WWG: a distributed and decentralized infrastructure with the aim of supporting distributed group learning and team work, centered on the distribution of events, so that every participant can be notified and thus be aware of the actions, changes, progress of the groups he or she belongs to - synchronous awareness for asynchronous work. The design issues, requirements and the resulting architecture are presented. WWG is based on a multicast mechanism for event distribution with meta-information agents responsible for the dissemination and transformation of events, repository agents responsible for the storage of group information and user agents responsible for the representation of users (sources and sinks of events). © 2015 Elsevier B.V., All rights reserved.",TOPIC
10.1109/EuCNC.2018.8442444,,"In the current Internet of Things (IoT), centralized IoT structures greatly limit the direct, efficient and privacy preserving interaction with the locally available resources. A sustainable path for the future development of Smart Urban Environments, from Smart Homes and Offices, to Smart Neighborhoods and Cities, requires next-generation IoT solutions which are interoperable and decentralized. Building on direct device-to-device interactions and the existing infrastructure operated by open and interoperable platforms, a novel decentralized IoT architecture is required to offer both privacy-preserving and smart real-time interactions in Smart Spaces, leading thus to truly trustful ambient intelligence serving ordinary citizens in everyday situations. We present the key interoperability and security-related aspects which are designed and implemented within the H2020 project symbIoTe to pave the way for such decentralized IoT solutions. Furthermore, we analyze the requirements and technologies, namely Distributed Ledger Technology (DLT), intelligent agents and edge technologies, as the building blocks for the next-generation IoT solutions. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1109/EuCNC/6GSummit54941.2022.9815572,,"6G networks require a flexible infrastructure to dynamically provide ubiquitous network coverage. Mobile Access Points (MAP) deployment is a promising solution. In this paper, we formulate the joint 3D MAP deployment and user association problem over a dynamic network under interference and mobility constraints. First, we propose an iterative algorithm to optimize the deployment of MAPs. Our solution efficiently and quickly determines the number, position and configuration of MAPs for highly dynamic scenarios. MAPs provide appropriate Quality of Service (QoS) connectivity to mobile ground user in mm-wave or sub-6GHz bands and find their optimal positions in a 3D grid. Each MAP also implies an energy cost (e.g. for travel) to be minimized. Once all MAPs deployed, a deep multi-agent reinforcement learning algorithm is proposed to associate multiple users to multiple MAPs under interference constraint. Each user acts as an independent agent that operates in a fully distributed architecture and maximizes the network sum-rate. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/FNWF63303.2024.11028857,,"We present a novel framework for the management of a multi-tier architecture, where a common, programmable, and pervasive context fabric feeds a powerful set of multi-vendor detection and analysis algorithms (business logic). The challenge is deep visibility over multiple software components by real-time collection of massive events from a multiplicity of capillary sources, while maintaining essential properties such as forwarding speed, scalability, autonomy, usability, fault tolerance, resistance to compromises, and responsiveness. The ambition is to support better and more reliable situational awareness by inter- and intra-domain data correlation in both space and time, in order to timely detect and respond even the more sophisticated multi-vector and interdisciplinary cyberattacks. The Context Broker (CB) is the logical component to manage the security context. We define the security context as the set of information, data, and measurements that describe the service and can be used for security-related purposes. The Local Control Plane (LCP) gives the CB access to the configuration of agents. We performed an evaluation of the CB Manager (CB-Man) and LCP considering different scenarios and workloads. The goal is to verify the robustness and the reliance of these two components in different execution scenarios. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1109/FUZZ-IEEE.2012.6251159,IEEE International Conference on Fuzzy Systems,"Situation awareness computing employs sensor networks to collect large amounts of heterogeneous data in different and complex environments. The rapid development and deployment of sensor technology stress the problem related to the availability of too much and heterogeneous data. Last trend emphasizes the semantic annotation of acquired sensor data. Semantic sensor data provides machine understandable contextual information. In particular, the availability of semantic sensor data allows situation awareness in several application domains. This paper introduces a swarm-based approach to semantic web reasoning in order to identify situations. On one hand, fuzzy control has been employed in order to face with uncertainty of happening situations. On the other hand, Situation Theory has been used in order to model situation awareness. A multi agent swarm architecture enables to monitor complex environments by using spatially distributed autonomous sensors. An application scenario for bank intrusion detection has been described. © 2012 IEEE. © 2012 Elsevier B.V., All rights reserved.",TOPIC
10.1109/FUZZ-IEEE.2012.6251224,IEEE International Conference on Fuzzy Systems,"Context aware computing as well as wearable and ubiquitous computing often attain with pattern recognition on incoming sensor data. Recognizing more (useful) contexts requires more information about the context, and thus more sensors and better recognition algorithms. In order to enable logic inference on incoming data, the proposed work assumes that incoming data are represented by means of semantic languages (e.g., RDF, OWL, etc.). Nevertheless, in a context aware computing purely logic-based reasoning on context may not be enough. So, the work introduces soft computing techniques to approximate context recognition. Specifically, this paper introduces an approach to context analysis and recognition that relies on f-SPARQL[1] tool, that is a flexible extension of SPARQL. In particular, in this work a JAVA implementation of f-SPARQL and the integrated support for fuzzy clustering and classification are discussed. This tool is exploited in the architecture that foresees some task oriented agents in order to achieve context analysis and recognition in order to identify critical situations. Finally, a simple application scenario and preliminary experimental results have been described. © 2012 IEEE. © 2012 Elsevier B.V., All rights reserved.",TOPIC
10.1109/FUZZY.2008.4630688,IEEE International Conference on Fuzzy Systems,"Coordination is one of the key components in distributed multi-agent systems. Establishing a coordination scheme with minimum communication requirements and robustness to communication failure is a difficult task. A new multi-agent architecture based on type-2 fuzzy decision making is proposed here for achieving coordination with minimum communication. The decision making module has been designed to achieve the coordination between agents by calculating the weight of the input to be used for deciding on the action plans in a dynamic manner. The effectiveness of the coordination scheme proposed was tested by applying it to a complex, non-linear and stochastic application of the traffic signal control. The size of the network chosen also serves to show the scalability of the agent architecture. The results obtained were compared with adaptive systems, fixed coordination schemes and no coordination schemes. Considerable improvement in the time delay was achieved while using the dynamic coordination scheme proposed. © 2008 IEEE. © 2008 Elsevier B.V., All rights reserved.",TOPIC
10.1109/FUZZY.2010.5584145,,"The significance that Ambient Intelligence (Ami) has acquired in recent years requires the development of innovative solutions. Nonetheless, the development of Ami-based systems requires the creation of increasingly complex and flexible applications. In this regard, the use of context-aware technologies is an essential aspect in these developments to perceive stimuli from the context and react upon it autonomously. This work presents a novel platform that defines a method for integrating dynamic and self-adaptable heterogeneous Wireless Sensor Networks (WSNs). This approach facilitates the inclusion of context-aware capabilities when developing intelligent ubiquitous systems, where functionalities can communicate in a distributed way. Furthermore, the information obtained must be managed by intelligent and self-adaptable technologies to provide an adequate interaction between the users and their environment. Agents and Multi-Agent Systems are one of these technologies. The agents have characteristics such as autonomy, reasoning, reactivity, social abilities and pro-activity which make them appropriate for developing dynamic and distributed systems based on Ami. This way, the integration of the platform with a Service-Oriented Multi-Agent architecture is proposed. Finally, conclusions and future work are presented. © 2010 IEEE. © 2010 Elsevier B.V., All rights reserved.",TOPIC
10.1109/GLOBECOM42002.2020.9322234,"Proceedings - IEEE Global Communications Conference, GLOBECOM","Autonomous deployment of unmanned aerial vehicles (UAVs) supporting next-generation communication networks requires efficient trajectory planning methods. We propose a new end-to-end reinforcement learning (RL) approach to UAV-enabled data collection from Internet of Things (IoT) devices in an urban environment. An autonomous drone is tasked with gathering data from distributed sensor nodes subject to limited flying time and obstacle avoidance. While previous approaches, learning and non-learning based, must perform expensive recomputations or relearn a behavior when important scenario parameters such as the number of sensors, sensor positions, or maximum flying time, change, we train a double deep Q-network (DDQN) with combined experience replay to learn a UAV control policy that generalizes over changing scenario parameters. By exploiting a multi-layer map of the environment fed through convolutional network layers to the agent, we show that our proposed network architecture enables the agent to make movement decisions for a variety of scenario parameters that balance the data collection goal with flight time efficiency and safety constraints. Considerable advantages in learning efficiency from using a map centered on the UAV's position over a non-centered map are also illustrated. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1109/GLOBECOM48099.2022.10000805,"Proceedings - IEEE Global Communications Conference, GLOBECOM","To tackle the heterogeneous requirements of beyond 5G (B5G) and future 6G wireless networks, conventional medium access control (MAC) procedures need to evolve to enable base stations (BSs) and user equipments (UEs) to automatically learn innovative MAC protocols catering to extremely diverse services. This topic has received significant attention, and several reinforcement learning (RL) algorithms, in which BSs and UEs are cast as agents, are available with the aim of learning a communication policy based on agents' local observations. However, current approaches are typically overfitted to the environment they are trained in, and lack robustness against unseen conditions, failing to generalize in different environments. To overcome this problem, in this work, instead of learning a policy in the high dimensional and redundant observation space, we leverage the concept of observation abstraction (OA) rooted in extracting useful information from the environment. This in turn allows learning communication protocols that are more robust and with much better generalization capabilities than current baselines. To learn the abstracted information from observations, we propose an architecture based on autoencoder (AE) and imbue it into a multi-agent proximal policy optimization (MAPPO) framework. Simulation results corroborate the effectiveness of leveraging abstraction when learning protocols by generalizing across environments, in terms of number of UEs, number of data packets to transmit, and channel conditions. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1109/GLOBECOM54140.2023.10437498,"Proceedings - IEEE Global Communications Conference, GLOBECOM","Trajectory prediction has been identified as a challenging critical task for achieving full autonomy of the connected and autonomous vehicles (CAVs). Despite the advancement of communication technologies, only few studies include the connectivity and data exchange aspects. Thus, we introduce a novel Edge-Assisted clustering architecture that takes advantage of recent deep learning models and the evolution of edge technologies to achieve better forecasting. First, the historical positions of the target vehicles are fed into the base models of all CAVs in the scene, resulting in multiple generated predictions. Then, each prediction is transmitted to an edge server where trajectories clustering is performed using DBSCAN algorithm to obtain multiple partitions with similar trajectories. The largest cluster is averaged then broadcast back to all CAVs in the scene. Our proposed method surpasses state-of-the-art results on the real world trajectory prediction nuScenes vehicles dataset, obtaining better predictions up to 21%. We also demonstrate the robustness of our method against single-agent system failures, succeeding to get very satisfactory results due to our ability to detect outliers. System practicality is studied under the current 5G/6G capabilities. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1109/HICSS.2010.166,Proceedings of the Annual Hawaii International Conference on System Sciences,"In order to lead a local government towards its politically set strategic objectives, the vision of the overall status quo, as well as of the desired target state of the complex multi-agent system have to be clear. To encounter the challenges of the change management in merging six former local governments into one, in forming a new NPM related operation model, in planning and leading strategic political objectives, and in order to leverage on the information usability produced in everyday governance practices, a Government Enterprise Architecture (GEA) method has been adopted in the city of Kouvola in Finland. The study is a case study by action research adopting the Finnish GEA method in situ by exploiting Gea grid adaptation model (Geagam). The required adaptation of the GEA grid for the case is described and the adoption analyzed. © 2010 IEEE. © 2010 Elsevier B.V., All rights reserved.",TOPIC
10.1109/HICSS.2014.490,Proceedings of the Annual Hawaii International Conference on System Sciences,"Technological innovations such as Building Information Modeling (BIM) offer opportunities to improve collaborative work and integration in the architecture, engineering and construction industry. However, research to date has documented how many organizations struggle with how to work based on this new technology, and many implementations fail. In this paper we present a case study of a major healthcare construction project in which the use of BIM was paramount, and where designers claim to have succeeded in integrated design. The designers organized their digital collaboration by establishing 1) change agents; 2) a cloud computing infrastructure; 3) new roles and responsibilities; 4) BIM contracts; 5) an IS learning environment; and 6) by involving software developers. These factors have been identified as influential for the successful diffusion of BIM in this project, and may serve as an example for implementation of BIM in other projects for supporting integrated design. © 2014 IEEE. © 2014 Elsevier B.V., All rights reserved.",TOPIC
10.1109/HiPCW.2018.8634034,,"Intelligent Cyber-physical systems can be modeled as multi-agent systems with planning capability to impart adaptivity for changing contexts. In such multi-agent systems, the protocol for plan execution must result in the proper completion and ordering of actions in spite of their distributed execution. However, in untrusted scenarios, there is a possibility of agents not respecting the protocol either due to faults or due to malicious reasons thereby resulting in plan failure. In order to prevent such situations, we propose to implement the execution of agents through smart contracts. This points to a generic architecture seamlessly integrating intelligent planning-based CPS and smart-contracts. © 2023 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.1109/HPCA47549.2020.00023,,"Many of the important services running on data centres are latency-critical, time-varying, and demand strict user satisfaction. Stringent tail-latency targets for colocated services and increasing system complexity make it challenging to reduce the power consumption of data centres. Data centres typically sacrifice server efficiency to maintain tail-latency targets resulting in an increased total cost of ownership. This paper introduces Twig, a scalable quality-of-service (QoS) aware task manager for latency-critical services co-located on a server system. Twig successfully leverages deep reinforcement learning to characterise tail latency using hardware performance counters and to drive energy-efficient task management decisions in data centres. We evaluate Twig on a typical data centre server managing four widely used latency-critical services. Our results show that Twig outperforms prior works in reducing energy usage by up to 38% while achieving up to 99% QoS guarantee for latency-critical services. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/HPCSim.2012.6266962,,"Multi-agent path planning on grid maps is a challenging problem and has numerous real-life applications ranging from robotics to real-time strategy games and non-player characters in video games. A* is a cost-optimal forward search algorithm for path planning which scales up poorly in practice since both the search space and the branching factor grow exponentially in the number of agents. In this work, we propose an A* implementation for the Graphics Processor Units (GPUs) which uses as search space a grid map. The approach uses a search space decomposition to break down the forward search A* algorithm into parallel independently forward sub-searches. The solution offer no guarantees with respect to completeness and solution quality but exploits the computational capability of GPUs to accelerate path planning for many thousands of agents. The paper describes this implementation using the Compute Unified Device Architecture (CUDA) programming environment, and demonstrates its advantages in GPU performance compared to GPU implementation of Real-Time Adaptive A*. © 2012 IEEE. © 2012 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IA.2013.6595188,,"Being able to acquire knowledge and form concepts by observing, exploring, and interacting with the environment and then applying the knowledge thus gained for problem solving to satisfy its goals and needs is the hallmark of an adaptive autonomous intelligent agent. However, for an intelligent agent to be fully autonomous and adaptive, all aspects of intelligent processing from perception to action must be engaged and integrated. To build such an all-encompassing system is a formidable task. We propose that a good approach is to first identify the necessary intelligent computational structures and processes for dealing with a suitably designed micro-environment so that they are tractable. The challenge for computational intelligence is then to uncover general principles leading to general computational structures and processes that can deal with the micro-environment and that are also scalable to deal with more complex and real-world environments. Neuroscience research revealed that there are indeed such scalable general mechanisms in the brain and this is reviewed to provide inspirations for the building of artificial systems. A suitable micro-environment for this purpose must consist of a minimal set of features necessary to engage the various intelligent processes from that of the perceptual to that of the attentional, memory, affective, conceptual, planning, action, and learning. The micro-environment benchmark we propose here consists of an internal environment including the affective states of the intelligent agent as well as an external environment that is dynamic and in which activities of and interactions between objects can take place to engage the intelligent agent in all the intelligent processes described above. © 2013 IEEE. © 2013 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.1109/IAICT62357.2024.10617647,,"The evolution of telecommunications networks from closed to open architectures has led to the development of the Open Radio Access Network (O-RAN) standard. ORAN’s Service Management and Orchestration (SMO) typically contains multiple autonomic management agents that simultaneously make configuration changes to optimize aspects of the network. Dealing with competing and conflicting configuration changes from these autonomic management agents remains a major issue. This paper proposes an extension to the O-RAN SMO architecture to incorporate a component that can predict when configuration changes are likely to degrade network performance. The purpose of this approach is to safeguard the actions taken by the management agents against unintended effects. The approach involves the use of two levels of clustering based on cell similarity and cell configuration. The results consist of predictions of network performance degradation based on statistical correlation with network performance. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICALT.2003.1215166,,"We developed a generic teaching environment that uses agents to support learning. An agent platform developed in our research group is used. The system is generic in the sense that the cognition core (domain model, student model and instruction model) is separated from the exercise modules and user interfaces. The architecture allows different user interfaces. An application of the environment for nurse training has been implemented. © 2003 IEEE. © 2014 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICAR53236.2021.9659413,,"Path planning methods for autonomous unmanned aerial vehicles (UAVs) are typically designed for one specific type of mission. This work presents a method for autonomous UAV path planning based on deep reinforcement learning (DRL) that can be applied to a wide range of mission scenarios. Specifically, we compare coverage path planning (CPP), where the UAV's goal is to survey an area of interest to data harvesting (DH), where the UAV collects data from distributed Internet of Things (IoT) sensor devices. By exploiting structured map information of the environment, we train double deep Q-networks (DDQNs) with identical architectures on both distinctly different mission scenarios to make movement decisions that balance the respective mission goal with navigation constraints. By introducing a novel approach exploiting a compressed global map of the environment combined with a cropped but uncompressed local map showing the vicinity of the UAV agent, we demonstrate that the proposed method can efficiently scale to large environments. We also extend previous results for generalizing control policies that require no retraining when scenario parameters change and offer a detailed analysis of crucial map processing parameters' effects on path planning performance. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICAR53236.2021.9659466,,"The problem of autonomous racing is to navigate through a race course as quickly as possible while not colliding with any obstacles. We approach the autonomous racing problem with the added constraint of not maintaining an updated obstacle map of the environment. Several current approaches to this problem use end-to-end learning systems where an agent replaces the entire navigation pipeline. This paper presents a hierarchical planning architecture that combines a high level planner and path following system with a reinforcement learning agent that learns that subsystem of obstacle avoidance. The novel 'modification planner' uses the path follower to track the global plan and the deep reinforcement learning agent to modify the references generated by the path follower to avoid obstacles. Importantly, our architecture does not require an updated obstacle map and only 10 laser range finders to avoid obstacles. The modification planner is evaluated in the context of mathbf{F}1/10{th} autonomous racing and compared to a end-to-end learning baseline, the Follow the Gap Method and an optimisation based planner. The results show that the modification planner can achieve faster average times compared to the baseline end-to-end planner and a 94% success rate which is similar to the baseline. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICASSP39728.2021.9414563,"Proceedings - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing","Dynamical systems comprised of autonomous agents arise in many relevant problems such as multi-agent robotics, smart grids, or smart cities. Controlling these systems is of paramount importance to guarantee a successful deployment. Optimal centralized controllers are readily available but face limitations in terms of scalability and practical implementation. Optimal decentralized controllers, on the other hand, are difficult to find. In this paper, we propose a framework using graph neural networks (GNNs) to learn decentralized controllers from data. While GNNs are naturally distributed architectures, making them perfectly suited for the task, we adapt them to handle delayed communications as well. Furthermore, they are equivariant and stable, leading to good scalability and transferability properties. The problem of flocking is explored to illustrate the potential of GNNs in learning decentralized controllers. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICBR.2013.6729268,,"In this paper, we present the interest of coupling learning capability and imitation strategy on individual and population levels in the field of Multi-Robot System. Particularly, we show that in an unknown environment adding a simple imitation capability to our bio-inspired architecture leads to a positive effect in the improvement the overall performance of the whole system. Indeed, our motivations is to optimize the robots goals discovery time and to improve the survival rate of agents. To analyze and validate our hypothesis, a series of experiments has been performed with and without a low level imitation strategy in a simulated multi-robot system. We will conclude with robotics' experiments which will feature how our approach applies accurately to real life environments. © 2013 IEEE. © 2014 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICC.2019.8762079,Conference Record - International Conference on Communications,"Drone-cell technology is emerging as a solution to support and backup the cellular network architecture. cell-drones are flexible and provide a more dynamic solution for resource allocation in both scales: spatial and geographic. They allow to increase the bandwidth availability anytime and everywhere according the continuous rate demands. Their fast deployment provide network operators with a reliable solution to face sudden network overload or peak data demands during mass events, without interrupting services and guaranteeing better QoS for users. With these advantages, drone-cell network management is still a complex task. We propose in this paper, a multiagent reinforcement learning approach for dynamic drones-cells management. Our approach is based on an enhanced joint action selection. Results show that our model speed up network learning and provide better network performance. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICC51166.2024.10622379,Conference Record - International Conference on Communications,"Cell- Free (CF) massive Multiple- Input- Multiple-Output (mMIMO) has recently gained significant research attention as a promising technology for future wireless networks. Since the conventional CF mMIMO has been considered unscalable and impractical, user-centric CF systems were proposed to improve its flexibility. While Access Point (AP) clustering has been studied in many research works as a challenging task in Radio Access Network (RAN), the limitations of the connecting links to the servers in a real scenario have not been taken into account. In this work, we consider the innovative combination of Open RAN (ORAN) and CF-RAN architecture that aims to improve the CF network limitations related to the connecting links. Then, we propose two control loops for ORAN Radio Unit (ORU) clustering and ORAN Distributed Unit (O-DU) assignment procedures that are conducted by Reinforcement Learning (RL) agents. Numerical results show that the proposed approach can successfully provide the user's requirements while the network is balanced. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICCV51070.2023.01006,Proceedings of the IEEE International Conference on Computer Vision,"Learning how to navigate among humans in an occluded and spatially constrained indoor environment, is a key ability required to embodied agents to be integrated into our society. In this paper, we propose an end-to-end architecture that exploits Proximity-Aware Tasks (referred as to Risk and Proximity Compass) to inject into a reinforcement learning navigation policy the ability to infer common-sense social behaviours. To this end, our tasks exploit the notion of immediate and future dangers of collision. Furthermore, we propose an evaluation protocol specifically designed for the Social Navigation Task in simulated environments. This is done to capture fine-grained features and characteristics of the policy by analyzing the minimal unit of human-robot spatial interaction, called Encounter. We validate our approach on Gibson4+ and Habitat-Matterport3D datasets. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICDCS51616.2021.00056,Proceedings - International Conference on Distributed Computing Systems,"We explore the feasibility of combining Graph Neural Network-based policy architectures with Deep Reinforcement Learning as an approach to problems in systems. This fits particularly well with operations on networks, which naturally take the form of graphs. As a case study, we take the idea of data-driven routing in intradomain traffic engineering, whereby the routing of data in a network can be managed taking into account the data itself. The particular subproblem which we examine is minimising link congestion in networks using knowledge of historic traffic flows. We show through experiments that an approach using Graph Neural Networks (GNNs) performs at least as well as previous work using Multilayer Perceptron architectures. GNNs have the added benefit that they allow for the generalisation of trained agents to different network topologies with no extra work. Furthermore, we believe that this technique is applicable to a far wider selection of problems in systems research. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICDL-EpiRob48136.2020.9278106,,"We present an intrinsic motivation architecture that generates behaviors towards self-generated and dynamic goals and that regulates goal selection and the balance between exploitation and exploration through multi-level monitoring of prediction error dynamics. This architecture modulates exploration noise and leverages computational resources according to the dynamics of the overall performance of the learning system. Results show that this architecture outperforms intrinsic motivation approaches where exploratory noise and goals are fixed. We suggest that the tracking of prediction error dynamics allows an artificial agent to be intrinsically motivated to seek new experiences but constrained to those that generate reducible prediction error. We argue about the potential relationship between emotional valence and rates of progress toward a goal. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICHR.2010.5686311,,"The control of the collective behavior of multiple interacting agents is a challenging problem in robotics and autonomous systems design. Such behaviors can be characterized by the dynamic interaction between multiple locomoting bipeds with highly nonlinear articulation dynamics. The analysis and design of the stability properties of such complex multi-component systems is a largely unsolved problem. We discuss a first approach to this problem exploiting concepts from Contraction Theory, a recent framework for the analysis of the stability of complex nonlinear dynamical systems. We demonstrate the application of this framework to groups of humanoid agents interacting collectively in different ways, requiring different types of control rules for their propagation in space and their articulation dynamics. We illustrate the framework based on a learning-based realtime-capable architecture for simulation of the kinematics of propagating bipeds, suitable for the reproduction of natural locomotion trajectories and walking styles. Exploiting central theorems from Contraction Theory and nonlinear control, we derive conditions guaranteeing the global exponential stability of the formation of the coordinated multiagent behavior. In addition, we demonstrate that the same approach permits to derive bounds that guarantee minimum convergence speeds for the formation of ordered states for collective behaviors of multiple humanoid agents. ©2010 IEEE. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICITE.2018.8492600,,"The incorporation of Advance Driver Assistance Systems (ADAS) is a growing trend in active safety systems. The current outlook of passive ADAS that, exclusively warning the driver, presents a reactive interaction model in which each system acts independently. The increasing of the amount of in-vehicle passive ADASs arises an interoperability issue against conflict situations that could affect driver's decision-making process negatively, diminishing their attention level. This paper proposes an architecture based on the multi-agent paradigm for designing driver-centered ADASs that operates through the data fusion. The principal goal is to design a hierarchical structure which can manage the knowledge acquisition process of all aspects involved in the driving scene such as the environment as well as the driver's behavior and state, providing support for building and testing reasoning models. An experimental method was performed to verify the feasibility of the proposed approach using the deployment of a warning ADAS which involves the interaction of several developed systems. Besides, the staging of one set of specific hazardous driving situations was designed to conduct an experimental assay with ten drivers in a driving simulation system. Regarding evaluation measurements, the analysis of the reaction time performed by the drivers and user questionnaires collected after each experimental session has shown promising results. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICMA57826.2023.10215975,,"The autonomous driving motion prediction is essential to have a correct and reliable planning. The influence of the road agents on each other makes it even more challenging. However, most prior works have not considered these interactions and planning against the predictions would decrease the ability of representing the possibilities of the future interactions among the different agents. In this work, we propose a model that predicts the agents' behavior in a jointly manner. We take advantage of using the strategy of masking to our model as the query. Our model architecture employ attention across, agent interactions, traffic rules in intersections, and the road elements. The evaluation of our model is done on autonomous driving datasets for behavior prediction and test it on Carla simulator. Our work demonstrates that motion prediction by a model with a masking strategy and having attention and traffic rules can lead us to a state-of-the-art model. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICMLA.2017.00011,,"Finding semantically rich and computer-understandable representations for textual dialogues, utterances and words is crucial for dialogue systems (or conversational agents), as their performance mostly depends on understanding the context of conversations. In recent research approaches, responses have been generated utilizing a decoder architecture, given the distributed vector representation (embedding) of the current conversation. In this paper, the utilization of embeddings for answer retrieval is explored by using Locality-Sensitive Hashing Forest (LSH Forest), an Approximate Nearest Neighbor (ANN) model, to find similar conversations in a corpus and rank possible candidates. Experimental results on the well-known Ubuntu Corpus (in English) and a customer service chat dataset (in Dutch) show that, in combination with a candidate selection method, retrieval-based approaches outperform generative ones and reveal promising future research directions towards the usability of such a system. © 2020 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.1109/ICMLA52953.2021.00039,,"Chatbots are intelligent software built to be used as a replacement for human interaction. Existing studies typically do not provide enough support for low-resource languages like Bangla. Due to the increasing popularity of social media, we can also see the rise of interactions in Bangla transliteration (mostly in English) among the native Bangla speakers. In this paper, we propose a novel approach to build a Bangla chatbot aimed to be used as a business assistant which can communicate in low-resource langauage like Bangla and Bangla Transliteration in English with high confidence consistently. Since annotated data was not available for this purpose, we had to work on the whole machine learning life cycle (data preparation, machine learning modeling, and model deployment) using Rasa Open Source Framework, fastText embeddings, Polyglot embeddings, Flask, and other systems as building blocks. While working with the skewed annotated dataset, we try out different components and pipelines to evaluate which works best and provide possible reasoning behind the observed results. Finally, we present a pipeline for intent classification and entity extraction which achieves reasonable performance (accuracy: 83.02%, precision: 80.82%, recall: 83.02%, F1-score: 80%). © 2022 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.1109/ICMLA52953.2021.00199,,"Inspired by the recent success of transformers in natural language processing and computer vision applications, we introduce a transformer-based neural architecture for two key StarCraft II (SC2) macromanagement tasks: global state and build order prediction. Unlike recurrent neural networks which suffer from a recency bias, transformers are able to capture patterns across very long time horizons, making them well suited for full game analysis. Our model utilizes the MSC (Macromanagement in StarCraft II) dataset and improves on the top performing gated recurrent unit (GRU) architecture in predicting global state and build order as measured by mean accuracy over multiple time horizons. We present ablation studies on our proposed architecture that support our design decisions.One key advantage of transformers is their ability to generalize well, and we demonstrate that our model achieves an even better accuracy when used in a transfer learning setting in which models trained on games with one racial matchup (e.g., Terran vs. Protoss) are transferred to a different one. We believe that transformers' ability to model long games, potential for parallelization, and generalization performance make them an excellent choice for StarCraft agents. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICMLA55696.2022.00010,,"A smart home system is realized by implementing various services. However, the design and deployment of smart home services are challenging due to their complexity and the large number of connected objects. Existing approaches to the smart home system to create services either require complex input from the inhabitant or can only work if the inhabitant specifies regulation solutions rather than targets. In addition, smart home services may conflict if they access the same actuators. Learning methods to dynamically generate smart home services are promising ways to solve the above problems. In this paper, depending on the ability to consider the composition of services and their mutual influence, we propose several reinforcement learning-based architectures for a smart home system to dynamically generate services. The expected advantages are, first, that the smart home services can propose the states of the actuators by considering the target values of the controllable environment states given by the inhabitant or by interacting with the inhabitant in a simple and natural way; and second, that there is no conflict between these propositions. We compare the performance of the proposed architectures using several simulated smart home environments with different services and select the architectures with the best performance concerning our predefined metrics. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICNC47757.2020.9049731,,"This paper concerns the dynamic spectrum access problem for femtocell networks, where traffic loads are different among cells. We model the interference relationship of the femtocell networks with conflict graphs, and a graphical game is employed as the channel access coordination mechanism. A graph neural network based architecture is proposed, which directly maps traffic loads to the channel access scheme for each femtocell. With our method, each femtocell first estimates the qualities of all available channels based on the information from its neighbors, and then the channels of the highest quality are accessed. A multiagent reinforcement learning framework is designed to train the proposed architecture to make accurate estimations of channel quality. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICNP52444.2021.9651930,"Proceedings - International Conference on Network Protocols, ICNP","Traffic Engineering (TE) is a basic building block of the Internet. In this paper, we analyze whether modern Machine Learning (ML) methods are ready to be used for TE optimization. We address this open question through a comparative analysis between the state of the art in ML and the state of the art in TE. To this end, we first present a novel distributed system for TE that leverages the latest advancements in ML. Our system implements a novel architecture that combines Multi-Agent Reinforcement Learning (MARL) and Graph Neural Networks (GNN) to minimize network congestion. In our evaluation, we compare our MARL+GNN system with DEFO, a network optimizer based on Constraint Programming that represents the state of the art in TE. Our experimental results show that the proposed MARL+GNN solution achieves equivalent performance to DEFO in a wide variety of network scenarios including three real-world network topologies. At the same time, we show that MARL+GNN can achieve significant reductions in execution time (from the scale of minutes with DEFO to a few seconds with our solution). © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICPHM.2017.7998308,,"This work presents the evolution of a solution for predictive maintenance to a Big Data environment. The proposed adaptation aims for predicting failures on wind turbines using a data-driven solution deployed in the cloud and which is composed by three main modules. (i) A predictive model generator which generates predictive models for each monitored wind turbine by means of Random Forest algorithm. (ii) A monitoring agent that makes predictions every 10 minutes about failures in wind turbines during the next hour. Finally, (iii) a dashboard where given predictions can be visualized. To implement the solution Apache Spark, Apache Kafka, Apache Mesos and HDFS have been used. Therefore, we have improved the previous work in terms of data process speed, scalability and automation. In addition, we have provided fault-tolerant functionality with a centralized access point from where the status of all the wind turbines of a company localized all over the world can be monitored, reducing O&M costs. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICPHM51084.2021.9486628,,"Collaborative prognosis is a technique that enables the industrial assets to learn from similar other assets in a fleet, and improve their data-driven prognosis models. When collaborative prognosis is implemented in a computationally distributed framework, each asset is monitored by its corresponding Digital Twin agent. Distributed collaborative prognosis is particularly beneficial for high value assets where the communication and the processing costs are negligible compared to the maintenance costs. This paper analyses the effects of Digital Twin deployment strategies on the effectiveness of predictive maintenance activities relying on distributed collaborative prognosis. Distributed and heterarchical multi-agent system architectures are analysed for large fleets of assets, with varying failure rates and noise levels in the failure data. The results show that no single architecture or deployment strategy can be deemed best across all failure rates and noise levels. The conclusion derived in this paper provides guidance to the asset owners to choose the most suitable combination for a given application. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICPR48806.2021.9412212,Proceedings - International Conference on Pattern Recognition,"An important goal of research in Deep Reinforcement Learning in mobile robotics is to train agents capable of solving complex tasks, which require a high level of scene understanding and reasoning from an egocentric perspective. When trained from simulations, optimal environments should satisfy a currently unobtainable combination of high-fidelity photographic observations, massive amounts of different environment configurations and fast simulation speeds. In this paper we argue that research on training agents capable of complex reasoning can be simplified by decoupling from the requirement of high fidelity photographic observations. We present a suite of tasks requiring complex reasoning and exploration in continuous, partially observable 3D environments. The objective is to provide challenging scenarios and a robust baseline agent architecture that can be trained on mid-range consumer hardware in under 24h. Our scenarios combine two key advantages: (i) they are based on a simple but highly efficient 3D environment (ViZDoom) which allows high speed simulation (12000fps); (ii) the scenarios provide the user with a range of difficulty settings, in order to identify the limitations of current state of the art algorithms and network architectures. We aim to increase accessibility to the field of Deep-RL by providing baselines for challenging scenarios where new ideas can be iterated on quickly. We argue that the community should be able to address challenging problems in reasoning of mobile agents without the need for a large compute infrastructure. Code for the generation of scenarios and training of baselines is available online at the following repository. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICRA.2019.8793777,Proceedings - IEEE International Conference on Robotics and Automation,"Effective communication is required for teams of robots to solve sophisticated collaborative tasks. In practice it is typical for both the encoding and semantics of communication to be manually defined by an expert; this is true regardless of whether the behaviors themselves are bespoke, optimization based, or learned. We present an agent architecture and training methodology using neural networks to learn task-oriented communication semantics based on the example of a communication-unaware expert policy. A perimeter defense game illustrates the system's ability to handle dynamically changing numbers of agents and its graceful degradation in performance as communication constraints are tightened or the expert's observability assumptions are broken. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICRA.2019.8793803,Proceedings - IEEE International Conference on Robotics and Automation,"While today's robots are able to perform sophisticated tasks, they can only act on objects they have been trained to recognize. This is a severe limitation: any robot will inevitably see new objects in unconstrained settings, and thus will always have visual knowledge gaps. However, standard visual modules are usually built on a limited set of classes and are based on the strong prior that an object must belong to one of those classes. Identifying whether an instance does not belong to the set of known categories (i.e. open set recognition), only partially tackles this problem, as a truly autonomous agent should be able not only to detect what it does not know, but also to extend dynamically its knowledge about the world. We contribute to this challenge with a deep learning architecture that can dynamically update its known classes in an end-to-end fashion. The proposed deep network, based on a deep extension of a non-parametric model, detects whether a perceived object belongs to the set of categories known by the system and learns it without the need to retrain the whole system from scratch. Annotated images about the new category can be provided by an 'oracle' (i.e. human supervision), or by autonomous mining of the Web. Experiments on two different databases and on a robot platform demonstrate the promise of our approach. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICRA.2019.8793940,Proceedings - IEEE International Conference on Robotics and Automation,"Navigating surgical tools in the dynamic and tortuous anatomy of the lung's airways requires accurate, real-time localization of the tools with respect to the preoperative scan of the anatomy. Such localization can inform human operators or enable closed-loop control by autonomous agents, which would require accuracy not yet reported in the literature. In this paper, we introduce a deep learning architecture, called OffsetNet, to accurately localize a bronchoscope in the lung in real-time. After training on only 30 minutes of recorded camera images in conserved regions of a lung phantom, OffsetNet tracks the bronchoscope's motion on a held-out recording through these same regions at an update rate of 47 Hz and an average position error of 1.4 mm. Because this model performs poorly in less conserved regions, we augment the training dataset with simulated images from these regions. To bridge the gap between camera and simulated domains, we implement domain randomization and a generative adversarial network (GAN). After training on simulated images, OffsetNet tracks the bronchoscope's motion in less conserved regions at an average position error of 2.4 mm, which meets conservative thresholds required for successful tracking. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICRA40945.2020.9196808,Proceedings - IEEE International Conference on Robotics and Automation,"While most robotics simulation libraries are built for low-dimensional and intrinsically serial tasks, soft-body and multi-agent robotics have created a demand for simulation environments that can model many interacting bodies in parallel. Despite the increasing interest in these fields, no existing simulation library addresses the challenge of providing a unified, highly-parallelized, GPU-accelerated interface for simulating large robotic systems. Titan is a versatile CUDA-based C++ robotics simulation library that employs a novel asynchronous computing model for GPU-accelerated simulations of robotics primitives. The innovative GPU architecture design permits simultaneous optimization and control on the CPU while the GPU runs asynchronously, enabling rapid topology optimization and reinforcement learning iterations. Kinematics are solved with a massively parallel integration scheme that incorporates constraints and environmental forces. We report dramatically improved performance over CPU baselines, simulating as many as 300 million primitive updates per second, while allowing flexibility for a wide range of research applications. We present several applications of Titan to high-performance simulations of soft-body and multi-agent robots. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICRA46639.2022.9812100,Proceedings - IEEE International Conference on Robotics and Automation,"The success of motion prediction for autonomous driving relies on integration of information from the HD maps. As maps are naturally graph-structured, investigation on graph neural networks (GNNs) for encoding HD maps is burgeoning in recent years. However, unlike many other applications where GNNs have been straightforwardly deployed, HD maps are heterogeneous graphs where vertices (lanes) are connected by edges (lane-lane interaction relationships) of various nature, and most graph-based models are not designed to understand the variety of edge types which provide crucial cues for predicting how the agents would travel the lanes. To overcome this challenge, we propose Path-Aware Graph Attention, a novel attention architecture that infers the attention between two vertices by parsing the sequence of edges forming the paths that connect them. Our analysis illustrates how the proposed attention mechanism can facilitate learning in a didactic problem where existing graph networks like GCN struggle. By improving map encoding, the proposed model surpasses previous state of the art on the Argoverse Motion Forecasting dataset, and won the first place in the 2021 Argoverse Motion Forecasting Competition. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICRA48506.2021.9561204,Proceedings - IEEE International Conference on Robotics and Automation,"The flock-guidance problem enjoys a challenging structure where multiple optimization objectives are solved simultaneously. This usually necessitates different control approaches to tackle various objectives, such as guidance, collision avoidance, and cohesion. The guidance schemes, in particular, have long suffered from complex tracking-error dynamics. Furthermore, techniques that are based on linear feedback strategies obtained at equilibrium conditions either may not hold or degrade when applied to uncertain dynamic environments. Pre-tuned fuzzy inference architectures lack robustness under such unmodeled conditions. This work introduces an adaptive distributed technique for the autonomous control of flock systems. Its relatively flexible structure is based on online fuzzy reinforcement learning schemes which simultaneously target a number of objectives; namely, following a leader, avoiding collision, and reaching a flock velocity consensus. In addition to its resilience in the face of dynamic disturbances, the algorithm does not require more than the agent position as a feedback signal. The effectiveness of the proposed method is validated with two simulation scenarios and benchmarked against a similar technique from the literature. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICRA48506.2021.9561377,Proceedings - IEEE International Conference on Robotics and Automation,"Path planning and collision avoidance are challenging in complex and highly variable environments due to the limited horizon of events. In literature, there are multiple model- and learning-based approaches that require significant computational resources to be effectively deployed and they may have limited generality. We propose a planning algorithm based on a globally stable passive controller that can plan smooth trajectories using limited computational resources in challenging environmental conditions. The architecture combines the recently proposed fractal impedance controller with elastic bands and regions of finite time invariance. As the method is based on an impedance controller, it can also be used directly as a force/torque controller. We validated our method in simulation to analyse the ability of interactive navigation in challenging concave domains via the issuing of via-points, and its robustness to low bandwidth feedback. A swarm simulation using 11 agents validated the scalability of the proposed method. We have performed hardware experiments on a holonomic wheeled platform validating smoothness and robustness of interaction with dynamic agents (i.e., humans and robots). The computational complexity of the proposed local planner enables deployment with low-power micro-controllers lowering the energy consumption compared to other methods that rely upon numeric optimisation. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICRA48506.2021.9561467,Proceedings - IEEE International Conference on Robotics and Automation,"As urban environments manifest high levels of complexity it is of vital importance that safety systems embedded within autonomous vehicles (AVs) are able to accurately anticipate short-term future motion of nearby agents. This problem can be further understood as generating a sequence of coordinates describing the future motion of the tracked agent. Various proposed approaches demonstrate significant benefits of using a rasterised top-down image of the road, with a combination of Convolutional Neural Networks (CNNs), for extraction of relevant features that define the road structure (eg. driveable areas, lanes, walkways). In contrast, this paper explores use of Capsule Networks (CapsNets) in the context of learning a hierarchical representation of sparse semantic layers corresponding to small regions of the High-Definition (HD) map. Each region of the map is dismantled into separate geometrical layers that are extracted with respect to the agent's current position. By using an architecture based on CapsNets the model is able to retain hierarchical relationships between detected features within images whilst also preventing loss of spatial data often caused by the pooling operation. We train and evaluate our model on publicly available dataset nuTonomy scenes and compare it to recently published methods. We show that our model achieves significant improvement over recently published works on deterministic prediction, whilst drastically reducing the overall size of the network. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICRA48506.2021.9561491,Proceedings - IEEE International Conference on Robotics and Automation,"Imitation Learning (IL) is a powerful paradigm to teach robots to perform manipulation tasks by allowing them to learn from human demonstrations collected via teleoperation, but has mostly been limited to single-arm manipulation. However, many real-world tasks require multiple arms, such as lifting a heavy object or assembling a desk. Unfortunately, applying IL to multi-arm manipulation tasks has been challenging - asking a human to control more than one robotic arm can impose significant cognitive burden and is often only possible for a maximum of two robot arms. To address these challenges, we present MULTI-ARM ROBOTURK (MART), a multi-user data collection platform that allows multiple remote users to simultaneously teleoperate a set of robotic arms and collect demonstrations for multi-arm tasks. Using MART, we collected demonstrations for five novel two and three-arm tasks from several geographically separated users. From our data we arrived at a critical insight: most multi-arm tasks do not require global coordination throughout its full duration, but only during specific moments. We show that learning from such data consequently presents challenges for centralized agents that directly attempt to model all robot actions simultaneously, and perform a comprehensive study of different policy architectures with varying levels of centralization on our tasks. Finally, we propose and evaluate a base-residual policy framework that allows trained policies to better adapt to the mixed coordination setting common in multi-arm manipulation, and show that a centralized policy augmented with a decentralized residual model outperforms all other models on our set of benchmark tasks. Additional results and videos at https://roboturk.stanford.edu/multiarm. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICRA48891.2023.10160559,Proceedings - IEEE International Conference on Robotics and Automation,"Manually specifying features that capture the diversity in traffic environments is impractical. Consequently, learning-based agents cannot realize their full potential as neural motion planners for autonomous vehicles. Instead, this work proposes to learn which features are task-relevant. Given its immediate relevance to motion planning, our proposed architecture encodes the probabilistic occupancy map as a proxy for obtaining pre-trained state representations of the environment. By leveraging a map-aware traffic graph formulation, our agent-centric encoder generalizes to arbitrary road networks and traffic situations. We show that our approach significantly improves the downstream performance of a reinforcement learning agent operating in urban traffic environments. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICRA48891.2023.10160606,Proceedings - IEEE International Conference on Robotics and Automation,"Affordances are a fundamental concept in robotics since they relate available actions for an agent depending on its sensory-motor capabilities and the environment. We present a novel Bayesian deep network to detect affordances in images, at the same time that we quantify the distribution of the aleatoric and epistemic variance at the spatial level. We adapt the Mask-RCNN architecture to learn a probabilistic representation using Monte Carlo dropout. Our results outperform the state-of-the-art of deterministic networks. We attribute this improvement to a better probabilistic feature space representation on the encoder and the Bayesian variability induced at the mask generation, which adapts better to the object contours. We also introduce the new Probability-based Mask Quality measure that reveals the semantic and spatial differences on a probabilistic instance segmentation model. We modify the existing Probabilistic Detection Quality metric by comparing the binary masks rather than the predicted bounding boxes, achieving a finer-grained evaluation of the probabilistic segmentation. We find aleatoric variance in the contours of the objects due to the camera noise, while epistemic variance appears in visual challenging pixels. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICRAE56463.2022.10056196,,"Self-driving cars face complex driving situations with a large amount of agents when moving in crowded cities. However, some of the agents are actually not influencing the behavior of the self-driving car. Filtering out unimportant agents would inherently simplify the behavior or motion planning task for the system. The planning system can then focus on fewer agents to find optimal behavior solutions for the ego agent. This is helpful especially in terms of computational efficiency. In this paper, therefore, the research topic of importance filtering with driving risk models is introduced. We give an overview of state-of-the-art risk models and present newly adapted risk models for filtering. Their capability to filter out surrounding unimportant agents is compared in a large-scale experiment. As it turns out, the novel trajectory distance balances performance, robustness and efficiency well. Based on the results, we can further derive a novel filter architecture with multiple filter steps, for which risk models are recommended for each step, to further improve the robustness. We are confident that this will enable current behavior planning systems to better solve complex situations in everyday driving. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICSTCC59206.2023.10308458,,"We consider a problem in which the trajectory of a mobile 3D sensor must be optimized so that certain objects are both found in the overall scene and covered by the point cloud, as fast as possible. This problem is called target search and coverage, and the paper provides an end-to-end deep reinforcement learning (RL) solution to solve it. The deep neural network combines four components: deep hierarchical feature learning occurs in the first stage, followed by multi-head transformers in the second, max-pooling and merging with bypassed information to preserve spatial relationships in the third, and a distributional dueling network in the last stage. To evaluate the method, a simulator is developed where cylinders must be found by a Kinect sensor. A network architecture study shows that deep hierarchical feature learning works for RL and that by using farthest point sampling (FPS) we can reduce the amount of points and achieve not only a reduction of the network size but also better results. We also show that multi-head attention for point-clouds helps to learn the agent faster but converges to the same outcome. Finally, we compare RL using the best network with a greedy baseline that maximizes immediate rewards and requires for that purpose an oracle that predicts the next observation. We decided RL achieves significantly better and more robust results than the greedy strategy. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICSTW52544.2021.00044,,"This short paper presents an architectural overview of an agent-based framework called iv4XR for automated testing that is currently under development by an H2020 project with the same name. The framework's intended main use case of is testing the family of Extended Reality (XR) based systems (e.g. 3D games, VR sytems, AR systems), though the approach can indeed be adapted to target other types of interactive systems. The framework is unique in that it is an agent-based system. Agents are inherently reactive, and therefore are arguably a natural match to deal with interactive systems. Moreover, it is also a natural vessel for mounting and combining different AI capabilities, e.g. reasoning, navigation, and learning. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICSTW58534.2023.00037,,"Digital twins (DT) of industrial processes have become increasingly important. They aim to digitally represent the physical world to help evaluate, optimize, and predict physical processes and behaviors. Therefore, DT is a vital tool to improve production automation through digitalization and becomes more sophisticated due to rapidly evolving simulation and modeling capabilities, integration of IoT sensors with DT, and high-capacity cloud/edge computing infrastructure. However, the fidelity and reliability of DT software are essential to represent the physical world. This paper shows an automated and systematic test architecture for DT that correlates DT states with real-time sensor data from a production line in the forging industry. Our evaluation shows that the architecture can significantly accelerate the automatic DT testing process and improve its reliability. A systematic online DT testing method can significantly detect the performance shift and continuously improve the DT's fidelity. The snapshot creation methodology and testing agent architecture can be an inspiration and can be generally applicable to other industrial processes that use DT to generalize their automated testing. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICTTA.2008.4530038,,"Mining the growing data issued from the interpretation of remotely sensed images to obtain the necessary information for land cover change studies becomes more difficult and makes the data volume problem particularly acute. Mitigating this problem requires using data efficiently as metadata for mining and selecting appropriate data for change studies. In this paper, we propose an integrate hierarchical approach based on the use of a blackboard architecture and multi-agent system and having a reasoning ability to find the best strategy to extract and create metadata about extracted objects. This architecture models relation-ship between objects and primitives extracted from images as metadata and use a transition diagram to handle temporal dependencies and perform the detection of temporal changes of objects. We validate our approach on a set of multi-temporal Spot images, to model the evolution of detected object. © 2008 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICUAS.2016.7502669,,"In this paper a scalable and flexible Architecture for real-time mission planning and dynamic agent-to-task assignment for a swarm of Unmanned Aerial Vehicles (UAV) is presented. The proposed mission planning architecture consists of a Global Mission Planner (GMP) which is responsible of assigning and monitoring different high-level missions through an Agent Mission Planner (AMP), which is in charge of providing and monitoring each task of the mission to each UAV in the swarm. The objective of the proposed architecture is to carry out high-level missions such as autonomous multi-agent exploration, automatic target detection and recognition, search and rescue, and other different missions with the ability of dynamically re-adapt the mission in real-time. The proposed architecture has been evaluated in simulation and real indoor flights demonstrating its robustness in different scenarios and its flexibility for real-time mission re-planning and dynamic agent-to-task assignment. © 2016 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ICUAS54217.2022.9836177,,"The consequences of natural catastrophes, such as floods, can be devastating. To mitigate their impact, it is critical to carry out a rapid analysis of the affected region in the moments after they occur, in order to enhance situational awareness. For this purpose, Unmanned Aerial Vehicles (UAVs) may be considered as the technological basis onto which intelligent systems capable of providing support to rescue teams are built. In this work, we present a novel design of a single-agent architecture that can monitor environments affected by a flood event, and provide support to first responders in the decision-making process. In this framework, the autonomous UAV agent is capable of selecting regions based on a hydrological models and generate trajectories for monitoring and coverage. While monitoring the selected areas, the agent collects real-time data regarding water depth and water velocity. Exploiting the data collection process, the agent updates the selected regions, hence constantly updating its path. To demonstrate the proposed framework, we present a simulation study of a flash-flood which could affect the city of Nicosia. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IE.2010.61,,"Digital cities have been evolved from web applications and knowledge bases to smart urban environments. This evolution has mainly been based on broadband metro-networks and complex information systems, and it suggests the form of the future city that is called wireless/smart/digital or ubiquitous city. Although common practices are being developed all over the world, different priorities are defined and different architectures are followed. In this paper we summarize on the applied architectures of multiple city case studies, we use the experiences of the digital city of Trikala, Greece, and we conclude to a common Enterprise Architecture for digital city cases. This common architecture identifies the blue prints for urban information based development. Moreover, this paper presents a common architecture for service delivery in urban spaces. © 2010 IEEE. © 2011 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IE.2011.44,,"In the last decade, a technological tendency is observed related to the integration of the digital objects in the daily routine of people. Latest technology achievements as wireless networks, tangible interfaces, embedded interaction and in general the diffusion of computing power in small units through space, reveal that the boundaries between physical and digital space are blurring. From contemporary technology applications, turns up that digital spaces can be easily adapted to our everyday life in the urban environment. That way a new perspective for architects appears: to manage simultaneously digital and physical urban space. This paper aims at indicating cases where digital tools help sustainable development in the urban environment and highlighting a potential research field for architecture that combines AmI, built environment and sustainability, by analyzing them. Through ambient or pervasive computing with specific applications and examples that will be extensively presented, it is shown how digital technology can be used for sustainable urban environments especially in the field of architecture, with respect to the local conditions of place. © 2011 IEEE. © 2011 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IECON.2005.1569263,IECON Proceedings (Industrial Electronics Conference),"The manufacturing industries are facing a rapidly changing landscape and new challenges are evolving. It is thus imperative for manufacturing enterprise to address these concerns with new innovation in order to stay competitive and achieve sustained growth. The competitive edges and innovation that enterprises can developed includes integrating quality services into well - established manufacturing processes for efficiency and effectiveness, practicing sustainable product development, adopting a total product life cycle oriented approach and leveraging on the up and coming web technology in the emergence of virtual enterprises. In this paper, a generic integrated manufacturing and services system (IMSS) framework is being proposed and subsequently it was deployed in a biomanufacturing scenario as an initial proof of concept. An agent-based goal-oriented modelling approach is being used in the realization of the framework architecture. © 2005 IEEE. © 2009 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IECON.2014.7048892,,"Cooperative systems are suitable for many types of applications and nowadays these system are vastly used to improve a previously defined system or to coordinate multiple devices working together. This paper provides an alternative to improve the reliability of a previous intelligent identification system. The proposed approach implements a cooperative model based on multi-agent architecture. This new system is composed of several radar-based systems which identify a detected object and transmit its own partial result by implementing several agents and by using a wireless network to transfer data. The proposed topology is a centralized architecture where the coordinator device is in charge of providing the final identification result depending on the group behavior. In order to find the final outcome, three different mechanisms are introduced. The simplest one is based on majority voting whereas the others use two different weighting voting procedures, both providing the system with learning capabilities. Using an appropriate network configuration, the success rate can be improved from the initial 80% up to more than 90%. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IEEECONF38699.2020.9389378,,"In marine operations underwater manipulators play a primordial role. However, due to uncertainties in the dynamic model and disturbances caused by the environment, low-level control methods require great capabilities to adapt to change. Furthermore, under position and torque constraints the requirements for the control system are greatly increased. Reinforcement learning is a data driven control technique that can learn complex control policies without the need of a model. The learning capabilities of these type of agents allow for great adaptability to changes in the operative conditions. In this article we present a novel reinforcement learning low-level controller for the position control of an underwater manipulator under torque and position constraints. The reinforcement learning agent is based on an actor-critic architecture using sensor readings as state information. Simulation results using the Reach Alpha 5 underwater manipulator show the advantages of the proposed control strategy. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IEEECONF44664.2019.9049050,"Conference Record of the Asilomar Conference on Signals, Systems and Computers","We investigate the problem of computation offloading in a mobile edge computing architecture, where multiple energy-constrained users compete to offload their computational tasks to multiple servers through a shared wireless medium. We propose a multi-agent deep reinforcement learning algorithm, where each server is equipped with an agent, observing the status of its associated users and selecting the best user for offloading at each step. We consider computation time (i.e., task completion time) and system lifetime as two key performance indicators, and we numerically demonstrate that our approach outperforms baseline algorithms in terms of the trade-off between computation time and system lifetime. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IJCNN.2010.5596500,Proceedings of the International Joint Conference on Neural Networks,"In Natural Language Processing (NLP) symbolic systems, several linguistic phenomena, for instance, the thematic role relationships between sentence constituents, such as AGENT and PATIENT, can be accounted for by the employment of a rule-based grammar. Another approach to NLP concerns the use of the connectionist model, which has the benefits of learning, generalization and fault tolerance, among others. Inspired on neuroscience, it is proposed a connectionist system called BIOθPRED (BIOlogically plausible thematic (θ) PREDictor), designed to reveal the thematic grid assigned to a sentence. Its architecture comprises, as input, a featural representation of the words (based on the verb/noun WordNet classification and on the classical semantic microfeature representation), and, as output, the thematic grid assigned to the sentence. BIOθPRED is designed to ""predict"" thematic (semantic) roles assigned to words in a sentence context, employing biologically inspired training algorithm and architecture, and adopting a psycholinguistic view of thematic theory. © 2010 IEEE. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IJCNN.2015.7280592,Proceedings of the International Joint Conference on Neural Networks,"This paper presents a two stage learning algorithm for a Growing-Pruning Spiking Neural Network (GPSNN) for pattern classification problems. The GPSNN uses three layered network architecture with input layer employing a modified population coding and, leaky integrate-and-fire spiking neurons in the hidden and output layers. The class label for a sample is determined according to the output neuron with minimum spike latency. The learning algorithm for the GPSNN employs a two stage learning mechanism. In the first stage, the hidden layer is grown and adapted to map the inputs to a hyperdimensional space. In the second stage, the hidden layer neurons with low dominance are pruned and the response of the most dominant neurons is mapped to the output space. The proposed approach has been evaluated on benchmark data sets from the UCI machine learning repository and the results were compared with batch as well as online spiking neural networks. The results clearly highlight that the GPSNN can achieve better performances using a compact network structure. © 2015 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IJCNN52387.2021.9534209,,"Prognostication of vehicle trajectories in unknown environments is intrinsically a challenging and difficult problem to solve. The behavior of such vehicles is highly influenced by surrounding traffic, road conditions, and rogue participants present in the environment. Moreover, the presence of pedestrians, traffic lights, stop signs, etc., makes it much harder to infer the behavior of various traffic agents. This paper attempts to solve the problem of spatio-temporal look-ahead trajectory prediction using a novel recurrent neural network called the Memory Neuron Network. The Memory Neuron Network (MNN) attempts to capture the input-output relationship between the past positions and the future positions of the traffic agents. The proposed prediction model is computationally less intensive and has a simple architecture as compared to other deep learning models that utilize LSTMs and GRUs. It is then evaluated on the publicly available NGSIM dataset and its performance is compared with several state-of-art algorithms. Additionally, the performance is also evaluated on a custom synthetic dataset generated from the CARLA simulator. It is seen that the proposed model outperforms the existing state-of-art algorithms. Finally, the model is integrated with the CARLA simulator to test its robustness in real-time traffic scenarios. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1109/INFOCOM42981.2021.9488865,Proceedings - IEEE INFOCOM,"Due to the sheer scale of the Internet of Things (IoT) and 5G, the wireless spectrum is becoming severely congested. For this reason, wireless devices will need to continuously adapt to current spectrum conditions by changing their communication parameters in real-time. Therefore, wireless signal classification (WSC) will become a compelling necessity to decode fast-changing signals from dynamic transmitters. Thanks to its capability of classifying complex phenomena without explicit mathematical modeling, deep learning (DL) has been demonstrated to be a key enabler of WSC. Although DL can achieve a very high accuracy under certain conditions, recent research has unveiled that the wireless channel can disrupt the features learned by the DL model during training, thus drastically reducing the classification performance in real-world live settings. Since retraining classifiers is cumbersome after deployment, existing work has leveraged the usage of carefully-tailored Finite Impulse Response (FIR) filters that, when applied at the transmitter's side, can restore the features that are lost because of the the channel actions, i.e., waveform synthesis. However, these approaches compute FIRs using offline optimization strategies, which limits their efficacy in highly-dynamic channel settings. In this paper, we improve the state of the art by proposing Chares, a Deep Reinforcement Learning (DRL)-based framework for channel-resilient adaptive waveform synthesis. Chares adapts to new and unseen channel conditions by optimally computing through DRL the FIRs in real time. Chares is a DRL agent whose architecture is based upon the Twin Delayed Deep Deterministic Policy Gradients (TD3), which requires minimal feedback from the receiver and explores a continuous action space for best performance. Chares has been extensively evaluated on two well-known datasets with an extensive number of channels. We have also evaluated the real-time latency of Chares with an implementation on field-programmable gate array (FPGA). Results show that Chares increases the accuracy up to 4.1x when no waveform synthesis is performed, by 1.9x with respect to existing work, and can compute new actions within 41μs. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/INFOCOMWKSHPS61880.2024.10620901,,"One of the prominent problems in envisioned 6G networks is the truly dynamic placement of multiple virtual network function chains on top of the physical network infrastructure. Reinforcement Learning based schemes have been recently explored for such problems. Yet these have to deal with astronomically high state and action spaces in this context. Using a standard Deep Q-Network (DQN) is a common way to effectively deal with state complexity. While the use of independent DQN (iDQN) agents could be further used to mitigate action space complexity, such schemes often suffer from instability and sample (in)efficiency, and their theoretical performance is hard to assess. To this end we propose a DQN-based scheme that uses a recent Deep Neural Network architecture, with a different branch responsible for the placement of each virtual network function (again reducing action space complexity), yet with (implicit) coordination among branches, via shared layers (hence avoiding iDQN shortcomings). Using a real traffic dataset, we (i) theoretically ground the proposed scheme by comparing it with an optimal online algorithm for a stateless experts environment; (ii) we demonstrate a 41% cost improvement compared the existing state-of-the-art multi-agent DQN approach (independent agents). © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IRC.2018.00068,,"In this work, we set the bases of the integration of ambient intelligence (AmI) with mobile robot teams (MRT), aiming to enhance ambient assisted living services addressing a variety of tasks. We argue that people with reduced mobility can benefit from a synergy between AmI and MRT in various aspects. Towards this direction, we identify principal functionalities such an integrated system should provide in connection to relevant previous works and the way by which synergy could be accomplished, from low-level behavioural to higher-level task planning of a multi-layered system architecture. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IRC.2019.00091,,"Current state of the art solutions in the control of an autonomous vehicle mainly use supervised end-to-end learning, or decoupled perception, planning and action pipelines. Another possible solution is deep reinforcement learning, but such a method requires that the agent interacts with its surroundings in a simulated environment. In this paper we introduce GridSim, which is an autonomous driving simulator engine running a car-like robot architecture to generate occupancy grids from simulated sensors. We use GridSim to study the performance of two deep learning approaches, deep reinforcement learning and driving behavioral learning through genetic algorithms. The deep network encodes the desired behavior in a two elements fitness function describing a maximum travel distance and a maximum forward speed, bounded to a specific interval. The algorithms are evaluated on simulated highways, curved roads and innercity scenarios, all including different driving limitations. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IROS.2014.6943092,IEEE International Conference on Intelligent Robots and Systems,"In this paper, we demonstrate a novel hybrid architecture for coordinating networked robots in sensing and information routing applications. The proposed INformation and Sensing driven PhysIcally REconfigurable robotic network (INSPIRE), consists of a Physical Control Plane (PCP) which commands agent position, and an Information Control Plane (ICP) which regulates information flow towards communication/sensing objectives. We describe an instantiation where a mobile robotic network is dynamically reconfigured to ensure high quality routes between static wireless nodes, which act as source/destination pairs for information flow. We demonstrate our propositions through simulation under a realistic wireless network regime. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IROS.2015.7353762,IEEE International Conference on Intelligent Robots and Systems,"When teleoperating a multi-robot system it is useful to control the kind of behavior of the fleet depending on the environment it is moving in. In this paper, a novel bilateral control architecture for teleoperating a group of mobile robots is proposed. The user can command the robots both as a flexible and amorphous group and as a set of agents executing different trajectories for achieving a desired task, mimicking a conductor-orchestra paradigm. Exploiting passivity based control, we ensure a stable and safe behavior for the user. The proposed teleoperation strategy is validated by means of experiments. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IROS40897.2019.8967824,IEEE International Conference on Intelligent Robots and Systems,"In this paper, we propose SwarmNet - a neural network architecture that can learn to predict and imitate the behavior of an observed swarm of agents in a centralized manner. Tested on artificially generated swarm motion data, the network achieves high levels of prediction accuracy and imitation authenticity. We compare our model to previous approaches for modelling interaction systems and show how modifying components of other models gradually approaches the performance of ours. Finally, we also discuss an extension of SwarmNet that can deal with nondeterministic, noisy, and uncertain environments, as often found in robotics applications. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IROS40897.2019.8967834,IEEE International Conference on Intelligent Robots and Systems,"Deep reinforcement learning has proven to be a great success in allowing agents to learn complex tasks. However, its application to actual robots can be prohibitively expensive. Furthermore, the unpredictability of human behavior in human-robot interaction tasks can hinder convergence to a good policy. In this paper, we present an architecture that allows agents to learn models of stochastic environments and use them to accelerate learning. We descirbe how an environment model can be learned online and used to generate synthetic transitions, as well as how an agent can leverage these synthetic data to accelerate learning. We validate our approach using an experiment in which a robotic arm has to complete a task composed of a series of actions based on human gestures. Results show that our approach leads to significantly faster learning, requiring much less interaction with the environment. Furthermore, we demonstrate how learned models can be used by a robot to produce optimal plans in real world applications. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IROS40897.2019.8968129,IEEE International Conference on Intelligent Robots and Systems,"We investigate a classification problem using multiple mobile agents capable of collecting (partial) pose-dependent observations of an unknown environment. The objective is to classify an image over a finite time horizon. We propose a network architecture on how agents should form a local belief, take local actions, and extract relevant features from their raw partial observations. Agents are allowed to exchange information with their neighboring agents to update their own beliefs. It is shown how reinforcement learning techniques can be utilized to achieve decentralized implementation of the classification problem by running a decentralized consensus protocol. Our experimental results on the MNIST handwritten digit dataset demonstrates the effectiveness of our proposed framework. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IROS40897.2019.8968165,IEEE International Conference on Intelligent Robots and Systems,"Building perceptual systems for robotics which perform well under tight computational budgets requires novel architectures which rethink the traditional computer vision pipeline. Modern vision architectures require the agent to build a summary representation of the entire scene, even if most of the input is irrelevant to the agent's current goal. In this work, we flip this paradigm, by introducing EARLYFUSION vision models that condition on a goal to build custom representations for downstream tasks. We show that these goal specific representations can be learned more quickly, are substantially more parameter efficient, and more robust than existing attention mechanisms in our domain. We demonstrate the effectiveness of these methods on a simulated item retrieval problem that is trained in a fully end-to-end manner via imitation learning. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IROS40897.2019.8968252,IEEE International Conference on Intelligent Robots and Systems,"There is an increasing interest in Reinforcement Learning to solve new and more challenging problems, as those emerging in robotics and unmanned autonomous vehicles. To face these complex systems, a hierarchical and multi-scale representation is crucial. This has brought the interest on Hierarchical Deep Reinforcement learning systems. Despite their successful application, Deep Reinforcement Learning systems suffer from a variety of drawbacks: they are data hungry, they lack of interpretability, and it is difficult to derive theoretical properties about their behavior. Classical Hierarchical Reinforcement Learning approaches, while not suffering from these drawbacks, are often suited for finite actions, and finite states, only. Furthermore, in most of the works, there is no systematic way to represent domain knowledge, which is often only embedded in the reward function.We present a novel Hierarchical Reinforcement Learning framework based on the hierarchical design approach typical of control theory. We developed our framework extending the block diagram representation of control systems to fit the needs of a Hierarchical Reinforcement Learning scenario, thus giving the possibility to integrate domain knowledge in an effective hierarchical architecture. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IROS40897.2019.8968560,IEEE International Conference on Intelligent Robots and Systems,"In many real-world decision making problems, reaching an optimal decision requires taking into account a variable number of objects around the agent. Autonomous driving is a domain in which this is especially relevant, since the number of cars surrounding the agent varies considerably over time and affects the optimal action to be taken. Classical methods that process object lists can deal with this requirement. However, to take advantage of recent high-performing methods based on deep reinforcement learning in modular pipelines, special architectures are necessary. For these, a number of options exist, but a thorough comparison of the different possibilities is missing. In this paper, we elaborate limitations of fully-connected neural networks and other established approaches like convolutional and recurrent neural networks in the context of reinforcement learning problems that have to deal with variable sized inputs. We employ the structure of Deep Sets in off-policy reinforcement learning for high-level decision making, highlight their capabilities to alleviate these limitations, and show that Deep Sets not only yield the best overall performance but also offer better generalization to unseen situations than the other approaches. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IROS45743.2020.9341367,IEEE International Conference on Intelligent Robots and Systems,"In this work, we present a system architecture to enable autonomous navigation of multiple agents across user-selected global interest points in a partially unknown environment. The system is composed of a server and a team of agents, here small aircrafts. Leveraging this architecture, computation-ally demanding tasks, such as global dense mapping and global path planning can be outsourced to a potentially powerful central server, limiting the onboard computation for each agent to local pose estimation using Visual-Inertial Odometry (VIO) and local path planning for obstacle avoidance. By assigning priorities to the agents, we propose a hierarchical multi-robot global planning pipeline, which avoids collisions amongst the agents and computes their paths towards the respective goals. The resulting global paths are communicated to the agents and serve as reference input to the local planner running onboard each agent. In contrast to previous works, here we relax the common assumption of a previously mapped environment and perfect knowledge about the state, and we show the effectiveness of the proposed approach in photo-realistic simulations with up to four agents operating in an industrial environment. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IROS45743.2020.9341635,IEEE International Conference on Intelligent Robots and Systems,"Robots navigating autonomously need to perceive and track the motion of objects and other agents in its surroundings. This information enables planning and executing robust and safe trajectories. To facilitate these processes, the motion should be perceived in 3D Cartesian space. However, most recent multi-object tracking (MOT) research has focused on tracking people and moving objects in 2D RGB video sequences. In this work we present JRMOT, a novel 3D MOT system that integrates information from RGB images and 3D point clouds to achieve real-time, state-of-the-art tracking performance. Our system is built with recent neural networks for re-identification, 2D and 3D detection and track description, combined into a joint probabilistic data-association framework within a multi-modal recursive Kalman architecture. As part of our work, we release the JRDB dataset, a novel large scale 2D+3D dataset and benchmark, annotated with over 2 million boxes and 3500 time consistent 2D+3D trajectories across 54 indoor and outdoor scenes. JRDB contains over 60 minutes of data including 360cylindrical RGB video and 3D pointclouds in social settings that we use to develop, train and evaluate JRMOT. The presented 3D MOT system demonstrates state-of-the-art performance against competing methods on the popular 2D tracking KITTI benchmark and serves as first 3D tracking solution for our benchmark. Real-robot tests on our social robot JackRabbot indicate that the system is capable of tracking multiple pedestrians fast and reliably. We provide the ROS code of our tracker at https://sites.google.com/view/jrmot © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IROS47612.2022.9981152,IEEE International Conference on Intelligent Robots and Systems,"This work presents a pipeline for autonomous emergency landing for multicopters, such as rotary wing Unmanned Aerial Vehicles (UAVs), using deep Reinforcement Learning (RL). Mechanical malfunctions, strong winds, sudden battery life drops (e.g, due to cold weather), failure in localization or GPS jamming are not uncommon and all constitute emergency situations that require a UAV to abort its mission early and land as quickly as possible in the immediate vicinity. To this end, it is crucial for a UAV that is deployed in real missions to be able to detect a safe landing spot efficiently and proceed to land autonomously, avoiding damage to both its integrity and the surroundings. Driven by the advances in semantic segmentation and depth completion using machine learning, the proposed architecture uses deep RL to infer actions from semantic and depth information, flying the robot towards secure areas, while respecting safety constraints. Thanks to our robust training strategy and the choice of these mid-level representations as input to the RL agent, we show that our policy can directly transfer to the real world, without the need for any additional fine-tuning. In a series of challenging experiments both in simulation and with a real platform, we demonstrate that our planner guides a rotorcraft UAV to a safe landing spot up to 1.5 times faster and with double success rate than the state of the art (including a commercially available solution), paving the way towards realistically deployable UAVs. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IROS47612.2022.9981779,IEEE International Conference on Intelligent Robots and Systems,"A kitchen assistant needs to operate human-scale objects, such as cabinets and ovens, in unmapped environments with dynamic obstacles. Autonomous interactions in such environments require integrating dexterous manipulation and fluid mobility. While mobile manipulators in different form factors provide an extended workspace, their real-world adoption has been limited. Executing a high-level task for general objects requires a perceptual understanding of the object as well as adaptive whole-body control among dynamic obstacles. In this paper, we propose a two-stage architecture for autonomous interaction with large articulated objects in unknown environments. The first stage, object-centric planner, only focuses on the object to provide an action-conditional sequence of states for manipulation using RGB-D data. The second stage, agent-centric planner, formulates the whole-body motion control as an optimal control problem that ensures safe tracking of the generated plan, even in scenes with moving obstacles. We show that the proposed pipeline can handle complex static and dynamic kitchen settings for both wheel-based and legged mobile manipulators. Compared to other agent-centric planners, our proposed planner achieves a higher success rate and a lower execution time. We also perform hardware tests on a legged mobile manipulator to interact with various articulated objects in a kitchen. For additional material, please check: www.pair.toronto.edularticulated-mm/. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IROS51168.2021.9636172,IEEE International Conference on Intelligent Robots and Systems,"Humans have a natural ability to effortlessly comprehend linguistic commands such as 'park next to the yellow sedan' and instinctively know which region of the road the vehicle should navigate. Extending this ability to autonomous vehicles is the next step towards creating fully autonomous agents that respond and act according to human commands. To this end, we propose the novel task of Referring Navigable Regions (RNR), i.e., grounding regions of interest for navigation based on the linguistic command. RNR is different from Referring Image Segmentation (RIS), which focuses on grounding an object referred to by the natural language expression instead of grounding a navigable region. For example, for a command 'park next to the yellow sedan,' RIS will aim to segment the referred sedan, and RNR aims to segment the suggested parking region on the road. We introduce a new dataset, Talk2Car-RegSeg, which extends the existing Talk2car [1] dataset with segmentation masks for the regions described by the linguistic commands. A separate test split with concise manoeuvre-oriented commands is provided to assess the practicality of our dataset. We benchmark the proposed dataset using a novel transformer-based architecture. We present extensive ablations and show superior performance over baselines on multiple evaluation metrics. A downstream path planner generating trajectories based on RNR outputs confirms the efficacy of the proposed framework. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IROS51168.2021.9636855,IEEE International Conference on Intelligent Robots and Systems,"In collaborative robotic applications, human and robot have to work together to accomplish a common job, composed by a set of tasks. In order to achieve an efficient human-robot collaboration (HRC), it is important to have an integration between a proper task scheduling strategy and a task execution strategy. The first must deal with the variability of the two agents, while the second must deal with the safety standards. In this paper, we propose an integrated architecture for task scheduling and execution in a collaborative cell. The tasks are dynamically scheduled handling the uncertainity in both the human and the robot behaviors. Subsequently, at the execution level, the task is accomplished computing trajectories comply with the safety regulations. The planning information are mutually integrated in real-time with the scheduling procedure in order improve the HRC. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IROS55552.2023.10341937,IEEE International Conference on Intelligent Robots and Systems,"This study presents the conflict-aware multi-agent estimated time of arrival (CAMETA) framework, a novel approach for predicting the arrival times of multiple agents in unstructured environments without predefined road infrastructure. The CAMETA framework consists of three components: a path planning layer generating potential path suggestions, a multi-agent ETA prediction layer predicting the arrival times for all agents based on the paths, and lastly, a path selection layer that calculates the accumulated cost and selects the best path. The novelty of the CAMETA framework lies in the heterogeneous map representation and the heterogeneous graph neural network architecture. As a result of the proposed novel structure, CAMETA improves the generalization capability compared to the state-of-the-art methods that rely on structured road infrastructure and historical data. The simulation results demonstrate the efficiency and efficacy of the multi-agent ETA prediction layer, with a mean average percentage error improvement of 29.5% and 44% when compared to a traditional path planning method (A *) which does not consider conflicts. The performance of the CAMETA framework shows significant improvements in terms of robustness to noise and conflicts as well as determining proficient routes compared to state-of-the-art multi-agent path planners. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IROS55552.2023.10342507,IEEE International Conference on Intelligent Robots and Systems,"Motion prediction is a challenging task for autonomous vehicles due to uncertainty in the sensor data, the non-deterministic nature of future, and complex behavior of agents. In this paper, we tackle this problem by representing the scene as dynamic occupancy grid maps (DOGMs), associating semantic labels to the occupied cells and incorporating map information. We propose a novel framework that combines deep-learning-based spatio-temporal and probabilistic approaches to predict vehicle behaviors. Contrary to the conventional OGM prediction methods, evaluation of our work is conducted against the ground truth annotations. We experiment and validate our results on real-world NuScenes dataset and show that our model shows superior ability to predict both static and dynamic vehicles compared to OGM predictions. Furthermore, we perform an ablation study and assess the role of semantic labels and map in the architecture. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ISBI.2019.8759410,Proceedings - International Symposium on Biomedical Imaging,"Breast cancer is the most diagnosed cancer and the most predominant cause of death in women worldwide. Imaging techniques such as breast cancer pathology helps in the diagnosis and monitoring of the disease. However identification of malignant cells can be challenging given the high heterogeneity in tissue absorption from staining agents. In this work, we present a novel approach for Invasive Ductal Carcinoma (IDC) cells discrimination in histopathology slides. We propose a model derived from the Inception architecture, proposing a multi-level batch normalization module between each convolutional steps. This module was used as a base block for feature extraction in a CNN architecture. We used the open IDC dataset in which we obtained a balanced accuracy of 0.89 and an F1 score of 0.90, thus surpassing recent state of the art classification algorithms tested on this public dataset. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ISCC.2008.4625773,Proceedings - International Symposium on Computers and Communications,"Mobile and wireless technology has revolutionized people's lives by enabling data delivery anytime, anywhere, liberating the users from the restrictions of wired networks. In addition broadband communications permit high speed data connections. Since multimedia content delivered on-line requires reasonably high data rates and today's wireless networks (3G, Wi-Fi, WiMAX etc) can support the quality requirements of media streaming delivery, while mobile devices handheld or not (Pocket PC, smart phones, laptop pc etc) are able to accommodate a variety of content formats, content delivery has become an indisputable trend. This paper presents such a content delivery network, the ENAMORADO architecture, which is the outcome of the work carried out in the IST project ENAMORADO (Enabling Nomadic Agents in a Multimedia Oriented Architecture of Distributed Objects). The ENAMORADO architecture covers the full content delivery chain from the media producers to the end users incorporating the content production, annotation, aggregation, adaptation and delivery. The paper describes the reference architecture of the infrastructure as well as the testbed used in the components integration and validation process. In addition further system evaluation results are presented. © 2008 IEEE. © 2008 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ISCC50000.2020.9219683,Proceedings - International Symposium on Computers and Communications,"In a world where Artificial Intelligence revolutionizes inference, prediction and decision-making tasks, Digital Twins emerge as game-changing tools. A case in point is the development and optimization of Cooperative Intelligent Transportation Systems (C-ITSs): a confluence of cyber-physical digital infrastructure and (semi)automated mobility. Herein we introduce Digital Twin for self-dRiving Intelligent VEhicles (DRIVE). The developed framework tackles shortcomings of traditional vehicular and network simulators. It provides a flexible, modular, and scalable implementation to ensure large-scale, city-wide experimentation with a moderate computational cost. The defining feature of our Digital Twin is a unique architecture allowing for submission of sequential queries, to which the Digital Twin provides instantaneous responses with the ""state of the world"", and hence is an Oracle. With such bidirectional interaction with external intelligent agents and realistic mobility traces, DRIVE provides the environment for development, training and optimization of Machine Learning based C-ITS solutions. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ISIE51582.2022.9831470,IEEE International Symposium on Industrial Electronics,"This paper addresses the challenge of achieving reliable and predictable operation of flexible and modular pro-duction systems with distributed control and potentially wireless communication. Such systems are envisaged as common in the future Industry 4.0 production facilities. A software design pattern is proposed to implement online monitoring of requirements. The IEC 61499 architecture is selected as the implementation platform and its benefits are essentially used by utilisation of the adapter interface mechanism. The paper also outlines a pathway to designing and verifying the monitors based on formal methods. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ITSC.2018.8569232,,"Active transportation, human-powered transportation modes such as walking and bicycling, not only reduces the carbon footprint from the transportation sector but also promotes healthy living by offering opportunities for people to build physical activity into their daily routine. To encourage active transportation through urban planning and public campaigns, it is of significant importance to infer factors that substantially influence commuters in their transportation mode choice process. This necessitates a flexible and repeatable tool that can evaluate how a policy is perceived by individual commuters and convert their decisions into macro level understanding. This paper introduces one such effort that is specifically designed for studies of transportation mode choices in metropolitan areas. It provides results from a high-resolution data driven simulation based on high performance computing implementation of the agent-based model framework for home-to-work commute trips. The framework uses a graph-partition based technique that can leverage the interaction structure of agents within a geographic proximity and can boost the simulation execution time. Further, based on a flexible design, it can run ABM with different levels of computing resources-from multi core workstations to an HPC grid. The framework has been tested on the Titan Cray XK7 supercomputer of the Oak Ridge Leadership Computing Facility. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ITSC.2019.8917271,,"A key challenge for autonomous driving is safe trajectory planning in cluttered, urban environments with dynamic obstacles, such as pedestrians, bicyclists, and other vehicles. A reliable prediction of the future environment, including the behavior of dynamic agents, would allow planning algorithms to proactively generate a trajectory in response to a rapidly changing environment. We present a novel framework that predicts the future occupancy state of the local environment surrounding an autonomous agent by learning a motion model from occupancy grid data using a neural network. We take advantage of the temporal structure of the grid data by utilizing a convolutional long-short term memory network in the form of the PredNet architecture. This method is validated on the KITTI dataset and demonstrates higher accuracy and better predictive power than baseline methods. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ITSC48978.2021.9564662,,"Moving object Detection (MOD) is a critical task in autonomous driving as moving agents around the ego-vehicle need to be accurately detected for safe trajectory planning. It also enables appearance agnostic detection of objects based on motion cues. There are geometric challenges like motion-parallax ambiguity which makes it a difficult problem. In this work, we aim to leverage the vehicle motion information and feed it into the model to have an adaptation mechanism based on ego-motion. The motivation is to enable the model to implicitly perform ego-motion compensation to improve performance. We convert the six degrees of freedom vehicle motion into a pixel-wise tensor which can be fed as input to the CNN model. The proposed model using Vehicle Motion Tensor (VMT) achieves an absolute improvement of 5.6% in mIoU over the baseline architecture. We also achieve state-of-the-art results on the public KITTI_MoSeg_Extended dataset even compared to methods which make use of LiDAR and additional input frames. Our model is also lightweight and runs at 85 fps on a TitanX GPU. Qualitative results are provided in https://youtu.be/ezbfjti-kTk. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ITSC48978.2021.9564912,,"Reinforcement learning (RL) has recently been used for solving challenging decision-making problems in the context of automated driving. However, one of the main drawbacks of the presented RL-based policies is the lack of safety guarantees, since they strive to reduce the expected number of collisions but still tolerate them. In this paper, we propose an efficient RL-based decision-making pipeline for safe and cooperative automated driving in merging scenarios. The RL agent is able to predict the current situation and provide high-level decisions, specifying the operation mode of the low level planner which is responsible for safety. In order to learn a more generic policy, we propose a scalable RL architecture for the merging scenario that is not sensitive to changes in the environment configurations. According to our experiments, the proposed RL agent can efficiently identify cooperative drivers from their vehicle state history and generate interactive maneuvers, resulting in faster and more comfortable automated driving. At the same time, thanks to the safety constraints inside the planner, all of the maneuvers are collision free and safe. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ITSC55140.2022.9922064,,"Deep learning is a key approach for the environment perception function of Cooperative Intelligent Transportation Systems (C-ITS) with autonomous vehicles and smart traffic infrastructure. The performance of the object recognition and detection strongly depends on the data volume in the model training, which is usually not sufficient due to the limited data collected by a typically small fleet of test vehicles. In today's C-ITS, smart traffic participants are capable of timely generating and transmitting a large amount of data. However, these data can not be used for model training directly due to privacy constraints. In this paper, we introduce a federated learning framework coping with Hierarchical Heterogeneity (H2-Fed), which can notably enhance the conventional pre-trained deep learning model. The framework exploits data from connected public traffic agents in vehicular networks without affecting user data privacy. By coordinating existing traffic infrastructure, including roadside units and road traffic clouds, the model parameters are efficiently disseminated by vehicular communications and hierarchically aggregated. Considering the individual heterogeneity of data distribution, computational and communication capabilities across traffic agents and roadside units, we employ a novel method that addresses the heterogeneity in different aggregation layers of the framework architecture, i.e., aggregation in layers of roadside units and cloud. The experimental results indicate that our method can well balance the learning accuracy and stability according to the knowledge of heterogeneity in current communication networks. Comparing to other baseline approaches, the evaluation on federated datasets shows that our framework is more general and capable especially in application scenarios with low communication quality. Even when 90% of the agents are timely disconnected, the pre-trained deep learning model can still be forced to converge stably, and its accuracy can be enhanced from 68% to over 90% after convergence. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ITSC55140.2022.9922515,,"The improvement of traffic efficiency at urban intersections receives strong research interest in the field of automated intersection management. So far, mostly non-learning algorithms like reservation or optimization-based ones were proposed to solve the underlying multi-agent planning problem. At the same time, automated driving functions for a single ego vehicle are increasingly implemented using machine learning methods. In this work, we build upon a previously presented graph-based scene representation and graph neural network to approach the problem using reinforcement learning. The scene representation is improved in key aspects by using edge features in addition to the existing node features for the vehicles. This leads to an increased representation quality that is leveraged by an updated network architecture. The paper provides an in-depth evaluation of the proposed method against baselines that are commonly used in automatic intersection management. Compared to a traditional signalized intersection and an enhanced first-in-first-out scheme, a significant reduction of traversal duration is observed at varying traffic densities. Finally, the generalization capability of the graph-based representation is evaluated by testing the policy on intersection layouts not seen during training. The model generalizes virtually without restrictions to smaller intersection layouts and within certain limits to larger ones. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ITSC57777.2023.10422227,,"In times of disaster, swift and efficient population evacuation is crucial to minimize losses. This study presents a generic framework for dynamic population evacuation (DPE), incorporating both planning and online management using vehicular communication. The framework deploys dynamic shelter allocation and traffic assignment techniques in the planning phase and combines an agent-based traffic simula-tor to represent the evacuation process with a vehicular ad hoc network (VANET), enabling real-time communication and decision-making among evacuees. The proposed methodology allows us to benchmark a range of evacuation strategies, focusing on identifying the most effective configuration of the framework's objective functions for DPE planning, particularly in large-scale scenarios. Additionally, the study investigates the optimal Penetration Rate (PR) - the proportion of vehicles that are capable of communicating with each other and the infrastructure. The aim is to determine the level of vehicle connectivity that promotes the most efficient evacuation procedures. A detailed benchmark comparison is conducted of two prevalent telecommunication network architectures: the centralized VCC and the distributed Vehicular Fog Computing (VFC). Multiple insights into the performance of these systems during evacuation situations are provided. The results show that a VFC architecture is the most suitable for large-scale population evacuation. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1109/IVS.2010.5548133,"IEEE Intelligent Vehicles Symposium, Proceedings","In this paper we propose the application of intelligent agents in traffic-lights, for the road control of urban transit in the city of Colima, México; using a multi-agent approach for dynamic urban traffic-lights system coordination that relies on locally available traffic data and the traffic condition of the neighboring intersections. According to this approach, our system consists of agents distributed into a hierarchical architecture. Each agent is responsible for one activity, for example, traffic data collection, preprocessing of these data and decision making of reconfiguration of the traffic-lights controllers. An intelligent algorithm based on the policy management model is defined and used as an auxiliary element for the coordination mechanism in order to form an adaptive control system with learning capabilities that allows a more fluid traffic and reduce some of the problems that the society face such as the average wait time and trip travel time and the average size queue per intersection. We define a model based on configuration profiles that are used as initial configurations and new configuration profiles are created as the traffic conditions change. Our approach is experimented with traffic control of a few connected junctions and the result obtained is promising; it can reduce the average delayed time of each car at each traffic-light near an intersection rather substantially when compared with the current traffic-lights control approach. ©2010 IEEE. © 2010 Elsevier B.V., All rights reserved.",TOPIC
10.1109/JBHI.2023.3340325,Graph-Based Conditional Generative Adversarial Networks for Major Depressive Disorder Diagnosis With Synthetic Functional Brain Network Generation,"Major Depressive Disorder (MDD) is a pervasive disorder affecting millions of individuals, presenting a significant global health concern. Functional connectivity (FC) derived from resting-state functional Magnetic Resonance Imaging (rs-fMRI) serves as a crucial tool in revealing functional connectivity patterns associated with MDD, playing an essential role in precise diagnosis. However, the limited data availability of FC poses challenges for robust MDD diagnosis. To tackle this, some studies have employed Deep Neural Networks (DNN) architectures to construct Generative Adversarial Networks (GAN) for synthetic FC generation, but this tends to overlook the inherent topology characteristics of FC. To overcome this challenge, we propose a novel Graph Convolutional Networks (GCN)-based Conditional GAN with Class-Aware Discriminator (GC-GAN). GC-GAN utilizes GCN in both the generator and discriminator to capture intricate FC patterns among brain regions, and the class-aware discriminator ensures the diversity and quality of the generated synthetic FC. Additionally, we introduce a topology refinement technique to enhance MDD diagnosis performance by optimizing the topology using the augmented FC dataset. Our framework was evaluated on publicly available rs-fMRI datasets, and the results demonstrate that GC-GAN outperforms existing methods. This indicates the superior potential of GCN in capturing intricate topology characteristics and generating high-fidelity synthetic FC, thus contributing to a more robust MDD diagnosis.",TOPIC
10.1109/JCN.2010.6391375,Synergy: An overlay internetworking architecture and implementation,"A multitude of overlay network designs for resilient routing, multicasting, quality of service, content distribution, storage, and object location have been proposed. Overlay networks offer several attractive features, including ease of deployment, flexibility, adaptivity, and an infrastructure for collaboration among hosts. In this paper, we explore cooperation among co-existing, possibly heterogeneous, overlay networks. We discuss a spectrum of cooperative forwarding and information sharing services, and investigate the associated scalability, heterogeneity, and security problems. Motivated by these services, we design Synergy, a utility-based overlay internetworking architecture that fosters overlay cooperation. Our architecture promotes fair peering relationships to achieve synergism. Results from Internet experiments with cooperative forwarding overlays indicate that our Synergy prototype improves delay, throughput, and loss performance, while maintaining the autonomy and heterogeneity of individual overlay networks.",TOPIC
10.1109/JETCAS.2018.2856117,IEEE Journal on Emerging and Selected Topics in Circuits and Systems,"Due to the distributed and asynchronous nature of neural computation through low-energy spikes, brain-inspired hardware systems offer high energy efficiency and massive parallelism. One such platform is the IBM TrueNorth neurosynaptic system. Recently, TrueNorth compatible representation learning algorithms have emerged, achieving close to the state-of-the-art performance in various data sets. However, its application in temporal sequence processing models, such as recurrent neural networks (RNNs), is still only at the proof of concept level. There is an inherent difficulty in capturing temporal dynamics of an RNN using spiking neurons, which is only exasperated by the hardware constraints in connectivity and synaptic weight resolution. This paper presents a design flow that overcomes these difficulties and maps a special case of recurrent networks called long short-term memory (LSTM) onto a spike-based platform. The framework utilizes various approximation techniques, such as activation discretization, weight quantization, and scaling and rounding, spiking neural circuits that implement the complex gating mechanisms, and a store-and-release technique to enable neuron synchronization and faithful storage. While the presented techniques can be applied to map LSTM to any spiking neural network (SNN) simulator/emulator, here we choose the TrueNorth chip as the target platform by adhering to its hardware constraints. Three LSTM applications, parity check, extended Reber grammar, and question classification, are evaluated. The tradeoffs among accuracy, performance, and energy tradeoffs achieved on TrueNorth are demonstrated. This is compared with the performance on an SNN platform without hardware constraints, which represents the upper bound of the achievable accuracy. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1109/JIOT.2020.2995843,IEEE Internet of Things Journal,"Currently, research centers, government, and industry have been developing technologies to enable novel capabilities for future classrooms. The Internet of Things (IoT), the Internet of Everything (IoE), and the Internet of Anything (IoA) are examples of technological paradigms that could transform current classrooms into collaborative classrooms. In this article, we investigate the design and simulation of a systems architecture that employs concepts related to System of Systems (SoS) and IoA to extend the capabilities of future classrooms. We design such architecture to be service oriented and to provide interactions between each established constituent system (CS), which is composed by the following elements: 1) local IoE modules; 2) CS negotiator agent; and 3) IoE/IoA agent. We consider a case study about interschool collaborations to improve learning in biology classes. Our results indicate that the usage of the IoA network improves on 52.02% the performance of the IoE network, it improves the recommendation of services by establishing a high competition between CSs, and quadruplicates the number of connections in this SoS network. These results suggest that such approach is effective to increase the collaboration between devices, people, or schools with different objectives and policies. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/JIOT.2023.3288050,IEEE Internet of Things Journal,"The rise of chronic disease patients and the pandemic pose immediate threats to healthcare expenditure and mortality rates. This calls for transforming healthcare systems away from one-on-one patient treatment into intelligent health systems, leveraging the recent advances of Internet of Things and smart sensors. Meanwhile, reinforcement learning (RL) has witnessed an intrinsic breakthrough in solving a variety of complex problems for distinct applications and services. Thus, this article presents a comprehensive survey of the recent models and techniques of RL that have been developed/used for supporting Intelligent-healthcare (I-health) systems. It can guide the readers to deeply understand the state-of-the-art regarding the use of RL in the context of I-health. Specifically, we first present an overview of the I-health systems' challenges, architecture, and how RL can benefit these systems. We then review the background and mathematical modeling of different RL, deep RL (DRL), and multiagent RL models. We highlight important guidelines on how to select the appropriate RL model for a given problem, and provide quantitative comparisons, showing the results of deploying key RL models in two scenarios that can be followed in monitoring applications. After that, we conduct an in-depth literature review on RL's applications in I-health systems, covering edge intelligence, smart core network, and dynamic treatment regimes. Finally, we highlight emerging challenges and future research directions to enhance RL's success in I-health systems, which opens the door for exploring some interesting and unsolved problems. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1109/JIOT.2025.3541715,DNN Task Assignment in UAV Networks: A Generative AI Enhanced Multiagent Reinforcement Learning Approach,"uncrewed aerial vehicles (UAVs) offer high mobility and flexible deployment capabilities, making them ideal for Internet of Things (IoT) applications. However, the substantial amount of data generated by various applications within the existing low-altitude network requires processing through deep neural networks (DNN) on UAVs, which is challenging due to their limited computational resources. To address this issue, we propose a two-stage optimization method for flight path planning and task allocation based on a mother-child UAV swarm system. In the first stage, we employ a greedy algorithm to solve the path planning problem by considering the task size of the target area to be inspected and the shortest flight path as constraints. The goal is to minimize both the flight path of the UAV and the overall cost of the system. In the second stage, we introduce a novel DNN task assignment algorithm that combines multiagent deep deterministic policy gradient (MADDPG) and generative diffusion models (GDMs), named GDM-MADDPG. This algorithm takes advantage of the reverse denoising process of GDM to replace the actor network in MADDPG. It enables UAVs to generate specific DNN task assignment actions based on agents’ observations in a dynamic environment, thereby improving the efficiency of task assignment and overall system performance. The simulation results demonstrate that our algorithm outperforms the benchmarks in terms of path planning, Age of Information (AoI), task completion rate, and system utility, demonstrating its effectiveness.",TOPIC
10.1109/JIOT.2025.3579862,Autonomous Driving: Integration of Segmentation and Depth Camera in a Curriculum Learning Approach,"Autonomous driving (AD) entails vehicles that can perceive their surroundings and navigate without human intervention. This involves utilising a combination of sensors and algorithms to recognize obstacles, interpret traffic signals, and make driving decisions. While AD holds promise for transforming transportation by enhancing safety, reducing congestion, minimising pollution, and optimising efficiency, it poses technical challenges also. This work extends a novel approach to building an autonomous vehicle agent using deep reinforcement learning (DRL) with proximal policy optimisation (PPO) to navigate urban environments simulated by the CAR learning to act (CARLA) Simulator. The agent aims to maintain lane integrity and avoid collisions, even in adverse weather conditions. The proposed architecture integrates a 180-degree environmental view and various multimodal data inputs (RGB, segmentation, and depth camera inputs), extensively tested through experimentation. Notably, the integration of segmentation and depth data results in a 13% reduction in the collision rate, with the proposed agent achieving a total reward of 2510. This approach demonstrates significant progress over the previous framework, showcasing improved obstacle detection and collision avoidance accuracy. Moreover, these findings contribute to ongoing autonomous vehicle research, offering insights into effective strategies for developing robust and dependable driving agents capable of navigating urban environments and interacting with road infrastructure, contributing to advancements in Augmented Intelligence of Things (AIoT)-enabled AD.",TOPIC
10.1109/JIOT.2025.3613063,Towards Securing IIoT: An Innovative Privacy-Preserving Anomaly Detector Based on Federated Learning,"In the light of the growing connectivity and sensitivity of industrial data, cyberattacks and data breaches are becoming more common in the Industrial Internet of Things (IIoT). To cope with such threats, this study presents an anomaly detection system based on a novel Federated Learning (FL) framework. This system detects anomalies such as cyberattacks and protects industrial data privacy by processing data locally and training anomaly detection models on industrial agents without sharing raw data. The proposed FL framework incorporates two key components to enhance both privacy and efficiency. The first component is Homomorphic Encryption (HE), which is integrated into the framework to further protect sensitive data transmissions such as model parameters. HE enhances privacy in FL by preventing adversaries from inferring private industrial data through attacks, such as model inversion attacks. The second component is an innovative dynamic agent selection scheme, wherein a selection threshold is calculated based on agent delays and data size. The purpose of this new scheme is to mitigate the straggler effect and the communication bottleneck that occur in traditional FL architectures, such as synchronous and asynchronous architectures. It ensures that agents are not unfairly selected by the different delays resulting from heterogeneous data in IIoT environments, while simultaneously improving model performance and convergence speed. The proposed framework exhibits superior performance over baseline approaches in terms of accuracy, precision, F1-scores, communication costs, convergence speeds, and fairness rate.",TOPIC
10.1109/JISPIN.2023.3334690,Drone Navigation and Target Interception Using Deep Reinforcement Learning: A Cascade Reward Approach,"This article proposes an architecture for drone navigation and target interception, utilizing a self-supervised, model-free deep reinforcement learning approach. Unlike the traditional methods relying on complex controllers, our approach uses deep reinforcement learning with cascade rewards, enabling a single drone to navigate obstacles and intercept targets using only a forward-facing depth–RGB camera. This research has significant implications for robotics, as it demonstrates how complex tasks can be tackled using deep reinforcement learning. Our work encompasses three key contributions. First, we tackle the challenge of partial observability when employing nonlinear function approximators for learning stochastic policies. Second, we optimize the task of maximizing the overall expected reward. Finally, we develop a software library for training drones to track and intercept targets. Through our experiments, we demonstrated that our approach, incorporating cascade reward, outperforms state-of-the-art deep Q-network algorithms in terms of learning policies. By leveraging our methodology, drones can successfully navigate complex indoor and outdoor environments and effectively intercept targets based on visual cues.",TOPIC
10.1109/JISPIN.2025.3567374,Neuromorphic Digital-Twin-Based Controller for Indoor Multi-UAV Systems Deployment,"This study introduces a novel distributed cloud-edge framework for autonomous multi-unmanned aerial vehicle (UAV) systems that combines the computational efficiency of neuromorphic computing with nature-inspired control strategies. The proposed architecture equips each UAV with an individual spiking neural network (SNN) that learns to reproduce optimal control signals generated by a cloud-based controller, enabling robust operation even during communication interruptions. By integrating spike coding with nature-inspired control principles inspired by tilapia fish territorial behavior, our system achieves sophisticated formation control and obstacle avoidance in complex urban environments. The distributed architecture leverages cloud computing for complex calculations while maintaining local autonomy through edge-based SNNs, significantly reducing energy consumption and computational overhead compared to traditional centralized approaches. Our framework addresses critical limitations of conventional methods, including the dependence on premodeled environments, computational intensity of traditional methods, and local minima issues in potential field approaches. Simulation results demonstrate the system's effectiveness across two different scenarios: first, the indoor deployment of a multi-UAV system made up of 15 UAVs, and second, the collision-free formation control of a moving UAV flock, including six UAVs considering the obstacle avoidance. Due to the sparsity of spiking patterns, and the event-based nature of SNNs on average for the whole group of UAVs, the framework achieves almost 90% reduction in computational burden compared to traditional von Neumann architectures implementing traditional artificial neural networks.",TOPIC
10.1109/JPROC.2021.3058954,Toward Causal Representation Learning,"The two fields of machine learning and graphical causality arose and are developed separately. However, there is, now, cross-pollination and increasing interest in both fields to benefit from the advances of the other. In this article, we review fundamental concepts of causal inference and relate them to crucial open problems of machine learning, including transfer and generalization, thereby assaying how causality can contribute to modern machine learning research. This also applies in the opposite direction: we note that most work in causality starts from the premise that the causal variables are given. A central problem for AI and causality is, thus, causal representation learning, that is, the discovery of high-level causal variables from low-level observations. Finally, we delineate some implications of causality for machine learning and propose key research areas at the intersection of both communities.",TOPIC
10.1109/JSAC.2019.2933973,IEEE Journal on Selected Areas in Communications,"This work demonstrates the potential of deep reinforcement learning techniques for transmit power control in wireless networks. Existing techniques typically find near-optimal power allocations by solving a challenging optimization problem. Most of these algorithms are not scalable to large networks in real-world scenarios because of their computational complexity and instantaneous cross-cell channel state information (CSI) requirement. In this paper, a distributively executed dynamic power allocation scheme is developed based on model-free deep reinforcement learning. Each transmitter collects CSI and quality of service (QoS) information from several neighbors and adapts its own transmit power accordingly. The objective is to maximize a weighted sum-rate utility function, which can be particularized to achieve maximum sum-rate or proportionally fair scheduling. Both random variations and delays in the CSI are inherently addressed using deep Q -learning. For a typical network architecture, the proposed algorithm is shown to achieve near-optimal power allocation in real time based on delayed CSI measurements available to the agents. The proposed scheme is especially suitable for practical scenarios where the system model is inaccurate and CSI delay is non-negligible. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1109/JSAC.2021.3078501,IEEE Journal on Selected Areas in Communications,"Recent 5G trials have demonstrated the usefulness of the Network Slicing concept that delivers customizable services to new and under-serviced industry sectors. However, user mobility's impact on the optimal resource allocation within and between slices deserves more attention. Slices and their dedicated resources should be offered where the services are to be consumed to minimize network latency and associated overheads and costs. Different mobility patterns lead to different resource re-allocation triggers, leading eventually to slice mobility when enough resources are to be migrated. The selection of the proper triggers for resource re-allocation and related slice mobility patterns is challenging due to triggers' multiplicity and overlapping nature. In this paper, we investigate the applicability of two Deep Reinforcement Learning based algorithms for allowing a fine-grained selection of mobility triggers that may instantiate slice and resource mobility actions. While the first proposed algorithm relies on a value-based learning method, the second one exploits a hybrid approach to optimize the action selection process. We present an enhanced ETSI Network Function Virtualization edge computing architecture that incorporates the studied mechanisms to implement service and slice migration. We evaluate the proposed methods' efficiency in a simulated environment and compare their performance in terms of training stability, learning time, and scalability. Finally, we identify and quantify the applicability aspects of the respective approaches. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/JSAC.2022.3156630,IEEE Journal on Selected Areas in Communications,"Integrating sensing functions into future mobile equipment has become an important trend. Realizing different types of sensing and achieving mutual enhancement under the existing communication hardware architecture is a crucial challenge in realizing the deep integration of sensing and communication. In the 5G New Radio context, active sensing can be performed through uplink beam sweeping on the user equipment (UE) side to observe the surrounding environment. In addition, the UE can perform passive sensing through downlink channel estimation to measure the multipath component (MPC) information. This study is the first to develop a hybrid simultaneous localization and mapping (SLAM) mechanism that combines active and passive sensing, in which mutual enhancement between the two sensing modes is realized in communication systems. Specifically, we first establish a common feature associated with the reflective surface to bridge active and passive sensing, thus enabling information fusion. Based on the common feature, we can attain physical anchor initialization through MPC with the assistance of active sensing. Then, we extend the classic probabilistic data association SLAM mechanism to achieve UE localization and continuously refine the physical anchor and target reflections through the subsequent passive sensing. Numerical results show that the proposed hybrid active and passive sensing-based SLAM mechanism can work successfully in tricky scenarios without any prior information on the floor plan, anchors, or agents. Moreover, the proposed algorithm demonstrates significant performance gains compared with active or passive sensing only mechanisms. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/JSEE.2013.00111,Immune multi-agent model using vaccine for cooperative air-defense system of systems for surface warship formation based on danger theory,"Aiming at the problem on cooperative air-defense of surface warship formation, this paper maps the cooperative air-defense system of systems (SoS) for surface warship formation (CASoSSWF) to the biological immune system (BIS) according to the similarity of the defense mechanism and characteristics between the CASoSSWF and the BIS, and then designs the models of components and the architecture for a monitoring agent, a regulating agent, a killer agent, a pre-warning agent and a communicating agent by making use of the theories and methods of the artificial immune system, the multi-agent system (MAS), the vaccine and the danger theory (DT). Moreover a new immune multi-agent model using vaccine based on DT (IMMUVBDT) for the cooperative air-defense SoS is advanced. The immune response and immune mechanism of the CASoSSWF are analyzed. The model has a capability of memory, evolution, commendable dynamic environment adaptability and self-learning, and embodies adequately the cooperative air-defense mechanism for the CA-SoSSWF. Therefore it shows a novel idea for the CASoSSWF which can provide conception models for a surface warship formation operation simulation system.",TOPIC
10.1109/JSTARS.2021.3120724,Adaptive Resource Optimized Edge Federated Learning in Real-Time Image Sensing Classifications,"With the exponential growth of the Internet of things (IoT) in remote sensing image applications, network resource orchestration and data privacy are significant aspects to handle in bigdata cellular networks. The image data sharing procedure toward central cloud servers in order to perform real-time classifications has leaked client personalization and heavily burdened the communication networks. Thus, the deployment of IoT image sensors in privacy-constrained sectors requires an optimized federated learning (FL) scheme to efficiently consider both aspects of securing data privacy and maximizing the model accuracy with sufficient communication and computation resources. In this article, an adaptive model communication scheme with virtual resource optimization for edge FL is proposed by converging a deep q-learning algorithm to enforce a self-learning agent interacting with network functions virtualization orchestrator and software-defined networking based architecture. The agent targets to optimize the resource control policy of virtual multi-access edge computing entities in virtualized infrastructure manager. The proposed scheme trains the learning model and weighs the optimal actions for particular network states by using an epsilon-greedy strategy. In the exploitation phase, the scheme considers multiple spatial-resolution sensing conditions and allocates computation offloading resources for global multiconvolutional neural networks model aggregation based on the congestion states. In the simulation results, the quality of service and global collaborative model performance metrics were evaluated in terms of delay, packet drop ratios, packet delivery ratios, loss values, and overall accuracy.",TOPIC
10.1109/JSTARS.2022.3232583,Automated Machine Learning Driven Stacked Ensemble Modeling for Forest Aboveground Biomass Prediction Using Multitemporal Sentinel-2 Data,"Modeling and large-scale mapping of forest aboveground biomass (AGB) is a complicated, challenging, and expensive task. There are considerable variations in forest characteristics that create functional disparity for different models and needs comprehensive evaluation. Moreover, the human-bias involved in the process of modeling and evaluation affects the generalization of models at larger scales. In this article, we present an automated machine learning framework for modeling, evaluation, and stacking of multiple base models for AGB prediction. We incorporate a hyperparameter optimization procedure for automatic extraction of targeted features from multitemporal Sentinel-2 data that minimizes human-bias in the proposed modeling pipeline. We integrate the two independent frameworks for automatic feature extraction and automatic model ensembling and evaluation. The results suggest that the extracted target-oriented features have an excessive contribution of red-edge and short-wave infrared spectrum. The feature importance scale indicates a dominant role of summer-based features as compared to other seasons. The automated ensembling and evaluation framework produced a stacked ensemble of base models that outperformed individual base models in accurately predicting forest AGB. The stacked ensemble model delivered the best scores of R2cv = 0.71 and RMSE = 74.44 Mgha−1. The other base models delivered R2cv and RMSE ranging between 0.38–0.66 and 81.27–109.44 Mg ha−1, respectively. The model evaluation metrics indicated that the stacked ensemble model was more resistant to outliers and achieved a better generalization. Thus, the proposed study demonstrated an effective automated modeling pipeline for predicting AGB by minimizing human-bias and deployable over large and diverse forest areas.",TOPIC
10.1109/JSTARS.2023.3324494,An Integrated Parallel Inner Deep Learning Models Information Fusion With Bayesian Optimization for Land Scene Classification in Satellite Images,"Classification of remote scenes in satellite imagery has many applications, such as surveillance, earth observation, etc. Classifying high-resolution remote sensing images in machine learning is a big challenge nowadays. Several automated techniques based on machine learning and deep learning have been introduced in the literature; however, these techniques fail to perform for complex texture images, complex backgrounds, and small objects. In this work, we proposed a new automated technique based on the inner fusion of two deep learning models and feature selection. A new network is designed at the initial phase based on the inner-level fusion of two networks and combined weights. After that, hyperparameters have been initialized based on the Bayesian optimization (BO). Usually, the hyperparameters have been initialized through a manual approach, but that is not an efficient way of selection. After that, the designed model is trained and extracted deep features from the deeper layer. In the last step, a poor–rich controlled entropy-based feature selection technique is developed for the best feature selection. The selected features are finally classified using machine learning classifiers. We performed the experimental process of the proposed architecture on three publically available datasets: Aerial image dataset (AID), UC-Merceds, and WHU-RS19. On these datasets, we obtained the accuracy of 96.3%, 95.6%, and 97.8%, respectively. Comparison is conducted with state-of-the-art techniques and shows improved accuracy.",TOPIC
10.1109/JSTARS.2023.3339297,An Integrated Framework of Two-Stream Deep Learning Models Optimal Information Fusion for Fruits Disease Recognition,"Diseases impact the rates of production of many agricultural goods. These diseases require detection, which is difficult to do manually. Therefore, the creation of some automated illness detection systems is urgently required. Deep learning showed significant success in the area of precision agriculture for the recognition of plant disease. Compared with the traditional techniques, the deep learning architecture automatically extracts deep features from the deeper layer. In this work, we proposed a new automated method for classifying apple and grapefruit leaf disease recognition utilizing two-stream deep learning architecture. The proposed framework entails several steps. The first phase is picture contrast enhancement, which combines the information from DnCNN and top–bottom hat filtering to create a better image. Then, the augmentation process uses horizontal and vertical flips to increase the dataset's original size. The Inception-ResNet-V2 deep learning model is then adjusted and trained using deep transfer learning on the expanded dataset. After being extracted from the training model, the best features are chosen using two techniques—an entropy-based strategy and tree growth optimization. Finally, a new effective method combines the chosen features, and machine learning classifiers are used to complete the classification. On the augmented dataset, the proposed framework correctly classified apple and leaf diseases with the accuracy rates of 99.4% and 99.9%, respectively.",TOPIC
10.1109/JSTARS.2024.3378298,Crops Leaf Disease Recognition From Digital and RS Imaging Using Fusion of Multi Self-Attention RBNet Deep Architectures and Modified Dragonfly Optimization,"Globally, pests and plant diseases severely threaten forestry and agriculture. Plant protection could be substantially enhanced by using noncontact, extremely effective, and reasonably priced techniques for identifying and tracking pests and plant diseases across large geographic areas. Precision agriculture is the study of using other technologies, such as hyperspectral remote sensing, to increase cultivation instead of traditional agricultural methods with less negative environmental effects. In this article, we proposed a novel deep-learning architecture and optimization algorithm for crop leaf disease recognition. In the initial step, a multilevel contrast enhancement technique is proposed for a better visual of the disease on the leaves of cotton and wheat. After that, we proposed three novel residual block and self-attention mechanisms, named 3-residual block-deep convolutional neural network (RBNet) Self, 5-RBNet Self, and 9-RBNet Self. After that, the proposed models are trained on enhanced images and later extracted deep features from the self-attention layer. The 5-RBNET Self and 9-RBNET Self performed well in terms of accuracy and precision rate; therefore, we did not consider the 3-RBNET Self for the next process. The dragonfly optimization algorithm is proposed for the best feature selection and applied to the self-attention features of 5-RBNET Self and 9-RBNET Self models to improve the classification performance further and reduce the computational cost. The proposed method is evaluated on two publically available crop disease images, such as the cotton, wheat, and EuroSAT datasets. For both crops, the proposed method obtained a maximum accuracy of 98.60% and 93.90%, respectively, whereas for the EuroSAT, the proposed method obtained an accuracy of 83.10%. Compared to the results with recent techniques, the proposed method shows improved accuracy and precision rate.",TOPIC
10.1109/JSTARS.2025.3556550,Designing a Classifier for Active Fire Detection From Multispectral Satellite Imagery Using Neural Architecture Search,"Wildfires are becoming increasingly devastating, and detecting them early is essential to containing them. Deep learning-based wildfire detection systems have increased in complexity dramatically in recent years, and in order to manage this added complexity, techniques have been proposed to automate the design of neural network architectures. Such techniques are usually referred to as neural architecture search (NAS). This article showcases the use of a reinforcement learning-based neural architecture search (NAS) agent to design a small neural network to perform active fire detection on multispectral satellite imagery. Specifically, we aim to automatically design a neural network that can determine if a single multispectral pixel is a part of a fire, and do so within the constraints of a low earth orbit nanosatellite with a limited power budget, to facilitate on-board processing of sensor data. A regression model that predicts the F1 score obtained by a particular architecture following quantization is used as a reward function. This model is trained on the classification performance statistics of a sample of neural network architectures. Besides the F1 score, we also include the total number of parameters in our reward function to limit the size of the designed model. Finally, we deployed the best neural network to the Google Coral Micro Dev Board and evaluated its inference latency and power consumption. This neural network consists of 1716 parameters, takes on average 984 $\mu$s to inference, and consumes around 800 mW to perform inference. These results show that our approach can be applied to new problems.",TOPIC
10.1109/JSTARS.2025.3567485,EDB-Net: Efficient Dual-Branch Convolutional Transformer Network for Hyperspectral Image Classification,"Hyperspectral image (HSI) classification, as a pivotal technology in remote sensing data processing, has garnered significant attention in recent years. Deep learning (DL) has been widely adopted for HSI classification due to its superior feature extraction capabilities. Nevertheless, the deployment of most existing DL models on resource-constrained devices remains challenging because of their intricate architectures and high computational demands. To tackle this challenge, we propose a lightweight dual-branch convolutional transformer network with efficient attention-aware mechanism (EDB-Net), which aims to balance model complexity, classification accuracy, and inference speed. EDB-Net achieves this by conducting an in-depth analysis and modeling of spatial-spectral features through two independent pipelines: one based on convolutional neural networks and the other on Transformer, thereby leveraging the complementary strengths of both approaches. Specifically, we introduce a novel lightweight spatial-spectral Transformer that incorporates a lightweight multi-head efficient attention-aware mechanism. This design ingeniously mitigates the quadratic growth of computational complexity associated with the standard self-attention mechanism's softmax calculation via the agent tokens approach. In addition, by correlating the self-attention map with the query vector, our model accurately extracts useful information to generate an attention gate that highlights key elements of the spectral sequence. Furthermore, the gated recurrent unit is incorporated into the algorithm to enhance the learning and analytical capabilities for spectral sequence data. Experimental results demonstrate that EDB-Net maintains high classification accuracy while significantly reducing computational complexity, outperforming existing state-of-the-art methods.",TOPIC
10.1109/JSTQE.2022.3217011,Scalable Nanophotonic-Electronic Spiking Neural Networks,"Spiking neural networks (SNN) provide a new computational paradigm capable of highly parallelized, real-time processing. Photonic devices are ideal for the design of high-bandwidth, parallel architectures matching the SNN computational paradigm. Furthermore, the co-integration of CMOS and photonic elements combineslow-loss photonic devices with analog electronics for greater flexibility of nonlinear computational elements. We designed and simulated an optoelectronic spiking neuron circuit on a monolithic silicon photonics (SiPh) process that replicates useful spiking behaviors beyond the leaky integrate-and-fire (LIF). Additionally, we explored two learning algorithms with the potential for on-chip learning using Mach-Zehnder Interferometric (MZI) meshes as synaptic interconnects. A variation of Random Backpropagation (RPB) was experimentally demonstrated on-chip and matched the performance of a standard linear regression on a simple classification task. In addition, we applied the Contrastive Hebbian Learning (CHL) rule to a simulated neural network composed of MZI meshes for a random input-output mapping task. The CHL-trained MZI network performed better than random guessing but did not match the performance of the ideal neural network (without the constraints imposed by the MZI meshes). Through these efforts, we demonstrate that co-integrated CMOS and SiPh technologies are well-suited to the design of scalable SNN computing architectures.",TOPIC
10.1109/JXCDC.2017.2697910,IEEE Journal on Exploratory Solid-State Computational Devices and Circuits,"There is great attention to develop hardware accelerator with better energy efficiency, as well as throughput, than GPUs for convolutional neural network (CNN). The existing solutions have relatively limited parallelism as well as large power consumption (including leakage power). In this paper, we present a resistive random access memory (ReRAM)-accelerated CNN that can achieve significantly higher throughput and energy efficiency when the CNN is trained with binary constraints on both weights and activations, and is further mapped on a digital ReRAM-crossbar. We propose an optimized accelerator architecture tailored for bitwise convolution that features massive parallelism with high energy efficiency. Numerical experiment results show that the binary CNN accelerator on a digital ReRAM-crossbar achieves a peak throughput of 792 GOPS at the power consumption of 4.5 mW, which is 1.61 times faster and 296 times more energy-efficient than a high-end GPU. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1109/JXCDC.2020.2999581,IEEE Journal on Exploratory Solid-State Computational Devices and Circuits,"We introduce 'aCortex,' an extremely energy-efficient, fast, compact, and versatile neuromorphic processor architecture suitable for the acceleration of a wide range of neural network inference models. The most important feature of our processor is a configurable mixed-signal computing array of vector-by-matrix multiplier (VMM) blocks utilizing embedded nonvolatile memory arrays for storing weight matrices. Analog peripheral circuitry for data conversion and high-voltage programming are shared among a large array of VMM blocks to facilitate compact and energy-efficient analog-domain VMM operation of different types of neural network layers. Other unique features of aCortex include configurable chain of buffers and data buses, simple and efficient instruction set architecture and its corresponding multiagent controller, programmable quantization range, and a customized refresh-free embedded dynamic random access memory. The energy-optimal aCortex with 4-bit analog computing precision was designed in a 55-nm process with embedded NOR flash memory. Its physical performance was evaluated using experimental data from testing individual circuit elements and physical layout of key components for several common benchmarks, namely, Inception-v1 and ResNet-152, two state-of-the-art deep feedforward networks for image classification, and GNTM, Google's deep recurrent network for language translation. The system-level simulation results for these benchmarks show the energy efficiency of 97, 106, and 336 TOp/J, respectively, combined with up to 15 TOp/s computing throughput and 0.27-MB/mm2 storage efficiency. Such estimated performance results compare favorably with those of previously reported mixed-signal accelerators based on much less mature aggressively scaled resistive switching memories. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/LCSYS.2023.3291657,Supervised Learning of Lyapunov Functions Using Laplace Averages of Approximate Koopman Eigenfunctions,"Modern data-driven techniques have rapidly progressed beyond modelling and systems identification, with a growing interest in learning high-level dynamical properties of a system, such as safe-set invariance, reachability, input-to-state stability etc. In this letter, we propose a novel supervised Deep Learning technique for constructing Lyapunov certificates, by leveraging Koopman Operator theory-based numerical tools (Extended Dynamic Mode Decomposition and Generalized Laplace Analysis) to robustly and efficiently generate explicit ground truth data for training. This is in stark contrast to existing Deep Learning methods where the loss functions plainly penalize Lyapunov condition violation in the absence of labelled data for direct regression. Furthermore, our approach leads to a linear parameterization of Lyapunov candidate functions in terms of stable eigenfunctions of the Koopman operator, making them more interpretable compared to standard DNN-based architecture. We demonstrate and validate our approach numerically using 2-dimensional and 10-dimensional examples.",TOPIC
10.1109/LRA.2021.3125450,IEEE Robotics and Automation Letters,"Drones are currently being explored for safety-critical applications where human agents are expected to evolve in their vicinity. In such applications, robust people avoidance must be provided by fusing a number of sensing modalities in order to avoid collisions. Currently however, people detection systems used on drones are solely based on standard cameras besides an emerging number of works discussing the fusion of imaging and event-based cameras. On the other hand, radar-based systems provide up-most robustness towards environmental conditions but do not provide complete information on their own and have mainly been investigated in automotive contexts, not for drones. In order to enable the fusion of radars with both event-based and standard cameras, we present KUL-UAVSAFE, a first-of-its-kind dataset for the study of safety-critical people detection by drones. In addition, we propose a baseline CNN architecture with cross-fusion highways and introduce a curriculum learning strategy for multi-modal data termed SAUL, which greatly enhances the robustness of the system towards hard RGB failures and provides a significant gain of 15% in peak F1 score compared to the use of BlackIn, previously proposed for cross-fusion networks. We demonstrate the real-time performance and feasibility of the approach by implementing the system in an edge-computing unit. We release our dataset and additional material in the project home page. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/LRA.2025.3572418,CaRaFFusion: Improving 2D Semantic Segmentation With Camera-Radar Point Cloud Fusion and Zero-Shot Image Inpainting,"Segmenting objects in an environment is a crucial task for autonomous driving and robotics, as it enables a better understanding of the surroundings of each agent. Although camera sensors provide rich visual details, they are vulnerable to adverse weather conditions. In contrast, radar sensors remain robust under such conditions, but often produce sparse and noisy data. Therefore, a promising approach is to fuse information from both sensors. In this work, we propose a novel framework to enhance camera-only baselines by integrating a diffusion model into a camera-radar fusion architecture. We leverage radar point features to create pseudo-masks using the Segment-Anything model, treating the projected radar points as point prompts. Additionally, we propose a noise reduction unit to denoise these pseudo-masks, which are further used to generate inpainted images that complete the missing information in the original images. Our method improves the camera-only segmentation baseline by 2.63% in mIoU and enhances our camera-radar fusion architecture by 1.48% in mIoU on the Waterscenes dataset. This demonstrates the effectiveness of our approach for semantic segmentation using camera-radar fusion under adverse weather conditions.",TOPIC
10.1109/MT-ITS49943.2021.9529332,,"Due to the rapidly accelerated innovation cycle in transport and the emergence of new mobility concepts and technologies, public authorities, policy makers, and transport planners are currently in need of the tools for sustainable spatial and transport planning in the new mobility era. In this paper, a new modular, software-agnostic and activity-based spatial and transport planning platform is designed, i.e, the HARMONY Model Suite, that facilitates a novel integration of new and existing spatial and transport modelling tools. The paper focuses on describing the architecture of the platform and its passenger mobility simulation framework, which integrates -in an interoperable manner-activity-based models, mobility service management, and traffic simulation tools for evaluating new mobility system dynamics. The service management controllers for new mobility concepts are discussed in more detail with regards to their functionality and applicability. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/MWC.2025.3601676,"Dynamic THz Backhaul for 6G Local Area Networks: Architecture, Analysis, Challenges and Future Directions","As the communications technology advances towards the era of sixth-generation (6G) communication systems, densification of networks is still one of the promising ways to improve the overall network capacity. Dense networks impose strict requirements and deployment problems for the backhaul infrastructure and its operations. Millimeter wave and low terahertz (THz) bands (30–500 GHz) offer ample capacity to meet any data rate requirements, but are challenging to implement on small-scale devices due to large antenna gain requirements. These are less concerning in a backhaul infrastructure, where devices are more costly and equipped to support such specifications. This article studies the opportunities presented by utilizing THz communications for backhaul operations with tailored architectures for 6G local area networks. Herein, urban microcell and small cell base station networks are investigated. Constraints for backhaul links in these networks are considered from various perspectives including the channel, hardware, physical layer signal processing, and intelligent network management challenges. Even though the THz frequency bands show remarkable potential for dense backhaul operations due to their large capacity, many practical challenges remain that must be addressed for real-world implementation.",TOPIC
10.1109/MWC.2025.3612872,Dynamic Spectrum Anti-Jamming for Low-Altitude Communication Networks: A Coalitional Game Learning Perspective,"Low-altitude communication networks (LACNs), characterized by dynamic air-ground coordination in exposed electromagnetic spaces, are highly susceptible to malicious jamming. To address this issue, coalition-based networking has emerged as a flexible architecture, enabling heterogeneous air-ground agents to form collaborative groups for joint jamming avoidance and internal spectrum cooperation. However, the inherent mobility of low-altitude aerial nodes and the unpredictability of jamming environments pose critical challenges to low-altitude air-ground dynamic spectrum access, particularly in managing real-time interference relationships caused by aerial platform mobility. This paper proposes a coalition-based deep reinforcement learning framework that integrates coalition formation games (CFG) into multi-agent decision-making processes to resolve these challenges. First, we identify four critical issues in low-altitude aerial dynamic spectrum anti-jamming (DSAJ), which consist of dynamics, heterogeneity, limited resources, and malicious jamming threats. To address these challenges, we develop a hierarchical framework comprising three components: task-driven coalition formation, robust inter-coalition spectrum sharing, and distributed intra-coalition anti-jamming access for real-time interference coordination. Besides, a case study demonstrates how aerial and ground node coalitions collaboratively optimize spectrum utilization while countering jamming attacks. Finally, we discuss future research directions, including coalition robustness analysis, scalability in large-scale networks, and real-world deployment.",TOPIC
10.1109/NOMS56928.2023.10154298,,"Containers have revolutionized application deployment and life-cycle management in current cloud platforms. Applications have evolved from large monoliths to complex graphs of loosely-coupled microservices aiming to improve deployment flexibility and operational efficiency. However, modern microservice-based architectures are challenging since proper allocation and scaling of microservices is a difficult task due to their complex inter-dependencies. Existing works do not consider microservice dependencies, which could lead to the application's performance degradation when service demand increases. This paper studies the impact of microservice interdependencies in auto-scaling mechanisms by proposing a novel framework named gym-hpa that enables different auto-scaling goals via Reinforcement Learning (RL). The framework has been developed based on the OpenAI Gym library for the popular Kubernetes (K8s) platform to bridge the gap between RL and auto-scaling research by training RL agents on real cloud environments. The aim is to improve resource usage and reduce the application's response time in future cloud platforms by considering microservice inter-dependencies in horizontal scaling. Experiments with microservice benchmark applications show that RL agents trained with the gym-hpa framework can reduce on average resource usage by 30% and reduce the application's response time by 25% compared to default scaling mechanisms. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1109/NOMS56928.2023.10154452,,"Open Radio Access Network (O-RAN) is a novel architecture that enables the disaggregation and the virtualization of network components. This would provide new ways to mix and match network components by 'opening up' the interfaces between them. O-RAN enables driving down the costs of network deployments and allows the entry of new players into the RAN market. It enables network operators to maximize resource utilization and deliver new network edge services at a lower cost, resulting in higher profits for operators. In this context, we consider a computing resource allocation problem for maximizing the operator's profit. Given that an operator receives subscribers' payments and pays the infrastructure provider's costs, we model the problem using Mixed Integer Linear Programming (MILP). Then, we propose to solve the problem using Reinforcement Learning (RL). Our simulation results demonstrate the ability of the RL agent to increase the operator's profit while reducing the algorithmic complexity of the MILP solver. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1109/OAJPE.2020.3023916,Reinforcement Learning for Building Energy Optimization Through Controlling of Central HVAC System,"This paper presents a novel methodology to control HVAC system and minimize energy cost on the premise of satisfying power system constraints. A multi-agent architecture based on game theory and reinforcement learning is developed so as to reduce the cost and computational complexity of the microgrid. The multi-agent architecture comprising agents, state variables, action variables, reward function and cost game is formulated. The paper fills the gap between multi-agent HVAC systems control and power system optimization and planning. The results and analysis indicate that the proposed algorithm is beneficial to deal with the problem of “curse of dimensionality” for multi-agent microgrid HVAC system control and speed up learning of unknown power system conditions.",TOPIC
10.1109/OJCAS.2020.3043737,An Energy Efficient EdgeAI Autoencoder Accelerator for Reinforcement Learning,"In EdgeAI embedded devices that exploit reinforcement learning (RL), it is essential to reduce the number of actions taken by the agent in the real world and minimize the compute-intensive policies learning process. Convolutional autoencoders (AEs) has demonstrated great improvement for speeding up the policy learning time when attached to the RL agent, by compressing the high dimensional input data into a small latent representation for feeding the RL agent. Despite reducing the policy learning time, AE adds a significant computational and memory complexity to the model which contributes to the increase in the total computation and the model size. In this article, we propose a model for speeding up the policy learning process of RL agent with the use of AE neural networks, which engages binary and ternary precision to address the high complexity overhead without deteriorating the policy that an RL agent learns. Binary Neural Networks (BNNs) and Ternary Neural Networks (TNNs) compress weights into 1 and 2 bits representations, which result in significant compression of the model size and memory as well as simplifying multiply-accumulate (MAC) operations. We evaluate the performance of our model in three RL environments including DonkeyCar, Miniworld sidewalk, and Miniworld Object Pickup, which emulate various real-world applications with different levels of complexity. With proper hyperparameter optimization and architecture exploration, TNN models achieve near the same average reward, Peak Signal to Noise Ratio (PSNR) and Mean Squared Error (MSE) performance as the full-precision model while reducing the model size by 10x compared to full-precision and 3x compared to BNNs. However, in BNN models the average reward drops up to 12% - 25% compared to the full-precision even after increasing its model size by 4x. We designed and implemented a scalable hardware accelerator which is configurable in terms of the number of processing elements (PEs) and memory data width to achieve the best power, performance, and energy efficiency trade-off for EdgeAI embedded devices. The proposed hardware implemented on Artix-7 FPGA dissipates 250 μJ energy while meeting 30 frames per second (FPS) throughput requirements. The hardware is configurable to reach an efficiency of over 1 TOP/J on FPGA implementation. The proposed hardware accelerator is synthesized and placed-and-routed in 14 nm FinFET ASIC technology which brings down the power dissipation to 3.9 μJ and maximum throughput of 1,250 FPS. Compared to the state of the art TNN implementations on the same target platform, our hardware is 5x and 4.4x (2.2x if technology scaled) more energy efficient on FPGA and ASIC, respectively.",TOPIC
10.1109/OJCOMS.2021.3081996,Multi-UAV Path Planning for Wireless Data Harvesting With Deep Reinforcement Learning,"Harvesting data from distributed Internet of Things (IoT) devices with multiple autonomous unmanned aerial vehicles (UAVs) is a challenging problem requiring flexible path planning methods. We propose a multi-agent reinforcement learning (MARL) approach that, in contrast to previous work, can adapt to profound changes in the scenario parameters defining the data harvesting mission, such as the number of deployed UAVs, number, position and data amount of IoT devices, or the maximum flying time, without the need to perform expensive recomputations or relearn control policies. We formulate the path planning problem for a cooperative, non-communicating, and homogeneous team of UAVs tasked with maximizing collected data from distributed IoT sensor nodes subject to flying time and collision avoidance constraints. The path planning problem is translated into a decentralized partially observable Markov decision process (Dec-POMDP), which we solve through a deep reinforcement learning (DRL) approach, approximating the optimal UAV control policy without prior knowledge of the challenging wireless channel characteristics in dense urban environments. By exploiting a combination of centered global and local map representations of the environment that are fed into convolutional layers of the agents, we show that our proposed network architecture enables the agents to cooperate effectively by carefully dividing the data collection task among themselves, adapt to large complex environments and state spaces, and make movement decisions that balance data collection goals, flight-time efficiency, and navigation constraints. Finally, learning a control policy that generalizes over the scenario parameter space enables us to analyze the influence of individual parameters on collection performance and provide some intuition about system-level benefits.",TOPIC
10.1109/OJCOMS.2021.3092690,Learning to Fly: A Distributed Deep Reinforcement Learning Framework for Software-Defined UAV Network Control,"Control and performance optimization of wireless networks of Unmanned Aerial Vehicles (UAVs) require scalable approaches that go beyond architectures based on centralized network controllers. At the same time, the performance of model-based optimization approaches is often limited by the accuracy of the approximations and relaxations necessary to solve the UAV network control problem through convex optimization or similar techniques, and by the accuracy of the channel network models used. To address these challenges, this article introduces a new architectural framework to control and optimize UAV networks based on Deep Reinforcement Learning (DRL). Furthermore, it proposes a virtualized, `ready-to-fly' emulation environment to generate the extensive wireless data traces necessary to train DRL algorithms, which are notoriously hard to generate and collect on battery-powered UAV networks. The training environment integrates previously developed wireless protocol stacks for UAVs into the CORE/EMANE emulation tool. Our `ready-to-fly' virtual environment guarantees scalable collection of high-fidelity wireless traces that can be used to train DRL agents. The proposed DRL architecture enables distributed data-driven optimization (with up to 3.7 × throughput improvement and 0.2 × latency reduction in reported experiments), facilitates network reconfiguration, and provides a scalable solution for large UAV networks.",TOPIC
10.1109/OJCOMS.2022.3213213,IEEE Open Journal of the Communications Society,"Various applications for inter-machine communications are on the rise. Whether it is for autonomous driving vehicles or the Internet of everything, machines are more connected than ever to improve their performance in fulfilling a given task. While in traditional communications the goal has often been to reconstruct the underlying message, under the emerging task-oriented paradigm, the goal of communication is to enable the receiving end to make more informed decisions or more precise estimates/computations. Motivated by these recent developments, in this paper, we perform an indirect design of the communications in a multi-agent system (MAS) in which agents cooperate to maximize the averaged sum of discounted one-stage rewards of a collaborative task. Due to the bit-budgeted communications between the agents, each agent should efficiently represent its local observation and communicate an abstracted version of the observations to improve the collaborative task performance. We first show that this problem can be approximated as a form of data-quantization problem which we call task-oriented data compression (TODC). We then introduce the state-aggregation for information compression algorithm (SAIC) to solve the formulated TODC problem. It is shown that SAIC is able to achieve near-optimal performance in terms of the achieved sum of discounted rewards. The proposed algorithm is applied to a geometric consensus problem and its performance is compared with several benchmarks. Numerical experiments confirm the promise of this indirect design approach for task-oriented multi-agent communications. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/OJCOMS.2023.3265425,Distributed Intelligence in Wireless Networks,"The cloud-based solutions are becoming inefficient due to considerably large time delays, high power consumption, and security and privacy concerns caused by billions of connected wireless devices and typically zillions of bytes of data they produce at the network edge. A blend of edge computing and Artificial Intelligence (AI) techniques could optimally shift the resourceful computation servers closer to the network edge, which provides the support for advanced AI applications (e.g., video/audio surveillance and personal recommendation system) by enabling intelligent decision making on computing at the point of data generation as and when it is needed, and distributed Machine Learning (ML) with its potential to avoid the transmission of the large dataset and possible compromise of privacy that may exist in cloud-based centralized learning. Besides, the deployment of AI techniques to redesign end-to-end communication is attracting attention to improve communication performance. Therefore, the interaction of AI and wireless communications generates a new concept, named native AI wireless networks. In this paper, we conduct a comprehensive overview of recent advances in distributed intelligence in wireless networks under the umbrella of native AI wireless networks, with a focus on the design of distributed learning architectures for heterogeneous networks, on AI-enabled edge computing, on the communication-efficient technologies to support distributed learning, and on the AI-empowered end-to-end communications. We highlight the advantages of hybrid distributed learning architectures compared to state-of-the-art distributed learning techniques. We summarize the challenges of existing research contributions in distributed intelligence in wireless networks and identify potential future opportunities.",TOPIC
10.1109/OJCOMS.2023.3322383,Enhancing XR Application Performance in Multi-Connectivity Enabled mmWave Networks,"mmWave communications are paving the way for next-generation cellular networks due to their inherent ability to provide high data rates and mitigate interference. Coupled with this are the enormous potential and challenges posed by eXtended Reality (XR) applications which are becoming increasingly ubiquitous. In this paper, we leverage the unique characteristics of mmWave networks to re-think and re-design fundamental network architecture and functions in order to meet the strict requirements of deadline-driven XR applications. We propose a multi-tiered multi-connectivity architecture that allows users (UEs) to connect to multiple base stations (gNBs) simultaneously and switch rapidly between them in case of blockages. By replicating UE data at multiple gNBs close to the UE, we ensure that we satisfy strict Quality of Service (QoS) constraints even with unpredictable, dynamic blockages of the mmWave links. We show through extensive system-level simulations that our network architecture allows us to shield UEs from high handover delays and minimizes data plane interruptions in case of blockages. Moreover, we note that existing algorithms for network functions such as gNB selection and scheduling are not optimized for the multi-connectivity paradigm, nor do they specifically cater to strict deadline constraints or intermittent wireless links. We propose a Deep Reinforcement Learning framework that selects gNBs for data replication by explicitly optimizing to meet strict deadline constraints of XR traffic. Our Deep Learning agent analyzes global state information and predicts the best selection of gNBs to preemptively replicate data for future transmissions. Furthermore, we propose a scheduler based on maximal weight matching, dubbed  $\beta -$ MWM, which is specifically tailored to exploit multi-connectivity. We show that our Deep Learning based Data Replication Predictor and  $\beta -$ MWM scheduler perform better than existing, conventional algorithms and result in markedly better performance for XR applications with strict deadlines.",TOPIC
10.1109/OJCOMS.2024.3480987,Dynamic Pricing in Multi-Tenant MANO With Resource Sharing: A Stackelberg Game Approach,"Network slicing is used to support the stringent requirements of sixth generation (6G) services by dividing an infrastructure network into multiple logical networks that can enable service-oriented resource allocation. However, there are several orchestration issues when considering multiple infrastructure providers (InPs) and multiple tenants in a recursive architecture. There are also challenging issues in designing efficient auction mechanisms for such multi-domain and multi-tenant network slicing. To address these challenges, we consider multi-tenant management and orchestration as a multi-buyer, multi-seller scenario, and propose a novel two-stage auction mechanism that aims to increase the overall utility of all participants while mitigating the overall cost of the network. We formulate this two-stage auction mechanism as a multi-leader multi-follower (MLMF) Stackelberg game approach that converges to a Stackelberg equilibrium. In this game, there are multiple InPs that lease network, computing, and storage infrastructure resources to multiple Tier1 tenants in the first stage of the auction mechanism. Next, Tier1 tenants instantiate triple 6G slices as extremely reliable and low-latency communications (eURLLC), ultra-massive machine-type communications (umMTC), and further enhanced mobile broadband (FeMBB) slices, and lease smaller slices to Tier2 tenants through the second step of the auction mechanism. Tier2 tenants then serve different eURLLC, umMTC, and FeMBB users who have specific and mostly different requirements and constraints, while Tier2 tenants manage their own resources to maximize their utility. Due to the distributed nature of the proposed problem, we consider distributed reinforcement learning (DRL) as a solution. Simulation results show that our DRL-based solution increases the average profit of the network by 19% compared to the existing state-of-the-art benchmark.",TOPIC
10.1109/OJCOMS.2025.3539355,IEEE Open Journal of the Communications Society,"The rapid growth of low-Earth-orbit (LEO) satellites has enabled integrated space-air-ground networks to provide seamless connectivity to mobile users. However, these networks face challenges such as physical layer security risks from line-of-sight channels and the energy constraints of high-altitude platforms (HAPs), necessitating solutions for secure communication and energy efficiency. In this work, we address the challenges of energy efficiency and secure communication in space-air-ground networks, which are becoming critical with the increasing deployment of LEO satellites to support high-mobility users. We propose a novel downlink architecture where high-altitude platforms (HAPs) assist the LEO satellite in serving ground users. To tackle the demands of secrecy energy efficiency (SEE) in this dynamic and complex network, we formulate a non-convex optimization problem that jointly considers HAP trajectory, user-HAP association, and beamforming. The problem's non-convexity makes it computationally challenging to solve in polynomial time. To overcome these challenges, we introduce a generative artificial intelligence (GAI)-based deep reinforcement learning (DRL) framework, named Gen-DRL, which leverages generative adversarial networks to empower its agents. This framework dynamically predicts and adapts to changes in the space-air-ground network environment by optimizing key parameters such as channel states, HAP trajectories, user associations, and beamforming. Compared to conventional methods, the proposed Gen-DRL achieves significant improvements in SEE by effectively managing complex interdependencies among multiple agents and intelligently adapting to the network's goals and constraints. Extensive simulation results demonstrate that Gen-DRL consistently outperforms existing state-of-the-art frameworks in terms of secrecy energy efficiency, robustness to dynamic user locations, and adaptability to varying network parameters. This work provides new insights into the design of secure and energy-efficient space-air-ground networks, highlighting the potential of GAI-based DRL for future communication systems. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1109/OJCOMS.2025.3567585,Inter-AGV Scheduling and a Novel Multi-Agent Collaborative Protocol for Intra-AGV Resource Allocation in MEC-Enabled Multi-AGV Scenarios,"In modern novel collaborative multi-Automated Guided Vehicle (AGV) systems, vehicles are responsible for executing both mission-critical process-related operations and purely computational tasks, such as collision avoidance. This work investigates the problem of joint inter-AGV task placement and intra-AGV computational resource allocation in MEC-enabled multi-AGV environments. To address this challenge, a two-step strategy is proposed to maximize the number of scheduled and completed tasks across multiple AGVs while ensuring fair and efficient resource use within each AGV. The problem of inter-AGV task placement is solved by dynamically applying a catalog of deep reinforcement learning (DRL) models for varying numbers of AGVs. Training time for these models is reduced threefold by using datasets from existing optimization solvers. Transfer learning further reduces training times by up to 51%. Second, a multi-agent deep reinforcement learning (MADRL)-based collaborative protocol for dynamic intra- AGV resource allocation (MACP-DRA) is proposed, allowing AGVs to adjust computational resources dynamically. It incorporates a minimum guaranteed share strategy to ensure fair resource distribution while optimizing performance under dynamic workloads. Compared to existing MADRL approaches, MACP-DRA enhances conflict resolution efficiency while maintaining low computational cost. Evaluation results demonstrate that the proposed inter-AGV scheduling strategy approaches optimal performance while achieving a superior trade-off between decision time and task completion rates. Compared to a multi-agent DRL baseline, the proposed MACP-DRA models reduced resource conflicts by 54.9%, task processing delays by 35.7%, and resource underutilization by 9.93%, while maintaining minimal computational and energy consumption overhead.",TOPIC
10.1109/OJCOMS.2025.3578149,Improving Secrecy Capacity in the Face of Eavesdropping in SWIPT CIoT Networks With Actor-Critic DRL,"One of the key enablers of 6th-generation (6G) wireless networks is cognitive radio, offering optimized spectrum utilization, enhanced device intelligence, and improved security. This article investigates secure communication in an energy-harvesting (EH) cognitive Internet of Things (CIoT) network operating over cascaded fading channels. Here, a CIoT transmitter employs an intelligent strategy to allocate time for simultaneous wireless information and power transfer (SWIPT) and transmission power to maximize the secrecy rate. The CIoT receiver operates in full-duplex (FD) mode, receiving confidential messages while simultaneously emitting cooperative jamming signals to disrupt an eavesdropper. We formulate the challenging non-convex optimization problem to maximize secrecy capacity while ensuring spectrum sharing and energy constraints and model the CIoT agent’s decision-making as a model-free Markov decision process (MDP). We then propose a deep reinforcement learning (DRL) approach to determine the optimal strategy for secure transmission and resource allocation. Specifically, we derive the instantaneous secrecy rate and employ a deep deterministic policy gradient (DDPG) algorithm with a lightweight actor-critic architecture to efficiently address dynamic channel occupancy, EH opportunities, and fading conditions. The proposed DDPG algorithm allows the CIoT agent to adapt to dynamic environments, enhance transmission security, and extend network lifetime without prior knowledge. Extensive simulations confirm its convergence and effectiveness in improving secrecy capacity, throughput, and energy efficiency. Moreover, the results attest to its superior performance compared to existing benchmarks.",TOPIC
10.1109/OJCOMS.2025.3580886,Adaptive Throughput Optimization in Multi-Rate IEEE 802.11 WLANs via Multi-Agent Deep Reinforcement Learning,"As wireless networks become increasingly important in modern society, their application scenarios are becoming more diverse and complex. However, the heterogeneity of nodes and transmission conditions presents significant challenges to existing wireless strategies and traditional centralized AI methods, making it difficult to meet user demands for network throughput. This paper proposes a distributed architecture based on multi-agent reinforcement learning combined with deep reinforcement learning. Agents are deployed on individual transmission nodes, enabling distributed observation and autonomous decision-making, while the access point provides feedback derived from the network performance resulting from their individual decisions. By experimentally comparing centralized and distributed architectures in multi-rate environments, this paper analyzes trade-offs in scalability and network performance. Additional experiments conducted under dynamic network conditions with node mobility and static scenarios involving a larger number of coexisting nodes further validate the system’s robustness and adaptability. The analysis of training loss trends shows that although the distributed architecture incurs a higher training cost, it achieves improved throughput. In particular, the distributed method outperforms the centralized method by nearly 30% when the number of nodes is relatively small, and maintains a 5–10% performance advantage as the network continues to scale.",TOPIC
10.1109/OJCOMS.2025.3608700,Proactive AI-and-RAN Workload Orchestration in O-RAN Architectures for 6G Networks,"The vision of AI-RAN convergence, as advocated by the AI-RAN Alliance, aims to unlock a unified 6G platform capable of seamlessly supporting AI and RAN workloads over shared infrastructure. However, the architectural framework and intelligent resource orchestration strategies necessary to realize this vision remain largely unexplored. In this paper, we propose a Converged AI-and-ORAN Architectural (CAORA) framework based on O-RAN specifications, enabling the dynamic coexistence of real-time RAN and computationally intensive AI workloads. We design custom xApps within the Near-Real-Time RAN Intelligent Controller (NRT-RIC) to monitor RAN KPIs and expose radio analytics to an End-to-End (E2E) orchestrator via the recently introduced Y1 interface. The orchestrator incorporates workload forecasting and anomaly detection modules, augmenting a Soft Actor-Critic (SAC) reinforcement learning agent that proactively manages resource allocation, including Multi-Instance GPU (MIG) partitioning. Using real-world 5G traffic traces from Barcelona, our trace-driven simulations demonstrate that CAORA achieves near 99% fulfillment of RAN demands, supports dynamic AI workloads, and maximizes infrastructure utilization even under highly dynamic conditions. Our results reveal that predictive orchestration significantly improves system adaptability, resource efficiency, and service continuity, offering a viable blueprint for future AI-and-RAN converged 6G systems.",TOPIC
10.1109/OJCOMS.2025.3614745,IEEE Open Journal of the Communications Society,"Service placement in current and next-generation mobile networks in emergency management is increasingly challenging due to resource-constrained edge clusters, where low latency and efficient workload distribution are critical. Traditional service placement strategies that rely solely on resource availability are no longer adequate. Modern deployments must address complex constraints, including end-to-end latency, system load distribution, and dynamic resource availability. In this paper, we propose a comprehensive architecture for service orchestration across multi-cluster Cloud-Edge environments, where independent clusters coordinate placement decisions through a federation layer. Our system is built on the Karmada federation control plane, which unifies heterogeneous cloud and edge clusters under a common framework to support optimal service placement. The core contribution of this work is a service placement solution integrated into a multi-cluster service management platform, supported by a decision-making module for service prioritization and optimal allocation. The decision process has two main components: (1) a multi-objective optimization model that balances CPU utilization and latency through a weighting mechanism, and (2) an Integer Linear Programming (ILP)-based model that prioritizes services and selectively discards requests when edge resources are constrained or system requirements cannot be met. A metric aggregator module is deployed via agents in each cluster and continuously monitors resource status to support placement decisions. Simulation results confirm that our approach ensures efficient resource usage and low latency, while maintaining low execution time even for large problem sizes. Additionally, we experimentally evaluate the proposed solution using our federated multi-cloud 5G testbed. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1109/OJCOMS.2025.3615970,Hydra-RAN: Multi-Functional Communications and Sensing Networks Applications: Intelligent Parking Systems,"Smart cities and intelligent transportation systems (ITS) confront substantial urban mobility challenges, with parking management emerging as a particularly complex subsystem. The operational efficacy of these systems is fundamentally constrained by dynamic stochastic variables, including spatiotemporal resource distribution, demand volatility, multimodal traffic interdependencies, and competing urban development priorities. These factors generate nonlinear system behaviors that manifest as chronic inefficiencies in parking resource allocation, ultimately degrading overall urban mobility performance. The Hydra radio access network (Hydra-RAN) is envisioned as a next-generation multifunctional (NG-MF) platform. A comprehensive solution designed to consolidate existing networks and technologies into a cohesive, integrated framework. This advanced architecture promotes a synergistic environment, enabling the simultaneous operation of multiple networks and applications. While Hydra-RAN supports a broad spectrum of applications, this study focuses specifically on its perceptive parking management - an innovative solution enabled by the network’s distinctive integration of multi-sparse input processing and multi-task learning (SMTL) paradigms. This approach provides intelligent real-time classification and dynamic allocation of available parking spaces through edge network nodes. The system’s advanced capabilities stem from three key technological integrations: (1) continuous processing of real-time urban data streams, (2) a hierarchical framework for computational task distribution across three integrated tiers: edge computing (EC), fog computing (FC), and cloud computing (CC), and (3) semantic communication protocols, collectively representing a paradigm shift in intelligent parking management. Our proposed solution demonstrated a 50% reduction in communication overhead, 75% improved real-time decision-making accuracy, and enhanced scalability in modern urban environments. These results have significant implications, e.g., for reducing operational costs, improving resource utilization, and supporting sustainable urban development.",TOPIC
10.1109/OJCOMS.2025.3631341,Twin Delayed Deep Deterministic Policy Gradient for Intelligent Optimization in STAR-RIS-Assisted Wireless Networks,"Reconfigurable intelligent surfaces (RIS) have emerged as a key technology to enhance the performance of next-generation wireless networks by intelligently reconfiguring the propagation environment. In particular, simultaneously transmitting and reflecting RIS (STAR-RIS) extend this paradigm by enabling full-space coverage through concurrent reflection and transmission. This paper investigates a downlink multiple-input single-output (MISO) system assisted by a STAR-RIS and addresses the joint optimization of base station beamforming and RIS coefficients. To tackle the inherent non-convexity of this problem, we propose a reinforcement learning framework based on the Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm. The proposed approach formulates the design task as a continuous control problem, allowing the agent to directly learn interference-aware policies that adapt to dynamic channel conditions. Extensive simulations validate the effectiveness of the proposed framework. The results demonstrate that the TD3-based policy achieves stable convergence and significantly improves the achievable sum rate compared to the baseline Deep Deterministic Policy Gradient (DDPG) method and the passive RIS benchmark. Performance scaling with the number of RIS elements and transmit power is clearly observed, confirming the scalability of the approach. In addition, hyperparameter sensitivity analysis highlights the importance of learning rate and decay parameter tuning for robust training. Cumulative distribution function (CDF) comparisons further show that the proposed framework enhances both average throughput and reliability across different channel realizations. The findings establish deep reinforcement learning, and TD3 in particular, as a promising tool for real-time optimization in STAR-RIS-assisted wireless systems. The proposed framework provides a flexible and scalable solution for intelligent resource allocation, paving the way for more reliable and efficient 6G communication networks.",TOPIC
10.1109/OJCS.2020.3000330,Network Resource Allocation Strategy Based on Deep Reinforcement Learning,"The traditional Internet has encountered a bottleneck in allocating network resources for emerging technology needs. Network virtualization (NV) technology as a future network architecture, the virtual network embedding (VNE) algorithm it supports shows great potential in solving resource allocation problems. Combined with the efficient machine learning (ML) algorithm, a neural network model close to the substrate network environment is constructed to train the reinforcement learning agent. This paper proposes a two-stage VNE algorithm based on deep reinforcement learning (DRL) (TS-DRL-VNE) for the problem that the mapping result of existing heuristic algorithm is easy to converge to the local optimal solution. For the problem that the existing VNE algorithm based on ML often ignores the importance of substrate network representation and training mode, a DRL VNE algorithm based on full attribute matrix (FAM-DRL-VNE) is proposed. In view of the problem that the existing VNE algorithm often ignores the underlying resource changes between virtual network requests, a DRL VNE algorithm based on matrix perturbation theory (MPT-DRL-VNE) is proposed. Experimental results show that the above algorithm is superior to other algorithms.",TOPIC
10.1109/OJCS.2024.3453924,Utilizing Deep improved ResNet50 for Brain Tumor Classification Based MRI,"A robust approach for brain tumor classification is being developed using deep convolutional neural networks (CNNs). This study leverages an open-source dataset derived from the MRI Brats2015 brain tumor dataset. Preprocessing included intensity normalization, contrast enhancement, and downsizing. Data augmentation techniques were also applied, encompassing rotations and flipping. The core of our proposed approach lies in the utilization of a modified ResNet-50 architecture for feature extraction. This model integrates transfer learning by replacing the final layer with a spatial pyramid pooling layer, enabling it to leverage pre-trained parameters from ImageNet. Transfer learning from ImageNet aids in countering overfitting. Our model's performance was evaluated with various hyperparameters, including existing methods in terms of accuracy, precision, recall, F1-score, sensitivity, and specificity. This study showcases the potential of deep learning, transfer learning, and spatial pyramid pooling in MRI-based brain tumor classification, providing an effective tool for medical image analysis. Our methodology employs a modified ResNet-50 architecture with transfer learning, integrating a spatial pyramid pooling layer for feature extraction. Systematic evaluation showcases the model's superiority over existing methods, demonstrating remarkable results in accuracy (0.9902), precision (0.9837), recall (0.9915), F1-score (0.9891), sensitivity, and specificity. The comparative analysis against prominent CNN architectures reaffirms its outstanding performance. Our model not only mitigates overfitting challenges but also offers a promising tool for medical image analysis, underlining the combined efficacy of spatial pyramid pooling and transfer learning. The study's optimization parameters, including 25 epochs, a learning rate of 1e-4, and a balanced batch size, contribute to its robustness and real-world applicability, furthering advancements in efficient brain tumor classification within MRI data.",TOPIC
10.1109/OJCSYS.2023.3316090,Constrained Environment Optimization for Prioritized Multi-Agent Navigation,"Traditional approaches for multi-agent navigation consider the environment as a fixed constraint, despite the obvious influence of spatial constraints on agents' performance. Yet hand-designing conducive environments is inefficient and potentially expensive. The goal of this article is to consider the obstacle layout of the environment as a decision variable in a system-level optimization problem. In other words, we aim to find an automated solution that optimizes the obstacle layout to improve the performance of multi-agent navigation, under a variety of realistic constraints. Towards this end, we propose novel problems of unprioritized and prioritized environment optimization, where the former considers agents unbiasedly and the latter incorporates agent priorities into optimization. We show, through formal proofs, under which conditions the environment can change to guarantee completeness (i.e., all agents reach goals), and analyze the role of agent priorities in the environment optimization. We proceed to impose constraints on the environment optimization that correspond to real-world restrictions on obstacle changes, and formulate it mathematically as a constrained stochastic optimization problem. Since the relationship between agents, environment and performance is challenging to model, we leverage reinforcement learning to develop a model-free solution and a primal-dual mechanism to handle constraints. Distinct information processing architectures are integrated for various implementation scenarios, including online/offline optimization and discrete/continuous environment. Numerical results corroborate the theory and demonstrate the validity and adaptability of our approach.",TOPIC
10.1109/OJIES.2024.3435956,Dual Modality Reverse Reranking (DM-RR) Based Image Retrieval Framework,"Retrieval of a product with desired modifications from a vast inventory of online industrial platforms is frequently encountered in our daily life. This study presents a specialized framework to retrieve user's queried product with its desired changes incorporated. To facilitate interaction between the end-user and agent in such scenarios, a multimodal content-based image retrieval system is essential. The system extracts textual and visual attributes, combining them through inductive learning to a unified representation. It is based on an in-depth understanding of visual characteristics that are modified by textual semantics. Lastly, a novel reverse reranking (RR) algorithm arranges the joint representation of dual modality queries and their corresponding target images for efficient retrieval. The proposed framework is novel compared to earlier methodologies. First, it achieves successful fusion of two different modalities. Second, it introduces a RR algorithm in the inference stage for efficient retrieval. The proposed framework's enhanced performance has been assessed using the Fashion-200 K and MIT-States real-world benchmark datasets. The proposed system can be used in real-world applications subject to its practical implications, such as generalization to diverse domains, availability of domain specific data, nature of the data and queries, and availability of computational resources.",TOPIC
10.1109/OJIES.2025.3623250,Methodology for Distributed Optimization of Flexible Energy Resources Through Semi-Automated Model Transformation and Deployment,"Effectively utilizing flexible energy resources requires optimizing their operation over time to balance dynamic demand and fluctuating supply from volatile renewable sources. Traditionally, this has been achieved through centralized optimization models, which suffer from scalability limitations, single points of failure, and limited flexibility when applied to decentralized and dynamically changing environments. Distributed models offer a promising alternative, providing enhanced flexibility, robustness, and computational efficiency by enabling parallel processing and reducing coordination delays. Thus, this work presents a methodology for the semi-automated transformation of centralized optimization models into distributed architectures, leveraging containerized multiagent systems to achieve scalable and efficient optimization across multiple computing units. A case study involving 120 electrolyzers distributed across up to five optimization agents, including both homogeneous and heterogeneous configurations, demonstrates that the distributed approach accelerates computation time by a factor up to 27.42 compared to a centralized model while accepting a solution quality deviation of only 2.2%. The optimization integrates site-wide and real-time optimization, ensuring adaptability to fluctuating renewable energy availability and improving system resilience. This combination enables long-term strategic planning while allowing real-time adjustments to maximize renewable energy utilization. The findings highlight the benefits of distributed optimization in modular energy systems and confirm that containerized multiagent architectures enhance scalability and computational efficiency, making the approach well-suited for real-world applications in decentralized and modular energy networks.",TOPIC
10.1109/OJITS.2023.3331449,A Survey on the Use of Container Technologies in Autonomous Driving and the Case of BeIntelli,"The application of containerization technology has seen a significant increase in popularity in recent years, both in the business and scientific sectors. In particular, the ability to create portable applications that can be deployed on different machines has become a valuable asset. Autonomous driving has embraced this technology, as it offers a wide range of potential applications, including the operation of autonomous vehicles and the digitization of infrastructure for the development of Cooperative, Connected, and Automated Mobility (CCAM) services. This paper provides a comprehensive analysis of containerization in autonomous driving, emphasizing its application, utility, benefits, and limitations.",TOPIC
10.1109/OJITS.2024.3376583,Model-Based Graph Reinforcement Learning for Inductive Traffic Signal Control,"We introduce MuJAM, an adaptive traffic signal control method which leverages model-based reinforcement learning to 1) extend recent generalization efforts (to road network architectures and traffic distributions) further by allowing a generalization to the controllers’ constraints (cyclic and acyclic policies), 2) improve performance and data efficiency over related model-free approaches, and 3) enable explicit coordination at scale for the first time. In a zero-shot transfer setting involving both road networks and traffic settings never experienced during training, and in a larger transfer experiment involving the control of 3,971 traffic signal controllers in Manhattan, we show that MuJAM, using both cyclic and acyclic constraints, outperforms domain-specific baselines as well as a recent transferable approach.",TOPIC
10.1109/OJPEL.2024.3496865,A Reinforcement-Learning Based Approach for Designing High-Voltage SiC MOSFET Guard Rings,"For high-power silicon carbide (SiC) devices, breakdown voltage analysis is an important parameter, especially for guard ring design. This work explores the implementation of machine learning on SiC guard ring parameters such as ion implanted dose and energy. In this work, the reinforcement learning method has been successfully implemented on the 1.7 kV SiC guard ring device TCAD simulated data for the prediction of parameters. Our work has predicted the parameters successfully for the 2.5 kV guard ring design. For training, proximal policy optimization (PPO) and advantage actor-critic (A2C) RL agents were deployed. The network architecture was kept at “auto” with 3 hidden layers of 128 neurons in each layer. Our method is practically feasible and easily implemented as compared to other works, and has been shown in this paper. By using the limited design parameters of the 1.7 kV guard ring device, the trained agent has successfully predicted the design parameters for the 2.5 kV guard ring device, which has been confirmed using TCAD simulations. This work is more accurate, practical, and result-oriented, and we believe that this can significantly minimize the computational cost as compared to the standalone TCAD simulations. Also, this implementation of ML on TCAD data can substantially accelerate the design exploration for the power devices and ultimately lower product-to-market time.",TOPIC
10.1109/OJSP.2021.3140000,Dif-MAML: Decentralized Multi-Agent Meta-Learning,"The objective of meta-learning is to exploit knowledge obtained from observed tasks to improve adaptation to unseen tasks. Meta-learners are able to generalize better when they are trained with a larger number of observed tasks and with a larger amount of data per task. Given the amount of resources that are needed, it is generally difficult to expect the tasks, their respective data, and the necessary computational capacity to be available at a single central location. It is more natural to encounter situations where these resources are spread across several agents connected by some graph topology. The formalism of meta-learning is actually well-suited for this decentralized setting, where the learner benefits from information and computational power spread across the agents. Motivated by this observation, we propose a cooperative fully-decentralized multi-agent meta-learning algorithm, referred to as Diffusion-based MAML or Dif-MAML. Decentralized optimization algorithms are superior to centralized implementations in terms of scalability, robustness, avoidance of communication bottlenecks, and privacy guarantees. The work provides a detailed theoretical analysis to show that the proposed strategy allows a collection of agents to attain agreement at a linear rate and to converge to a stationary point of the aggregate MAML objective even in non-convex environments. Simulation results illustrate the theoretical findings and the superior performance relative to the traditional non-cooperative setting.",TOPIC
10.1109/OJVT.2020.3018146,"Intelligent Energy Management Systems for Electrified Vehicles: Current Status, Challenges, and Emerging Trends","Powertrain electrification has heightened the need for an energy management strategy, which has been a continuing concern in the development of electrified vehicles. The energy management control unit manages power flow between different energy sources in an electrified powertrain that directly affects vehicle performance. Developing an energy management strategy that is compatible with different real-world driving scenarios has opened a significant field of study for researchers. Recent advances and progress in intelligent control approaches have facilitated developing an intelligent energy management strategy. However, there are inadequate numbers of studies on the latest energy management strategies. The presented review paper aims to provide the requirements of intelligent energy management strategies as well as a new categorization of them into principle-based, data-driven, and composite methods. Besides, enabling technologies for implementing an energy management system with a comparison of different controller chips are described to give readers an experimental view. Future trends and existing challenges are presented, which generate fresh insight into energy management strategies.",TOPIC
10.1109/OJVT.2025.3574385,MMTraP: Multi-Sensor Multi-Agent Trajectory Prediction in BEV,"Accurate detection and trajectory prediction of moving vehicles are essential for motion planning in autonomous driving systems. While traffic regulations provide clear boundaries, real-world scenarios remain unpredictable due to the complex interactions between vehicles. This challenge has driven significant interest in learning-based approaches for trajectory prediction. We present MMTraP: Multi-Sensor and Multi-Agent Trajectory Prediction in BEV. This method integrates camera, LiDAR, and radar data to create detailed Bird's-Eye-View representations of driving scenes. Our approach employs a hierarchical vector transformer architecture that first detects and classifies vehicle motion patterns before predicting future trajectories through spatiotemporal relationship modeling. This work specifically focuses on vehicle interactions and environmental constraints. Despite its significance, multi-agent trajectory prediction and moving object segmentation are still underexplored in the literature, especially in real-time applications. Our method leverages multisensor fusion to obtain precise BEV representations and predict vehicle trajectories. Our multi-sensor fusion approach achieves the highest vehicle Intersection over Union (IoU) of 63.23% and an overall mean IoU (mIoU) of 64.63%, demonstrating its effectiveness in utilizing all available sensor modalities. Additionally, we demonstrate vehicle segmentation and trajectory prediction capabilities across various lighting and weather conditions. The proposed approach has been rigorously evaluated using the nuScenes dataset. Results show that our method improves the accuracy of trajectory predictions and outperforms state-of-the-art techniques, particularly in challenging environments such as congested urban areas. For instance, in complex traffic scenarios, our approach achieves a relative improvement of 5% in trajectory prediction accuracy compared to baseline methods. This work advances vehicle-focused prediction systems by integrating multi-sensor BEV representation and interaction-aware transformers. Our approach shows promise in enhancing the reliability and accuracy of trajectory predictions for autonomous driving applications, potentially improving overall safety and efficiency in diverse driving environments.",TOPIC
10.1109/PESGM40551.2019.8973476,IEEE Power and Energy Society General Meeting,"Buildings consume 74% of the total electricity produced in the United States. A significant portion of the building electric load includes heating ventilation and air-conditioning (HVAC) systems and water heating (WH) systems. Enabling flexibility in the operations can improve overall electric grid efficiency. This paper describes a multi-agent system for supporting integration, learning, optimization, and control of HVAC and WH in supporting a future smart grid. The architecture supports a transactive-based negotiation strategy between homeowners and a microgrid controller to adjust consumption behavior and reduce electricity costs. The framework is deployed in a neighborhood and preliminary testing is underway. The agent architecture design is discussed along with the preliminary optimization results from the demonstration site. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/PESGM41954.2020.9281614,IEEE Power and Energy Society General Meeting,"The paradigm shift in energy generation towards microgrid-based architectures is changing the landscape of the energy control structure heavily in distribution systems. More specifically, distributed generation is deployed in the network demanding decentralised control mechanisms to ensure reliable power system operations. In this work, a Multi-Agent Reinforcement Learning approach is proposed to deliver an agent-based solution to implement load frequency control without the need of a centralised authority. Multi-Agent Deep Deterministic Policy Gradient is used to approximate the frequency control at the primary and the secondary levels. Each generation unit is represented as an agent that is modelled by a Recurrent Neural Network. Agents learn the optimal way of acting and interacting with the environment to maximise their long term performance and to balance generation and load, thus restoring frequency. In this paper we prove using three test systems, with two, four and eight generators, that our Multi-Agent Reinforcement Learning approach can efficiently be used to perform frequency control in a decentralised way. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/PIMRC48278.2020.9217135,,"Network slicing is included as a key feature of the 5G architecture in order to simultaneously support diverse service types with heterogeneous requirements. The deployment of network slicing in the Radio Access Network (RAN) needs mechanisms that allow the distribution of the available capacity in the system in an efficient manner while satisfying the requirements of the different services. In this paper, a capacity sharing function is proposed, which is approached as a multi-agent reinforcement learning based on the Deep Reinforcement Learning (DRL) algorithm Deep Q-Network (DQN). The proposed algorithm provides the capacity to be assigned to each RAN slice. Performance assessment reveals the promising behaviour of the proposed solution. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/PIMRC50174.2021.9569387,,"Safe interaction with the environment is one of the most challenging aspects of Reinforcement Learning (RL) when applied to real-world problems. This is particularly important when unsafe actions have a high or irreversible negative impact on the environment. In the context of network management operations, Remote Electrical Tilt (RET) optimisation is a safety-critical application in which exploratory modifications of antenna tilt angles of base stations can cause significant performance degradation in the network. In this paper, we propose a modular Safe Reinforcement Learning (SRL) architecture which is then used to address the RET optimisation in cellular networks. In this approach, a safety shield continuously benchmarks the performance of RL agents against safe baselines, and determines safe antenna tilt updates to be performed on the network. Our results demonstrate improved performance of the SRL agent over the baseline while ensuring the safety of the performed actions. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/PIMRC50174.2021.9569681,,"We study the problem of user association, namely finding the optimal assignment of user equipment to base stations to achieve a targeted network performance. In this paper, we focus on the knowledge transferability of association policies. Indeed, traditional non-trivial user association schemes are often scenario-specific or deployment-specific and require a policy re-design or re-learning when the number or the position of the users change. In contrast, transferability allows to apply a single user association policy, devised for a specific scenario, to other distinct user deployments, without needing a substantial re-learning or re-design phase and considerably reducing its computational and management complexity. To achieve transferability, we first cast user association as a multi-agent reinforcement learning problem. Then, based on a neural attention mechanism that we specifically conceived for this context, we propose a novel distributed policy network architecture, which is transferable among users with zero-shot generalization capability i.e., without requiring additional training. Numerical results show the effectiveness of our solution in terms of overall network communication rate, outperforming centralized benchmarks even when the number of users doubles with respect to the initial training point. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/QCE57702.2023.10180,Quantum Deep Q-Learning with Distributed Prioritized Experience Replay,"This paper introduces the QDQN-DPER framework to enhance the efficiency of quantum reinforcement learning (QRL) in solving sequential decision tasks. The framework incorporates prioritized experience replay, asynchronous training and novel matrix loss into the training algorithm to reduce the high sampling complexities. Numerical simulations demonstrate that QDQN-DPER outperforms the baseline distributed quantum Q-learning with the same model architecture. The proposed framework holds potential for more complex tasks while maintaining training efficiency.",TOPIC
10.1109/QCE60285.2024.00178,Differentiable Quantum Architecture Search in Asynchronous Quantum Reinforcement Learning,"The emergence of quantum reinforcement learning (QRL) is propelled by advancements in quantum computing (QC) and machine learning (ML), particularly through quantum neural networks (QNN) built on variational quantum circuits (VQC). These advancements have proven successful in addressing sequential decision-making tasks. However, constructing effective QRL models demands significant expertise due to challenges in designing quantum circuit architectures, including data encoding and parameterized circuits, which profoundly influence model performance. In this paper, we propose addressing this challenge with differentiable quantum architecture search (DiffQAS), enabling trainable circuit parameters and structure weights using gradient-based optimization. Furthermore, we enhance training efficiency through asynchronous reinforcement learning (RL) methods facilitating parallel training. Through numerical simulations, we demonstrate that our proposed DiffQAS-QRL approach achieves performance comparable to manually-crafted circuit architectures across considered environments, showcasing stability across diverse scenarios. This methodology offers a pathway for designing QRL models without extensive quantum knowledge, ensuring robust performance and fostering broader application of QRL.",TOPIC
10.1109/QCE60285.2024.00185,Over the Quantum Rainbow: Explaining Hybrid Quantum Reinforcement Learning,"In the realm of artificial intelligence, deep rein-forcement learning (RL) agents struggle with generalizability and require substantial computational resources, unlike humans who easily adapt and generalize across tasks. To address these challenges, we introduce Quantum Rainbow, a hybrid algorithm that leverages the neural mechanisms of human decision-making and the efficiency of quantum computing. Quantum Rainbow combines variational quantum circuits with the Rainbow Deep Q-Network (DQN) model to create a novel approach in rein-forcement learning that integrates quantum principles into deep learning paradigms. We evaluate our model using behavioral experiments through the Iowa Gambling Task and 4-Armed Bandit Task. Our investigations reveal a significant relationship between the architecture of quantum circuits and the performance of quantum RL agents. Specifically, using causal discovery methods, we demonstrate the critical role of quantum entanglement in enhancing model performance. These findings not only show promising results but also pave the way for future explorations into optimizing quantum circuit architectures for reinforcement learning applications. This study underscores the potential of quantum-enhanced algorithms to achieve “quantum advantage” by addressing fundamental limitations in conventional deep RL methods.",TOPIC
10.1109/RED-UAS.2015.7441002,,"In this article a distributed model predictive control scheme, for the cooperative motion control of Unmanned Aerial Vehicles (UAVs) is being presented. The UAVs are modeled by a 6-DOF nonlinear kinematic model. Two different control architectures: a centralized and a distributed MPC, are studied and evaluated in simulation experiments. In the centralized approach, one central MPC controller is responsible for the movement coordination of all the UAVs, while in the distributed approach each aerial vehicle plans only for its own actions, while the objective function is coupled with the behavior of the rest of the team members and the constraints are decoupled. In this approach, each agent only shares the future position of itself with the other agents to avoid collisions. For reducing the computation time and complexity, only one step ahead prediction in the corresponding MPC schemes have been considered without a loss of generality. Finally, the efficiency of the overall suggested decentralized MPC scheme, as well as it comparison with the centralized approach, is being evaluated through the utilization of multiple simulation scenarios. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1109/REV.2014.6784272,,"Search and rescue (SAR) teams often face several complex and dangerous tasks, which could be aided by unmanned robotic vehicles (UV). UV agents can potentially be used to decrease the risk in the loss of lives both of the rescuers and victims and aid in the search and transportation of survivors and in the removal of debris in a catastrophe scenario. Depending on the nature of a catastrophe and its geographical location, there are potentially three types of UVs that can be deployed: aerial, surface and ground. Due to the control and manipulation particularities each type of UV contemplates, their operators need prior training and certification. To train and certify the operators a tool (serious game) is under development. In this paper we will make an overview about our approach in its development. This game uses a typical client-server architecture where all client agents (virtual UVs and operator client interfaces) share the same immersive virtual environment which is generated through the merging of GIS data and a semantic model extracted from 3D laser data. There will be several types of scenarios suitable to several types of catastrophe situations. Each of these scenarios has its own mission plan for the trainees to follow. The game will also provide an interface for mission planning so that each mission plan will be carefully designed to accurately correspond to a matrix of skills. This matrix lists a set of common skills in various different UV operational case studies which will allow the certification of operators. © 2014 IEEE. © 2014 Elsevier B.V., All rights reserved.",TOPIC
10.1109/RO-MAN53752.2022.9900661,,"Handwriting learning is a long and complex process that takes about ten years to be fully mastered. Nearly one-third of all children aged 4-12 experiences handwriting difficulties and, sadly, most of them are left to fight them on their own, due to the scarcity of tools for the detection and remediation of such difficulties. Building on state-of-the-art digital solutions for automated handwriting assessment and the training of specific handwriting-related skills, in this article we discuss requirements, rationale, and architecture of a system for handwriting training, which relies on a social robot as a mediator agent, offering personalized training and suggestions. The system is envisioned to operate autonomously and to support long-term interactions via personalization. Preliminary validation of the system in an experiment with 31 children showed its potential not only for autonomously guiding handwriting training sessions, but also for its inclusion in the teachers' practice. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ROBOT.2006.1642066,Proceedings - IEEE International Conference on Robotics and Automation,"A distributed feedback control architecture that guarantees collision avoidance and destination convergence for multiple sphere world holonomic agents is presented. The well established tool of Decentralized Navigation Functions is redefined to cope with the communication restrictions of the system. Each agent plans its actions without knowing the destinations of the others and the positions of those agents lying outside its sensing neighborhood. The stability properties of the closed loop system are checked via Lyapunov stability techniques for hybrid systems. The collision avoidance and goal convergence properties are verified through simulations. The key advantage of the proposed algorithm with respect to the previous ones is the significant decrease of computational load and its applicability to large scale groups. © 2006 IEEE. © 2008 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ROBOT.2006.1642312,Proceedings - IEEE International Conference on Robotics and Automation,"The dangerous and time sensitive nature of a disaster area makes it an ideal application for robotic exploration. Our long term goal is to enable humans, software agents, and autonomous robots to work together to save lives. Existing work in coordination for search and rescue does not address the variety of constraints that apply to the problem. This paper provides an expressive language for specifying system constraints. We also describe a coordination architecture capable of quickly finding an optimal or near optimal solution to the combined problems of task allocation, scheduling, and path planning subject to system constraints. We address a perceived lack of benchmarks for this research area by establishing a repository open to the research community which includes a set of benchmarks we designed to illustrate some of the complexities of the problem space. Finally, we evaluate various algorithms on these benchmarks. © 2006 IEEE. © 2011 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ROMAN.2011.6005258,,"In daily human interactions spatial reasoning occupies an important place. With this ability we can build relations between objects and people, and we can predict the capabilities and the knowledge of the people around us. An interactive robot is also expected to have these abilities in order to establish an efficient and natural interaction. In this paper we present a situation assessment reasoner, based on spatial reasoning and perspective taking, which generates on-line relations between objects and agents in the environment. Being fully integrated to a complete architecture, this reasoner sends the generated symbolic knowledge to a fact data base which is built on the basis on an ontology and which is accessible to the entire system. This work is also part of a broader effort to develop a complete decisional framework for human-robot interactive task achievement. © 2011 IEEE. © 2011 Elsevier B.V., All rights reserved.",TOPIC
10.1109/SmartGridComm.2016.7778807,,"Studies reveal that an integrated system of smart grid and cloud computing ecosystems can better attain the energy efficiency objectives, considering all the aspects. To facilitate the integration, in this paper, we introduce an agent-oriented economic middleware architecture (ARTA) to exchange pervasive energy and computing resources in different layers of the service provisioning platform, from the edge layer of micro-grid and P2P-cloud to the mass production layer of the giant power plants and data centers. ARTA follows a semi-decentralized economic model by operating through partial system view in the edge-layer negotiations and considers system dynamics and uncertainties in the agents decisions. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1109/SMC.2013.134,,"Given the complexity of modelling actors and interactions of the deregulated electric energy market, the Multi-Agent System approach can be used for both simulation and applications of critical aspects in the Smart Grid. In particular, balancing demand and offer and handling negotiation among peers: now, even a domestic environment that features photovoltaic and/or wind turbines modules can decide to enter the deregulated market as a small-scale seller, thus making the requirement of having such an architecture to be autonomous by deploying Self-* properties such as Self-Organization, Self-Repairing, Self-Adaptation. To be more specific about the presented case study, we propose a model in which small-scale seller agents dynamically decide from to time to time, either to address the market as lone operators or by aggregating into Virtual Power Plants. This iterated decisional process depends on highly variable market related factors, thus the goal to design a net of agents able to autonomously react to this dynamic environment. © 2013 IEEE. © 2014 Elsevier B.V., All rights reserved.",TOPIC
10.1109/SMC.2016.7844956,,"The agent computing paradigm is rapidly emerging as one of the powerful technology to deal with the uncertainty in dynamic environment. Recently, traditional learning classifier system are challenged by changes in the context. In this paper, an anticipatory agent based on the Anticipatory Learning Classifier System (ACS) for learning in changing environments is presented. This research aims to develop an agent learning architecture using anticipatory system that will enable intelligent agent to be able to detect environmental changes, adapt functionality at run-time to achieve goal. For achieving the intended target, an extension to the ACS framework called 'Greedy Covering' to the ACS framework have been proposed. The novelty of the approach is in determining the changes in the environment and to generate optimal rules to adapt and reestablish the optimal policy to reach the goal state. The proposed algorithm is evaluated on several synthetic maze design and simulate a variety of changing environments. Experiment results indicate that up to 65% changes in an environment the ACS with the greedy covering can reestablish the optimal performance without increasing the number of classifiers. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1109/SMC.2019.8914294,"Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics","In many joint-action scenarios, humans and robots have to coordinate their movements to accomplish a given shared task. Examples include lifting an object together, sawing a wood log, transferring objects from a point to another. While dyadic coordination between a human and a robot has been studied in previous investigations, the multi-agent scenario in which a robot has to be integrated into a human group still remains a less explored field of research. In this paper we discuss how to synthesise an artificial agent, driven by a control architecture based on deep reinforcement learning, able to coordinate its motion in human ensembles. As a paradigmatic coordination task we take a group version of the so called mirror game from the human movement literature. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1109/SOCA.2015.40,,"The rise of the Internet of Things (IoT) paradigm has allowed the design and development of new services interconnecting heterogeneous devices. However, the complexity of these new systems hasn't been followed by the increase of intelligence and reasoning of the devices connected. On the other hand, intelligent agent systems have developed precisely these characteristics so the combination of both paradigms by modelling intelligent agents in IoT devices is a very promising approach that will enable a more powerful and smart IoT. The interconnection of agents through a Internet-based network implies addressing critical issues that affect all network communications, such as security, privacy and access control, specially given the sensitivity of the information exchanged by agents. In this paper, we propose the application of User-Managed Access (UMA) to provide an unified access control schema for an heterogeneous hybrid architecture of IoT devices and intelligent agents. © 2016 Elsevier B.V., All rights reserved.",TOPIC
10.1109/SOSE67019.2025.00014,AI-Augmented DevSecOps Pipelines for Secure and Scalable Service-Oriented Architectures in Cloud-Native Systems,"Cloud-native architectures face escalating security challenges that traditional approaches cannot address at scale. This paper presents an AI-augmented DevSecOps framework integrating machine learning models into security pipelines for realtime threat detection and automated response. The framework achieves 95% attack detection rates with sub-2 second latency at 10 k events/sec. Key contributions include LSTM-based threat detection embedded in CI/CD workflows, adaptive model training with 98% accuracy retention over 6 months, and complete opensource implementation. Experimental validation across multiple attack scenarios demonstrates effectiveness while maintaining operational efficiency in hybrid Kubernetes-serverless environments.",TOPIC
10.1109/SPAWC48557.2020.9154235,,"In the context of wireless networking, it was recently shown that multiple DNNs can be jointly trained to offer a desired collaborative behaviour capable of coping with a broad range of sensing uncertainties. In particular, it was established that DNNs can be used to derive policies that are robust with respect to the information noise statistic affecting the local information (e.g. CSI in a wireless network) used by each agent (e.g.Transmitter) to make its decision. While promising, a major challenge in the implementation of such method is that information noise statistics may differ from agent to agent and, more importantly, that such statistics may not be available at the time of training or may evolve over time, making burdensome retraining necessary. This situation makes it desirable to devise a ""universal"" machine learning model, which can be trained once for all so as to allow for decentralized cooperation in any future feedback noise environment. With this goal in mind, we propose an architecture inspired from the well-known Mixture of Experts (MoE) model, which was previously used for non-linear regression and classification tasks in various contexts, such as computer vision and speech recognition. We consider the decentralized power control problem as an example to showcase the validity of the proposed model and to compare it against other power control algorithms. We show the ability of the so called Team-DMoE model to efficiently track time-varying statistical scenarios. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/SPAWC48557.2020.9154327,,"Federated learning has emerged as an umbrella term for centralized coordination strategies in multi-Agent environments. While many federated learning architectures process data in an online manner, and are hence adaptive by nature, most performance analyses assume static optimization problems and offer no guarantees in the presence of drifts in the problem solution or data characteristics. We consider a federated learning model where at every iteration, a random subset of available agents perform local updates based on their data. Under a nonstationary random walk model on the true minimizer for the aggregate optimization problem, we establish that the performance of the architecture is determined by three factors, namely, the data variability at each agent, the model variability across all agents, and a tracking term that is inversely proportional to the learning rate of the algorithm. The results clarify the trade-off between convergence and tracking performance. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/SPAWC51858.2021.9593148,,"Federated learning involves a central processor that interacts with multiple agents to determine a global model. The process consists of repeatedly exchanging estimates, which may end up divulging some private information from the local agents. This scheme can be inconvenient when dealing with sensitive data, and therefore, there is a need for the privatization of the algorithm. Furthermore, the current architecture of a server connected to multiple clients is highly sensitive to communication failures and computational overload at the server. In this work, we develop a private multi-server federated learning scheme, which we call graph federated learning. We use cryptographic and differential privacy concepts to privatize the federated learning algorithm over a graph structure. We further show under convexity and Lipschitz conditions, that the privatized process matches the performance of the non-private algorithm. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/SPW.2018.00022,,"In the past few years, consumer review sites have become the main target of deceptive opinion spam, where fictitious opinions or reviews are deliberately written to sound authentic. Most of the existing work to detect the deceptive reviews focus on building supervised classifiers based on syntactic and lexical patterns of an opinion. With the successful use of Neural Networks on various classification applications, in this paper, we propose FakeGAN a system that for the first time augments and adopts Generative Adversarial Networks (GANs) for a text classification task, in particular, detecting deceptive reviews. Unlike standard GAN models which have a single Generator and Discriminator model, FakeGAN uses two discriminator models and one generative model. The generator is modeled as a stochastic policy agent in reinforcement learning (RL), and the discriminators use Monte Carlo search algorithm to estimate and pass the intermediate action-value as the RL reward to the generator. Providing the generator model with two discriminator models avoids the mod collapse issue by learning from both distributions of truthful and deceptive reviews. Indeed, our experiments show that using two discriminators provides FakeGAN high stability, which is a known issue for GAN architectures. While FakeGAN is built upon a semi-supervised classifier, known for less accuracy, our evaluation results on a dataset of TripAdvisor hotel reviews show the same performance in terms of accuracy as of the state-of-the-art approaches that apply supervised machine learning. These results indicate that GANs can be effective for text classification tasks. Specifically, FakeGAN is effective at detecting deceptive reviews. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1109/SSCI50451.2021.9660156,,"Autonomous driving is a complex task, which has been tackled since the first self-driving car ALVINN in 1989, with a supervised learning approach, or behavioral cloning (BC). In BC, a neural network is trained with state-action pairs that constitute the training set made by an expert, i.e., a human driver. However, this type of imitation learning does not take into account the temporal dependencies that might exist between actions taken in different moments of a navigation trajectory. These type of tasks are better handled by reinforcement learning (RL) algorithms, which need to define a reward function. On the other hand, more recent approaches to imitation learning, such as Generative Adversarial Imitation Learning (GAIL), can train policies without explicitly requiring to define a reward function, allowing an agent to learn by trial and error directly on a training set of expert trajectories. In this work, we propose two variations of GAIL for autonomous navigation of a vehicle in the realistic CARLA simulation environment for urban scenarios. Both of them use the same network architecture, which process high-dimensional image input from three frontal cameras, and other nine continuous inputs representing the velocity, the next point from the sparse trajectory and a high-level driving command. We show that both of them are capable of imitating the expert trajectory from start to end after training ends, but the GAIL loss function that is augmented with BC outperforms the former in terms of convergence time and training stability. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TAC.2011.2146890,IEEE Transactions on Automatic Control,"This paper solves an $n$ -agent formation shape control problem in the plane. The objective is to design decentralized control laws so that the agents cooperatively restore a prescribed formation shape in the presence of small perturbations from the prescribed shape. We consider two classes of directed, cyclic information architectures associated with so-called minimally persistent formations: leader-remote-follower and coleader. In our framework the formation shape is maintained by controlling certain interagent distances. Only one agent is responsible for maintaining each distance. We propose a decentralized control law where each agent executes its control using only the relative position measurements of agents to which it must maintain its distance. The resulting nonlinear closed-loop system has a manifold of equilibria, which implies that the linearized system is nonhyperbolic. We apply center manifold theory to show local exponential stability of the desired formation shape. The result circumvents the non-compactness of the equilibrium manifold. Choosing stabilizing gains is possible if a certain submatrix of the rigidity matrix has all leading principal minors nonzero, and we show that this condition holds for all minimally persistent leader-remote-follower and coleader formations with generic agent positions. Simulations are provided. © 2006 IEEE. © 2011 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TAC.2021.3056336,IEEE Transactions on Automatic Control,"This article addresses the problem of cooperative adaptive containment control for multiagent systems, which specifies the objective of jointly achieving containment control and accurate adaptive learning/identification of unknown system parameters. We consider a class of linear uncertain multiagent systems with multiple leaders subject to bounded unmeasurable inputs and multiple followers subject to unknown system dynamics. A novel cooperative adaptive containment control architecture is proposed, which consists of a discontinuous nonlinear state-feedback control law and a filter-based cooperative adaptation law. This new control architecture is compelling in the sense that exponential convergence of both containment tracking errors to zero and adaptation parameters to their true values can be achieved simultaneously under a mild cooperative finite-time excitation condition. This condition significantly relaxes existing ones (e.g., persistent excitation and finite-time excitation) for parameter identification in adaptive control systems. Effectiveness of the proposed approach has been demonstrated through both rigorous analysis and a case study. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TAC.2023.3330405,IEEE Transactions on Automatic Control,"—We study the asymptotic learning rates of belief vectors in a distributed hypothesis testing problem under linear and log-linear combination rules. We show that under both combination strategies, agents are able to learn the truth exponentially fast, with a faster rate under log-linear fusion. We examine the gap between the rates in terms of network connectivity and information diversity. We also provide closed-form expressions for special cases involving federated architectures and exchangeable networks. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TAC.2024.3365569,IEEE Transactions on Automatic Control,"The problem of coverage control, i.e., of coordinating multiple agents to optimally cover an area, arises in various applications. However, coverage applications face two major challenges: 1) dealing with nonlinear dynamics while respecting system and safety critical constraints and 2) performing the task in an initially unknown environment. We solve the coverage problem by using a hierarchical framework, in which references are calculated at a central server and passed to the agents' local model predictive control (MPC) tracking schemes. Furthermore, to ensure that the environment is actively explored by the agents a probabilistic exploration-exploitation tradeoff is deployed. In addition, we derive a control framework that avoids the hierarchical structure by integrating the reference optimization in the MPC formulation. Active learning is then performed drawing inspiration from Upper Confidence Bound (UCB) approaches. For all developed control architectures, we guarantee closed-loop constraint satisfaction and convergence to an optimal configuration. Furthermore, all methods are tested and compared on hardware using a miniature car platform. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TAES.2024.3434771,User-Centric Satellite Handover for Multiple Traffic Profiles Using Deep Q-Learning,"Multiple low Earth orbit (LEO) satellites have recently been launched in constellations to ensure direct Internet access to users anywhere and at any time. Due to the high-speed mobility of LEO satellites, users undergo multiple handovers (HOs) during their service time, which has a negative impact on users' quality of service (QoS) if occurred in high frequency. Moreover, next-generation communication technologies are designed to support a wide spectrum of applications, including artificial intelligence, virtual reality, and Internet of Things. Thus, differentiating user equipments (UEs) with different and varying traffic profiles (TP) has become necessary due to each application's unique performance requirements. However, LEO satellites have limited onboard resources and the launched constellations ensure that each UE will be covered by more than one LEO satellite at any given moment, making it challenging to select the optimal satellite at any given time to assure the optimum QoS. Therefore, a satellite HO strategy has to effectively use the few available satellite resources and prevent network congestion while respecting the various resource requirements per TP. To address all the above requirements, we propose a user-centric multiagent deep Q-network satellite HO strategy, which is the first in the state of the art to address the variety and diversity of UEs' performance requirements and generated traffic statistics. Our method showcases a significant achievement of approximately 60% reduction in HO rate and around 91% reduction in blocking rate compared to conventional single-criterion approaches.",TOPIC
10.1109/TAES.2025.3594697,Scalable Satellite Handover Management in Non-Terrestrial Networks: A Distributed MADQL Approach,"Satellite communications provide means for extending next-generation communication technology to areas beyond terrestrial network coverage. Multiple Low Earth Orbit (LEO) satellites have been deployed in constellations to offer ground users direct Internet connection at any time, place, and condition. However, integrating Non-Terrestrial Networks (NTNs) into terrestrial communication systems presents several challenges, including the management of handover strategies due to the rapid satellite movement. Even if previous studies have explored various approaches to optimize handovers in NTNs, they have often overlooked critical factors, such as user-specific data throughput requirements, limited satellite energy, and the need for dynamic adaptation to real-time network conditions. To address these gaps, this paper proposes a Scalable Multi-Agent Satellite Handover (SMASH) framework based on Distributed Multi-Agent Deep Q-Learning for optimized handover decisions and dynamic satellite selection. SMASH aims to ensure seamless connectivity while effectively managing satellite resources to meet diverse demands. It features an adaptive resource allocation strategy driven by user demands and network conditions, thereby ensuring application-specific Quality of Service requirements. We validate and evaluate SMASH using a satellite network simulator, conducting a comprehensive sensitivity analysis and benchmarking its performance against existing approaches in the literature. The proposed handover technique significantly enhances NTN communication performance by reducing the average number of handovers and optimizing satellite resource allocation, thereby preventing user blocking. The SMASH framework ensures continuous service delivery by dynamically adapting to fluctuations in both user demand and satellite resource availability.",TOPIC
10.1109/TAFFC.2022.3171719,IEEE Transactions on Affective Computing,"Prediction of human actions in social interactions has important applications in the design of social robots or artificial avatars. In this paper, we focus on a unimodal representation of interactions and propose to tackle interaction generation in a data-driven fashion. In particular, we model human interaction generation as a discrete multi-sequence generation problem and present SocialInteractionGAN, a novel adversarial architecture for conditional interaction generation. Our model builds on a recurrent encoder-decoder generator network and a dual-stream discriminator, that jointly evaluates the realism of interactions and individual action sequences and operates at different time scales. Crucially, contextual information on interacting participants is shared among agents and reinjected in both the generation and the discriminator evaluation processes. Experiments show that albeit dealing with low dimensional data, SocialInteractionGAN succeeds in producing high realism action sequences of interacting people, comparing favorably to a diversity of recurrent and convolutional discriminator baselines, and we argue that this work will constitute a first stone towards higher dimensional and multimodal interaction generation. Evaluations are conducted using classical GAN metrics, that we specifically adapt for discrete sequential data. Our model is shown to properly learn the dynamics of interaction sequences, while exploiting the full range of available actions. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TAFFC.2024.3494595,Machiavellian Robots and Their Theory of Mind,"The objective of this work is to develop and evaluate computational cognitive models of Theory of Mind (ToM) and Machiavellian behavior embedded in a humanoid robot. Machiavellianism, together with psychopathy and narcissism, is part of the Dark Triad (DT), three constructs that correspond to socially aversive yet not necessarily pathological personalities. The motivations of the present work are both theoretical and application-oriented. In the long term, we aim to: (i) Provide researchers with new insights into the Machiavellian as well as other DT constructs through simulated and robotic setups; (ii) Provide a tool to train psychologists to deal with social and antisocial behavior in a controlled setup; (iii) Help people become aware of the behavioral mechanisms that they may expect from people with DT traits in social and affective relationships; (iv) Assist robotic engineers in developing better robots by identifying behaviors that should be avoided. To this end, we explored a computational model of ToM in the popular Planning Domain Definition Language (PDDL), and defined a domain with the necessary elements to induce Machiavellian behavior during planning and execution. Subsequently, we implemented our computational model in a software architecture controlling the behavior of a humanoid robot and recorded videos of the robot interacting with two actors. Finally, we conducted experiments with 300 participants divided into 6 conditions to verify whether the implemented framework is versatile enough to generate behaviors that participants would rate as either more Machiavellian or less Machiavellian based on their observations of the recorded videos.",TOPIC
10.1109/TAMD.2014.2341351,Ecological Active Vision: Four Bioinspired Principles to Integrate Bottom–Up and Adaptive Top–Down Attention Tested With a Simple Camera-Arm Robot,"Vision gives primates a wealth of information useful to manipulate the environment, but at the same time it can easily overwhelm their computational resources. Active vision is a key solution found by nature to solve this problem: a limited fovea actively displaced in space to collect only relevant information. Here we highlight that in ecological conditions this solution encounters four problems: 1) the agent needs to learn where to look based on its goals; 2) manipulation causes learning feedback in areas of space possibly outside the attention focus; 3) good visual actions are needed to guide manipulation actions, but only these can generate learning feedback; and 4) a limited fovea causes aliasing problems. We then propose a computational architecture (“BITPIC”) to overcome the four problems, integrating four bioinspired key ingredients: 1) reinforcement-learning fovea-based top-down attention; 2) a strong vision-manipulation coupling; 3) bottom-up periphery-based attention; and 4) a novel action-oriented memory. The system is tested with a simple simulated camera-arm robot solving a class of search-and-reach tasks involving color-blob “objects.” The results show that the architecture solves the problems, and hence the tasks, very efficiently, and highlight how the architecture principles can contribute to a full exploitation of the advantages of active vision in ecological conditions.",TOPIC
10.1109/TASE.2022.3205651,IEEE Transactions on Automation Science and Engineering,"The ever-increasing demands for autonomy and precision have led to the development of heavily computational multi-robot system (MRS). However, numerous missions exclude the use of robotic cloud. Another solution is to use the robotic cluster to locally distribute the computational load. This complex distribution requires adaptability to come up with a dynamic and uncertain environment. Classical approaches are too limited to solve this problem, but recent advances in reinforcement learning and deep learning offer new opportunities. In this paper we propose a new Deep Q-Network (DQN) based approaches where the MRS learns to distribute tasks directly from experience. Since the problem complexity leads to a curse of dimensionality, we use two specific methods, a new branching architecture, called Branching Dueling Q-Network (BDQ), and our own optimized multi-agent solution and we compare them with classical Market-based approaches as well as with non-distributed and purely local solutions. Our study shows the relevancy of learning-based methods for task mapping and also highlight the BDQ architecture capacity to solve high dimensional state space problems. Note to Practitioners - A lot of applications in industry like area exploration and monitoring can be efficiently delegated to a group of small-size robots or autonomous vehicles with advantages like reliability and cost in respect of single-robot solutions. But autonomy requires high and increasing compute-intensive tasks such as computer-vision. On the other hand small robots have energy constraints, limited embedded computing capacities and usually restricted and/or unreliable communications that limit the use of cloud resources. An alternative solution to cope with this problem consists in sharing the computing resources of the group of robots. Previous work was a proof of concept limited to the parallelisation of a single specific task. In this paper we formalize a general method that allows the group of robots to learn on the field how to efficiently distribute tasks in order to optimize the execution time of a mission under energy constraint. We demonstrate the relevancy of our solution over market-based and non-distributed approaches by means of intensive simulations. This successful study is a necessary first step towards distribution and parallelisation of computation tasks over a robotic cluster. The next steps, not tested yet, will address hardware in the loop simulation and finally a real-life mission with a group of robots. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TASE.2024.3410703,A Digital Twin Driven Human-Centric Ecosystem for Industry 5.0,"Industry 5.0 embodies the vision for the future of factories, emphasizing the importance of sustainable industrialization and the role of industry in society, through the key concept of placing the well-being of workers at the center of the production process. Building upon this vision, we propose a new paradigm to design human-centric industrial applications. To this end, we exploit Digital Twin (DT) technology to build a digital replica for each entity on the shop floor and support and augment interaction among workers and machines. While so far DTs in automation have been proposed for machine digitalization, the core element of the proposed approach is the Operator Digital Twin (ODT). In this scenario, biometrics allows to build a reliable model of those operator’s characteristics that are relevant in working contexts. Biometric traits are measured and processed to detect physical, emotional, and mental conditions, which are used to define the operator’s state. Perspectively, this allows to manage and monitor production and processes in an operator-in-the-loop manner, where not only is the operator aware of the state of the plant, but also any technological agent in the plant acts and reacts according to the operator’s needs and conditions. In this paper, we define the modeling of the envisioned ecosystem, present the designed DT’s blue-print architecture, discuss its implementation in relevant application scenarios, and report an example of implementation in a collaborative robotics scenario.Note to Practitioners—This paper was motivated by the problem of designing human-cyber-physical systems, where production processes are managed by concurrently taking into account operators, machines and plant status. This answers the needs of the novel Industry 5.0 paradigm, which aims to enhance social sustainability of modern factories. To this end, we propose an architecture based on digital twins that allows to develop a digital layer, detached from the physical one, where the plant can be monitored and managed. This allows the creation of a digital ecosystem where machines, operators, and the interactions among them are represented, augmented, and managed. We discuss how the proposed architecture can be applied to three relevant scenarios: remote training and maintenance, line operation and line supervision. Moreover, the implementation in a collaborative robotics scenario is presented, to provide an example of the proposed architecture can be implemented in industrial scenarios.",TOPIC
10.1109/TBCAS.2018.2831618,IEEE Transactions on Biomedical Circuits and Systems,"Spiking neural networks (SNNs) are being explored in an attempt to mimic brain's capability to learn and recognize at low power. Crossbar architecture with highly scalable resistive RAM or RRAM array serving as synaptic weights and neuronal drivers in the periphery is an attractive option for the SNN. Recognition (akin to 'reading' the synaptic weight) requires small amplitude bias applied across the RRAM to minimize conductance change. Learning (akin to 'writing' or updating the synaptic weight) requires large amplitude bias pulses to produce a conductance change. The contradictory bias amplitude requirement to perform reading and writing simultaneously and asynchronously, akin to biology, is a major challenge. Solutions suggested in the literature rely on time-division-multiplexing of read and write operations based on clocks, or approximations ignoring the reading when coincidental with writing. In this paper, we overcome this challenge and present a clock-less approach wherein reading and writing are performed in different frequency domains. This enables learning and recognition simultaneously on an SNN. We validate our scheme in SPICE circuit simulator by translating a two-layered feed-forward Iris classifying SNN to demonstrate software-equivalent performance. The system performance is not adversely affected by a voltage dependence of conductance in realistic RRAMs, despite departing from linearity. Overall, our approach enables direct implementation of biological SNN algorithms in hardware. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TBME.2014.2372011,IEEE Transactions on Biomedical Engineering,"The accurate diagnosis of Alzheimer's disease (AD) is essential for patient care and will be increasingly important as disease modifying agents become available, early in the course of the disease. Although studies have applied machine learning methods for the computer-aided diagnosis of AD, a bottleneck in the diagnostic performance was shown in previous methods, due to the lacking of efficient strategies for representing neuroimaging biomarkers. In this study, we designed a novel diagnostic framework with deep learning architecture to aid the diagnosis of AD. This framework uses a zero-masking strategy for data fusion to extract complementary information from multiple data modalities. Compared to the previous state-of-the-art workflows, our method is capable of fusing multimodal neuroimaging features in one setting and has the potential to require less labeled data. A performance gain was achieved in both binary classification and multiclass classification of AD. The advantages and limitations of the proposed framework are discussed. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TBME.2024.3485233,Robust Myocardial Perfusion MRI Quantification With DeepFermi,"Stress perfusion cardiac magnetic resonance is an important technique for examining and assessing the blood supply of the myocardium. Currently, the majority of clinical perfusion scans are evaluated based on visual assessment by experienced clinicians. This makes the process subjective, and to this end, quantitative methods have been proposed to offer a more user-independent assessment of perfusion. These methods, however, rely on time-consuming deconvolution analysis and are susceptible to data outliers caused by artifacts due to cardiac or respiratory motion. In our work, we introduce a novel deep-learning method that integrates the commonly used Fermi function with a neural network architecture for fast, accurate, and robust myocardial perfusion quantification. This approach employs the Fermi model to ensure that the perfusion maps are consistent with measured data, while also utilizing a prior based on a 3D convolutional neural network to generalize spatio-temporal information across different patient data. Our network is trained within a self-supervised learning framework, which circumvents the need for ground-truth perfusion labels that are challenging to obtain. Furthermore, we extended this training methodology by adopting a technique that ensures estimations are resistant to data outliers, thereby improving robustness against motion artifacts. Our simulation experiments demonstrated an overall improvement in the accuracy and robustness of perfusion parameter estimation, consistently outperforming traditional deconvolution analysis algorithms across varying Signal-to-Noise Ratio scenarios in the presence of data outliers. For the in vivo studies, our method generated robust perfusion estimates that aligned with clinical diagnoses, while being approximately five times faster than conventional algorithms.",TOPIC
10.1109/TCAD.2021.3077193,IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,"Nowadays, deep convolutional neural networks (DCNNs) play a significant role in many application domains, such as computer vision, medical imaging, and image processing. Nonetheless, designing a DCNN, able to defeat the state of the art, is a manual, challenging, and time-consuming task, due to the extremely large design space, as a consequence of a large number of layers and their corresponding hyperparameters. In this work, we address the challenge of performing hyperparameter optimization of DCNNs through a novel multiagent reinforcement learning (MARL)-based approach, eliminating the human effort. In particular, we adapt Q -learning and define learning agents per layer to split the design space into independent smaller design subspaces such that each agent fine tunes the hyperparameters of the assigned layer concerning a global reward. Moreover, we provide a novel formation of Q -tables along with a new update rule that facilitates agents' communication. Our MARL-based approach is data driven and able to consider an arbitrary set of design objectives and constraints. We apply our MARL-based solution to different well-known DCNNs, including GoogLeNet, VGG, and U-Net, and various datasets for image classification and semantic segmentation. Our results have shown that compared to the original CNNs, the MARL-based approach can reduce the model size, training time, and inference time by up to, respectively, 83× , 52%, and 54% without any degradation in accuracy. Moreover, our approach is very competitive to state-of-the-art neural architecture search methods in terms of the designed CNN accuracy and its number of parameters while significantly reducing the optimization cost. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TCCN.2021.3087586,Cooperative Multi-Agent Deep Reinforcement Learning for Resource Management in Full Flexible VHTS Systems,"Very high throughput satellite (VHTS) systems are expected to have a huge increase in traffic demand in the near future. Nevertheless, this increase will not be uniform over the entire service area due to the non-uniform distribution of users and changes in traffic demand during the day. This problem is addressed by using flexible payload architectures, which allow the allocation of payload resources flexibly to meet the traffic demand of each beam, leading to dynamic resource management (DRM) approaches. However, DRM adds significant complexity to VHTS systems, so in this paper we discuss the use of one reinforcement learning (RL) algorithm and two deep reinforcement learning (DRL) algorithms to manage the resources available in flexible payload architectures for DRM. These algorithms are Q-Learning (QL), Deep Q-Learning (DQL) and Double Deep Q-Learning (DDQL) which are compared based on their performance, complexity and added latency. On the other hand, this work demonstrates the superiority a cooperative multiagent (CMA) decentralized distribution has over a single agent (SA).",TOPIC
10.1109/TCCN.2022.3155727,IEEE Transactions on Cognitive Communications and Networking,"The rapid production of mobile devices along with the wireless applications boom is continuing to evolve daily. This motivates the exploitation of wireless spectrum using multiple Radio Access Technologies (multi-RAT) and developing innovative network selection techniques to cope with such intensive demand while improving Quality of Service (QoS). Thus, we propose a distributed framework for dynamic network selection at the edge level, and resource allocation at the Radio Access Network (RAN) level, while taking into consideration diverse applications' characteristics. In particular, our framework employs a deep Multi-Agent Reinforcement Learning (DMARL) algorithm, that aims to maximize the edge nodes' quality of experience while extending the battery lifetime of the nodes and leveraging adaptive compression schemes. Indeed, our framework enables data transfer from the network's edge nodes, with multi-RAT capabilities, to the cloud in a cost and energy-efficient manner, while maintaining QoS requirements of different supported applications. Our results depict that our solution outperforms state-of-the-art techniques of network selection in terms of energy consumption, latency, and cost. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TCCN.2024.3408459,HRL-TSCH: A Hierarchical Reinforcement Learning-Based TSCH Scheduler for IIoT,"The Industrial Internet of Things (IIoT) demands adaptable Networked Embedded Systems (NES) for optimal performance. Combined with recent advances in Artificial Intelligence (AI), tailored solutions can be developed to meet specific application requirements. This study introduces HRL-TSCH, an approach rooted in Hierarchical Reinforcement Learning (HRL), to devise Time Slotted Channel Hopping (TSCH) schedules provisioning IIoT demand. HRL-TSCH employs dual policies: one at a higher level for TSCH schedule link management, and another at a lower level for timeslot and channel assignments. The proposed RL agents address a multi-objective problem, optimizing throughput, power efficiency, and network delay based on predefined application requirements. Simulation experiments demonstrate HRL-TSCH‘s superiority over existing state-of-art approaches, effectively achieving an optimal balance between throughput, power consumption, and delay, thereby enhancing IIoT network performance.",TOPIC
10.1109/TCCN.2025.3561289,Enhancing the Uplink of Cell-Free Massive MIMO Through Prioritized Sampling and Personalized Federated Deep Reinforcement Learning,"Effective power control is key to solving the inter-user interference problem that degrades performance in cell-free massive multiple-input multiple-output (MIMO) systems. Motivated by its ability to operate online and model-free, without relying on training datasets, we leverage deep reinforcement learning (DRL) for uplink power control, aiming to maximize the guaranteed rate. We propose a fully centralized single-agent framework and two distributed schemes that employ several agents for improved scalability, leveraging prioritized experience replay to enable fast adaptation to the dynamic changes of the wireless environment. We investigate the performance of two multi-agent system architectures: (1) centralized training, decentralized execution (CTDE), where each agent forwards its RL experience to a central trainer, and (2) personalized federated learning (FedPer), where the training is performed locally at each agent, and only the base layer of the local deep neural network (DNN) model is forwarded periodically for aggregation at a server. We focus on the realistic scenario of dynamic device (de-)activation, combined with user mobility. Numerical evaluations demonstrate that the proposed FedPer with prioritized sampling achieves near-optimal rate and power performance while incurring the least amount of communication overhead.",TOPIC
10.1109/TCDS.2016.2538961,GRAIL: A Goal-Discovering Robotic Architecture for Intrinsically-Motivated Learning,"In this paper, we present goal-discovering robotic architecture for intrisically-motivated learning (GRAIL), a four-level architecture that is able to autonomously: 1) discover changes in the environment; 2) form representations of the goals corresponding to those changes; 3) select the goal to pursue on the basis of intrinsic motivations (IMs); 4) select suitable computational resources to achieve the selected goal; 5) monitor the achievement of the selected goal; and 6) self-generate a learning signal when the selected goal is successfully achieved. Building on previous research, GRAIL exploits the power of goals and competence-based IMs to autonomously explore the world and learn different skills that allow the robot to modify the environment. To highlight the features of GRAIL, we implement it in a simulated iCub robot and test the system in four different experimental scenarios where the agent has to perform reaching tasks within a 3-D environment.",TOPIC
10.1109/TCDS.2016.2543839,Training Agents With Interactive Reinforcement Learning and Contextual Affordances,"In the future, robots will be used more extensively as assistants in home scenarios and must be able to acquire expertise from trainers by learning through crossmodal interaction. One promising approach is interactive reinforcement learning (IRL) where an external trainer advises an apprentice on actions to speed up the learning process. In this paper we present an IRL approach for the domestic task of cleaning a table and compare three different learning methods using simulated robots: 1) reinforcement learning (RL); 2) RL with contextual affordances to avoid failed states; and 3) the previously trained robot serving as a trainer to a second apprentice robot. We then demonstrate that the use of IRL leads to different performance with various levels of interaction and consistency of feedback. Our results show that the simulated robot completes the task with RL, although working slowly and with a low rate of success. With RL and contextual affordances fewer actions are needed and can reach higher rates of success. For good performance with IRL it is essential to consider the level of consistency of feedback since inconsistencies can cause considerable delay in the learning process. In general, we demonstrate that interactive feedback provides an advantage for the robot in most of the learning cases.",TOPIC
10.1109/TCDS.2016.2636291,IEEE Transactions on Cognitive and Developmental Systems,"This paper argues that, the third generation of neural networks-the spiking neural networks (SNNs), can be used to model dynamic, spatio-temporal, cognitive brain processes measured as functional magnetic resonance imaging (fMRI) data. This paper proposes a novel method based on the NeuCube SNN architecture for which the following new algorithms are introduced: fMRI data encoding into spike sequences; deep unsupervised learning of fMRI data in a 3-D SNN reservoir; classification of cognitive states; and connectivity visualization and analysis for the purpose of understanding cognitive dynamics. The method is illustrated on two case studies of cognitive data modeling from a benchmark fMRI data set of seeing a picture versus reading a sentence. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TCDS.2017.2699578,IEEE Transactions on Cognitive and Developmental Systems,"This paper introduces new results on the modeling of early vocal development using artificial intelligent cognitive architectures and a simulated vocal tract. The problem is addressed using intrinsically motivated learning algorithms for autonomous sensorimotor exploration, a kind of algorithm belonging to the active learning architectures family. The artificial agent is able to autonomously select goals to explore its own sensorimotor system in regions, where its competence to execute intended goals is improved. We propose to include a somatosensory system to provide a proprioceptive feedback signal to reinforce learning through the autonomous discovery of motor constraints. Constraints are represented by a somatosensory model which is unknown beforehand to the learner. Both the sensorimotor and somatosensory system are modeled using Gaussian mixture models. We argue that using an architecture which includes a somatosensory model would reduce redundancy in the sensorimotor model and drive the learning process more efficiently than algorithms taking into account only auditory feedback. The role of this proposed system is to predict whether an undesired collision within the vocal tract under a certain motor configuration is likely to occur. Thus, compromised motor configurations are rejected, guaranteeing that the agent is less prone to violate its own constraints. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TCDS.2019.2934643,IEEE Transactions on Cognitive and Developmental Systems,"The ability to learn the sensorimotor maps of unknown environments without supervision is a vital capability of any autonomous agent, be it biological or artificial. An accurate sensorimotor map should be able to encode the agent's world and equip it with the capability to anticipate or predict the results of its actions. However, to design a robust autonomous learning technique for an unknown, dynamic, partially observable, or noisy environment remains a daunting task. This article proposes a temporospatial merge grow when required (TMGWR) network for continuous self-organization of an agent's sensorimotor awareness in noisy environments. TMGWR is an adaptive neural algorithm that learns the sensorimotor map of an agent's world using a time series self-organizing strategy and the grow when required (GWR) algorithm. The algorithm is compared with growing neural gas (GNG), GWR, and time GNG in terms of their disambiguation performance, sensorial representation accuracy, and sensorimotor-link error, a new metric that is developed in this article to evaluate how well a sensorimotor map represents causality in the agent's world. The outcomes of the experiments show that TMGWR is more efficient and suitable for sensorimotor map learning in noisy environments than the competing algorithms. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TCDS.2021.3050723,IEEE Transactions on Cognitive and Developmental Systems,"Online reinforcement learning agents are currently able to process an increasing amount of data by converting it into a higher order value functions. This expansion of the information collected from the environment increases the agent's state space enabling it to scale up to more complex problems but also increases the risk of forgetting by learning on redundant or conflicting data. To improve the approximation of a large amount of data, a random mini-batch of the past experiences that are stored in the replay memory buffer is often replayed at each learning step. The proposed work takes inspiration from a biological mechanism which acts as a protective layer of higher cognitive functions found in mammalian brain: active memory consolidation mitigates the effect of forgetting previous memories by dynamically processing the new ones. Similar dynamics are implemented by the proposed augmented memory replay or AMR algorithm. The architecture of AMR, based on a simple artificial neural network is able to provide an augmentation policy which modifies each of the agents experiences by augmenting their relevance prior to storing them in the replay memory. The function approximator of AMR is evolved using genetic algorithm in order to obtain the specific augmentation policy function that yields the best performance of a learning agent in a specific environment given by its received cumulative reward. Experimental results show that an evolved AMR augmentation function capable of increasing the significance of the specific memories is able to further increase the stability and convergence speed of the learning algorithms dealing with the complexity of continuous action domains. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TCDS.2021.3108478,IEEE Transactions on Cognitive and Developmental Systems,"A key competence for open-ended learning is the formation of increasingly abstract representations useful for driving complex behavior. Abstract representations ignore specific details and facilitate generalization. Here, we consider the learning of abstract representations in a multimodal setting with two or more input modalities. We treat the problem as a lossy compression problem and show that generic lossy compression of multimodal sensory input naturally extracts abstract representations that tend to strip away modalitiy specific details and preferentially retain information that is shared across the different modalities. Specifically, we propose an architecture that is able to extract information common to different modalities based on the compression abilities of generic autoencoder neural networks. We test the architecture with two tasks that allow: 1) the precise manipulation of the amount of information contained in and shared across different modalities and 2) testing the method on a simulated robot with visual and proprioceptive inputs. Our results show the validity of the proposed approach and demonstrate the applicability to embodied agents. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TCDS.2022.3152081,C-GRAIL: Autonomous Reinforcement Learning of Multiple and Context-Dependent Goals,"When facing the problem of autonomously learning to achieve multiple goals, researchers typically focus on problems where each goal can be solved using just one policy. However, in environments presenting different contexts, the same goal might need different skills to be solved. These situations pose two challenges: 1) recognize which are the contexts that need different policies to perform the goals and 2) learn the policies to accomplish the same goal in the identified relevant contexts. These two challenges are even harder if faced within an open-ended learning framework where potentially an agent has no information on the environment, possibly not even about the goals it can pursue. We propose a novel robotic architecture, contextual GRAIL (C-GRAIL), that solves these challenges in an integrated fashion. The architecture is able to autonomously detect new relevant contexts and ignore irrelevant ones, on the basis of the decrease of the expected performance for a given goal. Moreover, C-GRAIL can quickly learn the policies for new contexts leveraging on transfer learning techniques. The architecture is tested in a simulated robotic environment involving a robot that autonomously discovers and learns to reach relevant target objects in the presence of multiple obstacles generating several different contexts.",TOPIC
10.1109/TCDS.2022.3152383,IEEE Transactions on Cognitive and Developmental Systems,"In order to effectively handle multiple tasks that are not predefined, a robotic agent needs to automatically map its high-dimensional sensory inputs into useful features. As a solution, feature learning has empirically shown substantial improvements in obtaining representations that are generalizable to different tasks, compared to feature engineering approaches, but it requires a large amount of data and computational capacity. These challenges are specifically relevant in robotics due to the low signal-to-noise ratios inherent to robotic data, and to the cost typically associated with collecting this type of input. In this article, we propose a deep probabilistic method based on convolutional variational autoencoders (CVAEs) to learn visual features suitable for interaction and recognition tasks. We run our experiments on a self-supervised robotic sensorimotor data set. Our data were acquired with the iCub humanoid and are based on a standard object collection, thus being readily extensible. We evaluated the learned features in terms of usability for: 1) object recognition; 2) capturing the statistics of the effects; and 3) planning. In addition, where applicable, we compared the performance of the proposed architecture with other state-of-the-art models. These experiments demonstrate that our model is capable of capturing the functional statistics of action and perception (i.e., images) which performs better than existing baselines, without requiring millions of samples or any hand-engineered features. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TCDS.2023.3299755,IEEE Transactions on Cognitive and Developmental Systems,"For most real-world applications, robots need to adapt and learn continually with limited data in their environments. In this article, we consider the problem of few-shot incremental learning (FSIL), in which an AI agent is required to learn incrementally from a few data samples without forgetting the data it has previously learned. To solve this problem, we present a novel framework inspired by theories of concept learning in the hippocampus and the neocortex. Our framework represents object classes in the form of sets of clusters and stores them in memory. The framework replays data generated by the clusters of the old classes, to avoid forgetting when learning new classes. Our approach is evaluated on two object classification data sets resulting in state-of-the-art (SOTA) performance for class-incremental learning and FSIL. We also evaluate our framework for FSIL on a robot demonstrating that the robot can continually learn to classify a large set of household objects with limited human assistance. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TCE.2025.3553407,Transfer Learning Applied to Deep Reinforcement Learning for 6G Resource Management in Intra- and Inter-Slice RAN-Edge Domains,"Leveraging the power of deep reinforcement learning (DRL) and strategic knowledge transfer, our study introduces PIRA-DRL-DTRL, a novel approach to optimizing resource allocation in emerging 6G networks. Central to this research is the innovative application of artificial intelligence (AI) at the network’s edge, enabling efficient management of resources across diverse timeframes while enhancing overall network performance. Implemented within an Open Radio Access Network (O-RAN) architecture, PIRA-DRL-DTRL employs a two-tiered decision-making system to dynamically adapt to varying network demands, ensuring optimal resource allocation for enhanced mobile broadband (eMBB), ultra-reliable low-latency communications (URLLC), and massive machine-type communications (mMTC). Our proposed algorithm achieves significant performance gains, providing a 14.28% and 10.67% improvement in throughput for eMBB slices compared to DRL-only and state-of-the-art (SOTA) methods, respectively. Additionally, it reduces delay by 23.57% and 7.48% compared to baseline and SOTA approaches for eMBB slices. By predicting and adapting to network slice demands, PIRA-DRL-DTRL ensures seamless service delivery. This research lays the groundwork for smarter, more efficient 6G networks capable of meeting the dynamic needs of users and applications.",TOPIC
10.1109/TCSS.2024.3508452,Unveiling Agents’ Confidence in Opinion Dynamics Models via Graph Neural Networks,"Opinion Dynamics models in social networks are a valuable tool to study how opinions evolve within a population. However, these models often rely on agent-level parameters that are difficult to measure in a real population. This is the case of the confidence threshold in opinion dynamics models based on bounded confidence, where agents are only influenced by other agents having a similar opinion (given by this confidence threshold). Consequently, a common practice is to apply a universal threshold to the entire population and calibrate its value to match observed real-world data, despite being an unrealistic assumption. In this work, we propose an alternative approach using graph neural networks to infer agent-level confidence thresholds in the opinion dynamics of the Hegselmann-Krause model of bounded confidence. This eliminates the need for additional simulations when faced with new case studies. To this end, we construct a comprehensive synthetic training dataset that includes different network topologies and configurations of thresholds and opinions. Through multiple training runs utilizing different architectures, we identify GraphSAGE as the most effective solution, achieving a coefficient of determination $R^{2}$ above 0.7 in test datasets derived from real-world topologies. Remarkably, this performance holds even when the test topologies differ in size from those considered during training.",TOPIC
10.1109/TCSS.2025.3598697,Why Do Opinions and Actions Diverge? A Dynamic Framework to Explore the Impact of Subjective Norms,"Socio-psychological studies have identified a common phenomenon where an individual’s public actions do not necessarily coincide with their private opinions, yet most existing models fail to capture the dynamic interplay between these two aspects. To bridge this gap, we propose a novel agent-based modeling framework that integrates opinion dynamics with a decision-making mechanism. More precisely, our framework generalizes the classical Hegselmann-Krause (HK) model by combining it with a utility maximization problem. Preliminary results from our model demonstrate that the degree of opinion-action divergence within a population can be effectively controlled by adjusting two key parameters that reflect agents’ personality traits, while the presence of social network amplifies the divergence. In addition, we study the social diffusion process by introducing a small number of committed agents into the model, and identify three key outcomes: adoption of innovation, rejection of innovation, and the enforcement of unpopular norms, consistent with findings in socio-psychological literature. The strong relevance of the results to real-world phenomena highlights our framework’s potential for future applications in understanding and predicting complex social behaviors.",TOPIC
10.1109/TCST.2024.3378991,IEEE Transactions on Control Systems Technology,"Sensor-estimator systems provide critical information on the state of cyber-physical plants. Often, these units operate in an environment of constrained computational resources. This condition makes them vulnerable to cyberattacks that aim especially to degrade their processing capability and effectively incapacitate them. In the event that computational nodes are lost, an approach to adapt the estimator's algorithm and reprogram the adapted form on the surviving hardware is presented. To prepare the sensor-estimator system for degradation, the following co-design steps are developed: 1) the estimation algorithm, a bank of Kalman filters (KFs), is distributed so that multiple elemental filters are implemented on a collection of field-programmable gate arrays (FPGAs) and 2) the matrix operations of the conventional KF are programmed on the FPGAs using Faddeeva's elimination. After the attack, adaptation of the filter bank is realized by leveraging dynamic partial reconfiguration (DPR) of the surviving FPGAs. A high-authority agent monitors the likelihood of all elemental filters, a measure of which filters currently provide the best estimates, and replaces the least likely elements of the bank with the most likely ones. The latter are loaded onto the freed-up fabric of the remaining FPGAs, while these units are running other elemental filters in order to process sensor data without interruption. We have demonstrated their method on a prototype system that uses a radar sensor to estimate the kinematics of a maneuvering unmanned surface vehicle (USV). © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TCST.2024.3425210,A Privacy-Preserving Distributed Greedy Framework to Desynchronize Power Consumption in a Network of Thermostatically Controlled Loads,"This manuscript presents a novel distributed greedy framework applicable to a network of thermostatically controlled loads (TCLs) to desynchronize the network’s aggregated power consumption. Compared to the existing literature, our proposed framework offers two distinct novelties. First, our proposed algorithm relaxes the restrictive assumptions associated with the communication graph among TCLs. To elaborate, our algorithm only requires a connected graph to execute control, a condition less demanding than its counterpart algorithms that mandate a star architecture, K-regular graphs, or undirected connected graphs. Second, a significant novel feature is the relaxation of the obligation to share private information, such as each unit’s local power consumption and appliance temperatures, either with a central coordinator or neighboring TCLs. The findings presented in this brief are validated through simulations conducted over a network comprising 1000 TCLs.",TOPIC
10.1109/TDSC.2022.3156941,RGB Cameras Failures and Their Effects in Autonomous Driving Applications,"RGB cameras are one of the most relevant sensors for autonomous driving applications. It is undeniable that failures of vehicle cameras may compromise the autonomous driving task, possibly leading to unsafe behaviors when images that are subsequently processed by the driving system are altered. To support the definition of safe and robust vehicle architectures and intelligent systems, in this paper we define the failure modes of a vehicle camera, together with an analysis of effects and known mitigations. Further, we build a software library for the generation of the corresponding failed images, and we feed them to six object detectors for mono and stereo cameras and to the self-driving agent of an autonomous driving simulator. The resulting misbehaviors with respect to operating with clean images allow a better understanding of failures effects and the related safety risks in image-based applications.",TOPIC
10.1109/TETC.2023.3346944,IEEE Transactions on Emerging Topics in Computing,"Deep Neural Networks (DNNs) have shown significant advantages in a wide variety of domains. However, DNNs are becoming computationally intensive and energy hungry at an exponential pace, while at the same time, there is a vast demand for running sophisticated DNN-based services on resource constrained embedded devices. In this paper, we target energy-efficient inference on embedded DNN accelerators. To that end, we propose an automated framework to compress DNNs in a hardware-aware manner by jointly employing pruning and quantization. We explore, for the first time, per-layer fine- and coarse-grained pruning, in the same DNN architecture, in addition to low bit-width mixed-precision quantization for weights and activations. Reinforcement Learning (RL) is used to explore the associated design space and identify the pruning-quantization configuration so that the energy consumption is minimized whilst the prediction accuracy loss is retained at acceptable levels. Using our novel composite RL agent we are able to extract energy-efficient solutions without requiring retraining and/or fine tuning. Our extensive experimental evaluation over widely used DNNs and the CIFAR-10/100 and ImageNet datasets demonstrates that our framework achieves 39% average energy reduction for 1.7% average accuracy loss and outperforms significantly the state-of-the-art approaches. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TG.2024.3399536,IEEE Transactions on Games,"The balancing process for game levels in competitive two-player contexts involves a lot of manual work and testing, particularly for non-symmetrical game levels. In this work, we frame game balancing as a procedural content generation task and propose an architecture for automatically balancing of tile-based levels within the PCGRL framework (procedural content generation via reinforcement learning). Our architecture is divided into three parts: (1) a level generator, (2) a balancing agent, and (3) a reward modeling simulation. Through repeated simulations, the balancing agent receives rewards for adjusting the level towards a given balancing objective, such as equal win rates for all players. To this end, we propose new swap-based representations to improve the robustness of playability, thereby enabling agents to balance game levels more effectively and quickly compared to traditional PCGRL. By analyzing the agent&#x0027;s swapping behavior, we can infer which tile types have the most impact on the balance. We validate our approach in the Neural MMO (NMMO) environment in a competitive two-player scenario. In this extended conference paper, we present improved results, explore the applicability of the method to various forms of balancing beyond equal balancing, compare the performance to another search-based approach, and discuss the application of existing fairness metrics to game balancing. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TGCN.2024.3431945,QACM: QoS-Aware xApp Conflict Mitigation in Open RAN,"The advent of Open Radio Access Network (RAN) has revolutionized the field of RAN by introducing elements of native support of intelligence and openness into the next generation of mobile network infrastructure. Open RAN paves the way for standardized interfaces and enables the integration of network applications from diverse vendors, thereby enhancing network management flexibility. However, control decision conflicts occur when components from different vendors are deployed together. This article provides an overview of various types of conflicts that may occur in Open RAN, with a particular focus on intra-component conflict mitigation among Extended Applications (xApps) in the Near Real Time RAN Intelligent Controller (Near-RT-RIC). A QoS-Aware Conflict Mitigation (QACM) method is proposed that finds the optimal configuration of conflicting parameters while maximizing the number of xApps that have their Quality of Service (QoS) requirements met. We compare the performance of the proposed QACM method with two benchmark methods for priority and non-priority cases. The results indicate that our proposed method is the most effective in maintaining QoS requirements for conflicting xApps.",TOPIC
10.1109/TIA.2025.3569502,Safe Reinforcement Learning to Improve FACTS Setpoint Control in Presence of Model Errors,"There is limited application of closed-loop control using model-based approaches in wide area monitoring, protection, and control. Challenges that impede model-based approaches include engineering complexity, convergence issues, and model errors. Specifically, considering the rapid growth of distributed generation and renewables in the grid, maintaining an updated model without model errors is challenging. As an alternative to model-based approaches, data-driven control architectures based on reinforcement learning (RL) have shown great promise. In this work, we confront safety concerns with data-driven approaches by studying safe RL to improve voltage and power flow control. For both a model-free RL agent and a model-based RL agent, the accumulated constraint violation is investigated in a case study on the IEEE 14-bus and IEEE 57-bus systems. To evaluate performance, agents are compared against a model-based approach subject to errors. Our findings suggest that RL could be considered for optimizing voltage and current setpoints in systems when topological model errors are present.",TOPIC
10.1109/TII.2019.2925837,Methodological Approach for Developing Reconfigurable Automation Systems,"One challenge for the designers of the current industrial control systems consists of assuring the system reconfiguration at runtime, envisaged at system design time. This article focuses specifically on the fault tolerance to controller failures (as it is the most complex challenge) aiming at redistributing the responsibilities at runtime in order to finish the current production plan. Its applicability is illustrated by means of a case study that consists of a reconfigurable control application based on the IEC 61131-3 for a flexible assembly cell. A prototype software tool guides the developer during the development process. This approach contributes to develop more flexible control systems because they can react in case of a controller failure, to increase the system availability during its operation and to reduce the production downtimes to perform the maintenance tasks.",TOPIC
10.1109/TLT.2011.1,Observation of Collaborative Activities in a Game-Based Learning Platform,"The work reported here takes place in the educational domain. Learning with Computer-Based Learning Environments changes habits, especially for teachers. In this paper, we wish to demonstrate through examples how learning sessions set up in a Game-Based Learning environment may be regulated by the teacher thanks to observation facilities. Providing teachers with feedback (via observation) on the ongoing activity is thus central to being aware of what is happening in the classroom, in order to react in an appropriate way and to adapt a given pedagogical scenario. The first part deals with the observation of a learning environment, based on traces left by users in their collaborative activities. The information existing in these traces is rich but the quantity of traces is huge and very often incomplete. Furthermore, the information is not always at the right level of abstraction. That is why we explain the observation process, the assets of a multisource approach and the need for visualization linked to the traces. The second part of the paper focuses on our view of learning games illustrated through the “pedagogical dungeon,” a game-based environment that we have developed. In the third part, we illustrate these concepts in the pedagogical dungeon equipped for observation and with the capacity for collaboration in certain activities. Finally, the feedback about the experiments presented is discussed at the end of the paper.",TOPIC
10.1109/TMI.2021.3056951,IEEE Transactions on Medical Imaging,"Ultrasound Localization Microscopy (ULM) can resolve the microvascular bed down to a few micrometers. To achieve such performance, microbubble contrast agents must perfuse the entire microvascular network. Microbubbles are then located individually and tracked over time to sample individual vessels, typically over hundreds of thousands of images. To overcome the fundamental limit of diffraction and achieve a dense reconstruction of the network, low microbubble concentrations must be used, which leads to acquisitions lasting several minutes. Conventional processing pipelines are currently unable to deal with interference from multiple nearby microbubbles, further reducing achievable concentrations. This work overcomes this problem by proposing a Deep Learning approach to recover dense vascular networks from ultrasound acquisitions with high microbubble concentrations. A realistic mouse brain microvascular network, segmented from 2-photon microscopy, was used to train a three-dimensional convolutional neural network (CNN) based on a V-net architecture. Ultrasound data sets from multiple microbubbles flowing through the microvascular network were simulated and used as ground truth to train the 3D CNN to track microbubbles. The 3D-CNN approach was validated in silico using a subset of the data and in vivo in a rat brain. In silico, the CNN reconstructed vascular networks with higher precision (81%) than a conventional ULM framework (70%). In vivo, the CNN could resolve micro vessels as small as 10 $ {\mu}$ m with an improvement in resolution when compared against a conventional approach. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TMLCN.2024.3436472,On Learning Suitable Caching Policies for In-Network Caching,"In-network cache architectures, such as Information-centric networks (ICNs), have proven to be an efficient alternative to deal with the growing content consumption on networks. In caching networks, any device can potentially act as a caching node. In practice, real cache networks may employ different caching replacement policies by a node. The reason is that the policies may vary in efficiency according to unbounded context factors, such as cache size, content request pattern, content distribution popularity, and the relative cache location. The lack of suitable policies for all nodes and scenarios undermines the efficient use of available cache resources. Therefore, a new model for choosing caching policies appropriately to cache contexts on-demand and over time becomes necessary. In this direction, we propose a new caching meta-policy strategy capable of learning the most appropriate policy for cache online and dynamically adapting to context variations that leads to changes in which policy is best. The meta-policy decouples the eviction strategy from managing the context information used by the policy, and models the choice of suitable policies as online learning with a bandit feedback problem. The meta-policy supports deploying a diverse set of self-contained caching policies in different scenarios, including adaptive policies. Experimental results with single and multiple caches have shown the meta-policy effectiveness and adaptability to different content request models in synthetic and trace-driven simulations. Moreover, we compared the meta-policy adaptive behavior with the Adaptive Replacement Policy (ARC) behavior.",TOPIC
10.1109/TMLCN.2024.3502576,Reinforcement-Learning-Based Trajectory Design and Phase-Shift Control in UAV-Mounted-RIS Communications,"Taking advantages of both unmanned aerial vehicles (UAVs) and reconfigurable intelligent surfaces (RISs), UAV-mounted-RIS systems are expected to enhance transmission performance in complicated wireless environments. In this paper, we focus on system design for a UAV-mounted-RIS system and investigate joint optimization for the RIS’s phase shift and the UAV’s trajectory. To cope with the practical issue of inaccessible information on the user terminals’ (UTs) location and channel state, a reinforcement learning (RL)-based solution is proposed to find the optimal policy with finite steps of “trial-and-error”. As the action space is continuous, the deep deterministic policy gradient (DDPG) algorithm is applied to train the RL model. However, the online interaction between the agent and environment may lead to instability during the training and the assumption of (first-order) Markovian state transition could be impractical in real-world problems. Therefore, the decision transformer (DT) algorithm is employed as an alternative for RL model training to adapt to more general situations of state transition. Experimental results demonstrate that the proposed RL solutions are highly efficient in model training along with acceptable performance close to the benchmark, which relies on conventional optimization algorithms with the UT’s locations and channel parameters explicitly known beforehand.",TOPIC
10.1109/TMLCN.2025.3533427,Deep Fusion Intelligence: Enhancing 5G Security Against Over-the-Air Attacks,"With the increasing deployment of 5G networks, the vulnerability to malicious interference, such as jamming attacks, has become a significant concern. Detecting such attacks is crucial to ensuring the reliability and security of 5G communication systems Specifically in CAVs. This paper proposes a robust jamming detection system addressing challenges posed by impairments, such as Carrier Frequency Offset (CFO) and channel effects. To improve overall detection performance, the proposed approach leverages deep ensemble learning techniques by fusing different features with different sensitivities from the RF domain and Physical layer namely, Primary Synchronization Signal (PSS) and Secondary Synchronization Signal (SSS) cross-correlations in the time and the frequency domain, the energy of the null subcarriers, and the PBCH Error Vector Magnitude (EVM). The ensemble module is optimized for the aggregation method and different learning parameters. Furthermore, to mitigate the false positive and false negative, a systematic approach, termed Temporal Epistemic Decision Aggregator (TEDA) is introduced, which elegantly navigates the time-accuracy tradeoff by seamlessly integrating temporal decisions, thereby enhancing decision reliability. The presented approach is also capable of detecting inter-cell/inter-sector interference, thereby enhancing situational awareness on 5G air interface and RF domain security. Results show that the presented approach achieves the Area Under Curve (AUC) of 0.98, outperforming other compared methods by at least 0.06 (a 6% improvement). The true positive and negative rates are reported as 93.5% and 91.9%, respectively, showcasing strong performance for scenarios with CFO and channel impairments and outperforming the other compared methods by at least 12%. An optimization problem is formulated and solved based on the level of uncertainty observed in the experimental set-up and the optimum TEDA configuration is derived for the target false-alarm and miss-detection probability. Ultimately, the performance of the entire architecture is confirmed through analysis of real 5G signals acquired from a practical testbed, showing strong agreement with the simulation results.",TOPIC
10.1109/TMLCN.2025.3534139,Risk-Aware Reinforcement Learning Framework for User-Centric O-RAN,"The evolution of Open Radio Access Networks (O-RAN) presents an opportunity to enhance network performance by enabling dynamic orchestration of configuration and optimization parameters (COPs) through online learning methods. However, leveraging this potential requires overcoming the limitations of traditional cell-centric RAN architectures, which lack the necessary flexibility. On the other hand, despite their recent popularity, the practical deployment of online learning frameworks, such as Deep Reinforcement Learning (DRL)-based COP optimization solutions, remains limited due to their risk of deteriorating network performance during the exploration phase. In this article, we propose and analyze a novel risk-aware DRL framework for user-centric RAN (UC-RAN), which offers both the architectural flexibility and COP optimization to exploit this flexibility. We investigate and identify UC-RAN COPs that can be optimized via a soft actor-critic algorithm implementable as an O-RAN application (rApp) to jointly maximize latency satisfaction, reliability satisfaction, area spectral efficiency, and energy efficiency. We use the offline learning on UC-RAN to reliably accelerate DRL training, thus minimizing the risk of DRL deteriorating cellular network performance. Results show that our proposed solution approaches near-optimal performance in just a few hundred iterations with a decrease in risk score by a factor of ten.",TOPIC
10.1109/TMLCN.2025.3534754,Knowledge- and Model-Driven Deep Reinforcement Learning for Efficient Federated Edge Learning: Single- and Multi-Agent Frameworks,"In this paper, we investigate federated learning (FL) efficiency improvement in practical edge computing systems, where edge workers have non-independent and identically distributed (non-IID) local data, as well as dynamic and heterogeneous computing and communication capabilities. We consider a general FL algorithm with configurable parameters, including the number of local iterations, mini-batch sizes, step sizes, aggregation weights, and quantization parameters, and provide a rigorous convergence analysis. We formulate a joint optimization problem for FL worker selection and algorithm parameter configuration to minimize the final test loss subject to time and energy constraints. The resulting problem is a complicated stochastic sequential decision-making problem with an implicit objective function and unknown transition probabilities. To address these challenges, we propose knowledge/model-driven single-agent and multi-agent deep reinforcement learning (DRL) frameworks. We transform the primal problem into a Markov decision process (MDP) for the single-agent DRL framework and a decentralized partially-observable Markov decision process (Dec-POMDP) for the multi-agent DRL framework. We develop efficient single-agent and multi-agent asynchronous advantage actor-critic (A3C) approaches to solve the MDP and Dec-POMDP, respectively. In both frameworks, we design a knowledge-based reward to facilitate effective DRL and propose a model-based stochastic policy to tackle the mixed discrete-continuous actions and large action spaces. To reduce the computational complexities of policy learning and execution, we introduce a segmented actor-critic architecture for the single-agent DRL and a distributed actor-critic architecture for the multi-agent DRL. Numerical results demonstrate the effectiveness and advantages of the proposed frameworks in enhancing FL efficiency.",TOPIC
10.1109/TMLCN.2025.3537967,Reinforcement Learning With Selective Exploration for Interference Management in mmWave Networks,"The next generation of wireless systems will leverage the millimeter-wave (mmWave) bands to meet the increasing traffic volume and high data rate requirements of emerging applications (e.g., ultra HD streaming, metaverse, and holographic telepresence). In this paper, we address the joint optimization of beamforming, power control, and interference management in multi-cell mmWave networks. We propose novel reinforcement learning algorithms, including a single-agent-based method (BPC-SA) for centralized settings and a multi-agent-based method (BPC-MA) for distributed settings. To tackle the high-variance rewards caused by narrow antenna beamwidths, we introduce a selective exploration method to guide the agent towards more intelligent exploration. Our proposed algorithms are well-suited for scenarios where beamforming vectors require control in either a discrete domain, such as a codebook, or in a continuous domain. Furthermore, they do not require channel state information, extensive feedback from user equipments, or any searching methods, thus reducing overhead and enhancing scalability. Numerical results demonstrate that selective exploration improves per-user spectral efficiency by up to 22.5% compared to scenarios without it. Additionally, our algorithms significantly outperform existing methods by 50% in terms of per-user spectral effciency and achieve 90% of the per-user spectral efficiency of the exhaustive search approach while requiring only 0.1% of its computational runtime.",TOPIC
10.1109/TMLCN.2025.3605855,Robust Defensive Cyber Agent for Multi-Adversary Defense,"Modern cyber environments are becoming increasingly complex and distributed, often organized into multiple interconnected subnets and nodes. Even relatively small-scale networks can exhibit significant security challenges due to their dynamic topologies and the diversity of potential attack vectors. In modern cyber environments, human-led defense alone is insufficient due to delayed response times, cognitive overload, and limited availability of skilled personnel, particularly in remote or resource-constrained settings. These challenges are intensified by the growing diversity of cyber threats, including adaptive and machine learning-based attacks, which demand rapid and intelligent responses. Addressing this, we propose a reinforcement learning (RL)-based framework that integrates eXtreme Gradient Boosting (XGBoost) and transformer architectures to develop robust, generalizable defensive agents. The proposed agents are evaluated against both baseline defenders trained to counter specific adversaries and hierarchical generic agents representing the current state-of-the-art. Experimental results demonstrate that the RL-XGBoost (integration of RL and XGBoost) agent consistently achieves superior performance in terms of defense accuracy and efficiency across varied adversarial strategies and network configurations. Notably, in scenarios involving changes to network topology, both RL-Transformer (RL combined with transformer architectures) and RL-XGBoost agents exhibit strong adaptability and resilience, outperforming specialized blue agents and hierarchical agents in performance consistency. In particular, the RL-Transformer variant (RL-BERT) demonstrates exceptional robustness when attacker entry points are altered, effectively capturing long-range dependencies and temporal patterns through its self-attention mechanism. Overall, these findings highlight the RL-XGBoost model’s potential as a scalable and intelligent solution for multi-adversary defense in dynamic and heterogeneous cyber environments.",TOPIC
10.1109/TMLCN.2025.3618815,Cyrus+: A DRL-Based Puncturing Solution to URLLC/eMBB Multiplexing in O-RAN,"Puncturing is a promising technique in 3GPP to multiplex Enhanced Mobile Broadband (eMBB) and Ultra-Reliable Low Latency Communications (URLLC) traffic on the same 5G New Radio (NR) air interface. The essence of puncturing is to transmit URLLC packets on demand upon their arrival, by preempting the radio resources (or subcarriers) that are already allocated to eMBB traffic. Although it is considered most bandwidth efficient, puncturing URLLC data on eMBB can lead to degradation of eMBB’s performance. Most of the state-of-the-art research addressing this problem employ raw eMBB data throughput as performance metric. This is inadequate as, after puncturing, eMBB data may or may not be successfully decoded at its receiver. This paper presents Cyrus+—a deep reinforcement learning (DRL)-based puncturing solution that employs goodput (through feedback from a receiver’s decoder), rather than estimated raw throughput, in its design of reward function. Further, Cyrus+ is tailored specifically for the Open RAN (O-RAN) architecture and fully leverages O-RAN’s three control loops at different time scales in its design of DRL. In the Non-Real-Time (Non-RT) RAN Intelligent Controller (RIC), Cyrus+ initializes the policy network that will be used in the RT Open Distributed Unit (O-DU). In the Near-RT RIC, Cyrus+ refines the policy based on dynamic network conditions and feedback from the receivers. In the RT O-DU, Cyrus+ generates a puncturing codebook by considering all possible URLLC arrivals. We build a standard-compliant link-level 5G NR simulator to demonstrate the efficacy of Cyrus+. Experimental results show that Cyrus+ outperforms benchmark puncturing algorithms and meets the stringent timing requirement in 5G NR (numerology 3).",TOPIC
10.1109/TMM.2015.2478068,IEEE Transactions on Multimedia,"An adversary is an agent designed to make a classification system perform in some particular way, e.g., increase the probability of a false negative. Recent work builds adversaries for deep learning systems applied to image object recognition, exploiting the parameters of the system to find the minimal perturbation of the input image such that the system misclassifies it with high confidence. We adapt this approach to construct and deploy an adversary of deep learning systems applied to music content analysis. In our case, however, the system inputs are magnitude spectral frames, which require special care in order to produce valid input audio signals from network- derived perturbations. For two different train-test partitionings of two benchmark datasets, and two different architectures , we find that this adversary is very effective. We find that convolutional architectures are more robust compared to systems based on a majority vote over individually classified audio frames. Furthermore , we experiment with a new system that integrates an adversary into the training loop, but do not find that this improves the resilience of the system to new adversaries. © 2015 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TMRB.2021.3082210,IEEE Transactions on Medical Robotics and Bionics,"The next stage for robotics development is to introduce autonomy and cooperation with human agents in tasks that require high levels of precision and/or that exert considerable physical strain. To guarantee the highest possible safety standards, the best approach is to devise a deterministic automaton that performs identically for each operation. Clearly, such approach inevitably fails to adapt itself to changing environments or different human companions. In a surgical scenario, the highest variability happens for the timing of different actions performed within the same phases. This paper presents a cognitive control architecture that uses a multi-modal neural network trained on a cooperative task performed by human surgeons and produces an action segmentation that provides the required timing for actions while maintaining full phase execution control via a deterministic Supervisory Controller and full execution safety by a velocity-constrained Model-Predictive Controller. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TMSCS.2017.2761231,IEEE Transactions on Multi-Scale Computing Systems,"The brain-inspired spiking neural network neuromorphic architecture offers a promising solution for a wide set of cognitive computation tasks at a very low power consumption. Due to the practical feasibility of hardware implementation, we present a memristor-based model of hardware spiking neural networks which we simulate with Neural Network Scalable Spiking Simulator (N2S3), our open source neuromorphic architecture simulator. Although Spiking neural networks are widely used in the community of computational neuroscience and neuromorphic computation, there is still a need for research on the methods to choose the optimum parameters for better recognition efficiency. With the help of our simulator, we analyze and evaluate the impact of different parameters such as number of neurons, STDP window, neuron threshold, distribution of input spikes, and memristor model parameters on the MNIST hand-written digit recognition problem. We show that a careful choice of a few parameters (number of neurons, kind of synapse, STDP window, and neuron threshold) can significantly improve the recognition rate on this benchmark (around 15 points of improvement for the number of neurons, a few points for the others) with a variability of four to five points of recognition rate due to the random initialization of the synaptic weights. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TNET.2022.3187310,IEEE/ACM Transactions on Networking,"The Network Slicing (NS) paradigm enables the partition of physical and virtual resources among multiple logical networks, possibly managed by different tenants. In such a scenario, network resources need to be dynamically allocated according to the slice requirements. In this paper, we attack the above problem by exploiting a Deep Reinforcement Learning approach. Our framework is based on a distributed architecture, where multiple agents cooperate towards a common goal. The agent training is carried out following the Advantage Actor Critic algorithm, which permits to handle continuous action spaces. By means of extensive simulations, we show that our approach yields better performance than both a static allocation of system resources and an efficient empirical strategy. At the same time, the proposed system ensures high adaptability to different scenarios without the need for additional training. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TNET.2024.3396214,IEEE/ACM Transactions on Networking,"MmWaves have been envisioned as a promising direction to provide Gbps wireless access. However, they are susceptible to high path losses and blockages, which can only be partially mitigated by directional antennas. That makes mmWave networks coverage-limited, thus requiring dense deployments. Integrated access and backhaul (IAB) architectures have emerged as a cost-effective solution for network densification. Resource allocation in mmWave IAB networks must face big challenges originated by heavy temporal dynamics, such as intermittent links caused by user mobility and blockages from moving obstacles. This makes it extremely difficult to find optimal and adaptive solutions. In this article, exploiting the distributed structure of the problem, we propose a Multi-Agent Reinforcement Learning (MARL) framework to optimize user throughput via flow routing and link scheduling in mmWave IAB networks characterized by mobile users and obstacles. The proposed approach implicitly captures the environment dynamics, coordinates the interference, and manages the buffer levels of IAB relay nodes. We design different MARL components, respectively for full-duplex and half-duplex networks. In addition, we propose an online training algorithm, which addresses the feasibility issues of practical systems, especially the communication and coordination among RL agents. Numerical results show the effectiveness of the proposed approach. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TNNLS.2018.2816518,IEEE Transactions on Neural Networks and Learning Systems,"We present here a learning system using the iCub humanoid robot and the SpiNNaker neuromorphic chip to solve the real-world task of object-specific attention. Integrating spiking neural networks with robots introduces considerable complexity for questionable benefit if the objective is simply task performance. But, we suggest, in a cognitive robotics context, where the goal is understanding how to compute, such an approach may yield useful insights to neural architecture as well as learned behavior, especially if dedicated neural hardware is available. Recent advances in cognitive robotics and neuromorphic processing now make such systems possible. Using a scalable, structured, modular approach, we build a spiking neural network where the effects and impact of learning can be predicted and tested, and the network can be scaled or extended to new tasks automatically. We introduce several enhancements to a basic network and show how they can be used to direct performance toward behaviorally relevant goals. Results show that using a simple classical spike-timing-dependent plasticity (STDP) rule on selected connections, we can get the robot (and network) to progress from poor task-specific performance to good performance. Behaviorally relevant STDP appears to contribute strongly to positive learning: 'do this' but less to negative learning: 'don't do that.' In addition, we observe that the effect of structural enhancements tends to be cumulative. The overall system suggests that it is by being able to exploit combinations of effects, rather than any one effect or property in isolation, that spiking networks can achieve compelling, task-relevant behavior. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TNNLS.2018.2854291,IEEE Transactions on Neural Networks and Learning Systems,"It is now known that astrocytes modulate the activity at the tripartite synapses where indirect signaling via the retrograde messengers, endocannabinoids, leads to a localized self-repairing capability. In this paper, a self-repairing spiking astrocyte neural network (SANN) is proposed to demonstrate a distributed self-repairing capability at the network level. The SANN uses a novel learning rule that combines the spike-timing-dependent plasticity (STDP) and Bienenstock, Cooper, and Munro (BCM) learning rules (hereafter referred to as the BSTDP rule). In this learning rule, the synaptic weight potentiation is not only driven by the temporal difference between the presynaptic and postsynaptic neuron firing times but also by the postsynaptic neuron activity. We will show in this paper that the BSTDP modulates the height of the plasticity window to establish an input-output mapping (in the learning phase) and also maintains this mapping (via self-repair) if synaptic pathways become dysfunctional. It is the functional dependence of postsynaptic neuron firing activity on the height of the plasticity window that underpins how the proposed SANN self-repairs on the fly. The SANN also uses the coupling between the tripartite synapses and γ-GABAergic interneurons. This interaction gives rise to a presynaptic neuron frequency filtering capability that serves to route information, represented as spike trains, to different neurons in the subsequent layers of the SANN. The proposed SANN follows a feedforward architecture with multiple interneuron pathways and astrocytes modulate synaptic activity at the hidden and output neuronal layers. The self-repairing capability will be demonstrated in a robotic obstacle avoidance application, and the simulation results will show that the SANN can maintain learned maneuvers at synaptic fault densities of up to 80% regardless of the fault locations. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TNNLS.2021.3089023,IEEE Transactions on Neural Networks and Learning Systems,"Trajectory or path planning is a fundamental issue in a wide variety of applications. In this article, we show that it is possible to solve path planning on a maze for multiple start point and endpoint highly efficiently with a novel configuration of multilayer networks that use only weighted pooling operations, for which no network training is needed. These networks create solutions, which are identical to those from classical algorithms such as breadth-first search (BFS), Dijkstra's algorithm, or TD(0). Different from competing approaches, very large mazes containing almost one billion nodes with dense obstacle configuration and several thousand importance-weighted path endpoints can this way be solved quickly in a single pass on parallel hardware. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TNSE.2022.3195370,IEEE Transactions on Network Science and Engineering,"The papers in this special issue focus on collaborative machine learning for next generation intelligent applications. As a distributed learning technology, collaborative machine learning (CML) has been recently introduced to collaboratively train a model among multiple networking agents by using on-device computation. By integrating the high-potential CML with advanced emerging technologies, next-generation intelligent applications will provide more efficient, intelligent, and secure services, which may dramatically enhance the life experience of humans and revolutionize modern business. However, there are still many open challenges in this area. CML needs significant research efforts on theories, algorithms, architecture, and experiences of system deployment and maintenance. This special issue aims to offer a platform for researchers from both academia and industry to publish recent research findings and to discuss opportunities, challenges, and solutions related to collaborative machine learning. © 2022 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.1109/TNSM.2022.3169988,IEEE Transactions on Network and Service Management,"The tremendous achievements of Artificial Intelligence (AI) in computer vision, natural language processing, games and robotics, has extended the reach of the AI hype to other fields: In telecommunication networks, the long term vision is to let AI fully manage, and autonomously drive, all aspects of network operation. In this industry vision paper, we discuss challenges and opportunities of Autonomous Driving Network (ADN) driven by AI technologies. To understand how AI can be successfully landed in current and future networks, we start by outlining challenges that are specific to the networking domain, putting them in perspective with advances that AI has achieved in other fields. We then present a system view, clarifying how AI can be fitted in the network architecture. We finally discuss current achievements as well as future promises of AI in networks, mentioning a roadmap to avoid bumps in the road that leads to true large-scale deployment of AI technologies in networks. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TNSM.2022.3191746,ICRAN: Intelligent Control for Self-Driving RAN Based on Deep Reinforcement Learning,"Mobile networks are increasingly expected to support use cases with diverse performance expectations at a very high level of reliability. These expectations imply the need for approaches that timely detect and correct performance problems. However, current approaches often focus on optimizing a single performance metric. Here, we aim to address this gap by proposing a novel control framework that maximizes radio resources utilization and minimizes performance degradation in the most challenging part of cellular architecture that is the radio access network (RAN). We devise a method called Intelligent Control for Self-driving RAN (ICRAN) which involves two deep reinforcement learning based approaches that control the RAN in a centralized and a distributed way, respectively. ICRAN defines a dual-objective optimization goals that are achieved through a set of diverse control actions. Using extensive discrete event simulations, we confirm that ICRAN succeeds in achieving its design goals, showing a greater edge over competing approaches. We believe that ICRAN is implementable and can serve as an important point on the way to realizing self-driving mobile networks.",TOPIC
10.1109/TNSM.2024.3434328,A Framework for Dynamically Meeting Performance Objectives on a Service Mesh,"We present a framework for achieving end-to-end management objectives for multiple services that concurrently execute on a service mesh. We apply reinforcement learning (RL) techniques to train an agent that periodically performs control actions to reallocate resources. We develop and evaluate the framework using a laboratory testbed where we run information and computing services on a service mesh, supported by the Istio and Kubernetes platforms. We investigate different management objectives that include end-to-end delay bounds on service requests, throughput objectives, cost-related objectives, and service differentiation. Our framework supports the design of a control agent for a given management objective. The management objective is defined first and then mapped onto available control actions. Several types of control actions can be executed simultaneously, which allows for efficient resource utilization. Second, the framework separates the learning of the system model and the operating region from the learning of the control policy. By first learning the system model and the operating region from testbed traces, we can instantiate a simulator and train the agent for different management objectives. Third, the use of a simulator shortens the training time by orders of magnitude compared with training the agent on the testbed. We evaluate the learned policies on the testbed and show the effectiveness of our approach in several scenarios. In one scenario, we design a controller that achieves the management objectives with 50% less system resources than Kubernetes HPA autoscaling.",TOPIC
10.1109/TNSRE.2023.3264797,Monitoring Level of Hypnosis Using Stationary Wavelet Transform and Singular Value Decomposition Entropy With Feedforward Neural Network,"Classifying the patient’s depth of anesthesia (LoH) level into a few distinct states may lead to inappropriate drug administration. To tackle the problem, this paper presents a robust and computationally efficient framework that predicts a continuous LoH index scale from 0–100 in addition to the LoH state. This paper proposes a novel approach for accurate LoH estimation based on Stationary Wavelet Transform (SWT) and fractal features. The deep learning model adopts an optimized temporal, fractal, and spectral feature set to identify the patient sedation level irrespective of age and the type of anesthetic agent. This feature set is then fed into a multilayer perceptron network (MLP), a class of feed-forward neural networks. A comparative analysis of regression and classification is made to measure the performance of the chosen features on the neural network architecture. The proposed LoH classifier outperforms the state-of-the-art LoH prediction algorithms with the highest accuracy of 97.1% while utilizing minimized feature set and MLP classifier. Moreover, for the first time, the LoH regressor achieves the highest performance metrics ( $\text{R}^{{{2}}}=0.9$ , MAE = 1.5) as compared to previous work. This study is very helpful for developing highly accurate monitoring for LoH which is important for intraoperative and postoperative patients’ health.",TOPIC
10.1109/TNSRE.2024.3352416,Learning to Walk With Deep Reinforcement Learning: Forward Dynamic Simulation of a Physics-Based Musculoskeletal Model of an Osseointegrated Transfemoral Amputee,"This paper leverages the OpenSim physics-based simulation environment for the forward dynamic simulation of an osseointegrated transfemoral amputee musculoskeletal model, wearing a generic prosthesis. A deep reinforcement learning architecture, which combines the proximal policy optimization algorithm with imitation learning, is designed to enable the model to walk by using three different observation states. The first is a complete state that includes the agent’s kinematics, ground reaction forces, and muscle data; the second is a reduced state that only includes the kinematics and ground reaction forces; the third is an augmented state that combines the kinematics and ground reaction forces with a prediction of the muscle data generated by a fully-connected feed-forward neural network. The empirical results demonstrate that the model trained with the augmented observation state can achieve walking patterns with rewards and gait symmetry ratings comparable to those of the model trained with the complete observation state, while there are no symmetric walking patterns when using the reduced observation state. This paper shows the importance of including muscle data in a deep reinforcement learning architecture for the forward dynamic simulation of musculoskeletal models of transfemoral amputees.",TOPIC
10.1109/TNSRE.2024.3465243,Closed-Loop Deep Brain Stimulation With Reinforcement Learning and Neural Simulation,"Deep Brain Stimulation (DBS) is effective for movement disorders, particularly Parkinson’s disease (PD). However, a closed-loop DBS system using reinforcement learning (RL) for automatic parameter tuning, offering enhanced energy efficiency and the effect of thalamus restoration, is yet to be developed for clinical and commercial applications. In this research, we instantiate a basal ganglia-thalamic (BGT) model and design it as an interactive environment suitable for RL models. Four finely tuned RL agents based on different frameworks, namely Soft Actor-Critic (SAC), Twin Delayed Deep Deterministic Policy Gradient (TD3), Proximal Policy Optimization (PPO), and Advantage Actor-Critic (A2C), are established for further comparison. Within the implemented RL architectures, the optimized TD3 demonstrates a significant 67% reduction in average power dissipation when compared to the open-loop system while preserving the normal response of the simulated BGT circuitry. As a result, our method mitigates thalamic error responses under pathological conditions and prevents overstimulation. In summary, this study introduces a novel approach to implementing an adaptive parameter-tuning closed-loop DBS system. Leveraging the advantages of TD3, our proposed approach holds significant promise for advancing the integration of RL applications into DBS systems, ultimately optimizing therapeutic effects in future clinical trials.",TOPIC
10.1109/TPAMI.2023.3311912,IEEE Transactions on Pattern Analysis and Machine Intelligence,"Devising and analysing learning models for spatiotemporal network data is of importance for tasks including forecasting, anomaly detection, and multi-agent coordination, among others. Graph Convolutional Neural Networks (GCNNs) are an established approach to learn from time-invariant network data. The graph convolution operation offers a principled approach to aggregate information and offers mathematical analysis by exploring tools from graph signal processing. This analysis provides insights into the equivariance properties of GCNNs; spectral behaviour of the learned filters; and the stability to graph perturbations, which arise from support perturbations or uncertainties. However, extending the convolutional learning and respective analysis to the spatiotemporal domain is challenging because spatiotemporal data have more intrinsic dependencies. Hence, a higher flexibility to capture jointly the spatial and temporal dependencies is required to learn meaningful higher-order representations. Here, we leverage product graphs to represent the spatiotemporal dependencies in the data and introduce Graph-Time Convolutional Neural Networks (GTCNNs) as a principled architecture. We also introduce a parametric product graph to learn the spatiotemporal coupling. The convolution principle further allows a similar mathematical tractability as for GCNNs. In particular, the stability result shows GTCNNs are stable to spatial perturbations. owever, there is an implicit trade-off between discriminability and robustness; i.e., the more complex the model, the less stable. Extensive numerical results on benchmark datasets corroborate our findings and show the GTCNN compares favorably with state-of-the-art solutions. We anticipate the GTCNN to be a starting point for more sophisticated models that achieve good performance but are also fundamentally grounded. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TPAMI.2023.3328347,Understanding and Accelerating Neural Architecture Search With Training-Free and Theory-Grounded Metrics,"This work targets designing a principled and unified training-free framework for Neural Architecture Search (NAS), with high performance, low cost, and in-depth interpretation. NAS has been explosively studied to automate the discovery of top-performer neural networks, but suffers from heavy resource consumption and often incurs search bias due to truncated training or approximations. Recent NAS works Mellor et al. 2021, Chen et al. 2021, Abdelfattah et al. 2021 start to explore indicators that can predict a network's performance without training. However, they either leveraged limited properties of deep networks, or the benefits of their training-free indicators were not applied to more extensive search methods. By rigorous correlation analysis, we present a unified framework to understand and accelerate NAS, by disentangling “TEG” characteristics of searched networks – Trainability, Expressivity, Generalization – all assessed in a training-free manner. The TEG indicators could be scaled up and integrated with various NAS search methods, including both supernet and single-path NAS approaches. Extensive studies validate the effective and efficient guidance from our TEG-NAS framework, leading to both improved search accuracy and over 56% reduction in search time cost. Moreover, we visualize search trajectories on three landscapes of “TEG” characteristics, observing that a good local minimum is easier to find on NAS-Bench-201 given its simple topology, whereas balancing “TEG” characteristics is much harder on the DARTS space due to its complex landscape geometry.",TOPIC
10.1109/TPDS.2025.3550531,Reinforcement Learning-Driven Adaptive Prefetch Aggressiveness Control for Enhanced Performance in Parallel System Architectures,"In modern parallel system architectures, prefetchers are essential to mitigating the performance challenges posed by long memory access latencies. These architectures rely heavily on efficient memory access patterns to maximize system throughput and resource utilization. Prefetch aggressiveness is a central parameter in managing these access patterns; although increased prefetch aggressiveness can enhance performance for certain applications, it often risks causing cache pollution and bandwidth contention, leading to significant performance degradation in other workloads. While many existing prefetchers rely on static or simple built-in aggressiveness controllers, a more flexible, adaptive approach based on system-level feedback is essential to achieving optimal performance across parallel computing environments. In this paper, we introduce an Adaptive Prefetch Aggressiveness Control (APAC) framework that leverages Reinforcement Learning (RL) to dynamically manage prefetch aggressiveness in parallel system architectures. The APAC controller operates as an RL agent, which optimizes prefetch aggressiveness by dynamically responding to system feedback on prefetch accuracy, timeliness, and cache pollution. The agent receives a reward signal that reflects the impact of each adjustment on both performance and memory bandwidth, learning to adapt its control strategy based on workload characteristics. This data-driven adaptability makes APAC particularly well-suited for parallel architectures, where efficient resource management across cores is essential to scaling system performance. Our evaluation with the ChampSim simulator demonstrates that APAC effectively adapts to diverse workloads and system configurations, achieving performance gains of 6.73$\%$% in multi-core systems compared to traditional Feedback Directed Prefetching (FDP). By improving memory bandwidth utilization, reducing cache pollution, and minimizing inter-core interference, APAC significantly enhances prefetching performance in multi-core processors. These results underscore APAC’s potential as a robust solution for performance optimization in parallel system architectures, where efficient resource management is paramount for scaling modern processing environments.",TOPIC
10.1109/TPDS.2025.3602521,EdgeAIBus: AI-Driven Joint Container Management and Model Selection Framework for Heterogeneous Edge Computing,"Containerized Edge computing offers lightweight, reliable, and quick solutions to latency-critical Machine Learning (ML) and Deep Learning (DL) applications. Existing solutions considering multiple Quality of Service (QoS) parameters either overlook the intricate relation of QoS parameters or pose significant scheduling overheads. Furthermore, reactive decision-making can damage Edge servers at peak load, incurring escalated costs and wasted computations. Resource provisioning, scheduling, and ML model selection substantially influence energy consumption, user-perceived accuracy, and delay-oriented Service Level Agreement (SLA) violations. Addressing contrasting objectives and QoS simultaneously while avoiding server faults is highly challenging in the exposed heterogeneous and resource-constrained Edge continuum. In this work, we propose the EdgeAIBus framework that offers a novel joint container management and ML model selection algorithm based on Importance Weighted Actor-Learner Architecture to optimize energy, accuracy, SLA violations, and avoid server faults. First, Patch Time Series Transformer (PatchTST) is utilized for CPU usage predictions of Edge servers for its 8.51% Root Mean Squared Error and 5.62% Mean Absolute Error. Leveraging pipelined predictions, EdgeAIBus conducts consolidation, resource oversubscription, and ML/DL model switching with possible migrations to conserve energy, maximize utilization and user-perceived accuracy, and reduce SLA violations. Simulation results show EdgeAIBus oversubscribed 110% cluster-wide CPU with real usage up to 70%, conserved 14 CPU cores, incurred less than 1% SLA violations with 2.54% drop in inference accuracy against industry-led Model Switching Balanced load and Google Kubernetes Optimized schedulers. Google Kubernetes Engine experiments demonstrate 80% oversubscription, 14 CPU cores conservation, 1% SLA violations, and 3.81% accuracy loss against the counterparts. Finally, constrained setting experiment analysis shows that PatchTST and EdgeAIBus can produce decisions within 100 ms in a 1-core and 1 GB memory device.",TOPIC
10.1109/TQE.2022.3148667,DQRA: Deep Quantum Routing Agent for Entanglement Routing in Quantum Networks,"Quantum routing plays a key role in the development of the next-generation network system. In particular, an entangled routing path can be constructed with the help of quantum entanglement and swapping among particles (e.g., photons) associated with nodes in the network. From another side of computing, machine learning has achieved numerous breakthrough successes in various application domains, including networking. Despite its advantages and capabilities, machine learning is not as much utilized in quantum networking as in other areas. To bridge this gap, in this article, we propose a novel quantum routing model for quantum networks that employs machine learning architectures to construct the routing path for the maximum number of demands (source–destination pairs) within a time window. Specifically, we present a deep reinforcement routing scheme that is called Deep Quantum Routing Agent (DQRA). In short, DQRA utilizes an empirically designed deep neural network that observes the current network states to accommodate the network’s demands, which are then connected by a qubit-preserved shortest path algorithm. The training process of DQRA is guided by a reward function that aims toward maximizing the number of accommodated requests in each routing window. Our experiment study shows that, on average, DQRA is able to maintain a rate of successfully routed requests at above 80% in a qubit-limited grid network and approximately 60% in extreme conditions, i.e., each node can be repeater exactly once in a window. Furthermore, we show that the model complexity and the computational time of DQRA are polynomial in terms of the sizes of the quantum networks.",TOPIC
10.1109/TQE.2024.3464572,SPARQ: Efficient Entanglement Distribution and Routing in Space–Air–Ground Quantum Networks,"In this article, a space–air–ground quantum (SPARQ) network is developed as a means for providing a seamless on-demand entanglement distribution. The node mobility in SPARQ poses significant challenges to entanglement routing. Existing quantum routing algorithms focus on stationary ground nodes and utilize link distance as an optimality metric, which is unrealistic for dynamic systems, like SPARQ. Moreover, in contrast to the prior art that assumes homogeneous nodes, SPARQ encompasses heterogeneous nodes with different functionalities further complicates the entanglement distribution. To solve the entanglement routing problem, a deep reinforcement learning (RL) framework is proposed and trained using deep Q-network (DQN) on multiple graphs of SPARQ to account for the network dynamics. Subsequently, an entanglement distribution policy, third-party entanglement distribution (TPED), is proposed to establish entanglement between communication parties. A realistic quantum network simulator is designed for performance evaluation. Simulation results show that the TPED policy improves entanglement fidelity by 3% and reduces memory consumption by 50% compared with benchmark. The results also show that the proposed DQN algorithm improves the number of resolved teleportation requests by 39% compared with shortest path baseline and the entanglement fidelity by 2% compared with an RL algorithm that is based on long short-term memory. It also improved entanglement fidelity by 6% and 9% compared with state-of-the-art benchmarks. Moreover, the entanglement fidelity is improved by 15% compared with DQN trained on a snapshot of SPARQ. Additionally, SPARQ enhances the average entanglement fidelity by 23.5% compared with existing networks spanning only space and ground layers.",TOPIC
10.1109/TRO.2019.2922493,IEEE Transactions on Robotics,"State-of-the-art distributed algorithms for reinforcement learning rely on multiple independent agents, which simultaneously learn in parallel environments1 while asynchronously updating a common, shared policy. Moreover, decentralized control architectures (e.g., central pattern generators) can coordinate spatially distributed portions of an articulated robot to achieve system-level objectives. In this paper, we investigate the relationship between distributed learning and decentralized control by learning decentralized control policies for the locomotion of articulated robots in challenging environments. To this end, we present an approach that leverages the structure of the asynchronous advantage actor-critic (A3C) algorithm to provide a natural means of learning decentralized control policies on a single articulated robot. Our primary contribution shows individual agents in the A3C algorithm can be defined by independently controlled portions of the robot's body, thus enabling distributed learning on a single robot for efficient hardware implementation. We present results of closed-loop locomotion in unstructured terrains on a snake and a hexapod robot, using decentralized controllers learned offline and online, respectively, as a natural means to cover the different key applications of our approach. For the snake robot, we are optimizing the forward progression in unstructured environments, but for the hexapod robot, the goal is to maintain a stabilized body pose. Our results show that the proposed approach can be adapted to many different types of articulated robots by controlling some of their independent parts in a distributed manner, and the decentralized policy can be trained with high sample efficiency. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TRO.2020.2994002,IEEE Transactions on Robotics,"Among the main challenges in robotics, target-driven visual navigation has gained increasing interest in recent years. In this task, an agent has to navigate in an environment to reach a user specified target, only through vision. Recent fruitful approaches rely on deep reinforcement learning, which has proven to be an effective framework to learn navigation policies. However, current state-of-the-art methods require to retrain, or at least fine-tune, the model for every new environment and object. In real scenarios, this operation can be extremely challenging or even dangerous. For these reasons, we address generalization in target-driven visual navigation by proposing a novel architecture composed of two networks, both exclusively trained in simulation. The first one has the objective of exploring the environment, while the other one of locating the target. They are specifically designed to work together, while separately trained to help generalization. In this article, we test our agent in both simulated and real scenarios, and validate its generalization capabilities through extensive experiments with previously unseen goals and unknown mazes, even much larger than the ones used for training. 1552-3098 © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TRO.2021.3073771,IEEE Transactions on Robotics,"Designing artificial avatars able to interact with humans in a safe, smart, and natural way is a current open problem in control. Solving such an issue will allow the design of cyber-agents capable of cooperatively interacting with people in order to fulfil common joint tasks in a multitude of different applications. This is particularly relevant in the context of healthcare applications. Indeed, the use for rehabilitation has been proposed of artificial agents able to interact and coordinate their movements with those of patients suffering from social or motor disorders. Moreover, it has also been shown that the level of motor coordination between the avatar and the human patient is enhanced if the kinematic properties of the avatar's motion are similar to those of the individual it is interacting with. In this article, we discuss, first, a new method based on Markov chains to confer 'human motor characteristics' on the motion of a virtual agent so that it can coordinate its motion with that of a target individual while exhibiting specific kinematic properties. Then, we embed such synthetic model in a novel control architecture based on reinforcement learning to synthesize a cyber-agent able to mimic the behavior of a specific human performing a joint motor task with one or more individuals. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TSG.2021.3103156,IEEE Transactions on Smart Grid,"ACN-Sim is a data-driven, open-source simulation environment designed to accelerate research in the field of smart electric vehicle (EV) charging. It fills the need in this community for a widely available, realistic simulation environment in which researchers can evaluate algorithms and test assumptions. ACN-Sim provides a modular, extensible architecture, which models the complexity of real charging systems, including battery charging behavior and unbalanced three-phase infrastructure. It also integrates with a broader ecosystem of research tools. These include ACN-Data, an open dataset of EV charging sessions, which provides realistic simulation scenarios, and ACN-Live, a framework for field-testing charging algorithms. It also integrates with grid simulators like MATPOWER, PandaPower and OpenDSS, and OpenAI Gym for training reinforcement learning agents. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TSG.2024.3370822,IEEE Transactions on Smart Grid,"Synergies between advanced communications, computing and artificial intelligence are unraveling new directions of coordinated operation and resiliency in microgrids. On one hand, coordination among sources is facilitated by distributed, privacy-minded processing at multiple locations, whereas on the other hand, it also creates exogenous data arrival paths for adversaries that can lead to cyber-physical attacks amongst other reliability issues in the communication layer. This long-standing problem necessitates new intrinsic ways of exchanging information between converters through power lines to optimize the system's control performance. Going beyond the existing power and data co-transfer technologies that are limited by efficiency and scalability concerns, this paper proposes neuromorphic learning to implant communicative features using spiking neural networks (SNNs) at each node, which is trained collaboratively in an online manner simply using the power exchanges between the nodes. As opposed to the conventional neuromorphic sensors that operate with spiking signals, we employ an event-driven selective process to collect sparse data for training of SNNs. Finally, its multi-fold effectiveness and reliable performance is validated under simulation conditions with different microgrid topologies and components to establish a new direction in the sense-actuate-compute cycle for power electronic dominated grids and microgrids. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TSG.2025.3616402,CommonPower: A Framework for Safe Data-Driven Smart Grid Control,"The growing complexity of power system management has led to an increased interest in reinforcement learning (RL). To validate their effectiveness, RL algorithms have to be evaluated across multiple case studies. Case study design is an arduous task requiring the consideration of many aspects, among them the influence of available forecasts and the level of decentralization in the control structure. Furthermore, vanilla RL controllers cannot themselves ensure the satisfaction of system constraints, which makes devising a safeguarding mechanism a necessary task for every case study before deploying the system. To address these shortcomings, we introduce the Python tool CommonPower, the first general framework for the modeling and simulation of power system management tailored towards machine learning. Its modular architecture enables users to focus on specific elements without having to implement a simulation environment. Another unique contribution of CommonPower is the automatic synthesis of model predictive controllers and safeguards. Beyond offering a unified interface for single-agent RL, multi-agent RL, and optimal control, CommonPower includes a training pipeline for machine-learning-based forecasters as well as a flexible mechanism for incorporating feedback of safeguards into the learning updates of RL controllers.",TOPIC
10.1109/TSMCA.2003.817394,"IEEE Transactions on Systems, Man, and Cybernetics Part A:Systems and Humans","This paper presents a new hybrid, synergistic approach in applying computational intelligence concepts to implement a cooperative, hierarchical, multiagent system for real-time traffic signal control of a complex traffic network. The large-scale traffic signal control problem is divided into various subproblems, and each subproblem is handled by an intelligent agent with fuzzy neural decision-making module. The decisions made by lower-level agents are mediated by their respective higher-level agents. Through adopting a cooperative distributed problem solving approach, coordinated control by the agents is achieved. In order for the multiagent architecture to adapt itself continuously to the dynamically changing problem domain, a multistage online learning process for each agent is implemented involving reinforcement learning, learning rate and weight adjustment as well as dynamic update of fuzzy relations using evolutionary algorithm. The test bed used for this research is a section of the Central Business District of Singapore. The performance of the proposed multiagent architecture is evaluated against the set of signal plans used by the current real-time adaptive traffic control system. The multiagent architecture produces significant improvements in the conditions of the traffic network, reducing the total mean delay by 40% and total vehicle stoppage time by 50%. © 2008 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TSP.2021.3092336,IEEE Transactions on Signal Processing,"Graph neural networks (GNNs) model nonlinear representations in graph data with applications in distributed agent coordination, control, and planning among others. Current GNN architectures assume ideal scenarios and ignore link fluctuations that occur due to environment, human factors, or external attacks. In these situations, the GNN fails to address its distributed task if the topological randomness is not considered accordingly. To overcome this issue, we put forth the stochastic graph neural network (SGNN) model: a GNN where the distributed graph convolution module accounts for the random network changes. Since stochasticity brings in a new learning paradigm, we conduct a statistical analysis on the SGNN output variance to identify conditions the learned filters should satisfy for achieving robust transference to perturbed scenarios, ultimately revealing the explicit impact of random link losses. We further develop a stochastic gradient descent (SGD) based learning process for the SGNN and derive conditions on the learning rate under which this learning process converges to a stationary point. Numerical results corroborate our theoretical findings and compare the benefits of SGNN robust transference with a conventional GNN that ignores graph perturbations during learning. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TUFFC.2022.3161719,Interpretable Machine Learning for Characterization of Focal Liver Lesions by Contrast-Enhanced Ultrasound,"This work proposes an interpretable radiomics approach to differentiate between malignant and benign focal liver lesions (FLLs) on contrast-enhanced ultrasound (CEUS). Although CEUS has shown promise for differential FLLs diagnosis, current clinical assessment is performed only by qualitative analysis of the contrast enhancement patterns. Quantitative analysis is often hampered by the unavoidable presence of motion artifacts and by the complex, spatiotemporal nature of liver contrast enhancement, consisting of multiple, overlapping vascular phases. To fully exploit the wealth of information in CEUS, while coping with these challenges, here we propose combining features extracted by the temporal and spatiotemporal analysis in the arterial phase enhancement with spatial features extracted by texture analysis at different time points. Using the extracted features as input, several machine learning classifiers are optimized to achieve semiautomatic FLLs characterization, for which there is no need for motion compensation and the only manual input required is the location of a suspicious lesion. Clinical validation on 87 FLLs from 72 patients at risk for hepatocellular carcinoma (HCC) showed promising performance, achieving a balanced accuracy of 0.84 in the distinction between benign and malignant lesions. Analysis of feature relevance demonstrates that a combination of spatiotemporal and texture features is needed to achieve the best performance. Interpretation of the most relevant features suggests that aspects related to microvascular perfusion and the microvascular architecture, together with the spatial enhancement characteristics at wash-in and peak enhancement, are important to aid the accurate characterization of FLLs.",TOPIC
10.1109/TVLSI.2025.3592300,IEEE Transactions on Very Large Scale Integration (VLSI) Systems,"To improve the system performance of multiprocessor system-on-chips (MPSoCs), modern processors have several built-in hardware features, such as prefetchers, which respond to short-term variations in processor load that occurs on a submillisecond scale. However, even the latest dynamic (voltage) frequency scaling governors using reinforcement learning (RL) are implemented in software and, thus, cannot take advantage of these variations. In this work, we propose a hardware RL agent, augmented with preemptive shielding and eligibility traces, to optimize the execution of deadline-bound quality-of-service (QoS) tasks in mixed-critical environments. We demonstrate the features of our algorithm in a hardware-in-the-loop simulation by running LLVM’s single-source benchmarks on SparcV8 processors. We also present our field-programmable gate array (FPGA) implementation with optimized resource usage and timing performance achieved through quantization and approximation. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TVT.2020.3034800,Voronoi-Based Multi-Robot Autonomous Exploration in Unknown Environments via Deep Reinforcement Learning,"Autonomous exploration is an important application of multi-vehicle systems, where a team of networked robots are coordinated to explore an unknown environment collaboratively. This technique has earned significant research interest due to its usefulness in search and rescue, fault detection and monitoring, localization and mapping, etc. In this paper, a novel cooperative exploration strategy is proposed for multiple mobile robots, which reduces the overall task completion time and energy costs compared to conventional methods. To efficiently navigate the networked robots during the collaborative tasks, a hierarchical control architecture is designed which contains a high-level decision making layer and a low-level target tracking layer. The proposed cooperative exploration approach is developed using dynamic Voronoi partitions, which minimizes duplicated exploration areas by assigning different target locations to individual robots. To deal with sudden obstacles in the unknown environment, an integrated deep reinforcement learning based collision avoidance algorithm is then proposed, which enables the control policy to learn from human demonstration data and thus improve the learning speed and performance. Finally, simulation and experimental results are provided to demonstrate the effectiveness of the proposed scheme.",TOPIC
10.1109/TVT.2021.3099557,IEEE Transactions on Vehicular Technology,"5G is envisioned to simultaneously provide diverse service types with heterogeneous needs under very different application scenarios and business models. Therefore, network slicing is included as a key feature of the 5G architecture to allow sharing a common infrastructure among different tenants, such as mobile communication providers, vertical market players, etc. In order to provide the Radio Access Network (RAN) with network slicing capabilities, mechanisms that efficiently distribute the available capacity among the different tenants while satisfying their needs are required. For this purpose, this paper proposes a multi-agent reinforcement learning approach for RAN capacity sharing. It makes use of the Deep Q-Network algorithm in a way that each agent is associated to a different tenant and learns the capacity to be provided to this tenant in each cell while ensuring that the service level agreements are satisfied and that the available radio resources are efficiently used. The consideration of multiple agents contributes to a better scalability and higher learning speed in comparison to single-agent approaches. In this respect, results show that the policy learnt by the agent of one tenant can be generalised and directly applied by other agents, thus reducing the complexity of the training and making the proposed solution easily scalable, e.g., to add new tenants in the system. The proposed approach is well aligned with the on-going 3GPP standardization work and guidelines for the parametrization of the solution are provided, thus enforcing its practical applicability. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TVT.2022.3218158,IEEE Transactions on Vehicular Technology,"Network slicing enables multiple virtual networks to be instantiated and customized to meet heterogeneous use case requirements over 5G and beyond network deployments. However, most of the solutions available today face scalability issues when considering many slices, due to centralized controllers requiring a holistic view of the resource availability and consumption over different networking domains. In order to tackle this challenge, we design a hierarchical architecture to manage network slices resources in a federated manner. Driven by the rapid evolution of deep reinforcement learning (DRL) schemes and the Open RAN (O-RAN) paradigm, we propose a set of traffic-Aware local decision agents (DAs) dynamically placed in the radio access network (RAN). These federated decision entities tailor their resource allocation policy according to the long-Term dynamics of the underlying traffic, defining specialized clusters that enable faster training and communication overhead reduction. Indeed, aided by a traffic-Aware agent selection algorithm, our proposed Federated DRL approach provides higher resource efficiency than benchmark solutions by quickly reacting to end-user mobility patterns and reducing costly interactions with centralized controllers. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TVT.2024.3359426,IEEE Transactions on Vehicular Technology,"One of the security issues in a wireless network is jamming attacks, where the jammer causes congestion and significant decrement in the network throughput by obstructing channels and disrupting user signals. Recent works have proposed using a deep-reinforcement learning (DRL) model to confront the jamming attacker due to its capability in predicting the jammer decisions and pattern recognition. Training a DRL model from scratch may take a long time. We first propose a recurrent neural network architecture to minimize the number of parameters for training a DRL model. We further propose a transfer learning (TL) approach to enable the DRL agent to learn fast in dynamic wireless networks to confront jamming attacks effectively. To make our proposed TL method adaptive to different network environments, we propose a novel method to quantitatively measure the difference between the source and target domains, using an integrated feature extractor. Afterward, based on the measured difference, we can choose an optimal setting for the TL model. We also show that the proposed TL method can effectively reduce the training time for the DRL model and outperforms other existing TL methods. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TVT.2024.3385494,DRL-Assisted Dynamic Subconnected Hybrid Precoding for Multi-Layer THz mMIMO-NOMA System,"Massive multiple-input multiple-output (mMIMO) techniques can be combined with the non-orthogonal multiple access (NOMA) scheme in terahertz (THz) communication to achieve multiplexing gains and satisfy the ultra-high capacity and massive connectivity requirements. However, the development of a near-optimal solution for energy and spectral efficiency problems in a dynamic wireless cellular environment remains challenging. In this paper, a cooperative THz mMIMO-NOMA enabled base station is established to optimize the power consumption and maximize the spectral efficiency. A multi-layer mMIMO antenna architecture is used to perform dynamic sub-connected hybrid precoding in each layer. The fuzzy c-means clustering algorithm is used to group densely located users into clusters to efficiently use the power coefficients. To optimize the power distribution constraints and coordination of the hybrid precoding structure, a multi-agent deep reinforcement learning algorithm is developed, which operates in a distributive manner. Each base station layer involves an agent that trains a deep Q-network, and optimal actions are executed by sharing exchangeable network parameters among layers. The simulation results indicate that the proposed scheme is able to learn the trade-off between maximization of the energy efficiency and overall system capacity.",TOPIC
10.1109/TVT.2024.3415656,IEEE Transactions on Vehicular Technology,"With the deployment of the fifth generation (5G) of cellular networks, the focus of the information society has switched to the next era in which the limitations of 5G will be addressed, and the emerging services and applications will be satisfied. The sixth generation (6G) of wireless networks is envisioned to answer all demands of the next decade, which is only possible with advances in network design and management. This paper first presents a 6G-based network architecture that deploys emerging technologies, including Open-Radio Access Network (O-RAN) and Cell-Free massive Multiple-Input-Multiple-Output (CF mMIMO). Then, a hierarchical network slicing and resource management approach compatible with the presented architecture is defined. The proposed novel Reinforcement Learning (RL)-based scheme benefits from the openness of O-RAN to provide two levels of centralized multi-agent decision-making and decentralized single-agent execution for choosing proper service types by following the objective of maximizing the system capacity while guaranteeing the defined Quality of Service (QoS). To demonstrate the performance of the management method, Deep RL (DRL)-based algorithms for each level are proposed. Finally, the presented simulation results illustrate the effectiveness of the proposed solution in terms of peak data rate, user-experienced data rate, and latency. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TVT.2024.3483288,IEEE Transactions on Vehicular Technology,"The escalating demands of next-generation, beyond-5G services necessitate innovative approaches to dynamic resource management, critical for satisfying end-user expectations and maintaining quality of service (QoS). This study leverages the Open Radio Access Network (O-RAN) architecture's flexibility and programmability to introduce a novel deep reinforcement learning (DRL) strategy for QoS-aware intra-slice resource allocation. By employing intelligent agents and a Deep Q-Network (DQN)-based framework, our approach precisely tailors resource distribution within O-RAN, optimizing for enhanced mobile broadband (eMBB) and ultra-reliable low-latency communications (URLLC) slices. The proposed method, featuring intelligent QoS-aware resource allocation (IQRA) and its low-complexity variant (LIQRA), demonstrates significant throughput improvements for eMBB by 11.5% compared to state-of-the-art (SOTA) methods and reduces URLLC latency by 19.94% and 16.54%, achieving up to 45.5% lower latency than baseline. A streamlined algorithm effectively reduces computational complexity, ensuring robust performance under resource constraints. Simulation results underscore the algorithm's ability to substantially enhance 5G network slice performance, offering a parameterized solution for user association in O-RAN networks using DRL. This research not only meets high key performance indicators (KPIs) but also advances edge intelligence, fostering a more responsive network ecosystem. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TVT.2024.3520637,Cooperative Multi-Agent Deep Reinforcement Learning for Dynamic Task Execution and Resource Allocation in Vehicular Edge Computing,"Computer vision plays a crucial role in enabling connected autonomous vehicles (CAVs) to observe and comprehend their surroundings. The computer vision tasks are typically based on convolutional neural networks (CNNs). However, CNNs often require significant processing power. Techniques like early exiting and split computing enhance CNN task execution latency and adaptability to varying environmental conditions. Since the split computing introduces additional overhead for offloading of the task from the CAV to an edge servers, we incorporate multiple autoencoders within each split point to enhance the adaptability of splitting under varying environmental conditions. However, the autoencoders introduce an additional layer of complexity related to the selection of the optimal compression strategy alongside the splitting and exiting decisions. To tackle this challenge, we introduce a novel approach based on the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm. This algorithm dynamically and jointly determines the most suitable exit point, split point, and autoencoder. Furthermore, the MADDPG-based approach considers other CAVs when selecting action, promoting cooperation among CAVs. Our results demonstrate that the proposed approach reduces latency up to 44.4% while maintaining at least comparable or even higher accuracy of the computed vision outcome compared to the state-of-the-art solutions.",TOPIC
10.1109/TWC.2022.3153175,IEEE Transactions on Wireless Communications,"This paper investigates the problem of distributed resource management in two-tier heterogeneous networks, where each cell selects its joint device association, spectrum allocation, and power allocation strategy based only on locally-observed information without any central controller. As the optimization problem with devices' quality-of-service (QoS) constraints is non-convex and NP-hard, we model it as a Markov decision process (MDP). Considering the fact that the network is highly complex with large state and action spaces, a multi-agent dueling deep-Q network-based algorithm combined with distributed coordinated learning is proposed to effectively learn the optimized intelligent resource management policy, where the algorithm adopts dueling deep network to learn the action-value distribution by estimating both the state-value and action advantage functions. Under the distributed coordinated learning manner and dueling architecture, the learning algorithm can rapidly converge to the optimized policy. Simulation results demonstrate that the proposed distributed coordinated learning algorithm outperforms other existing learning algorithms in terms of learning efficiency, network data rate, and QoS satisfaction probability. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1109/TWC.2024.3396273,Empowering Traffic Steering in 6G Open RAN With Deep Reinforcement Learning,"The sixth-generation (6G) wireless network landscape is evolving toward enhanced programmability, virtualization, and intelligence to support heterogeneous use cases. The O-RAN Alliance is pivotal in this transition, introducing a disaggregated architecture and open interfaces within the 6G network. Our paper explores an intelligent traffic steering (TS) scheme within the Open radio access network (RAN) architecture, aimed at improving overall system performance. Our novel TS algorithm efficiently manages diverse services, improving shared infrastructure performance amid unpredictable demand fluctuations. To address challenges like varying channel conditions, dynamic traffic demands, we propose a multi-layer optimization framework tailored to different timescales. Techniques such as long-short-term memory (LSTM), heuristics, and multi-agent deep reinforcement learning (MADRL) are employed within the non-real-time (non-RT) RAN intelligent controller (RIC). These techniques collaborate to make decisions on a larger timescale, defining custom control applications such as the intelligent TS-xAPP deployed at the near-real-time (near-RT) RIC. Meanwhile, optimization on a smaller timescale occurs at the RAN layer after receiving inferences/policies from RICs to address dynamic environments. The simulation results confirm the system’s effectiveness in intelligently steering traffic through a slice-aware scheme, improving eMBB throughput by an average of 99.42% over slice isolation.",TOPIC
10.1109/VTC2021-Spring51267.2021.9448889,IEEE Vehicular Technology Conference,"One of the key features of the 5G architecture is network slicing, which allows the simultaneous support of diverse service types with heterogeneous requirements over a common network infrastructure. In order to support this feature in the Radio Access Network (RAN), it is required to have capacity sharing mechanisms that distribute the available capacity in each cell among the existing RAN slices while satisfying their requirements and efficiently using the available resources. Deep Reinforcement Learning (DRL) techniques are good candidates to deal with the complexity of capacity sharing in multi-cell scenarios where the traffic in the different cells can be heterogeneously distributed in the time and space domains. In this paper, a multi-agent reinforcement learning-based solution for capacity sharing in multi-cell scenarios is discussed and assessed under heterogeneous traffic conditions. Results show the capability of the solution to satisfy the requirements of the RAN slices while using the resources in the different cells efficiently. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/VTCSpring.2015.7146076,IEEE Vehicular Technology Conference,"In a self-organized Long Term Evolution (LTE) network, different Self-Organizing Network (SON) functions or different instances of the same SON function can execute parallel actions, which interact or collide among each other. When the effect of the interaction negatively affects the performances of the system, this is referred to in 3rd Generation Partnership Project (3GPP) as a SON conflict, which needs to be handled by means of a self-coordination framework. We focus on the self-coordination of different actions taken by two SON functions in a distributed SON (D-SON) architecture, which implements the SON functions at the edges of the network. We propose a multi-agent framework where each Enhanced Node Base station (eNB), is an autonomous agent modeled by means of a Markov Decision Process (MDP). We subdivide this global Markov Decision problem onto simpler subMDPs modeling the different SON functions. Each sub-problem is defined as an MDP and solved independently, and their individual policies are combined to obtain a global policy. This combined policy can execute several actions per state in parallel, but can introduce policy conflicts, which model the mentioned SON conflicts. Each subMDP is solved by means of a Reinforcement Learning (RL) approach. We focus on the SON conflict generated by the concurrent execution of Coverage and Capacity Optimization (CCO) and Inter-Cell Interference Coordination (ICIC) SON functions, which may require to update the same parameter, i.e. the transmission power level. Coordination among different actions is achieved by means of a coordination game where the players are the subMDPs and the actions and rewards are those provided by the independent RL solutions. Performance evaluation is carried out in a ns3 release 10 compliant LTE system simulator and it shows that our self-coordination approach provides satisfying solutions in terms of system performances for both the conflicting SON functions. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/WACV45572.2020.9093562,,"Incremental learning is useful if an AI agent needs to integrate data from a stream. The problem is non trivial if the agent runs on a limited computational budget and has a bounded memory of past data. In a deep learning approach, the constant computational budget requires the use of a fixed architecture for all incremental states. The bounded memory generates imbalance in favor of new classes and a prediction bias toward them appears. This bias is commonly countered by introducing a data balancing step in addition to the basic network training. We depart from this approach and propose simple but efficient scaling of past classifiers' weights to make them more comparable to those of new classes. Scaling exploits incremental state statistics and is applied to the classifiers learned in the initial state of classes to profit from all their available data. We also question the utility of the widely used distillation loss component of incremental learning algorithms by comparing it to vanilla fine tuning in presence of a bounded memory. Evaluation is done against competitive baselines using four public datasets. Results show that the classifier weights scaling and the removal of the distillation are both beneficial. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/WCNCW48565.2020.9124723,,"This paper presents a control solution for the optimal network selection problem in 5G heterogeneous networks. The control logic proposed is based on multi-agent Friend-or-Foe Q-Learning, allowing the design of a distributed control architecture that sees the various access points compete for the allocation of the connection requests. Numerical simulations validate conceptually the approach, developed in the scope of the EU-Korea project 5G-ALLSTAR. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1109/WD.2009.5449648,,"Broadband access to the Internet at home was the first step in the emergence of so called Home Networks. In a close future, the number of appliance connected will rise and the network will become the home backbone. This lead us to a mesh architecture, in which routing will be mandatory. This paper introduces a complete system to, first, pilot the forwarding in order to ensure a proper quality of experience; and secondly to monitor and diagnosis the network from the ISP-network in order to reduce OPEX. The system is based on the knowledge plane composed of agents embedded on devices. ©2009 IEEE. © 2010 Elsevier B.V., All rights reserved.",TOPIC
10.1109/WIIAT50758.2020.00085,,"Static word embeddings encode word associations, extensively utilized in downstream NLP tasks. Although prior studies have discussed the nature of such word associations in terms of biases and lexical regularities captured, the variation in word associations based on the embedding training procedure remains in obscurity. This work aims to address this gap by assessing attributive word associations across five different static word embedding architectures, analyzing the impact of the choice of the model architecture, context learning flavor and training corpora. Our approach utilizes a semi-supervised clustering method to cluster annotated proper nouns and adjectives, based on their word embedding features, revealing underlying attributive word associations formed in the embedding space, without introducing any confirmation bias. Our results reveal that the choice of the context learning flavor during embedding training (CBOW vs skip-gram) impacts the word association distinguishability and word embeddings' sensitivity to deviations in the training corpora. Moreover, it is empirically shown that even when trained over the same corpora, there is significant inter-model disparity and intra-model similarity in the encoded word associations across different word embedding models, portraying specific patterns in the way the embedding space is created for each embedding architecture. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1109/WiMob61911.2024.10770457,"International Conference on Wireless and Mobile Computing, Networking and Communications","Public safety and first-responder networks require technologies that outperform current emergency networks. 5G and Wi-Fi architectures seem to be promising solutions for those environments. However, seamless integration of these wireless networks needs to be well investigated to benefit from the advan-tages of both networks and to fulfill the firefighter requirements. For this purpose, we propose a gateway selection algorithm for firefighter interventions. Proximal Policy Optimization, a well-known reinforcement learning strategy, is used to define and train the agent. Simulation results demonstrate that the proposed framework outperforms the Host Network Association scheme defined in the Optimized Link State Routing Protocol in terms of network throughput and packet drop rate. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1111/jcal.13046,Journal of Computer Assisted Learning,"Background: The integration of Text-to-Speech (TTS) and virtual reality (VR) technologies in K-12 education is an emerging trend. However, little is known about how students perceive these technologies and whether these technologies effectively facilitate learning. Objectives: This study aims to investigate the perception and effectiveness of TTS voices and VR agents in a K-12 classroom setting, with a focus on information recall. Methods: Using a recent TTS architecture, we developed four different synthetic voices based on 5, 10, 15 and 20 h of training materials. Two experiments were conducted involving students in a K-12 setting. The first experiment examined students' evaluations of TTS voices with varying hours of training material and the impact on information recall. The second experiment assessed the effect of pairing TTS voices with a VR agent on students' perception and recall performance. Results and Conclusions: Human voices received superior quality ratings over TTS voices within the classroom context. The integration of a VR agent was found to enhance the perception of TTS voices, aligning with existing literature on the positive impact of virtual agents on speech synthesis. However, this incorporation did not translate to improved recall, suggesting that the student focus may have been compromised by the VR agent's novelty and its design limitations. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1111/mice.13463,Computer-Aided Civil and Infrastructure Engineering,"Coordinating a platoon of connected and automated vehicles significantly improves traffic efficiency and safety. Current platoon control methods prioritize consistency and convergence performance but overlook the inherent interdependence between the platoon and the the non-connected leading vehicle. This oversight constrains the platoon's adaptability in car-following scenarios, resulting in suboptimal optimization performance. To address this issue, this paper proposed a platoon control framework based on multi-agent reinforcement learning, aiming to integrate cooperative optimization with platoon tracking behavior and internal coordination strategies. This strategy employs a bidirectional cooperative optimization mechanism to effectively decouple the platoon's tracking behavior from its internal coordination control, and then recouple it in a multi-objective optimized manner. Additionally, it leverages long short-term memory networks to accurately capture and manage the platoon's dynamic nature over time, aiming to achieve enhanced optimization outcomes. The simulation results demonstrate that the proposed method effectively improves the platoon's cooperative effect and car-following adaptability. Compared to the consensus control strategy, it reduces the average spacing error by 8.3%. Furthermore, the average length of the platoon decreases by 19.1%. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1115/DSCC2019-9097,,"Operation in a real world traffic requires the ability to planmotion in complex environments (multiple moving participants)from autonomous vehicles. Navigation through such environments necessitates the provision of the right search space forthe trajectory or maneuver planners so that the safest motion forthe ego vehicle can be identified. Analyzing risks based on thepredicted trajectories of all traffic participants (given the current state of the environment and its participants) aids in theproper formulation of this search space. This study introducesa fresh taxonomy of safety and risk that an autonomous vehicleshould be capable of handling. It formulates a reference system architecture for implementation as well as describes a novelway of identifying and predicting the behaviors of other trafficparticipants utilizing classic Multi Model Adaptive Estimation(MMAE). Detailed simulation results and a discussion about theassociated tuning of the implemented model conclude this work. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.11159/mvml25.150,Proceedings of the World Congress on Electrical Engineering and Computer Systems and Science,"Accurate segmentation of breast cancer lesions in medical imaging is pivotal for diagnosis, treatment planning, and monitoring progression [1]. While U-Net architectures have become a cornerstone in medical image segmentation, redundant feature maps in convolutional layers often hinder performance by diluting critical tumor-related information [2]. This study addresses this limitation by integrating the Dynamic Whale Optimization Algorithm (DWOA)—a metaheuristic technique inspired by humpback whale foraging behavior—into a U-Net model [3]. The primary objective is to enhance segmentation accuracy through dynamic channel selection during training, optimizing feature relevance while maintaining computational efficiency and model interpretability. The proposed architecture modified the U-Net framework by embedding a custom WOA-based channel selection layer within encoder blocks [4]. During training, the WOA module iteratively refined channel selections by evaluating feature map activations, prioritizing those most discriminative for tumor boundaries and texture. The algorithm initializes ""whale"" agents representing candidate channel subsets, which evolve over iterations using exploration-exploitation strategies. Channels associated with higher activation magnitudes were weighted dynamically during max-pooling to amplify their contribution. The encoder-decoder structure retained spatial hierarchies through skip connections, while transpose convolutions in the decoder enable precise localization. The model was trained on breast ultrasound and mammography [5] datasets using IoU loss, with evaluation metrics including the Dice Coefficient and Intersection-over-Union (IoU) to quantify overlap with ground truth masks. Unlike static or attention-based methods, the WOA layer adaptively selects channels by balancing global exploration (diversifying candidate subsets) and local exploitation (refining high-scoring solutions). This reduces redundancy and focuses computation on tumor-salient features. Channel selection occurs exclusively during training, ensuring inference efficiency. Selected channels are encoded into a binary mask, combined with batch normalization to stabilize learning. Additionally, each encoder block processes features via dual convolutional layers, followed by WOA-driven selection and weighted pooling. The bottleneck layer expands the receptive field to capture contextual tumor features before reconstruction. Experimental results demonstrate a 4.1% improvement in IoU over the baseline U-Net, alongside a 3.05% increase in Dice Coefficient, validating the efficacy of WOA-driven feature optimization. The model exhibits robustness in heterogeneous tumor morphology and low-contrast imaging scenarios, achieving faster convergence due to reduced parameter redundancy. Computational overhead during training remains manageable, with a 12% increase in time per epoch compared to the standard U-Net, while inference latency matches conventional architectures. These advancements address critical challenges in medical imaging, such as generalizability across diverse datasets and interpretability of feature importance, bridging the gap between complex deep learning models and clinical usability. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1117/12.2515407,Proceedings of SPIE - The International Society for Optical Engineering,"Ionospheric conditions are variable in nature and can cause destructive interference to transmissions made in the High Frequency (HF) band, which ranges from 3-30 MHz. This poses a problem as the HF band is a critical fre-quency range for various applications (i.e. emergency, military). To manage these dynamic conditions, intelligent techniques should be implemented at the transmitter and receiver to properly maintain reliable communications. In this paper, we present work deriving components of a cognitive HF transceiver with agents called cognitive engines (CEs) operating at the transmitter and receiver. At the transmitter, cognition is employed to determine the combination of modulation and coding techniques that maximize throughput. At the receiver, cognition is implemented to derive the best parameters for equalization (i.e. tap length, step size, filter type, etc.) Results are presented showing that the individual components are able to satisfy their objectives. A discussion is also provided surveying recent research efforts pertaining to the development of cognitive methods for the Automatic Link Establishment (ALE) protocol, a common networking methodology for HF stations. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1117/12.820141,Proceedings of SPIE - The International Society for Optical Engineering,"Effective defense against chemical and biological threats requires an ""end-to-end"" strategy that encompasses the entire problem space, from threat assessment and target hardening to response planning and recovery. A key element of the strategy is the definition of appropriate system requirements for surveillance and detection of threat agents. Our end-toend approach to venue chem/bio defense is captured in the Facilities Weapons of Mass Destruction Decision Analysis Capability (FacDAC), an integrated system-of-systems toolset that can be used to generate requirements across all stages of detector development. For example, in the early stage of detector development the approach can be used to develop performance targets (e.g., sensitivity, selectivity, false positive rate) to provide guidance on what technologies to pursue. In the development phase, after a detector technology has been selected, the approach can aid in determining performance trade-offs and down-selection of competing technologies. During the application stage, the approach can be employed to design optimal defensive architectures that make the best use of available technology to maximize system performance. This presentation will discuss the end-to-end approach to defining detector requirements and demonstrate the capabilities of the FacDAC toolset using examples from a number of studies for the Department of Homeland Security. © 2009 SPIE. © 2009 Elsevier B.V., All rights reserved.",TOPIC
10.1117/12.850588,Proceedings of SPIE - The International Society for Optical Engineering,"We address supporting unanticipated users and uses of limited information resources (sensors, databases, weapons - any resource intrinsically tied to digital information) in a timely and efficient fashion. Platform-centric systems often preclude users and uses not identified when the system was developed and deployed. Net-centric approaches, however, can address these problems by allowing services and information to be discovered and accessed at run-time. We have developed a resource brokering service that uses net-centric principles and semantic metadata to enable multi-domain information and resource sharing and support for unanticipated users and uses. The resource brokering service uses federated brokering agents and a modular software component framework for dynamically composing and tasking heterogeneous resources including sensors, data feeds, processors, archived data, networks, and even analysts into resilient, mission-oriented workflows. The resource brokering service is applicable to multiple sense-decide-act military domains including missile defense, space situation awareness, ISR, border protection, and cyber defense. In this paper we present a concept and architecture for resource brokering and describe current applications. Our architecture is aligned with the U.S. DoD's NCES (Net-Centric Enterprise Services). © 2010 Copyright SPIE - The International Society for Optical Engineering. © 2011 Elsevier B.V., All rights reserved.",TOPIC
10.1128/msystems.00345-23,mSystems,"Antimicrobial peptides (AMPs) are a promising alternative to antibiotics to combat drug resistance in pathogenic bacteria. However, the development of AMPs with high potency and specificity remains a challenge, and new tools to evaluate antimicrobial activity are needed to accelerate the discovery process. Therefore, we proposed MBC-Attention, a combination of a multi-branch convolution neural network architecture and attention mechanisms to predict the experimental minimum inhibitory concentration of peptides against Escherichia coli. The optimal MBC-Attention model achieved an average Pearson correlation coefficient (PCC) of 0.775 and a root mean squared error (RMSE) of 0.533 (log μM) in three independent tests of randomly drawn sequences from the data set. This results in a 5–12% improvement in PCC and a 6–13% improvement in RMSE compared to 17 traditional machine learning models and 2 optimally tuned models using random forest and support vector machine. Ablation studies confirmed that the two proposed attention mechanisms, global attention and local attention, contributed largely to performance improvement. IMPORTANCE Antimicrobial peptides (AMPs) are potential candidates for replacing conventional antibiotics to combat drug resistance in pathogenic bacteria. Therefore, it is necessary to evaluate the antimicrobial activity of AMPs quantitatively. However, wet-lab experiments are labor-intensive and time-consuming. To accelerate the evaluation process, we develop a deep learning method called MBC-Attention to regress the experimental minimum inhibitory concentration of AMPs against Escherichia coli. The proposed model outperforms traditional machine learning methods. Data, scripts to reproduce experiments, and the final production models are available on GitHub. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1128/msystems.00606-23,mSystems,"Acinetobacter baumannii causes severe infections in humans, resists multiple antibiotics, and survives in stressful environmental conditions due to modulations of its complex transcriptional regulatory network (TRN). Unfortunately, our global understanding of the TRN in this emerging opportunistic pathogen is limited. Here, we apply independent component analysis, an unsupervised machine learning method, to a compendium of 139 RNA-seq data sets of three multidrug-resistant A. baumannii international clonal complex I strains (AB5075, AYE, and AB0057). This analysis allows us to define 49 independently modulated gene sets, which we call iModulons. Analysis of the identified A. baumannii iModulons reveals validating parallels to previously defined biological operons/regulons and provides a framework for defining unknown regulons. By utilizing the iModulons, we uncover potential mechanisms for a RpoS-independent general stress response, define global stress-virulence trade-offs, and identify conditions that may induce plasmid-borne multidrug resistance. The iModulons provide a model of the TRN that emphasizes the importance of transcriptional regulation of virulence phenotypes in A. baumannii. Furthermore, they suggest the possibility of future interventions to guide gene expression toward diminished pathogenic potential. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1128/mSystems.01013-20,mSystems,"Identification of transcriptional regulatory elements in the GC-rich Streptomyces genome is essential for the production of novel biochemicals from secondary metabolite biosynthetic gene clusters (smBGCs). Despite many efforts to understand the regulation of transcription initiation in smBGCs, information on the regulation of transcription termination and posttranscriptional processing remains scarce. In this study, we identified the transcriptional regulatory elements in b-lac-tam antibiotic-producing Streptomyces clavuligerus ATCC 27064 by determining a total of 1,427 transcript 39-end positions (TEPs) using the term-seq method. Termination of transcription was governed by three classes of TEPs, of which each displayed unique sequence features. The data integration with transcription start sites and transcriptome data generated 1,648 transcription units (TUs) and 610 transcription unit clusters (TUCs). TU architecture showed that the transcript abundance in TU isoforms of a TUC was potentially affected by the sequence context of their TEPs, suggesting that the regulatory elements of TEPs could control the transcription level in additional layers. We also identified TU features of a xenobiotic response element (XRE) family regulator and DUF397 domain-containing protein, particularly showing the abundance of bidirectional TEPs. Finally, we found that 189 noncoding TUs contained potential cis- and trans-regulatory elements that played a major role in regulating the 59 and 39 UTR. These findings highlight the role of transcriptional regulatory elements in transcription termination and posttranscriptional processing in Streptomyces sp. IMPORTANCE Streptomyces sp. is a great source of bioactive secondary metabolites, including antibiotics, antifungal agents, antiparasitic agents, immunosuppressant compounds, and other drugs. Secondary metabolites are synthesized via multistep conversions of the precursor molecules from primary metabolism, governed by multicomplex enzymes from secondary metabolite biosynthetic gene clusters. As their production is closely related with the growth phase and dynamic cellular status in response to various intra- and extracellular signals, complex regulatory systems tightly control the gene expressions related to secondary metabolism. In this study, we determined genome-wide transcript 39-end positions and transcription units in the b-lactam antibiotic producer Streptomyces clavuligerus ATCC 27064 to elucidate the transcriptional regulatory elements in transcription termination and posttranscriptional processing by integration of multiomics data. These unique features, such © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1140/epjqt/s40507-024-00225-1,EPJ Quantum Technology,"Quantum circuit optimization is an inevitable task with the current noisy quantum backends. This task is considered non-trivial due to the varying circuits’ complexities in addition to hardware-specific noise, topology, and limited connectivity. The currently available methods either rely on heuristics for circuit optimization tasks or reinforcement learning with complex unscalable neural networks such as transformers. In this paper, we are concerned with optimizing the initial logical-to-physical mapping selection. Specifically, we investigate whether a reinforcement learning agent with simple scalable neural network is capable of finding a near-optimal logical-to-physical mapping, that would decrease as much as possible additional CNOT gates, only from a fixed-length feature vector. To answer this question, we train a Maskable Proximal Policy Optimization agent to progressively take steps towards a near-optimal logical-to-physical mapping on a 20-qubit hardware architecture. Our results show that our agent coupled with a simple routing evaluation is capable of outperforming other available reinforcement learning and heuristics approaches on 12 out of 19 test benchmarks, achieving geometric mean improvements of 2.2% and 15% over the best available related work and two heuristics approaches, respectively. Additionally, our neural network model scales linearly as the number of qubits increases. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1142/9789813235533_0031,Pacific Symposium on Biocomputing,"Glioblastoma Multiforme (GBM), a malignant brain tumor, is among the most lethal of all cancers. Temozolomide is the primary chemotherapy treatment for patients diagnosed with GBM. The methylation status of the promoter or the enhancer regions of the O 6 -methylguanine methyltransferase (MGMT) gene may impact the efficacy and sensitivity of temozolomide, and hence may affect overall patient survival. Microscopic genetic changes may manifest as macroscopic morphological changes in the brain tumors that can be detected using magnetic resonance imaging (MRI), which can serve as noninvasive biomarkers for determining methylation of MGMT regulatory regions. In this research, we use a compendium of brain MRI scans of GBM patients collected from The Cancer Imaging Archive (TCIA) combined with methylation data from The Cancer Genome Atlas (TCGA) to predict the methylation state of the MGMT regulatory regions in these patients. Our approach relies on a bi-directional convolutional recurrent neural network architecture (CRNN) that leverages the spatial aspects of these 3-dimensional MRI scans. Our CRNN obtains an accuracy of 67% on the validation data and 62% on the test data, with precision and recall both at 67%, suggesting the existence of MRI features that may complement existing markers for GBM patient stratification and prognosis. We have additionally presented our model via a novel neural network visualization platform, which we have developed to improve interpretability of deep learning MRI-based classification models. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1142/S1793351X23620040,International Journal of Semantic Computing,"The driving process involves many layers of planning and navigation, in order to enable tractable solutions for the otherwise highly complex problem of autonomous driving. One such layer involves an inherent discrete layer of decision-making corresponding to tactical maneuvers. Inspired by this, the focus of this work is predicting high-level maneuvers for the ego-vehicle. As maneuver prediction is fundamentally feedback-structured, it requires modeling techniques that take into consideration the interaction awareness of the traffic agents involved. This work addresses this challenge by modeling the traffic scenario as an interaction graph and proposing three deep learning architectures for interaction-aware tactical maneuver prediction of the ego-vehicle. These architectures are based on graph neural networks (GNNs) for extracting spatial features among traffic agents and recurrent neural networks (RNNs) for extracting dynamic motion patterns of surrounding agents. These proposed architectures have been trained and evaluated using BLVD dataset. Moreover, this dataset is expanded using data augmentation, data oversampling and data undersampling approaches, to strengthen model's resilience and enhance the learning process. Lastly, we compare proposed learning architectures for ego-vehicle maneuver prediction in various driving circumstances with various numbers of surrounding traffic agents in order to effectively verify the proposed architectures. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1145/1329125.1329399,,"Ontologies building from text is still a time-consuming task which justifies the growth of Ontology Learning. Our system named Dynamo is designed along this domain but following an original approach based on an adaptive multi-agent architecture. In this paper we present a distributed hierarchical clustering algorithm, core of our approach. It is evaluated and compared to a more conventional centralized algorithm. We also present how it has been improved using a multi-criteria approach. With those results in mind, we discuss the limits of our system and add as perspectives the modifications required to reach a complete ontology building solution. © 2007 IFAAMAS. © 2012 Elsevier B.V., All rights reserved.",TOPIC
10.1145/1401843.1401865,,"This paper presents a novel approach to modeling a generic cognitive framework in game agents to provide tactical behavior generation as well as strategic decision making in modern multi-agent computer games. The core of our framework consists of two characterization concepts we term as the tactical and strategic personalities, embedded in each game agent. Tactical actions and strategic plans are generated according to the weights defined in their respective personalities. The personalities are constantly improved as the game proceeds by a learning process based on reinforcement learning. Also, the strategies selected at each level of the agents' command hierarchy affect the personalities and hence the decisions of other agents. The learning system improves performance of the game agents in combat and is decoupled from the action selection mechanism to ensure speed. The variability in tactical behavior and decentralized strategic decision making improves realism and increases entertainment value. Our framework is implemented in a real game scenario as an experiment and shown to outperform various scripted opponent team tactics and strategies, as well as one with a randomly varying strategy. © 2008 ACM. © 2012 Elsevier B.V., All rights reserved.",TOPIC
10.1145/2486001.2486026,,"Layer-4 load balancing is fundamental to creating scale-out web services. We designed and implemented Ananta, a scale-out layer-4 load balancer that runs on commodity hardware and meets the performance, reliability and operational requirements of multi-tenant cloud computing environments. Ananta combines existing techniques in routing and distributed systems in a unique way and splits the components of a load balancer into a consensus-based reliable control plane and a decentralized scale-out data plane. A key component of Ananta is an agent in every host that can take over the packet modification function from the load balancer, thereby enabling the load balancer to naturally scale with the size of the data center. Due to its distributed architecture, Ananta provides direct server return (DSR) and network address translation (NAT) capabilities across layer-2 boundaries. Multiple instances of Ananta have been deployed in the Windows Azure public cloud with combined bandwidth capacity exceeding 1Tbps. It is serving traffic needs of a diverse set of tenants, including the blob, table and relational storage services. With its scale-out data plane we can easily achieve more than 100Gbps throughput for a single public IP address. In this paper, we describe the requirements of a cloud-scale load balancer, the design of Ananta and lessons learnt from its implementation and operation in the Windows Azure public cloud. © 2013 ACM. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3055635.3056621,ACM International Conference Proceeding Series,"Using neural networks as function approximators in temporal difference reinforcement problems proved to be very effective in dealing with high-dimensionality of input state space, especially in more recent developments such as Deep Q-learning. These approaches share the use of a mechanism, called experience replay, that uniformly samples the previous experiences to a memory buffer to exploit them to re-learn, thus improving the efficiency of the learning process. In order to increase the learning performance, techniques such as prioritized experience and prioritized sampling have been introduced to deal with storing and replaying, respectively, the transitions with larger TD error. In this paper, we present a concept, called Attention-Based Experience REplay (ABERE), concerned with selective focusing of the replay buffer to specific types of experiences, therefore modeling the behavioral characteristics of the learning agent in a single and multi-agent environment. We further explore how different behavioral characteristics influence the performance of agents faced with dynamic environment that is able to become more hostile or benevolent by changing the relative probability to get positive or negative reinforcement. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3132170,ACM Transactions on Architecture and Code Optimization,"Modern multi-core systems provide huge computational capabilities, which can be used to run multiple processes concurrently. To achieve the best possible performance within limited power budgets, the various system resources need to be allocated effectively. Any mismatch between runtime resource requirement and allocation leads to a sub-optimal energy-delay product (EDP). Different optimization techniques exist for addressing the problem of mismatch between the dynamic requirement and runtime allocation of the system resources. Choosing between multiple optimizations at runtime is complex due to the non-additive effects, making the scenario suitable for the application of machine learning techniques. We present a novel method,Machine LearnedMachines (MLM), by using online reinforcement learning (RL) to perform dynamic partitioning of the last level cache (LLC), along with dynamic voltage and frequency scaling (DVFS) of the core and uncore (interconnection network and LLC). We have proposed and evaluated three different MLM co-optimization techniques based on independent and cooperative multi-agent learners. We show that the co-optimization results in a much lower system EDP than any of the techniques applied individually. We explore various RL models targeted toward optimization of different system metrics and study their effects on a system EDP, system throughput (STP), and Fairness. The various proposed techniques have been extensively evaluated with a mix of 20 workloads on a 4-core system using Spec2006 benchmarks.We have further evaluated our cooperative MLM techniques on a 16-core system. The results show an average of 20.5% and 19.1% system EDP improvement on a 4-core and 16-core system, respectively, with limited degradation of STP and Fairness. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3194554.3194610,,"In this work I explore bio-inspired architectures for adaptive and smart sensing incorporating two key aspects present on the insect brain that are not found in more traditional neural network approaches: modulated, hierarchical processing and modulated learning. Our architecture incorporates two central ideas: 1) a state-dependent processing of inputs that can be triggered internally or externally, and 2) state-dependent online learning capabilities, in this specific case allowing the system to change the valence associated to different types of input. These ideas are explored through a hybrid design in which information is processed through a spiking neural network, while a recurrent non-spiking component provides the modulatory feedback to the system. The proposed approach exemplifies how neuromorphic computing approaches naturally integrate sensing and processing within a single functional unit. The proposed architecture can be implemented using conventional VLSI processing, though the integration of novel materials can help simplify its implementation. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3205455.3205529,,"Typically, AI researchers and roboticists try to realize intelligent behavior in machines by tuning parameters of a predefined structure (body plan and/or neural network architecture) using evolutionary or learning algorithms. Another but not unrelated longstanding property of these systems is their brittleness to slight aberrations, as highlighted by the growing deep learning literature on adversarial examples. Here we show robustness can be achieved by evolving the geometry of soft robots, their control systems, and how their material properties develop in response to one particular interoceptive stimulus (engineering stress) during their lifetimes. By doing so we realized robots that were equally fit but more robust to extreme material defects (such as might occur during fabrication or by damage thereafter) than robots that did not develop during their lifetimes, or developed in response to a different interoceptive stimulus (pressure). This suggests that the interplay between changes in the containing systems of agents (body plan and/or neural architecture) at different temporal scales (evolutionary and developmental) along different modalities (geometry, material properties, synaptic weights) and in response to different signals (interoceptive and external perception) all dictate those agents' abilities to evolve or learn capable and robust strategies. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3205455.3205615,,"Generally intelligent agents exhibit successful behavior across problems in several settings. Endemic in approaches to realize such intelligence in machines is catastrophic forgetting: sequential learning corrupts knowledge obtained earlier in the sequence, or tasks antagonistically compete for system resources. Methods for obviating catastrophic forgetting have sought to identify and preserve features of the system necessary to solve one problem when learning to solve another, or to enforce modularity such that minimally overlapping sub-functions contain task specific knowledge. While successful, both approaches scale poorly because they require larger architectures as the number of training instances grows, causing different parts of the system to specialize for separate subsets of the data. Here we present a method for addressing catastrophic forgetting called developmental compression. It exploits the mild impacts of developmental mutations to lessen adverse changes to previously-evolved capabilities and 'compresses' specialized neural networks into a generalized one. In the absence of domain knowledge, developmental compression produces systems that avoid overt specialization, alleviating the need to engineer a bespoke system for every task permutation and suggesting better scalability than existing approaches. We validate this method on a robot control problem and hope to extend this approach to other machine learning domains in the future. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3301293.3302356,,"We present a design for a mobile and IoT data privacy agent that lives in software on end devices. Our privacy agent learns and enforces a user's privacy policy across all devices that he manages. Implemented as a hypervisor onboard the end device, our privacy agent sits between the device's hardware and its application software. It can inspect, modify, block, and inject I/O traffic between the device's main CPU and its peripherals. The key advantage of our architecture is that, unlike network middleboxes, the hypervisor can track all I/O transactions in unencrypted form. This makes our privacy agent potentially much more effective than those that only monitor network traffic because it can track and modify plaintext data. Our privacy agent also gives users the ability to impose a uniform privacy policy across all devices that they manage, which minimizes the burden and possibility of error that arise when setting privacy policy on individual devices. Since the notion of per-user (as opposed to per-app) privacy policy is relatively new, there has not been much opportunity for researchers to think about how to define and implement policy on that scale. We propose a method for learning a user's privacy policy one time and automatically implementing it in a context-aware fashion on multiple devices. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3359999.3360495,,"We present RobustTP, an end-to-end algorithm for predicting future trajectories of road-agents in dense traffic with noisy sensor input trajectories obtained from RGB cameras (either static or moving) through a tracking algorithm. In this case, we consider noise as the deviation from the ground truth trajectory. The amount of noise depends on the accuracy of the tracking algorithm. Our approach is designed for dense heterogeneous traffic, where the road agents corresponding to a mixture of buses, cars, scooters, bicycles, or pedestrians. RobustTP is an approach that first computes trajectories using a combination of a non-linear motion model and a deep learning-based instance segmentation algorithm. Next, these noisy trajectories are trained using an LSTM-CNN neural network architecture that models the interactions between road-agents in dense and heterogeneous traffic. Our trajectory prediction algorithm outperforms state-of-the-art methods for end-to-end trajectory prediction using sensor inputs. We achieve an improvement of upto 18% in average displacement error and an improvement of up to 35.5% in final displacement error at the end of the prediction window (5 seconds) over the next best method. All experiments were set up on an Nvidia TiTan Xp GPU. Additionally, we release a software framework, TrackNPred. The framework consists of implementations of state-of-the-art tracking and trajectory prediction methods and tools to benchmark and evaluate them on real-world dense traffic datasets. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3368691.3368692,ACM International Conference Proceeding Series,"In this paper, we present a model of architecture based on flat peer-to-peer (P2P) networks. This architecture aims to reduce the impact of information vagueness and uncertainty on decision making using an information quality metric to manage its components. The model makes no assumptions about the homogeneity of the components or of the data they handle; however, all components must all be able to process the queries that they receive taking into account different qualities and response times, as well as limitations on the number of interactions that they can each undertake (limited number of messages, limited energy for communications, limited bandwidth or number of transmissible data). Part of the response process is to fuse information on the incoming data. Systems with these features have a wide variety of applications, ranging from decision support in critical environments (disaster areas, war, etc.) to mobile recommendation systems. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3368826.3377928,,"One of the key challenges arising when compilers vectorize loops for today's SIMD-compatible architectures is to decide if vectorization or interleaving is beneficial. Then, the compiler has to determine the number of instructions to pack together and the interleaving level (stride). Compilers are designed today to use fixed-cost models that are based on heuristics to make vectorization decisions on loops. However, these models are unable to capture the data dependency, the computation graph, or the organization of instructions. Alternatively, software engineers often hand-write the vectorization factors of every loop. This, however, places a huge burden on them, since it requires prior experience and significantly increases the development time. In this work, we explore a novel approach for handling loop vectorization and propose an end-to-end solution using deep reinforcement learning (RL). We conjecture that deep RL can capture different instructions, dependencies, and data structures to enable learning a sophisticated model that can better predict the actual performance cost and determine the optimal vectorization factors. We develop an end-to-end framework, from code to vectorization, that integrates deep RL in the LLVM compiler. Our proposed framework takes benchmark codes as input and extracts the loop codes. These loop codes are then fed to a loop embedding generator that learns an embedding for these loops. Finally, the learned embeddings are used as input to a Deep RL agent, which dynamically determines the vectorization factors for all the loops. We further extend our framework to support random search, decision trees, supervised neural networks, and nearest-neighbor search.We evaluate our approaches against the currently used LLVM vectorizer and loop polyhedral optimization techniques. Our experiments show 1.29 × -4.73× performance speedup compared to baseline and only 3% worse than the brute-force search on a wide range of benchmarks. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3371158.3371168,ACM International Conference Proceeding Series,"Robotics has proved to be an indispensable tool in many industrial as well as social applications, such as warehouse automation, manufacturing, disaster robotics, etc. In most of these scenarios, damage to the agent while accomplishing mission-critical tasks can result in failure. To enable robotic adaptation in such situations, the agent needs to adopt policies which are robust to a diverse set of damages and must do so with minimum computational complexity. We thus propose a damage aware control architecture which diagnoses the damage prior to gait selection while also incorporating domain randomization in the damage space for learning a robust policy. To implement damage awareness, we have used a Long Short Term Memory based supervised learning network which diagnoses the damage and predicts the type of damage. The main novelty of this approach is that only a single policy is trained to adapt against a wide variety of damages and the diagnosis is done in a single trial at the time of damage. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3377930.3389847,,"Inattentional blindness is the psychological phenomenon that causes one to miss things in plain sight. It is a consequence of the selective attention in perception that lets us remain focused on important parts of our world without distraction from irrelevant details. Motivated by selective attention, we study the properties of artificial agents that perceive the world through the lens of a self-attention bottleneck. By constraining access to only a small fraction of the visual input, we show that their policies are directly interpretable in pixel space. We find neuroevolution ideal for training self-attention architectures for vision-based reinforcement learning (RL) tasks, allowing us to incorporate modules that can include discrete, non-differentiable operations which are useful for our agent. We argue that self-attention has similar properties as indirect encoding, in the sense that large implicit weight matrices are generated from a small number of key-query parameters, thus enabling our agent to solve challenging vision based tasks with at least 1000x fewer parameters than existing methods. Since our agent attends to only task critical visual hints, they are able to generalize to environments where task irrelevant elements are modified while conventional methods fail.1 © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3377930.3390214,,"Rapid online adaptation to changing tasks is an important problem in machine learning and, recently, a focus of meta-reinforcement learning. However, reinforcement learning (RL) algorithms struggle in POMDP environments because the state of the system, essential in a RL framework, is not always visible. Additionally, hand-designed meta-RL architectures may not include suitable computational structures for specific learning problems. The evolution of online learning mechanisms, on the contrary, has the ability to incorporate learning strategies into an agent that can (i) evolve memory when required and (ii) optimize adaptation speed to specific online learning problems. In this paper, we exploit the highly adaptive nature of neuromodulated neural networks to evolve a controller that uses the latent space of an autoencoder in a POMDP. The analysis of the evolved networks reveals the ability of the proposed algorithm to acquire inborn knowledge in a variety of aspects such as the detection of cues that reveal implicit rewards, and the ability to evolve location neurons that help with navigation. The integration of inborn knowledge and online plasticity enabled fast adaptation and better performance in comparison to some non-evolutionary meta-reinforcement learning algorithms. The algorithm proved also to succeed in the 3D gaming environment Malmo Minecraft. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3381755.3381776,ACM International Conference Proceeding Series,"The evolution of biological brains has always been contingent on their embodiment within their respective environments, in which survival required appropriate navigation and manipulation skills. Studying such interactions thus represents an important aspect of computational neuroscience and, by extension, a topic of interest for neuromorphic engineering. Here, we present three examples of embodiment on the BrainScaleS-2 architecture, in which dynamical timescales of both agents and environment are accelerated by several orders of magnitude with respect to their biological archetypes. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3384419.3430776,,"Robust and accurate trajectory estimation of mobile agents such as people and robots is a key requirement for providing spatial awareness for emerging capabilities such as augmented reality or autonomous interaction. Although currently dominated by optical techniques e.g., visual-inertial odometry these suffer from challenges with scene illumination or featureless surfaces. As an alternative, we propose milliEgo, a novel deep-learning approach to robust egomotion estimation which exploits the capabilities of low-cost mm Wave radar. Although mmWave radar has a fundamental advantage over monocular cameras of being metric i.e., providing absolute scale or depth, current single chip solutions have limited and sparse imaging resolution, making existing point-cloud registration techniques brittle. We propose a new architecture that is optimized for solving this challenging pose transformation problem. Secondly, to robustly fuse mmWave pose estimates with additional sensors, e.g. inertial or visual sensors we introduce a mixed attention approach to deep fusion. Through extensive experiments, we demonstrate our proposed system is able to achieve 1.3% 3D error drift and generalizes well to unseen environments. We also show that the neural architecture can be made highly efficient and suitable for real-time embedded applications. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3408876,ACM Transactions on Human-Robot Interaction,"Physical agents that can autonomously generate engaging, life-like behavior will lead to more responsive and user-friendly robots and other autonomous systems. Although many advances have been made for one-to-one interactions in well-controlled settings, physical agents should be capable of interacting with humans in natural settings, including group interaction. To generate engaging behaviors, the autonomous system must first be able to estimate its human partners' engagement level. In this article, we propose an approach for estimating engagement during group interaction by simultaneously taking into account active and passive interaction, and use the measure as the reward signal within a reinforcement learning framework to learn engaging interactive behaviors. The proposed approach is implemented in an interactive sculptural system in a museum setting. We compare the learning system to a baseline using pre-scripted interactive behaviors. Analysis based on sensory data and survey data shows that adaptable behaviors within an expert-designed action space can achieve higher engagement and likeability. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3427773.3427863,,"While reinforcement learning (RL) on humans has shown incredible promise, it often suffers from a scarcity of data and few steps. In instances like these, a planning model of human behavior may greatly help. We present an experimental setup for the development and testing of an Soft Actor Critic (SAC) V2 RL architecture for several different neural architectures for planning models: an autoML optimized LSTM, an OLS, and a baseline model. We present the effects of including a planning model in agent learning within a simulation of the office, currently reporting a limited success with the LSTM. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3449726.3463173,,"The International Workshop on Learning Classifier Systems (IWLCS) is an annual workshop at the GECCO conference where new concepts and results regarding learning classifier systems (LCSs) are presented and discussed. One recurring part of the workshop agenda is a presentation that reviews and summarizes the advances made in the field over the last year; this is intended to provide an easy entry point to the most recent progress and achievements. The 2020 presentation was accompanied by a survey workshop paper, a practice which we hereby continue. We give an overview of all the LCS-related publications from 11 March 2020 to 10 March 2021. The 46 publications we review are grouped into seven overall topics: Formal theoretic advances, contributions to LCS-based multi-agent reinforcement learning, approaches to setting and adapting LCS hyperparameters, new LCS architectures and adaptations, LCS implementations, improvements to existing LCSs and applications of LCSs. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3450741.3466806,ACM International Conference Proceeding Series,"The maze, a classic architectural type of post-functional nature, is reinvented through the contemporary lens of video game. With novel analytical insights and computing methodologies on the system-unit relationship of a maze, we design and develop a Moving Maze that moves its parts methodically in response to the player's movement. A disorienting and adaptive system composed of identical parts, the Moving Maze is deconstructed into the non-subdivisible unit, which can propagate into a field through replication and orthogonal rotation. The game generates unit-To-system interactive outcomes with fragmental movements using gamer-relational rules. In achieving difficulty progression and game balance through Reinforcement Learning, the maze arouses problem-solving curiosity and immerses the player in a risk-reward structure. Centering the game mechanics on interactivity and adaptability, we enhance player engagement in this cognitive puzzle game through balanced player and environment agency. An artwork synthesizing procedural computation with gaming architecture, the Moving Maze pushes the imaginative boundary of what a maze can be and embodies the philosophy that systemic complexities arise from the simplest elements. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3466752.3480114,"Proceedings of the Annual International Symposium on Microarchitecture, MICRO","Past research has proposed numerous hardware prefetching techniques, most of which rely on exploiting one specific type of program context information (e.g., program counter, cacheline address, or delta between cacheline addresses) to predict future memory accesses. These techniques either completely neglect a prefetcher's undesirable effects (e.g., memory bandwidth usage) on the overall system, or incorporate system-level feedback as an afterthought to a system-unaware prefetch algorithm.We showthat prior prefetchers often lose their performance benefit over a wide range of workloads and system configurations due to their inherent inability to take multiple different types of program context and system-level feedback information into account while prefetching. In this paper, we make a case for designing a holistic prefetch algorithm that learns to prefetch using multiple different types of program context and system-level feedback information inherent to its design. To this end, we propose Pythia, which formulates the prefetcher as a reinforcement learning agent. For every demand request, Pythia observes multiple different types of program context information to make a prefetch decision. For every prefetch decision, Pythia receives a numerical reward that evaluates prefetch quality under the current memory bandwidth usage. Pythia uses this reward to reinforce the correlation between program context information and prefetch decision to generate highly accurate, timely, and systemaware prefetch requests in the future. Our extensive evaluations using simulation and hardware synthesis show that Pythia outperforms two state-of-the-art prefetchers (MLOP and Bingo) by 3.4% and 3.8% in single-core, 7.7% and 9.6% in twelve-core, and 16.9% and 20.2% in bandwidth-constrained core configurations, while incurring only 1.03% area overhead over a desktop-class processor and no software changes in workloads. The source code of Pythia can be freely downloaded from https://github.com/CMU-SAFARI/Pythia. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3472306.3478335,,"We propose the first approach to synthesize the synchronous 3D conversational body and hand gestures, as well as 3D face and head animations, of a virtual character from speech input. Our algorithm uses a CNN architecture that leverages the inherent correlation between facial expression and hand gestures. Synthesis of conversational body gestures is a multi-modal problem since many similar gestures can plausibly accompany the same input speech. To synthesize plausible body gestures in this setting, we train a Generative Adversarial Network (GAN) based model that measures the plausibility of the generated sequences of 3D body motion when paired with the input audio features. We also contribute a new corpus that contains more than 33 hours of annotated data from in-the-wild videos of talking people. To this end, we apply state-of-the-art monocular approaches for 3D body and hand pose estimation as well as 3D face performance capture to the video corpus. In this way, we can train on orders of magnitude more data than previous algorithms that resort to complex in-studio motion capture solutions, and thereby train more expressive synthesis algorithms. Our experiments and user study show the state-of-the-art quality of our speech-synthesized full 3D character animations. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3490354.3494366,,"Deep reinforcement learning (DRL) has been envisioned to have a competitive edge in quantitative finance. However, there is a steep development curve for quantitative traders to obtain an agent that automatically positions to win in the market, namely to decide where to trade, at what price and what quantity, due to the error-prone programming and arduous debugging. In this paper, we present the first open-source framework FinRL as a full pipeline to help quantitative traders overcome the steep learning curve. FinRL is featured with simplicity, applicability and extensibility under the key principles, full-stack framework, customization, reproducibility and hands-on tutoring. Embodied as a three-layer architecture with modular structures, FinRL implements fine-tuned state-of-the-art DRL algorithms and common reward functions, while alleviating the debugging workloads. Thus, we help users pipeline the strategy design at a high turnover rate. At multiple levels of time granularity, FinRL simulates various markets as training environments using historical data and live trading APIs. Being highly extensible, FinRL reserves a set of user-import interfaces and incorporates trading constraints such as market friction, market liquidity and investor's risk-aversion. Moreover, serving as practitioners' stepping stones, typical trading tasks are provided as step-by-step tutorials, e.g., stock trading, portfolio allocation, cryptocurrency trading, etc. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3498327,ACM Transactions on Design Automation of Electronic Systems,"Recently, Reinforcement Learning (RL) has shown great performance in solving sequential decision-making and control in dynamic environment problems. Despite its achievements, deploying Deep Neural Network (DNN)-based RL is expensive in terms of time and power due to the large number of episodes required to train agents with high dimensional image representations. Additionally, at the interference the large energy footprint of deep neural networks can be a major drawback. Embedded edge devices as the main platform for deploying RL applications are intrinsically resource-constrained and deploying deep neural network-based RL on them is a challenging task. As a result, reducing the number of actions taken by the RL agent to learn desired policy, along with the energy-efficient deployment of RL, is crucial. In this article, we propose Energy Efficient Hierarchical Reinforcement Learning (E2HRL), which is a scalable hardware architecture for RL applications. E2HRL utilizes a cross-layer design methodology for achieving better energy efficiency, smaller model size, higher accuracy, and system integration at the software and hardware layers. Our proposed model for RL agent is designed based on the learning hierarchical policies, which makes the network architecture more efficient for implementation on mobile devices. We evaluated our model in three different RL environments with different level of complexity. Simulation results with our analysis illustrate that hierarchical policy learning with several levels of control improves RL agents training efficiency and the agent learns the desired policy faster compared to a non-hierarchical model. This improvement is specifically more observable as the environment or the task becomes more complex with multiple objective subgoals. We tested our model with different hyperparameters to achieve the maximum reward by the RL agent while minimizing the model size, parameters, and required number of operations. E2HRL model enables efficient deployment of RL agent on resource-constraint-embedded devices with the proposed custom hardware architecture that is scalable and fully parameterized with respect to the number of input channels, filter size, and depth. The number of processing engines (PE) in the proposed hardware can vary between 1 to 8, which provides the flexibility of tradeoff of different factors such as latency, throughput, power, and energy efficiency. By performing a systematic hardware parameter analysis and design space exploration, we implemented the most energy-efficient hardware architectures of E2HRL on Xilinx Artix-7 FPGA and NVIDIA Jetson TX2. Comparing the implementation results shows Jetson TX2 boards achieve 0.1 ∼1.3 GOP/S/W energy efficiency while Artix-7 FPGA achieves 1.1 ∼11.4 GOP/S/W, which denotes 8.8× ∼11× better energy efficiency of E2HRL when model is implemented on FPGA. Additionally, compared to similar works our design shows better performance and energy efficiency. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3512290.3528844,,"Cybersecurity simulations can offer deep insights into the behavior of agents in the battle to secure computer systems. We build on existing work modeling the competition between an attacker and defender on a network architecture in a zero-sum game using a graph database linking cybersecurity attack patterns, vulnerabilities, and software. We apply coevolution to this challenging environment, and in a novel modeling approach for this problem, interpret each population as a distribution over fixed strategies to form a mixed strategy Nash equilibrium. We compare the results to solutions generated by multi-agent reinforcement learning and show that evolutionary methods demonstrate a considerable degree of robustness to parameter misspecification in this environment. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3523230.3523232,Computer Communication Review,"We describe a new system for distributed tracing at the IP level of the routes that packets take through the IPv4 internet. Our Zeph algorithm coordinates route tracing efforts across agents at multiple vantage points, assigning to each agent a number of /24 destination prefixes in proportion to its probing budget and chosen according to a reinforcement learning heuristic that aims to maximize the number of multipath links discovered. Zeph runs on top of Iris, our fault tolerant system for orchestrating internet measurements across distributed agents of heterogeneous probing capacities. Iris is built around third party free open source software and modern containerization technology, thereby presenting a new model for assembling a resilient and maintainable internet measurement architecture. We show that carefully choosing the destinations to probe from which vantage point matters to optimize topology discovery and that a system can learn which assignment will maximize the overall discovery based on previous measurements. After 10 cycles of probing, Zeph is capable of discovering 2.4M nodes and 10M links in a cycle of 6 hours, when deployed on 5 Iris agents. This is at least 2 times more nodes and 5 times more links than other production systems for the same number of prefixes probed. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3526241.3530335,,"Network-on-chip (NoC) architectures rely on buffers to store flits to cope with contention for router resources during packet switching. Recently, reversible multi-function channel (RMC) buffers have been proposed to simultaneously reduce power and enable adaptive NoC buffering between adjacent routers. While adaptive buffering can improve NoC performance by maximizing buffer utilization, controlling the RMC buffer allocations requires a congestion-aware, scalable, and proactive policy. In this work, we present RACE, a novel reinforcement learning (RL) framework that utilizes better awareness of network congestion and a new reward metric (""falsefulls"") to help guide the RL agent towards better RMC buffer control decisions. We show that RACE reduces NoC latency by up to 48.9%, and energy consumption by up to 47.1% against state-of-the-art NoC buffer control policies. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3534678.3539480,,"The increased integration of renewable energy poses a slew of technical challenges for the operation of power distribution networks. Among them, voltage fluctuations caused by the instability of renewable energy are receiving increasing attention. Utilizing MARL algorithms to coordinate multiple control units in the grid, which is able to handle rapid changes of power systems, has been widely studied in active voltage control task recently. However, existing approaches based on MARL ignore the unique nature of the grid and achieve limited performance. In this paper, we introduce the transformer architecture to extract representations adapting to power network problems and propose a Transformer-based Multi-Agent Actor-Critic framework (T-MAAC) to stabilize voltage in power distribution networks. In addition, we adopt a novel auxiliary-task training process tailored to the voltage control task, which improves the sample efficiency and facilitating the representation learning of the transformer-based model. We couple T-MAAC with different multi-agent actor-critic algorithms, and the consistent improvements on the active voltage control task demonstrate the effectiveness of the proposed method. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3536220.3558806,ACM International Conference Proceeding Series,"In this article, we present two models to jointly and automatically generate the head, facial and gaze movements of a virtual agent from acoustic speech features. Two architectures are explored: a Generative Adversarial Network and an Adversarial Encoder-Decoder. Head movements and gaze orientation are generated as 3D coordinates, while facial expressions are generated using action units based on the facial action coding system. A large corpus of almost 4 hours of videos, involving 89 different speakers is used to train our models. We extract the speech and visual features automatically from these videos using existing tools. The evaluation of these models is conducted objectively with measures such as density evaluation and a visualisation from PCA reduction, as well as subjectively through a users perceptive study. Our proposed methodology shows that on 15 seconds sequences, encoder-decoder architecture drastically improves the perception of generated behaviours in two criteria: the coordination with speech and the naturalness. Our code can be found in : https://github.com/aldelb/non-verbal-behaviours-generation. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3536221.3556569,ACM International Conference Proceeding Series,"In this paper, we propose and compare personalized models for Productive Engagement (PE) recognition. PE is defined as the level of engagement that maximizes learning. Previously, in the context of robot-mediated collaborative learning, a framework of productive engagement was developed by utilizing multimodal data of 32 dyads and learning profiles, namely, Expressive Explorers (EE), Calm Tinkerers (CT), and Silent Wanderers (SW) were identified which categorize learners according to their learning gain. Within the same framework, a PE score was constructed in a non-supervised manner for real-time evaluation. Here, we use these profiles and the PE score within an AutoML deep learning framework to personalize PE models. We investigate two approaches for this purpose: (1) Single-task Deep Neural Architecture Search (ST-NAS), and (2) Multitask NAS (MT-NAS). In the former approach, personalized models for each learner profile are learned from multimodal features and compared to non-personalized models. In the MT-NAS approach, we investigate whether jointly classifying the learners' profiles with the engagement score through multi-task learning would serve as an implicit personalization of PE. Moreover, we compare the predictive power of two types of features: incremental and non-incremental features. Non-incremental features correspond to features computed from the participant's behaviours in fixed time windows. Incremental features are computed by accounting to the behaviour from the beginning of the learning activity till the time window where productive engagement is observed. Our experimental results show that (1) personalized models improve the recognition performance with respect to non-personalized models when training models for the gainer vs. non-gainer groups, (2) multitask NAS (implicit personalization) also outperforms non-personalized models, (3) the speech modality has high contribution towards prediction, and (4) non-incremental features outperform the incremental ones overall. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3545008.3545025,ACM International Conference Proceeding Series,"Recent years have seen a great increase in the capacity and parallel processing power of data centers and cloud services. To fully utilize the said distributed systems, optimal load balancing for parallel queuing architectures must be realized. Existing state-of-the-art solutions fail to consider the effect of communication delays on the behaviour of very large systems with many clients. In this work, we consider a multi-agent load balancing system, with delayed information, consisting of many clients (load balancers) and many parallel queues. In order to obtain a tractable solution, we model this system as a mean-field control problem with enlarged state-action space in discrete time through exact discretization. Subsequently, we apply policy gradient reinforcement learning algorithms to find an optimal load balancing solution. Here, the discrete-time system model incorporates a synchronization delay under which the queue state information is synchronously broadcasted and updated at all clients. We then provide theoretical performance guarantees for our methodology in large systems. Finally, using experiments, we prove that our approach is not only scalable but also shows good performance when compared to the state-of-the-art power-of-d variant of the Join-the-Shortest-Queue (JSQ) and other policies in the presence of synchronization delays. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3563357.3566168,,"Deep Reinforcement Learning (DRL) has started showing success in real-world applications such as building energy optimization. Much of the research in this space utilized simulated environments to train RL-agent in an offline mode. Very few research have used DRL-based control in real-world systems due to two main reasons: 1) sample efficiency challenge-DRL approaches need to perform a lot of interactions with the environment to collect sufficient experiences to learn from, which is difficult in real systems, and 2) comfort or safety related constraints-user's comfort must never or at least rarely be violated. In this work, we propose a novel deep Reinforcement Learning framework with online Data Augmentation (RLDA) to address the sample efficiency challenge of real-world RL. We used a time series Generative Adversarial Network (TimeGAN) architecture as a data generator. We further evaluated the proposed RLDA framework using a case study of an intelligent HVAC control. With a ≈28% improvement in the sample efficiency, RLDA framework lays the way towards increased adoption of DRL-based intelligent control in real-world building energy management systems. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3567445.3567454,,"Autonomous IoT systems require the development of good automation algorithms capable of handling a huge number of IoT devices such as in smart cities. Deep Reinforcement Learning (DRL) is a powerful automation technique that can be used in massive systems thanks to its ability to deal with big state spaces. Moreover, it adapts quickly to changes in the system by reinforcement learning, making the automation algorithm very flexible. However, using DRL relies generally on centralized agent architecture making it more exposed to communication failures. In this paper, we propose a distributed architecture to solve the task offloading problem in autonomous IoT systems where learning is achieved in a master agent while decision making is delegated to IoT devices. This architecture is more resilient as decisions are made locally and interactions between IoT devices and the master agent are less frequent and not blocking. We tested this architecture in the ns3-gym environment and our results show very good resilience of this architecture. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3571306.3571393,ACM International Conference Proceeding Series,"This paper considers the problem of resilient distributed optimization and stochastic learning in a server-based architecture. The system comprises a server and multiple agents, where each agent has its own local cost function. The agents collaborate with the server to find a minimum of the aggregate of the local cost functions. In the context of stochastic learning, the local cost of an agent is the loss function computed over the data at that agent. In this paper, we consider this problem in a system wherein some of the agents may be Byzantine faulty and some of the agents may be slow (also called stragglers). In this setting, we investigate the conditions under which it is possible to obtain an ""approximate""solution to the above problem. In particular, we introduce the notion of (f, r;μ)-resilience to characterize how well the true solution is approximated in the presence of up to f Byzantine faulty agents, and up to r slow agents (or stragglers) - smaller μ represents a better approximation. We also introduce a measure named (f, rμ)-redundancy to characterize the redundancy in the cost functions of the agents. Greater redundancy allows for a better approximation when solving the problem of aggregate cost minimization. In this paper, we constructively show (both theoretically and empirically) that -resilience can indeed be achieved in practice, given that the local cost functions are sufficiently redundant. Our empirical evaluation considers a distributed gradient descent (DGD)-based solution; for distributed learning in the presence of Byzantine and asynchronous agents, we also evaluate a distributed stochastic gradient descent (D-SGD)-based algorithm. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3577190.3616546,,"This paper explores privacy-compliant group-level emotion recognition ""in-the-wild""within the EmotiW Challenge 2023. Group-level emotion recognition can be useful in many fields including social robotics, conversational agents, e-coaching and learning analytics. This research imposes itself using only global features avoiding individual ones, i.e. all features that can be used to identify or track people in videos (facial landmarks, body poses, audio diarization, etc.). The proposed multimodal model is composed of a video and an audio branches with a cross-attention between modalities. The video branch is based on a fine-tuned ViT architecture. The audio branch extracts Mel-spectrograms and feed them through CNN blocks into a transformer encoder. Our training paradigm includes a generated synthetic dataset to increase the sensitivity of our model on facial expression within the image in a data-driven way. The extensive experiments show the significance of our methodology. Our privacy-compliant proposal performs fairly on the EmotiW challenge, with 79.24% and 75.13% of accuracy respectively on validation and test set for the best models. Noticeably, our findings highlight that it is possible to reach this accuracy level with privacy-compliant features using only 5 frames uniformly distributed on the video. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3578360.3580273,,"We aim to automate decades of research and experience in register allocation, leveraging machine learning. We tackle this problem by embedding a multi-agent reinforcement learning algorithm within LLVM, training it with the state of the art techniques. We formalize the constraints that precisely define the problem for a given instruction-set architecture, while ensuring that the generated code preserves semantic correctness. We also develop a gRPC based framework providing a modular and efficient compiler interface for training and inference. Our approach is architecture independent: we show experimental results targeting Intel x86 and ARM AArch64. Our results match or out-perform the heavily tuned, production-grade register allocators of LLVM. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3579371.3589081,,"Coarse-grained reconfigurable architecture (CGRA) has become a promising candidate for data-intensive computing due to its flexibility and high energy efficiency. CGRA compilers map data flow graphs (DFGs) extracted from applications onto CGRAs, playing a fundamental role in fully exploiting hardware resources for acceleration. Yet the existing compilers are time-demanding and cannot guarantee optimal results due to the traversal search of enormous search spaces brought about by the spatio-temporal flexibility of CGRA structures and the complexity of DFGs. Inspired by the amazing progress in reinforcement learning (RL) and Monte-Carlo tree search (MCTS) for real-world problems, we consider constructing a compiler that can learn from past experiences and comprehensively understand the target DFG and CGRA. In this paper, we propose an architecture-aware compiler for CGRAs based on RL and MCTS, called MapZero – a framework to automatically extract the characteristics of DFG and CGRA hardware and map operations onto varied CGRA fabrics. We apply Graph Attention Network to generate an adaptive embedding for DFGs and also model the functionality and interconnection status of the CGRA, aiming at training an RL agent to perform placement and routing intelligently. Experimental results show that MapZero can generate superior-quality mappings and reduce compilation time hundreds of times compared to state-of-the-art methods. MapZero can find high-quality mappings very quickly when the feasible solution space is rather small and all other compilers fail. We also demonstrate the scalability and broad applicability of our framework. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3580507.3597714,,"Many multi-agent machine learning settings can be modeled as games, from social or economic systems with algorithmic decision-makers to popular learning architectures such as generative adversarial networks (GANs). Desired outcomes in these settings are often encoded as equilibrium concepts, and therefore a primary goal is identifying machine learning algorithms with provable convergence to these equilibria. However, a growing body of negative results casts doubt on this goal by uncovering games exhibiting non-convergence, chaos, and even essentially arbitrary behaviour [Andrade et al. 2021; Benaïm et al. 2012; Cheung and Piliouras 2019; Chotibut et al. 2020; Flokas et al. 2020; Letcher 2021; Milionis et al. 2022; Wibisono et al. 2022]. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3589737.3605992,,"Evolutionary algorithms have been shown to be an effective method for training (or configuring) spiking neural networks. There are, however, challenges to developing accessible, scalable, and portable solutions. We present an extension to the Fugu framework that wraps the NEAT framework, bringing evolutionary algorithms to Fugu. This approach provides a flexible and customizable platform for optimizing network architectures, independent of fitness functions and input data structures. We leverage Fugu's computational graph approach to evaluate all members of a population in parallel. Additionally, as Fugu is platform-agnostic, this population can be evaluated in simulation or on neuromorphic hardware. We demonstrate our extension using several classification and agent-based tasks. One task illustrates how Fugu integration allows for spiking pre-processing to lower the search space dimensionality. We also provide some benchmark results using the Intel Loihi platform. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3598301,ACM Transactions on Computing for Healthcare,"This article presents a resource-efficient adaptive sampling methodology for classifying electrocardiogram (ECG) signals into different heart rhythms. We present our methodology in two folds: (i) the design of a novel real-time adaptive neural network architecture capable of classifying ECG signals with different sampling rates and (ii) a runtime implementation of sampling rate control using deep reinforcement learning (DRL). By using essential morphological details contained in the heartbeat waveform, the DRL agent can control the sampling rate and effectively reduce energy consumption at runtime. To evaluate our adaptive classifier, we use the MIT-BIH database and the recommendation of the AAMI to train the classifiers. The classifier is designed to recognize three major types of arrhythmias, which are supraventricular ectopic beats (SVEB), ventricular ectopic beats (VEB), and normal beats (N). The performance of the arrhythmia classification reaches an accuracy of 97.2% for SVEB and 97.6% for VEB beats. Moreover, the designed system is 7.3× more energy-efficient compared to the baseline architecture, where the adaptive sampling rate is not utilized. The proposed methodology can provide reliable and accurate real-time ECG signal analysis with performances comparable to state-of-the-art methods. Given its time-efficient, low-complexity, and low-memory-usage characteristics, the proposed methodology is also suitable for practical ECG applications, in our case for arrhythmia classification, using resource-constrained devices, especially wearable healthcare devices and implanted medical devices. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3600100.3623749,,"Renewable energy transition and decarbonization pose significant challenges for grid-interactive efficient building communities. The optimization of intermittent renewable energy can be achieved using advanced control architecture and energy storage, enhancing energy flexibility. Reinforcement learning (RL) offers potential solutions, but its scalability and computational demands in large-scale settings remain unclear. This paper examines the scalability of Soft-Actor Critic (SAC) in multi-agent systems, comparing decentralized-independent SACs and centralized SACs using CityLearn, an OpenAI Gym environment. We consider neighborhoods consisting of 2 to 64 single-family residential buildings, each equipped with cooling and heating storage devices, domestic hot water storage devices, electrical storage devices, and solar PV systems. Our findings suggest that independent controllers outperform the centralized controller with increasing number of buildings. We also show that the performance on the building level can differ from the aggregated performance. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3603269.3604860,,"We present the design, implementation, evaluation, deployment and production experiences of EBB (Express BackBone), a private WAN (Wide Area Network) connecting Meta's global data centers (DCs). Initiated in 2015, EBB now carries 100% of DC-DC traffic, witnessing remarkable growth over the years. A key design aspect of EBB is its multi-plane architecture, facilitating seamless deployment of a new control plane while ensuring operational simplicity. This architecture allows for efficient failure mitigation, standard maintenance, and capacity expansion by draining one or two planes without impacting service level objectives (SLOs). Another critical design decision is the hybrid model, combining distributed control agents and a central controller. EBB's centralized traffic engineering utilizes an MPLS-TE based solution to allocate paths periodically for different traffic classes based on service requirements, while its distributed control agents enable fast local failure recovery by pre-installing pre-computed backup paths in the data plane. We delve into our eight-year production experience, highlighting the successful deployment of multiple generations of EBB. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3604237.3626886,,"The Cumulative Prospect Theory (CPT) is a popular behavioral decision-making model that has been shown to reflect humans' risk-sensitive behavior. This work develops an end-to-end CPT-based DRL trading agent. For our architecture, we draw on the Truncated Quantile Critics (TQC), an actor-critic distributional RL method designed to learn return distributions for risk-neutral continuous control while guarding against overestimation bias. We introduce a CPT actor and realistic trading constraints to TQC to build a novel TQ2CPT trading algorithm. We evaluate the performance of our algorithm against several benchmark strategies in various portfolio metrics and demonstrate CPT's efficacy as a risk measure for DRL trading, as well as its synergistic relationships with TQC. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3610977.3635006,ACM/IEEE International Conference on Human-Robot Interaction,"As robots enter human workspaces, there is a crucial need for robots to understand and predict human motion to achieve safe and fluent human-robot collaboration (HRC). However, accurate prediction is challenging due to a lack of large-scale datasets for close-proximity HRC and the absence of generalizable algorithms. To overcome these challenges, we present INTERACT, a comprehensive multimodal dataset covering 3-D Skeleton, RGB+D, gaze, and robot joint data for human-human and human-robot collaboration. Additionally, we introduce PoseTron, a novel transformer-based architecture to address the gap in learning algorithms. PoseTron introduces a conditional attention mechanism in the encoder enabling efficient weighing of motion information from all agents to incorporate team dynamics. The decoder features a novel multimodal attention mechanism, which weights representations from different modalities and the encoder outputs to predict future motion. We extensively evaluated PoseTron by comparing its performance on the INTERACT dataset against state-of-the-art algorithms. The results suggest that PoseTron outperformed all other methods across all the scenarios, attaining lowest prediction errors. Furthermore, we conducted a comprehensive ablation study, emphasizing the importance of design choices, pointing towards a promising direction for integrating motion prediction with robot perception in safe and effective HRC. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3613424.3614295,,"Heterogeneous multicore systems have emerged as a promising approach to scale performance in high-end desktops within limited power and die size constraints. Despite their advantages, these systems face three major challenges: memory bandwidth limitation, shared cache contention, and heterogeneity. Small cores in these systems tend to occupy a significant portion of shared LLC and memory bandwidth, despite their lower computational capabilities, leading to performance degradation of up to 18% in memory-intensive workloads. Therefore, it is crucial to address these challenges holistically, considering shared resources and core heterogeneity while managing shared cache and bandwidth. To tackle these issues, we propose McCore, a comprehensive solution that reorganizes the heterogeneous multicore memory hierarchy and effectively leverages this structure through a hardware-based reinforcement learning (RL) scheduler. The McCore structure aims to enhance performance by partitioning the shared LLC based on each cluster's asymmetric computing power and conditionally enabling fine-grained access in small cores. The McCore RL agent holistically controls these structures, incorporating a hardware-based online RL scheduler that accounts for bandwidth utilization and caching effectiveness to consider the heterogeneity in McCore structures. By implementing the RL agent module as hardware that cooperates with existing hardware monitors and performance counters, low-latency scheduling is enabled without burdening the OS kernel. McCore achieves a 25.1% performance gain compared to the baseline and significantly outperforms existing state-of-the-art cache partitioning, sparse access managing schemes, and heterogeneous multicore schedulers, providing a comprehensive solution for high-performance heterogeneous multicore systems. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3613424.3623780,,"Online Reinforcement Learning (RL) has been adopted as an effective mechanism in various decision-making problems in microarchitecture. Its high adaptability and the ability to learn at runtime are attractive characteristics in microarchitecture settings. However, although hardware RL agents are effective, they suffer from two main problems. First, they have high complexity and storage overhead. This complexity stems from decomposing the environment into a large number of states and then, for each of these states, bookkeeping many action values. Second, many RL agents are engineered for a specific application and are not reusable. In this work, we tackle both of these shortcomings by designing an RL agent that is both lightweight and reusable across different microarchitecture decision-making problems. We find that, in some of these problems, only a small fraction of the action space is useful in a given time window. We refer to this property as temporal homogeneity in the action space. Motivated by this property, we design an RL agent based on Multi-Armed Bandit algorithms, the simplest form of RL. We call our agent Micro-Armed Bandit. We showcase our agent in two use cases: data prefetching and instruction fetch in simultaneous multithreaded (SMT) processors. For prefetching, our agent outperforms non-RL prefetchers Bingo and MLOP by 2.6% and 2.3% (geometric mean), respectively, and attains similar performance as the state-of-the-art RL prefetcher Pythia - with the dramatically lower storage requirement of only 100 bytes. For SMT instruction fetch, our agent outperforms the Hill Climbing method by 2.2% (geometric mean). © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3631613,ACM Transactions on Cyber-Physical Systems,"Cooperative adaptive cruise control (CACC) is a smart transportation solution to alleviate traffic congestion and enhance road safety. The performance of CACC systems can be remarkably affected by communication time delays, and traditional control methods often compromise control performance by adjusting control gains to maintain system stability. In this article, we present a study on the stability of a CACC system in the presence of time delays and highlight the tradeoff between control performance and tuning controller gains to address increasing delays. We propose a novel approach incorporating a neural network module called the deep time delay filter (DTDF) to overcome this limitation. The DTDF leverages the assumption that time delays primarily originate from the communication layer of the CACC network, which can be subject to adversarial delays of varying magnitudes. By considering time-delayed versions of the car states and predicting the present (un-delayed) states, the DTDF compensates for the effects of communication delays. The proposed approach combines classical control techniques with machine learning, offering a hybrid control system that excels in explainability and robustness to unknown parameters.We conduct comprehensive experiments using various deep learning architectures to train and evaluate the DTDF models. Our experiments utilize a robot platform consisting of MATLAB, Simulink, the Optitrack motion capture system, and the Qbot2e robots. Through these experiments, we demonstrate that when appropriately trained, our system can effectively mitigate the adverse effects of constant time delays and outperforms a traditional CACC baseline in control performance. This experimental comparison, to the best of the authors' knowledge, is the first of its kind in the context of a hybrid machine learning CACC system. We thoroughly explore initial conditions and range policy parameters to evaluate our system under various experimental scenarios. By providing detailed insights and experimental results, we aim to contribute to the advancement of CACC research and highlight the potential of hybrid machine learning approaches in improving the performance and reliability of CACC systems. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3632366.3632368,,"In the realm of neural network research, achieving experiment reproducibility is paramount for building upon existing knowledge and advancing the field. This paper examines a multi-agent neural network framework on its ability to facilitate the reproduction of experiments. Also, we address the reproducibility problem when there are data or source code limitations. The framework offers crucial functionalities for facilitating experiment reproducibility achieved through data, layer outputs, architectures, and weights exchange among the framework's agents. Through the integration of these functionalities, this framework empowers researchers to reproduce and validate experimental results consistently, fostering a more robust and collaborative research environment in the field of neural networks. The experimental results demonstrate the framework's reproducibility abilities. Furthermore, we test the framework in terms of reproducibility in an emergency natural disaster management situation. Finally, we analyze how the privacy limitations of the original neural network affect the reproducibility results. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3632366.3632373,,"The use of the Federated Learning paradigm could be disruptive in robotics, where data are naturally distributed among teams of agents and centralizing them would increase latency and break privacy. Unfortunately there are a lack of robot oriented framework for federated learning that use state of the art machine learning libraries. ROS2 (Robot Operating Systems) is a standard de-facto in robotics for building up teams of robots in a multi-node fully distributed manner. In this paper we presents the integration of ROS2 with PyTorch allowing an easy training of a global machine learning model starting from a set of local datasets. We present the architecture, the used methodology and finally we discuss the experimentation results over a well-known public dataset. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3637528.3671555,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"The online advertising market, with its thousands of auctions run per second, presents a daunting challenge for advertisers who wish to optimize their spend under a budget constraint. Thus, advertising platforms typically provide automated agents to their customers, which act on their behalf to bid for impression opportunities in real time at scale. Because these proxy agents are owned by the platform but use advertiser funds to operate, there is a strong practical need to balance reliability and explainability of the agent with optimizing power. We propose a generalizable approach to optimizing bidding policies in production environments by learning from real data using offline reinforcement learning. This approach can be used to optimize any differentiable base policy (practically, a heuristic policy based on principles which the advertiser can easily understand), and only requires data generated by the base policy itself. We use a hybrid agent architecture that combines arbitrary base policies with deep neural networks, where only the optimized base policy parameters are eventually deployed, and the neural network part is discarded after training. We demonstrate that such an architecture achieves statistically significant performance gains in both simulated and at-scale production bidding environments compared to the default production bidding policy. Our approach does not incur additional infrastructure, safety, or explainability costs, as it directly optimizes the parameters of existing production routines without necessarily replacing them with black box-style models like neural networks. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3637528.3672009,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Prior research on neural architecture search (NAS) for adversarial robustness has revealed that a lightweight and adversarially robust sub-network could exist in a non-robust large teacher network. Such a sub-network is generally discovered based on heuristic rules to perform neural architecture search. However, heuristic rules are inadequate to handle diverse adversarial attacks and different ""teacher""network capacity. To address this key challenge, we propose Reinforced Compressive Neural Architecture Search (RC-NAS), aiming to achieve Versatile Adversarial Robustness. Specifically, we define novel task settings that compose datasets, adversarial attacks, and teacher network configuration. Given diverse tasks, we develop an innovative dual-level training paradigm that consists of a meta-training and a fine-tuning phase to effectively expose the RL agent to diverse attack scenarios (in meta-training), and make it adapt quickly to locate an optimal sub-network (in fine-tuning) for previously unseen scenarios. Experiments show that our framework could achieve adaptive compression towards different initial teacher networks, datasets, and adversarial attacks, resulting in more lightweight and adversarially robust architectures. We also provide a theoretical analysis to explain why the reinforcement learning (RL)-guided adversarial architectural search helps adversarial robustness over standard adversarial training methods. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3638530.3664148,,"The eXtended Classifier System (XCS) is the most widely studied classifier system in the community. It is a class of interpretable AI which has shown strong capability to master various classification and regression tasks. It has also shown strong performance in certain multi-step environments in the reinforcement learning domain. XCS consists of a population of classifiers of size N which is decided at design time. The population size N is typically large to provide room for the learning and generalization mechanism of XCS. Experience replay (ER) is a popular technique in reinforcement learning which significantly improves the learning of the agents. ER uses a replay memory of fixed size which is defined at design time. Typically XCS has been trained on high-performance computers or servers which have near to no limitations on memory. XCS when applied to embedded applications or IoT devices are constrained by the memory consumption. This memory constraint affects the population size and the size of the replay memory in ER. In this work, we propose XCS with dynamic sized experience replay, where the size of the replay memory is resized inversely proportional to the number of macro-classifiers in the population to maximize the performance within a memory constraint. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3653453,ACM Transactions on Design Automation of Electronic Systems,"In this article, we focus on chip floorplanning, which aims to determine the location and orientation of circuit macros simultaneously, so the chip area and wirelength are minimized. As the highest level of abstraction in hierarchical physical design, floorplanning bridges the gap between the system-level design and the physical synthesis, whose quality directly influences downstream placement and routing. To tackle chip floorplanning, we propose an end-to-end reinforcement learning (RL) methodology with a hindsight experience replay technique. An edge-aware graph attention network (EAGAT) is developed to effectively encode the macro and connection features of the netlist graph. Moreover, we build a hierarchical decoder architecture mainly consisting of transformer and attention pointer mechanism to output floorplan actions. Since the RL agent automatically extracts knowledge about the solution space, the previously learned policy can be quickly transferred to optimize new unseen netlists. Experimental results demonstrate that, compared with state-of-the-art floorplanners, the proposed end-to-end methodology significantly optimizes area and wirelength on public GSRC and MCNC benchmarks. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3653714,"ACM Transactions on Multimedia Computing, Communications and Applications","Given an object of interest, visual navigation aims to reach the object's location based on a sequence of partial observations. To this end, an agent needs to (1) acquire specific knowledge about the relations of object categories in the world during training and (2) locate the target object based on the pre-learned object category relations and its trajectory in the current unseen environment. In this article, we propose a Category Relation Graph (CRG) to learn the knowledge of object category layout relations and a Temporal-Spatial-Region attention (TSR) architecture to perceive the long-term spatial-temporal dependencies of objects, aiding navigation. We establish CRG to learn prior knowledge of object layout and deduce the positions of specific objects. Subsequently, we propose the TSR architecture to capture relationships among objects in temporal, spatial, and regions within observation trajectories. Specifically, we implement a Temporal attention module (T) to model the temporal structure of the observation sequence, implicitly encoding historical moving or trajectory information. Then, a Spatial attention module (S) uncovers the spatial context of the current observation objects based on CRG and past observations. Last, a Region attention module (R) shifts the attention to the target-relevant region. Leveraging the visual representation extracted by our method, the agent accurately perceives the environment and easily learns a superior navigation policy. Experiments on AI2-THOR demonstrate that our CRG-TSR method significantly outperforms existing methods in both effectiveness and efficiency. The supplementary material includes the code and will be publicly available. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3654439,ACM Transactions on Software Engineering and Methodology,"Autonomous systems, such as drones and rescue robots, are increasingly used during emergencies. They deliver services and provide situational awareness that facilitate emergency management and response. To do so, they need to interact and cooperate with humans in their environment. Human behaviour is uncertain and complex, so it can be difficult to reason about it formally. In this article, we propose IDEA: an adaptive software architecture that enables cooperation between humans and autonomous systems, by leveraging the social identity approach. This approach establishes that group membership drives human behaviour. Identity and group membership are crucial during emergencies, as they influence cooperation among survivors. IDEA systems infer the social identity of surrounding humans, thereby establishing their group membership. By reasoning about groups, we limit the number of cooperation strategies the system needs to explore. IDEA systems select a strategy from the equilibrium analysis of game-theoretic models that represent interactions between group members and the IDEA system. We demonstrate our approach using a search-and-rescue scenario, in which an IDEA rescue robot optimises evacuation by collaborating with survivors. Using an empirically validated agent-based model, we show that the deployment of the IDEA system can reduce median evacuation time by 13.6%. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3678957.3685732,,"Research on non-verbal behavior generation for social interactive agents focuses mainly on the believability and synchronization of non-verbal cues with speech. However, existing models, predominantly based on deep learning architectures, often perpetuate biases inherent in the training data. This raises ethical concerns, depending on the intended application of these agents. This paper addresses these issues by first examining the influence of gender on facial non-verbal behaviors. We concentrate on gaze, head movements, and facial expressions. We introduce a classifier capable of discerning the gender of a speaker from their non-verbal cues. This classifier achieves high accuracy on both real behavior data, extracted using state-of-the-art tools, and synthetic data, generated from a model developed in previous work. Building upon this work, we present a new model, FairGenderGen, which integrates a gender discriminator and a gradient reversal layer into our previous behavior generation model. This new model generates facial non-verbal behaviors from speech features, mitigating gender sensitivity in the generated behaviors. Our experiments demonstrate that the classifier, developed in the initial phase, is no longer effective in distinguishing the gender of the speaker from the generated non-verbal behaviors. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3679240.3734602,,"Power grid operation is becoming more complex due to the increase in generation of renewable energy. The recent series of Learning To Run a Power Network (L2RPN) competitions have encouraged the use of artificial agents to assist human dispatchers in operating power grids. However, the combinatorial nature of the action space poses a challenge to both conventional optimizers and learned controllers. Action space factorization, which breaks down decision-making into smaller sub-tasks, is one approach to tackle the curse of dimensionality. In this study, we propose a centrally coordinated multi-agent (CCMA) architecture for action space factorization. In this approach, regional agents propose actions and subsequently a coordinating agent selects the final action. We investigate several implementations of the CCMA architecture, and benchmark in different experimental settings against various L2RPN baseline approaches. The CCMA architecture exhibits higher sample efficiency and superior final performance than the baseline approaches. The results suggest high potential of the CCMA approach for further application in higher-dimensional L2RPN as well as real-world power grid settings. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3679240.3734670,,"Building control systems typically use either setpoint regulation, where controllers determine optimal setpoints for low-level systems, or direct actuator control, which bypasses the setpoint layer. Despite widespread hierarchical approaches, empirical evidence comparing these strategies remains limited. This paper presents a systematic evaluation of both paradigms using reinforcement learning (RL) with the Building Optimization Performance Test (BOPTEST) framework [1]. We implement and compare: (1) setpoint-trained RL agents using PPO [8], DQN [6], and A2C [5] algorithms, (2) direct actuation-controlled RL agents with identical algorithms, and (3) a conventional PI controller baseline. Experiments span two simulation environments (BESTEST Hydronic Heat Pump and BESTEST Air systems) with constant electricity pricing. Results demonstrate that setpoint regulation achieves near-perfect thermal comfort (>99% discomfort reduction) with modest energy cost increases (4.8–5.0%), while direct actuator control offers smaller energy penalties (1.8–3.2%) with substantial comfort improvements (>80% discomfort reduction). Most significantly, setpoint regulation consistently demonstrated faster learning, requiring 48–79% fewer training steps across algorithms and environments. The setpoint-trained approach also exhibited 38% lower control signal variance (measured as the standard deviation of actuator commands) over the 14-day testing period. These findings provide quantitative evidence supporting a two-level control architecture, where an RL agent optimizes setpoints for existing low-level controllers, while also identifying conditions where direct actuator control by an RL agent may be advantageous. Our research contributes valuable empirical insights for designing energy-efficient building control strategies using reinforcement learning, with setpoint regulation offering significant advantages in training efficiency and control stability. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3686215.3688819,,"Co-speech gestures synthesis is a growing field of research. However, new systems often use complex or heavy architecture, making them unsuitable for incorporation into Embodied Conversational Agents (ECAs) or for interpretation in other research fields such as linguistics, where the link between speech and gestures is difficult to investigate manually. This paper presents STARGATE, a novel architecture for Spatio-Temporal Autoregressive Graph from Audio-Text Embeddings. The model takes advantage of autoregression to provide fast generation capabilities. Additionally, it employs graph convolutions coupled with attention to incorporate explicit structural prior knowledge and enable efficient spatial and temporal processing. The model was evaluated against a state-of-the-art model in both perceptive and quantitative studies. We demonstrated that our model is capable of generating convincing gestures in the same range as state-of-the-art. Furthermore, we conducted in-depth analysis that show how our model actually produces gestures from its input. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3688671.3688778,,"Vision-based end-to-end driving systems have demonstrated impressive capabilities through the utilization of large Transformer architectures.More specifically, researchers have combined Transformers with Imitation Learning, in order to construct agents that learn to map navigation states to actions from large datasets created by experts.Although this approach usually works well, it relies on specific datasets and expert actions, and thus achieving limited generalization capability, which can be quite catastrophic in uncertain navigation environments, such as urban areas.To overcome this limitation, we further expand the training process of the agent by applying the Phasic Policy Gradient algorithm, a Deep Reinforcement Learning (DRL) method that improves its generalization capability by enabling it to explore and interact with the environment.We further enhance our approach by integrating a custom reward function that penalizes the weaknesses of the pretrained agent, alongside with additional DRL techniques to enhance its efficiency and accelerate convergence.Our experimental results in the CARLA simulation environment demonstrate that our approach not only achieves robustness in comparison to previous approaches, but also shows potential for wider application in similar navigation scenarios. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3704919,ACM Transactions on Computational Logic,"We introduce a subclass of concurrent game structures (CGS) with imperfect information in which agents are endowed with private data-sharing capabilities. Importantly, our CGSs are such that it is still decidable to model-check these CGSs against a relevant fragment of ATL. These systems can be thought as a generalization of architectures allowing information forks, that is, cases where strategic abilities lead to certain agents outside a coalition privately sharing information with selected agents inside that coalition. Moreover, in our case, in the initial states of the system, we allow information forks from agents outside a given set to agents inside this group . For this reason, together with the fact that the communication in our models underpins a specialized form of broadcast, we call our formalism -cast systems. To underline, the fragment of ATL for which we show the model-checking problem to be decidable over -cast is a large and significant one; it expresses coalitions over agents in any subset of the set . Indeed, as we show, our systems and this ATL fragments can encode security problems that are notoriously hard to express faithfully: terrorist-fraud attacks in identity schemes. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3705328.3759339,,"In this study, we present a neural network (NN) based recommender system with novel custom loss function developed to recommend fee for its pricelock product. It is a popular add-on product that allows users to lock a flight price and book it later at the same locked price, even if the price increases while flight booking. The core challenge in enabling this product lies in predicting the magnitude of future price changes over time horizons.We formulate this problem as a multi-task learning (MTL) setup, where price change magnitudes are modeled as ordinal categories across several time intervals modeled as heads. Crucially, we address the ordinal nature of price change buckets by introducing a novel loss function called Learnable Soft Ordinal Regression (L-SORD).Our demo showcases how this system improves both predictive accuracy and revenue performance, enabling more effective price recommendations in a high stakes, real world environment. This work highlights the potential of combining MTL architectures with custom loss functions in production grade pricing recommender systems. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3715020.3715042,,"Background: Despite the success of Deep Neural Networks in forecasting the therapeutic efficacy of oncological agents, the lack of explainability of their decision-making process is a significant challenge. They further grapple with two principal challenges: first, the deterministic nature of feature compression, which fails to capture the stochastic essence of data distributions during the inferential process; and second, the inherent limitations of multi-class classification models, which tend to overlook the nuanced interplay of”pro” and”anti” dynamics intrinsic to the target classes. Methods: We propose constructing a composite, interpretable neural network architecture designed to estimate the Mechanism of Action based on a reduced gene expression profile. Furthermore, we introduce a novel ternary loss function that exploits the inherent relationships among the related MoAs, thereby enhancing the model’s predictive accuracy and overall efficacy. Findings: The model expedited the training process, reducing the computational time when compared with alternative tabular learning methodologies. It also demonstrated performance comparable to state-of-the-art deep learning frameworks designed for tabular data processing, even when applied to a condensed gene expression signature. Moreover, leveraging gene expression profiles has enabled the model to predict Mechanisms of Action with a training dataset encompassing approximately 5,000 distinct pharmaceutical compounds. Interpretation: The proposed model effectively predicts the Mechanism of Action of a drug while also allowing the assessment of the importance of the feature attributes. This method remains robust even when applied to a reduced dataset. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3719208,ACM Transactions on Intelligent Systems and Technology,"Reinforcement Learning-Based Recommender Systems (RLRS) have shown promise across a spectrum of applications, from e-commerce platforms to streaming services. Yet, they grapple with challenges, notably in crafting reward functions and harnessing large pre-existing datasets within the RL framework. Recent advancements in offline RLRS provide a solution for how to address these two challenges. However, existing methods mainly rely on the transformer architecture, which, as sequence lengths increase, can introduce challenges associated with computational resources and training costs. Additionally, the prevalent methods employ fixed-length input trajectories, restricting their capacity to capture evolving user preferences. In this study, we introduce a new offline RLRS method to deal with the above problems. We reinterpret the RLRS challenge by modeling sequential decision-making as an inference task, leveraging adaptive masking configurations. This adaptive approach selectively masks input tokens, transforming the recommendation task into an inference challenge based on varying token subsets, thereby enhancing the agent's ability to infer across diverse trajectory lengths. Furthermore, we incorporate a multi-scale segmented retention mechanism that facilitates efficient modeling of long sequences, significantly enhancing computational efficiency. Our experimental analysis, conducted on both online simulator and offline datasets, clearly demonstrates the advantages of our proposed method. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3719384.3719475,,"The rapid expansion of wireless communication and the Internet of Things (IoT) has led to a growing need for real-time data processing. Traditional cloud computing architectures often struggle to meet the low latency, high bandwidth, and low energy consumption requirements of certain applications. In response, Mobile Edge Computing (MEC) has emerged as a promising solution, offloading data processing closer to the user's device at the network's edge, significantly reducing system overhead. This enables more efficient handling of latency-sensitive and energy-efficient applications. One critical challenge in MEC research is optimizing the offloading of computational tasks from user devices to edge nodes, while fully utilizing idle resources to minimize operational overhead and enhance Quality of Service (QoS). This paper focuses on offloading algorithms in a multi-user, multi-edge-node environment, where each user device generates tasks with dependency constraints. The goal is to minimize total system overhead. We propose a parametric modeling approach for task offloading and introduce a Multi-agent Deep Deterministic Policy Gradient (M-DDPG) algorithm to solve the offloading strategy. The M-DDPG algorithm, deployed at the edge layer, is designed to optimize offloading decisions based on state space, observations, action space, and reward mechanisms. Experimental results show that the M-DDPG algorithm outperforms the traditional S-DDPG algorithm in terms of convergence and achieves lower total system overhead, improving overall performance in the edge network environment. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3719545.3759089,,"In recent years, multi-agent reinforcement learning (MARL) has been increasingly applied to swarm intelligence, offering effective solutions for complex decision-making in multi-agent systems. However, MARL models remain vulnerable to imperceptible perturbations, which can lead to erroneous decisions and potentially cause system disruptions or failures. While existing research on adversarial attacks predominantly focuses on traditional supervised learning and single-agent reinforcement learning, the extension to multi-agent scenarios has been largely overlooked. Furthermore, a comprehensive platform for evaluating MARL robustness is lacking. To address this gap, we propose an integrated framework for robust evaluation of MARL. The platform integrates over six classical MARL algorithms, spanning both on-policy and off-policy architectures. It supports more than ten interactive environments across a diverse range of application domains, including gaming, sports, robotics, autonomous vehicles, drones, traffic signal control, and power systems. We have implemented over eight adversarial attack methods - targeting policies, states/observations, actions, rewards, and environments - covering all stages of the MDP closed-loop. Additionally, the platform includes more than five robustness evaluation metrics, addressing both self-model and inter-model perspectives. It supports automated batch experiments and allows for easy customization of agents and environments, enabling seamless integration for rapid MARL robustness research. Our experiments further validate the platform's efficacy in evaluating and improving MARL robustness. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3719545.3759428,,"Building large-scale generalist pre-trained models for many tasks is becoming an emerging and potential direction in reinforcement learning (RL). Research such as Gato and Multi-Game Decision Transformer have displayed outstanding performance and generalization capabilities on many games and domains. However, there exists a research blank about developing highly capable and generalist models in multi-agent RL (MARL), which can substantially accelerate progress toward general AI. To fill this gap, we propose Multi-Agent multi-Game ENtity TrAnsformer (MAGENTA) from the entity perspective as orthogonal research to previous time-sequential modeling. Specifically, to deal with different state/observation spaces in different games, we analogize games as languages by aligning one single game to one single language, thus training different ""tokenizers""and a shared transformer for various games. The feature inputs are split according to different entities and tokenized in the same continuous space. Then, two types of transformer-based models are proposed as permutation-invariant architectures to deal with various numbers of entities and capture the attention of different entities. MAGENTA is trained on Honor of Kings, Starcraft II micromanagement, and Neural MMO with a single set of transformer weights. Extensive experiments show that MAGENTA can play games across various categories with arbitrary numbers of agents and increase the efficiency of fine-tuning in new games and scenarios by 50%-100%. See our project page at https://sites.google.com/view/rl-magenta. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3723498.3723702,,"In this study, we explore the reasoning capabilities of Large Language Models (LLMs) within the context of the social communication game Werewolf, aiming to evaluate their performance in managing complex system states commonly found in computer games. Our agent architecture gathers data, refines them into detailed information, and plans actions based on this knowledge. To demonstrate the feasibility of using LLM based agents in computer games, we developed a simulation and evaluation tool using the Unity game engine. This software enables users to experiment with various LLMs and agent architectures and to measure model performance within the application. For evaluation, we tested three models: GPT-3.5 Turbo, Mistral-7B-OpenOrca, and Nous-Hermes-Llama2-13B. The results show that even smaller models can perform reasonably well in Werewolf. However, their error rate is significantly higher, highlighting the need for additional software modules or fine-tuning to improve their accuracy. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3725843.3756096,"Proceedings of the Annual International Symposium on Microarchitecture, MICRO","Online reinforcement learning (RL) holds promise for microarchitectural techniques like prefetching. Its ability to adapt to changing and previously-unseen scenarios makes it a versatile technique. However, when multiple RL-operated components compete for shared resources in multicore systems, they can often converge to sub-optimal policies due to conflicting incentives. In this work, we identify key challenges that arise when scaling RL-based prefetchers to multi-core environments, and relate these to known problems from Multi-Agent Reinforcement Learning (MARL). In particular, we find that recent work using multi-armed bandit algorithms for prefetching can lead to inefficient systems when memory bandwidth is limited, as each agent attempts to claim a disproportionate share of the system's bandwidth. To solve this problem, we present μMama, a light-weight supervisor of distributed multi-armed bandit agents, which learns performant joint-policies. In μMama, distributed local agents narrow the global joint-action search space, while a central agent with a global perspective learns system-wide policies. Additionally, μMama provides key local agents with a system perspective, encouraging them to avoid actions that would harm the others. μMama exhibits high adaptability, which we show by evaluating it using multiple measures of performance. In our evaluation of an 8-core system, the policies learned by μMama outperform those of independently-operating agents by an average of 2.1% when optimizing for throughput, and by an average of 10.4% when optimizing for fairness. We also show that μMama performs better in systems that are more bandwidth constrained, as well as when profiles of the workloads are provided. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3728725.3728759,,"Accurate segmentation of brain tumors is essential for clinical assessment and treatment planning, as it leverages multiple MRI modalities to provide complementary diagnostic information. However, missing modalities are frequently en- countered in clinical practice due to factors such as image degradation, artifacts, protocol inconsistencies, or patient con- traindications to contrast agents. While certain unified models are designed to accommodate various missing modality scenarios, their performance declines markedly when multiple modalities are absent, particularly in cases where only a single modality is available. To tackle this challenge, we introduce a Guided- learning Network that leverages dynamic FFT filters. This network trains multiple specialized models designed for different missing modality scenarios, achieving outstanding performance. The architecture comprises two distinct learning paths: one dedicated to capturing multimodal information and another focused on generating modality-specific representations for the missing modality. A guided-learning strategy connects these two paths. Initially, the multimodal path is trained and its parameters are locked, enabling the missing modality path to learn under its guidance. The training process incorporates several key com- ponents: adversarial learning to align high-level features across paths, frequency-domain adaptive filtering using dynamic FFT filters to extract global features, and mutual information transfer to ensure critical information is retained even when modality data is missing. Experiments conducted on the BraTS2018 dataset demonstrate that our model outperforms comparable state-of- the-art methods in all missing modality cases. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3728725.3728817,,"With the wide deployment of deep learning models in various applications, the reliability problem of neural networks has gradually become a research hotspot. Computer systems are susceptible to single-particle effects, electromagnetic interference, and other factors in complex environments, resulting in frequent bit-flipping faults. Among them, Silent Data Corruption (SDC), as an imperceptible fault, cannot be detected by the system, which ultimately destroys the output results of neural network models. Current SDC detection techniques mainly focus on the system instruction stream level, and lack efficient methods to implement detection reinforcement at the model level. In addition, due to the black-box weight update mechanism of neural networks, traditional selective redundancy methods cannot provide a reliable explanation of which important weights to fix. To address these issues, this paper proposes a Convolutional Neural Network Reinforcement Framework Based on Neural Network Interpretability (RFNI). RFNI explores the redundancy ratio of convolutional kernels by performing layer-by-layer search in convolutional neural networks through SAC (Soft Actor-Critic) agent; secondly, the importance of each convolutional kernel in the current layer is calculated by combining with neural network interpretability algorithms; and finally, the importance of each convolutional kernel in the current layer is calculated based on the total Floating Point Operations Per Second (FLOPS). Second, the importance of each convolutional kernel in the current layer is calculated by combining with the neural network interpretable algorithm; finally, the granularity configurable redundancy reinforcement is implemented based on the total floating point operations per second (FLOPS). The experimental results show that RFNI on multiple neural network architectures significantly improves the recognition accuracy in case of SDC over existing methods, and can effectively enhance the robustness of the model. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3732778,ACM Transactions on Modeling and Computer Simulation,"Agent-based modeling (ABM) is increasing its popularity and is applied to practical simulation where millions of agents need to interact with each other over a large-scale logical space. Cluster computing is an approach to accommodating ABM’s needs of both CPU and spatial scalability. This research compares three parallel ABM libraries such as FLAME, Repast HPC, and our MASS C++ libraries, all modeling simulation programs in C/C++ and running them in parallel over a cluster system. Our comparative work selects seven benchmark programs from social, behavioral, and economic sciences, biology, and urban planning; parallelizes them with each of these three libraries; analyzes their programmability through the parallelization; and measures their parallel performance. Our results reach two findings. The programmability of each ABM library has different pros and cons in metrics such as total lines of code (LoC), boilerplate percentages, agent/space modeling and management LoC, lack of cohesion of methods (LCOM), ease of agent synchronizations, and semantically smooth coding. Therefore, there is no all-in-one ABM library for best programming any application domains. However, ABM parallel executions are heavily affected by each library’s design principles. In particular, FLAME’s frequent file accesses and message broadcasts as well as Repast HPC’s central agent managements incur system overheads or bottlenecks. These performance drawbacks give MASS C++ an advantage in performing fastest and scaling up simulation most successfully. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3745238.3745531,,"As an important application of large language model(LLM), artificial intelligence agent(AI Agent) have the ability to autonomously perceive, understand, plan, memory, act, and use tools. It can automate complex tasks and effectively empower various business scenarios. Single AI Agent flexible and diverse deployment, multi-AI Agent innovative interaction and collaboration, multi-AI Agent collaboration improves the autonomy of the intelligent system by integrating the capabilities of single AI Agent. This paper provides an overview of multi-AI Agent from four aspects. Firstly, the core capabilities of AI Agent were outlined, and multi-AI Agent collaboration was introduced and its characteristics were analyzed. Secondly, the theoretical basis, key technologies, and scenario applications of multi-AI Agent collaboration were discussed, and the mechanism, architecture design, communication protocol, reinforcement learning, security and trustworthiness of multi-AI Agent collaboration were deeply studied. Thirdly, the advantages and disadvantages of multi-AI Agent collaboration in technology, application, and security directions were summarized, and frontier research and innovation directions were provided. Finally, a summary and outlook were made on the high-quality development of multi-AI Agent collaboration. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3756580.3756593,,"The convergence of Artificial Intelligence (AI) and higher education is revolutionising the paradigm of traditional teaching and learning, this paper proposes a novel framework on top of previous research by means of an advanced dialogue system empowered by attentional mechanisms in the field of Artificial Intelligence in which an AI-driven dialogue agent dynamically evaluates student responses over multiple interactions,using attentional mechanisms to identify key semantic patterns, from conceptual comprehension to logical coherence.The system calibrates student responses through iterative scoring and averaging to build adaptive learner profiles that accurately categorise students into five levels at different proficiency levels (e.g., introductory, basic, intermediate, advanced, proficient).In addition to automated assessment, this approach facilitates personalised learning interventions: high-achieving students receive tailored resources for intellectual development, while students with learning difficulties receive targeted remediation through micro-lessons curated by AI. Technological innovations include a hybrid architecture combining a bi-directional GRU network with a context-aware attention layer optimised to detect subtle awareness gaps in open academic discourse.As higher education struggles to respond to the needs of a mass and diverse learner population, this research highlights how AI's dual role as an analytical tool and instructional partner transforms classrooms into responsive ecosystems where every conversation shapes tomorrow's learning trajectory. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/375735.375741,,"Recent work in animated human-like agent has made impressive progress toward generating agents with believable appearances and realistic motions for the interactive applications of inhabited virtual worlds. It remains difficult, however, to instruct animated agents to perform specific tasks or take initiatives. This paper addresses the challenge of instructability by introducing cognitive modelling - a novel logical approach based on a highly developed logical theory of actions, i. e. Event Calculus. Cognitive models go beyond behavioural models in that they govern an agent s behaviour by reasoning about its knowledge, actions and events. To facilitate the construction of the cognitive models, we propose a high-level behaviour specification language (BSL) from the event calculus formalism. Using BSL, we can specify an agent s domain knowledge, design behaviour controllers and then control the agent s behaviour in terms of goals and/or user s instructions. This approach allows agent s behaviours to be spe cified and controlled more naturally and intuitively, more succinctly and at a much higher level of abstraction than would otherwise be possible. It also provides a logical characterisation of planning via abductive reasoning process. Furthermore, we integrate sensing capability into our underlying theoretical framework, thus enabling animated agents to generate appropriate behaviour even in complex, dynamic virtual worlds. An animated human-like interface agent for virtual environments is used to demonstrate the approach. The architecture for implementing the approach is also described. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3760269.3760299,,"Aiming at the problem of task collaboration and path planning for multi-agent drones in unknown environments, this paper proposes a multi-agent collaborative planning architecture that integrates a large language model (LLM) and a multimodal (MM) perception network, which is used for executing the multi-agent tasks in outdoor environments. This paper innovatively proposes an improved Proximal Policy Optimization (PPO) algorithm for path planning. Through a structured reward function and a joint strategy sharing mechanism, the path planning among multiple drones were efficiently achieved. The system in this paper innovatively proposes a loop intelligent control process called UTTUT (User Instruction, Task Graph Generation, Task Allocation, UAV Feedback, and Task Graph Updating), as well as a P3 (Perception, Planning, Prompt) factor graph model. Theoretically analyzes the interpretability of large model collaborative task planning. The Doubao large language model is introduced as the central control unit, and the Grounding DINO perception model is deployed at the drone end. By combining RGBD, semantic information, and asynchronous scheduling task factors, the perception and positioning of targets in complex scenes are realized. In addition, this paper compares the performances of different large model collaborative frameworks and gets the optimal large model control scheme results. Simulations are carried out on different platforms to verify the superiority of the framework proposed in this paper. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3760269.3760302,,"With the large-scale integration of electric vehicles, disorderly charging behaviors pose a serious challenge to the stability of the power grid. This paper proposes an electric vehicle hierarchical smart charging algorithm based on multi-agent reinforcement learning (HSCA-MARL) to resolve the conflict between individual interests and system constraints in the V2G scenario with only one power transformer. The algorithm adopts a hierarchical hybrid architecture, including the distributed agents, a global coordination agent, and a contribution-driven value transfer mechanism. Each charging station acts as an independent agent and the individual object is optimized through the local Actor-Critic network. The global Critic network quantifies system risks, and the contribution-driven mechanism distributes global Q value based on the contribution of user satisfaction, economic benefits, and load balance. Each individual’s learning is guided by combining global Q value and local Q value, so as to balance team goals and individual goals. Experimental results show that the proposed algorithm outperforms other algorithms in terms of algorithm convergence, global return, and variance of individual return. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3760269.3760353,,"Modern intelligent manufacturing systems are inherently complex, driven by product variety, dynamic scheduling, and intricate interactions among humans, machines, and materials. This complexity presents significant challenges for production planning, control, and decision-making. To address these issues, we propose ABCM (Agent-Based Complexity Management), a novel method that integrates system dynamics simulation with a large language model (LLM)-based agent framework. ABCM utilizes PySD to simulate manufacturing processes and extract structured model outputs, which are analyzed through a suite of modular tools registered within a LangChain agent. These tools enable the computation of descriptive statistics, dynamic performance indicators, and complexity metrics—including entropy, rise time, overshoot, and integral errors—thus allowing for automated, data-driven complexity assessment. The agent autonomously interprets simulation results, identifies performance bottlenecks, and offers optimization recommendations. A case study demonstrates the practical application of ABCM in managing production variability and enhancing system responsiveness. The modular and extensible architecture supports scalable deployment in diverse intelligent manufacturing scenarios, contributing to improved adaptability, efficiency, and complexity control. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3762184,ACM Transactions on Design Automation of Electronic Systems,"The scope of this article is the design verification of a multicore chip or multichip multiprocessor by running concurrent test programs until coverage goals are reached. Interactions between multiple processors through shared memory must obey a memory consistency model, which specifies valid behaviors. We propose a canonical test-program representation that encodes primal shared-memory behaviors to be induced at runtime. It is intended as one of the main keys to the design of new test generators. We prove that our representation does not limit the search space, because it induces equivalence classes that can be completely and uniquely encoded. In particular, we show experimental evidence that our representation is also suitable to learning-based test generators, because it enables the design of effective actions. We have built a generator directed by a Reinforcement Learning agent, designed its actions based on our encoding, and compared it with three generators when targeting 32-core designs. For a given time limit, our generator reached the largest coverage and led to the fastest error diagnosis in 3/4 of the verification scenarios, despite our choice of a minimalist agent. The theoretical guarantees and the experimental evidence indicate that our representation provides proper grounds for defining effective actions, and it prevents them from either inducing redundant tests or limiting the test suite. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/3762329.3762334,,"This paper presents a novel framework for intelligent game AI in real-time 2D shooting games using large language models (LLMs), with Tank War as the testbed. Addressing the limitations of conventional rulebased systems and reinforcement learning approaches in dynamic combat scenarios. Leveraging the inherent interpretability and general-purpose nature of LLMs, our approach demonstrates superior cost-effectiveness and interpretability compared to reinforcement learning systems (requiring no specialized training) while outperforming rule-based architectures in adaptability and intelligence. To successfully and smoothly using LLMs in the game, we propose a hierarchical decision-making architecture that synergizes LLM-based strategic reasoning with real-time tactical execution. Specifically, In the strategic reasoning stage, a LLM is responsible for dispatching tanks to the most suitable destination in order to protect the base or attack the enemy or to wait for an opportunity. In the tactical execution stage, we construct a automatic attack module for attacking enemies in allowed distance, and a path planning module for generating a series of optimal moving actions to the destination and avoid obstacles according to the LLM's output. This work not only advances real-time game AI capabilities but also provides insights for applying LLMs in time-sensitive interactive systems. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1145/964442.964454,"International Conference on Intelligent User Interfaces, Proceedings IUI","In this paper, we describe a new approach to the creation of virtual environments, which uses qualitative physics to implement object behaviour. We adopted Qualitative Process Theory as a qualitative reasoning formalism, due to its representational properties (e.g., its orientation towards process ontologies and its explicit formulation of process' pre-conditions). The system we describe is developed using a game engine and takes advantage of its event-based system to integrate qualitative process simulation in an interactive fashion. We use a virtual kitchen as a test environment. In this virtual world, we have implemented various behaviours: physical object behaviour, complex device behaviour (appliances) and ""alternative"" (i.e. non-realistic) behaviours, which can all be simulated in user real-time. After a presentation of the system architecture and its implementation, we discuss example results from the prototype. This approach has potential applications in simulation and training, as well as in entertainment and digital arts. This work also constitutes a test case for the integration of an Artificial Intelligence technique into 3D user interfaces. Copyright 2004 ACM. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1155/2009/518042,Mobile Information Systems,"Vehicular Ad hoc Networks (VANETs) are a compelling application of ad hoc networks, because of the potential to access specific context information (e.g. traffic conditions, service updates, route planning) and deliver multimedia services (Voice over IP, in-car entertainment, instant messaging, etc.). This paper proposes an agent based information dissemination model for VANETs. A two-tier agent architecture is employed comprising of the following: 1) 'lightweight', network-facing, mobile agents; 2) 'heavyweight', application-facing, norm-aware agents. The limitations of VANETs lead us to consider a hybrid wireless network architecture that includes Wireless LAN/Cellular and ad hoc networking for analyzing the proposed model. The proposed model provides flexibility, adaptability and maintainability for traffic information dissemination in VANETs as well as supports robust and agile network management. The proposed model has been simulated in various network scenarios to evaluate the effectiveness of the approach. © 2009-IOS Press and the authors. All rights reserved. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1155/2010/363065,Eurasip Journal on Wireless Communications and Networking,"We propose a frequency planning based on zone switching diversity scheme for multicell OFDMA mobile WiMAX networks. In our approach, we focus on the use of Fractional Frequency Reuse (FFR) for guaranteeing the quality of service for the different service flows in the system. We investigate an architecture that coordinates the allocation of resources in terms of slots (the basic allocation unit in time and frequency domain in an OFDMA frame) between the Radio Resource Controller (RRC) and the Radio Resource Agent (RRA) which resides in the Base Station (BS). The proposed algorithm attempts to capture three types of diversity, namely, mutual interference diversity, traffic diversity, and selective fading channel diversity. As a consequence, the proposed algorithm for slot allocation makes a trade-off between maximizing overall throughput of the system while guaranteeing the Quality of Service (QoS) requirements for a mixture of real-time and non-real-time service flows under different diversity configurations. Our algorithm is evaluated under various cell configurations and traffic models. The results reveal important insights on the trade-off between cell interference suppression and QoS assurance. Copyright © 2010 T. Ali-Yahiya and H. Chaouchi. © 2010 Elsevier B.V., All rights reserved.",TOPIC
10.1155/2013/505794,Mathematical Problems in Engineering,"Parallel runway is the mainstream structure of China hub airport, runway is often the bottleneck of an airport, and the evaluation of its capacity is of great importance to airport management. This study outlines a model, multiagent architecture, implementation approach, and software prototype of a simulation system for evaluating runway capacity. Agent Unified Modeling Language (AUML) is applied to illustrate the inbound and departing procedure of planes and design the agent-based model. The model is evaluated experimentally, and the quality is studied in comparison with models, created by SIMMOD and Arena. The results seem to be highly efficient, so the method can be applied to parallel runway capacity evaluation and the model propose favorable flexibility and extensibility. © 2013 Yang Peng et al. © 2013 Elsevier B.V., All rights reserved.",TOPIC
10.1155/2014/782789,Journal of Sensors,"Autonomic computing (AC) is a promising approach to meet basic requirements in the design of wireless sensor networks (WSNs), and its principles can be applied to efficiently manage nodes operation and optimize network resources. Middleware for WSNs supports the implementation and basic operation of such networks. In this systematic literature review (SLR) we aim to provide an overview of existing WSN middleware systems that address autonomic properties. The main goal is to identify which development approaches of AC are used for designing WSN middleware system, which allow the self-management of WSN. Another goal is finding out which interactions and behavior can be automated in WSN components. We drew the following main conclusions from the SLR results: (i) the selected studies address WSN concerns according to the self- properties of AC, namely, self-configuration, self-healing, self-optimization, and self-protection; (ii) the selected studies use different approaches for managing the dynamic behavior of middleware systems for WSN, such as policy-based reasoning, context-based reasoning, feedback control loops, mobile agents, model transformations, and code generation. Finally, we identified a lack of comprehensive system architecture designs that support the autonomy of sensor networking. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1155/2015/896943,Mathematical Problems in Engineering,"Reinforcement learning (RL) has shown great potential for motorway ramp control, especially under the congestion caused by incidents. However, existing applications limited to single-agent tasks and based on Q-learning have inherent drawbacks for dealing with coordinated ramp control problems. For solving these problems, a Dyna-Q based multiagent reinforcement learning (MARL) system named Dyna-MARL has been developed in this paper. Dyna-Q is an extension of Q-learning, which combines model-free and model-based methods to obtain benefits from both sides. The performance of Dyna-MARL is tested in a simulated motorway segment in the UK with the real traffic data collected from AM peak hours. The test results compared with Isolated RL and noncontrolled situations show that Dyna-MARL can achieve a superior performance on improving the traffic operation with respect to increasing total throughput, reducing total travel time and CO<inf>2</inf> emission. Moreover, with a suitable coordination strategy, Dyna-MARL can maintain a highly equitable motorway system by balancing the travel time of road users from different on-ramps. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1155/2015/936125,Mobile Information Systems,"This work describes an approach to synergistically exploit ambient intelligence technologies, mobile devices, and evolutionary computation in order to support blended commerce or ubiquitous commerce scenarios. The work proposes a software architecture consisting of three main components: linked data for e-commerce, cloud-based services, and mobile apps. The three components implement a scenario where a shopping mall is presented as an intelligent environment in which customers use NFC capabilities of their smartphones in order to handle e-coupons produced, suggested, and consumed by the abovesaid environment. The main function of the intelligent environment is to help customers define shopping plans, which minimize the overall shopping cost by looking for best prices, discounts, and coupons. The paper proposes a genetic algorithm to find suboptimal solutions for the shopping plan problem in a highly dynamic context, where the final cost of a product for an individual customer is dependent on his previous purchases. In particular, the work provides details on the Shopping Plan software prototype and some experimentation results showing the overall performance of the genetic algorithm. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1155/2017/4259652,Journal of Sensors,"The challenges associated with developing accurate models for cyber-physical systems are attributable to the intrinsic concurrent and heterogeneous computations of these systems. Even though reasoning based on interconnected domain specific ontologies shows promise in enhancing modularity and joint functionality modelling, it has become necessary to build interoperable cyber-physical systems due to the growing pervasiveness of these systems. In this paper, we propose a semantically oriented distributed reasoning architecture for cyber-physical systems. This model accomplishes reasoning through a combination of heterogeneous models of computation. Using the flexibility of semantic agents as a formal representation for heterogeneous computational platforms, we define autonomous and intelligent agent-based reasoning procedure for distributed cyber-physical systems. Sensor networks underpin the semantic capabilities of this architecture, and semantic reasoning based on Markov logic networks is adopted to address uncertainty in modelling. To illustrate feasibility of this approach, we present a Markov logic based semantic event model for cyber-physical systems and discuss a case study of event handling and processing in a smart home. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1155/2018/6170718,Wireless Communications and Mobile Computing,"Today, most energy-intensive processes have a high degree of optimization. However, in some of these processes large amounts of energy are inevitably released due to the way in which this energy is used. One of the most obvious examples is produced in the power plants during the process of obtaining electrical energy through the transformation of some kind of energy (chemical, kinetic, thermal, lighting, and nuclear or solar energy, among others). This released energy can be used in other processes that may need it so that no additional energy is needed. One of the possible uses of this energy is its use in greenhouses. Greenhouses need large amounts of energy to recreate the climatic conditions that crops need, which are not those of the weather station. To take advantage of the energy released from the power stations in greenhouses, a system based on agents has been developed that manages energy and allows it to be reused. This paper explains how the system allows us to reuse energy by a power plant and how the agents that integrate the system by means of communication with sensors and actuators and the use of data analysis algorithms allow us to use this energy in greenhouses, providing a reduction of the energy they need without the system. The system has been tested in several greenhouses with a pepper crop. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1155/2019/4801985,Mathematical Problems in Engineering,"We propose an artificial deep neural network-(ANN-) based automatic parking controller that overcomes a stubborn restriction prevalent in traditional approaches. The proposed ANN learns human-like control laws for automatic parking through supervised learning from a training database generated by computer-Aided optimizations or real experiments. By learning the relationships between the instantaneous vehicle states and the corresponding maneuver parameters, the proposed twin controller yields lateral and longitudinal maneuvering parameters for executing automatic parking tasks in confined spaces. The proposed automatic parking controller exhibits a twin architecture comprising a main agent and its cloned agent. Before the main agent assumes a maneuvering action, the cloned agent predicts the consequences of the maneuvering action through a Collision Checking and Adjustment (CCA) system. The proposed parking agent operates like a human driver in a manner that is characterized by an unplanned trajectory. In addition, the kinematics of the subject vehicle is not exactly modelled for parking control. The simulation results demonstrate that the proposed twin agent emulates the attributes of a human driver such as adaptive control and determines the consequences of the tentative maneuvering action under varying kinematic models of the subject vehicle. We validate the proposed parking controller by simulating the software-in-The-loop architecture using a PreScan simulator in which the dynamics of the virtual vehicle's behavior resemble a real vehicle. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1155/2020/6539123,Advances in Fuzzy Systems,"The paper aims to propose a distributed method for machine learning models and its application for medical data analysis. The great challenge in the medicine field is to provide a scalable image processing model, which integrates the computing processing requirements and computing-aided medical decision making. The proposed Fuzzy logic method is based on a distributed approach of type-2 Fuzzy logic algorithm and merges the HPC (High Performance Computing) and cognitive aspect on one model. Accordingly, the method is assigned to be implemented on big data analysis and data science prediction models for healthcare applications. The paper focuses on the proposed distributed Type-2 Fuzzy Logic (DT2FL) method and its application for MRI data analysis under a massively parallel and distributed virtual mobile agent architecture. Indeed, the paper presents some experimental results which highlight the accuracy and efficiency of the proposed method. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1155/2020/8830359,Complexity,"Most current online distributed machine learning algorithms have been studied in a data-parallel architecture among agents in networks. We study online distributed machine learning from a different perspective, where the features about the same samples are observed by multiple agents that wish to collaborate but do not exchange the raw data with each other. We propose a distributed feature online gradient descent algorithm and prove that local solution converges to the global minimizer with a sublinear rate O2T. Our algorithm does not require exchange of the primal data or even the model parameters between agents. Firstly, we design an auxiliary variable, which implies the information of the global features, and estimate at each agent by dynamic consensus method. Then, local parameters are updated by online gradient descent method based on local data stream. Simulations illustrate the performance of the proposed algorithm. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1155/2021/6136670,Security and Communication Networks,"Software Defined Network (SDN) is a next-generation networking architecture and its power lies in centralized control intelligence. The control plane of SDN can be extended to many underlying networks such as fog to Internet of Things (IoT). The fog-to-IoT is currently a promising architecture to manage a real-time large amount of data. However, most of the fog-to-IoT devices are resource-constrained and devices are widespread that can be potentially targeted with cyber-attacks. The evolving cyber-attacks are still an arresting challenge in the fog-to-IoT environment such as Denial of Service (DoS), Distributed Denial of Service (DDoS), Infiltration, malware, and botnets attacks. They can target varied fog-to-IoT agents and the whole network of organizations. The authors propose a deep learning (DL) driven SDN-enabled architecture for sophisticated cyber-attacks detection in fog-to-IoT environment to identify new attacks targeting IoT devices as well as other threats. The extensive simulations have been carried out using various DL algorithms and current state-of-the-art Coburg Intrusion Detection Data Set (CIDDS-001) flow-based dataset. For better analysis five DL models are compared including constructed hybrid DL models to distinguish the DL model with the best performance. The results show that proposed Long Short-Term Memory (LSTM) hybrid model outperforms other DL models in terms of detection accuracy and response time. To show unbiased results 10-fold cross-validation is performed. The proposed framework is so effective that it can detect several types of cyber-attacks with 99.92% accuracy rate in multiclass classification. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1155/2021/6663243,Mobile Information Systems,"Content Delivery Networks (CDNs) have enabled large-scale, reliable, and efficient content distribution over the Internet. Although CDNs have been very successful in serving a large portion of Internet traffic, they have several drawbacks. Despite their distributed nature, they rely on largely centralized management and replication. This can affect availability in case of node failure. Further, CDNs are complex infrastructures that span multiple layers of the networking stack. To address these issues, in this paper, we introduce NCDN, a novel highly distributed system for large-scale delivery of content and services. NCDN is designed to provide resilience against node failure through location-independent storage and replication of content. This is achieved through a two-layer architecture: the first layer (exposure layer) exposes services implemented by NCDN (e.g., Web, SFTP) to clients; the second layer (hidden layer) provides reliable distributed storage of content and application state. Content in NCDN's hidden layer is stored and exchanged as Named Data Network (NDN) content packets. We employ the reinforcement learning (RL) to dynamically learn the optimal numbers of duplicates for different type of contents, because the RL agent has the advantage of not requiring expert labels or knowledge and instead the ability to learn directly from its own interaction with the world. The combination of NDN and RL brings NCDN fine-grained, fully decentralized content replication mechanisms. We compare the performance and resilience of NCDN to those of an idealized CDN via extensive simulations. Our results show that NCDN is able to provide higher availability than CDNs (between 8% and 100% higher under the same conditions), without substantially increasing content retrieval delay. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1155/2021/8423297,Journal of Sensors,"At the Summer Olympics in Tokyo, technology was used extensively in major sports events. The level of foot movement ability greatly affects the performance of sports technology. Modern sports are developing in the direction of high speed, high skills, flexibility, and rapidity, and more and more reflect the important position of reasonable and accurate foot movement ability in sports. This article uses wireless sensor technology and wireless communication technology to design the overall architecture of the wireless underground footwork mobile training and monitoring network in venues of major sports events. According to the determined monitoring parameters and data transmission plan, a wireless remote monitoring data acquisition system is designed, and the hardware design, software design, and networking of the wireless monitoring node are completed, so as to realize the real-time monitoring and remote transmission of the underlying data. This paper proposes a wireless sensor network management architecture and method based on multiagent cooperation and combines active and passive wireless underground footwork mobile training and monitoring for experimental verification. A multitask allocation strategy optimized for network working life is proposed. A genetic algorithm is used to model and optimize the task data report routing of cluster head nodes. The simulation experiment results show that the wireless sensor network management method based on multiagent cooperation can effectively coordinate different monitoring sensor nodes to complete the assigned monitoring tasks; the multitask assignment strategy based on a genetic algorithm can optimize the working life of the application network. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1155/2022/1231979,Wireless Communications and Mobile Computing,"In view of the inability of traditional interdomain routing schemes to meet the sudden network changes and adapt the routing policy accordingly, many optimization schemes such as modifying Border Gateway Protocol (BGP) parameters and using software-defined network (SDN) to optimize interdomain routing decisions have been proposed. However, with the change and increase of the demand for network data transmission, the high latency and flexibility of these mechanisms have become increasingly prominent. Recent researches have addressed these challenges through multiagent reinforcement learning (MARL), which can be capable of dynamically meeting interdomain requirements, and the multiagent Markov Decision Process (MDP) is introduced to construct this routing optimization problem. Thus, in this paper, an interdomain collaborative routing scheme is proposed in interdomain collaborative architecture. The proposed Feudal Multiagent Actor-Critic (FMAAC) algorithm is designed based on multiagent actor-critic and feudal reinforcement learning to solve this competition-cooperative problem. Our multiagent learns about the optimal interdomain routing decisions, focused on different optimization objectives such as end-to-end delay, throughput, and average delivery rate. Experiments were carried out in the interdomain testbed to verify the convergence and effectiveness of the FMAAC algorithm. Experimental results show that our approach can significantly improve various Quality of Service (QoS) indicators, containing reduced end-to-end delay, increased throughput, and guaranteed over 90% average delivery rate. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1155/2022/2863495,Journal of Healthcare Engineering,"Current guidelines on atrial fibrillation (AF) emphasized that radiofrequency catheter ablation (RFCA) should be decided after fully considering its prognosis. However, a robust prediction model reflecting the complex interactions between the features affecting prognosis remains to be developed. In this paper, we propose a deep learning model for predicting the late recurrence after RFCA in patients with AF. Aiming to predict the late recurrence (LR) of AF within 1 year after pulmonary vein isolation, we designed a multimodal model based on the multilayer perceptron architecture. For quantitative evaluation, we conducted 4-fold cross-validation on data from 177 AF patients including 47 LR patients. The proposed model (area under the receiver operating characteristic curve-AUROC, 0.766) outperformed the acute patient physiologic and laboratory evaluation (APPLE) score (AUROC, 0.605), CHA2DS2-VASc score (AUROC, 0.595), linear regression (AUROC, 0.541), logistic regression (AUROC, 0.546), extreme gradient boosting (AUROC, 0.608), and support vector machine (AUROC, 0.638). The proposed model exhibited better performance than clinical indicators (APPLE and CHA2DS2-VASc score) and machine learning techniques (linear regression, logistic regression, extreme gradient boosting, and support vector machine). The model will support clinical decision-making for selecting good responders to the RFCA intervention. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1155/2022/2870314,Journal of Sensors,"With sixth generation (6G) communication technologies, target sensing can be finished in milliseconds. The mobile tracking-oriented Internet of Things (MTT-IoT) as a kind of emerging application network can detect sensor nodes and track targets within their sensing ranges cooperatively. Nevertheless, huge data processing and low latency demands put tremendous pressure on the conventional architecture where sensing data is executed in the remote cloud and the short transmission distance of 6G channels presents new challenges into the design of network topology. To cope with the above difficulties, this paper proposes a new resource allocation scheme to perform delicate node scheduling and accurate tracking in multitarget tracking mobile networks. The dynamic tracking problem is formulated as an infinite horizon Markov Decision Process (MDP), where the state space that considers energy consumption, system responding delay, and target important degree is extended. A model-free reinforcement learning is applied to obtain satisfied tracking actions by frequent iterations, in which smart agents interact with the complicated environment directly. The performance of each episode is evaluated by the action-value function in search of the optimal reward. Simulation results demonstrate that the proposed scheme shows excellent tracking performance in terms of energy cost and tracking delay. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1155/2022/4193365,Security and Communication Networks,"The task offloading in space-aerial-ground integrated network (SAGIN) has been envisioned as a challenging issue. In this paper, we investigate a space/aerial-assisted edge computing network architecture considering whether to take advantage of edge server mounted on the unmanned aerial vehicle and satellite for task offloading or not. By optimizing the energy consumption and completion delay, we formulate a NP-hard and non-convex optimization problem to minimize the computation cost, limited by the computation capacity and energy availability constraints. By formulating the problem as a Markov decision process (MDP), we propose a multiagent deep reinforcement learning (MADRL)-based scheme to obtain the optimal task offloading policies considering dynamic computation request and stochastic time-varying channel conditions, while ensuring the quality-of-service requirements. Finally, simulation results demonstrate the task offloading scheme learned from our proposed algorithm that can substantially reduce the average cost as compared to the other three single agent deep reinforcement learning schemes. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1155/2022/6095964,Computational and Mathematical Methods in Medicine,"Stroke is a common cerebrovascular disease that threatens human health, and the search for therapeutic drugs is the key to treatment. New drug discovery was driven by many accidental factors in the early stage. With the deepening of research, disease-related target discovery and computer-aided drug design constitute a more rational drug discovery process. The deep learning model was constructed by using recurrent neural network, and then, the classification and prediction of compound-protein interactions were studied. In this study, the network pharmacological prediction of stroke based on deep learning is obtained. (1) In the case of discrete time, a distributed optimization algorithm with finite time convergence is applied. A distributed exact first-order algorithm for the case where the objective function is smooth. On the basis of the DGD algorithm, an additional cumulative correction term is added to correct the error caused by the fixed step size of DGD. Solve multiple optimization problems with equality constraints by using Lagrangian functions. Alternately update the original variable and the dual variable to get the solution of a large global problem. It converges to the optimal solution in an asymptotic or exponential way; that is, the node can reach the optimal solution more accurately when the time tends to infinity. (2) Deep learning, also sometimes called representation learning, has a set of algorithms that can automatically discover the desired classification or detection by feeding it into a machine using raw datasets. Multiple levels of abstraction are abstracted through the use of nonlinear models. This simplifies finding solutions to complex and nonlinear functions. Based on the automatic learning function, it provides the functions of modularization and transfer learning. Deep architectures, which usually contain hidden layers, differ from traditional machine learning, which requires a large amount of data to train the network. There are many levels of modules that are nonlinear and transform the information present on the first level into higher levels which are more abstract in nature and are basically used for feature extraction and transformation. (3) The accuracy rate of the framework based on the multitask deep learning algorithm is 91.73%, and the recall rate reaches 96.13%. The final model was predicted and analyzed using real sample data. In the inference problem, it has the advantages of fast training and low cost; in the generation problem, it also has the advantages of fast training, high stability, high diversity, and high quality of image reconstruction. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1155/2022/7703327,Scientific Programming,"The intelligent programming analysis system based on Internet has attracted more and more attention in the field of education management. The problem of how to flexibly master the application capabilities of intelligent programming and development tools, debugging and optimizing programs, and project deployment is becoming more and more serious. Based on the intelligent programming analysis method, this paper systematically introduces the research and design process of education management model and designs modules such as distributed parallel PhpDig, information analyzer, and information resource database. The system adopts client/middleware/server (C/M/S) three-tier architecture planning and design. The server-side carries the resource manager, the middleware carries the intelligent work tasks (information analyzer, resource collection agent), and the client implements user interaction and data representation solves the storage load problem of a large amount of data. The experimental results show that the semantic processing of search object attributes can improve the retrieval performance, and the retrieval rate and tolerance factor reach 87.6% and 0.041, respectively, which effectively promotes the integration of the analysis data on the chain level and the education system. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1155/2023/2852085,Wireless Communications and Mobile Computing,"The integration of the industrial internet of things (IIoT) and blockchain has become a popular concept that provides IIoT with a trustworthy computing environment. Numerous IIoT nodes together form a decentralized network with rich location-aware computation resources, which can offer great data processing capabilities and low-latency services. However, we still face the challenges of how to efficiently process the massive IIoT data on resource-constrained IIoT nodes by blockchain smart contracts, as their storage capacity only allows them to store limited blockchain data. This work is aimed at improving the smart contract execution efficiency on these IIoT nodes by caching based on deep reinforcement learning. On the one hand, focusing on the characteristics of IIoT, the ledger structure, network architecture, and transaction flow are optimized. IIoT nodes are enabled to store and cache part of block data without affecting global data consistency. On the other hand, we formulated the blockchain caching problem as a Markov decision process and implemented a lightweight caching agent based on deep Q-learning. Proper features and a reward function are defined to minimize the execution delay of smart contracts. The extensive experimental results show that our proposed scheme can effectively reduce the data dissemination costs and smart contract execution delays of IIoT nodes that hold limited blockchain data. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.11591/ijai.v12.i1.pp114-123,IAES International Journal of Artificial Intelligence,"The traffic congestion in vehicular adhoc networks (VANETs) is a vital problem due to its dynamic increase in traffic loads VANETs undergo inefficient routing capability due to its increasing traffic demands. This has led to the need for intelligent transport system (ITS) to assist VANETs in enabling suitable traffic loads between vehicles and road side units (RSU). Most conventional systems offer distributed solution to manage traffic congestion but fail to regulate real-time traffic flows. In this paper, a dynamic traffic control in VANETs is offered by combining deep neural network (DNN) with mobile agents (MA). An experimental analysis is carried out to test the efficacy of the DNN-MA against conventional machine learning and a deep learning routing algorithm in VANETs. DNN-MA is validated under various traffic congestion metrics like latency, percentage delivery ratio, packet error rate, and throughput. The results show that the proposed method offers reduced energy consumption and latency. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.11591/ijece.v12i1.pp515-523,International Journal of Electrical and Computer Engineering,"Learners attend their courses in remote or hybrid systems find it difficult to follow one size fits all courses. These difficulties have increased with the pandemic, lockdown, and the stress they cause. Hence, the role of adaptive systems to recommend personalized learning resources according to the learner's profile. The purpose of this paper is to design a system for recommending learning objects according learner's condition, including his mental state, his COVID-19 history, as well as his social situation and ability to connect to the e-learning system on a regular basis. In this article, we present an architecture of a recommendation system for personalized learning objects based on ontologies and on rule-based reasoning, and we will also describe the inference rules required for the adaptation of the educational content to the needs of the learners, taking into account the learner’s health and mental state, as well as his social situation. The system designed, and validated using the unified modeling language (UML). It additionally allows teachers to have a holistic view of learners’ progress and situations. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.11591/ijece.v13i5.pp5908-5921,International Journal of Electrical and Computer Engineering,"The fast emerging of internet of things (IoTs) has introduced fog computing as an intermediate layer between end-users and the cloud datacenters. Fog computing layer characterized by its closeness to end users for service provisioning than the cloud. However, security challenges are still a big concern in fog and cloud computing paradigms as well. In fog computing, one of the most destructive attacks is man-in-the-middle (MitM). Moreover, MitM attacks are hard to be detected since they performed passively on the network level. This paper proposes a MitM mitigation scheme in fog computing architecture. The proposal mapped the fog layer on software-defined network (SDN) architecture. The proposal integrated multi-path transmission control protocol (MPTCP), moving target defense (MTD) technique, and reinforcement learning agent (RL) in one framework that contributed significantly to improving the fog layer resources utilization and security. The proposed schema hardens the network reconnaissance and discovery, thus improved the network security against MitM attack. The evaluation framework was tested using a simulation environment on mininet, with the utilization of MPTCP kernel and Ryu SDN controller. The experimental results shows that the proposed schema maintained the network resiliency, improves resource utilization without adding significant overheads compared to the traditional transmission control protocol (TCP). © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.11591/ijece.v14i5.pp5543-5553,International Journal of Electrical and Computer Engineering,"This paper introduces an effective intrusion detection system (IDS) for the internet of things (IoT) that employs a conflict-driven learning model within a multi-agent architecture to enhance network security. A double deep Q-network (DDQN) reinforcement learning algorithm is implemented in the proposed IDS with two specialized agents, the defender and the challenger. These agents engaged in an antagonistic adaptation process that dynamically refined their strategies through continual interaction within a custom-made environment designed using OpenAI Gym. The defender agent aims to identify and mitigate threats by matching the actions of the challenger agent, which is designed to simulate potential attacks in the environment. The study introduces a binary reward mechanism to encourage both agents to explore and exploit different actions and discover new strategies as a response to adversarial actions. The results showcase the effectiveness of the proposed IDS in terms of higher detection rate the comparative analysis also validates the effectiveness of the proposed IDS scheme with an accuracy of approximately 96%, outperforming similar existing approaches. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.11591/ijeecs.v26.i2.pp998-1008,Indonesian Journal of Electrical Engineering and Computer Science,"The integration of multi-agent system and blockchain technology can be beneficial to healthcare applications by providing intelligent data analysis with security. This paper presents an architecture that integrates multi-agent learning system and blockchain technology to support breast cancer diagnosis in a secured manner. The proposed system is based on a parallel hybrid fuzzy logic approach for supporting the prediction of breast cancer disease. The proposed system showed a classification accuracy of 96.49% in breast cancer diagnosis when testing with the Wisconsin diagnostic breast cancer dataset. The blockchain is used to provide agent security in the proposed system to ensure that the only trusted and reputed agents are participated in the decision-making process. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1162/comj_a_00662,Computer Music Journal,"Somax2 is an artificial intelligence (AI)-based multiagent system for human–machine “coimprovisation” that generates stylistically coherent streams while continuously listening and adapting to musicians or other agents. The model on which it is based can be used with little configuration to interact with humans in full autonomy, but it also allows fine real-time control of its generative processes and interaction strategies, closer in this case to a “smart” digital instrument. An offspring of the Omax system, conceived at the Institut de Recherche et Coordination Acoustique/Musique (IRCAM), the Somax2 environment is part of the European Research Council Raising Cocreativity in Cyber–Human Musicianship (REACH) project, which studies distributed creativity as a general template for symbiotic interaction between humans and digital systems. It fosters mixed musical reality involving cocreative AI agents. The REACH project puts forward the idea that cocreativity in cyber–human systems results from the emergence of complex joint behavior, produced by interaction and featuring cross-learning mechanisms. Somax2 is a first step toward this ideal, and already shows life-size achievements. This article describes Somax2 extensively, from its theoretical model to its system architecture, through its listening and learning strategies, representation spaces, and interaction policies. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1162/evco_a_00232,Emergent Solutions to High-Dimensional Multitask Reinforcement Learning,"Algorithms that learn through environmental interaction and delayed rewards, or reinforcement learning (RL), increasingly face the challenge of scaling to dynamic, high-dimensional, and partially observable environments. Significant attention is being paid to frameworks from deep learning, which scale to high-dimensional data by decomposing the task through multilayered neural networks. While effective, the representation is complex and computationally demanding. In this work, we propose a framework based on genetic programming which adaptively complexifies policies through interaction with the task. We make a direct comparison with several deep reinforcement learning frameworks in the challenging Atari video game environment as well as more traditional reinforcement learning frameworks based on a priori engineered features. Results indicate that the proposed approach matches the quality of deep learning while being a minimum of three orders of magnitude simpler with respect to model complexity. This results in real-time operation of the champion RL agent without recourse to specialized hardware support. Moreover, the approach is capable of evolving solutions to multiple game titles simultaneously with no additional computational cost. In this case, agent behaviours for an individual game as well as single agents capable of playing all games emerge from the same evolutionary run.",TOPIC
10.1167/tvst.12.1.12,Translational Vision Science and Technology,"Purpose: To determine whether convolutional neural networks can detect morphological differences between images of microbiologically positive and negative corneal ulcers. Methods: A cross-sectional comparison of prospectively collected data consisting of bacterial and fungal cultures and smears from eyes with acute infectious keratitis at Aravind Eye Hospital. Two convolutional neural network architectures (DenseNet and MobileNet) were trained using images obtained from handheld cameras collected from culture-positive and negative images and smear-positive and-negative images. Each architecture was trained on two image sets: (1) one with labels assigned using only culture results and (2) one using culture and smear results. The outcome measure was area under the receiver operating characteristic curve for predicting whether an ulcer would be microbiologically positive or negative. Results: There were 1970 images from 886 patients were included. None of the models were better than random chance at predicting positive microbiologic results (area under the receiver operating characteristic curve ranged from 0.49 to 0.56; all confidence inter-vals included 0.5). Conclusions: These two state-of-the-art deep convolutional neural network architectures could not reliably predict whether a corneal ulcer would be microbiologically positive or negative based on clinical photographs. This absence of detectable morphological differences informs the future development of computer vision models trained to predict the causative agent in infectious keratitis using corneal photography. Translational Relevance: These deep learning models were not able to identify morphological differences between microbiologically positive and negative corneal ulcers. This finding suggests that similar artificial intelligence models trained to identify the causative pathogen using only microbiologically positive cases may have potential to generalize well, including to cases with falsely negative microbiologic testing. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1177/0037549720923401,Simulation,"Analyzing demand behavior of end consumers is pivotal in long term energy planning. Various models exist for simulating household load profiles to cater different purposes. A macroscopic viewpoint necessitates modeling of a large-scale population at an aggregate level, whereas a microscopic perspective requires measuring loads at a granular level, pertinent to the individual devices of a household. Both aspects have lucrative benefits, instigating the need to combine them into a modeling framework which allows model scalability and flexibility, and to analyze domestic electricity consumption at different resolutions. In this applied research, we propose a multi-resolution agent-based modeling and simulation (ABMS) framework for estimating domestic electricity consumption. Our proposed framework simulates per minute electricity consumption by combining large neighborhoods, the behavior of household individuals, their interactions with the electrical appliances, their sociological habits and the effects of exogenous conditions such as weather and seasons. In comparison with the existing energy models, our framework uniquely provides a hierarchical, multi-scale, multi-resolution implementation using a multi-layer architecture. This allows the modelers flexibility in order to model large-scale neighborhoods at one end, without any loss of expressiveness in modeling microscopic details of individuals’ activities at house level, and energy consumption at the appliance level, at the other end. The validity of our framework is demonstrated using a case study of 264 houses. A validated ABMS framework will support: (a) Effective energy planning; (b) Estimation of the future energy demand; (c) and the analysis of the complex dynamic behavior of the consumers. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1177/0278364908104855,International Journal of Robotics Research,"Medical nanorobotics exploits nanometer-scale components and phenomena with robotics to provide new medical diagnostic and interventional tools. Here, the architecture and main specifications of a novel medical interventional platform based on nanorobotics and nanomedicine, and suited to target regions inaccessible to catheterization, are described. The robotic platform uses magnetic resonance imaging (MRI) for feeding back information to a controller responsible for the real-time control and navigation along pre-planned paths in the blood vessels of untethered magnetic carriers, nanorobots, and/or magnetotactic bacteria (MTB) loaded with sensory or therapeutic agents acting like a wireless robotic arm, manipulator, or other extensions necessary to perform specific remote tasks. Unlike known magnetic targeting methods, the present platform allows us to reach locations deep in the human body while enhancing targeting efficacy using real-time navigational or trajectory control. We describe several versions of the platform upgraded through additional software and hardware modules allowing enhanced targeting efficacy and operations in very difficult locations such as tumoral lesions only accessible through complex microvasculature networks. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1177/0278364920961809,International Journal of Robotics Research,"For mobile robots navigating on sidewalks, the ability to safely cross street intersections is essential. Most existing approaches rely on the recognition of the traffic light signal to make an informed crossing decision. Although these approaches have been crucial enablers for urban navigation, the capabilities of robots employing such approaches are still limited to navigating only on streets that contain signalized intersections. In this article, we address this challenge and propose a multimodal convolutional neural network framework to predict the safety of a street intersection for crossing. Our architecture consists of two subnetworks: an interaction-aware trajectory estimation stream (interaction-aware temporal convolutional neural network (IA-TCNN)), that predicts the future states of all observed traffic participants in the scene; and a traffic light recognition stream AtteNet. Our IA-TCNN utilizes dilated causal convolutions to model the behavior of all the observable dynamic agents in the scene without explicitly assigning priorities to the interactions among them, whereas AtteNet utilizes squeeze-excitation blocks to learn a content-aware mechanism for selecting the relevant features from the data, thereby improving the noise robustness. Learned representations from the traffic light recognition stream are fused with the estimated trajectories from the motion prediction stream to learn the crossing decision. Incorporating the uncertainty information from both modules enables our architecture to learn a likelihood function that is robust to noise and mispredictions from either subnetworks. Simultaneously, by learning to estimate motion trajectories of the surrounding traffic participants and incorporating knowledge of the traffic light signal, our network learns a robust crossing procedure that is invariant to the type of street intersection. Furthermore, we extend our previously introduced Freiburg Street Crossing dataset with sequences captured at multiple intersections of varying types, demonstrating complex interactions among the traffic participants as well as various lighting and weather conditions. We perform comprehensive experimental evaluations on public datasets as well as our Freiburg Street Crossing dataset, which demonstrate that our network achieves state-of-the-art performance for each of the subtasks, as well as for the crossing safety prediction. Moreover, we deploy the proposed architectural framework on a robotic platform and conduct real-world experiments that demonstrate the suitability of the approach for real-time deployment and robustness to various environments. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1177/1729881418785073,International Journal of Advanced Robotic Systems,"This article presents a cloud-based multi-agent architecture for the intelligent management of aerial robots in a disaster response situation. In a disaster scenario, a team of highly maneuverable quadcopters is deployed to carry out surveillance and decision support in disaster-affected areas. In Pakistan, such events usually result from sudden unpredictable calamities such as earthquakes. The aim of this work is to develop a robust mechanism to autonomously manage and react to sensory inputs received in soft real time from an unstructured environment. The immediate goal is to locate the maximum number of trapped, injured people within a large area, and help first responders plan rescue activities accordingly. To evaluate the proposed framework, a number of simulations are carried out using GAMA platform to emulate a disaster environment. Subsequently, algorithms are developed to survey an affected geographical area through the use of small flight drones. The key challenges in this work are related to the combination of the domains of multi-agent technology, robotics, and cloud computing for effectively bridging the cyber world with the physical world. Therefore, the proposed work demonstrates the effective use of a limited number of drones to capture inputs from a disaster situation in the physical world, and such inputs are used for timely planning of rescue efforts. The results of fixed resource assignment are compared with the proposed reactive assignment strategy, and it clearly shows a significant improvement in terms of resource usage compared to traditional approach. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1177/22808000241245298,Journal of Applied Biomaterials and Functional Materials,"In the current study, Cnicus benedictus extract was loaded into electrospun gelatin scaffolds for diabetic wound healing applications. Scaffolds were characterized in vitro by mechanical testing, cell culture assays, electron microscopy, cell migration assay, and antibacterial assay. In vivo wound healing study was performed in a rat model of diabetic wound. In vitro studies revealed fibrous architecture of our developed dressings and their anti-inflammatory properties. In addition, Cnicus benedictus extract-loaded wound dressings prevented bacterial penetration. In vivo study showed that wound size reduction, collagen deposition, and epithelial thickness were significantly greater in Cnicus benedictus extract-loaded scaffolds than other groups. Gene expression studies showed that the produced wound dressings significantly upregulated VEGF and IGF genes expression in diabetic wounds. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1177/23998083231224831,Environment and Planning B: Urban Analytics and City Science,"Agent-based models are computational methods for simulating the actions and reactions of autonomous entities with the ability to capture their effects on a system through interaction rules. This study develops an agent-based simulation model (RANGE) to replicate the growth of Sydney Trains network by given exogenous historical evolution in land use. A set of locational rules has been defined to find a sequence of optimal stations from an initial seed. The model framework is an iterative process that includes five consecutive components including environment loading, measuring access, locating stations, connecting stations, and evaluating connections. In each iteration, following the locating/connecting process in each line of railways network, the accessibility will be calculated, and land use will be updated. Based on the compilation of network topology and properties, each iteration will be a year-on-year time step analysis. The network evolves based on a set of locational rules in regards to changes in the historic land use. Also, two coverage indices are defined to evaluate the fitness of the simulated lines in comparison to the Sydney tram and train network. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1186/2194-3206-1-3,Complex Adaptive Systems Modeling,"Purpose: This paper is to describe development of the features and functions of Repast Simphony, the widely used, free, and open source agent-based modeling environment that builds on the Repast 3 library. Repast Simphony was designed from the ground up with a focus on well-factored abstractions. The resulting code has a modular architecture that allows individual components such as networks, logging, and time scheduling to be replaced as needed. The Repast family of agent-based modeling software has collectively been under continuous development for more than 10 years. Method: Includes reviewing other free and open-source modeling libraries and environments as well as describing the architecture of Repast Simphony. The architectural description includes a discussion of the Simphony application framework, the core module, ReLogo, data collection, the geographical information system, visualization, freeze drying, and third party application integration. Results: Include a review of several Repast Simphony applications and brief tutorial on how to use Repast Simphony to model a simple complex adaptive system. Conclusions: We discuss opportunities for future work, including plans to provide support for increasingly large-scale modeling efforts. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1186/2194-3206-2-3,Complex Adaptive Systems Modeling,"Purpose: Following Holland, complex adaptive systems (CASs) are collections of interacting, autonomous, learning decision makers embedded in an interactive environment. Modeling CASs is challenging for a variety of reasons including the presence of heterogeneity, spatial relationships, nonlinearity, and, of course, adaptation. The challenges of modeling CASs can largely be overcome by using the individual-level focus of agent-based modeling. Agent-based modeling has been used successfully to model CASs in many disciplines. Many of these models were implemented using agent-based modeling software such as Swarm, Repast 3, Repast Simphony, Repast for High-Performance Computing, MASON, NetLogo, or StarLogo. All of these options use modular imperative architectures with factored agents, spaces, a scheduler, logs, and an interface. Many custom agent-based models also use this kind of architecture. This paper’s contribution is to introduce and apply a theoretical formalism for analyzing modular imperative agent-based models of CASs. This paper includes an analysis of three example models to show how the formalism is useful for predicting the execution time and space requirements for representations of common CASs. Method: The paper details the formalism and then uses it to prove several new findings about modular imperative agent-based models. Results: It is proven that the asymptotic time and space performance of modular imperative agent-based modeling studies is computationally optimal for a common class of problems. Here ‘optimal’ means that no other technique can solve the same problem computationally using less asymptotic time or space. Modular imperative agent-based models are shown to be universal models, subject to the correctness of the Church-Turing thesis. Several other results are also proven about the time and space performance of modular imperative agent-based models. The formalism is then used to predict the performance of three models and the results are found to compare closely to the measured performance. Conclusions: This paper’s contribution is to introduce, analyze, and apply a theoretical formalism for proving findings about agent-based models with modular agent scheduler architectures. Given that this kind of modeling is both computationally optimal and a natural structural match for many modeling problems, it follows that it is the best modeling method for such problems. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1186/s12859-021-04352-9,BMC Bioinformatics,"Background: One of the major challenges in precision medicine is accurate prediction of individual patient’s response to drugs. A great number of computational methods have been developed to predict compounds activity using genomic profiles or chemical structures, but more exploration is yet to be done to combine genetic mutation, gene expression, and cheminformatics in one machine learning model. Results: We presented here a novel deep-learning model that integrates gene expression, genetic mutation, and chemical structure of compounds in a multi-task convolutional architecture. We applied our model to the Genomics of Drug Sensitivity in Cancer (GDSC) and Cancer Cell Line Encyclopedia (CCLE) datasets. We selected relevant cancer-related genes based on oncology genetics database and L1000 landmark genes, and used their expression and mutations as genomic features in model training. We obtain the cheminformatics features for compounds from PubChem or ChEMBL. Our finding is that combining gene expression, genetic mutation, and cheminformatics features greatly enhances the predictive performance. Conclusion: We implemented an extended Graph Neural Network for molecular graphs and Convolutional Neural Network for gene features. With the employment of multi-tasking and self-attention functions to monitor the similarity between compounds, our model outperforms recently published methods using the same training and testing datasets. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1186/s12859-024-05983-4,BMC Bioinformatics,"Antimicrobial peptides (AMPs) are a promising class of antimicrobial drugs due to their broad-spectrum activity against microorganisms. However, their clinical application is limited by their potential to cause hemolysis, the destruction of red blood cells. To address this issue, we propose a deep learning model based on convolutional neural networks (CNNs) for predicting the hemolytic activity of AMPs. Peptide sequences are represented using one-hot encoding, and the CNN architecture consists of multiple convolutional and fully connected layers. The model was trained on six different datasets: HemoPI-1, HemoPI-2, HemoPI-3, RNN-Hem, Hlppredfuse, and AMP-Combined, achieving Matthew’s correlation coefficients of 0.9274, 0.5614, 0.6051, 0.6142, 0.8799, and 0.7484, respectively. Our model outperforms previously reported methods and can facilitate the development of novel AMPs with reduced hemolytic activity, which is crucial for their therapeutic use in treating bacterial infections. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1186/S12911-025-02986-W,BMC Medical Informatics and Decision Making,"Background Accurately predicting the depth of anesthesia is essential for ensuring patient safety and optimizing surgical outcomes. Traditional regression-based approaches often struggle to model the complex and dynamic nature of patient responses to anesthetic agents. Machine learning techniques offer a promising alternative by capturing intricate relationships within physiological data. This study proposes a hybrid model integrating Long ShortTerm Memory (LSTM) networks, Transformer architectures, and Kolmogorov-Arnold Networks (KAN) to improve the predictive accuracy of anesthesia depth. Methods The proposed model combines multiple deep learning techniques to address different aspects of anesthesia prediction. The LSTM component captures the sequential nature of drug administration and physiological responses. The Transformer architecture utilizes attention mechanisms to enhance contextual understanding of patient data. The KAN models nonlinear relationships between drug infusion histories and anesthesia depth. The model was trained and evaluated on patient data from a publicly available anesthesia monitoring database. Performance was assessed using Mean Squared Error (MSE) and compared against other models. Results The hybrid model demonstrated superior predictive performance compared to conventional regression approaches. Tested on the VitalDB database, the proposed framework achieved a MSE of 0.0062, which is lower than other methods. The inclusion of attention mechanisms and nonlinear modeling contributed to improved accuracy and robustness. The results indicate that the combined approach effectively captures the temporal and nonlinear characteristics of anesthesia depth, offering a more reliable predictive tool for clinical use. Conclusions This study presents a novel deep learning framework for anesthesia depth prediction, integrating sequential, attention-based, and nonlinear modeling techniques. The results suggest that this hybrid approach enhances prediction reliability and provides anesthesiologists with a more comprehensive analysis of factors influencing anesthesia depth. Future research will focus on refining model robustness, exploring real-time applications, and addressing potential biases in predictive analytics to further improve clinical decision-making. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1186/s12951-021-00980-8,Journal of Nanobiotechnology,"Background: Biofilm formation is one of the main reasons for persistent bacterial infections. Recently, pH-sensitive copolymers have fascinated incredible attention to tackle biofilm-related infections. However, the proper incorporation of pH-sensitive segments in the polymer chains, which could significantly affect the biofilms targeting ability, has not been particularly investigated. Herein, we synthesized three types of pH-sensitive copolymers based on poly (β-amino ester) (PAE), poly (lactic-co-glycolic acid) (PLA) and polyethylene glycol (PEG), PAE-PLA-mPEG (A-L-E), PLA-PAE-mPEG (L-A-E) and PLA-PEG-PAE (L-E-A) to address this issue. Results: The three copolymers could self-assemble into micelles (M<inf>A-L-E</inf>, M<inf>L-A-E</inf> and M<inf>L-E-A</inf>) in aqueous medium. Compared with M<inf>A-L-E</inf> and M<inf>L-A-E</inf>, placing the PAE at the distal PEG end of PLA-PEG to yield PLA-PEG-PAE (M<inf>L-E-A</inf>) was characterized with proper triggering pH, fully biofilm penetration, and high cell membrane binding affinity. Further loaded with Triclosan (TCS), M<inf>L-E-A</inf>/TCS could efficiently kill the bacteria either in planktonic or biofilm mode. We reasoned that PAE segments would be preferentially placed near the surface and distant from the hydrophobic PLA segments. This would increase the magnitude of surface charge-switching capability, as the cationic PAE+ would easily disassociate from the inner core without conquering the additional hydrophobic force arising from covalent linkage with PLA segments, and rapidly rise to the outermost layer of the micellar surface due to the relative hydrophilicity. This was significant in that it could enable the micelles immediately change its surface charge where localized acidity occurred, and efficiently bind themselves to the bacterial surface where they became hydrolyzed by bacterial lipases to stimulate release of encapsulated TCS even a relatively short residence time to prevent rapid wash-out. In vivo therapeutic performance of M<inf>L-E-A</inf>/TCS was evaluated on a classical biofilm infection model, implant-related biofilm infection. The result suggested that M<inf>L-E-A</inf>/TCS was effective for the treatment of implant-related biofilm infection, which was proved by the efficient clearance of biofilm-contaminated catheters and the recovery of surrounding infected tissues. Conclusions: In summary, elaboration on the architecture of pH-sensitive copolymers was the first step to target biofilm. The M<inf>L-E-A</inf> structure may represent an interesting future direction in the treatment of biofilm-relevant infections associated with acidity. Graphic abstract: [Figure not available: see fulltext.] © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1186/s12951-024-02680-5,Journal of Nanobiotechnology,"On a global note, oral health plays a critical role in improving the overall human health. In this vein, dental-related issues with dentin exposure often facilitate the risk of developing various oral-related diseases in gums and teeth. Several oral-based ailments include gums-associated (gingivitis or periodontitis), tooth-based (dental caries, root infection, enamel erosion, and edentulous or total tooth loss), as well as miscellaneous diseases in the buccal or oral cavity (bad breath, mouth sores, and oral cancer). Although established conventional treatment modalities have been available to improve oral health, these therapeutic options suffer from several limitations, such as fail to eradicate bacterial biofilms, deprived regeneration of dental pulp cells, and poor remineralization of teeth, resulting in dental emergencies. To this end, the advent of nanotechnology has resulted in the development of various innovative nanoarchitectured composites from diverse sources. This review presents a comprehensive overview of different nanoarchitectured composites for improving overall oral health. Initially, we emphasize various oral-related diseases, providing detailed pathological circumstances and their effects on human health along with deficiencies of the conventional therapeutic modalities. Further, the importance of various nanostructured components is emphasized, highlighting their predominant actions in solving crucial dental issues, such as anti-bacterial, remineralization, and tissue regeneration abilities. In addition to an emphasis on the synthesis of different nanostructures, various nano-therapeutic solutions from diverse sources are discussed, including natural (plant, animal, and marine)-based components and other synthetic (organic- and inorganic-) architectures, as well as their composites for improving oral health. Finally, we summarize the article with an interesting outlook on overcoming the challenges of translating these innovative platforms to clinics. Graphical abstract: (Figure presented.) © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1186/s13321-021-00488-1,Journal of Cheminformatics,"Protein solubility is significant in producing new soluble proteins that can reduce the cost of biocatalysts or therapeutic agents. Therefore, a computational model is highly desired to accurately predict protein solubility from the amino acid sequence. Many methods have been developed, but they are mostly based on the one-dimensional embedding of amino acids that is limited to catch spatially structural information. In this study, we have developed a new structure-aware method GraphSol to predict protein solubility by attentive graph convolutional network (GCN), where the protein topology attribute graph was constructed through predicted contact maps only from the sequence. GraphSol was shown to substantially outperform other sequence-based methods. The model was proven to be stable by consistent R 2 of 0.48 in both the cross-validation and independent test of the eSOL dataset. To our best knowledge, this is the first study to utilize the GCN for sequence-based protein solubility predictions. More importantly, this architecture could be easily extended to other protein prediction tasks requiring a raw protein sequence.[Figure not available: see fulltext.] © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1186/s13321-022-00646-z,Journal of Cheminformatics,"A plethora of AI-based techniques now exists to conduct de novo molecule generation that can devise molecules conditioned towards a particular endpoint in the context of drug design. One popular approach is using reinforcement learning to update a recurrent neural network or language-based de novo molecule generator. However, reinforcement learning can be inefficient, sometimes requiring up to 105 molecules to be sampled to optimize more complex objectives, which poses a limitation when using computationally expensive scoring functions like docking or computer-aided synthesis planning models. In this work, we propose a reinforcement learning strategy called Augmented Hill-Climb based on a simple, hypothesis-driven hybrid between REINVENT and Hill-Climb that improves sample-efficiency by addressing the limitations of both currently used strategies. We compare its ability to optimize several docking tasks with REINVENT and benchmark this strategy against other commonly used reinforcement learning strategies including REINFORCE, REINVENT (version 1 and 2), Hill-Climb and best agent reminder. We find that optimization ability is improved ~ 1.5-fold and sample-efficiency is improved ~ 45-fold compared to REINVENT while still delivering appealing chemistry as output. Diversity filters were used, and their parameters were tuned to overcome observed failure modes that take advantage of certain diversity filter configurations. We find that Augmented Hill-Climb outperforms the other reinforcement learning strategies used on six tasks, especially in the early stages of training or for more difficult objectives. Lastly, we show improved performance not only on recurrent neural networks but also on a reinforcement learning stabilized transformer architecture. Overall, we show that Augmented Hill-Climb improves sample-efficiency for language-based de novo molecule generation conditioning via reinforcement learning, compared to the current state-of-the-art. This makes more computationally expensive scoring functions, such as docking, more accessible on a relevant timescale. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1186/s13634-024-01173-9,Eurasip Journal on Advances in Signal Processing,"Being able to robustly interact with and navigate a dynamic environment has been a long-standing challenge in intelligent transportation systems. Autonomous agents can use models that mimic the human brain to learn how to respond to other participants’ actions in the environment and proactively coordinate with the dynamics. Modeling brain learning procedures is challenging for multiple reasons, such as stochasticity, multimodality, and unobservant intents. Active inference may be defined as the Bayesian modeling of a brain with a biologically plausible model of the agent. Its primary idea relies on the free energy principle and the prior preference of the agent. It enables the agent to choose an action that leads to its preferred future observations. An exploring action-oriented model is introduced to address the inference complexity and solve the exploration–exploitation dilemma in unobserved environments. It is conducted by adapting active inference to an imitation learning approach and finding a theoretical connection between them. We present a multimodal self-awareness architecture for autonomous driving systems where the proposed techniques are evaluated on their ability to model proper driving behavior. Experimental results provide the basis for the intelligent driving system to make more human-like decisions and improve agent performance to avoid a collision. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1186/s13638-017-1018-9,Eurasip Journal on Wireless Communications and Networking,"The developments in wireless sensor network (WSN) that enriches with the unique capabilities of cognitive radio technique are giving impetus to the evolution of Cognitive Wireless Sensor Network (CWSN). In a CWSN, wireless sensor nodes can opportunistically transmit on vacant licensed frequencies and operate under a strict interference avoidance policy with the other licensed users. However, typical constraints of energy conservation from battery-driven design, local spectrum availability, reachability with other sensor nodes, and large-scale network architecture with complex topology are factors that maintain an acceptable network performance in the design of CWSN. In addition, the distributed nature of sensor networks also forces each sensor node to act cooperatively for a goal of maximizing the performance of overall network. The desirable features of CWSN make Multi-agent Reinforcement Learning (RL) technique an attractive choice. In this paper, we propose a reinforcement learning-based transmission power and spectrum selection scheme that allows individual sensors to adapt and learn from their past choices and those of their neighbors. Our proposed scheme is multi-agent distributed and is adaptive to both the end-to-end source to sink data requirements and the level of residual energy contained within the sensors in the network. Results show significant improvement in network lifetime when compared with greedy-based resource allocation schemes. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1186/s13638-021-01895-6,Eurasip Journal on Wireless Communications and Networking,"In the last few years, the Internet of Things (IOT), as a new disruptive technology, has gradually changed the world. With the prosperous development of the mobile Internet and the rapid growth of the Internet of Things, various new applications continue to emerge, such as mobile payment, face recognition, wearable devices, driverless, VR/AR, etc. Although the computing power of mobile terminals is getting higher and the traditional cloud computing model has higher computing power, it is often accompanied by higher latency and cannot meet the needs of users. In order to reduce user delay to improve user experience, and at the same time reduce network load to a certain extent, edge computing, as an application of IOT, came into being. In view of the new architecture after dating edge computing, this paper focuses on the task offloading in edge computing, from task migration in multi-user scenarios and edge server resource management expansion, and proposes a multi-agent load balancing distribution based on deep reinforcement learning DTOMALB, a distributed task allocation algorithm, can perform a reasonable offload method for this scenario to improve user experience and balance resource utilization. Simulations show that the algorithm has a certain adaptability compared to the traditional algorithm in the scenario of multi-user single cell, and reduces the complexity of the algorithm compared to the centralized algorithm, and reduces the average response delay of the overall user. And balance the load of each edge computing server, improve the robustness and scalability of the system. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1186/s13640-015-0059-4,Eurasip Journal on Image and Video Processing,"Spiking neural networks (SNN) have gained popularity in embedded applications such as robotics and computer vision. The main advantages of SNN are the temporal plasticity, ease of use in neural interface circuits and reduced computation complexity. SNN have been successfully used for image classification. They provide a model for the mammalian visual cortex, image segmentation and pattern recognition. Different spiking neuron mathematical models exist, but their computational complexity makes them ill-suited for hardware implementation. In this paper, a novel, simplified and computationally efficient model of spike response model (SRM) neuron with spike-time dependent plasticity (STDP) learning is presented. Frequency spike coding based on receptive fields is used for data representation; images are encoded by the network and processed in a similar manner as the primary layers in visual cortex. The network output can be used as a primary feature extractor for further refined recognition or as a simple object classifier. Results show that the model can successfully learn and classify black and white images with added noise or partially obscured samples with up to ×20 computing speed-up at an equivalent classification ratio when compared to classic SRM neuron membrane models. The proposed solution combines spike encoding, network topology, neuron membrane model and STDP learning. © 2015 Elsevier B.V., All rights reserved.",TOPIC
10.1186/s13677-023-00446-2,Journal of Cloud Computing,"Cloud computing has completely revolutionized the concept of computing by providing users with always-accessible resources. In terms of computational, storage, bandwidth, and transmission costs, cloud technology offers its users an entirely new set of advantages and cost savings. Cross-cloud data migration, required whenever a user switches providers, is one of the most common issues the users encounter. Due to smartphones’ limited local storage and computational power, it is often difficult for users to back up all data from the original cloud servers to their mobile phones to upload and download the data to the new cloud provider. Additionally, the user must remember numerous tokens and passwords for different applications. In many instances, the anonymity of users who access any or all services provided by this architecture must be ensured. Outsourcing IT resources carries risks, particularly regarding security and privacy, because cloud service providers manage and control all data and resources stored in the cloud. However, cloud users would prefer that cloud service providers not know the services they employ or the frequency of their use. Consequently, developing privacy protections takes a lot of work. We devised a system of binding agreements and anonymous identities to address this problem. Based on a binding contract and admission control policy (ACP), the proposed model facilitates cross-cloud data migration by fostering cloud provider trust. Finally, Multi-Agent Reinforcement Learning Algorithm (MARL) is applied to identify and classify anonymity in the cloud by conducting various pre-processing techniques, feature selection, and dimensionality reduction. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1186/s13677-023-00512-9,Journal of Cloud Computing,"Aerial base stations (AeBSs), as crucial components of air-ground integrated networks, are widely employed in cloud computing, disaster relief, and various applications. How to quickly and efficiently deploy multi-AeBSs for higher capacity gain has become a key research issue. In this paper, we address the 3D deployment optimization problem of multi-AeBSs with the objective of maximizing system capacity. To overcome communication overhead and privacy challenges in multi-agent deep reinforcement learning (MADRL), we propose a federated deep deterministic policy gradient (Fed-DDPG) algorithm for the multi-AeBS deployment decision. Specifically, a high-altitude platform (HAP)-assisted multi-AeBS deployment architecture is designed, in which low-altitude AeBS act as the local nodes to train its own deployment decision model, while the HAP acts as the global node to aggregate the weights of local models. In this architecture, AeBSs do not exchange raw data, addressing data privacy concerns and reducing communication overhead. Simulation results show that the proposed algorithm outperforms fully distributed MADRL algorithms and closely approximates the performance of multi-agent deep deterministic policy gradient (MADDPG), which requires global information during training, but with less training time. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1186/s42162-021-00158-4,Energy Informatics,"Modeling and simulation have been popularly used for system investigation and evaluation. With proper evaluation, distribution system operators can decide on a reasonable course of action for encouraging energy flexibility and make predictions on the recommended timing and magnitude of system updates under different scenarios. However, there is no efficient tool for system operators to quickly set up and perform simulations of alternative scenarios for system updates before planning their course of action, without much experience with programming or system modeling. This paper proposes an agent-based modeling framework for developing agent-based simulation models of business ecosystems that can be applied to multiple evaluation scenarios by simple configuration of agents and roles. There are two steps in this proposed framework: Step 1 – Interface and role interactions design and Step 2 – Agent architecture and connections design. In addition, the framework depends on a pre-step that covers mapping and architecture development of the business ecosystem to be modeled. The framework is demonstrated with a case study of an energy business ecosystem consisting of an electricity distribution grid with 137 connected domestic consumers. The case study shows that the proposed agent-based modeling framework supports the development of agent-based models for simulating energy business ecosystems. To verify the behavior of the developed agent-based simulation models, a verification procedure of the agent models is briefly discussed, which includes unit, integration, and system testing approaches similar to the ones used in software testing. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1186/s42162-022-00197-5,Energy Informatics,"Electrification of the transportation sector provides several advantages in favor of climate protection and a shared economy. At the same time, the rapid growth of electric vehicles also demands innovative solutions to mitigate risks to the low-voltage network due to unpredictable charging patterns of electric vehicles. This article conceptualizes a stochastic reinforcement learning agent that learns the optimal policy for regulating the charging power. The optimization objective intends to reduce charging time, thus charging faster while minimizing the expected voltage violations in the distribution network. The problem is formulated as a two-stage optimization routine where the stochastic policy gradient agent predicts the boundary condition of the inner non-linear optimization problem. The results confirm the performance of the proposed architecture to control the charging power as intended. The article also provides extensive theoretical background and directions for future research in this discipline. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1186/s42400-023-00199-0,Cybersecurity,"The network security analyzers use intrusion detection systems (IDSes) to distinguish malicious traffic from benign ones. The deep learning-based (DL-based) IDSes are proposed to auto-extract high-level features and eliminate the time-consuming and costly signature extraction process. However, this new generation of IDSes still needs to overcome a number of challenges to be employed in practical environments. One of the main issues of an applicable IDS is facing traffic concept drift, which manifests itself as new (i.e., zero-day) attacks, in addition to the changing behavior of benign users/applications. Furthermore, a practical DL-based IDS needs to be conformed to a distributed (i.e., multi-sensor) architecture in order to yield more accurate detections, create a collective attack knowledge based on the observations of different sensors, and also handle big data challenges for supporting high throughput networks. This paper proposes a novel multi-agent network intrusion detection framework to address the above shortcomings, considering a more practical scenario (i.e., online adaptable IDSes). This framework employs continual deep anomaly detectors for adapting each agent to the changing attack/benign patterns in its local traffic. In addition, a federated learning approach is proposed for sharing and exchanging local knowledge between different agents. Furthermore, the proposed framework implements sequential packet labeling for each flow, which provides an attack probability score for the flow by gradually observing each flow packet and updating its estimation. We evaluate the proposed framework by employing different deep models (including CNN-based and LSTM-based) over the CIC-IDS2017 and CSE-CIC-IDS2018 datasets. Through extensive evaluations and experiments, we show that the proposed distributed framework is well adapted to the traffic concept drift. More precisely, our results indicate that the CNN-based models are well suited for continually adapting to the traffic concept drift (i.e., achieving an average detection rate of above 95% while needing just 128 new flows for the updating phase), and the LSTM-based models are a good candidate for sequential packet labeling in practical online IDSes (i.e., detecting intrusions by just observing their first 15 packets). © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.12694/scpe.v22i2.1895,Scalable Computing,"With the advancement in the technology, deployment of sensors in the industrial or public building is increasing rapidly. The basic aim is to obtain the data from the environment and decision making to the energy saving. The activities caused by the human results the undergoing negative change in the environment. There are many techniques available for decision making and consider the environmental factors solely which cause the energy consumption. However, user’s preferences are not adapted by the systems, but at energy consumption optimization, these systems are very successful. The end-users use the system which considers the factors and their wellbeing are get affected. The distributed generation is incorporated by the Smart Small Grid (SSG), communication network and the sensors for the more reliable, flexible and efficient grid. The energy saving system is presented in this paper which also adapts to the inhabitants preferences apart from environmental conditions consideration. The architecture of Multi-Agent System (MAS) and the agents are utilized for negotiation process performance between the users comfort preferences and optimization degree that according to these preferences, achievement of system is done. The energy consumption of 40% is obtained and in the inhabitants’ behavior pattern, the algorithm was specialized. The 16.89% of reduction is obtained by the existing system and it was focused to obtain the agreement between the system and users for user preference satisfaction and the energy optimization is also performed at the same time. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.12732/ijam.v38i4s.293,International Journal of Applied Mathematics,"Growing computational demand across cloud, fog, and edge infrastructures is intensifying energy consumption and carbon emissions, yet existing scheduling frameworks typically treat power draw as a static, short-term metric. This narrow view struggles with the fluid geography of modern workloads bursty, migratory, and thermally entangled leading to inefficient energy use and weak carbon accountability. To confront these gaps, we introduce a five-stage resource–energy orchestration model that explicitly intertwines spatio-temporal energy prediction, quantum Inspired optimization, live task migration, thermal dynamics, and carbon-economic feedback. The pipeline begins with Multi-Modal Spatio-Temporal Energy Profiler (MSTEP), which continuously profiles heterogeneous nodes through tensor decomposition and graph-temporal convolution, forecasting per-node energy use over 5-second horizons and improving power-capping accuracy by about 12%. Its predictive map drives the Energy-Aware Quantum Inspired Resource Orchestrator (EQUIRO), a classical Hamiltonian optimizer borrowing from quantum annealing to escape local minima, cutting energy consumption by roughly 18% while lowering latency. The resulting plan is enacted by Reinforcement-Driven Adaptive Task Migrator (R-ATM), where policy-gradient agents treat migration as a continuous-time control problem, reducing unnecessary moves by ~20%. To prevent thermal hotspots created by such migrations, Cross-Layer Thermal-Aware Cooling Optimizer (CLTACO) applies physics Informed neural networks to couple micro-scale thermal diffusion with macro cooling strategy, yielding around 15% better power usage effectiveness. Finally, Carbon Impact Feedback and Economic Optimizer (CIFEO) close the loop by translating operational data into carbon-weighted pricing and deferral schedules, achieving near-neutral or positive margins with an estimated 25% cut in carbon footprint. This integrated architecture demonstrates how predictive, cross-layer intelligence can transform cloud-fog-edge scheduling from reactive energy management into proactive carbon-aware economics, pointing toward greener and more economically resilient distributed computing. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.12785/IJCDS/120171,International Journal of Computing and Digital Systems,"In this paper, the Deep Deterministic Policy Gradient (DDPG) reinforcement-learning algorithm is employed to enable a double-jointed robot arm to reach continuously changing target locations. The experimentation of the algorithm is carried out by training an agent to control the movement of this double-jointed robot arm. The architectures of the actor and critic networks are meticulously designed and the DDPG hyperparameters are carefully tuned. An enhanced version of the DDPG is also presented to handle multiple robot arms simultaneously. The trained agents are successfully tested in the Unity Machine Learning Agents environment for controlling both a single robot arm as well as multiple simultaneous robot arms. The testing shows the robust performance of the DDPG algorithm for empowering robot arm maneuvering in complex environments. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.12785/ijcds/130125,International Journal of Computing and Digital Systems,"The Land use management constitutes a multi-dimensional issue affected by a variety of criteria of different significance. Many decision-makers (DMs) are involved in this type of dilemma, and their preferences are often in dispute. To address these issues, researchers created a variety of GDSS with various architectures; nevertheless, not all of them can apply artificial intelligence approaches to mimic human behavior by predciting or classifying solutions. In this work, the authors used a previously designed GDSS named WIM-GDSS as the foundation for developing a new one with various features; the two systems differ in the prediction model employed. The proposed system's prediction module employs a model trained on a multicriteria method known as PROMETHEE II rather than TOPSIS; the latter method is widely used in the literature and provides more choice and flexibility to the user when expressing preferences (more subjective parameters than TOPSIS). The paper includes a real case study in territorial planning, in which the proposed system would manage a group decision-making process for selecting the most suitable vacant zones for housing building. A coordination protocol will ensure DMs cooperation. The AHP approach will be used to assign criteria weights based on the preferences of DMs. This system includes a prediction module that predicts solutions rather than calculating them using a prediction model. In order to choose the optimal model, a comparison study was done between two models: Linear Regression (LR) and Multi Layer Perceptron (MLP). The results suggest that the MLP model is more suited to PROMETHEE II than the LR model, with a 95% accuracy. Future study will broaden the trials to include fuzzy logic approaches and completely integrate the proposed system with the geographic information system. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.12785/ijcds/1571033189,International Journal of Computing and Digital Systems,"Unmanned Aerial Vehicles (UAVs), particularly quadrotors, have become highly versatile platforms for various applications and missions. In this study, the use of Multi-Agent Reinforcement Learning (MARL) in quadrotor control systems is investigated, expanding its conventional usage beyond multi-UAV path planning and obstacle avoidance tasks. While traditional single-agent control techniques face limitations in effectively managing the coupled dynamics associated with attitude control, especially when exposed to complex scenarios and trajectories, this paper presents a novel method to enhance the adaptability and generalization capabilities of Reinforcement Learning (RL) low-level control agents in quadrotors. We propose a framework consisting of collaborative MARL to control the roll, pitch, and yaw of the quadrotor, aiming to stabilize the system and efficiently track various predefined trajectories. Alongside detailing the overall system architecture of the MARL-based attitude control system, we elucidate the training framework, collaborative interactions among agents, neural network structures, and implemented reward functions. While experimental validation is pending, theoretical analyses and simulations illustrate the envisioned benefits of employing MARL for quadrotor control in terms of stability, responsiveness, and adaptability. Central to our approach is the use of multiple actor-critic algorithms within the proposed control architecture. Through a comparative study, we evaluate the performance of the advocated technique against a single-agent RL controller and established linear and nonlinear methodologies, including Proportional-Integral-Derivative (PID) and Backstepping control, highlighting the advantages of collaborative intelligence in enhancing quadrotor control in complex environments. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.12928/telkomnika.v13i3.1382,Telkomnika (Telecommunication Computing Electronics and Control),"Wireless Sensor Network (WSN) is small embedded devices deployed in large scale network with capability to sense, compute, and communicate. It combines modern sensor, microelectronic, computation, communication, and distributed processing technology. WSN has been taking an important contribution in structural health monitoring system, especially in Suramadu Bridge, one of the longest span bridges in Indonesia connecting Surabaya (East Java) and Madura Island. Due to subjected by environmental circumstance, it is necessary to implement intelligent and autonomous WSN to monitor the bridge condition, detect the bridge damage, and send warning message to bridge users when unsafe condition occurs. The multi-agent system is a promising approach to be implemented on intelligent and autonomous WSN, especially in the bridge structural health monitoring system. In this approach agents are empowered to have several intelligent learning capabilities for structural monitoring, damage detection, and prediction. This paper describes multi-agent system conceptual design that will be implemented as model of long span bridge structural health monitoring system considering system architecture and agent organization. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1299/jamdsm.4.673,"Journal of Advanced Mechanical Design, Systems and Manufacturing","In this paper, we propose a technique for the communication between agents in the dynamic generation of a production plan in an autonomous production system using product agents, parts agents and assembly machine agents. A parts agent leads the promotion of processes in this type of assembly system. First, product agents create the assembly process model that contains the assembly sequence to complete the product. Next, product agents generate parts agents that have the assembly process model. Parts agents will be assembled by machines, with some communications between other agents. The proposed system is defined as an event driven architecture. The increase in the costs of communication between agents is polynomial in the number of the agents. Moreover, this system adjusts the production schedule dynamically using only local negotiation when conditions are changed. Finally, we show experimental results with simply examples. Copyright © 2010 by JSME. © 2011 Elsevier B.V., All rights reserved.",TOPIC
10.13052/jcsm2245-1439.1225,Journal of Cyber Security and Mobility,"In the last two decades, the number of rapidly increasing cyber incidents (i.e., data theft and privacy breaches) shows that it is becoming enormously difficult for conventional defense mechanisms and architectures to neutralize modern cyber threats in a real-time situation. Disgruntled and rouge employees/agents and intrusive applications are two notorious classes of such modern threats, referred to as Insider Threats, which lead to data theft and privacy breaches. To counter such state-of-the-art threats, modern defense mechanisms require the incorporation of active threat analytics to proactively detect and mitigate any malicious intent at the employee or application level. Existing solutions to these problems intensively rely on co-relation, distance-based risk metrics, and human judgment. Especially when humans are kept in the loop for access-control policy-related decision-making against advanced persistent threats. As a consequence, the situation can escalate and lead to privacy/data breaches in case of insider threats. To confront such challenges, the security community has been striving to identify anomalous intent for advanced behavioral anomaly detection and auto-resiliency (the ability to deter an ongoing threat by policy tuning). Towards this dimension, we aim to review the literature in this domain and evaluate the effectiveness of existing approaches per our proposed criteria. According to our knowledge, this is one of the first endeavors toward developing evaluation-based standards to assess the effectiveness of relevant approaches in this domain while considering insider employees and intrusive applications simultaneously. There have been efforts in literature towards describing and understanding insider threats in general. However, none have addressed the detection and deterrence element in its entirety, hence making our contribution one of a kind. Towards the end of this article, we enlist and discuss the existing data sets. The data sets can help understand the attributes that play crucial roles in insider threat detection. In addition, they can be beneficial for testing the newly designed security solutions in this domain. We also present recommendations for establishing a baseline standard for analyzing insider-threat data sets. This baseline standard could be used in the future to design resilient architectures and provide a road map for organizations to enhance their defense capabilities against insider threats. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.13052/jicts2245-800X.1314,Deep Reinforcement Learning-Based Asymmetric Convolutional Autoencoder for Intrusion Detection,"In recent years, intrusion detection systems (IDSs) have become a critical component of network security, due to the growing number and complexity of cyber-attacks. Traditional IDS methods, including signature-based and anomaly-based detection, often struggle with the high-dimensional and imbalanced nature of network traffic, leading to suboptimal performance. Moreover, many existing models fail to efficiently handle the diverse and complex attack types. In response to these challenges, we propose a novel deep learning-based IDS framework that leverages a deep asymmetric convolutional autoencoder (DACA) architecture. Our model combines advanced techniques for feature extraction, dimensionality reduction, and anomaly detection into a single cohesive framework. The DACA model is designed to effectively capture complex patterns and subtle anomalies in network traffic while significantly reducing computational complexity. By employing this architecture, we achieve superior detection accuracy across various types of attacks even in imbalanced datasets. Experimental results demonstrate that our approach surpasses several state-of-the-art methods, including HCM-SVM, D1-IDDS, and GNN -IDS, achieving high accuracy, precision, recall, and F1-score on benchmark datasets such as NSL-KDD and UNSW-NB15. The results emphasize how effectively our model identifies complex and varied attack patterns. In conclusion, the proposed IDS model offers a promising solution to the limitations of current detection systems, with significant improvements in performance and efficiency. This approach contributes to advancing the development of robust and scalable network security solutions.",TOPIC
10.13052/jicts2245-800X.934,6G Mobile Communications for Multi-Robot Smart Factory,"Private or special-purpose wireless networks present a new technological trend for future mobile communications, while one attractive application scenario is the wireless communication in a smart factory. In addition to wireless technologies, this paper pays special attention to treat a smart factory as the integration of collaborative multi-robot systems for production robots and transportation robots. Multiple aspects of collaborative multi-robot systems enabled by wireless networking have been investigated, dynamic multi-robot task assignment for collaborative production robots and subsequent transportation robots, social learning to enhance precision and robustness of collaborative production robots, and more efficient operation of collaborative transportation robots. Consequently, the technical requirements of 6G mobile communication can be logically highlighted.",TOPIC
10.13052/JWE1540-9589.2325,Journal of Web Engineering,"The aviation business encounters difficulties in correctly and swiftly predicting flight fares due to the dynamic nature of the sector. Factors such as variations in demand, fuel costs, and the intricacies of various routes have an impact on this. This work presents a new method to tackle this issue by utilizing generative artificial intelligence (GAI) approaches to accurately forecast airfares in real-time. This paper presents a novel framework that integrates generative models, deep learning architectures, and historical pricing data to improve the precision of future flight price predictions. The study employs a GAI within a cutting-edge web engineering framework. This approach is designed primarily to gather knowledge about complex patterns and relationships present in historical airline data. Through the utilization of this methodology, the model is able to accurately perceive complex connections and adjust to ever-changing market conditions. Our model utilizes deep neural networks to effectively handle various circumstances and extract vital information, so facilitating a comprehensive comprehension of the intricate elements that impact flight cost. Moreover, the suggested approach places significant emphasis on precisely predicting upcoming occurrences in real-time, facilitating prompt reactions to market volatility and offering a valuable resource for airlines, travel agents, and customers alike. In order to enhance the accuracy of real-time forecasts, we utilize a web-based platform that allows for smooth interaction with live data streams and guarantees swift updates. The results demonstrate the model’s capacity to adjust to dynamic market conditions, rendering it an attractive option for stakeholders in search of precise and current forecasts of flight prices. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1364/JOCN.10.000482,Journal of Optical Communications and Networking,"Focused on reducing capital expenditures by opening the data plane to multiple vendors without impacting performance, node disaggregation is attracting the interest of network operators. Although the softwaredefined networking (SDN) paradigm is key for the control of such networks, the increased complexity of multilayer networks strictly requires monitoring/telemetry and data analytics capabilities to assist in creating and operating self-managed (autonomic) networks. Such autonomicity greatly reduces operational expenditures, while improving network performance. In this context, a monitoring and data analytics (MDA) architecture consisting of centralized data storage with data analytics capabilities, together with a generic node agent for monitoring/telemetry supporting disaggregation, is presented. A YANG data model that allows one to clearly separate responsibilities for monitoring configuration from node configuration is also proposed. The MDA architecture and YANG data models are experimentally demonstrated through three different use cases: i) virtual link creation supported by an optical connection, where monitoring is automatically activated; ii) multilayer self-configuration after bit error rate (BER) degradation detection, where a modulation format adaptation is recommended for the SDN controller to minimize errors (this entails reducing the capacity of both the virtual link and supported multiprotocol label switching-transport profile (MPLS-TP) paths); and iii) optical layer selfhealing, including failure localization at the optical layer to find the cause of BER degradation. A combination of active and passive monitoring procedures allows one to localize the cause of the failure, leading to lightpath rerouting recommendations toward the SDN controller avoiding the failing element(s). © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1364/JOCN.11.000371,Journal of Optical Communications and Networking,"To keep up with constantly growing user demands for services with higher quality and bandwidth requirements, telecommunication operators are forced to upgrade their networks. This upgrade, or migration of the network to a new technology, is a complex strategic network planning problem that involves technoeconomic evaluations over multiple periods of time. The state-of-the-art approaches consider migrations to a concrete architecture and do not take uncertainties, such as user churn, into account. This results in migration cost underestimations and profitability overestimations. In this paper, we propose a generic migration algorithm derived from a search-based rational agent decision process that can deal with uncertainties and provides the migration path using a maximized utility function. The algorithm maximizes the migration project profitability, measured as the accumulated net present value. This flexible and generic methodology has been evaluated on the example of migration from existing copper networks to the future-proof passive optical network architectures. Our proposed flexible migration algorithm is validated over pure residential and converged scenarios in a fully reproducible case study. The results affirm that migration flexibility is key to profit maximization. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1364/JOCN.494694,Software defined networking agent demonstration to enable configuration and management of XGS-PON architectures,"This paper describes the design and implementation of an OpenFlow software defined network (SDN) agent that manages and configures 10-gigabit-capable symmetric passive optical network (XGS-PON) architectures. Acting as an OpenFlow switch, the SDN agent communicates with an SDN controller using OpenFlow, while holding direct communication with the optical line terminal (OLT) through the chipset manufacturer-specific application programming interface, eliminating the need for emulating SDN layers in hardware devices. The proposal was evaluated through experiments conducted on a White Box XGS-PON OLT using the Open Network Operating System. The results demonstrate that the proposal facilitates a real-time SDN configuration of various Internet services, successfully fulfilling different quality of service requirements. Due to its ease of deployment, low complexity, smooth learning curve, scalability, and flexibility in integrating services, the proposal has significant potential. As a result, it offers a rapid SDN solution for configuring and testing new functionalities with minimal programming changes required in specific layers of the developed SDN agent.",TOPIC
10.1371/journal.pcbi.1006176,PLOS Computational Biology,"We use reinforcement learning to train an agent for computational RNA design: given a target secondary structure, design a sequence that folds to that structure in silico. Our agent uses a novel graph convolutional architecture allowing a single model to be applied to arbitrary target structures of any length. After training it on randomly generated targets, we test it on the Eterna100 benchmark and find it outperforms all previous algorithms. Analysis of its solutions shows it has successfully learned some advanced strategies identified by players of the game Eterna, allowing it to solve some very difficult structures. On the other hand, it has failed to learn other strategies, possibly because they were not required for the targets in the training set. This suggests the possibility that future improvements to the training protocol may yield further gains in performance. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1371/journal.pcbi.1006460,PLOS Computational Biology,"The delivery of blood-borne therapeutic agents to solid tumours depends on a broad range of biophysical factors. We present a novel multiscale, multiphysics, in-silico modelling framework that encompasses dynamic tumour growth, angiogenesis and drug delivery, and use this model to simulate the intravenous delivery of cytotoxic drugs. The model accounts for chemo-, hapto- and mechanotactic vessel sprouting, extracellular matrix remodelling, mechano-sensitive vascular remodelling and collapse, intra- and extravascular drug transport, and tumour regression as an effect of a cytotoxic cancer drug. The modelling framework is flexible, allowing the drug properties to be specified, which provides realistic predictions of in-vivo vascular development and structure at different tumour stages. The model also enables the effects of neoadjuvant vascular normalisation to be implicitly tested by decreasing vessel wall pore size. We use the model to test the interplay between time of treatment, drug affinity rate and the size of the vessels’ endothelium pores on the delivery and subsequent tumour regression and vessel remodelling. Model predictions confirm that small-molecule drug delivery is dominated by diffusive transport and further predict that the time of treatment is important for low affinity but not high affinity cytotoxic drugs, the size of the vessel wall pores plays an important role in the effect of low affinity but not high affinity drugs, that high affinity cytotoxic drugs remodel the tumour vasculature providing a large window for the normalisation of the vascular architecture, and that the combination of large pores and high affinity enhances cytotoxic drug delivery efficiency. These results have implications for treatment planning and methods to enhance drug delivery, and highlight the importance of in-silico modelling in investigating the optimisation of cancer therapy on a personalised setting. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1371/journal.pcbi.1007342,PLOS Computational Biology,"Stochastic mechanistic epidemiological models largely contribute to better understand pathogen emergence and spread, and assess control strategies at various scales (from withinhost to transnational scale). However, developing realistic models which involve multi-disciplinary knowledge integration faces three major challenges in predictive epidemiology: Lack of readability once translated into simulation code, low reproducibility and reusability, and long development time compared to outbreak time scale. We introduce here EMULSION, an artificial intelligence-based software intended to address those issues and help modellers focus on model design rather than programming. EMULSION defines a domain-specific language to make all components of an epidemiological model (structure, processes, parameters) explicit as a structured text file. This file is readable by scientists from other fields (epidemiologists, biologists, economists), who can contribute to validate or revise assumptions at any stage of model development. It is then automatically processed by EMULSION generic simulation engine, preventing any discrepancy between model description and implementation. The modelling language and simulation architecture both rely on the combination of advanced artificial intelligence methods (knowledge representation and multi-level agent-based simulation), allowing several modelling paradigms (from compartment- to individual- based models) at several scales (up to metapopulation). The flexibility of EMULSION and its capability to support iterative modelling are illustrated here through examples of progressive complexity, including late revisions of core model assumptions. EMULSION is also currently used to model the spread of several diseases in real pathosystems. EMULSION provides a command-line tool for checking models, producing model diagrams, running simulations, and plotting outputs. Written in Python 3, EMULSION runs on Linux, MacOS, and Windows. It is released under Apache-2.0 license. A comprehensive documentation with installation instructions, a tutorial and many examples are available from: Https://sourcesup. renater.fr/www/emulsion-public. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1371/journal.pcbi.1012853,PLOS Computational Biology,"When formed in vivo, murine hemostatic thrombi exhibit a heterogeneous architecture comprised of distinct regions of densely and sparsely packed platelets. In this study, we utilize high-resolution electron microscopy alongside machine learning and physics-based simulations to investigate how such clot microstructure impacts molecular diffusivity. We used Serial Block Face – Scanning Electron Microscopy (SBF-SEM) to image select volumes of hemostatic masses formed in a mouse jugular vein, producing high-resolution 2D images. Images were segmented using machine learning software (Cellpose), whose training was augmented by manually segmented images. The segmented images were then utilized as 2D computational domains for Lattice Kinetic Monte-Carlo (LKMC) simulations. This process constitutes a computational pipeline that combines purely data-derived biological domains with physics-driven simulations to estimate how molecular movement is hindered in a hemostatic platelet mass. Using our pipeline, we estimated that the 2D hindered diffusion rates of a globular protein range from 2% to 40% of the unhindered rate, with denser packing regions lending to lower molecular diffusivity. These data suggest that coagulation reactions rates, thrombin generation and activity, as well as platelet releasate activity may be drastically impacted by the internal geometry of a hemostatic thrombus. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.14201/ADCAIJ201981512,Advances in Distributed Computing and Artificial Intelligence Journal,"A multi-agent architecture has been developed for tutorial assignation scheduling. It has two main types of agents: the students and the teachers. These two are coordinated by an algorithm which assigns the classes in order of arrival. The architecture will provide the necessary tools to the students, so they get the maximum profit from the tutorials. Students and Lecturers can coordinate their tutorial meeting in an efficient way with the help of the multi-agent system. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.14313/JAMRIS/1-2020/4,"Journal of Automation, Mobile Robotics and Intelligent Systems","Inspired by the multi-agent systems, we propose a model-based distributed control architecture for robotic manipulators. Here, each of the joints of the manipulator is controlled using a joint level controller and these controllers account for the dynamic coupling between the links by interacting among themselves. Apart from the reduced computational time due to distributed computation of the control law at the joint levels, the knowledge of dynamics is fully utilized in the proposed control scheme, unlike the decentralized control schemes proposed in the literature. While the proposed distributed control architecture is useful for a general serial-link manipulator, in this paper, we focus on planar manipulators with revolute joints. We provide a simple model-based distributed control scheme as an illustration of the proposed distributed model-based control architecture. Based on this scheme, distributed model-based controller has been designed for a planar 3R manipulator and simulations results are presented to demonstrate that the manipulator successfully tracks the desired trajectory. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.14324/111.444.amps.2022v21i1.003,Architecture_MPS,"Crossing Cultures is a university-based research initiative that is part of London Metropolitan’s Centre for Urban and Built Ecologies (CUBE) which aims to develop a new pedagogical model. The focus is to provide an inclusive learning environment that facilitates intercultural relationships and group learning, equipping students with essential skills for a globally connected world beyond the subject of architecture. We have paired the design studio activities in London with a field experience of live engagement in southern Italy, in a region suffering from depopulation, while simultaneously experiencing the arrival of asylum seekers. The confluence of these opposing developments creates a need to rebuild local communities and presents an exceptional opportunity for our students to become agents of change. The article outlines how, through the creation of an additional teaching and learning platform for multi-disciplinary research outside the boundaries of the university campus, this teaching practice is raising social capital by attracting and integrating students and asylum seekers alike, adding to population and economic growth. The article concludes by highlighting the unique opportunity to scale up this hybrid studio/field study model, which has arisen because of the COVID-19 pandemic. What is proposed is that now, as universities are developing blended learning delivery models, our observations could feed into a new, expansive model for studying architecture as a student-in-residence mode of study. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.14445/23488379/IJEEE-V11I12P133,SSRG International Journal of Electrical and Electronics Engineering,"Recent progress in ophthalmology provides advanced operating rooms with surgical robots and microscopes. Integrating these tools has a significant impact on the field of retinal surgery. Traditional retinal surgeries were often limited by the risk of tremors and challenges in maintaining steady control during complex surgical procedures, leading to a higher risk of complications. This study proposes a Reinforcement Learning (RL) approach to control a robotic arm in retinal microsurgery to enhance precision and reduce the inherent risks of this delicate procedure. The proposed model consists of several key elements, such as a robotic surgery arm, a microscope, and RL agents to control the surgical instrument in real-time according to the visual feedback from the microscope. The RL agent employs a Deep Q-Network (DQN) architecture by interacting with the environment through a sequence of actions and rewards to enhance the movement of the robotic arm. The model utilizes a Convolutional Neural Network (CNN) to extract features from images or frames for accurate state representation. The results demonstrated superior performance with an accuracy of 95%, precision of 97%, recall of 96%, and an F1 score of 96%. The simulation results confirm the high precision control of the robotic arm for minimizing complications in retinal surgeries. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.14488/BJOPM.2020.044,Brazilian Journal of Operations and Production Management,"Goal: This research provides specific solution for dynamic scheduling of product-driven production with unique level of detail and original architecture. Design / Methodology / Approach: Design process of scheduling problem-solving MAS is divided into three steps: agent encapsulation of entities participating in scheduling, including concept of agents and responsibilities they assume, system architecture and topology of the agents network, detailed design of decision scheme of individual agents. Results: Production processes take place in dynamic environment and have to react to numerous real-time events, hence reschedule the production by a new design and implement agent-based model in order to solve dynamic flexible job shop scheduling problem in product-driven production environment. Limitations of the investigation: Designed model counts with simple agents behaving on condition-action rules. These agents could be replaced by more sophisticated types of agents such as utility-based or learning agents. Also the implemented coordination mechanism ensuring global view on the scheduling problem is rather simple. Practical implications: Via simulations of realistic production scenarios it was expected to prove an applicability of specific solution of how bringing the intelligence to the lower levels of control system may be used in dynamic scheduling. Based on elaboration of theoretical basis, principles were identified as suitable or widely used in design of such model. Originality / Value: This research provides specific real-time architecture for a multi-agents dynamic scheduling of product-driven production with unique level of detail and scenarios analysis. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.14529/JSFI230207,Supercomputing Frontiers and Innovations,"One of the promising directions for improving hybrid reconfigurable high-performance computer platforms operating in the mode of collaborative applied computing centers is their inclusion as an active component in the machine learning ecosystem, which opens up new opportunities to enhance the actual outperformance of solving various application tasks by intellectualizing the management of available computing resources. The task scheduler operation is crucial in improving the efficiency of hybrid supercomputer platforms, which combine dozens of processor blocks with different architectures, including specialized graphics and reconfigurable accelerators. To form an optimal order of jobs in the HPC queue, the article proposes to apply deep survival machine learning models, which increase the accuracy of the estimated time of the tasks successful execution and the required amount of computing resources. The main peculiarity of the machine learning models is that they are trained on censored heterogeneous data collected from previous periods of task execution observations using a multi-agent scheduler. In order to ensure high accuracy, the random survival forest is used as a part of the machine learning model which provides survival and hazard functions in the framework of the survival analysis. A specific weighted clustering procedure is proposed to divide tasks in accordance with their execution times as well as the feature vectors. Various numerical experiments with actual data illustrate the outperformance of the presented approach. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.14569/IJACSA.2019.0100345,International Journal of Advanced Computer Science and Applications,"The main objective of Distance Education (DE) is to spread quality education regardless of time and space. This objective is easily achieved with the help of technology. With the development of World Wide Web and high-speed internet the quality of DE is improved because now Digital Content (DC) can be easily and in no time distributed to many learners of different locations in text, audio and video formats. But, the main obstacle in digital publishing is the protection of Intellectual Property Rights (IPR) of DC. Digital Rights Management (DRM) that manages rights over any digital creation is the only solution to this problem. In this paper, we have made an attempt to implement a Digital Rights Management System for Distance Education known as DRMSDE. We have identified that Multi-Agent System (MAS) based technology is very popular for such type of implementations. Keeping that in mind, we have chosen one of the most popular Multi-Agent based tools, namely JAVA Agent Development Framework (JADE), for our system. This paper presents an overview and the system architecture for the proposed implementation. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.14569/ijacsa.2019.0101059,International Journal of Advanced Computer Science and Applications,"After conducting the historical review and establishing the state of the art, the authors of this paper focus on the incorporation of Project Based Learning (PBL), in an adaptive e- Learning environment, a novel and emerging perspective, which allows the application of what today constitutes one of the most effective strategies for the process of teaching learning. In PBL, each project is defined as a complex task or problem of reality, for which resolution, the student must develop research activities, planning, design, development, validation, testing, etc. For the proposal of the Hybrid Architecture of the e-Learning system model, the authors use artificial intelligence techniques, which make it possible to identify the Learning Styles (LS), with the purpose of automatically assigning the projects, according to the characteristics, interests, expectations and demands of the student, who will interact with an e-Learning environment, with a high capacity of adaptation to each individual. Finally, the conclusions and recommendations of the research work are established. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.14569/IJACSA.2019.0101148,International Journal of Advanced Computer Science and Applications,"Parking is a key element of a sustainable urban mobility policy. It plays a fundamental role in travel planning and transport management, as the foremost vector of modal choice, but also as a potential means of freeing up public spaces. In this article we define the smart parking concept, as an application of smart mobility, present a historical analysis of the evolution of smart parking framework and show a statistical analysis of the published patent applications in this field around the world using the ORBIT database. Then, we propose a new smart parking architecture based on multi-agent features. Finally, we introduce the e-Parking system, platform to improve the driver experience of crowded cities. It provides real-time parking prices and offers a reservation and guidance services. In addition, the system assigns an optimal parking for a driver based on the user's requirements that combine proximity to destination, parking cost and dwell time, while ensuring a fair sharing of public space among users and improves traffic conditions. Our approach is based on dynamic pricing policy. Our scheme is suitable for mixed-usage areas, as it considers the presence of reserved and not reserved driver in the same parking area. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.14569/IJACSA.2022.0130108,International Journal of Advanced Computer Science and Applications,"e-Learning has transposed the perception of teaching and learning considering knowledge delivery and knowledge acquirement. Today, e-learning participants access and upload their materials at any time and at any place since e-learning technologies are typically hosted on the cloud. Cloud computing has embellished the base platform for the future of e-learning, however, security and privacy remains a major concern. Cloud-hosted e-learning technologies as they are accessed over the internet suffer from the same risks to information security aspects namely availability, confidentiality, and integrity. In such a context, data authenticity, privacy, access rights and digital footprints are vulnerable in the cloud. Research in this domain focuses on specific components of cloud and e-learning without covering a holistic view of applied cryptographic techniques and practical implementation. Hence, aiming at the various security aspects and impacts of cloud-based e-learning technologies, this paper puts forward reviewing the various cryptographic techniques used to secure data across the whole end-to-end cloud-based e-learning service spectrum using systematic review and exploratory method. The results obtained define several sets of criteria to evaluate the requirements of cryptographic techniques and propose an implementation framework across an end-to-end cloud-based e-learning architecture using multi-agent software. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.14569/IJACSA.2022.0130961,International Journal of Advanced Computer Science and Applications,"Traffic signal control is a way for reducing traffic jams in urban areas, and to optimize the flow of vehicles by minimizing the total waiting times. Several intelligent methods have been proposed to control the traffic signal. However, these methods use a less efficient road features vector, which can lead to suboptimal controls. The objective of this paper is to propose a deep reinforcement learning approach as the hybrid model that combines the convolutional neural network with eXtreme Gradient Boosting to traffic light optimization. We first introduce the deep convolutional neural network architecture for the best features extraction from all available traffic data and then integrated the extracted features into the eXtreme Gradient Boosting model to improve the prediction accuracy. In our approach; cross-validation grid search was used for the hyper-parameters tuning process during the training of the eXtreme Gradient Boosting model, which will attempt to optimize the traffic signal control. Our system is coupled to a microscopic agent-based simulator (Simulation of Urban MObility). Simulation results show that the proposed approach improves significantly the average waiting time when compared to other well-known traffic signal control algorithms. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.14569/IJACSA.2023.0140937,International Journal of Advanced Computer Science and Applications,"Cocoa cultivation is of immense importance to the people of Côte d'Ivoire. However, this culture is experiencing significant challenges due to diseases spread by various agents such as bacteria, viruses, and fungi, which cause considerable economic losses. Currently, the methods available to detect these cocoa diseases force farmers to seek the expertise of agronomists for visual inspections and diagnostics, a laborious and complex process. In the search for solutions, many studies have opted for using convolutional neural networks (CNNs) to identify diseases in cocoa pods. However, an essential advance is to develop hybrid approaches that combine the advantages of a CNN with sophisticated classification algorithms. This research stands out for its innovative contribution, combining MobileNetV2, a convolutional neural network architecture, with algorithms, such as Logistic Regression (LR), K Nearest Neighbors (KNN), Support Vector Machines (SVM), XGBoost, and Random Forest. The study was conducted in two distinct phases. First, each algorithm was evaluated individually, and then performance was measured when MobileNetV2 was merged with the algorithms mentioned. These hybrid approaches complement and amplify MobileNetV2's capabilities. To do so, they draw on MobileNetV2's inherent capabilities to extract key features and enhance information quality. By combining this expertise with the classification methods of these other models, hybrid approaches outperform individual techniques. Accuracy rates range from 72.4% to 86.04%.This performance amplitude underlines the effectiveness of the synergy between the extraction characteristics of MobileNetV2 and the classification skills of other algorithms. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.14569/IJACSA.2025.0160944,International Journal of Advanced Computer Science and Applications,"Precision agriculture increasingly relies on autonomous UAVs for tasks, such as crop monitoring and targeted pesticide spraying. However, maintaining stable flight and precise spray delivery under varying payloads and wind disturbances remains challenging. This paper proposes a hybrid control architecture that combines interpretable Mamdani fuzzy logic controllers with a deep reinforcement learning (DRL) agent (Proximal Policy Optimization, PPO). The fuzzy controllers encode expert-crafted rules for baseline altitude and attitude stabilization, while the PPO agent adaptively adjusts setpoints to optimize spray coverage and energy efficiency. We train the agent in a realistic PyBullet simulator with dynamic payload and wind conditions. In simulated precision-spraying trials, our hybrid controller outperformed both a conventional PID-based controller and a pure PPO controller. Specifically, it achieved roughly 2 –3× faster disturbance rejection, near-zero overshoot, and ~30% faster settling than the baselines, resulting in more uniform coverage and reduced pesticide use. These results demonstrate that fusing fuzzy logic with deep PPO yields a UAV spray controller that is both high-performance and robust for precision agriculture applications. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1504/IJCAT.2010.036027,International Journal of Computer Applications in Technology,"This paper presents a service-oriented architecture that allows a more efficient distribution of resources and functionalities. The architecture has been used to develop a multi-agent system aimed at enhancing the assistance and healthcare for Alzheimer patients living in geriatric residences. Most of the system functionalities have been modelled as independent and distributed services, including reasoning, planning and security mechanisms. The results obtained after testing the architecture in a real healthcare scenario demonstrate that a service-oriented approach is far more robust and has better performance than a centralised one. Copyright © 2010 Inderscience Enterprises Ltd. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1504/IJMMS.2017.084409,International Journal of Mechatronics and Manufacturing Systems,"In this research work a control architecture which gives response to the requirements of new generation of flexible manufacturing systems in terms of flexibility, reconfigurability, robustness and autonomy is designed and implemented. To do so the main principles of the holonic manufacturing paradigm are applied using the IEC61499 function block (FB) technology. Unlike other similar research proposals, in this work FBs are not relegated to low-level control but are used to model manufacturing execution and control high-level control tasks. This is done with the objective of evaluating the viability of using FBs to develop holonic architectures in comparison to more established technologies like multi-Agent systems. Moreover, the proposed control architecture also focuses on better integrating and exploiting the products' information to enhance its flexibility and adaptability. For this STEP-NC (ISO14649) is used to model richer process plans which include manufacturing alternatives and could be easily integrated in the control itself. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1504/IJRIS.2010.034908,International Journal of Reasoning-based Intelligent Systems,"This paper presents an ambient intelligence based architecture model that defines intelligent hybrid agents. These agents have the ability to obtain automatic and real-time information about the context using a set of technologies, such as radio frequency identification, wireless networks and wireless control devices. The architecture can be implemented on a wide diversity of dynamic environments, especially for providing home care to elderly and dependent people. © 2010 Inderscience Enterprises Ltd. © 2016 Elsevier B.V., All rights reserved.",TOPIC
10.1504/IJVD.2023.134751,International Journal of Vehicle Design,"In this paper, lane change process of vehicle is divided into two stages: lane change decision and lane change movement, and put forward the double-layer deep reinforcement learning architecture, the use of upper structure deep Q network (DQN) exchange way to control decision, and send the lane changing information to the lower deep deterministic policy gradient (DDPG) of vehicle trajectory control, After the lane change process the collaborative optimisation of DQN was completed through the feedback of vehicle position information before and after lane change., the collaborative optimisation of DQN is completed. The results show that, the proposed two-layer deep reinforcement learning architecture can increase the average velocity of the agent vehicle by 2–5% and reduce the average lateral speed and lateral acceleration by 12.5% and 12.2% respectively in the lane-changing process. Compared with no collaborative optimisation, the optimal lane change timing of the effectively cooptimised two-layer architecture is 34.64%. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1504/IJWET.2013.055707,International Journal of Web Engineering and Technology,"This paper presents a solution to the problem of the search and retrieval digital tagged content in heterogeneous learning object repositories through architecture for intelligent retrieval of educational content in heterogeneous environments (AIREH) framework. This architecture unifies the search and retrieval of objects, thus facilitating the personalised learning search process by filtering and properly classifying learning objects retrieved for an approach for semantic-aware learning content retrieval based on abstraction layers between the repositories and the search clients. The use of federated databases techniques by using an organisation of agents allows those agents to work in a coordinated manner to solve a common problem, allowing the agents to adapt to the constantly changing environment (users, content repositories, etc.). Combining a complete agent-based architecture that implements the concept of federated search along with IR technologies may help organising and sorting search results in a meaningful way for educational content. Copyright © 2013 Inderscience Enterprises Ltd. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1515/amcs-2015-0033,International Journal of Applied Mathematics and Computer Science,"During interactions, system actors may face up misunderstandings when their local states contain inconsistent data about the same fact. Misunderstandings in interactions are likely to reduce interactivity performances (deviation or deadlock) or even affect overall system behavior. In this paper, we characterize misunderstandings in interactions between system actors (that may be human users or system agents) in interactive adaptive systems. To deal with such misunderstandings and ensure state consistency, we present an agent-based architecture and a scenario structuring approach. The system includes several agents devoted to scenario unfolding, plot adaptation and consistency management. Scenario structuring is based on the notion of a situation that is an elementary building block dividing the interactions between systems' actors into contextual scenes. This pattern supports not only scenario execution but consistency management as well. In order to organize and control interactions, the situation contextualizes interactions and activity of the system's actors. It also includes prevention and tolerance agent-based mechanisms to deal with the misunderstandings and their causes. We validate our consistency management mechanisms using Uppaal simulation and provide some experimental results to show the effectiveness of our approach on an online distance learning case study. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1515/cait-2017-0025,Cybernetics and Information Technologies,"This paper presents an environment which generates tests automatically. It is designed for assistance in the software engineering education and is part of the Virtual Education Space. The environment has two functionalities - generation and assessment of different types of test questions. In the paper, the architecture of the environment is described in detail. The test generation is supported by specialized ontologies, which are served by two intelligent agents known as Questioner Operative and Assessment Operative. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.1515/ijb-2024-0068,International Journal of Biostatistics,"Learning individualized treatment rules (ITRs) for a target patient population with mental disorders is confronted with many challenges. First, the target population may be different from the training population that provided data for learning ITRs. Ignoring differences between the training patient data and the target population can result in sub-optimal treatment strategies for the target population. Second, for mental disorders, a patient's underlying mental state is not observed but can be inferred from measures of high-dimensional combinations of symptomatology. Treatment mechanisms are unknown and can be complex, and thus treatment effect moderation can take complicated forms. To address these challenges, we propose a novel method that connects measurement models, efficient weighting schemes, and flexible neural network architecture through latent variables to tailor treatments for a target population. Patients' underlying mental states are represented by a compact set of latent state variables while preserving interpretability. Weighting schemes are designed based on lower-dimensional latent variables to efficiently balance population differences so that biases in learning the latent structure and treatment effects are mitigated. Extensive simulation studies demonstrated consistent superiority of the proposed method and the weighting approach. Applications to two real-world studies of patients with major depressive disorder have shown a broad utility of the proposed method in improving treatment outcomes in the target population. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1515/jisys-2018-0125,Journal of Intelligent Systems,"Renewable energies constitute an alternative to fossil energies for several reasons. The microgrid can be assumed as the ideal way to integrate a renewable energy source in the production of electricity and give the consumer the opportunity to participate in the electricity market not just like a consumer but also like a producer. In this paper, we present a multi-agent system based on wind and photovoltaic power prediction using the extreme learning machine algorithm. This algorithm was tested on real weather data taken from the region of Tetouan City in Morocco. The process aimed to implement a microgrid located in Tetouan City and composed of different generation units (solar and wind energies were combined together to increase the efficiency of the system) and storage units (batteries were used to ensure the availability of power on demand as much as possible). In the proposed architecture, the microgrid can exchange electricity with the main grid; therefore, it can buy or sell electricity. Thus, the goal of our multi-agent system is to control the amount of power delivered or taken from the main grid in order to reduce the cost and maximize the benefit. To address uncertainties in the system, we use fuzzy logic control to manage the flow of energy, to ensure the availability of power on demand, and to make a reasonable decision about storing or selling electricity. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.1515/JISYS.2005.14.4.321,Journal of Intelligent Systems,"A neural network training method ID-BT (Incremental Discriminatory Batch Training) is presented in this paper. The method separates the input space into two batches - significant and insignificant attributes-and before introducing them into the network, orders the attributes within each batch according to their individual discrimination ability. By backward eliminating insignificant attributes that are futile, the generalization accuracy of network training is increased. Incremental Discriminatory Batch and Individual Training (ID-BIT), which further improves ID-BT, introduces significant attributes individually and insignificant attributes as a batch. The architecture used for both methods employs several incremental learning algorithms. We tested our algorithm extensively, using several widely used benchmark problems, i.e. PROBEN1. The simulation results show that these two methods outperform incremental training with an increasing input dimension or conventional batch training where no partitioning of neural network input space occurs; we can achieve better network performance in terms of generalization accuracy. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.15388/informatica.2010.303,Informatica (Netherlands),"This paper analyses the possibilities of integrating different technological and knowledge representation techniques for the development of a framework for the remote control of multiple agents such as wheelchair-type robots. Large-scale multi-dimensional recognitions of emotional diagnoses of disabled persons often generate a large amount of multi-dimensional data with complex recognition mechanisms, based on the integration of different knowledge representation techniques and complex inference models. The problem is to reveal the main components of a diagnosis as well as to construct flexible decision making models. Sensors can help record primary data for monitoring objects. However the recognition of abnormal situations, clustering of emotional stages and resolutions for certain types of diagnoses is an oncoming issue for bio-robot constructors. The prediction criteria of the diagnosis of the emotional situations of disabled persons are described using knowledge based model of Petri nets. The research results present the development of multi-layered framework architecture with the integration of artificial agents for diagnosis recognition and control of further actions. The method of extension of Petri nets is introduced in the reasoning modules of robots that work in real time. The framework provides movement support for disabled individuals. The fuzzy reasoning is described by using fuzzy logical Petri nets in order to define the physiological state of disabled individuals through recognizing their emotions during their different activities. © 2010 Vilnius University. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.15407/knit2024.02.003,Space Science and Technology,"The article investigates the task of spacecraft relative control using reactive actuators, the output of which has two states, “on” or “off”. For cases where the resolution of the thrusters does not provide an accurate approximation of linear control laws using a pulse-width thrust modulator, the possibility of applying reinforcement learning methods for direct finding of control laws that map the state vector and the on-off thruster commands has been investigated. To implement such an approach, a model of controlled relative motion of two satellites in the form of a Markov decision process was obtained. The intelligent agent is presented in the form of “actor” and “critic” neural networks, and the architecture of these modules is defined. It is proposed to use a cost function with variable weights of control actions, which allows for optimizing the number of thruster firings explicitly. To improve the control performance, it is proposed to use an extended input vector for the “actor” and “critic” neural networks of the intelligent agent, which, in addition to the state vector, also includes information about the control action on the previous control step and the control step number. To reduce the training time, the agent was pre-trained on the data obtained using conventional control algorithms. Numerical results demonstrate that the reinforcement learning methodology allows the agent to outperform the results provided by the linear controller with the pulse-width modulator in terms of control accuracy, response time, and number of thruster firings. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1541/ieejias.121.669,IEEJ Transactions on Industry Applications,"In recent years autonomous distributed scheduling architecture with flexibility and robustness is required in manufacturing systems to facilitate effective manufacturing operation. We proposed a self-organised scheduling methodology as a new scheduling concept based on multi-agent paradigm. Each work is defined as agent in the methodology and cooperates so as to formulate self-organised workflows. This paper studies the abilities of reinforcement learning algorithm with multi-agent paradigm to move appropriately in relation to several process machines. We analyse the effectiveness of a major reinforcement learning algorithm, profit sharing method, in terms of scheduling robustness, and show the rationality of the algorithm in the self-organised scheduling environment. Profit sharing method is proved to enhance the robustness and reliability of work agents coping with the several scheduling demands. © 2001, The Institute of Electrical Engineers of Japan. All rights reserved. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1541/ieejias.125.67,IEEJ Transactions on Industry Applications,"The goal of this research is to develop an intelligent wheelchair (IWC) system which aids an indoor safe mobility for elderly and disabled people with a new conceptual architecture which realizes autonomy, cooperativeness, and a collaboration behavior. In order to develop the IWC system in real environment, we need design-tools and flexible architecture. In particular, as more significant ones, this paper describes two key techniques which are an evolutionary simulation and an overall control mechanism. The evolutionary simulation technique corrects the error between the virtual environment in a simulator and real one in during the learning of an IWC agent, and coevolves with the agent. The overall control mechanism is implemented with subsumption architecture which is employed in an autonomous robot controller. By using these techniques in both simulations and experiments, we confirm that our IWC system acquires autonomy, cooperativeness, and a collaboration behavior efficiently.© 2005, The Institute of Electrical Engineers of Japan. All rights reserved. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.15439/2018F231,,"In this work we present a method for using Deep Q-Networks (DQNs) in multi-objective environments. Deep Q-Networks provide remarkable performance in single objective problems learning from high-level visual state representations. However, in many scenarios (e.g in robotics, games), the agent needs to pursue multiple objectives simultaneously. We propose an architecture in which separate DQNs are used to control the agent's behaviour with respect to particular objectives. In this architecture we introduce decision values to improve the scalarization of multiple DQNs into a single action. Our architecture enables the decomposition of the agent's behaviour into controllable and replaceable sub-behaviours learned by distinct modules. Moreover, it allows to change the priorities of particular objectives post-learning, while preserving the overall performance of the agent. To evaluate our solution we used a game-like simulator in which an agent-provided with high-level visual input-pursues multiple objectives in a 2D world. © 2019 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.15587/1729-4061.2023.280355,Eastern-European Journal of Enterprise Technologies,"The object of research are decision support systems. The subject of research is the decision-making process in management problems using bio-inspired algorithms. A method for the search of solutions in the field of national security using bio-inspired algorithms is proposed. The proposed method is based on a combination of an artificial bat algorithm and evolving artificial neural networks. The method has the following sequence of actions: – input of initial data; – processing of initial data taking into account the degree of uncertainty; – numbering of bat agents (BA); – placement of bat agents taking into account the degree of uncertainty about the state of the analysis object in the search space; – setting the initial BA speed and the echolocation frequency of each BA; – starting a local search; – launching a global search; – training knowledge bases of bat agents. The originality of the proposed method consists in the arrangement of bat agents taking into account the uncertainty of initial data, improved global and local search procedures taking into account the noise degree of data about the state of the analysis object. Another feature of the proposed method is the use of an improved procedure for training bat agents. The training procedure consists in learning the synaptic weights of an artificial neural network, the type and parameters of the membership function, the architecture of individual elements and the architecture of the artificial neural network as a whole. The method makes it possible to increase the efficiency of data processing at the level of 13–21 % due to the use of additional improved procedures. The proposed method should be used to solve the problems of evaluating complex and dynamic processes in the interests of solving national security problems © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.15587/1729-4061.2023.284315,Eastern-European Journal of Enterprise Technologies,"The object of research is decision support systems. The subject of research is the decision-making process in management problems using the fish school (FSH) algorithm, an advanced genetic algorithm and evolving artificial neural networks. A solution search method using an improved FSH algorithm is proposed. The study is based on the FSH algorithm for finding a solution on the object state. For training FSH, evolving artificial neural networks are used. The method has the following sequence of actions: – input of initial data; – processing of initial data taking into account the degree of uncertainty; – checking the fitness function of the solution found; – procedure of feeding fish agents (FA); – instinctive-collective FA swimming; – calculation of the center of school gravity; – collective voluntary FA swimming; – changing the FA swimming parameters; – training of FA knowledge bases. The originality of the proposed method lies in the arrangement of FA taking into account the uncertainty of the initial data, improved global and local search procedures taking into account the degree of noise of data about the state of the analysis object. The peculiarity of the proposed method is the use of an improved FA training procedure. The training procedure consists in learning the synaptic weights of the artificial neural network, the type and parameters of the membership function, the architecture of individual elements and the architecture of the artificial neural network as a whole. The use of the method makes it possible to increase the efficiency of data processing at the level of 18–25 % due to the use of additional improved procedures. The proposed method should be used to solve the problems of evaluating complex and dynamic processes in the interest of solving national security problems. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.15587/1729-4061.2023.287003,Eastern-European Journal of Enterprise Technologies,"The object of the research is decision support systems. The subject of the research is the decision-making process in management problems using the monkey algorithm and evolving artificial neural networks. A solution search method using an improved monkey algorithm is proposed. The research is based on the monkey algorithm – for finding a solution regarding the state of an object. For training monkey agents (MA), evolving artificial neural networks are used. The method has the following sequence of steps: – input of initial data; – processing of initial data taking into account the degree of uncertainty; – a search vector is generated for each MA, taking into account the degree of uncertainty; – determination of the initial speed of MA movement; – calculation of the fitness function of the MA solution; – calculation of the height of MA movement; – verification of fulfillment of local jump conditions; – generation of local search plane coordinates; – calculation of the fitness function of the MA solution; – generation of global search plane coordinates; – search distribution among the MA flock; – changing the speed of MA movement; – checking the permissible value of the obtained solution regarding the object state; – training of MA knowledge bases. The originality of the proposed method lies in the arrangement of MA taking into account the uncertainty of the initial data, improved procedures of global and local search taking into account the degree of noise of data about the state of the analysis object. A feature of the proposed method is the use of an improved MA training procedure. The training procedure consists in learning the parameters and architecture of individual elements and the architecture of the artificial neural network as a whole. The method makes it possible to increase the efficiency of data processing at the level of 23–28 % due to the use of additional improved procedures. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.15587/1729-4061.2023.287316,Eastern-European Journal of Enterprise Technologies,"The object of the research is decision support systems. The subject of the research is the decision-making process in management problems using the locust swarm algorithm and evolving artificial neural networks. A solution search method using an improved locust swarm algorithm is proposed. The research is based on the locust swarm algorithm for finding a solution regarding the state of an object. For training locust agents (LA), evolving artificial neural networks are used. The method has the following sequence of steps: - input of initial data; - processing of initial data taking into account the degree of uncertainty; - initial setting of LA in the search area; - determination of the initial speed of the LA movement; - a search vector is generated taking into account the degree of uncertainty; - calculation of the change in the value of the LA fitness function; - training of LA knowledge bases. The originality of the proposed method lies in the arrangement of LA taking into account the uncertainty of the initial data, improved procedures of global and local search taking into account the degree of noise of data about the state of the analysis object. Also, the originality of the research is avoiding the concentration of LA on the current best positions, reducing the probability of premature convergence of the algorithm and maintaining a balance between the convergence rate of the algorithm and diversification. The peculiarity of the proposed method is the use of an improved procedure for LA training. The training procedure consists in learning the parameters and architecture of individual elements and the architecture of the artificial neural network as a whole © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.15587/1729-4061.2024.318600,Eastern-European Journal of Enterprise Technologies,"The object of the study is a group of unmanned aerial vehicles (UAVs). The subject of the study is the decision-making process in management tasks using: – an improved brown bear algorithm (BBA), which achieves the determination of the optimal UAV movement route based on the given optimization criterion (the probability of completing the flight task), described by complex multimodal functions; – evolving artificial neural networks for deep learning of the multi-agent system knowledge base, by training both the parameters and the architecture of artificial neural networks. The originality of the method lies in using additional improved procedures that allow: – the initial BBA population and their initial position on the search plane are determined considering the degree of uncertainty in the data on the UAV group movement route; – the initial speed of each BBA is considered, enabling the prioritization of searches in the respective search plane (height, latitude, and longitude); – the suitability of the UAV group’s flight route for performing the flight task is determined, considering a set of external factors, thereby reducing the decision search time; – the universality of BBA food search strategies allows classifying a set of conditions and factors affecting the completion of the flight task. This aids in identifying the most feasible movement options for the UAV group based on the defined optimization criterion for movement route. Modeling the operation of the proposed method has shown that the increase in decision-making efficiency reaches 15–18 %. The enhancement in the method’s efficiency is achieved through additional procedures and ensuring the reliability of the decisions at a level of 0.9 © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.15587/1729-4061.2025.315248,Eastern-European Journal of Enterprise Technologies,"Security information systems constitute a significant application domain for the concept of situational awareness. The object of this study is security information systems for residential complexes. The task addressed involved devsigning an efficient, flexible, and adaptive structure to ensure situational awareness in security information systems. Unlike existing systems, this structure is based on the integration of intelligent agents, server services, and a central unit that interacts with the Internet of Things (IoT) network. The proposed system ensures the autonomy of intelligent agents, which perform specialized tasks using integrated intelligent sensors, while server services handle basic computational tasks such as machine learning, pattern matching, and model construction. The central unit aggregates information, implements reasoning procedures, and identifies situations for the entire system. An architecture has been proposed that includes three main subsystems: video surveillance, access control, and operator service management. The essence of the results is the development of a flexible architecture that effectively combines IoT technologies with the situational awareness approach. The research results were achieved by integrating innovative approaches such as the use of intelligent agents, machine learning, and situational analysis, enabling a flexible distribution of functions among system components depending on the specific task requirements. The distinctive features of this architecture facilitate the implementation of the situational awareness principle and support continuous system learning processes. Given its modular architecture, the proposed system could be applied in extensive residential networks serviced by Internet providers, as well as in associations of co-owners of multi-apartment buildings. The formalization of architectural elements simplifies the process of designing and deploying systems, making them accessible for a wide range of applications in residential complexes by Internet service providers © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.15837/ijccc.2010.5.2249,"International Journal of Computers, Communications and Control","Our contribution focuses on the behavioral aspects that are currently used in the modeling of the virtual inhabitants of a reconstructed Greek-Roman colony in the framework of the TOMIS project. The project aims at promoting culture by the mean of the reconstruction of historical sites together with their virtual societies based on virtual and/or augmented reality technologies. Our efforts are oriented both on 3D modeling of virtual humans, animation of the virtual humans on every-day human activities and, most important, on the spicing these activities with human emotions. To this end, we iterate the most common agent-based architectures used to produce credible behavior of the virtual agents (humans or animals) in situations inspired from the real world, and emphasize their direct applicability both in humans and animal animations in order to obtain complex behavior based on atomic activities. Finally, the paper presents the technological issues related to the used motion capture technology, as source of high-definition human atomic actions, that participates in complex action plans for virtual agents activities. © 2006-2010 by CCC Publications. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.15837/ijccc.2013.3.465,"International Journal of Computers, Communications and Control","This work presents the development of MABAP, a decision support system based on the agent technology that helps in solving the problem of berth allocation for ships within a port. The Berth Allocation Problem (BAP) regards the logistics involved in planning and controlling the berthing of vessels. A software architecture in terms of agents is presented; Berths and Ships representing the actors in the system, BerthRequest and BerthPlanner as representatives of ships and berths in the planning process, and finally the Dock and Central agents representing the dock or pier. The architecture modeling was done using PASSI methodology for the design of agent-oriented systems, and the implementation was done in JADE, a Javabased development environment for multiagent systems. To validate the resulting support system, tests were carried out in which the user can choose different portpolicy scenarios, ranging from maximizing vessels throughput to maximize berths use. © 2006-2013 by CCC Publications. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.1587/transinf.2016NTI0002,IEICE Transactions on Information and Systems,"The increase in network access devices and demand for high quality of service (QoS) by the users have led to insufficient capacity for the network operators. Moreover, the existing control equipment and mechanisms are not flexible and agile enough for the dynamically changing environment of heterogeneous cellular networks (HetNets). This nonagile control plane is hard to scale with ever increasing traffic demand and has become the performance bottleneck. Furthermore, the new HetNet architecture requires tight coordination and cooperation for the densely deployed small cell base stations, particularly for interference mitigation and dynamic frequency reuse and sharing. These issues further complicate the existing control plane and can cause serious inefficiencies in terms of users' quality of experience and network performance. This article presents an SDN control framework for energy efficient downlink/uplink scheduling in HetNets. The framework decouples the control plane from data plane by means of a logically centralized controller with distributed agents implemented in separate entities of the network (users and base stations). The scheduling problem consists of three sub-problems: (i) user association, (ii) power control, (iii) resource allocation and (iv) interference mitigation. Moreover, these sub-problems are coupled and must be solved simultaneously. We formulate the DL/UL scheduling in HetNet as an optimization problem and use the Markov approximation framework to propose a distributed economical algorithm. Then, we divide the algorithm into three sub-routines for (i) user association, (ii) power control, (iii) resource allocation and (iv) interference mitigation. These sub-routines are then implemented on different agents of the SDN framework. We run extensive simulation to validate our proposal and finally, present the performance analysis. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.1609/aaai.v24i1.7569,,"We present an instance-based, online method for learning action models in unanticipated, relational domains. Our algorithm memorizes pre- and post-states of transitions an agent encounters while experiencing the environment, and makes predictions by using analogy to map the recorded transitions to novel situations. Our algorithm is implemented in the Soar cognitive architecture, integrating its task-independent episodic memory module and analogical reasoning implemented in procedural memory. We evaluate this algorithm's prediction performance in a modified version of the blocks world domain and the taxi domain. We also present a reinforcement learning agent that uses our model learning algorithm to significantly speed up its convergence to an optimal policy in the modified blocks world domain. © 2024 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.1609/aaai.v25i1.7833,,"Action modeling is an important skill for agents that must perform tasks in novel domains. Previous work on action modeling has focused on learning STRIPS operators in discrete, relational domains. There has also been a separate vein of work in continuous function approximation for use in optimal control in robotics. Most real world domains are grounded in continuous dynamics but also exhibit emergent regularities at an abstract relational level of description. These two levels of regularity are often difficult to capture using a single action representation and learning method, m this paper we describe a system that combines discrete and contmuous action modeling techniques in the Soar cognitive architecture. Our system accents a continuous state representation from the environment and derives a relational state on top of it using spatial relations. The dynamics over each representation is learned separately using two simple instance-based algorithms. The predictions from the individual models are then combined in a way that takes advantage of the information captured by each representation. We empirically show that this combined model is more accurate and generalizable than each of the individual models in a spatial navigation domain. © 2024 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.1609/aaai.v27i1.8469,,"We present GOSMR (""goal oriented scenario modeling robots""), a cognitive architecture designed to show coordinated, goal-directed behavior over the Internet, focusing on the web browser as a case study. The architecture combines a variety of artificial intelligence techniques, including planning, temporal difference learning, elementary reasoning over uncertainty, and natural language parsing, but is designed to be computationally lightweight. Its intended use is to be deployed on virtual machines in large-scale network experiments in which simulated users' adaptation in the face of resource denial should be intelligent but varied. The planning system performs temporal difference learning of action times, discounts goals according to hyperbolic discounting of time-to-completion and chance of success, takes into account the assertions of other agents, and separates abstract action from site-specific affordances. Our experiment, in which agents learn to prefer a social networking style site for sending and receiving messages, shows that utility-proportional goal selection is a reasonable alternative to Boltzmann goal selection for producing a rational mix of behavior. Copyright © 2013, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. © 2024 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.1609/aaai.v33i01.33013412,,"There are many reasons to expect an ability to reason in terms of objects to be a crucial skill for any generally intelligent agent. Indeed, recent machine learning literature is replete with examples of the benefits of object-like representations: generalization, transfer to new tasks, and interpretability, among others. However, in order to reason in terms of objects, agents need a way of discovering and detecting objects in the visual world - a task which we call unsupervised object detection. This task has received significantly less attention in the literature than its supervised counterpart, especially in the case of large images containing many objects. In the current work, we develop a neural network architecture that effectively addresses this large-image, many-object setting. In particular, we combine ideas from Attend, Infer, Repeat (AIR), which performs unsupervised object detection but does not scale well, with recent developments in supervised object detection. We replace AIR's core recurrent network with a convolutional (and thus spatially invariant) network, and make use of an object-specification scheme that describes the location of objects with respect to local grid cells rather than the image as a whole. Through a series of experiments, we demonstrate a number of features of our architecture: that, unlike AIR, it is able to discover and detect objects in large, many-object scenes; that it has a significant ability to generalize to images that are larger and contain more objects than images encountered during training; and that it is able to discover and detect objects with enough accuracy to facilitate non-trivial downstream processing. © 2025 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.1609/aaai.v33i01.33014561,,"Deep reinforcement learning techniques have demonstrated superior performance in a wide variety of environments. As improvements in training algorithms continue at a brisk pace, theoretical or empirical studies on understanding what these networks seem to learn, are far behind. In this paper we propose an interpretable neural network architecture for Q-learning which provides a global explanation of the model's behavior using key-value memories, attention and reconstructible embeddings. With a directed exploration strategy, our model can reach training rewards comparable to the state-of-the-art deep Q-learning models. However, results suggest that the features extracted by the neural network are extremely shallow and subsequent testing using out-of-sample examples shows that the agent can easily overfit to trajectories seen during training. © 2025 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.1609/aaai.v33i01.33014691,,"StarCraft II poses a grand challenge for reinforcement learning. The main difficulties include huge state space, varying action space, long horizon, etc. In this paper, we investigate a set of techniques of reinforcement learning for the full-length game of StarCraft II. We investigate a hierarchical approach, where the hierarchy involves two levels of abstraction. One is the macro-actions extracted from expert's demonstration trajectories, which can reduce the action space in an order of magnitude yet remain effective. The other is a two-layer hierarchical architecture, which is modular and easy to scale. We also investigate a curriculum transfer learning approach that trains the agent from the simplest opponent to harder ones. On a 64×64 map and using restrictive units, we train the agent on a single machine with 4 GPUs and 48 CPU threads. We achieve a winning rate of more than 99% against the difficulty level-1 built-in AI. Through the curriculum transfer learning algorithm and a mixture of combat model, we can achieve over 93% winning rate against the most difficult non-cheating built-in AI (level-7) within days. We hope this study could shed some light on the future research of large-scale reinforcement learning. © 2025 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.1609/aaai.v33i01.33016062,,"This paper introduces the IPOMDP-net, a neural network architecture for multi-agent planning under partial observability. It embeds an interactive partially observable Markov decision process (I-POMDP) model and a QMDP planning algorithm that solves the model in a neural network architecture. The IPOMDP-net is fully differentiable and allows for end-to-end training. In the learning phase, we train an IPOMDP-net on various fixed and randomly generated environments in a reinforcement learning setting, assuming observable reinforcements and unknown (randomly initialized) model functions. In the planning phase, we test the trained network on new, unseen variants of the environments under the planning setting, using the trained model to plan without reinforcements. Empirical results show that our model-based IPOMDP-net outperforms the other state-of-the-art model-free network and generalizes better to larger, unseen environments. Our approach provides a general neural computing architecture for multi-agent planning using I-POMDPs. It suggests that, in a multi-agent setting, having a model of other agents benefits our decision-making, resulting in a policy of higher quality and better generalizability. © 2025 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.1609/aaai.v33i01.33018247,,"Deep learning based methods have achieved remarkable progress in action recognition. Existing works mainly focus on designing novel deep architectures to achieve video representations learning for action recognition. Most methods treat sampled frames equally and average all the frame-level predictions at the testing stage. However, within a video, discriminative actions may occur sparsely in a few frames and most other frames are irrelevant to the ground truth and may even lead to a wrong prediction. As a result, we think that the strategy of selecting relevant frames would be a further important key to enhance the existing deep learning based action recognition. In this paper, we propose an attention-aware sampling method for action recognition, which aims to discard the irrelevant and misleading frames and preserve the most discriminative frames. We formulate the process of mining key frames from videos as a Markov decision process and train the attention agent through deep reinforcement learning without extra labels. The agent takes features and predictions from the baseline model as input and generates importance scores for all frames. Moreover, our approach is extensible, which can be applied to different existing deep learning based action recognition models. We achieve very competitive action recognition performance on two widely used action recognition datasets. © 2025 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.1609/aaai.v35i13.17360,,"In explainable artificial intelligence, there is increasing interest in understanding the behaviour of autonomous agents to build trust and validate performance. Modern agent architectures, such as those trained by deep reinforcement learning, are currently so lacking in interpretable structure as to effectively be black boxes, but insights may still be gained from an external, behaviourist perspective. Inspired by conceptual spaces theory, we suggest that a versatile first step towards general understanding is to discretise the state space into convex regions, jointly capturing similarities over the agent’s action, value function and temporal dynamics within a dataset of observations. We create such a representation using a novel variant of the CART decision tree algorithm, and demonstrate how it facilitates practical understanding of black box agents through prediction, visualisation and rule-based explanation. © 2024 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.1609/aaai.v35i13.17366,,"Many systems proposed for the implementation of ethical reasoning involve an encoding of user values as a set of rules or a model. We consider the question of how changes of context affect these encodings. We propose the use of a reasoning cycle, in which information about the ethical reasoner’s context is imported in a logical form, and we propose that context-specific aspects of an ethical encoding be prefaced by a guard formula. This guard formula should evaluate to true when the reasoner is in the appropriate context and the relevant parts of the reasoner’s rule set or model should be updated accordingly. This architecture allows techniques for the model-checking of agent-based autonomous systems to be used to verify that all contexts respect key stakeholder values. We implement this framework using the hybrid ethical reasoning agents system (HERA) and the model-checking agent programming languages (MCAPL) framework. © 2025 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.1609/aaai.v35i14.17470,,"Deep reinforcement learning approaches have shown impressive results in a variety of different domains, however, more complex heterogeneous architectures such as world models require the different neural components to be trained separately instead of end-to-end. While a simple genetic algorithm recently showed end-to-end training is possible, it failed to solve a more complex 3D task. This paper presents a method called Deep Innovation Protection (DIP) that addresses the credit assignment problem in training complex heterogenous neural network models end-to-end for such environments. The main idea behind the approach is to employ multiobjective optimization to temporally reduce the selection pressure on specific components in multi-component network, allowing other components to adapt. We investigate the emergent representations of these evolved networks, which learn to predict properties important for the survival of the agent, without the need for a specific forward-prediction loss. © 2025 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.1609/aaai.v35i5.16565,,"Recently, multi-hop reasoning over incomplete Knowledge Graphs (KGs) has attracted wide attention due to its desirable interpretability for downstream tasks, such as question answer and knowledge graph completion. Multi-Hop reasoning is a typical sequential decision problem, which can be formulated as a Markov decision process (MDP). Subsequently, some reinforcement learning (RL) based approaches are proposed and proven effective to train an agent for reasoning paths sequentially until reaching the target answer. However, these approaches assume that an entity/relation representation follows a one-point distribution. In fact, different entities and relations may contain different certainties. On the other hand, since REINFORCE used for updating the policy in these approaches is a biased policy gradients method, the agent is prone to be stuck in high reward paths rather than broad reasoning paths, which leads to premature and suboptimal exploitation. In this paper, we consider a Bayesian reinforcement learning paradigm to harness uncertainty into multi-hop reasoning. By incorporating uncertainty into the representation layer, the agent trained by RL has uncertainty in a region of the state space then it should be more efficient in exploring unknown or less known part of the KG. In our approach, we build a Bayesian Q-learning architecture as a state-action value function for estimating the expected long-term reward. As initialized by Gaussian prior or pre-trained prior distribution, the representation layer drives uncertainty that allows regularizing the training. We conducted extensive experiments on multiple KGs. Experimental results show a superior performance than other baselines, especially significant improvements on the automated extracted KG. © 2025 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.1609/aaai.v35i6.16628,,"For prediction of interacting agents’ trajectories, we propose an end-to-end trainable architecture that hybridizes neural nets with game-theoretic reasoning, has interpretable intermediate representations, and transfers to downstream decision making. It uses a net that reveals preferences from the agents’ past joint trajectory, and a differentiable implicit layer that maps these preferences to local Nash equilibria, forming the modes of the predicted future trajectory. Additionally, it learns an equilibrium refinement concept. For tractability, we introduce a new class of continuous potential games and an equilibrium-separating partition of the action space. We provide theoretical results for explicit gradients and soundness. In experiments, we evaluate our approach on two real-world data sets, where we predict highway drivers’ merging trajectories, and on a simple decision-making transfer task. © 2025 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.1609/aaai.v36i11.21473,,"Waves in the oceans are one of the most significant renewable energy sources and are an excellent resource to tackle climate challenges through decarbonizing energy generation. Lowering the Levelized Cost of Energy (LCOE) for energy generation from ocean waves is critical for competitiveness with other forms of clean energy like wind and solar. It requires complex controllers to maximize efficiency for state-of-the-art multi-generator industrial Wave Energy Converters (WEC), which optimizes the reactive forces of the generators on multiple legs of WEC. This paper introduces Multi-Agent Reinforcement Learning controller (MARL) architectures that can handle these various objectives for LCOE. MARL can help increase energy capture efficiency to boost revenue, reduce structural stress to limit maintenance cost, and adaptively and proactively protect the wave energy converter from catastrophic weather events preserving investments and lowering effective capital cost. These architectures include 2-agent and 3-agent MARL implementing proximal policy optimization (PPO) with various optimizations to help sustain the training convergence in the complex hyperplane without falling off the cliff. Also, the design for trust assures the operation of WEC within a safe zone of mechanical compliance. As a part of this design, reward shaping for multiple objectives of energy capture and penalty for harmful motions minimizes stress and lowers the cost of maintenance. We achieved double-digit gains in energy capture efficiency across the waves of different principal frequencies over the baseline Spring Damper controller with the proposed MARL controllers. © 2025 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.1609/aaai.v36i11.21669,,"Existing research in the field of automated negotiation considers a negotiation architecture in which some of the negotiation components are designed separately by reinforcement learning (RL), but comprehensive negotiation strategy design has not been achieved. In this study, we formulated an RL model based on a Markov decision process (MDP) for bilateral multi-issue negotiations. We propose a versatile negotiating agent that can effectively learn various negotiation strategies and domains through comprehensive strategies using deep RL. We show that the proposed method can achieve the same or better utility than existing negotiation agents. © 2025 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.1609/aaai.v36i11.21671,,"A lifelong learning agent is able to continually learn from potentially infinite streams of pattern sensory data. One major historic difficulty in building agents that adapt in this way is that neural systems struggle to retain previously-acquired knowledge when learning from new samples. This problem is known as catastrophic forgetting (interference) and remains an unsolved problem in the domain of machine learning to this day. While forgetting in the context of feedforward networks has been examined extensively over the decades, far less has been done in the context of alternative architectures such as the venerable self-organizing map (SOM), an unsupervised neural model that is often used in tasks such as clustering and dimensionality reduction. Although the competition among its internal neurons might carry the potential to improve memory retention, we observe that a fixed-sized SOM trained on task incremental data, i.e., it receives data points related to specific classes at certain temporal increments, it experiences severe interference. In this study, we propose the c-SOM, a model that is capable of reducing its own forgetting when processing information. © 2024 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.1609/aaai.v36i11.21728,,"We present a demonstration of the interactive task learning agent Rosie, where it learns the task of patrolling a simulated barracks environment through situated natural language instruction. In doing so, it builds a sizable task hierarchy composed of both innate and learned tasks, tasks formulated as achieving a goal or following a procedure, tasks with conditional branches and loops, and involving communicative and mental actions. Rosie is implemented in the Soar cognitive architecture, and represents tasks using a declarative task network which it compiles into procedural rules through chunking. This is key to allowing it to learn from a single training episode and generalize quickly. © 2025 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.1609/aaai.v36i5.20481,,"Robust adversarial reinforcement learning is an effective method to train agents to manage uncertain disturbance and modeling errors in real environments. However, for systems that are sensitive to disturbances or those that are difficult to stabilize, it is easier to learn a powerful adversary than establish a stable control policy. An improper strong adversary can destabilize the system, introduce biases in the sampling process, make the learning process unstable, and even reduce the robustness of the policy. In this study, we consider the problem of ensuring system stability during training in the adversarial reinforcement learning architecture. The dissipative principle of robust H∞ control is extended to the Markov Decision Process, and robust stability constraints are obtained based on L2 gain performance in the reinforcement learning system. Thus, we propose a dissipation-inequation-constraint-based adversarial reinforcement learning architecture. This architecture ensures the stability of the system during training by imposing constraints on the normal and adversarial agents. Theoretically, this architecture can be applied to a large family of deep reinforcement learning algorithms. Results of experiments in MuJoCo and GymFc environments show that our architecture effectively improves the robustness of the controller against environmental changes and adapts to more powerful adversaries. Results of the flight experiments on a real quadcopter indicate that our method can directly deploy the policy trained in the simulation environment to the real environment, and our controller outperforms the PID controller based on hardware-in-the-loop. Both our theoretical and empirical results provide new and critical outlooks on the adversarial reinforcement learning architecture from a rigorous robust control perspective. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1609/aaai.v36i7.20732,,"How to obtain good value estimation is a critical problem in Reinforcement Learning (RL). Current value estimation methods in continuous control, such as DDPG and TD3, suffer from unnecessary over- or under- estimation. In this paper, we explore the potential of double actors, which has been neglected for a long time, for better value estimation in the continuous setting. First, we interestingly find that double actors improve the exploration ability of the agent. Next, we uncover the bias alleviation property of double actors in handling overestimation with single critic, and underestimation with double critics respectively. Finally, to mitigate the potentially pessimistic value estimate in double critics, we propose to regularize the critics under double actors architecture. Together, we present Double Actors Regularized Critics (DARC) algorithm. Extensive experiments on challenging continuous control benchmarks, MuJoCo and PyBullet, show that DARC significantly outperforms current baselines with higher average return and better sample efficiency. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1609/aaai.v36i9.21165,,"When dealing with a series of imminent issues, humans can naturally concentrate on a subset of these concerning issues by prioritizing them according to their contributions to motivational indices, e.g., the probability of winning a game. This idea of concentration offers insights into reinforcement learning of sophisticated Large-scale Multi-Agent Systems (LMAS) participated by hundreds of agents. In such an LMAS, each agent receives a long series of entity observations at each step, which can overwhelm existing aggregation networks such as graph attention networks and cause inefficiency. In this paper, we propose a concentration network called ConcNet. First, ConcNet scores the observed entities considering several motivational indices, e.g., expected survival time and state value of the agents, and then ranks, prunes, and aggregates the encodings of observed entities to extract features. Second, distinct from the well-known attention mechanism, ConcNet has a unique motivational subnetwork to explicitly consider the motivational indices when scoring the observed entities. Furthermore, we present a concentration policy gradient architecture that can learn effective policies in LMAS from scratch. Extensive experiments demonstrate that the presented architecture has excellent scalability and flexibility, and significantly outperforms existing methods on LMAS benchmarks. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1609/aaai.v37i11.26556,,"Endowing dialogue agents with personas is the key to delivering more human-like conversations. However, existing persona-grounded dialogue systems still lack informative details of human conversations and tend to reply with inconsistent and generic responses. One of the main underlying causes is that pre-defined persona sentences are generally short and merely superficial descriptions of personal attributes, making appropriate persona selection and understanding non-trivial. Another challenge is that it is crucial to consider the context and the conversation flow to dynamically determine when to invoke different types of persona signals. To address these problems, we propose a disentangled-attention based pre-training architecture, which incorporates persona-aware prompt learning to bridge the connection between the selected persona and response generation. Our model first exploits the conversation flow to select context-relevant personas, and subsequently enriches the superficial persona descriptions with extra personality traits through persona-aware prompting. Finally, the decoder leverages a disentangled-attention mechanism to flexibly control the reliance on personas and dialogue contexts, and incorporates A*-like keyword-based heuristic estimates for controllable generation. Extensive experiments show that our approach can outperform strong baselines and deliver more consistent and engaging responses on the PERSONA-CHAT dataset. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1609/aaai.v37i13.26903,,"As artificial intelligence (AI) becomes a prominent part of modern life, AI literacy is becoming important for all citizens, not just those in technology careers. Previous research in AI education materials has largely focused on the introduction of terminology as well as AI use cases and ethics, but few allow students to learn by creating their own machine learning models. Therefore, there is a need for enriching AI educational tools with more adaptable and flexible platforms for interested educators with any level of technical experience to utilize within their teaching material. As such, we propose the development of an open-source tool (Build-a-Bot) for students and teachers to not only create their own transformer-based chatbots based on their own course material, but also learn the fundamentals of AI through the model creation process. The primary concern of this paper is the creation of an interface for students to learn the principles of artificial intelligence by using a natural language pipeline to train a customized model to answer questions based on their own school curriculums. The model uses contexts given by their instructor, such as chapters of a textbook, to answer questions and is deployed on an interactive chatbot/voice agent. The pipeline teaches students data collection, data augmentation, intent recognition, and question answering by having them work through each of these processes while creating their AI agent, diverging from previous chatbot work where students and teachers use the bots as black-boxes with no abilities for customization or the bots lack AI capabilities, with the majority of dialogue scripts being rule-based. In addition, our tool is designed to make each step of this pipeline intuitive for students at a middle-school level. Further work primarily lies in providing our tool to schools and seeking student and teacher evaluations. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1609/aaai.v37i13.27023,,"Previous research on the comprehensive negotiation strategy using deep reinforcement learning (RL) has scalability issues of not performing effectively in the large-sized domains. We improve negotiation strategy via deep RL by considering an issue-based represented deep policy network to deal with multi-issue negotiation. The architecture of the proposed learning agent considers the characteristics of multi-issue negotiation domains and policy-based learning. We demonstrate that proposed method achieve equivalent or higher utility than existing negotiation agents in the large-sized domains. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1609/aaai.v37i7.26058,,"Goal-conditioned reinforcement learning (GCRL) has a wide range of potential real-world applications, including manipulation and navigation problems in robotics. Especially in such robotics tasks, sample efficiency is of the utmost importance for GCRL since, by default, the agent is only rewarded when it reaches its goal. While several methods have been proposed to improve the sample efficiency of GCRL, one relatively under-studied approach is the design of neural architectures to support sample efficiency. In this work, we introduce a novel neural architecture for GCRL that achieves significantly better sample efficiency than the commonly-used monolithic network architecture. The key insight is that the optimal action-value function must satisfy the triangle inequality in a specific sense. Furthermore, we introduce the metric residual network (MRN) that deliberately decomposes the action-value function into the negated summation of a metric plus a residual asymmetric component. MRN provably approximates any optimal action-value function, thus making it a fitting neural architecture for GCRL. We conduct comprehensive experiments across 12 standard benchmark environments in GCRL. The empirical results demonstrate that MRN uniformly outperforms other state-of-the-art GCRL neural architectures in terms of sample efficiency. The code is available at https://github.com/Cranial-XIX/metric-residual-network. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1609/aaai.v39i12.33382,Proceedings of the AAAI Conference on Artificial Intelligence,"Point-of-Interest (POI) recommendation aims to predict users' future locations based on their historical check-ins. Despite the success of recent deep learning approaches in capturing POI semantics and user behavior, they continue to face the persistent problem of data sparsity and incompleteness. In this paper, we introduce Multi-Objective Adversarial Imitation Recommender (MOAIR), a novel framework that integrates Generative Adversarial Imitation Learning with multi-objectives to address this issue. MOAIR effectively captures user behavior patterns and spatial-temporal contextual information via graph-enhanced self-supervised state encoder and overcomes data sparsity by robustly learning from limited data and generating diverse samples. By accommodating diverse user patterns in the training data, the framework also mitigates the typical mode-collapse issue in generative adversarial learning and thus enhances the overall performance. MOAIR employs a multi-objective imitation learning architecture where the imitation learning agent (IL agent) explores the POI space and receives multifaceted reward signals. Utilizing the Paralleled Proximal Policy Optimization (3PO) framework to optimize multi-objectives, the IL agent ensures efficient and stable policy updates. Additionally, to address the issue of high noise in POI recommendation scenarios, we use a novel generative way to define our policy net and incorporate a variational bottleneck for regularization to enhance the stability of adversarial learning. Comprehensive experiments reveal the superior performance for MOAIR compared with baselines, especially with sparse training data. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1609/aaai.v39i12.33458,Proceedings of the AAAI Conference on Artificial Intelligence,"Recent studies have revealed the vulnerability of graph neural networks (GNNs) to adversarial attacks. In practice, effectively attacking GNNs is not easy. Existing attack methods primarily focus on modifying the topology of the graph data. In many scenarios, attackers do not have the authority to manipulate the graph's topology, making such attacks challenging to execute. Although node injection attacks are more feasible than modifying the topology, current injection attacks rely on knowledge of the victim model's architecture. This dependency significantly degrades attack quality when there is inconsistency in the victim models. Moreover, the generation of injected nodes often lacks precise control over features, making it difficult to balance attack effectiveness and stealthiness. In this paper, we investigate a node injection attack under model-agnostic conditions and propose Targeted Evasion Attack via Node Injection (TEANI). Specifically, TEANI models the generation of adversarial nodes as a Markov process. Without considering the target model's structure, it guides the agent to select features that maximize attack effectiveness within a budget, based solely on the results of queries to a black-box model. Extensive experiments on real-world datasets and mainstream GNN models demonstrate that the proposed TEANI poses more effective and imperceptible threats than state-of-the-art attack methods. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1609/aaai.v39i20.35391,Proceedings of the AAAI Conference on Artificial Intelligence,"Categorical Distributional Reinforcement Learning (CDRL) has demonstrated superior sample efficiency in learning complex tasks compared to conventional Reinforcement Learning (RL) approaches. However, the practical application of CDRL is encumbered by challenging projection steps, detailed parameter tuning, and domain knowledge. This paper addresses these challenges by introducing a pioneering Continuous Distributional Model-Free RL algorithm tailored for continuous action spaces. The proposed algorithm simplifies the implementation of distributional RL, adopting an actor-critic architecture wherein the critic outputs a continuous probability distribution. Additionally, we propose an ensemble of multiple critics fused through a Kalman fusion mechanism to mitigate overestimation bias. Through a series of experiments, we validate that our proposed method provides a sample-efficient solution for executing complex continuous-control tasks. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1609/aaaiss.v5i1.35593,,"Effective academic advising plays a crucial role in student success, yet universities face challenges in optimizing advising processes and course enrollment. This task is complicated by the fact that several graduation requirements have to be met while also taking the students' interests into account. Academic advising has historically been performed by a skilled human adviser. Universities can optimize course planning and help students make informed decisions about their academic path with recommender systems. This case study develops a goal-based agent recommender system based on a large language model tailored to undergraduate students, depending on curriculum requirements, prerequisite dependencies, and student preferences. The developed recommendation system helps universities increase student advising efficiency and create more intuitive and student-centric curricula. We show how to structure and process complex curriculum data to create an algorithm-ready environment, simplifying the relationships between degree requirements and course offerings. This study evaluates multiple algorithms based on recommendation accuracy, computational efficiency, and their ability to meet degree requirements while fostering academic engagement. By streamlining course selection and exploring possible degree paths, the system may also help students graduate on time and navigate complex curricula. This system also collects important metrics to accurately predict student enrollment for classes, enabling college departments to plan their course offerings better. The system poses a significant benefit to university advising offices by reducing advisor workloads and encouraging student engagement, advancing the academic achievement of the entire student body. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1609/aiide.v13i2.12964,,"Games have used different mechanisms along its history to provide agent behavior: FSMs, utility systems, behavior trees and planning methods. In this paper, we present an architecture that aims at incorporating all these approaches into trees of event handling nodes with behaviours as leaves, using rules for combining actions akin to utility systems. This formalism aims to develop hybrid systems in an easier way. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1609/aiide.v18i1.21966,"Proceedings - AAAI Artificial Intelligence and Interactive Digital Entertainment Conference, AIIDE","Reinforcement learning (RL) is a powerful way to solve sequential decision-making tasks. However training an RL agent in a complex environment requires a large amount of interactions, which is non-ideal when acting in an environment is costly or dangerous. One alternative is to learn an approximation of the real environment, referred to as a world model. This simulator can be used to train an agent and transfer the learned policy to the real environment. Unfortunately, training world models have traditionally required a significant number of interactions in the real environment. This brings us to the same problem when it is costly or dangerous to act in the real environment. To address this problem, we present an entity-based representation and corresponding architecture, which allows for greater data efficiency in world model training. Our approach outperforms other world model baselines in an initial application to the game Pong. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.1609/aiide.v1i1.18724,,"Planning in real-time offers several benefits over the more typical techniques of implementing Non-Player Character (NPC) behavior with scripts or finite state machines. NPCs that plan their actions dynamically are better equipped to handle unexpected situations. The modular nature of the goals and actions that make up the plan facilitates re-use, sharing, and maintenance of behavioral building blocks. These benefits, however, come at the cost of CPU cycles. In order to simultaneously plan for several NPCs in real-time, while continuing to share the processor with the physics, animation, and rendering systems, careful consideration must taken with the supporting architecture. The architecture must support distributed processing and caching of costly calculations. These considerations have impacts that stretch beyond the architecture of the planner, and affect the agent architecture as a whole. This paper describes lessons learned while implementing real-time planning for NPCs for F.E.A.R., a AAA first person shooter shipping for PC in 2005. Copyright © 2005, American Association for Artificial Intelligence (www.aaai.org). All rights reserved. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1609/aiide.v3i1.18801,,"The Interactive Story Architecture for Training (ISAT) is designed to address the limitations of computer games for advanced distributed learning (ADL) and to fully realize the potential of games to become engaging and individualized training environments. The central component of the ISAT architecture is an intelligent director agent responsible for individualizing the training experience. To achieve this, the director tracks the trainee's demonstration of knowledge and skills during the training experience. Using that information, the director plays a role similar to that of a schoolhouse trainer, customizing training scenarios to meet individual trainee needs. The director can react to trainee actions within a scenario, dynamically adapting the environment to the learning needs of trainee as well as the dramatic needs of the scene. Copyright © 2007, Association for the Advancement of Artificial Intelligence. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1609/aiide.v5i1.12351,,"Dynamic scripting is a reinforcement learning algorithm designed specifically to learn appropriate tactics for an agent in a modern computer game, such as Neverwinter Nights. This reinforcement learning algorithm has previously been extended to support the automatic construction of new abstract states to improve its context sensitivity and integrated with a graphical behavior modeling architecture to allow for hierarchical dynamic scripting and task decomposition. In this paper, we describe a tactical abstract game representation language that was designed specifically to make it easier to define abstract games that include the large amount of uncertainty found in modern computer games. We then use this framework to examine the effectiveness of the extended version of the dynamic scripting algorithm, using Q-learning and the original dynamic scripting algorithms as benchmarks. Results and discussion are provided for three different abstract games: one based on combat in role-playing games and two based on different aspects of real-time strategy games.© 2009, Association for the Advancement of Artificial. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1609/aiide.v5i1.12365,,"Computer games in general, and Real Time Strategy games in particular is a challenging task for both AI research and game AI programmers. The player, or AI bot, must use its workers to gather resources. They must be spent wisely on structures such as barracks or factories, mobile units such as soldiers, workers and tanks. The constructed units can be used to explore the game world, hunt down the enemy forces and destroy the opponent buildings. We propose a multi-agent architecture based on artificial potential fields for a full real time strategy scenario. We validate the solution by participating in a yearly open real time strategy game tournament and show that the bot, even though not using any form of path planning for navigation, is able to perform well and win the tournament.© 2009, Association for the Advancement of Artificial. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1609/aimag.v29i3.2148,AI Magazine,"The Association for the Advancement of Artificial Intelligence (AAAI) was pleased to present the AAAI 2008 Spring Symposium Series, held Wednesday through Friday, March 26-28, 2008, at Stanford University, California. The eight symposia were titled (1) AI Meets Business Rules and Process Management, (2) Architectures for Intelligent Theory-Based Agents, (3) Creative Intelligent Systems, (4) Emotion, Personality, and Social Behavior, (5) Semantic Scientific Knowledge Integration, (6) Social Information Processing, (7) Symbiotic Relationships between Semantic Web and Knowledge Engineering, (8) Using Al to Motivate Greater Participation in Computer Science. The goal of the AI Meets Business Rules and Process Management AAAI symposium was to investigate the various approaches and standards to represent business rules, business process management, and the semantic web with respect to expressiveness and reasoning capabilities. The focus of the Architectures ror Intelligent Theory-Based Agents AAAI symposium was the definition or architectures for intelligent theory-based agents, comprising languages, knowledge representation methodologies, reasoning algorithms, and control loops. The Creative Intelligent Systems symposium included five major discussion sessions and a general poster session (in which all contributing papers were presented). The purpose of this symposium was to explore the synergies between creative cognition and intelligent systems. The goal of the Emotion, Personality, and Social Behavior symposium was to examine fundamental issues in affect and personality in both biological and artificial agents, focusing on the roles of these factors in mediating social behavior. The Semantic Scientific Knowledge Integration symposium brought together the semantic technologies community with the scientific information technology community in an effort to build the general semantic science information community. The Social Information Processing symposium's goal was to investigate computational and analytic approaches that will enable users to harness the efforts of large numbers of other users to solve a variety of information processing problems, from discovering high-quality content to managing common resources. The goal of the Symbiotic Relationships between the Semantic Web and Software Engineering symposium was to explore how the lessons learned by the knowledge-engineering community over the past three decades could be applied to the bold research agenda of current workers in semantic web technologies. The purpose of the Using AI to Motivate Greater Participation in Computer Science symposium was to identify ways that topics in AI may be used to motivate greater student participation in computer science by highlighting fun, engaging, and intellectually challenging developments in the AI-related curriculum at a number of educational levels. Technical reports of the symposia were published by AAAI Press. Copyright © 2008, Association for the Advancement of Artificial Intelligence. All rights reserved. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1609/aimag.v31i1.2283,AI Magazine,"We discuss an interaction-based approach to study the coevolution between sociotechnical networks, individual behaviors, and contagion processes on these networks. We use epidemics in human populations as an example of this phenomenon. The methods consist of developing synthetic yet realistic national-scale networks using a first-principles approach. Unlike simple random graph techniques, these methods combine real-world data sources with behavioral and social tiieories to synthesize detailed social contact (proximity) networks. Individual-based models of within-host disease progression and interhost transmission are then used to model the contagion process. Finally, models of individual behaviors are composed with disease progression models to develop a realistic representation of the complex system in which individual behaviors and the social network adapt to the contagion. These methods are embodied within Simdemics, a general-purpose modeling environment to support pandemic planning and response. Simdemics is designed specifically to be scalable to networks with 300 million agents; the underlying algorithms and methods in Simdemics are all high-performance computing-oriented methods. New advances in network science, machine learning, high-performance computing, data mining, and behavioral modeling were necessary to develop Simdemics. Simdemics is combined with two other environments, Simftastructure and Didactic, to form an integrated cyber environment. The integrated cyber environment provides the end user with flexible and seamless Internet-based access to Simdemics. Service-oriented architectures play a critical role in delivering the desired services to the end user. Simdemics, in conjunction with the integrated cyber environment, has been used in more than a dozen user-defined case studies. These case studies were done to support specific policy questions that arose in the context of planning the response to pandemics (for example, HlNl, H5N1) and human-initiated bioterrorism events. These studies played a crucial role in the continual development and improvement of the cyber environment. Copyright © 2010, Association for the Advancement of Artificial Intelligence. All rights reserved. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1609/aimag.v34i4.2511,AI Magazine,"The AAAI-13 Workshop Program, a part of the 27th AAAI Conference on Artificial Intelligence, was held Sunday and Monday, July 14-15, 2013, at the Hyatt Regency Bellevue Hotel in Bellevue, Washington, USA. The program included 12 workshops covering a wide range of topics in artificial intelligence, including Activity Context-Aware System Architectures (WS-13-05); Artificial Intelligence and Robotics Methods in Computational Biology (WS-13-06); Combining Constraint Solving with Mining and Learning (WS-13-07); Computer Poker and Imperfect Information (WS-13-08); Expanding the Boundaries of Health Informatics Using Artificial Intelligence (WS-13-09); Intelligent Robotic Systems (WS-13-10); Intelligent Techniques for Web Personalization and Recommendation (WS- 13-11); Learning Rich Representations from Low-Level Sensors (WS-13-12); Plan, Activity, and Intent Recognition (WS-13-13); Space, Time, and Ambient Intelligence (WS-13-14); Trading Agent Design and Analysis (WS-13-15); and Statistical Relational Artificial Intelligence (WS-13-16). Copyright © 2013, Association for the Advancement of Artificial Intelligence. All rights reserved. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.1609/icaps.v34i1.31476,"Proceedings International Conference on Automated Planning and Scheduling, ICAPS","MuZero has demonstrated remarkable performance in board and video games where Monte Carlo tree search (MCTS) method is utilized to learn and adapt to different game environments. This paper leverages the strength of MuZero to enhance agents' planning capability for joint active simultaneous localization and mapping (SLAM) and navigation tasks, which require an agent to navigate an unknown environment while simultaneously constructing a map and localizing itself. We propose SLAMuZero, a novel approach for joint SLAM and navigation, which employs a search process that uses an explicit encoder-decoder architecture for mapping, followed by a prediction function to evaluate policy and value based on the generated map. SLAMuZero outperforms the state-of-the-art baseline and significantly reduces training time, underscoring the efficiency of our approach. Additionally, we develop a new open source library for implementing SLAMuZero, which is a flexible and modular toolkit for researchers and practitioners (https://github.com/bwfbowen/SLAMuZero). © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.1609/socs.v18i1.36015,The International Symposium on Combinatorial Search,"Multi-Agent Path Finding (MAPF), which focuses on finding collision-free paths for multiple robots, is crucial for applications ranging from aerial swarms to warehouse automation. Solving MAPF is NP-hard so learning-based approaches for MAPF have gained attention, particularly those leveraging deep neural networks. Nonetheless, despite the community's continued efforts, all learning-based MAPF planners still rely on decentralized planning due to variability in the number of agents and map sizes. We have developed the first centralized learning-based policy for MAPF problem called RAILGUN. RAILGUN is not an agent-based policy but a map-based policy. By leveraging a CNN-based architecture, RAILGUN can generalize across different maps and handle any number of agents. We collect trajectories from rule-based methods to train our model in a supervised way. In experiments, RAILGUN outperforms most baseline methods and demonstrates great zero-shot generalization capabilities on various tasks, maps and agent numbers that were not seen in the training dataset. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1613/JAIR.1.12839,Journal of Artificial Intelligence Research,"Machine learning on sets towards sequential output is an important and ubiquitous task, with applications ranging from language modelling and meta-learning to multi-agent strategy games and power grid optimization. Combining elements of representation learning and structured prediction, its two primary challenges include obtaining a meaningful, permutation invariant set representation and subsequently utilizing this representation to output a complex target permutation. This paper provides a comprehensive introduction to the field as well as an overview of important machine learning methods tackling both of these key challenges, with a detailed qualitative comparison of selected model architectures. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.1613/jair.1.13743,Journal of Artificial Intelligence Research,"StarCraft II (SC2) poses a grand challenge for reinforcement learning (RL), of which the main difficulties include huge state space, varying action space, and a long time horizon. In this work, we investigate a set of RL techniques for the full-length game of StarCraft II. We investigate a hierarchical RL approach, where the hierarchy involves two. One is the extracted macro-actions from experts’ demonstration trajectories to reduce the action space in an order of magnitude. The other is a hierarchical architecture of neural networks, which is modular and facilitates scale. We investigate a curriculum transfer training procedure that trains the agent from the simplest level to the hardest level. We train the agent on a single machine with 4 GPUs and 48 CPU threads. On a 64x64 map and using restrictive units, we achieve a win rate of 99% against the difficulty level-1 built-in AI. Through the curriculum transfer learning algorithm and a mixture of combat models, we achieve a 93% win rate against the most difficult non-cheating level built-in AI (level-7). In this extended version of the paper, we improve our architecture to train the agent against the most difficult cheating level AIs (level-8, level-9, and level-10). We also test our method on different maps to evaluate the extensibility of our approach. By a final 3-layer hierarchical architecture and applying significant tricks to train SC2 agents, we increase the win rate against the level-8, level-9, and level-10 to 96%, 97%, and 94%, respectively. Our codes and models are all open-sourced now at https://github.com/liuruoze/HierNet-SC2. To provide a baseline referring the AlphaStar for our work as well as the research and open-source community, we reproduce a scaled-down version of it, mini-AlphaStar (mAS). The latest version of mAS is 1.07, which can be trained using supervised learning and reinforcement learning on the raw action space which has 564 actions. It is designed to run training on a single common machine, by making the hyper-parameters adjustable and some settings simplified. We then can compare our work with mAS using the same computing resources and training time. By experiment results, we show that our method is more effective when using limited resources. The inference and training codes of mini-AlphaStar are all open-sourced at https://github.com/liuruoze/mini-AlphaStar. We hope our study could shed some light on the future research of efficient reinforcement learning on SC2 and other large-scale games. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.17083/ijsg.v10i4.638,International Journal of Serious Games,"A realistic representation of the traffic participants is a key feature of serious games for driving. We propose a novel method for improving the behavioral planning of non-player vehicles (NPVs) by supporting implementation of (i) “human-like”, high-level decision making and (ii) different driving styles. The method relies on the deep reinforcement learning (DRL) technology, which is gaining ever more interest in the real-world automated driving research. We designed a system architecture including advanced driving assistance systems (ADAS) and trained the agent in the highway-env DRL environment. Compared to a low-level decision making system, our system performs better both in terms of safety and speed. Moreover, the proposed approach allows reducing the number of training steps by more than one order of magnitude. This makes the development of new models much more efficient. As a second main contribution, we demonstrate that it is possible to train agents characterized by different driving behaviors, by tweaking the weights of the factors of a general DRL reward function. This approach avoids heuristic coding of the driving styles, saving development and maintenance time. The developed agent models can then be seamlessly deployed as NPVs in any target SG in the same development environment (i.e., highway-env). Furthermore, the information and lessons learned presented in this article can be useful to effectively and efficiently train similar agents in their target SG environment. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.17323/1998-0663.2019.1.33.44,Business Informatics,"This article presents a new approach to designing decision-making systems for socioeconomic and ecological planning using parallel real-coded genetic algorithms (RCGAs), aggregated with simulation models by objective functions. A feature of this approach is the use of special agent-processes, which are autonomous genetic algorithms (GAs) acting synchronously in parallel streams and exchanging periodically by the best potential decisions. This allows us to overcome the premature convergence problem in local extremums. In addition, it was shown that the combined use of different crossover and mutation operators significantly improves the time efficiency of RCGAs, as well as the quality of the decisions obtained (proximity to optimum), providing a more diverse population of potential decisions (individuals). In this paper, several suggested crossover and mutation operators are used, in particular, a modified simulated binary crossover (MSBX) and scalable uniform mutation operator (SUM), which is based on quantization of the feasible region of the search space (dividing the feasible region on small subranges with equal lengths) while taking into account the common amount of interacting agent-processes and the maximum number of internal iterations of GAs forming potential decisions through selection, crossover and mutation. Such a functional dependence of the parameters of heuristic operators on the corresponding process characteristics, aggregated with the combined probabilistic use of various crossover and mutation operators, makes it possible to get maximum effect from the multi-processes architecture. As a result, the computational possibilities of RCGAs for solving large-scale optimization problems (hundreds and thousands of decision variables, multiple objective functions) become dependent only on the physical characteristics of the existing computing clusters. This makes it possible to efficiently use supercomputer technologies. An important advantage of the proposed system is the implemented integration between the developed parallel RCGA (implemented in C++ and MPI) and the simulation modelling system AnyLogic (Java) using JNI technology. Such an approach allows one to synthesize real world optimization problems in decision-making systems of socio-economic and ecological planning, using simulation methods supported by AnyLogic. The result is an effective solution to single-objective and multi-objective optimization tasks of large dimension, in which the objective functionals are the result of simulation modeling and cannot be obtained analytically. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.17323/2587-814X.2020.2.7.20,Business Informatics,"This article deals with the application of transfer learning methods and domain adaptation in a recurrent neural network based on the long short-term memory architecture (LSTM) to improve the efficiency of management decisions and state economic policy. Review of existing approaches in this area allows us to draw a conclusion about the need to solve a number of practical issues of improving the quality of predictive analytics for preparing forecasts of the development of socio-economic systems. In particular, in the context of applying machine learning algorithms, one of the problems is the limited number of marked data. The authors have implemented training of the original recurrent neural network on synthetic data obtained as a result of simulation, followed by transfer training and domain adaptation. To achieve this goal, a simulation model was developed by combining notations of system dynamics with agent-based modeling in the AnyLogic system, which allows us to investigate the influence of a combination of factors on the key parameters of the efficiency of the socio-economic system. The original LSTM training was realized with the help of TensorFlow, an open source software library for machine learning. The suggested approach makes it possible to expand the possibilities of complex application of simulation methods for building a neural network in order to justify the parameters of the development of the socio-economic system and allows us to get information about its future state. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.17559/TV-20200423145443,Tehnicki Vjesnik,"Automated facial expression recognition has gained much attention in the last years due to growing application areas such as computer animated agents, sociable robots and human computer interaction. The realization of a reliable facial expression recognition system through machine learning is still a challenging task particularly on databases with large number of images. Convolutional Neural Network (CNN) architectures have been proposed to deal with large numbers of training data for better accuracy. For CNNs, a task related best achieving architectural structure does not exist. In addition, the representation of the input image is equivalently important as the architectural structure and the training data. Therefore, this study focuses on the performances of various CNN architectures trained by different region of interests of the same input data. Experiments are performed on three distinct CNN architectures with three different crops of the same dataset. Results show that by appropriately localizing the facial region and selecting the correct CNN architecture it is possible to boost the recognition rate from 84% to 98% while decreasing the training time for proposed CNN architectures. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.17559/TV-20240227001353,Tehnicki Vjesnik,"Urban road traffic congestion has become a major problem that hinders the rapid and healthy development of cities. In this paper, the heterogeneous congestion network is divided into multiple congestion proton regions and boundary subregions by the double-layer partition method, and the traffic flow balance model of multi-regional network is established based on the macro basic map. A layered traffic management architecture based on multi-agent is designed, which provides a new method to improve the efficiency of urban traffic signal control. The wireless sensor network is deeply studied, and the path of the most critical factor affecting the transportation cost in the site construction model is studied in detail by tabu algorithm. According to the traffic network and real-time road condition information, the road network is abstracted as a graph based on the principle of graph theory, and the shortest path algorithm in graph theory is used to avoid obstacles and search for the optimal path, which can make drivers understand the road condition information in real time and make route decisions. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.17721/1812-5409.2023/2.38,Bulletin of the Taras Shevchenko National University of Kyiv. Physics and Mathematics,"The paper is dedicated to evaluating performance in forecasting tasks of the novel routine that includes adapted DTW + K-Means for aggregating series with similar dynamics. The algorithm was developed throughout the series of papers. Novel parts are designed in a way to work with periodic series, like in the investigated monthly data case. It is used over hundreds of Consumer Price Index components to find similar dynamics and aggregate them by the similarity of their dynamics. Then aggregated series are given as input to the ARIMA, SARIMA, and LSTM models, to forecast the total Core Consumer Price Index. The choice is based on the necessity to capture possible non-linear relationships between series. The dataset is quite rich and contains hundreds of Consumer Price Index components, which is a level of prices for different goods. Data suffers from multiple issues, including seasonality, so controlling them either with satellite models such as X-12 or with the architecture of the forecasting model is sufficient. The research results are important for different groups of agents. Private businesses seek to plan their pricing while government structures want to employ their administrative measures in a proactive data-driven manner. The result shows that the SARIMA currently outperforms other models. An LSTM model combined with DTW + K-Means method shows worse results yet it was able to catch non-linearities, unlike more traditional models. Further investigation of LSTM + DTW/K-Means performance and fitting is necessary. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.17762/ijritcc.v11i7s.7033,International Journal on Recent and Innovation Trends in Computing and Communication,"Grid computing provides big possibilities like resource sharing, resource virtualization, and capacity planning since diverse resources that are geographically dispersed are virtualized as a single entity. The associated security concerns are one of the key obstacles preventing grid computing from being broadly adopted and used. Users in a grid are concerned about the security of their assets and the privacy of their data. A host's security in terms of its data or virtual servers may be jeopardised when it interacts with a grid. By providing multilateral security, i.e., security for both the Grid client and the Grid supplier, our building design expands the degree of assurance that can be placed on the accuracy of a Grid calculation and the assurance of client-provided resources. We discuss the issue of ensuring security and present the multi-agent security construction analysis. The paper outlines a multi-agent strategy for protecting the grid environment's resources. The strategy is put forth to address the grid computing industry's growing, serious security issue. The paper defines a multi-agent security architecture that integrates the capabilities of agents with the Grid Security Infrastructure's basic security mechanism (GSI). A security Master agent and a few security task execution agents make up the strategy. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.17775/CSEEJPES.2019.00590,Direct load control of thermostatically controlled loads based on sparse observations using deep reinforcement learning,"This paper considers a demand response agent that must find a near-optimal sequence of decisions based on sparse observations of its environment. Extracting a relevant set of features from these observations is a challenging task and may require substantial domain knowledge. One way to tackle this problem is to store sequences of past observations and actions in the state vector, making it high dimensional, and apply techniques from deep learning. This paper investigates the capabilities of different deep learning techniques, such as convolutional neural networks and recurrent neural networks, to extract relevant features for finding near-optimal policies for a residential heating system and electric water heater that are hindered by sparse observations. Our simulation results indicate that in this specific scenario, feeding sequences of time-series to an Long Short-Term Memory (LSTM) network, which is a specific type of recurrent neural network, achieved a higher performance than stacking these time-series in the input of a convolutional neural network or deep neural network.",TOPIC
10.17775/CSEEJPES.2020.03390,Comprehensive overview of multi-agent systems for controlling smart grids,"Agents are intelligent entities that act flexibly and autonomously and make wise decisions based on their intelligence and experience. A multi-agent system (MAS) contains multiple, intelligent, and interconnected collaborating agents for solving a problem beyond the ability of a single agent. A smart grid (SG) combines advanced intelligent systems, control techniques, and sensing methods with an existing utility power network. For controlling smart grids, various control systems with different architectures have already been developed. MAS-based control of power system operations has been shown to overcome the limitations of time required for analysis, relaying, and protection; transmission switching; communication protocols; and management of plant control. These systems provide an alternative for fast and accurate power network control. This paper provides a comprehensive overview of MASs used for the control of smart grids. The paper provides a wide-spectrum view of the status of smart grids, MAS-based control techniques and their implementation for the control of smart grids. Use of MASs in the control of various aspects of smart grids—including the management of energy, marketing energy, pricing, scheduling energy, reliability, network security, fault handling capability, communication between agents, SG-electrical vehicles, SG-building energy systems, and soft grids—have been critically reviewed. More than a hundred publications on the topic of MAS-based control of smart grids have been critically examined, classified, and arranged for fast reference.",TOPIC
10.18293/SEKE2016-102,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE","The concept of Quantified Self is about connected objects self-monitoring their human owner (e.g., a watch measuring heart rate, etc.). A natural transposition is in self-monitoring arbitrary things, therefore named Quantified Things. In this paper, we present the case of self-monitoring agricultural products. We discuss the rationales for the design of a Quantified Fruit multi-agent architecture for self-monitoring and self-prediction of the maturation of fruits. The architecture includes 6 different types of agents, the 2 more specific ones being respectively, the self-controller equipped with various sensors and the self-prediction module. Our current implementation uses an Arduino microcontroller board with 5 sensors (measuring respectively: temperature, light, humidity, hydrogen and methane). The prediction module uses a neural network. We have implemented the architecture and have conducted various experiments, storing bananas in diverse settings: room, refrigerator, in a box, with other fruits, etc. The paper discusses the architecture, its current implementation, experiments and current results. Future issues (scalability, collaborative prediction, etc.) are also addressed. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.18293/SEKE2018-110,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE","Ubiquitous systems consider the use of electronic components for enhancing daily objects with some kind of computational intelligence for aiding users in their tasks pervasively. Ambient Intelligence (AmI) is a branch of ubiquitous computing that provides an environment full of interconnected devices and it can provide data communication, inference mechanism based on context information and collaboration among system's devices. Similarly, the Internet of Things (IoT) provides uniquely identified devices or things in a network for helping users in their activities. Multi-Agent Systems (MAS) are intelligent systems where agents are responsible for reasoning, competing and using resources to achieve desirable goals pro-Actively and autonomously. Agents have been employed in some approaches and works during the last years, but none of them considered embedded MAS responsible for smart devices in an AmI system running over an IoT network. Besides, it is also interesting that agents of the embedded MAS can interact, sharing information with agents situated in another embedded MAS using the IoT network to learn from user's experiences. This paper proposes an architecture for the development of AmI systems using embedded MAS for interfacing with sensors and actuators in a heterogenous network using an IoT middleware. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.18564/jasss.1557,JASSS,"Auction mechanisms have attracted a great deal of interest and have been used in diverse e-marketplaces. In particular, combinatorial auctions have the potential to play an important role in electronic transactions. Therefore, diverse combinatorial auction market types have been proposed to satisfy market needs. These combinatorial auction types have diverse market characteristics, which require an effective market design approach. This study proposes a comprehensive and systematic market design methodology for combinatorial auctions based on three phases: market architecture design, auction rule design, and winner determination design. A market architecture design is for designing market architecture types by Backward Chain Reasoning. Auction rules design is to design transaction rules for auctions. The specific auction process type is identified by the Backward Chain Reasoning process. Winner determination design is about determining the decision model for selecting optimal bids and auctioneers. Optimization models are identified by Forward Chain Reasoning. Also, we propose an agent based combinatorial auction market design system using Backward and Forward Chain Reasoning. Then we illustrate a design process for the general n-bilateral combinatorial auction market. This study serves as a guideline for practical implementation of combinatorial auction markets design. © JASSS. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.18653/v1/2020.acl-main.407,Proceedings of the Annual Meeting of the Association for Computational Linguistics,"Natural language allows us to refer to novel composite concepts by combining expressions denoting their parts according to systematic rules, a property known as compositionality. In this paper, we study whether the language emerging in deep multi-agent simulations possesses a similar ability to refer to novel primitive combinations, and whether it accomplishes this feat by strategies akin to human-language compositionality. Equipped with new ways to measure compositionality in emergent languages inspired by disentanglement in representation learning, we establish three main results. First, given sufficiently large input spaces, the emergent language will naturally develop the ability to refer to novel composite concepts. Second, there is no correlation between the degree of compositionality of an emergent language and its ability to generalize. Third, while compositionality is not necessary for generalization, it provides an advantage in terms of language transmission: The more compositional a language is, the more easily it will be picked up by new learners, even when the latter differ in architecture from the original agents. We conclude that compositionality does not arise from simple generalization pressure, but if an emergent language does chance upon it, it will be more likely to survive and thrive. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.18653/v1/2020.coling-industry.1,,"With the recent explosion in popularity of voice assistant devices, there is a growing interest in making them available to user populations in additional countries and languages. However, to provide the highest accuracy and best performance for specific user populations, most existing voice assistant models are developed individually for each region or language, which requires linear investment of effort. In this paper, we propose a general multilingual model framework for Natural Language Understanding (NLU) models, which can help bootstrap new language models faster and reduce the amount of effort required to develop each language separately. We explore how different deep learning architectures affect multilingual NLU model performance. Our experimental results show that these multilingual models can reach same or better performance compared to monolingual models across language-specific test data while require less effort in creating features and model maintenance. © 2023 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.18653/v1/2020.findings-emnlp.75,,"In order to improve the sample-efficiency of deep reinforcement learning (DRL), we implemented imagination augmented agent (I2A) in spoken dialogue systems (SDS). Although I2A achieves a higher success rate than baselines by augmenting predicted future into a policy network, its complicated architecture introduces unwanted instability. In this work, we propose actor-double-critic (ADC) to improve the stability and overall performance of I2A. ADC simplifies the architecture of I2A to reduce excessive parameters and hyper-parameters. More importantly, a separate model-based critic shares parameters between actions and makes back-propagation explicit. In our experiments on Cambridge Restaurant Booking task, ADC enhances success rates considerably and shows robustness to imperfect environment models. In addition, ADC exhibits the stability and sample-efficiency as significantly reducing the baseline standard deviation of success rates and reaching the 80% success rate with half training data. © 2024 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.18653/v1/2020.semeval-1.56,,"This paper describes our efforts in tackling Task 5 (Yang et al., 2020) of SemEval-2020. The task involved detecting a class of textual expressions known as counterfactuals and separating them into their constituent elements. Counterfactual statements describe events that have not or could not have occurred and the possible implications of such events. While counterfactual reasoning is natural for humans, understanding these expressions is difficult for artificial agents due to a variety of linguistic subtleties. Our final submitted approaches were an ensemble of various fine-tuned transformer-based and CNN-based models for the first subtask and a transformer model with dependency tree information for the second subtask. We ranked 4th and 9th in the overall leaderboard. We also explored various other approaches that involved the use of classical methods, other neural architectures and the incorporation of different linguistic features. © 2025 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.18653/v1/2021.acl-demo.27,,"We present Logical Optimal Actions (LOA), an action decision architecture of reinforcement learning applications with a neuro-symbolic framework which is a combination of neural network and symbolic knowledge acquisition approach for natural language interaction games. The demonstration for LOA experiments consists of a web-based interactive platform for text-based games and visualization for acquired knowledge for improving interpretability for trained rules. This demonstration also provides a comparison module with other neuro-symbolic approaches as well as non-symbolic state-of-the-art agent models on the same text-based games. Our LOA also provides open-sourced implementation in Python for the reinforcement learning environment to facilitate an experiment for studying neuro-symbolic agents. Demo site: https://ibm.biz/acl21-loa, Code: https://github.com/ibm/loa © 2025 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.18653/v1/2021.eacl-main.290,,"Visual dialog is a vision-language task where an agent needs to answer a series of questions grounded in an image based on the understanding of the dialog history and the image. The occurrences of coreference relations in the dialog makes it a more challenging task than visual question-answering. Most previous works have focused on learning better multi-modal representations or on exploring different ways of fusing visual and language features, while the coreferences in the dialog are mainly ignored. In this paper, based on linguistic knowledge and discourse features of human dialog we propose two soft constraints that can improve the model's ability of resolving coreferences in dialog in an unsupervised way. Experimental results on the VisDial v1.0 dataset shows that our model, which integrates two novel and linguistically inspired soft constraints in a deep transformer neural architecture, obtains new state-of-the-art performance in terms of recall at 1 and other evaluation metrics compared to current existing models and this without pretraining on other vision-language datasets. Our qualitative results also demonstrate the effectiveness of the method that we propose. © 2024 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.18653/v1/2021.emnlp-main.357,,"We propose a novel problem within end-to-end learning of task oriented dialogs (TOD), in which the dialog system mimics a troubleshooting agent who helps a user by diagnosing their problem (e.g., car not starting). Such dialogs are grounded in domain-specific flowcharts, which the agent is supposed to follow during the conversation. Our task exposes novel technical challenges for neural TOD, such as grounding an utterance to the flowchart without explicit annotation, referring to additional manual pages when user asks a clarification question, and ability to follow unseen flowcharts at test time. We release a dataset (FLODIAL) consisting of 2,738 dialogs grounded on 12 different troubleshooting flowcharts. We also design a neural model, FLONET, which uses a retrieval-augmented generation architecture to train the dialog agent. Our experiments find that FLONET can do zero-shot transfer to unseen flowcharts, and sets a strong baseline for future research. © 2025 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.18653/v1/2021.emnlp-main.91,,"With counterfactual bandit learning, models can be trained based on positive and negative feedback received for historical predictions, with no labeled data needed. Such feedback is often available in real-world dialog systems, however, the modularized architecture commonly used in large-scale systems prevents the direct application of such algorithms. In this paper, we study the feedback attribution problem that arises when using counterfactual bandit learning for multi-domain spoken language understanding. We introduce an experimental setup to simulate the problem on small-scale public datasets, propose attribution methods inspired by multi-agent reinforcement learning and evaluate them against multiple baselines. We find that while directly using overall feedback leads to disastrous performance, our proposed attribution methods can allow training competitive models from user feedback. © 2025 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.18653/v1/2021.naacl-main.216,,"The capability to automatically detect human stress can benefit artificial intelligent agents involved in affective computing and human-computer interaction. Stress and emotion are both human affective states, and stress has proven to have important implications on the regulation and expression of emotion. Although a series of methods have been established for multimodal stress detection, limited steps have been taken to explore the underlying inter-dependence between stress and emotion. In this work, we investigate the value of emotion recognition as an auxiliary task to improve stress detection. We propose MUSER – a transformer-based model architecture and a novel multi-task learning algorithm with speed-based dynamic sampling strategy. Evaluations on the Multimodal Stressed Emotion (MuSE) dataset show that our model is effective for stress detection with both internal and external auxiliary tasks, and achieves state-of-the-art results. © 2024 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.18653/v1/2022.findings-emnlp.441,,"'Actions' play a vital role in how humans interact with the world. Thus, autonomous agents that would assist us in everyday tasks also require the capability to perform 'Reasoning about Actions & Change' (RAC). This has been an important research direction in Artificial Intelligence (AI) in general, but the study of RAC with visual and linguistic inputs is relatively recent. The CLEVR_HYP (Sampat et al., 2021) is one such testbed for hypothetical vision-language reasoning with actions as the key focus. In this work, we propose a novel learning strategy that can improve reasoning about the effects of actions. We implement an encoder-decoder architecture to learn the representation of actions as vectors. We combine the aforementioned encoder-decoder architecture with existing modality parsers and a scene graph question answering model to evaluate our proposed system on the CLEVR_HYP dataset. We conduct thorough experiments to demonstrate the effectiveness of our proposed approach and discuss its advantages over previous baselines in terms of performance, data efficiency, and generalization capability. © 2025 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.18653/v1/2022.naacl-main.334,,"The performance of Reinforcement Learning (RL) for natural language tasks including Machine Translation (MT) is crucially dependent on the reward formulation. This is due to the intrinsic difficulty of the task in the high-dimensional discrete action space as well as the sparseness of the standard reward functions defined for limited set of ground-truth sequences biased towards singular lexical choices. To address this issue, we formulate SURF, a maximally dense semantic-level unsupervised reward function which mimics human evaluation by considering both sentence fluency and semantic similarity. We demonstrate the strong potential of SURF to leverage a family of Actor-Critic Transformer-based Architectures with synchronous and asynchronous multi-agent variants. To tackle the problem of large action-state spaces, each agent is equipped with unique exploration strategies, promoting diversity during its exploration of the hypothesis space. When BLEU scores are compared, our dense unsupervised reward outperforms the standard sparse reward by 2% on average for in- and out-of-domain settings. © 2025 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.18653/v1/2022.naacl-main.438,,"Vision-and-language navigation (VLN) is a multimodal task where an agent follows natural language instructions and navigates in visual environments. Multiple setups have been proposed, and researchers apply new model architectures or training techniques to boost navigation performance. However, there still exist non-negligible gaps between machines' performance and human benchmarks. Moreover, the agents' inner mechanisms for navigation decisions remain unclear. To the best of our knowledge, how the agents perceive the multimodal input is under-studied and needs investigation. In this work, we conduct a series of diagnostic experiments to unveil agents' focus during navigation. Results show that indoor navigation agents refer to both object and direction tokens when making decisions. In contrast, outdoor navigation agents heavily rely on direction tokens and poorly understand the object tokens. Transformer-based agents acquire a better cross-modal understanding of objects and display strong numerical reasoning ability than non-Transformer-based agents. When it comes to vision-and-language alignments, many models claim that they can align object tokens with specific visual targets. We find unbalanced attention on the vision and text input and doubt the reliability of such cross-modal alignments. © 2025 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.18653/v1/2022.naacl-srw.19,,"We provide a study of how induced model sparsity can help achieve compositional generalization and better sample efficiency in grounded language learning problems. We consider simple language-conditioned navigation problems in a grid world environment with disentangled observations. We show that standard neural architectures do not always yield compositional generalization. To address this, we design an agent that contains a goal identification module that encourages sparse correlations between words in the instruction and attributes of objects, composing them together to find the goal. The output of the goal identification module is the input to a value iteration network planner. Our agent maintains a high level of performance on goals containing novel combinations of properties even when learning from a handful of demonstrations. We examine the internal representations of our agent and find the correct correspondences between words in its dictionary and attributes in the environment. © 2025 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.18653/v1/2023.emnlp-demo.5,,"The advent of large language models has brought about new ways of interacting with data intuitively via natural language. In recent years, a variety of visualization systems have explored the use of natural language to create and modify visualizations through visualization-oriented dialog. However, the majority of these systems rely on tailored dialog agents to analyze domain-specific data and operate domain-specific visualization tools and libraries. This is a major challenge when trying to transfer functionalities between dialog interfaces of different visualization applications. To address this issue, we propose VIST5, a visualization-oriented dialog system that focuses on easy adaptability to an application domain as well as easy transferability of language-controllable visualization library functions between applications. Its architecture is based on a retrieval-augmented T5 language model that leverages few-shot learning capabilities to enable a rapid adaptation of the system. © 2025 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.18653/v1/2023.findings-acl.491,Proceedings of the Annual Meeting of the Association for Computational Linguistics,"The study of emergent communication has long been devoted to coax neural network agents to learn a language sharing similar properties with human language. In this paper, we try to find a 'natural' way to help agents learn a compositional and symmetric language in complex settings like dialog games. Inspired by the theory that human language was originated from simple interactions, we hypothesize that language may evolve from simple tasks to difficult tasks. We propose a curriculum learning method called task transfer, and propose a novel architecture called symbolic mapping. We find that task transfer distinctly helps language learning in difficult tasks, and symbolic mapping promotes the effect. Further, we explore vocabulary expansion, and show that with the help of symbolic mapping, agents can easily learn to use new symbols when the environment becomes more complex. All in all, we find that a process from simplicity to complexity can serve as a natural way to help multi-agent language learning, and the proposed symbolic mapping is effective for this process. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.18653/v1/2023.findings-emnlp.326,,"Large Language Models (LLMs) have emerged as influential instruments within the realm of natural language processing; nevertheless, their capacity to handle multi-party conversations (MPCs) - a scenario marked by the presence of multiple interlocutors involved in intricate information exchanges - remains uncharted. In this paper, we delve into the potential of generative LLMs such as ChatGPT and GPT-4 within the context of MPCs. An empirical analysis is conducted to assess the zero-shot learning capabilities of ChatGPT and GPT-4 by subjecting them to evaluation across three MPC datasets that encompass five representative tasks. The findings reveal that ChatGPT's performance on a number of evaluated MPC tasks leaves much to be desired, whilst GPT-4's results portend a promising future. Additionally, we endeavor to bolster performance through the incorporation of MPC structures, encompassing both speaker and addressee architecture. This study provides an exhaustive evaluation and analysis of applying generative LLMs to MPCs, casting a light upon the conception and creation of increasingly effective and robust MPC agents. Concurrently, this work underscores the challenges implicit in the utilization of LLMs for MPCs, such as deciphering graphical information flows and generating stylistically consistent responses. © 2025 Elsevier B.V., All rights reserved.",PUBLICATION_TYPE
10.18653/v1/2023.findings-emnlp.469,,"A desirable trait of an artificial agent acting in the visual world is to continually learn a sequence of language-informed tasks while striking a balance between sufficiently specializing in each task and building a generalized knowledge for transfer. Selective specialization, i.e., a careful selection of model components to specialize in each task, is a strategy to provide control over this trade-off. However, the design of selection strategies requires insights on the role of each model component in learning rather specialized or generalizable representations, which poses a gap in current research. Thus, our aim with this work is to provide an extensive analysis of selection strategies for visually grounded continual language learning. Due to the lack of suitable benchmarks for this purpose, we introduce two novel diagnostic datasets that provide enough control and flexibility for a thorough model analysis. We assess various heuristics for module specialization strategies as well as quantifiable measures for two different types of model architectures. Finally, we design conceptually simple approaches based on our analysis that outperform common continual learning baselines. Our results demonstrate the need for further efforts towards better aligning continual learning algorithms with the learning behaviors of individual model parts. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.18653/v1/d18-2025,,"We present LIA, an intelligent personal assistant that can be programmed using natural language. Our system demonstrates multiple competencies towards learning from human-like interactions. These include (i) the ability to be taught reusable conditional procedures, (ii) ability to be taught new knowledge about the world (concepts in an ontology) and (iii) the ability to be taught how to ground that knowledge in a set of sensors and effectors. Building such a system highlights design questions regarding the overall architecture that such an agent should have, as well as questions about parsing and grounding language in situational contexts. We outline key properties of this architecture, and demonstrate a prototype that embodies them in the form of a personal assistant on an Android device. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.18653/v1/n18-3018,,"Fast expansion of natural language functionality of intelligent virtual agents is critical for achieving engaging and informative interactions. However, developing accurate models for new natural language domains is a time and data intensive process. We propose efficient deep neural network architectures that maximally re-use available resources through transfer learning. Our methods are applied for expanding the understanding capabilities of a popular commercial agent and are evaluated on hundreds of new domains, designed by internal or external developers. We demonstrate that our proposed methods significantly increase accuracy in low resource settings and enable rapid development of accurate models with less data. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.18653/v1/w18-5010,,"We present a modular, end-to-end dialogue system for a situated agent to address a multimodal, natural language dialogue task in which the agent learns complex representations of block structure classes through assertions, demonstrations, and questioning. The concept to learn is provided to the user through a set of positive and negative visual examples, from which the user determines the underlying constraints to be provided to the system in natural language. The system in turn asks questions about demonstrated examples and simulates new examples to check its knowledge and verify the user’s description is complete. We find that this task is non-trivial for users and generates natural language that is varied yet understandable by our deep language understanding architecture. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.18653/v1/W19-5908,,"We explore state-of-the-art deep reinforcement learning methods such as prioritized experience replay, double deep Q-Networks, dueling network architectures, distributional learning methods for dialog policy. Our main findings show that each individual method improves the rewards and the task success rate but combining these methods in a Rainbow agent, which performs best across tasks and environments, is a non-trivial task. We, therefore, provide insights about the influence of each method on the combination and how to combine them to form the Rainbow agent. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.18687/LACCEI2018.1.1.528,"Proceedings of the LACCEI international Multi-conference for Engineering, Education and Technology","In this document, we propose a system architecture that aims to improve the performance and learning of basic sciences in STEM undergraduate students at Peruvian national universities. For this purpose, we first analyze the problems that arise in the most representative STEM university of Peru, the National University of Engineering (UNI by its initials in Spanish). Then, we review some papers with topics on STEM education, Human-Agent Interaction and Artificial Intelligence to finally propose the mentioned system and explain how it works. So, since the present document contains the first progress of a project that is currently under development, it will serve as a basis for future experiments, which will be defined and discussed at the end of this paper. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.19101/IJACR.2018.836002,International Journal of Advanced Computer Research,"Grid is a technology that implements the process of sharing resources in a flexible, secure and coordinated manner. Task management in computational grids involves planning, implementation and monitoring. The main contribution of this work consists in the development of a model with an agent-based architecture for managing computer resources each with defined operations so that the user can perform tasks efficiently and effectively and thus improve substantially the management by a gLite Grid middleware. The solution proposed provides a platform based on a collection of agents in a virtual organization. The model considers the heterogeneity of resources so that it is completely independent of any physical network architecture. This paper focus on the model, simulation and evaluation of an agent-based management of computational resources in grid environment architecture. Experimental results showed significantly the effectiveness of algorithms and planning policies to achieve load balancing, fault monitoring, and service quality. The computational complexity of the proposed model is studied and the experimental results are analyzed with respect to the use of the computing resources. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.20532/cit.2017.1003573,Journal of Computing and Information Technology,"Today there are numerous robots in different applications domains despite the fact that they still have limitations in perception, actuation and decision process. Consequently, robots usually have limited autonomy, they are domain specific or have difficulty to adapt on new environments. Learning is the property that makes an agent intelligent and the crucial property that a robot should have to proliferate into the human society. Embedding the learning ability into the robot may simplify the development of the robot control mechanism. The motivation for this research is to develop the agent architecture of the universal robot - Unibot. In our approach the agent is the robot i.e. Unibot that acts in the physical world and is capable of learning. The Unibot conducts several simultaneous simulations of a problem of interest like path-finding. The novelty in our approach is the Multi-Agent Decision Support System which is developed and integrated into the Unibot agent architecture in order to execute simultaneous simulations. Furthermore, the Unibot calculates and evaluates between multiple solutions, decides which action should be performed and performs the action. The prototype of the Unibot agent architecture is described and evaluated in the experiment supported by the Lego Mindstorms robot and the NetLogo. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.20532/cit.2019.1004318,Journal of Computing and Information Technology,"Multi-agent coordination mechanisms are frequently used in pursuit-evasion games with the aim of enabling the coalitions of the pursuers and unifying their individual skills to deal with the complex tasks encountered. In this paper, we propose a coalition formation algorithm based on organizational principles and applied to the pursuit-evasion problem. In order to allow the alliances of the pursuers in different pursuit groups, we have used the concepts forming an organizational modeling framework known as YAMAM (Yet Another Multi Agent Model). Specifically, we have used the concepts Agent, Role, Task, and Skill, proposed in this model to develop a coalition formation algorithm to allow the optimal task sharing. To control the pursuers' path planning in the environment as well as their internal development during the pursuit, we have used a Reinforcement learning method (Q-learning). Computer simulations reflect the impact of the proposed techniques. ACM CCS (2012) Classification: Computing methodologies → Artificial intelligence → Distributed artificial intelligence → Multi-agent systems Theory of computation → Theory and algorithms for application domains → Algorithmic game theory and mechanism design → Convergence and learning in games. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.20532/cit.2019.1004464,Journal of Computing and Information Technology,"Computer science and information communication technologies are among the fastest changing areas and it is essential to follow this world-wide trend also in education, constantly innovating and adapting curricula. In this paper, we introduce the structure, methodological aspects and educational experiences of teaching two courses on distributed systems and agent technologies at two different universities and countries. The presentation is focused on the role of agent middleware and multi-agent systems in teaching various theoretical and practical aspects of these courses. At the University of Craiova, the conclusion is that the use of agent middleware in general and of JADE platform in particular for teaching the course Distributed Systems certainly brings many advantages, but also has some limitations. At the University of Novi Sad, within the Agent Technologies course, agent middleware, initially developed as part of the research project, has been successfully used for educational purposes, too. For both courses, we present the structure, the tools, teachers' and students' experiences and joint useful conclusions and lessons learned with regard to courses delivery. ACM CCS (2012) Classification: Computing methodologies → Artificial intelligence → Distributed artificial intelligence → Multi-agent systems Applied computing → Education → Interactive learning environments Computing methodologies → Distributed computing methodologies → Distributed algorithms Computer systems organization → Architectures → Distributed architectures → Client-server architectures. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.20948/graphicon-2021-3027-954-961,CEUR Workshop Proceedings,"The problem of creating a fully autonomous vehicle is one of the most urgent in the field of artificial intelligence. Many companies claim to sell such cars in certain working conditions. The task of interacting with other road users is to detect them, determine their physical properties, and predict their future states. The result of this prediction is the trajectory of road users’ movement for a given period of time in the near future. Based on such trajectories, the planning system determines the behavior of an autonomous-driving vehicle. This paper demonstrates a multi-agent method for determining the trajectories of road users, by means of a road map of the surrounding area, working with the use of convolutional neural networks. In addition, the input of the neural network gets an agent state vector containing additional information about the object. A number of experiments are conducted for the selected neural architecture in order to attract its modifications to the prediction result. The results are estimated using metrics showing the spatial deviation of the predicted trajectory. The method is trained using the nuscenes test dataset obtained from lgsvl-simulator. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.20965/jaciii.2022.p0893,Journal of Advanced Computational Intelligence and Intelligent Informatics,"The external reward plays an important role in the reinforcement learning process, and the quality of its design determines the final effect of the algorithm. However, in several real-world scenarios, rewards extrinsic to the agent are extremely sparse. This is particularly evident in mobile robot navigation. To solve this problem, this paper proposes a curiosity-based autonomous navigation algorithm that consists of a reinforcement learning framework and curiosity system. The curiosity system consists of three parts: prediction network, associative memory network, and curiosity rewards. The prediction network predicts the next state. An associative memory network was used to represent the world. Based on the associative memory network, an inference algorithm and distance calibration algorithm were designed. Curiosity rewards were combined with extrinsic rewards as complementary inputs to the Q-learning algorithm. The simulation results show that the algorithm helps the agent reduce repeated exploration of the environment during autonomous navigation. The algorithm also exhibits a better convergence effect. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.20965/jaciii.2024.p1240,Journal of Advanced Computational Intelligence and Intelligent Informatics,"Unilateral spatial neglect (USN) is a disorder characterized by the inability to attend to the space opposite the cerebral hemisphere lesion, significantly hindering daily activities. Due to the complex neural circuitry of the brain, understanding the mechanisms of USN has proven challenging. In clinical settings, the Behavioral Inattention Test (BIT), a paper-based examination, is commonly used to assess USN. However, improved scores on this test do not necessarily guarantee functional improvement, as it solely evaluates performance in a two-dimensional space. To address this limitation, various approaches utilizing information and communication technology (ICT) and measurement devices in rehabilitation engineering have been proposed. However, related studies have focused on analyzing motor responses to specific sensory stimuli, and the assessment measures often fail to capture a patient’s symptoms in dynamic environments. Therefore, this study proposes a methodology for modeling human spatial cognition. This cognitive architecture utilizes a structural coupling system that integrates parameters from multiple computational intelligence subsystems. In this study, we constructed a simulation environment capable of replicating the movements of patients with USN using empirical data collected from actual experiments. Furthermore, in this simulation environment, we developed patient agents that incorporated the proposed cognitive architecture. The experimental results suggest that hypothesis testing concerning attention mechanisms can be applied through the performance of patient agents within the simulation environment. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.20965/jrm.2024.p0589,Journal of Robotics and Mechatronics,"In this study, we introduce a deep Q-network agent utilizing a dueling architecture to refine the valuation of actions through separate estimations of the state-value and action-value functions, adapted to facilitate con-current multi-agent operations within a shared environment. Inspired by the self-organized, decentralized cooperation observed in natural swarms, this study uniquely integrates a centralized mechanism, or a centralized critic. This enhances performance and coherence in decision-making within the multi-agent system. This hybrid approach enables agents to execute informed and optimized decisions by considering the actions of their counterparts while maintaining an element of collective and flexible task-information sharing, thereby presenting a groundbreaking framework for cooperation and information sharing in swarm robot systems. To augment the communication capabilities, we employ low-power wide-area networks, or Long Range (LoRa), which are characterized by their low power consumption and long-range communication abilities, facilitating the sharing of task information and reducing the load on individual robots. The aim is to leverage LoRa as a communication platform to construct a cooperative algorithm that enables efficient task-information sharing among groups. This can provide innovative solutions and promote effective cooperation and communication within multi-agent systems, with significant implications for industrial and exploratory robots. In conclusion, by integrating a centralized system into the proposed model, this approach successfully enhances the performance of multi-agent systems in real-world applications, offering a balanced synergy between decentralized flexibility and centralized control. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.20965/jrm.2024.p0658,Journal of Robotics and Mechatronics,"Although communication plays a pivotal role in achieving coordinated activities in multi-agent systems, conventional approaches often involve complicated high-dimensional messages generated by deep networks. These messages are typically indecipherable to humans, are relatively costly to transmit, and require intricate encoding and decoding networks. This can pose a design limitation for the agents such as autonomous (mobile) robots. This lack of interpretability can lead to systemic issues with security and reliability. In this study, inspired by common human communication about likely actions in collaborative endeavors, we propose a novel approach in which each agent’s action probabilities are transmitted to other agents as messages, drawing inspiration from the common human practice of sharing likely actions in collaborative endeavors. Our proposed framework is referred to as communication based on action probabilities (CAP), and focuses on generating straightforward, low-dimensional, interpretable messages to support multiple agents in coordinating their activities to achieve specified cooperative goals. CAP streamlines our comprehension of the agents’ learned coordinated and cooperative behaviors and eliminates the need to use additional network models to generate messages. CAP’s network architecture is simpler than that of state-of-the-art methods, and our experimental results show that it nonetheless performed comparably, con-verged faster, and exhibited a lower volume of communication with better interpretability. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.21123/bsj.2021.18.1.0163,Baghdad Science Journal,"To ensure fault tolerance and distributed management, distributed protocols are employed as one of the major architectural concepts underlying the Internet. However, inefficiency, instability and fragility could be potentially overcome with the help of the novel networking architecture called software-defined networking (SDN). The main property of this architecture is the separation of the control and data planes. To reduce congestion and thus improve latency and throughput, there must be homogeneous distribution of the traffic load over the different network paths. This paper presents a smart flow steering agent (SFSA) for data flow routing based on current network conditions. To enhance throughput and minimize latency, the SFSA distributes network traffic to suitable paths, in addition to supervising link and path loads. A scenario with a minimum spanning tree (MST) routing algorithm and another with open shortest path first (OSPF) routing algorithms were employed to assess the SFSA. By comparison, to these two routing algorithms, the suggested SFSA strategy determined a reduction of 2% in packets dropped ratio (PDR), a reduction of 15-45% in end-to-end delay according to the traffic produced, as well as a reduction of 23% in round trip time (RTT). The Mininet emulator and POX controller were employed to conduct the simulation. Another advantage of the SFSA over the MST and OSPF is that its implementation and recovery time do not exhibit fluctuations. The smart flow steering agent will open a new horizon for deploying new smart agents in SDN that enhance network programmability and management. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.21278/brod76206,Brodogradnja,"An adaptive proportional integral derivative (PID) controller based on the soft actor-critic (SAC) algorithm for trajectory control of unmanned surface vehicles (USV) is proposed in this paper. The gains of the PID controller need to be manually adjusted based on experience in the original formulation. Furthermore, once tuned, these gains remain fixed and making further modifications becomes time-consuming and labor-intensive. To address these limitations, the SAC algorithm is introduced, enabling online tuning of PID gains through agent-environment interaction. Additionally, the strategy of combining SAC algorithm with PID controller mitigates concerns regarding interpretability and security often associated with DRL. In this study, stability analysis of the adaptive trajectory controller based on the SAC-PID algorithm is conducted. This paper horizontally compares the proposed method with traditional PID tuning methods, genetic algorithms (GA), and deep deterministic policy gradient (DDPG) algorithm to highlight the superiority of the SAC-PID approach. Finally, experiments in different scenarios are performed to compare generalization capabilities between DDPG and SAC algorithms. Results demonstrate that the proposed SAC-PID algorithm exhibits excellent stability properties, fast convergence speed, and strong generalization ability. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.21428/5395bc37.07c150ec,International Conference on Design and Semantics of Form and Movement,"This paper probes questions of how big machines— buildings—can function as hybrid metabolic/AI organisms. Focusing on AI, artificial life (ALife), and microbial intelligence I look through the lens of Ludwig Wittgenstein’s Tractatus and Alan Turing’s algorithmic plant simulations to source modernist theory for biointelligent architectures. I’m using scant records and testimony interpreted through each thinker’s writings, architecture, and/or simulations. This text is then a device for considering ways-of-being within, and ways-of-thinking about, theory/practice for the fusion of biological-to-biosynthetic intelligences (microbes, plants, animals, AI, machines.) Resulting theory thereafter supports the development of bioremedial environmental cleanup addressing climate change. My proposition then deploys biomimetic and laboratory data to nurture metabolically driven intelligences partnered with AI in the production of architectures. That ontological pathway stems from machine learning, bio-surveillance, and digital simulation at object, agent, and urban scales. Accomplishments in neural net AI and synthetic biology stirred me to question earlier breakthroughs in relation to current experimental practices. Subsequently, I link and hybridize emergent design proposition to AI, ALife, and biological intelligences as unities for environmentally performative, intelligent buildings. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.21428/92fbeb44.84c0b364,Proceedings of the International Conference on New Interfaces for Musical Expression,"We present Spire Muse, a co-creative musical agent that engages in different kinds of interactive behaviors. The software utilizes corpora of solo instrumental performances encoded as self-organized maps and outputs slices of the corpora as concatenated, remodeled audio sequences. Transitions between behaviors can be automated, and the interface enables the negotiation of these transitions through feedback buttons that signal approval, force reversions to previous behaviors, or request change. Musical responses are embedded in a pre-trained latent space, emergent in the interaction, and influenced through the weighting of rhythmic, spectral, harmonic, and melodic features. The training and run-time modules utilize a modified version of the MASOM agent architecture. Our model stimulates spontaneous creativity and reduces the need for the user to sustain analytical mind frames, thereby optimizing flow. The agent traverses a system autonomy axis ranging from reactive to proactive, which includes the behaviors of shadowing, mirroring, and coupling. A fourth behavior—negotiation—is emergent from the interface between agent and user. The synergy of corpora, interactive modes, and influences induces musical responses along a musical similarity axis from converging to diverging. We share preliminary observations from experiments with the agent and discuss design challenges and future prospects. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.21629/JSEE.2018.02.12,Discrete decision model and multi-agent simulation of the Liang Zong two-chain hierarchical organization in a complex project,"Different from the organization structure of complex projects in Western countries, the Liang Zong hierarchical organization structure of complex projects in China has two different chains, the chief-engineer chain and the general-director chain, to handle the trade-off between technical and management decisions. However, previous works on organization search have mainly focused on the single-chain hierarchical organization in which all decisions are regarded as homogeneous. The heterogeneity and the interdependency between technical decisions and management decisions have been neglected. A two-chain hierarchical organization structure mapped from a real complex project is constructed. Then, a discrete decision model for a Liang Zong two-chain hierarchical organization in an NK model framework is proposed. This model proves that this kind of organization structure can reduce the search space by a large amount and that the search process should reach a final stable state more quickly. For a more complicated decision mechanism, a multi-agent simulation based on the above NK model is used to explore the effect of the two-chain organization structure on the speed, stability, and performance of the search process. The results provide three insights into how, compared with the single-chain hierarchical organization, the two-chain organization can improve the search process: it can reduce the number of iterations efficiently; the search is more stable because the search space is a smoother hill-like fitness landscape; in general, the search performance can be improved. However, when the organization structure is very complicated, the performance of a two-chain organization is inferior to that of a single-chain organization. These findings about the efficiency of the unique Chinese-style organization structure can be used to guide organization design for complex projects.",TOPIC
10.2174/1874070702014010124,Open Biotechnology Journal,"Cellulose production of aerobic bacteria with its very unique physiochemical properties attracted many researchers. The biosynthetic of Bacterial Cellulose (BC) was produced by low-cost media recently. BC has been used as biomaterials and food ingredient these days. Moreover, the capacity of BC composite gives the numerous application opportunities in other fields. Bacterial Cellulose (BC) development is differentiated from suspension planktonic culture by their Extracellular Polymeric Substances (EPS), down-regulation of growth rate and up-down the expression of genes. The attachment of microorganisms is highly dependent on their cell membrane structures and growth medium. This is a very complicated phenomenon that optimal conditions defined the specific architecture. This architecture is made of microbial cells and EPS. Cell growth and cell communication mechanisms effect biofilm development and detachment. Understandings of development and architecture mechanisms and control strategies have a great impact on the management of BC formation with beneficial microorganisms. This mini-review paper presents the overview of outstanding findings from isolating and characterizing the diversity of bacteria to BC's future application, from food to biosensor products. The review would help future researchers in the sustainable production of BC, applications advantages and opportunities in food industry, biomaterial and biomedicine. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.21817/indjcse/2020/v11i5/201105044,Indian Journal of Computer Science and Engineering,"A hysteresis multiple agent aggregations (M-MA) based load balancing system is proposed to distribute the Software-Defined Networking (SDN) control plane of Wide Area Network architecture. Agent-based load balancing is based on the Markov chain process. It considers control policy with thresholding and scaling under the eventual distribution of traffic among an overloaded SDN controller (user controller) and lightweight neighboring Controller (server-side). This can be acquired with a more massive discrepancy in resource utilization via dynamically utilizes the Controller's global available capacity. The anticipated M-MA strategy attempts to gain Multi-objective computation appropriate to high availability, scalability, flexibility, agility, resource utilization, energy-saving, and data computation probability without any overhead. This is anticipated via numerical investigations to validate the efficiency of the expected model. This is acquired by steady-state and transient analysis based on suitable performance metrics like transition rate (among server and client), aggregated capacity, throughput computation, and latency computation. This work depicts that the anticipated (M-MA) scheme outperforms prevailing approaches, and resource provision is attained with specific essential requirements. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.2197/IPSJJIP.31.562,Journal of Information Processing,"Penetration testing is among the most efficient techniques to improve network system defense and search for potential weaknesses. Applying penetration testing with reinforcement learning can enhance automation and accuracy and reduce dependence on human labor. However, this approach still encounters obstacles in intricate network systems, such as large ones, where compromising is challenging. The lack of modeling derived from a specific common cy-bersecurity knowledge base also complicates effective applications in practice. Therefore, based on MITRE ATT&CK knowledge, we propose a multilayer action representation to improve the performance, accuracy, and applicability of penetration testing on complex networks. The multilayer action representation’s goal is to embody actions in penetration testing as n-dimensional vectors while faithfully capturing their characteristics and relationships. Therefore, it directly improves the performance of reinforcement learning agents in large and complicated network scenarios. For faster training, we also use an epsilon-Wolpertinger architecture. We conducted experiments on four difficulty levels with three network configurations and 119 system scenarios and compared our approach with four different reinforcement learning techniques. Our approach not only represents and models actions with high accuracy but also improves the ability of reinforcement learning agents in a variety of difficult levels of network systems. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.22266/ijies2025.0731.35,International Journal of Intelligent Engineering and Systems,"The escalating volume of electronic waste (e-waste) presents significant environmental and logistical challenges, demanding more intelligent and automated sorting systems. Existing approaches often fall short due to limited adaptability, static communication protocols, and suboptimal classification accuracy. This work introduces a novel cognitive communication framework integrated with a Modified Vision Transformer (MVT) for high-precision e-waste image classification. The core innovation lies in the incorporation of a Deep Q-learning-based Reinforcement Learning (DQRL) mechanism that dynamically optimizes inter-agent communication within the cognitive system, reducing latency and communication overhead. Simultaneously, the MVT architecture enhances image understanding through transformer-based encoding, improving the model’s ability to recognize complex and varied e-waste components. Evaluations were conducted on the publicly available E-waste Object Detection Dataset, comprising annotated images across eight e-waste categories. Comparative analysis with existing models, including YOLOv5, YOLOv8, and other deep learning architectures like Vision Transformer (ViT), Swin Transformer and Data-Efficient Image Transformer (DeiT), shows that the proposed method achieves better performance, achieving 97.36% accuracy, significantly outperforming prior state-of-the-art techniques. This integrated cognitive-transformer solution offers a scalable and adaptive framework for smart e-waste management systems. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.22266/ijies2025.1130.29,International Journal of Intelligent Engineering and Systems,"With the rapid increase in mobile data traffic and connected devices, energy-efficient resource allocation in cell-free massive Multiple-Input Multiple-Output (CF-mMIMO) systems has emerged as a key challenge for beyond-5G networks. Existing optimization techniques often struggle scaling large user-centric (UC) architectures, particularly under millimeter wave (mmWave) frequencies, and frequently overlook fairness across users, which is essential for robust and practical deployment. In this paper, we propose a hybrid Multi-Agent Twin Delayed Deep Deterministic Policy Gradient (MATD3) with Proximal Policy Optimization (PPO), that jointly optimizes downlink power allocation and fairness in UC CF-mMIMO systems. This approach leverages the sample exploration of MATD3 and the stability update of PPO, enabling robust learning in dynamic multi-agent environments. Furthermore, we incorporate the minimum per-user spectral efficiency to address fairness. The proposed simulation results demonstrate 430 Mbit/joule energy efficiency and 17.6 bps/Hz spectral efficiency compared to traditional optimization techniques. These findings validate the superior capability of proposed algorithm providing a promising solution for energy-efficient and fairness in large-scale UC CF-mMIMO deployments. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.22364/bjmc.2019.7.4.03,Baltic Journal of Modern Computing,"The problems of dynamic systems' management, in particular the regional power distribution grid, are characterized by heterogeneity, lack of time for decision-making, distribution and partial observability of the control object, as well as the interdependence of actions performed and decisions made. Traditional abstract mathematical methods used in electric power industry are not relevant to such problems due to their inherent non-factors, and therefore solve only well formalized parts of these problems. To provide information support for solving problems in dynamic environments, a new class of intelligent systems is proposed, which simulate collective decision-making under the guidance of a facilitator, namely hybrid intelligent multi-Agent systems of heterogeneous thinking. The presence of a hybrid component in these systems provides the opportunity to work with the heterogeneity of problems, and the presence of intelligent selforganizing agents make it possible to relevantly model effective problem-solving practices of expert teams in order to provide operational dispatching personnel with relevant solutions under time pressure. The paper considers the architecture of such a system for solving the problem of restoring the regional power distribution grid after large-scale accidents. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.2298/CSIS100209015D,Computer Science and Information Systems,"In this paper we present a framework for fusing approximate knowledge obtained from various distributed, heterogenous knowledge sources. This issue is substantial in modeling multi-agent systems, where a group of loosely coupled heterogeneous agents cooperate in achieving a common goal. In paper [5] we have focused on defining general mechanism for knowledge fusion. Next, the techniques ensuring tractability of fusing knowledge expressed as a Horn subset of propositional dynamic logic were developed in [13,16]. Propositional logics may seem too weak to be useful in real-world applications. On the other hand, propositional languages may be viewed as sublanguages of first-order logics which serve as a natural tool to define concepts in the spirit of description logics [2]. These notions may be further used to define various ontologies, like e.g. those applicable in the Semantic Web. Taking this step, we propose a framework, in which our Horn subset of dynamic logic is combined with deductive database technology. This synthesis is formally implemented in the framework of HSPDL architecture. The resulting knowledge fusion rules are naturally applicable to real-world data. © 2010 Elsevier B.V., All rights reserved.",TOPIC
10.2298/CSIS141026047I,Computer Science and Information Systems,"In last decade, intensive research on emotional intelligence has advanced significantly from its theoretical basis, analytical studies and processing technology to exploratory applications in a wide range of real-life domains. This paper brings new insights in the field of emotional, intelligent software agents. The first part is devoted to an overview of the state-of-the-art in emotional intelligence research with emphasis on emotional agents. A wide range of applications in different areas like modeling emotional agents, aspects of learning in emotional environments, interactive emotional systems and so on are presented. After that we suggest a systematic order of research steps with the idea of proposing an adequate framework for several possible real-life applications of emotional agents. We recognize that it is necessary to apply specific methods for dynamic data analysis in order to identify and discover new knowledge from available emotional information and data sets. The last part of the paper discusses research activities for designing an agent-based architecture, in which agents are capable of reasoning about and displaying some kind of emotions based on emotions detected in human speech, as well as online documents. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.2316/journal.203.2007.1.203-3588,International Journal of Power and Energy Systems,"The liberalization of the electricity supply industry has shifted the analyses and modelling activities from planning to operation. However, project studies and investment appraisal still require medium and long-term anticipation of the electricity market prices. The models traditionally used for making such projections i.e. statistical extrapolation or econometrics fail to capture the future structural changes in the emerging electricity markets. There is a need for a novel framework of modelling that could extend game theoretical assumptions to more complex ones. This paper proposes, in a decision-making perspective, a new multi-agent architecture specifically designed to support flexible planning activities in decentralized electricity markets. In this model, the concept of synthetic agents is used for modelling in flexible forms multi-functional market players, possible mergers and coalitions in the electricity market. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.2316/p.2010.677-015,,"In this paper we extend finite state machines to allow expressions in Plausible Logic for labelling transitions. As a result, we enable the design of behaviours that incorporate non-monotonic reasoning with a high-level software development tool. Using a cognitive software architecture that supports the efficient implementation of a developing/ programming environment, we automatically translate graphical designs of behaviour into executables that run on board autonomous robots. The graphical designs are obtained by demonstrating the transformation of the state machine into a Behavior Tree does not lose information and enhances modularisation of logic descriptions. We illustrate this with a description of the rapid development of the behaviour of a friendly poker player on an Aibo that interacts with humans. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.23919/ACC53348.2022.9867557,Proceedings of the American Control Conference,"With the growing need to reduce energy consumption and greenhouse gas emissions, Eco-driving strategies provide a significant opportunity for additional fuel savings on top of other technological solutions being pursued in the transportation sector. In this paper, a model-free deep reinforcement learning (RL) control agent is proposed for active Eco-driving assistance that trades-off fuel consumption against other driver-accommodation objectives, and learns optimal traction torque and transmission shifting policies from experience. The training scheme for the proposed RL agent uses an off-policy actor-critic architecture that iteratively does policy evaluation with a multi-step return and policy improvement with the maximum posteriori policy optimization algorithm for hybrid action spaces. The proposed Eco-driving RL agent is implemented on a commercial vehicle in car following traffic. It shows superior performance in minimizing fuel consumption compared to a baseline controller that has full knowledge of fuel-efficiency tables. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.23919/cje.2022.00.305,Dispersed Computing Resource Discovery Model and Algorithm for Polymorphic Migration Network Architecture,"Dynamic resource discovery in a network of dispersed computing resources is an open problem. The establishment and maintenance of resource pool information are critical, which involves both the polymorphic migration of the network and the time and energy costs resulting from node selection and frequent interactions of information between nodes. The resource discovery problem for dispersed computing can be considered a dynamic multi-level decision problem. A bi-level programming model of dispersed computing resource discovery is developed, which is driven by time cost, energy consumption and accuracy of information acquisition. The upper-level model is to design a reasonable network structure of resource discovery, and the lower-level model is to explore an effective discovery mode. Complex network topology features are used for the first time to analyze the polymorphic migration characteristics of resource discovery networks. We propose an integrated calibration method for energy consumption parameters based on two discovery modes (i.e., agent mode and self-directed mode). A symmetric trust region based heuristic algorithm is proposed for solving the system model. The numerical simulation is performed in a dispersed computing network with multiple modes and topological states, which proves the feasibility of the model and the effectiveness of the algorithm.",TOPIC
10.23919/CNSM59352.2023.10327825,,"Designing smart mechanisms to facilitate and accelerate service deployment and management is one of the most challenging aspects for network infrastructure providers. This is due to the massive amount of traffic that they are expected to support, the decentralized nature of the architectures, and the services they run to meet quality targets and avoid Service Level Agreement (SLA) violations. Therefore, Communications Service Providers (CSPs) are devoting much of their efforts on reducing energy consumption and reducing carbon foot-print of their network infrastructures. In future communication networks, traditional management mechanisms, and centralized legacy solutions show their limitations in ensuring revenue for the infrastructure providers, the service providers, and a good Quality of Experience (QoE) for the end-users. The deployment of these services requires, typically, an efficient allocation of Virtual Network Function Forwarding Graph (VNF-FG). In this context, we propose an intelligent energy efficient VNF-FG embedding approach based on multi-Agent attention-based Deep Reinforcement Learning (DRL). Our contribution uses a semi-distributed DRL mechanism for VNF-FG placement. The proposed algorithm is shown to outperform previous state-of-The-Art approaches in terms of acceptance rate, power consumption, and execution time. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.23919/EUSIPCO54536.2021.9616256,European Signal Processing Conference,"Meta-learning aims to improve efficiency of learning new tasks by exploiting the inductive biases obtained from related tasks. Previous works consider centralized or federated architectures that rely on central processors, whereas, in this paper, we propose a decentralized meta-learning scheme where the data and the computations are distributed across a network of agents. We provide convergence results for non-convex environments and illustrate the theoretical findings with experiments. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.23919/ICN.2024.0007,Adaptive Cache Policy Optimization Through Deep Reinforcement Learning in Dynamic Cellular Networks,"We explore the use of caching both at the network edge and within User Equipment (UE) to alleviate traffic load of wireless networks. We develop a joint cache placement and delivery policy that maximizes the Quality of Service (QoS) while simultaneously minimizing backhaul load and UE power consumption, in the presence of an unknown time-variant file popularity. With file requests in a time slot being affected by download success in the previous slot, the caching system becomes a non-stationary Partial Observable Markov Decision Process (POMDP). We solve the problem in a deep reinforcement learning framework based on the Advantageous Actor-Critic (A2C) algorithm, comparing Feed Forward Neural Networks (FFNN) with a Long Short-Term Memory (LSTM) approach specifically designed to exploit the correlation of file popularity distribution across time slots. Simulation results show that using LSTM-based A2C outperforms FFNN-based A2C in terms of sample efficiency and optimality, demonstrating superior performance for the non-stationary POMDP problem. For caching at the UEs, we provide a distributed algorithm that reaches the objectives dictated by the agent controlling the network, with minimum energy consumption at the UEs, and minimum communication overhead.",TOPIC
10.23919/ICN.2025.0001,Cooperative UAV Clustering for Fair Coverage of Communication Regions,"Cooperative unmanned aerial vehicles (UAVs) cluster technology is considered a prospective solution for area coverage problems, enabling network access and emergency communications in remote areas. In this paper, we investigate how to control UAV cluster to achieve long-term and stable regional coverage while maintaining link connectivity and minimizing energy consumption, given the limited communication range and energy consumption of the UAVs themselves. To this end, we propose a cooperative UAV cluster strategy based on multi-agent deep reinforcement learning (MADRL) to achieve fair coverage of communication regions, which we call MADRL-based cooperative UAV cluster strategy (MADRL-CUCS). Our solution is a centralized training distributed execution architecture and defines a cluster structure for leader UAVs and follower UAVs. Under the premise of comprehensively considering the maximum coverage, we use a new energy efficiency function to minimize energy consumption, so as to extend the network lifetime of the UAVs cluster networks. The new fairness index and collision avoidance factor are used to ensure that the UAV cluster achieve effective and secure regional coverage. We adopt depth first search algorithm to check the link connectivity of the UAVs during the coverage process. Experiments show that the MADRL-CUCS algorithm outperforms the benchmark algorithm.",TOPIC
10.23919/JCN.2020.000032,A deep-Q learning approach to mobile operator collaboration,"Next-generation mobile connectivity services include a large number of devices distributed across vast geographical areas. Mobile network operators will need to collaborate to fulfill service requirements at scale. Existing approaches to multi-operator services assume already-established collaborations to fulfill customer service demand with specific quality of service (QoS). In this paper, we propose an agent-based architecture, where establishment of collaboration for a given connectivity service is done proactively, given predictions about future service demand. We build a simulation environment and evaluate our approach with a number of scenarios and in context of a real-world use case, and compare it with existing collaboration approaches. Results show that by learning how to adapt their collaboration strategy, operators can fulfill a greater part of the service requirements than by providing the service independently, or through pre-established, intangible service level agreements.",TOPIC
10.23919/JSEE.2020.000006,Multi-agent system application in accordance with game theory in bi-directional coordination network model,"The multi-agent system is the optimal solution to complex intelligent problems. In accordance with the game theory, the concept of loyalty is introduced to analyze the relationship between agents' individual income and global benefits and build the logical architecture of the multi-agent system. Besides, to verify the feasibility of the method, the cyclic neural network is optimized, the bi-directional coordination network is built as the training network for deep learning, and specific training scenes are simulated as the training background. After a certain number of training iterations, the model can learn simple strategies autonomously. Also, as the training time increases, the complexity of learning strategies rises gradually. Strategies such as obstacle avoidance, firepower distribution and collaborative cover are adopted to demonstrate the achievability of the model. The model is verified to be realizable by the examples of obstacle avoidance, fire distribution and cooperative cover. Under the same resource background, the model exhibits better convergence than other deep learning training networks, and it is not easy to fall into the local endless loop. Furthermore, the ability of the learning strategy is stronger than that of the training model based on rules, which is of great practical values.",TOPIC
10.23919/JSEE.2021.000121,UAV cooperative air combat maneuver decision based on multi-agent reinforcement learning,"In order to improve the autonomous ability of unmanned aerial vehicles (UAV) to implement air combat mission, many artificial intelligence-based autonomous air combat maneuver decision-making studies have been carried out, but these studies are often aimed at individual decision-making in 1v1 scenarios which rarely happen in actual air combat. Based on the research of the 1v1 autonomous air combat maneuver decision, this paper builds a multi-UAV cooperative air combat maneuver decision model based on multi-agent reinforcement learning. Firstly, a bidirectional recurrent neural network (BRNN) is used to achieve communication between UAV individuals, and the multi-UAV cooperative air combat maneuver decision model under the actor-critic architecture is established. Secondly, through combining with target allocation and air combat situation assessment, the tactical goal of the formation is merged with the reinforcement learning goal of every UAV, and a cooperative tactical maneuver policy is generated. The simulation results prove that the multi-UAV cooperative air combat maneuver decision model established in this paper can obtain the cooperative maneuver policy through reinforcement learning, the cooperative maneuver policy can guide UAVs to obtain the overall situational advantage and defeat the opponents under tactical cooperation.",TOPIC
10.23919/JSEE.2023.000118,Distributed Collaborative Complete Coverage Path Planning Based on Hybrid Strategy,"Collaborative coverage path planning (CCPP) refers to obtaining the shortest paths passing over all places except obstacles in a certain area or space. A multi-unmanned aerial vehicle (UAV) collaborative CCPP algorithm is proposed for the urban rescue search or military search in outdoor environment. Due to flexible control of small UAVs, it can be considered that all UAVs fly at the same altitude, that is, they perform search tasks on a two-dimensional plane. Based on the agents' motion characteristics and environmental information, a mathematical model of CCPP problem is established. The minimum time for UAVs to complete the CCPP is the objective function, and complete coverage constraint, no-fly constraint, collision avoidance constraint, and communication constraint are considered. Four motion strategies and two communication strategies are designed. Then a distributed CCPP algorithm is designed based on hybrid strategies. Simulation results compared with pattern-based genetic algorithm (PBGA) and random search method show that the proposed method has stronger real-time performance and better scalability and can complete the complete CCPP task more efficiently and stably.",TOPIC
10.23919/JSEE.2024.000114,Battlefield Target Intelligence System Architecture Modeling and System Optimization,"To address the current problems of poor generality, low real-time, and imperfect information transmission of the battlefield target intelligence system, this paper studies the battlefield target intelligence system from the top-level perspective of multi-service joint warfare. First, an overall planning and analysis method of architecture modeling is proposed with the idea of a bionic analogy for battlefield target intelligence system architecture modeling, which reduces the difficulty of the planning and design process. The method introduces the Department of Defense architecture framework (DoDAF) modeling method, the multi-living agent (MLA) theory modeling method, and other combinations for planning and modeling. A set of rapid planning methods that can be applied to model the architecture of various types of complex systems is formed. Further, the liveness analysis of the battlefield target intelligence system is carried out, and the problems of the existing system are presented from several aspects. And the technical prediction of the development and construction is given, which provides directional ideas for the subsequent research and development of the battlefield target intelligence system. In the end, the proposed architecture model of the battlefield target intelligence system is simulated and verified by applying the colored Petri nets (CPN) simulation software. The analysis demonstrates the reasonable integrity of its logic.",TOPIC
10.23919/transcom.2025EBP3068,Adaptive deep reinforcement learning-based secure transmission mechanism for underwater wireless sensor networks,"To address the security challenges of underwater wireless sensor networks (UWSNs) in complex and hostile environments, this paper investigates the physical-layer secrecy performance of the transmitter-receiver link, with particular emphasis on transmission optimization under eavesdropping threats. We formulate a non-linear, non-convex optimization problem that jointly allocates sub-channels and transmission power to maximize the secrecy rate while considering the inherent constraints of underwater acoustic communication. To efficiently solve this problem, we develop a deep reinforcement learning (DRL)-based resource allocation algorithm that integrates a prioritized experience replay mechanism, thereby enhancing learning efficiency and improving optimization performance. Extensive simulations are conducted to assess the convergence and adaptability of the proposed method under varying node densities and maximum transmission power levels. The results demonstrate that the proposed algorithm consistently achieves higher system security, greater stability, and faster convergence compared to several benchmark schemes.",TOPIC
10.23919/transcom.2025EBP3092,Distributed deep reinforcement learning-based resource management for underwater acoustic communication networks,"This paper investigates the problem of distributed resource management in underwater acoustic communication networks (UACNs) involving multiple transmitters and receivers. In this setting, each transmitter autonomously selects a power allocation strategy based solely on local observations, without reliance on a central controller. Given that the optimization problem incorporating fairness and quality of service (QoS) constraints is non-convex and NP-hard, it is reformulated as a Markov Decision Process (MDP). To address the high complexity of underwater networks and the large state and action spaces, we propose a distributed learning framework based on a multi-agent dueling deep Q-network (MAD3QN). The proposed scheme enables each transmitter to dynamically adjust its transmission power based on local observations by integrating the Jain fairness index, QoS interruption penalty, and energy consumption constraints. Furthermore, by incorporating a dueling network architecture and a neighborhood cooperation mechanism, the learning efficiency is significantly enhanced, leading to a stable and effective resource optimization policy. Simulation results demonstrate that the proposed distributed learning algorithm outperforms existing approaches in terms of convergence speed, network fairness, and communication rate.",TOPIC
10.23919/transcom.2025SCI0001,Research on smart wireless aerial networks facilitating digital twin construction,"This paper proposes a comprehensive framework for constructing smart wireless aerial networks to support high-fidelity digital twin (DT) systems. To meet the stringent data rate demands of airborne Light Detection and Ranging (LiDAR) sensing, we analyze the required throughput for point cloud transmission and design a millimeter-wave (mmWave) aerial link budget model. A software-defined architecture integrating Network Function Virtualization/Software Defined Networking (NFV/SDN) is introduced to enable dynamic Unmanned Aerial Vehicle (UAV) orchestration, routing, and network slicing. To enhance robustness and efficiency, we propose two application-layer innovations: a multi-route redundant communication framework and a semantic image transmission protocol using deep joint source-channel coding (DJSCC) with feature-based elastic compression. Furthermore, we implement a multi-agent reinforcement learning strategy to enable autonomous UAV placement and relay network formation in dynamic environments. Simulation results demonstrate the proposed system's scalability, adaptability, and potential to enable reliable and efficient DT construction across diverse deployment scenarios.",TOPIC
10.24084/repqj01.397,Renewable Energy and Power Quality Journal,"Adequate training programs for power systems restoration tasks must take into account that this is a cooperative activity involving several entities. The proposed architecture of the Intelligent Tutoring System presented in this paper is based on a multi-agent system offering a simulated training environment. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.2478/jaiscr-2014-0003,Journal of Artificial Intelligence and Soft Computing Research,"The complexity and dynamics in groupage traffic require flexible, efficient, and adaptive planning and control processes. The general problem of allocating orders to vehicles can be mapped into the Vehicle Routing Problem (VRP). However, in practical applications additional requirements complicate the dispatching processes and require a proactive and reactive system behavior. To enable automated dispatching processes, this article presents a multiagent system where the decision making is shifted to autonomous, interacting, intelligent agents. Beside the communication protocols and the agent architecture, the focus is on the individual decision making of the agents which meets the specific requirements in groupage traffic. To evaluate the approach we apply multiagent-based simulation and model several scenarios of real world infrastructures with orders provided by our industrial partner. Moreover, a case study is conducted which covers the autonomous groupage traffic in the current processes of our industrial parter. The results reveal that agent-based dispatching meets the sophisticated requirements of groupage traffic. Furthermore, the decision making supports the combination of pickup and delivery tours efficiently while satisfying logistic request priorities, time windows, and capacity constraints. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.2478/s13230-010-0010-4,Paladyn,"Motivation is a central concept in the development of autonomous agents and robots. This paper describes an architecture that uses a psychological BDI model of reasoning, combined with a distributed multi-level model of motivation. The robot controlling architecture makes use of a generic set of deliberative components plus an environment task-centred set of reactive components that reflect the architecture's embodiment. The architecture has been used in a number of simulated environments and here is used to control a mobile robot. A theoretical framework for motivation and affect is given, and related to the nature of autonomy and embodiment. A BDI model, based on a psychological model of reasoning in a 5 year old child, is described in terms of the nature of motivation and affect within the architecture. Finally, criteria for judging the nature of an agent's motivation are introduced, and used to validate the motivational constructs implemented within the architecture. Experimental results lead to a comparative discussion. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.2478/s13230-013-0106-8,Paladyn,"Robots and living beings exhibit latencies in their sensorimotor processing due to mechanical and electronic or neural processing delays. A reaction typically occurs to input stimuli of the past. This is critical not only when the environment changes (e.g. moving objects) but also when the agent itself moves. An agent that does not predict while moving may need to remain static between sensory input acquisition and output response to guarantee that the response is appropriate to the percept. We propose a biologically-inspired learning model of predictive sensorimotor integration to compensate for this latency. In this model, an Elman network is developed for sensory prediction and sensory filtering; a Continuous Actor-Critic Learning Automaton (CACLA) is trained for continuous action generation. For a robot docking experiment, this architecture improves the smoothness of the robot's sensory input and therefore results in a faster and more accurate continuous approach behavior. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.2478/v10006-008-0037-4,International Journal of Applied Mathematics and Computer Science,"The paper presents an algorithm which solves the shortest path problem in an arbitrary deterministic environment with n states with an emotional agent in linear time. The algorithm originates from an algorithm which in exponential time solves the same problem, and the agent architecture used for solving the problem is an NN-CAA architecture (neural network crossbar adaptive array). By implementing emotion learning, the linear time algorithm is obtained and the agent architecture is modified. The complexity of the algorithm without operations for initiation in general does not depend on the number of states n, but only on the length of the shortest path. Depending on the position of the goal state, the complexity can be at most O (n). It can be concluded that the choice of the function which evaluates the emotional state of the agent plays a decisive role in solving the problem efficiently. That function should give as detailed information as possible about the consequences of the agent's actions, starting even from the initial state. In this way the function implements properties of human emotions. © 2008 Elsevier B.V., All rights reserved.",TOPIC
10.2478/v10006-011-0004-3,International Journal of Applied Mathematics and Computer Science,"The problem considered concerns data reduction for machine learning. Data reduction aims at deciding which features and instances from the training set should be retained for further use during the learning process. Data reduction results in increased capabilities and generalization properties of the learning model and a shorter time of the learning process. It can also help in scaling up to large data sources. The paper proposes an agent-based data reduction approach with the learning process executed by a team of agents (A-Team). Several A-Team architectures with agents executing the simulated annealing and tabu search procedures are proposed and investigated. The paper includes a detailed description of the proposed approach and discusses the results of a validating experiment. © 2011 Elsevier B.V., All rights reserved.",TOPIC
10.24846/v24i1y201502,Studies in Informatics and Control,"The evolution of Web technologies has made e-Learning a popular common way to teach and learn both in school and non-school settings. This paper provides an education-oriented approach for building personalized e-Learning environments that focuses on putting the learners' needs in the centre of the development process. The proposed agent-based adaptive architecture extends Moodle platform in order to support instructional decisions and adaptive behaviour. The paper describes the characteristics, functions, and interactions of the agents which take part in each module of the adaptive architecture, as well as an intelligent agent for instructional decisions making. The aim of this agent is to collect information generated by the rest of agents and to provide the best personalised support for the final users, tutors and students, taking into account their attitudes towards the learning environment. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.2495/DNE-V11-N2-107-115,International Journal of Design and Nature and Ecodynamics,"Supply chain management (SCM) is a well-known example of a complex system. Classical computing technologies have shown little success in modeling complex systems. However, a large body of research in multi-agent system (MAS) technology has demonstrated how complex systems can be modeled to generate smart solutions, which could not be done otherwise. We have researched on the design and development of MAS for SCM. In this solution, each phase in the supply chain has been developed as an agent enabling communication, coordination and negotiation among the agents to achieve intended business goals. The study investigated decentralized collaborative planning architecture and agents are attached to different containers of the system. The containers have been implemented using a Java Agent Development Framework (JADE) and consist of diverse methods to support collaboration in the supply chain environment. Agents have different behaviors and their decisions are based on defined ontology. The identified key roles in the supply chain are raw material suppliers, manufacturers, distributors and retailers. They perform autonomous tasks with collaboration to accomplish final customer satisfaction. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.2495/DNE-V11-N2-116-126,International Journal of Design and Nature and Ecodynamics,"The paper proposes a multi-agent method to creating an intelligent adaptive system of train real time scheduling with conflict limitations. The architecture of the multi-agent system consisting of two base planning subsystems is described. Subsystem interaction protocols and protocols of agent interaction within each subsystem are presented. The example of schedule planning in various situations is presented in details. Realizable characteristics of the developed multiagent system are presented. High quality of schedule planning and system performance is shown. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.2495/UT090171,WIT Transactions on the Built Environment,"This paper reports on the development of myTIS, which is a multi-agent based architecture to support public transport users in planning and executing their trips on a daily basis. Commuters that use public transport in their daily lives are frequently faced with problems, such as finding out what time the next bus service to a certain destination arrives or how to improve their travel experience to minimise the time spend in transit. On the other hand, non-commuters must address even more complicated issues, as they are not familiar with the network and would need continuous assistance throughout the trip realisation. These scenarios bring about interesting and challenging problems that suggest the adequacy of the multi-agent systems (MAS) metaphor. In a first abstraction exercise, it is very intuitive to identify such characteristics in the public transport domain. myTIS (where the TIS excerpt stands for traveller information system) is intended to be a cross-platform for public transport travellers, divided in terms of agents that cooperate to fulfil users' trip planning goals. Such a design decision is a requirement as the system must cover the whole decision-making process of a commuting plan. The methodological approach followed in this project includes a modelling phase, in which the requirements of the system and its main functionalities are defined. This phase is supported by an in-depth state-of-the-art review and the study of similar applications and results in the design of a new generation MAS-based traveller information system. © 2009 WIT Press. © 2010 Elsevier B.V., All rights reserved.",TOPIC
10.24963/ijcai.2017/280,IJCAI International Joint Conference on Artificial Intelligence,"Question-answering (QA) on video contents is a significant challenge for achieving human-level intelligence as it involves both vision and language in real-world settings. Here we demonstrate the possibility of an AI agent performing video story QA by learning from a large amount of cartoon videos. We develop a video-story learning model, i.e. Deep Embedded Memory Networks (DEMN), to reconstruct stories from a joint scene-dialogue video stream using a latent embedding space of observed data. The video stories are stored in a long-term memory component. For a given question, an LSTM-based attention model uses the long-term memory to recall the best question-story-answer triplet by focusing on specific words containing key information. We trained the DEMN on a novel QA dataset of children's cartoon video series, Pororo. The dataset contains 16,066 scene-dialogue pairs of 20.5-hour videos, 27,328 fine-grained sentences for scene description, and 8,913 story-related QA pairs. Our experimental results show that the DEMN outperforms other QA models. This is mainly due to 1) the reconstruction of video stories in a scene-dialogue combined form that utilize the latent embedding and 2) attention. DEMN also achieved state-of-the-art results on the MovieQA benchmark. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.24963/ijcai.2018/37,IJCAI International Joint Conference on Artificial Intelligence,"Within the context of video games the notion of perfectly rational agents can be undesirable as it leads to uninteresting situations, where humans face tough adversarial decision makers. Current frameworks for stochastic games and reinforcement learning prohibit tuneable strategies as they seek optimal performance. In this paper, we enable such tuneable behaviour by generalising soft Q-learning to stochastic games, where more than one agent interact strategically. We contribute both theoretically and empirically. On the theory side, we show that games with soft Q-learning exhibit a unique value and generalise team games and zero-sum games far beyond these two extremes to cover a continuous spectrum of gaming behaviour. Experimentally, we show how tuning agents' constraints affect performance and demonstrate, through a neural network architecture, how to reliably balance games with high-dimensional representations. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.24963/ijcai.2018/4,IJCAI International Joint Conference on Artificial Intelligence,"Norms describe the social architecture of a society and govern the interactions of its member agents. It may be appropriate for an agent to deviate from a norm; the deviation being indicative of a specialized norm applying under a specific context. Existing approaches for norm emergence assume simplified interactions wherein deviations are negatively sanctioned. We investigate via simulation the benefits of enriched interactions where deviating agents share selected elements of their contexts. We find that as a result (1) the norms are learned better with fewer sanctions, indicating improved social cohesion; and (2) the agents are better able to satisfy their individual goals. These results are robust under societies of varying sizes and characteristics reflecting pragmatic, considerate, and selfish agents. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.24963/ijcai.2018/55,IJCAI International Joint Conference on Artificial Intelligence,"Although recent work in AI has made great progress in solving large, zero-sum, extensive-form games, the underlying assumption in most past work is that the parameters of the game itself are known to the agents. This paper deals with the relatively under-explored but equally important “inverse” setting, where the parameters of the underlying game are not known to all agents, but must be learned through observations. We propose a differentiable, end-to-end learning framework for addressing this task. In particular, we consider a regularized version of the game, equivalent to a particular form of quantal response equilibrium, and develop 1) a primal-dual Newton method for finding such equilibrium points in both normal and extensive form games; and 2) a backpropagation method that lets us analytically compute gradients of all relevant game parameters through the solution itself. This ultimately lets us learn the game by training in an end-to-end fashion, effectively by integrating a “differentiable game solver” into the loop of larger deep network architectures. We demonstrate the effectiveness of the learning method in several settings including poker and security game tasks. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.24963/ijcai.2018/682,IJCAI International Joint Conference on Artificial Intelligence,"Collecting training data from the physical world is usually time-consuming and even dangerous for fragile robots, and thus, recent advances in robot learning advocate the use of simulators as the training platform. Unfortunately, the reality gap between synthetic and real visual data prohibits direct migration of the models trained in virtual worlds to the real world. This paper proposes a modular architecture for tackling the virtual-to-real problem. The proposed architecture separates the learning model into a perception module and a control policy module, and uses semantic image segmentation as the meta representation for relating these two modules. The perception module translates each perceived RGB image to semantic image segmentation. The control policy module is implemented as a deep reinforcement learning agent, which performs actions based on the translated image segmentation. Our architecture is evaluated in an obstacle avoidance task and a target following task. Experimental results show that our architecture significantly outperforms all of the baseline methods in both virtual and real environments, and demonstrates a faster learning curve than them. We also present a detailed analysis for a variety of variant configurations, and validate the transferability of our modular architecture. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.24963/ijcai.2019/445,IJCAI International Joint Conference on Artificial Intelligence,"Dyna is an architecture for model-based reinforcement learning (RL), where simulated experience from a model is used to update policies or value functions. A key component of Dyna is search-control, the mechanism to generate the state and action from which the agent queries the model, which remains largely unexplored. In this work, we propose to generate such states by using the trajectory obtained from Hill Climbing (HC) the current estimate of the value function. This has the effect of propagating value from high-value regions and of preemptively updating value estimates of the regions that the agent is likely to visit next. We derive a noisy projected natural gradient algorithm for hill climbing, and highlight a connection to Langevin dynamics. We provide an empirical demonstration on four classical domains that our algorithm, HC-Dyna, can obtain significant sample efficiency improvements. We study the properties of different sampling distributions for search-control, and find that there appears to be a benefit specifically from using the samples generated by climbing on current value estimates from low-value to high-value region. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.24963/ijcai.2019/497,IJCAI International Joint Conference on Artificial Intelligence,"Classically, imitation learning algorithms have been developed for idealized situations, e.g., the demonstrations are often required to be collected in the exact same environment and usually include the demonstrator's actions. Recently, however, the research community has begun to address some of these shortcomings by offering algorithmic solutions that enable imitation learning from observation (IfO), e.g., learning to perform a task from visual demonstrations that may be in a different environment and do not include actions. Motivated by the fact that agents often also have access to their own internal states (i.e., proprioception), we propose and study an IfO algorithm that leverages this information in the policy learning process. The proposed architecture learns policies over proprioceptive state representations and compares the resulting trajectories visually to the demonstration data. We experimentally test the proposed technique on several MuJoCo domains and show that it outperforms other imitation from observation algorithms by a large margin. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.24963/ijcai.2019/86,IJCAI International Joint Conference on Artificial Intelligence,"Learning to adapt to a series of different goals in visual navigation is challenging. In this work, we present a model-embedded actor-critic architecture for the multi-goal visual navigation task. To enhance the task cooperation in multi-goal learning, we introduce two new designs to the reinforcement learning scheme: inverse dynamics model (InvDM) and multi-goal co-learning (MgCl). Specifically, InvDM is proposed to capture the navigation-relevant association between state and goal, and provide additional training signals to relieve the sparse reward issue. MgCl aims at improving the sample efficiency and supports the agent to learn from unintentional positive experiences. Extensive results on the interactive platform AI2-THOR demonstrate that the proposed method converges faster than state-of-the-art methods while producing more direct routes to navigate to the goal. The video demonstration is available at: https://youtube.com/channel/ UCtpTMOsctt3yPzXqe JMD3w/videos. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.24963/ijcai.2019/906,IJCAI International Joint Conference on Artificial Intelligence,"Robotics in healthcare has recently emerged, backed by the recent advances in the field of machine learning and robotics. Researchers are focusing on training robots for interacting with elderly adults. This research primarily focuses on engineering more efficient robots that can learn from their mistakes, thereby aiding in better human-robot interaction. In this work, we propose a method in which a robot learns to navigate itself to the individual in need. The robotic agents' learning algorithm will be capable of navigating in an unknown environment. The robot's primary objective is to locate human in a house, and upon finding the human, the goal is to interact with them while complementing their pose and gaze. We propose an end to end learning strategy, which uses a recurrent neural network architecture in combination with Q-learning to train an optimal policy. The idea can be a contribution to better human-robot interaction. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.24963/ijcai.2021/60,IJCAI International Joint Conference on Artificial Intelligence,"The bus system is a critical component of sustainable urban transportation. However, due to the significant uncertainties in passenger demand and traffic conditions, bus operation is unstable in nature and bus bunching has become a common phenomenon that undermines the reliability and efficiency of bus services. Despite recent advances in multi-agent reinforcement learning (MARL) on traffic control, little research has focused on bus fleet control due to the tricky asynchronous characteristic-control actions only happen when a bus arrives at a bus stop and thus agents do not act simultaneously. In this study, we formulate route-level bus fleet control as an asynchronous multi-agent reinforcement learning (ASMR) problem and extend the classical actor-critic architecture to handle the asynchronous issue. Specifically, we design a novel critic network to effectively approximate the marginal contribution for other agents, in which graph attention neural network is used to conduct inductive learning for policy evaluation. The critic structure also helps the ego agent optimize its policy more efficiently. We evaluate the proposed framework on real-world bus services and actual passenger demand derived from smart card data. Our results show that the proposed model outperforms both traditional headway-based control methods and existing MARL methods. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.24963/ijcai.2022/431,IJCAI International Joint Conference on Artificial Intelligence,"Network pruning is considered efficient for sparsification and acceleration of Convolutional Neural Network (CNN) based models that can be adopted in resource-constrained environments. Inspired by two popular pruning criteria, i.e. magnitude and similarity, this paper proposes a novel structural pruning method based on Graph Convolution Network (GCN) to further promote compression performance. The channel features are firstly extracted by Global Average Pooling (GAP) from a batch of samples, and a graph model for each layer is generated based on the similarity of features. A set of agents for individual CNN layers are implemented by GCN and utilized to synthesize comprehensive channel information and determine the pruning scheme for the overall CNN model. The training process of each agent is carried out using Reinforcement Learning (RL) to ensure their convergence and adaptability to various network architectures. The proposed solution is assessed based on a range of image classification datasets i.e., CIFAR and Tiny-ImageNet. The numerical results indicate that the proposed pruning method outperforms the pure magnitude-based or similarity-based pruning solutions and other SOTA methods (e.g., HRank and SCP). For example, the proposed method can prune VGG16 by removing 93% of the model parameters without any accuracy reduction in the CIFAR10 dataset. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.25046/aj030310,"Advances in Science, Technology and Engineering Systems","The rapid evolution of Collaborative e-Learning Systems migrates to the use of new technologies such the artificial intelligence (AI). In this context, the role of AI in increasing the quality of learning and making it more productive, persistent and efficient. In addition, it can accomplish repetitive and complex tasks in record time and unmatched accuracy. These advantages offer the ability to interact with learners in an almost human way. This interaction could be made on the base of adaptive hypermedia techniques, Multi-agent Systems technology and a cognitive learner model. In this paper, we present and analyze some existing intelligent collaborative e-Learning systems on the basis of their various features such as collaboration features, intelligent actors' interaction, adaptability measurement, cognitive student modeling, and security measurement. Our analysis aims to provide important information to researchers, educators and software developers of educational environments concerning strengths and weaknesses of those e-Learning systems. According to this study, we found that some collaborative e-Learning environments, even the use of the mentioned technologies, still poor in terms of the structure of human cognitive architecture aspects and the capacity to assess the help provided to learners. For these reasons, we present, in the end, some prospects in order to determine how we can improve these systems to stop the reasons of abandoning courses. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.25046/aj030618,"Advances in Science, Technology and Engineering Systems","Optical switching provided the means for the development of Data Centers with high throughput interconnection networks. A significant contribution to the advanced optical Data Centers designs is the Nephele architecture that employs optical data planes, optical Points of Delivery (PoD) switches and Top of Rack (ToR) switches equipped with 10 Gbps connections to the PoDs and the servers. Nephele follows the Software Defined Network (SDN) paradigm based on the OpenFlow protocol and it employs an Agent communicating the protocol commands to the data plane. The current paper presents a management tool for the Agent. The Agent's management tool is utilized to configure the Agent, create commands, perform step operations and monitor the results and the status. Moreover, as a testing and validation tool, it plays a significant role in the improvement of the Agent's design as well as in the upgrade of the entire data center's organization and performance. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.2507/26th.daaam.proceedings.164,Annals of DAAAM and Proceedings of the International DAAAM Symposium,"The pressure of global competition has led the urge of highly individualizes products to sustain in the market. This entaile a rise of information technologies in area of discrete manufacturing, which has led to Computer Integrated Manufacturin (CIM) and later to Reconfigurable Manufacturing Systems (RMS). Both paradigms struggle with stiff hierarchical contro architectures, and a lack of flexibility. To overcome those limitations, the aim is to integrate the concepts of Servic Oriented Architecture (SOA) into the factory automation domain. By elaborating a way to induct the paradigm of SO in Manufacturing Execution System (MES), a supporting framework will be established. This will enable an autonomou model for multi agent based control architecture of a demonstration cell. This proposal aims to work out those synergie and to give a short envision of the state of the art, in order to expound the authors previous approach and an outlook. Th previous approach was built around a demonstrator manufacturing cell, where an OPC UA server has been developed fo the machine control. Through the capability of evolving method into the information model, the opportunity of sequencin rudimentary services to higher services processes occurred The outlook will show how we plan to merge those higher services to a service oriented Manufacturing Execution System by taking the guideline VDI 5600 into consideration. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.2514/6.2010-7586,,"In this paper, we introduce a method for learning and adapting cooperative control strategies in real-time stochastic domains. Our framework is an instance of the intelligent cooperative control architecture (iCCA) 1. The agent starts by following the ""safe"" plan calculated by the planning module and incrementally adapting its policy to maximize the cumulative rewards. Actor-critic and consensus-based bundle algorithm (CBBA) were employed as the building blocks of the iCCA framework. We demonstrate the performance of our approach by simulating limited fuel unmanned aerial vehicles aiming for stochastic targets. In one experiment where the optimal solution can be calculated, the integrated framework boosted the optimality of the solution by an average of %10, when compared to running each of the modules individually, while keeping the computational load within the requirements for real-time implementation. Copyright © 2010 by Jonathan P. How. © 2012 Elsevier B.V., All rights reserved.",TOPIC
10.2514/6.2021-0812,,"Several reports forecast a very high demand for Urban Air Mobility services such as package delivery and air taxi. This would lead to very dense low-altitude operations which cannot be safely accommodated by the current air traffic management system. Many different architectures for low-altitude air traffic management have been proposed in the literature, however, the lack of a common framework makes it difficult to compare strategies. The work presented here establishes efficiency, safety and capacity metrics, defines the components of an automated traffic management system architecture and introduces a preliminary framework to compare different alternatives. This common framework allows for the evaluation and comparison of different alternatives for unmanned traffic management. The framework is showcased on different strategies with different architectures. The impact of algorithmic choices and airspace architectures is evaluated. A decoupled approach to 4D trajectory planning is shown to scale poorly with agents density. The impact of segregating traffic by heading is shown to be very different depending on the algorithms and airspace access rules chosen. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.26599/CVM.2025.9450484,Computer-Aided Layout Generation for Building Design: A Review,"Generating realistic building layouts for automatic building design has been studied in both computer vision and architectural domains. Traditional approaches in the latter, which are based on optimization techniques or heuristic design guidelines, can synthesize desirable layouts, but usually require post-processing and involve human interaction in the design pipeline, making them costly and time-consuming. The advent of deep generative models has significantly improved the fidelity and diversity of the generated architecture layouts, reducing the workload of designers and making the process much more efficient. This paper presents a comprehensive review of three major research topics in architectural layout design and generation: floorplan layout generation, scene layout synthesis, and generation of various other formats of building layouts. For each topic, we overview the leading paradigms, categorized either by research domains (architecture or machine learning) or by user input conditions or constraints. We then introduce commonly-adopted benchmark datasets used to verify the effectiveness of the methods, as well as corresponding evaluation metrics. Finally, we identify the well-solved problems and limitations of existing approaches, and then propose promising directions for future research. This survey has an associated project which aims to maintain the resources, at https://github.com/jcliu0428/awesome-building-layout-generation.",TOPIC
10.26599/JICV.2023.9210039,Development of Deep-Learning-Based Autonomous Agents for Low-Speed Maneuvering in Unity,"This study provides a systematic analysis of the resource-consuming training of deep reinforcement-learning (DRL) agents for simulated low-speed automated driving (AD). In Unity, this study established two case studies: garage parking and navigating an obstacle-dense area. Our analysis involves training a path-planning agent with real-time-only sensor information. This study addresses research questions insufficiently covered in the literature, exploring curriculum learning (CL), agent generalization (knowledge transfer), computation distribution (CPU vs. GPU), and mapless navigation. CL proved necessary for the garage scenario and beneficial for obstacle avoidance. It involved adjustments at different stages, including terminal conditions, environment complexity, and reward function hyperparameters, guided by their evolution in multiple training attempts. Fine-tuning the simulation tick and decision period parameters was crucial for effective training. The abstraction of high-level concepts (e.g., obstacle avoidance) necessitates training the agent in sufficiently complex environments in terms of the number of obstacles. While blogs and forums discuss training machine learning models in Unity, a lack of scientific articles on DRL agents for AD persists. However, since agent development requires considerable training time and difficult procedures, there is a growing need to support such research through scientific means. In addition to our findings, we contribute to the R&D community by providing our environment with open sources.",TOPIC
10.26599/JICV.2023.9210040,Critical Roles of Control Engineering in the Development of Intelligent and Connected Vehicles,"In recent years, advancements in onboard computing hardware and wireless communication technology have remarkably stimulated the development of intelligent and connected vehicles (ICVs). Specifically, some researchers have investigated the issue of employing various advanced control techniques to optimize the performance of autonomous vehicles in practice (Sun et al., 2023; Zhang et al., 2023a, 2023b). Therefore, this article aims to discuss why and how control engineering plays an essential role in the development of ICVs.",TOPIC
10.26599/TST.2021.9010048,Optimizing the Perceptual Quality of Time-Domain Speech Enhancement with Reinforcement Learning,"In neural speech enhancement, a mismatch exists between the training objective, i.e., Mean-Square Error (MSE), and perceptual quality evaluation metrics, i.e., perceptual evaluation of speech quality and short-time objective intelligibility. We propose a novel reinforcement learning algorithm and network architecture, which incorporate a non-differentiable perceptual quality evaluation metric into the objective function using a dynamic filter module. Unlike the traditional dynamic filter implementation that directly generates a convolution kernel, we use a filter generation agent to predict the probability density function of a multivariate Gaussian distribution, from which we sample the convolution kernel. Experimental results show that the proposed reinforcement learning method clearly improves the perceptual quality over other supervised learning methods with the MSE objective function.",TOPIC
10.26599/TST.2024.9010142,"A Review on Air-Ground Coordination in Mobile Edge Computing: Key Technologies, Applications and Future Directions","In recent years, Mobile Edge Computing (MEC) has received extensive research attention due to its characteristics, such as real-time data processing and flexible application deployment. However, traditional MEC server deployment relies on the terrestrial Base Stations (BSs), resulting in high deployment costs and limited coverage range. In response to these challenges, air-ground coordination has emerged, which effectively combines the advantages of edge computing and Unmanned Aerial Vehicles (UAVs), providing an effective architecture for edge intelligence. By utilizing the flexibility of UAVs and empowering them into edge nodes with computing resources, the coverage range of MEC can be expanded, thereby reducing the reliance of edge devices on terrestrial BSs. Furthermore, leveraging terrestrial BSs as supplements to the computing power compensates for relatively limited computational capabilities of UAVs. Although extensive studies have been conducted on air-ground coordination, there are few related summaries of application technologies and prospects. Thus, the key technologies of air-ground coordination and applications are comprehensively reviewed in this paper. Finally, to provide guidance for interested researchers, the development trends and potential applications of air-ground coordination are explored.",TOPIC
10.28945/5194,Journal of Information Technology Education: Research,"Aim/Purpose Our study is focused on prototyping, development, testing, and deployment of a new knowledge primitive for the humanoid robot assistant NAO, in order to enhance student visual learning by establishing a human-robot interaction. Background This new primitive, utilizing a convolutional neural network (CNN), enables real-time recognition of handwritten digits captured by the NAO robot, a hu-manoid robot assistant developed by SoftBank Robotics. It is equipped with ad-vanced capabilities, including a wide range of sensors, cameras, and interactive features. By integrating the proposed primitive, the NAO robot gains the ability to accurately recognize handwritten digits, contributing to improved student visual learning experiences. Methodology Our developed primitive consists of the use of a convolutional neural network (CNN) so that the robot is able to recognize the handwriting of the digits pre-sent in the input image received in real-time. The NAO robot establishes inter-action with the learners through a scenario based on a predefined assignment. In this scenario, NAO captures the digit handwritten by the learner via its cam-era, recognizes the digit using the deep learning model generated by the MNIST dataset, and announces to the learner the handwritten digit in the input image. The prototype is realized using the concept of a distributed system allowing the distribution of tasks in four different computing nodes. Contribution Our research makes a significant contribution by equipping the humanoid robot NAO with a cognitive intelligence system through the integration of a new knowledge primitive based on handwriting digit recognition (HWDR). Our ap-proach used to create and implement this primitive in the NAO robot is inter-esting and innovative, and presents a promising provision for enhancing the vis-ual learning experience of children and young students with special needs, based on the use of distributed systems that divide the work using various compo-nents distributed over several nodes, coordinating their efforts to perform tasks more efficiently than a single device besides the NAO robot. Findings We designed our model using specific parameters and a fully convolutional neu-ral network architecture, which includes three residual depthwise separable con-volutions, each followed by batch normalization and ReLU activation. To evalu-ate the performance of our model, we tested it on the MNIST dataset, where we achieved a remarkable accuracy, F1 score, and recall of 99%. An experiment was conducted to test our implemented primitive and see the effectiveness of this invention for enhancing visual learning in children with special needs. We developed a visual learning strategy based on the creation of engaging activities mediated by the NAO robot in an educational context. The results showed that participants achieved a strong commitment to the NAO robot, appreciating its ability to recognize handwritten digits and highlighting its promising potential to enrich visual learning experiences. Participants expressed a strong preference for teaching methods integrating assistive learning technologies, demonstrating the positive impact of our humanoid assistant robot on improving learning and visual intelligence in an educational environment. Recommendations for Practitioners Encourage creativity and innovation in the field of robotics and special needs. This can lead to new and effective solutions that improve the lives of students with special needs. Recommendations for Researchers Test and evaluate the proposed robotics solutions to ensure they are effective and making a positive impact. Use feedback from users, educators, and parents to refine and improve your solutions. Also, ensure that the robotics solutions are accessible to students with a range of abilities. This may involve designing solutions that are adjustable or providing alternative means of access. Impact on Society As there are several ways to educate, there are multiple forms of learning. With the help of this learning procedure and strategy, the human teacher collaborates with the robot assistance NAO to improve visual learning among students. The findings of this research can serve as an application for the implementation of various pedagogical methods that will assist in meeting the needs of the majority of learners. Future Research Our future research will concentrate on addressing the educational needs of students with special needs, enabling them to overcome their challenges and reach academic excellence in an inclusive environment. To achieve this goal, we plan to leverage the capabilities of social robots, which have emerged as a significant contributor to the field of human-robot interaction, particularly in facilitating inclusive education. These agents have proven to be effective in providing support to students with special needs, thereby enabling them to receive the education they need to succeed. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.29333/ejmste/85036,"Eurasia Journal of Mathematics, Science and Technology Education","The university's computer laboratory is currently one of the most challenging aspects when imparting practical tasks with regards to the education technology (ET) enhancement. This study intends to observe the issues confronted by students while performing tasks in the laboratory in different educational modes. The online survey is conducted using quantitative and qualitative research instruments to evaluate the students' perspectives. This exploratory work has emphasized the practical issues such as an insufficient time constraint, and instruments, geographical needs, financial concerns, and unavailability of subject specialists to cater for relevant issues about a particular course. The sample size was (N= 161) drawn from a stratified sampling method for analysis of four strata. This research addresses these problems in the laboratory with an aim to improve the student's practical skills as well as their investigation-based learning. It is needed for practical based courses, through experimentation with the help of artificial intelligence (AI) paradigms. The design science methodology is adopted, it presents the conception of an Intelligent Virtual Laboratory (IVL) based on pedagogical agent-based cognitive architecture (PACA). This IVL provides the level of excellence of laboratory needs by enhancing the ET which students can efficiently perform practical tasks online at anywhere. The results showed that IVL has a significant model for enhancing the learning to students and recommendations for further research implementation. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.2991/agi.2009.13,,"Inspired by mental imagery, we present results of extending a symbolic cognitive architecture (Soar) with general computational mechanisms to support reasoning with symbolic, quantitative spatial, and visual depictive representations. Our primary goal is to achieve new capabilities by combining and manipulating these representations using specialized processing units specific to a modality but independent of task knowledge. This paper describes the architecture supporting behavior in an environment where perceptual-based thought is inherent to problem solving. Our results show that imagery provides the agent with additional functional capabilities improving its ability to solve rich spatial and visual problems. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.2991/agi.2010.16,,"A software architecture is described which enables a virtual agent in an online virtual world to carry out simple English language interactions grounded in its perceptions and actions. The use of perceptions to guide anaphor resolution is discussed, along with the use of natural language generation to answer simple questions about the observed world. This architecture has been implemented within the larger PetBrain system, which is built on the OpenCog open-source Al software framework and architected based on the OpenCogPrime design for integrative AGI, and has previously been used for nonlinguistic intelligent behaviors such as imitation and reinforcement learning. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.2991/ijcis.2010.3.5.14,International Journal of Computational Intelligence Systems,"This paper presents a novel Intelligent Inference System (IIS) for the determination of an optimum preshape for multifingered robot hand grasping, given object under a manipulation task. The IIS is formed as hybrid agent architecture, by the synthesis of object properties, manipulation task characteristics, grasp space partitioning, low-level kinematical analysis, evaluation of contact wrench patterns via fuzzy approximate reasoning and ANN structure for incremental learning. The IIS is implemented in software with a robot hand simulation. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.2991/ijcis.d.191101.001,International Journal of Computational Intelligence Systems,"A novel accurate and robust metric called II-Learn for measuring the increase of intelligence of a system after a learning process is proposed. We define evolving learning systems, as systems that are able to make at least one measurable evolutionary step by learning. To prove the effectiveness of the metric we performed a case study, using a learning system. The universality of II-Learn is based on the fact that it does not depend on the architecture of the studied system. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.2991/ijndc.2018.6.2.4,International Journal of Networked and Distributed Computing,"Electronic commerce applications have strict timing constraints on the interactions between e-commerce servers and customers. Customers prefer real-time services, which mean immediate response from the server shortly after submission of a request. This trend of demand gives e-commerce servers high pressure, both on the software and the architecture they currently use. In this paper, we propose a real-time architecture for e-commerce servers that addresses the problem efficiently. We adopt a framework that permits the appropriate treatment of dynamic behaviours that are data interdependent, and reasoning about the communication protocols and internal mechanisms of client / server relationships in a real-time multi-agents based e-commerce application architecture. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.30630/joiv.7.3.1323,International Journal on Informatics Visualization,"There has been an increased reliance on interconnected Cyber-Physical Systems (CPS) applications. This reliance has caused tremendous growth in high assurance challenges. Due to the functional interdependence between the internal systems of CPS applications, the utilities' ability to reliably provide services could be disrupted if security threats are not addressed. To address this challenge, we propose a multi-level, multi-agent detection and response architecture built on the formalisms of Hidden Markov Models (HMM) and Markov Decision Processes (MDP). We have evaluated the performance of the proposed architecture on one of the critical smart grid applications, Advanced Metering Infrastructure (AMI). This paper utilizes a simulation tool called SecAMI for performance evaluation. A Stealthy attack scenario contains multiple distinct multi-stage attacks deployed concurrently in a network to compromise the system and stop several critical services in a CPS. The results show that the proposed architecture effectively detects and responds to stealthy attack scenarios against Cyber-Physical Systems. In particular, the simulation results show that the proposed system can preserve the availability of more than 93% of the AMI network under stealthy attacks. A future study may evaluate the effectiveness of various stealthy attack strategies and detection and response systems. The high availability of any AMI should be protected against new attack techniques. The proposed system will also determine a distributed IDS's efficient placement for intrusion detection sensors and response nodes within an AMI. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.30837/ITSSI.2022.21.051,Innovative Technologies and Scientific Solutions for Industries,"The subject of the research is the investment attractiveness of enterprises producing competitive products with modern component architecture. The aim of the article is to develop complex methods for research of investment attractiveness of projects on creation of new high-tech products with component architecture. Tasks to be solved are: to use component method for the analysis of innovativeness of created high-tech products; to study investment attractiveness of an innovation project with the use of expert assessments and the method of planning experiments; to substantiate the composition of a diversification project portfolio for investment taking into account the limited possibilities of the enterprise based on the method of integer optimization; to study the performance of the project portfolio using agent-based imitational modeling. Methods used are: system analysis, component design, multi-criteria optimization, expert assessment and agent-based simulation modeling in the form of applied information technology. The results have been obtained: the analysis of investment attractiveness of projects on creation of new high-tech products with component architecture is carried out. The architecture of a complex product built with components from previous positive development experience is investigated. A classification of possible components in the architecture of a complex product is created. A set of indicators for assessing the investment attractiveness of an innovative component-based product is formed. The qualitative assessments of experts for the main indicators of the component composition of the product in the form of linguistic variables are proposed. The use of multifactor experiment to assess the investment attractiveness of a project to create a complex product with a component-based architecture is proposed. An optimization model for selecting the rational composition of components in an innovative product is developed. An agent-based simulation model is built to study the performance of work on the preparation of production of innovative products on a component basis. Conclusions: The use of a set of developed methods and applied information technology for the creation of high-tech products with component-based architecture allows you to plan a diversification portfolio of projects with investment attractiveness and competitiveness of products. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.30837/ITSSI.2023.26.095,Innovative Technologies and Scientific Solutions for Industries,"The subject of the article is the role of ontological systems in improving the processes of structuring and analyzing scientific content, especially in the context of STEM education. The goal of the work is to research and analyze the application of ontological systems in the context of managing educational materials in STEM education. The use of such approaches is focused on developing effective methods for structuring and presenting educational knowledge in the STEM education system, emphasizing the importance of integrating different scientific disciplines to optimize the educational process. In accordance with the purpose, the following tasks were set: to develop a methodology for creating and implementing ontological systems in STEM education and to develop the architecture of a virtual STEM center that would provide the implementation of the proposed principles. The research is based on the following methods: For the development of the architecture of the virtual STEM center, we used UML diagrams. We developed UML diagrams of roles and activities that illustrate the interaction of different users and systems, as well as demonstrate work processes and interactions in multi-agent systems. Special attention is paid to activity diagrams, which reflect the processing of user requests and the interaction of the stemua.science agent with other components of the STEM center. The following results were obtained: A modular system architecture of the virtual STEM center was developed and described using UML diagrams, which includes roles such as the STEM center administrator, editor, author, and user, as well as the administrator of the CIT ""Polyhedron"". The interaction of these roles with the virtual STEM center is described in detail, revealing the mechanisms of their interaction and joint work aimed at creating, filling, and editing content in the transdisciplinary STEM center. The process of optimizing work processes in the modular system of the virtual STEM center is also considered. Ways to fill and use the T-STEM center in an ontological form have been identified. The interaction of software entities of the T-STEM center in an ontological form has been analyzed. Conclusions: Based on the conducted research, it is concluded that the use of ontological systems in the context of managing educational materials in STEM education is an effective method for structuring and presenting scientific content, promoting the integration of various scientific disciplines, and optimizing the learning process. It is determined that ontological systems are an effective method for structuring and presenting scientific content, facilitating the integration of various scientific disciplines, and optimizing the learning process. The modular architecture of the system is found to facilitate efficient interaction among different roles and automate workflow processes. Integration with a multi-agent system allows for the use of external data sources and ensures interoperability with other systems. For the further development of the system, research is needed to enhance the efficiency of role interactions and workflow automation. Additionally, research on integrating the system with other STEM education systems is necessary. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3103/S1060992X23060103,Optical Memory and Neural Networks (Information Optics),"Abstract: We present an analysis of a self-supervised learning approach for monocular depth and ego-motion estimation. This is an important problem for computer vision systems of robots, autonomous vehicles and other intelligent agents, equipped only with monocular camera sensor. We have explored a number of neural network architectures that perform single-frame depth and multi-frame camera pose predictions to minimize photometric error between consecutive frames on a sequence of camera images. Unlike other existing works, our proposed approach called ERF-SfMLearner examines the influence of the deep neural network receptive field on the performance of depth and ego-motion estimation. To do this, we study the modification of network layers with two convolution operators with extended receptive field: dilated and deformable convolutions. We demonstrate on the KITTI dataset that increasing the receptive field leads to better metrics and lower errors both in terms of depth and ego-motion estimation. Code is publicly available at github.com/linukc/ERF-SfMLearner. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.31127/tuje.1581124,Turkish Journal of Engineering,"Advances in image processing and techniques in artificial intelligence have made it possible for computers to see and learn. This article introduced a technology that has utilised MobilenetV2 Deep Convolution Neural Network architecture to automatically identify and diagnose plant diseases from images. The identification and classification of plant diseases are now carried out by only human experts-crop extension agents, and farmers, expensive labour that is prone to mistakes. This study relies on dataset gathering as a technique of classifying and identifying plant diseases. It is a multistep process involving pre-process data on the raw set, mask green area of the leaf, remove green section, convert to grayscale and then obtain some characteristics, select, and classify with regard to disease management, etc. Two different types of plants, maize and potato, have been taken in consideration to show effectiveness of the outcome of the proposed model. The confusion matrix and classification performance report were used to evaluate the system. The dataset for potato and maize comprised 6228 and 6878 images, respectively, of leaves. Precise, recall, and F1-scores of 95.15%, 94.76%, and 94.93% were recorded as a cumulative performance across the datasets of potato and maize respectively. This translates to its resistance in picking most diseases for these crops, making it a resource that can be used with confidence in agriculture disease detection. The MobileNetV2 model performs well in both crops, especially for potato early blight and maize common rust. Lower performance in recognizing healthy potato leaves suggests that the feature space of healthy and diseased leaves may overlap. The MobileNetV2 model performed a robust ability in general in the detection of most diseases affecting both potato and maize leaves, but some specific areas need to be targeted for further enhancement. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3130/jaabe.17.401,Journal of Asian Architecture and Building Engineering,"This article explores how idealized architectural plans are negotiated in relation to the practical concerns and socio-cultural conditions of modern and contemporary Korea. As a case study, it focuses on analyzing the masterplans of Yonsei University, one of the key universities that illustrate the architectural modernity of Korea, as well as reflecting the continual interactions between different agents of power within and outside the country. Particular attention is given to the evolution of the university's masterplans at four different points in time: the plans proposed in 1917, 1925, 1957, and 1970 respectively, all of which are compared to the 2016 map. The 1917 plan is a product made by an American architect—Henry K. Murphy—who proposed a design without visiting the site. Such a process lacking tactile engagement resulted in generating an overly western-style and also an 'ideal' plan that does not adequately respond to actual site conditions. While the 1925 and 1957 plans are updated versions that are based on Murphy's site visits, they still seem idealized to a great degree. It is rather the last two maps—1970 and 2016 plans—where one can detect how they manifest themselves for the changing conditions of modern and contemporary Korea; a number of those working at the university participated in the design process, which focused on generating more realistic strategies in response to South Korea's 'compressed modernity'. Our in-depth visual analysis of the Yonsei masterplans shows how idealized plans are negotiated and reworked, thereby reflecting realistic demands for university life in material ways. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.3141/2343-09,Transportation Research Record,"A multimodeling approach to large-scale, activity-based, multiagent simulation of travel demand is introduced. MATSIM is a full activity-based transport simulation. Its greatest current performance limitation is the network loading simulation, currently a queue simulation (QSim). QSim is iteratively executed for the entire agent population for evaluating the effects of random mutations on the activity plans of a fraction of the population. After each QSim, poorly performing plans are discarded, good plans are kept, and the agents slowly learn what works best for their individual activity needs. In the application presented, the system periodically replaces QSim for a number of iterations with a simplified pseudosimulation that runs approximately two orders of magnitude faster. The pseudosimulation uses travel time information from the preceding QSim iteration to estimate how well an agent day plan might perform. Repeated iterations of the pseudosimulation produce better-performing plans in a short time. These plans are passed to the QSim for updating of network travel time information, and the process repeats. The technique is tested in a scenario for Zurich, Switzerland, and incorporates mode choice, road pricing, secondary activity location choice, activity timing adjustment, and dynamic routing. The technique dramatically improves convergence rates for such complex, large-scale simulations and fully exploits modern multicore computer architectures. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.31436/IIUMEJ.V23I1.1807,IIUM Engineering Journal,"Deep reinforcement learning usage in creating intelligent agents for various tasks has shown outstanding performance, particularly the Q-Learning algorithm. Deep Q-Network (DQN) is a reinforcement learning algorithm that combines the Q-Learning algorithm and deep neural networks as an approximator function. In the single-agent environment, the DQN model successfully surpasses human ability several times over. Still, when there are other agents in the environment, DQN may experience decreased performance. This research evaluated a DQN agent to play in the two-player traditional board game of Surakarta Chess. One of the drawbacks that we found when using DQN in two-player games is its consistency. The agent will experience performance degradation when facing different opponents. This research shows Dueling Deep Q-Network usage with increasing batch size can improve the agent's performance consistency. Our agent trained against a rule-based agent that acts based on the Surakarta Chess positional properties and was then evaluated using different rule-based agents. The best agent used Dueling DQN architecture with increasing batch size that produced a 57% average win rate against ten different agents after training for a short period © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3182/20130619-3-RU-3018.00303,IFAC-PapersOnLine,"Today enterprises are organized in networks of several distributed production sites in a geographical area more and more extended, where sites use the intermediary products of other sites to manufacture the final products. Therefore they transport raw materials and intermediate products between plants for manufacturing. Additionally these enterprises have to distribute their final products to far away consumers. In this context, it is difficult and not cost effective for these enterprises to manage their own transport vehicles. Thus they outsource their transportation tasks to third party logistics enterprises. These enterprises group transport orders of multiple enterprises together in order to reduce cost and travels number. The objective of this paper is to present a distributed architecture planning of transportation activities aimed at better utilize transport resources by grouping several orders of transport for each effective displacement. © IFAC. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.3233/AIC-2009-0442,AI Communications,"In competitive domains, some knowledge about the opponent can give players a clear advantage. This idea led many people to propose approaches that automatically acquire models of opponents, based only on the observation of their input-output behavior. If opponent outputs could be accessed directly, a model can be constructed by feeding a machine learning method with traces of the behavior of the opponent. However, that is not the case in the RoboCup domain where an agent does not have direct access to the opponent inputs and outputs. Rather, the agent sees the opponent behavior from its own point of view and inputs and outputs (actions) have to be inferred from observation. In this paper, we present an approach to model low-level behavior of individual opponent agents. First, we build a classifier to infer and label opponent actions based on observation. Second, our agent observes an opponent and labels its actions using the previous classifier. From these observations, machine learning techniques generate a model that predicts the opponent actions. Finally, the agent uses the model to anticipate opponent actions. In order to test our ideas, we have created an architecture called OMBO (Opponent Modeling Based on Observation). Using OMBO, a striker agent can anticipate goalie actions. Results show that in this striker-goalie scenario, scores are significantly higher using the acquired opponent's model of actions. © 2009 Elsevier B.V., All rights reserved.",TOPIC
10.3233/AIS-220482,Journal of Ambient Intelligence and Smart Environments,"Over the last fifty years, societies across the world have experienced multiple periods of energy insufficiency with the most recent one being the 2022 global energy crisis. In addition, the electric power industry has been experiencing a steady increase in electricity consumption since the second industrial revolution because of the widespread usage of electrical appliances and devices. Newer devices are equipped with sensors and actuators, they can collect a large amount of data that could help in power management. However, current energy management approaches are mostly applied to limited types of devices in specific domains and are difficult to implement in other scenarios. They fail when it comes to their level of autonomy, flexibility, and genericity. To address these shortcomings, we present, in this paper, an automated energy management approach for connected environments based on generating power estimation models, representing a formal description of energy-related knowledge, and using reinforcement learning (RL) techniques to accomplish energy-efficient actions. The architecture of this approach is based on three main components: power estimation models, knowledge base, and intelligence module. Furthermore, we develop algorithms that exploit knowledge from both the power estimator and the ontology, to generate the corresponding RL agent and environment. We also present different reward functions based on user preferences and power consumption. We illustrate our proposal in the smart home domain. An implementation of the approach is developed and two validation experiments are conducted. Both case studies are deployed in the context of smart homes: (a) a living room with a variety of devices and (b) a smart home with a heating system. The obtained results show that our approach performs well given the low convergence period, the high level of user preferences satisfaction, and the significant decrease in energy consumption. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3233/ATDE231265,Advances in Transdisciplinary Engineering,"In traditional teaching, teachers and students conduct real-time teaching face-to-face, while the efficiency of teacher-student interaction is low. To address this issue, this article proposes an intelligent teaching interaction system based on MAS. We have conducted a demand and feasibility analysis of teaching interaction applications based on artificial intelligence, and established the basic architecture of the teaching interaction system. Then, the key interactive modules are implemented with the Multi Agent concept, and a communication model based on SOAP is implemented using Web Service technology. To meet the needs of the system, a grouping strategy based on learners' learning objectives is also proposed to allocate personalized tasks to individuals with different knowledge sets. Finally, the composition, module division, and implementation method of a web-based and MAS based online teaching system are provided and tested. The testing results show that our scheme improves the openness and knowledge scalability of the system, achieves communication between multiple agents in the system, and provides learners with a more convenient and efficient interactive learning environment. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3233/FAIA230343,Frontiers in Artificial Intelligence and Applications,"The capability of continuously learning new skills via a sequence of pre-collected offline datasets is desired for an agent. However, consecutively learning a sequence of offline tasks likely leads to the catastrophic forgetting issue under resource-limited scenarios. In this paper, we formulate a new setting, continual offline reinforcement learning (CORL), where an agent learns a sequence of offline reinforcement learning tasks and pursues good performance on all learned tasks with a small replay buffer without exploring any of the environments of all the sequential tasks. For consistently learning on all sequential tasks, an agent requires acquiring new knowledge and meanwhile preserving old knowledge in an offline manner. To this end, we introduced continual learning algorithms and experimentally found experience replay (ER) to be the most suitable algorithm for the CORL problem. However, we observe that introducing ER into CORL encounters a new distribution shift problem: the mismatch between the experiences in the replay buffer and trajectories from the learned policy. To address such an issue, we propose a new model-based experience selection (MBES) scheme to build the replay buffer, where a transition model is learned to approximate the state distribution. This model is used to bridge the distribution bias between the replay buffer and the learned model by filtering the data from offline data that most closely resembles the learned model for storage. Moreover, in order to enhance the ability on learning new tasks, we retrofit the experience replay method with a new dual behavior cloning (DBC) architecture to avoid the disturbance of behavior-cloning loss on the Q-learning process. In general, we call our algorithm offline experience replay (OER). Extensive experiments demonstrate that our OER method outperforms SOTA baselines in widely-used Mujoco environments. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3233/FAIA230359,Frontiers in Artificial Intelligence and Applications,"The Vision Transformer architecture has shown to be competitive in the computer vision (CV) space where it has dethroned convolution-based networks in several benchmarks. Nevertheless, convolutional neural networks (CNN) remain the preferential architecture for the representation module in reinforcement learning. In this work, we study pretraining a Vision Transformer using several state-of-the-art self-supervised methods and assess the quality of the learned representations. To show the importance of the temporal dimension in this context we propose an extension of VICReg to better capture temporal relations between observations by adding a temporal order verification task. Our results show that all methods are effective in learning useful representations and avoiding representational collapse for observations from the Atari Learning Environment (ALE) which leads to improvements in data efficiency when we evaluated in reinforcement learning (RL). Moreover, the encoder pretrained with the temporal order verification task shows the best results across all experiments, with richer representations, more focused attention maps and sparser representation vectors throughout the layers of the encoder, which shows the importance of exploring such similarity dimension. With this work, we hope to provide some insights into the representations learned by ViT during a self-supervised pretraining with observations from RL environments and to understand which properties arise in the representations that lead to the best-performing agents. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3233/FAIA230551,Frontiers in Artificial Intelligence and Applications,"Evolutionary reinforcement learning (ERL) algorithms recently raise attention in tackling complex reinforcement learning (RL) problems due to high parallelism, while they are prone to insufficient exploration or model collapse without carefully tuning hyperparameters (aka meta-parameters). In the paper, we propose a general meta ERL framework via bilevel optimization (BiERL) to jointly update hyperparameters in parallel to training the ERL model within a single agent, which relieves the need for prior domain knowledge or costly optimization procedure before model deployment. We design an elegant meta-level architecture that embeds the inner-level's evolving experience into an informative population representation and introduce a simple and feasible evaluation of the meta-level fitness function to facilitate learning efficiency. We perform extensive experiments in MuJoCo and Box2D tasks to verify that as a general framework, BiERL outperforms various baselines and consistently improves the learning performance for a diversity of ERL algorithms. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3233/FAIA240812,Frontiers in Artificial Intelligence and Applications,"Efficiently learning unsupervised pixel-wise visual representations is crucial for training agents that can perceive their environment without relying on heavy human supervision or abundant annotated data. Motivated by recent work that promotes motion as a key source of information in representation learning, we propose a novel instance of contrastive criterions over time and space. In our architecture, pixel-wise motion field and representations are extracted by neural models, trained from scratch in an integrated fashion. Learning proceeds online over time, exploiting also a momentum-based moving average to update the feature extractor, without replaying any large buffers of past data. Experiments on real-world videos and on a recently introduced benchmark, with photorealistic streams generated from a 3D environment, confirm that the proposed model can learn to estimate motion and jointly develop representations. Our model nicely encodes the variable appearance of the visual information in space and time, significantly overcoming a recent approach and it also compares favourably with convolutional and Transformer-based networks, offline-pre-trained on large collections of supervised and unsupervised images. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3233/ICA-2010-0332,Integrated Computer-Aided Engineering,"The exchange of CO<inf>2</inf> between the atmosphere and the ocean surface is a problem that has become increasingly important due to its impact on climatic behavior. Given the large quantity of sources of information available for studying the CO<inf>2</inf> problem, it is necessary to provide innovative solutions that facilitate the automation of certain tasks and incorporate decision support systems to obtain a better understanding of this phenomenon. This paper presents a multiagent architecture aimed at providing solutions for monitoring the interaction between the atmosphere and the ocean. The ocean surface and the atmosphere exchange carbon dioxide. This process is can be modeled by a multiagent system with advanced learning and adaption capabilities. The proposed multiagent architecture incorporates CBR-agents that integrate novel strategies that both monitor the parameters that affect the interaction, and facilitate the creation of models. The system was tested and this paper presents the results obtained. © 2010 IOS Press and the author(s). © 2010 Elsevier B.V., All rights reserved.",TOPIC
10.3233/JID-221009,Journal of Integrated Design and Process Science,"Design and manufacturing sectors are vital agents of an economy. However, multiple challenges influence product designs such as the predicted scarcity of energy and primary materials, the ubiquitous integration of electronic components and computing science in systems' architectures, the pervasive production of data by most systems, the emphasis given to CO2 free energy solutions, recycling, and reuse, the transformation of the consumption model from product ownership to product as a service, as well as the geopolitical conflicts. Major technological advancements leading to transformation in socio-economic practices would be required to address these challenges which can have a profound effect on design and manufacturing activities. This research aims to evaluate the potential impact and modification induced by such transformations on product design process. The research identifies that early design automation can enable coping with unmanageable cognitive load generated by cascading changes. A list of modifications to current design practices is proposed to enable the development of a new generation of design tools. The article provides an initial prospective effort to discuss the potential services and functionality that will be offered by future design tools'. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3233/SHTI220761,Studies in Health Technology and Informatics,"In the EU project FAIR4Health, a ETL pipeline for the FAIRification of structured health data as well as an agent-based, distributed query platform for the analysis of research hypotheses and the training of machine learning models were developed. The system has been successfully tested in two clinical use cases with patient data from five university hospitals. Currently, the solution is also being considered for use in other hospitals. However, configuring the system and deploying it in the local IT architecture is non-trivial and meets with understandable concerns about security. This paper presents a model for describing the information architecture based on a formal approach, the 3LGM metamodel. The model was evaluated by the developers. As a result, the clear separation of tasks and the software components that implement them as well as the rich description of interactions via interfaces were positively emphasized. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3233/SW-160224,Semantic Web,"Ontology-driven systems with reasoning capabilities in the legal field are now better understood. Legal concepts are not discrete, but make up a dynamic continuum between common sense terms, specific technical use, and professional knowledge, in an evolving institutional reality. Thus, the tension between a plural understanding of regulations and a more general understanding of law is bringing into view a new landscape in which general legal frameworks -grounded in well-known legal theories stemming from 20th-century c. legal positivism or sociological jurisprudence -are made compatible with specific forms of rights management on the Web. In this sense, Semantic Web tools are not only being designed for information retrieval, classification, clustering, and knowledge management. They can also be understood as regulatory tools, i.e. as components of the contemporary legal architecture, to be used by multiple stakeholders -front-line practitioners, policymakers, legal drafters, companies, market agents, and citizens. That is the issue broadly addressed in this Special Issue on the Semantic Web for the Legal Domain, overviewing the work carried out over the last fifteen years, and seeking to foster new research in this field, beyond the state of the art. © 2016 Elsevier B.V., All rights reserved.",TOPIC
10.32473/flairs.36.133195,"Proceedings of the International Florida Artificial Intelligence Research Society Conference, FLAIRS","This paper describes a discussion-bot that provides answers to students’ questions about the Data Science master program at the University of Lyon 1. Based on a seq2seq architecture combined with a supervised memory module, the bot identifies the questioner’s interest and encodes relevant information from the past conversation to provide personalized answers. A dialogue generator based on hand-crafted dialogues was built to train our model on these synthetic dialogues. The agent and its memory are adaptable to another context by modifying the intention database of the generator. The model was deployed and the results show that the discussion-bot meets most students’ learning requests. We discuss further directions that might be taken to increase the model’s effectivenes. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.32604/cmc.2022.028285,"Computers, Materials and Continua","The advent of the latest technologies like the Internet of things (IoT) transforms the world from a manual to an automated way of lifestyle. Meanwhile, IoT sector open numerous security challenges. In traditional networks, intrusion detection and prevention systems (IDPS) have been the key player in the market to ensure security. The challenges to the conventional IDPS are implementation cost, computing power, processing delay, and scalability. Further, online machine learning model training has been an issue. All these challenges still question the IoT network security. There has been a lot of research for IoT based detection systems to secure the IoT devices such as centralized and distributed architecture-based detection systems. The centralized system has issues like a single point of failure and load balancing while distributed system design has scalability and heterogeneity hassles. In this study, we design and develop an agent-based hybrid prevention system based on software-defined networking (SDN) technology. The system uses lite weight agents with the ability to scaleup for bigger networks and is feasible for heterogeneous IoT devices. The baseline profile for the IoT devices has been developed by analyzing network flows from all the IoT devices. This profile helps in extracting IoT device features. These features help in the development of our dataset that we use for anomaly detection. For anomaly detection, support vector machine has been used to detect internet control message protocol (ICMP) flood and transmission control protocol synchronize (TCP SYN) flood attacks. The proposed system based on machine learning model is fully capable of online and offline training. Other than detection accuracy, the system can fullymitigate the attacks using the software-defined technology SDN technology. The major goal of the research is to analyze the accuracy of the hybrid agent-based intrusion detection systems as compared to conventional centralized only solutions, especially under the flood attack conditions generated by the distributed denial of service (DDoS) attacks. The system shows 97% to 99% accuracy in simulated results with no false-positive alarm. Also, the system shows notable improvement in terms of resource utilization and performance under attack scenarios. The R-IDPS is scalable, and the system is suitable for heterogeneous IoT devices and networks. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.32604/cmc.2023.035126,"Computers, Materials and Continua","Concept drift is a main security issue that has to be resolved since it presents a significant barrier to the deployment of machine learning (ML) models. Due to attackers’ (and/or benign equivalents’) dynamic behavior changes, testing data distribution frequently diverges from original training data over time, resulting in substantial model failures. Due to their dispersed and dynamic nature, distributed denial-of-service attacks pose a danger to cybersecurity, resulting in attacks with serious consequences for users and businesses. This paper proposes a novel design for concept drift analysis and detection of malware attacks like Distributed Denial of Service (DDOS) in the network. The goal of this architecture combination is to accurately represent data and create an effective cyber security prediction agent. The intrusion detection system and concept drift of the network has been analyzed using secure adaptive windowing with website data authentication protocol (SAW_WDA). The network has been analyzed by authentication protocol to avoid malware attacks. The data of network users will be collected and classified using multilayer perceptron gradient decision tree (MLPGDT) classifiers. Based on the classification output, the decision for the detection of attackers and authorized users will be identified. The experimental results show output based on intrusion detection and concept drift analysis systems in terms of throughput, end-end delay, network security, network concept drift, and results based on classification with regard to accuracy, memory, and precision and F-1 score. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.32604/cmc.2023.040068,"Computers, Materials and Continua","Mobile-edge computing (MEC) is a promising technology for the fifth-generation (5G) and sixth-generation (6G) architectures, which provides resourceful computing capabilities for Internet of Things (IoT) devices, such as virtual reality, mobile devices, and smart cities. In general, these IoT applications always bring higher energy consumption than traditional applications, which are usually energy-constrained. To provide persistent energy, many references have studied the offloading problem to save energy consumption. However, the dynamic environment dramatically increases the optimization difficulty of the offloading decision. In this paper, we aim to minimize the energy consumption of the entire MEC system under the latency constraint by fully considering the dynamic environment. Under Markov games, we propose a multi-agent deep reinforcement learning approach based on the bi-level actor-critic learning structure to jointly optimize the offloading decision and resource allocation, which can solve the combinatorial optimization problem using an asymmetric method and compute the Stackelberg equilibrium as a better convergence point than Nash equilibrium in terms of Pareto superiority. Our method can better adapt to a dynamic environment during the data transmission than the single-agent strategy and can effectively tackle the coordination problem in the multi-agent environment. The simulation results show that the proposed method could decrease the total computational overhead by 17.8% compared to the actor-critic-based method and reduce the total computational overhead by 31.3%, 36.5%, and 44.7% compared with random offloading, all local execution, and all offloading execution, respectively. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.32604/cmc.2024.051307,"Computers, Materials and Continua","The management of network intelligence in Beyond 5G (B5G) networks encompasses the complex challenges of scalability, dynamicity, interoperability, privacy, and security. These are essential steps towards achieving the realization of truly ubiquitous Artificial Intelligence (AI)-based analytics, empowering seamless integration across the entire Continuum (Edge, Fog, Core, Cloud). This paper introduces a Federated Network Intelligence Orchestration approach aimed at scalable and automated Federated Learning (FL)-based anomaly detection in B5G networks. By leveraging a horizontal Federated learning approach based on the FedAvg aggregation algorithm, which employs a deep autoencoder model trained on non-anomalous traffic samples to recognize normal behavior, the system orchestrates network intelligence to detect and prevent cyber-attacks. Integrated into a B5G Zero-touch Service Management (ZSM) aligned Security Framework, the proposal utilizes multi-domain and multi-tenant orchestration to automate and scale the deployment of FL-agents and AI-based anomaly detectors, enhancing reaction capabilities against cyber-attacks. The proposed FL architecture can be dynamically deployed across the B5G Continuum, utilizing a hierarchy of Network Intelligence orchestrators for real-time anomaly and security threat handling. Implementation includes FL enforcement operations for interoperability and extensibility, enabling dynamic deployment, configuration, and reconfiguration on demand. Performance validation of the proposed solution was conducted through dynamic orchestration, FL, and real-time anomaly detection processes using a practical test environment. Analysis of key performance metrics, leveraging the 5G-NIDD dataset, demonstrates the system’s capability for automatic and near real-time handling of anomalies and attacks, including real-time network monitoring and countermeasure implementation for mitigation. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.32604/cmc.2024.053079,"Computers, Materials and Continua","Large-scale indoor 3D reconstruction with multiple robots faces challenges in core enabling technologies. This work contributes to a framework addressing localization, coordination, and vision processing for multi-agent reconstruction. A system architecture fusing visible light positioning, multi-agent path finding via reinforcement learning, and 360° camera techniques for 3D reconstruction is proposed. Our visible light positioning algorithm leverages existing lighting for centimeter-level localization without additional infrastructure. Meanwhile, a decentralized reinforcement learning approach is developed to solve the multi-agent path finding problem, with communications among agents optimized. Our 3D reconstruction pipeline utilizes equirectangular projection from 360° cameras to facilitate depth-independent reconstruction from posed monocular images using neural networks. Experimental validation demonstrates centimeter-level indoor navigation and 3D scene reconstruction capabilities of our framework. The challenges and limitations stemming from the above enabling technologies are discussed at the end of each corresponding section. In summary, this research advances fundamental techniques for multi-robot indoor 3D modeling, contributing to automated, data-driven applications through coordinated robot navigation, perception, and modeling. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.32604/cmc.2024.056823,"Computers, Materials and Continua","In the evolving landscape of the smart grid (SG), the integration of non-organic multiple access (NOMA) technology has emerged as a pivotal strategy for enhancing spectral efficiency and energy management. However, the open nature of wireless channels in SG raises significant concerns regarding the confidentiality of critical control messages, especially when broadcasted from a neighborhood gateway (NG) to smart meters (SMs). This paper introduces a novel approach based on reinforcement learning (RL) to fortify the performance of secrecy. Motivated by the need for efficient and effective training of the fully connected layers in the RL network, we employ an improved chimp optimization algorithm (IChOA) to update the parameters of the RL. By integrating the IChOA into the training process, the RL agent is expected to learn more robust policies faster and with better convergence properties compared to standard optimization algorithms. This can lead to improved performance in complex SG environments, where the agent must make decisions that enhance the security and efficiency of the network. We compared the performance of our proposed method (IChOA-RL) with several state-of-the-art machine learning (ML) algorithms, including recurrent neural network (RNN), long short-term memory (LSTM), K-nearest neighbors (KNN), support vector machine (SVM), improved crow search algorithm (I-CSA), and grey wolf optimizer (GWO). Extensive simulations demonstrate the efficacy of our approach compared to the related works, showcasing significant improvements in secrecy capacity rates under various network conditions. The proposed IChOA-RL exhibits superior performance compared to other algorithms in various aspects, including the scalability of the NOMA communication system, accuracy, coefficient of determination (R2), root mean square error (RMSE), and convergence trend. For our dataset, the IChOA-RL architecture achieved coefficient of determination of 95.77% and accuracy of 97.41% in validation dataset. This was accompanied by the lowest RMSE (0.95), indicating very precise predictions with minimal error. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.32604/cmc.2025.062980,"Computers, Materials and Continua","The knapsack problem is a classical combinatorial optimization problem widely encountered in areas such as logistics, resource allocation, and portfolio optimization. Traditional methods, including dynamic programming (DP) and greedy algorithms, have been effective in solving small problem instances but often struggle with scalability and efficiency as the problem size increases. DP, for instance, has exponential time complexity and can become computationally prohibitive for large problem instances. On the other hand, greedy algorithms offer faster solutions but may not always yield the optimal results, especially when the problem involves complex constraints or large numbers of items. This paper introduces a novel reinforcement learning (RL) approach to solve the knapsack problem by enhancing the state representation within the learning environment. We propose a representation where item weights and volumes are expressed as ratios relative to the knapsack’s capacity, and item values are normalized to represent their percentage of the total value across all items. This novel state modification leads to a 5% improvement in accuracy compared to the state-of-the-art RL-based algorithms, while significantly reducing execution time. Our RL-based method outperforms DP by over 9000 times in terms of speed, making it highly scalable for larger problem instances. Furthermore, we improve the performance of the RL model by incorporating Noisy layers into the neural network architecture. The addition of Noisy layers enhances the exploration capabilities of the agent, resulting in an additional accuracy boost of 0.2%–0.5%. The results demonstrate that our approach not only outperforms existing RL techniques, such as the Transformer model in terms of accuracy, but also provides a substantial improvement than DP in computational efficiency. This combination of enhanced accuracy and speed presents a promising solution for tackling large-scale optimization problems in real-world applications, where both precision and time are critical factors. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.32604/cmc.2025.063206,"Computers, Materials and Continua","The 3GPP standard defines the requirements for next-generation wireless networks, with particular attention to Ultra-Reliable Low-Latency Communications (URLLC), critical for applications such as Unmanned Aerial Vehicles (UAVs). In this context, Non-Orthogonal Multiple Access (NOMA) has emerged as a promising technique to improve spectrum efficiency and user fairness by allowing multiple users to share the same frequency resources. However, optimizing key parameters–such as beamforming, rate allocation, and UAV trajectory–presents significant challenges due to the nonconvex nature of the problem, especially under stringent URLLC constraints. This paper proposes an advanced deep learning-driven approach to address the resulting complex optimization challenges. We formulate a downlink multiuser UAV, Rate-Splitting Multiple Access (RSMA), and Multiple Input Multiple Output (MIMO) system aimed at maximizing the achievable rate under stringent constraints, including URLLC quality-of-service (QoS), power budgets, rate allocations, and UAV trajectory limitations. Due to the highly nonconvex nature of the optimization problem, we introduce a novel distributed deep reinforcement learning (DRL) framework based on dual-agent deep deterministic policy gradient (DA-DDPG). The proposed framework leverages inception-inspired and deep unfolding architectures to improve feature extraction and convergence in beamforming and rate allocation. For UAV trajectory optimization, we design a dedicated actor-critic agent using a fully connected deep neural network (DNN), further enhanced through incremental learning. Simulation results validate the effectiveness of our approach, demonstrating significant performance gains over existing methods and confirming its potential for real-time URLLC in next-generation UAV communication networks. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.32604/cmc.2025.065465,"Computers, Materials and Continua","Edge computing has transformed smart grids by lowering latency, reducing network congestion, and enabling real-time decision-making. Nevertheless, devising an optimal task-offloading strategy remains challenging, as it must jointly minimise energy consumption and response time under fluctuating workloads and volatile network conditions. We cast the offloading problem as a Markov Decision Process (MDP) and solve it with Deep Reinforcement Learning (DRL). Specifically, we present a three-tier architecture—end devices, edge nodes, and a cloud server—and enhance Proximal Policy Optimization (PPO) to learn adaptive, energy-aware policies. A Convolutional Neural Network (CNN) extracts high-level features from system states, enabling the agent to respond continually to changing conditions. Extensive simulations show that the proposed method reduces task latency and energy consumption far more than several baseline algorithms, thereby improving overall system performance. These results demonstrate the effectiveness and robustness of the framework for real-time task offloading in dynamic smart-grid environments. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.32604/cmc.2025.066428,"Computers, Materials and Continua","Next-generation 6G networks seek to provide ultra-reliable and low-latency communications, necessitating network designs that are intelligent and adaptable. Network slicing has developed as an effective option for resource separation and service-level differentiation inside virtualized infrastructures. Nonetheless, sustaining elevated Quality of Service (QoS) in dynamic, resource-limited systems poses significant hurdles. This study introduces an innovative packet-based proactive end-to-end (ETE) resource management system that facilitates network slicing with improved resilience and proactivity. To get around the drawbacks of conventional reactive systems, we develop a cost-efficient slice provisioning architecture that takes into account limits on radio, processing, and transmission resources. The optimization issue is non-convex, NP-hard, and requires online resolution in a dynamic setting. We offer a hybrid solution that integrates an advanced Deep Reinforcement Learning (DRL) methodology with an Improved Manta-Ray Foraging Optimization (ImpMRFO) algorithm. The ImpMRFO utilizes Chebyshev chaotic mapping for the formation of a varied starting population and incorporates Lévy flight-based stochastic movement to avert premature convergence, hence facilitating improved exploration-exploitation trade-offs. The DRL model perpetually acquires optimum provisioning strategies via agent-environment interactions, whereas the ImpMRFO enhances policy performance for effective slice provisioning. The solution, developed in Python, is evaluated across several 6G slicing scenarios that include varied QoS profiles and traffic requirements. The DRL model perpetually acquires optimum provisioning methods via agent-environment interactions, while the ImpMRFO enhances policy performance for effective slice provisioning. The solution, developed in Python, is evaluated across several 6G slicing scenarios that include varied QoS profiles and traffic requirements. Experimental findings reveal that the proactive ETE system outperforms DRL models and non-resilient provisioning techniques. Our technique increases PSSRr, decreases average latency, and optimizes resource use. These results demonstrate that the hybrid architecture for robust, real-time, and scalable slice management in future 6G networks is feasible. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.32604/cmc.2025.068533,"Computers, Materials and Continua","Smart learning environments have been considered as vital sources and essential needs in modern digital education systems. With the rapid proliferation of smart and assistive technologies, smart learning processes have become quite convenient, comfortable, and financially affordable. This shift has led to the emergence of pervasive computing environments, where user’s intelligent behavior is supported by smart gadgets; however, it is becoming more challenging due to inconsistent behavior of Artificial intelligence (AI) assistive technologies in terms of networking issues, slow user responses to technologies and limited computational resources. This paper presents a context-aware predictive reasoning based formalism for smart learning environments that facilitates students in managing their academic as well as extra-curricular activities autonomously with limited human intervention. This system consists of a three-tier architecture including the acquisition of the contextualized information from the environment autonomously, modeling the system using Web Ontology Rule Language (OWL 2 RL) and Semantic Web Rule Language (SWRL), and perform reasoning to infer the desired goals whenever and wherever needed. For contextual reasoning, we develop a non-monotonic reasoning based formalism to reason with contextual information using rule-based reasoning. The focus is on distributed problem solving, where context-aware agents exchange information using rule-based reasoning and specify constraints to accomplish desired goals. To formally model-check and simulate the system behavior, we model the case study of a smart learning environment in the UPPAAL model checker and verify the desired properties in the model, such as safety, liveness and robust properties to reflect the overall correctness behavior of the system with achieving the minimum analysis time of 0.002 s and 34,712 KB memory utilization. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.32604/cmc.2025.069332,"Computers, Materials and Continua","The Industrial Internet of Things (IIoT) is increasingly vulnerable to sophisticated cyber threats, particularly zero-day attacks that exploit unknown vulnerabilities and evade traditional security measures. To address this critical challenge, this paper proposes a dynamic defense framework named Zero-day-aware Stackelberg Game-based Multi-Agent Distributed Deep Deterministic Policy Gradient (ZSG-MAD3PG). The framework integrates Stackelberg game modeling with the Multi-Agent Distributed Deep Deterministic Policy Gradient (MAD3PG) algorithm and incorporates defensive deception (DD) strategies to achieve adaptive and efficient protection. While conventional methods typically incur considerable resource overhead and exhibit higher latency due to static or rigid defensive mechanisms, the proposed ZSG-MAD3PG framework mitigates these limitations through multi-stage game modeling and adaptive learning, enabling more efficient resource utilization and faster response times. The Stackelberg-based architecture allows defenders to dynamically optimize packet sampling strategies, while attackers adjust their tactics to reach rapid equilibrium. Furthermore, dynamic deception techniques reduce the time required for the concealment of attacks and the overall system burden. A lightweight behavioral fingerprinting detection mechanism further enhances real-time zero-day attack identification within industrial device clusters. ZSG-MAD3PG demonstrates higher true positive rates (TPR) and lower false alarm rates (FAR) compared to existing methods, while also achieving improved latency, resource efficiency, and stealth adaptability in IIoT zero-day defense scenarios. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.32604/cmes.2019.04727,CMES - Computer Modeling in Engineering and Sciences,"Deep Learning presents a critical capability to be geared into environments being constantly changed and ongoing learning dynamic, which is especially relevant in Network Intrusion Detection. In this paper, as enlightened by the theory of Deep Learning Neural Networks, Hierarchy Distributed-Agents Model for Network Risk Evaluation, a newly developed model, is proposed. The architecture taken on by the distributed-agents model are given, as well as the approach of analyzing network intrusion detection using Deep Learning, the mechanism of sharing hyper-parameters to improve the efficiency of learning is presented, and the hierarchical evaluative framework for Network Risk Evaluation of the proposed model is built. Furthermore, to examine the proposed model, a series of experiments were conducted in terms of NSL-KDD datasets. The proposed model was able to differentiate between normal and abnormal network activities with an accuracy of 97.60% on NSL-KDD datasets. As the results acquired from the experiment indicate, the model developed in this paper is characterized by high-speed and high-accuracy processing which shall offer a preferable solution with regard to the Risk Evaluation in Network. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.32604/cmes.2020.010986,CMES - Computer Modeling in Engineering and Sciences,"With the increasing demand for the automation of operations and processes in mechatronic systems, fault detection and diagnosis has become a major topic to guarantee the process performance. There exist numerous studies on the topic of applying artificial intelligence methods for fault detection and diagnosis. However, much of the focus has been given on the detection of faults. In terms of the diagnosis of faults, on one hand, assumptions are required, which restricts the diagnosis range. On the other hand, different faults with similar symptoms cannot be distinguished, especially when the model is not trained by plenty of data. In this work, we proposed a reinforcement learning system for fault detection and diagnosis. No assumption is required. Feature exaction is first made. Then with the features as the states of the environment, the agent directly interacts with the environment. Optimal policy, which determines the exact category, size and location of the fault, is obtained by updating Q values. The method takes advantage of expert knowledge. When the features are unclear, action will be made to get more information from the new state for further determination. We create recurrent neural network with the long short-term memory architecture to approximate Q values. The application on a motor is discussed. The experimental results validate that the proposed method demonstrates a significant improvement compared with existing state-of-the-art methods of fault detection and diagnosis. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.32604/cmes.2024.052039,CMES - Computer Modeling in Engineering and Sciences,"Aiming at the problems of low solution accuracy and high decision pressure when facing large-scale dynamic task allocation (DTA) and high-dimensional decision space with single agent, this paper combines the deep reinforcement learning (DRL) theory and an improved Multi-Agent Deep Deterministic Policy Gradient (MADDPG-D2) algorithm with a dual experience replay pool and a dual noise based on multi-agent architecture is proposed to improve the efficiency of DTA. The algorithm is based on the traditional Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm, and considers the introduction of a double noise mechanism to increase the action exploration space in the early stage of the algorithm, and the introduction of a double experience pool to improve the data utilization rate; at the same time, in order to accelerate the training speed and efficiency of the agents, and to solve the cold-start problem of the training, the a priori knowledge technology is applied to the training of the algorithm. Finally, the MADDPG-D2 algorithm is compared and analyzed based on the digital battlefield of ground and air confrontation. The experimental results show that the agents trained by the MADDPG-D2 algorithm have higher win rates and average rewards, can utilize the resources more reasonably, and better solve the problem of the traditional single agent algorithms facing the difficulty of solving the problem in the high-dimensional decision space. The MADDPG-D2 algorithm based on multi-agent architecture proposed in this paper has certain superiority and rationality in DTA. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.32604/cmes.2025.070517,CMES - Computer Modeling in Engineering and Sciences,"Isolated power systems, such as those on islands, face acute challenges in balancing energy demand with limited generation resources, making them particularly vulnerable to disruptions. This paper addresses these challenges by proposing a novel control and simulation framework based on a holonic multi-agent architecture, specifically developed as a digital twin for the Mayotte island grid. The primary contribution is a multi-objective optimization model, driven by a genetic algorithm, designed to enhance grid resilience through intelligent, decentralized decision-making. The efficacy of this architecture is validated through three distinct simulation scenarios: (1) a baseline scenario establishing nominal grid operation; (2) a critical disruption involving the failure of a major power plant; and (3) a localized fault resulting in the complete disconnection of a regional sub-grid. The major results demonstrate the system’s dual resilience mechanisms. In the plant failure scenario, the top-level holon successfully managed a global energy deficit by optimally reallocating shared resources, prioritizing grid stability over complete demand satisfaction. In the disconnection scenario, the affected holon demonstrated true autonomy, transitioning seamlessly into a self-sufficient islanded microgrid to prevent a cascading failure. Collectively, these findings validate the holonic model as a robust decision-support tool capable of managing both systemic and localized faults, thereby significantly enhancing the operational resilience and stability of isolated smart grids. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.32604/CSSE.2022.019523,Computer Systems Science and Engineering,"Electronic learning (e-learning) has become one of the widely used modes of pedagogy in higher education today due to the convenience and flexibility offered in comparison to traditional learning activities. Advancements in Information and Communication Technology have eased learner connectivity online and enabled access to an extensive range of learning materials on the World Wide Web. Post covid-19 pandemic, online learning has become the most essential and inevitable medium of learning in primary, secondary and higher education. In recent times, Massive Open Online Courses (MOOCs) have transformed the current education strategy by offering a technology-rich and flexible form of online learning. A key component to assess the learner’s progress and effectiveness of online teaching is the Multiple Choice Question (MCQ) assessment in most of the MOOC courses. Uncertainty exists on the reliability and validity of the assessment component as it raises a qualm whether the real knowledge acquisition level reflects upon the assessment score. This is due to the possibility of random and smart guesses, learners can attempt, as MCQ assessments are more vulnerable than essay type assessments. This paper presents the architecture, development, evaluation of the I-Quiz system, an intelligent assessment tool, which captures and analyses both the implicit and explicit non-verbal behaviour of learner and provides insights about the learner’s real knowledge acquisition level. The I-Quiz system uses an innovative way to analyse the learner non-verbal behaviour and trains the agent using machine learning techniques. The intelligent agent in the system evaluates and predicts the real knowledge acquisition level of learners. A total of 500 undergraduate engineering students were asked to attend an on-Screen MCQ assessment test using the I-Quiz system comprising 20 multiple choice questions related to advanced C programming. The non-verbal behaviour of the learner is recorded using a front-facing camera during the entire assessment period. The resultant dataset of non-verbal behaviour and question-answer scores is used to train the random forest classifier model to predict the real knowledge acquisition level of the learner. The trained model after hyperparameter tuning and cross validation achieved a normalized prediction accuracy of 85.68%. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.32604/csse.2023.024868,Computer Systems Science and Engineering,"Edge computing is a cloud computing extension where physical computers are installed closer to the device to minimize latency. The task of edge data centers is to include a growing abundance of applications with a small capability in comparison to conventional data centers. Under this framework, Federated Learning was suggested to offer distributed data training strategies by the coordination of many mobile devices for the training of a popular Artificial Intelligence (AI) model without actually revealing the underlying data, which is significantly enhanced in terms of privacy. Federated learning (FL) is a recently developed decentralized profound learning methodology, where customers train their localized neural network models independently using private data, and then combine a global model on the core server together. The models on the edge server use very little time since the edge server is highly calculated. But the amount of time it takes to download data from smartphone users on the edge server has a significant impact on the time it takes to complete a single cycle of FL operations. A machine learning strategic planning system that uses FL in conjunction to minimise model training time and total time utilisation, while recognising mobile appliance energy restrictions, is the focus of this study. To further speed up integration and reduce the amount of data, it implements an optimization agent for the establishment of optimal aggregation policy and asylum architecture with several employees’ shared learners. The main solutions and lessons learnt along with the prospects are discussed. Experiments show that our method is superior in terms of the effective and elastic use of resources. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.32620/REKS.2021.1.13,Radioelectronic and Computer Systems,"The development of enterprises in strategic industries depends on funding made innovative products that are in demand in the markets for high-tech products. The interest of investors depends on the innovation and com-petitiveness of the products that the enterprise can produce. The enterprise should make a new, diversified portfolio of orders to attract funding from potential investors. The innovativeness of the product is determined by the novelty of the components in its composition. Therefore, the pressing challenge is to study the innova-tion of high-tech products based on their component architecture. It makes it possible for investors to assess the possibility of enterprise financing while making a promising diversified portfolio of orders. The study de-velops a method to justify investments into the new orders that are based on the research of the component ar-chitecture of the complex product. The tasks analyzed the product component architecture innovation and investment attractiveness, justify and select the diversified portfolio of orders, simulate and assess orders portfolio feasibility are stated and solved. The paper proposes the component method that makes it possible to evaluate the architecture of the new prod-uct in terms of innovation and investment attractiveness. The research of innovation is conducted depending on the composition of the components in the architecture of the whole product. These components can be either new that require a new cycle of creation, or “old” ones, taken from previous experience with the possible ad-aptation to the technical requirements of the new product. By using the proposed multifactor planning of the experiment, the possible options are considered and the main indicators of the new product are assessed: in-vestment attractiveness, costs, timelines, and risks of order fulfillment. Using lexicographic ordering of alter-natives the compromised selection of the optimal option in terms of limited capabilities of the enterprise is conducted. To optimize the diversified portfolio of orders the method of integer (Boolean) programming is used. Investment attractiveness is used as a target function. The restrictions consider allowable costs, time-lines, and risks of the orders portfolio fulfillment. In the last part of the paper, the method of simulation agent modeling in a form of applied information tech-nology is used to assess the timeline for order fulfillment and the impact of risks on the feasibility of the diver-sified portfolio of orders. The novelty of the results is related to the justification of the choice of a diversified portfolio of orders, which in contrast to the already existing approaches, is based on the advanced component architecture of complex products and the simulation of orders portfolio selection considering innovation and investor interests. The proposed method and information technology are planned for the future development of an enterprise that makes it possible to assess the competitiveness of products, as well as the possibility to attract funding © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.32725/jab.2020.006,Journal of Applied Biomedicine,"Background: The liver is the main metabolic organ involved in disposal and detoxification of various molecules. Plantago psyllium L. seed has been reported to exert positive effects in some pathological conditions. The current study aims to assess the hepatoprotective effect of Plantago psyllium L. seed extract against carbon tetrachloride-induced hepatotoxicity. Methods: Male albino Wistar rats were randomly divided into five groups of 10 rats each. Hepatotoxicity was induced by orally administered carbon tetrachloride (CCl<inf>4</inf>) for nine weeks with or without the different treatments which were utilized daily for the whole nine weeks. Serum and tissue samples were then withdrawn and different liver biomarkers were investigated. Results: Treatment of rats with Psyllium seed ethanolic extract significantly alleviated the toxic effects of CCl<inf>4</inf>. This was evidenced by its ability to restore liver biomarkers levels. Moreover, treatment with Psyllium seed extract normalized levels of oxidative biomarkers such as lipid peroxidation, hepatic content of reduced glutathione and catalase activity, as well as the expression level of the inflammatory marker TNF-α. Histopathological examination reflected the protective effect of the extract on liver architecture and confirmed the observed biochemical data. Conclusions: The presented data demonstrates a potential hepatoprotective effect of Psyllium seed extract compared to the standard hepatoprotective drug silymarin. This effect can be attributed to the antioxidant and anti-inflammatory effects of Psyllium extract. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.33271/nvngu/2020-3/103,Naukovyi Visnyk Natsionalnoho Hirnychoho Universytetu,"Purpose. To model consolidated information systems as a result of interaction of economic entities in the information space. To reveal the information and communication direction of the virtual integration plane, to substantiate the principles of its formation and composition of the elements which constitute it. Methodology. The theoretical and methodological basis of the article involves neoclassical economic theories, concepts of economic integration, methodological basis of systematic and synergistic approaches. The authors used methods of subject and cognitive modeling, which allowed developing a model of multiagent information plane to implement mechanisms of interaction of participants in integrated business structures. The logical method of scientific cognition allowed the authors to formulate conclusions that substantiate the need to create an economic and informational space for interaction between the participants of the economic integration. findings. The authors suggest the theoretical and methodological provisions of the use of information technologies to ensure the information interaction of participants of integration entities. A model of a multiagent information plane, based on a 4tier open distribution information system, is presented. The role and tasks of interconnected subsystems in the economic and information space are substantiated. Directions of influence through the formed information and communication corridors are clarified. The authors proved the need to accumulate information flows within the virtual integration plane based on the agents' local information systems. The multiagent architecture of the virtual interaction environment for business entities within the integration plane is improved; the scheme of virtual agent interaction model based on the virtual plane is defined and the block diagram of the algorithm of interaction of economic agents within the virtual integration plane is improved. originality. Scientific priority of ensuring information interaction of participants of integration entities based on using information technologies is enhanced. The authors revealed information and communication direction of the virtual integration plane. The process of formation of the virtual economicinformation space of interaction of participants within the framework of a multiagent virtual information plane is specified, which allows accumulating, processing, distributing, and using the consolidated knowledge base with the purpose of information and communication support of crosscutting business processes, support of the adoption of management decisions to provide virtual interaction of the agents. Practical value. The conducted research provides applied tools of modernization of the use of information technologies to ensure information interaction of participants of integration entities. A virtual integration plane is formed, which is the basis for managing the virtual integration interaction of business entities and implementing the concept of integration development. The results obtained during the research will allow providing informational support of managerial decisionmaking, implementing economic ties, monitoring the implementation of integration programs and strategies. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.33640/2405-609X.3321,Karbala International Journal of Modern Science,"The rapid expansion of human-software-agent interaction has come with new issues. Accordingly, different engage-ments are necessary to adapt to changing human needs in dynamic socio-technical systems. Generally, cybervandalism is the act of leaving any negative impact on any piece of writing in an attempt to modify it. In Wikipedia, vandalism is any attempt to modify an article in a way that negatively affects the article's quality. Recently, several automatic detec-tion techniques and related features have been developed to address this issue. This work introduces a deep learning model with a new and light architecture to detect vandalism in Wikipedia articles. The proposed model employs a one-dimensional convolutional neural network architecture (1D CNN) that can determine the type of modification in Wikipedia articles based on two main stages: the feature extraction stage and the vandalism detection stage, preceded by the data-resampling step, which is used to address class imbalance issues in the dataset. Features are extracted from edits and their associated metadata, as well as new features (reviewers' trust), and then only the salient features are adopted to make a decision about the article; regular or vandalism can contribute to improving the accuracy of predic-tion. The experiments were conducted on a benchmark dataset, the PAN-WVC-2010 corpus, taken from a vandalism detection competition hosted at the CLEF conference. The proposed system, with the new features added, has achieved an accuracy of 100%. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3389/fbioe.2021.679525,Frontiers in Bioengineering and Biotechnology,"RADA16 is a synthetic peptide that exists as a viscous solution in an acidic formulation. In an acidic aqueous environment, the peptides spontaneously self-assemble into β-sheet nanofibers. Upon exposure and buffering of RADA16 solution to the physiological pH of biological fluids such as blood, interstitial fluid and lymph, the nanofibers begin physically crosslinking within seconds into a stable interwoven transparent hydrogel 3-D matrix. The RADA16 nanofiber hydrogel structure closely resembles the 3-dimensional architecture of native extracellular matrices. These properties make RADA16 formulations ideal topical hemostatic agents for controlling bleeding during surgery and to prevent post-operative rebleeding. A commercial RADA16 formulation is currently used for hemostasis in cardiovascular, gastrointestinal, and otorhinolaryngological surgical procedures, and studies are underway to investigate its use in wound healing and adhesion reduction. Straightforward application of viscous RADA16 into areas that are not easily accessible circumvents technical challenges in difficult-to-reach bleeding sites. The transparent hydrogel allows clear visualization of the surgical field and facilitates suture line assessment and revision. The shear-thinning and thixotropic properties of RADA16 allow its easy application through a narrow nozzle such as an endoscopic catheter. RADA16 hydrogels can fill tissue voids and do not swell so can be safely used in close proximity to pressure-sensitive tissues and in enclosed non-expandable regions. By definition, the synthetic peptide avoids potential microbiological contamination and immune responses that may occur with animal-, plant-, or mineral-derived topical hemostats. In vitro experiments, animal studies, and recent clinical experiences suggest that RADA16 nanofibrous hydrogels can act as surrogate extracellular matrices that support cellular behavior and interactions essential for wound healing and for tissue regenerative applications. In the future, the unique nature of RADA16 may also allow us to use it as a depot for precisely regulated drug and biopharmaceutical delivery. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3389/fbioe.2021.786077,Frontiers in Bioengineering and Biotechnology,"This study aimed to address the significant problems of bacterial biofilms found in medical fields and many industries. It explores the potential of classic photoactive carbon dots (CDots), with 2,2′-(ethylenedioxy)bis (ethylamine) (EDA) for dot surface functionalization (thus, EDA-CDots) for their inhibitory effect on B. subtilis biofilm formation and the inactivation of B. subtilis cells within established biofilm. The EDA-CDots were synthesized by chemical functionalization of selected small carbon nanoparticles with EDA molecules in amidation reactions. The inhibitory efficacy of CDots with visible light against biofilm formation was dependent significantly on the time point when CDots were added; the earlier the CDots were added, the better the inhibitory effect on the biofilm formation. The evaluation of antibacterial action of light-activated EDA-CDots against planktonic B. subtilis cells versus the cells in biofilm indicate that CDots are highly effective for inactivating planktonic cells but barely inactivate cells in established biofilms. However, when coupling with chelating agents (e.g., EDTA) to target the biofilm architecture by breaking or weakening the EPS protection, much enhanced photoinactivation of biofilm-associated cells by CDots was achieved. The study demonstrates the potential of CDots to prevent the initiation of biofilm formation and to inhibit biofilm growth at an early stage. Strategic combination treatment could enhance the effectiveness of photoinactivation by CDots to biofilm-associated cells. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3389/fcomp.2025.1678976,Frontiers in Computer Science,"Cloud resource allocation has emerged as a major challenge in modern computing environments, with organizations struggling to manage complex, dynamic workloads while optimizing performance and cost efficiency. Traditional heuristic approaches prove inadequate for handling the multi-objective optimization demands of existing cloud infrastructures. This paper presents a comparative analysis of state-of-the-art artificial intelligence and machine learning algorithms for resource allocation. We systematically evaluate 10 algorithms across four categories: Deep Reinforcement Learning approaches, Neural Network architectures, Traditional Machine Learning enhanced methods, and Multi-Agent systems. Analysis of published results demonstrates significant performance improvements across multiple metrics including makespan reduction, cost optimization, and energy efficiency gains compared to traditional methods. The findings reveal that hybrid architectures combining multiple artificial intelligence and machine learning techniques consistently outperform single-method approaches, with edge computing environments showing the highest deployment readiness. Our analysis provides critical insights for both academic researchers and industry practitioners seeking to implement next-generation cloud resource allocation strategies in increasingly complex and dynamic computing environments. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3389/fict.2016.00026,Frontiers in ICT,"This article presents an immersive virtual reality (VR) system for training classroom management skills, with a specific focus on learning to manage disruptive student behavior in face-to-face, one-to-many teaching scenarios. The core of the system is a real-time 3D virtual simulation of a classroom populated by twenty-four semi-autonomous virtual students. The system has been designed as a companion tool for classroom management seminars in a syllabus for primary and secondary school teachers. This will allow lecturers to link theory with practice using the medium of VR. The system is therefore designed for two users: a trainee teacher and an instructor supervising the training session. The teacher is immersed in a real-time 3D simulation of a classroom by means of a head-mounted display and headphone. The instructor operates a graphical desktop console, which renders a view of the class and the teacher whose avatar movements are captured by a marker less tracking system. This console includes a 2D graphics menu with convenient behavior and feedback control mechanisms to provide human-guided training sessions. The system is built using low-cost consumer hardware and software. Its architecture and technical design are described in detail. A first evaluation confirms its conformance to critical usability requirements (i.e., safety and comfort, believability, simplicity, acceptability, extensibility, affordability, and mobility). Our initial results are promising and constitute the necessary first step toward a possible investigation of the efficiency and effectiveness of such a system in terms of learning outcomes and experience. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.3389/fmars.2020.00327,Frontiers in Marine Science,"Rehabilitated and restored mangrove ecosystems have important ecological, economic, and social values for coastal communities. Although a sine qua non of successful mangrove rehabilitation or restoration projects is accurate attention to local hydrology and basic biology of mangrove trees and their associated fauna, their long-term success depends on far more axes, each with their own challenges. Rehabilitation projects: are planned, designed, executed, and managed by people with diverse backgrounds and different scientific and socio-political agendas; need to be responsive to these multiple stakeholders and agents who hold different values; are often influenced by laws and treaties spanning local to international scales; and must be able to adapt and evolve both geomorphologically and socioeconomically over decades-to-centuries in the context of a rapidly changing climate. We view these challenges as opportunities for innovative approaches to rehabilitation and restoration that engage new and larger constituencies. Restored mangrove ecosystems can be deliberately designed and engineered to provide valuable ecosystem services, be adaptable to climatic changes, and to develop platforms for educating nonspecialists about both the successes and failures of restored mangrove ecosystems. When mangrove rehabilitation or restoration projects are developed as experiments, they can be used as case-studies and more general models to inform policy- and decision-makers and guide future restoration efforts. Achieving this vision will require new investment and dedication to research and adaptive management practices. These ideas are illustrated with examples from mangrove restoration and rehabilitation projects in the Indo-West Pacific and Caribbean regions, the two hotspots of mangrove biodiversity and its ongoing loss and degradation. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.3389/fnbot.2017.00013,Frontiers in Neurorobotics,"Intelligent agents, such as robots, have to serve a multitude of autonomous functions. Examples are, e.g., collision avoidance, navigation and route planning, active sensing of its environment, or the interaction and non-verbal communication with people in the extended reach space. Here, we focus on the recognition of the action of a human agent based on a biologically inspired visual architecture of analyzing articulated movements. The proposed processing architecture builds upon coarsely segregated streams of sensory processing along different pathways which separately process form and motion information (Layher et al., 2014). Action recognition is performed in an event-based scheme by identifying representations of characteristic pose configurations (key poses) in an image sequence. In line with perceptual studies, key poses are selected unsupervised utilizing a feature-driven criterion which combines extrema in the motion energy with the horizontal and the vertical extendedness of a body shape. Per class representations of key pose frames are learned using a deep convolutional neural network consisting of 15 convolutional layers. The network is trained using the energy-efficient deep neuromorphic networks (Eedn) framework (Esser et al., 2016), which realizes the mapping of the trained synaptic weights onto the IBMNeurosynaptic System platform (Merolla et al., 2014). After the mapping, the trained network achieves real-time capabilities for processing input streams and classify input images at about 1,000 frames per second while the computational stages only consume about 70 mW of energy (without spike transduction). Particularly regarding mobile robotic systems, a low energy profile might be crucial in a variety of application scenarios. Cross-validation results are reported for two different datasets and compared to state-of-the-art action recognition approaches. The results demonstrate, that (I) the presented approach is on par with other key pose based methods described in the literature, which select key pose frames by optimizing classification accuracy, (II) compared to the training on the full set of frames, representations trained on key pose frames result in a higher confidence in class assignments, and (III) key pose representations show promising generalization capabilities in a cross-dataset evaluation. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.3389/fnbot.2019.00040,Frontiers in Neurorobotics,"An effective way to achieve intelligence is to simulate various intelligent behaviors in the human brain. In recent years, bio-inspired learning methods have emerged, and they are different from the classical mathematical programming principle. From the perspective of brain inspiration, reinforcement learning has gained additional interest in solving decision-making tasks as increasing neuroscientific research demonstrates that significant links exist between reinforcement learning and specific neural substrates. Because of the tremendous research that focuses on human brains and reinforcement learning, scientists have investigated how robots can autonomously tackle complex tasks in the form of making a self-driving agent control in a human-like way. In this study, we propose an end-to-end architecture using novel deep-Q-network architecture in conjunction with a recurrence to resolve the problem in the field of simulated self-driving. The main contribution of this study is that we trained the driving agent using a brain-inspired trial-and-error technique, which was in line with the real world situation. Besides, there are three innovations in the proposed learning network: raw screen outputs are the only information which the driving agent can rely on, a weighted layer that enhances the differences of the lengthy episode, and a modified replay mechanism that overcomes the problem of sparsity and accelerates learning. The proposed network was trained and tested under a third-party OpenAI Gym environment. After training for several episodes, the resulting driving agent performed advanced behaviors in the given scene. We hope that in the future, the proposed brain-inspired learning system would inspire practicable self-driving control solutions. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.3389/fnbot.2021.772012,Frontiers in Neurorobotics,"Plants offer a source of bioinspiration for soft robotics. Nevertheless, a gap remains in designing robots based on the fundamental principles of plant intelligence, rooted in a non-centralized, modular architecture and a highly plastic phenotype. We contend that a holistic approach to plant bioinspiration—one that draws more fully on the features of plant intelligence and behavior—evidences the value of an enactivist perspective. This is because enactivism emphasizes not only features of embodiment such as material composition and morphology, but also autonomy as an important aspect of plant intelligence and behavior. The enactivist sense of autonomy concerns the dynamics of self-producing systems (such as plants) that create a distinction between themselves and a domain of interactions that bear on the conditions of viability of the system. This contrasts with the widespread, but diluted notion of autonomy that merely indicates the independent operability of a system for an arbitrary period. Different notions of autonomy are relevant for soft roboticists, for instance, when evaluating limitations on existing growing robots (“growbots”) that take bioinspiration from plants, but depend on a fixed source of energy and material provided by an external agent. More generally, plant-inspired robots serve as a case study for an enactivist approach to intelligence, while, correspondingly, enactivism calls attention to the possibility of non-zoological forms of intelligence embodied in a self-organizing, autonomous system. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3389/fnbot.2022.1072887,Frontiers in Neurorobotics,"Modern air defense battlefield situations are complex and varied, requiring high-speed computing capabilities and real-time situational processing for task assignment. Current methods struggle to balance the quality and speed of assignment strategies. This paper proposes a hierarchical reinforcement learning architecture for ground-to-air confrontation (HRL-GC) and an algorithm combining model predictive control with proximal policy optimization (MPC-PPO), which effectively combines the advantages of centralized and distributed approaches. To improve training efficiency while ensuring the quality of the final decision. In a large-scale area air defense scenario, this paper validates the effectiveness and superiority of the HRL-GC architecture and MPC-PPO algorithm, proving that the method can meet the needs of large-scale air defense task assignment in terms of quality and speed. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3389/fnbot.2022.750482,Frontiers in Neurorobotics,"Human hand gesture recognition from surface electromyography (sEMG) signals is one of the main paradigms for prosthetic and rehabilitation device control. The accuracy of gesture recognition is correlated with the control mechanism. In this work, a new classifier based on the Bayesian neural network, pattern recognition networks, and layer recurrent network is presented. The online results obtained with this architecture represent a promising solution for hand gesture recognition (98.7% accuracy) in sEMG signal classification. For real time classification performance with rehabilitation devices, a new simple and efficient interface is developed in which users can re-train the classification algorithm with their own sEMG gesture data in a few minutes while enables shape memory alloy-based rehabilitation device connection and control. The position of reference for the rehabilitation device is generated by the algorithm based on the classifier, which is capable of detecting user movement intention in real time. The main aim of this study is to prove that the device control algorithm is adapted to the characteristics and necessities of the user through the proposed classifier with high accuracy in hand gesture recognition. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3389/fnbot.2023.1211570,Frontiers in Neurorobotics,"Introduction: We introduce a bio-inspired navigation system for a robot to guide a social agent to a target location while avoiding static and dynamic obstacles. Robot navigation can be accomplished through a model of ring attractor neural networks. This connectivity pattern between neurons enables the generation of stable activity patterns that can represent continuous variables such as heading direction or position. The integration of sensory representation, decision-making, and motor control through ring attractor networks offers a biologically-inspired approach to navigation in complex environments. Methods: The navigation system is divided into perception, planning, and control stages. Our approach is compared to the widely-used Social Force Model and Rapidly Exploring Random Tree Star methods using the Social Individual Index and Relative Motion Index as metrics in simulated experiments. We created a virtual scenario of a pedestrian area with various obstacles and dynamic agents. Results: The results obtained in our experiments demonstrate the effectiveness of this architecture in guiding a social agent while avoiding obstacles, and the metrics used for evaluating the system indicate that our proposal outperforms the widely used Social Force Model. Discussion: Our approach points to improving safety and comfort specifically for human-robot interactions. By integrating the Social Individual Index and Relative Motion Index, this approach considers both social comfort and collision avoidance features, resulting in better human-robot interactions in a crowded environment. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3389/fnbot.2023.1274543,Frontiers in Neurorobotics,"Introduction: In the realm of basketball, refining shooting skills and decision-making levels using intelligent agents has garnered significant interest. This study addresses the challenge by introducing an innovative framework that combines multi-modal perception and deep reinforcement learning. The goal is to create basketball robots capable of executing precise shots and informed choices by effectively integrating sensory inputs and learned strategies. Methods: The proposed approach consists of three main components: multi-modal perception, deep reinforcement learning, and end-to-end architecture. Multi-modal perception leverages the multi-head attention mechanism (MATT) to merge visual, motion, and distance cues for a holistic perception of the basketball scenario. The deep reinforcement learning framework utilizes the Deep Q-Network (DQN) algorithm, enabling the robots to learn optimal shooting strategies over iterative interactions with the environment. The end-to-end architecture connects these components, allowing seamless integration of perception and decision-making processes. Results: The experiments conducted demonstrate the effectiveness of the proposed approach. Basketball robots equipped with multi-modal perception and deep reinforcement learning exhibit improved shooting accuracy and enhanced decision-making abilities. The multi-head attention mechanism enhances the robots' perception of complex scenes, leading to more accurate shooting decisions. The application of the DQN algorithm results in gradual skill improvement and strategic optimization through interaction with the environment. Discussion: The integration of multi-modal perception and deep reinforcement learning within an end-to-end architecture presents a promising avenue for advancing basketball robot training and performance. The ability to fuse diverse sensory inputs and learned strategies empowers robots to make informed decisions and execute accurate shots. The research not only contributes to the field of robotics but also has potential implications for human basketball training and coaching methodologies. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3389/fnbot.2024.1376215,Frontiers in Neurorobotics,"In uncertain environments with robot input saturation, both model-based reinforcement learning (MBRL) and traditional controllers struggle to perform control tasks optimally. In this study, an algorithmic framework of Curiosity Model Policy Optimization (CMPO) is proposed by combining curiosity and model-based approach, where tracking errors are reduced via training agents on control gains for traditional model-free controllers. To begin with, a metric for judging positive and negative curiosity is proposed. Constrained optimization is employed to update the curiosity ratio, which improves the efficiency of agent training. Next, the novelty distance buffer ratio is defined to reduce bias between the environment and the model. Finally, CMPO is simulated with traditional controllers and baseline MBRL algorithms in the robotic environment designed with non-linear rewards. The experimental results illustrate that the algorithm achieves superior tracking performance and generalization capabilities. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3389/fphy.2020.00200,Frontiers in Physics,"Complex global behavior patterns can emerge from very simple local interactions between many agents. However, no local interaction rules have been identified that generate some patterns observed in nature, for example the rotating balls, rotating tornadoes and the full-core rotating mills observed in fish collectives. Here we show that locally interacting agents modeled with a minimal cognitive system can produce these collective patterns. We obtained this result by using recent advances in reinforcement learning to systematically solve the inverse modeling problem: given an observed collective behavior, we automatically find a policy generating it. Our agents are modeled as processing the information from neighbor agents to choose actions with a neural network and move in an environment of simulated physics. Even though every agent is equipped with its own neural network, all agents have the same network architecture and parameter values, ensuring in this way that a single policy is responsible for the emergence of a given pattern. We find the final policies by tuning the neural network weights until the produced collective behavior approaches the desired one. By using modular neural networks with modules using a small number of inputs and outputs, we built an interpretable model of collective motion. This enabled us to analyse the policies obtained. We found a similar general structure for the four different collective patterns, not dissimilar to the one we have previously inferred from experimental zebrafish trajectories; but we also found consistent differences between policies generating the different collective pattern, for example repulsion in the vertical direction for the more three-dimensional structures of the sphere and tornado. Our results illustrate how new advances in artificial intelligence, and specifically in reinforcement learning, allow new approaches to analysis and modeling of collective behavior. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3389/frai.2023.1151003,Frontiers in Artificial Intelligence,"We employ deep reinforcement learning (RL) to train an agent to successfully translate a high-frequency trading signal into a trading strategy that places individual limit orders. Based on the ABIDES limit order book simulator, we build a reinforcement learning OpenAI gym environment and utilize it to simulate a realistic trading environment for NASDAQ equities based on historic order book messages. To train a trading agent that learns to maximize its trading return in this environment, we use Deep Dueling Double Q-learning with the APEX (asynchronous prioritized experience replay) architecture. The agent observes the current limit order book state, its recent history, and a short-term directional forecast. To investigate the performance of RL for adaptive trading independently from a concrete forecasting algorithm, we study the performance of our approach utilizing synthetic alpha signals obtained by perturbing forward-looking returns with varying levels of noise. Here, we find that the RL agent learns an effective trading strategy for inventory management and order placing that outperforms a heuristic benchmark trading strategy having access to the same signal. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3389/frai.2024.1397860,Frontiers in Artificial Intelligence,"Studies on reinforcement learning have developed the representation of curiosity, which is a type of intrinsic motivation that leads to high performance in a certain type of tasks. However, these studies have not thoroughly examined the internal cognitive mechanisms leading to this performance. In contrast to this previous framework, we propose a mechanism of intrinsic motivation focused on pattern discovery from the perspective of human cognition. This study deals with intellectual curiosity as a type of intrinsic motivation, which finds novel compressible patterns in the data. We represented the process of continuation and boredom of tasks driven by intellectual curiosity using “pattern matching,” “utility,” and “production compilation,” which are general functions of the adaptive control of thought-rational (ACT-R) architecture. We implemented three ACT-R models with different levels of thinking to navigate multiple mazes of different sizes in simulations, manipulating the intensity of intellectual curiosity. The results indicate that intellectual curiosity negatively affects task completion rates in models with lower levels of thinking, while positively impacting models with higher levels of thinking. In addition, comparisons with a model developed by a conventional framework of reinforcement learning (intrinsic curiosity module: ICM) indicate the advantage of representing the agent's intention toward a goal in the proposed mechanism. In summary, the reported models, developed using functions linked to a general cognitive architecture, can contribute to our understanding of intrinsic motivation within the broader context of human innovation driven by pattern discovery. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3389/frai.2025.1608365,Frontiers in Artificial Intelligence,"Recent breakthroughs in Large Language Models (LLMs) have the potential to disrupt equity investing by enabling sophisticated data analysis, market prediction, and automated trading. This paper presents a comprehensive review of 84 research studies conducted between 2022 and early 2025, synthesizing the state of LLM applications in stock investing. We provide a dual-layered categorization: first, by financial applications such as stock price forecasting, sentiment analysis, portfolio management, and algorithmic trading; second, by technical methodologies, including prompting, fine-tuning, multi-agent frameworks, reinforcement learning, and custom architectures. Additionally, we consolidate findings on the datasets used, ranging from financial statements to multimodal data (news, market trends, earnings transcripts, social media), and systematically compare general-purpose vs. finance-specialized LLMs used in research. Our analysis identifies key research trends, commonalities, and divergences across studies, evaluating both their empirical contributions and methodological innovations. We highlight the strengths of existing research, such as improved sentiment extraction and the use of reinforcement learning to factor market feedback, alongside critical gaps in scalability, interpretability, and real-world validation. Finally, we propose directions for future research, emphasizing hybrid modeling approaches, architectures that factor reasoning and large context windows, and robust evaluation frameworks to advance AI-driven financial strategies. By mapping the intersection of LLMs and equity markets, this review provides a foundation and roadmap for future research and practical implementation in the financial sector. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3389/frai.2025.1672273,Frontiers in Artificial Intelligence,"The increasing complexity and decentralization of modern blockchain networks have highlighted the limitations of traditional consensus protocols when operating under adverse or dynamic conditions. Existing approaches often fail to adapt to real-time anomalies such as Sybil attacks, network congestion, or node failures, resulting in decreased throughput, increased latency, and reduced security. Furthermore, most systems lack autonomous mechanisms to adjust operational policies based on context, especially in edge computing environments where resource constraints and topological variability demand flexible and efficient solutions. This work proposes an adaptive consensus architecture that integrates a graph-based Proximal Policy Optimization (PPO) reinforcement learning agent capable of detecting malicious behavior, optimizing validation paths, and dynamically modifying consensus logic in response to adversarial scenarios. The model is trained on a hybrid dataset composed of real traffic traces and synthetically generated adversarial behaviors, and evaluated in stress-testing environments with multiple threat vectors. Experimental results demonstrate that the proposed system maintains stable throughput (TPS) while reducing average consensus latency by 34% relative to baseline protocols under adverse high-load conditions. Regarding security, it achieves high detection in Sybil and node-collapse scenarios (DR exceeding 0.90 with FPR below 0.10), and moderate detection under congestion and erroneous transactions (DR between 0.58 and 0.70, FPR between 0.14 and 0.22). Additionally, we observe up to 16% lower average energy consumption in high-congestion settings. Energy consumption is reduced by up to 17% in crash-prone scenarios. The architecture demonstrates stable convergence over 100 operating cycles and robust adaptation to topological changes, validating its applicability in real-world deployments. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3389/frobt.2017.00027,Frontiers in Robotics and AI,"The success of robotic agents in close proximity of humans depends on their capacity to engage in social interactions and maintain these interactions over periods of time that are suitable for learning. A critical requirement is the ability to modify the behavior of the robot contingently to the attentional and social cues signaled by the human. A benchmark challenge for an engaging social robot is that of storytelling. In this paper, we present an exploratory study to investigate dialogic storytelling-storytelling with contingent responses-using a child-friendly robot. The aim of the study was to develop an engaging storytelling robot and to develop metrics for evaluating engagement. Ten children listened to an illustrated story told by a social robot during a science fair. The responses of the robot were adapted during the interaction based on the children's engagement and touches of the pictures displayed by the robot on a tablet embedded in its torso. During the interaction the robot responded contingently to the child, but only when the robot invited the child to interact. We describe the robot architecture used to implement dialogic storytelling and evaluate the quality of human-robot interaction based on temporal (patterns of touch, touch duration) and spatial (motions in the space surrounding the robot) metrics. We introduce a novel visualization that emphasizes the temporal dynamics of the interaction and analyze the motions of the children in the space surrounding the robot. The study demonstrates that the interaction through invited contingent responses succeeded in engaging children, although the robot missed some opportunities for contingent interaction and the children had to adapt to the task. We conclude that (i) the consideration of both temporal and spatial attributes is fundamental for establishing metrics to estimate levels of engagement in real-time, (ii) metrics for engagement are sensitive to both the group and individual, and (iii) a robot's sequential mode of interaction can facilitate engagement, despite some social events being ignored by the robot. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.3389/frobt.2018.00060,Frontiers in Robotics and AI,"The study of collective behavior has traditionally relied on a variety of different methodological tools ranging from more theoretical methods such as population or game-theoretic models to empirical ones like Monte Carlo or multi-agent simulations. An approach that is increasingly being explored is the use of information theory as a methodological framework to study the flow of information and the statistical properties of collectives of interacting agents. While a few general purpose toolkits exist, most of the existing software for information theoretic analysis of collective systems is limited in scope. We introduce Inform, an open-source framework for efficient information theoretic analysis that exploits the computational power of a C library while simplifying its use through a variety of wrappers for common higher-level scripting languages. We focus on two such wrappers here: PyInform (Python) and rinform (R). Inform and its wrappers are cross-platform and general-purpose. They include classical information-theoretic measures, measures of information dynamics and information-based methods to study the statistical behavior of collective systems, and expose a lower-level API that allow users to construct measures of their own. We describe the architecture of the Inform framework, study its computational efficiency and use it to analyze three different case studies of collective behavior: biochemical information storage in regenerating planaria, nest-site selection in the ant Temnothorax rugatulus, and collective decision making in multi-agent simulations. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.3389/frobt.2020.00034,Frontiers in Robotics and AI,"Predictions and predictive knowledge have seen recent success in improving not only robot control but also other applications ranging from industrial process control to rehabilitation. A property that makes these predictive approaches well-suited for robotics is that they can be learned online and incrementally through interaction with the environment. However, a remaining challenge for many prediction-learning approaches is an appropriate choice of prediction-learning parameters, especially parameters that control the magnitude of a learning machine's updates to its predictions (the learning rates or step sizes). Typically, these parameters are chosen based on an extensive parameter search—an approach that neither scales well nor is well-suited for tasks that require changing step sizes due to non-stationarity. To begin to address this challenge, we examine the use of online step-size adaptation using the Modular Prosthetic Limb: a sensor-rich robotic arm intended for use by persons with amputations. Our method of choice, Temporal-Difference Incremental Delta-Bar-Delta (TIDBD), learns and adapts step sizes on a feature level; importantly, TIDBD allows step-size tuning and representation learning to occur at the same time. As a first contribution, we show that TIDBD is a practical alternative for classic Temporal-Difference (TD) learning via an extensive parameter search. Both approaches perform comparably in terms of predicting future aspects of a robotic data stream, but TD only achieves comparable performance with a carefully hand-tuned learning rate, while TIDBD uses a robust meta-parameter and tunes its own learning rates. Secondly, our results show that for this particular application TIDBD allows the system to automatically detect patterns characteristic of sensor failures common to a number of robotic applications. As a third contribution, we investigate the sensitivity of classic TD and TIDBD with respect to the initial step-size values on our robotic data set, reaffirming the robustness of TIDBD as shown in previous papers. Together, these results promise to improve the ability of robotic devices to learn from interactions with their environments in a robust way, providing key capabilities for autonomous agents and robots. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.3389/frobt.2021.665301,Frontiers in Robotics and AI,"In many real-word scenarios, humans and robots are required to coordinate their movements in joint tasks to fulfil a common goal. While several examples regarding dyadic human robot interaction exist in the current literature, multi-agent scenarios in which one or more artificial agents need to interact with many humans are still seldom investigated. In this paper we address the problem of synthesizing an autonomous artificial agent to perform a paradigmatic oscillatory joint task in human ensembles while exhibiting some desired human kinematic features. We propose an architecture based on deep reinforcement learning which is flexible enough to make the artificial agent interact with human groups of different sizes. As a paradigmatic coordination task we consider a multi-agent version of the mirror game, an oscillatory motor task largely used in the literature to study human motor coordination. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3389/frobt.2022.1067502,Frontiers in Robotics and AI,"Reinforcement Learning has been shown to have a great potential for robotics. It demonstrated the capability to solve complex manipulation and locomotion tasks, even by learning end-to-end policies that operate directly on visual input, removing the need for custom perception systems. However, for practical robotics applications, its scarce sample efficiency, the need for huge amounts of resources, data, and computation time can be an insurmountable obstacle. One potential solution to this sample efficiency issue is the use of simulated environments. However, the discrepancy in visual and physical characteristics between reality and simulation, namely the sim-to-real gap, often significantly reduces the real-world performance of policies trained within a simulator. In this work we propose a sim-to-real technique that trains a Soft-Actor Critic agent together with a decoupled feature extractor and a latent-space dynamics model. The decoupled nature of the method allows to independently perform the sim-to-real transfer of feature extractor and control policy, and the presence of the dynamics model acts as a constraint on the latent representation when finetuning the feature extractor on real-world data. We show how this architecture can allow the transfer of a trained agent from simulation to reality without retraining or finetuning the control policy, but using real-world data only for adapting the feature extractor. By avoiding training the control policy in the real domain we overcome the need to apply Reinforcement Learning on real-world data, instead, we only focus on the unsupervised training of the feature extractor, considerably reducing real-world experience collection requirements. We evaluate the method on sim-to-sim and sim-to-real transfer of a policy for table-top robotic object pushing. We demonstrate how the method is capable of adapting to considerable variations in the task observations, such as changes in point-of-view, colors, and lighting, all while substantially reducing the training time with respect to policies trained directly in the real. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3389/frobt.2022.819107,Frontiers in Robotics and AI,"We address the problem of learning relationships on state variables in Partially Observable Markov Decision Processes (POMDPs) to improve planning performance. Specifically, we focus on Partially Observable Monte Carlo Planning (POMCP) and represent the acquired knowledge with a Markov Random Field (MRF). We propose, in particular, a method for learning these relationships on a robot as POMCP is used to plan future actions. Then, we present an algorithm that deals with cases in which the MRF is used on episodes having unlikely states with respect to the equality relationships represented by the MRF. Our approach acquires information from the agent’s action outcomes to adapt online the MRF if a mismatch is detected between the MRF and the true state. We test this technique on two domains, rocksample, a standard rover exploration task, and a problem of velocity regulation in industrial mobile robotic platforms, showing that the MRF adaptation algorithm improves the planning performance with respect to the standard approach, which does not adapt the MRF online. Finally, a ROS-based architecture is proposed, which allows running the MRF learning, the MRF adaptation, and MRF usage in POMCP on real robotic platforms. In this case, we successfully tested the architecture on a Gazebo simulator of rocksample. A video of the experiments is available in the Supplementary Material, and the code of the ROS-based architecture is available online. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3389/frobt.2022.862391,Frontiers in Robotics and AI,"Biological and artificial agents are faced with many of the same computational and mechanical problems, thus strategies evolved in the biological realm can serve as inspiration for robotic development. The octopus in particular represents an attractive model for biologically-inspired robotic design, as has been recognized for the emerging field of soft robotics. Conventional global planning-based approaches to controlling the large number of degrees of freedom in an octopus arm would be computationally intractable. Instead, the octopus appears to exploit a distributed control architecture that enables effective and computationally efficient arm control. Here we will describe the neuroanatomical organization of the octopus peripheral nervous system and discuss how this distributed neural network is specialized for effectively mediating decisions made by the central brain and the continuous actuation of limbs possessing an extremely large number of degrees of freedom. We propose top-down and bottom-up control strategies that we hypothesize the octopus employs in the control of its soft body. We suggest that these strategies can serve as useful elements in the design and development of soft-bodied robotics. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3389/frobt.2023.1126033,Frontiers in Robotics and AI,"Understanding novelty and improvisation in music requires gathering insight from a variety of disciplines. One fruitful path for synthesizing these insights is via modeling. As such, my aim in this paper is to start building a bridge between traditional cognitive models and contemporary embodied and ecological approaches to cognitive science. To achieve this task, I offer a perspective on a model that would combine elements of ecological psychology (especially affordances) and the Learning Intelligent Decision Agent (LIDA) cognitive architecture. Jeff Pressing’s cognitive model of musical improvisation will also be a central link between these elements. While some overlap between these three areas already exists, there are several points of tension between them, notably concerning the nature of perception and the function of artificial general intelligence modeling. I thus aim to alleviate the most worrisome concerns here, introduce several future research questions, and conclude with several points on how my account is part of a general theory, rather than merely a redescription of existent work. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3389/frobt.2024.1372375,Frontiers in Robotics and AI,"Navigation of mobile agents in unknown, unmapped environments is a critical task for achieving general autonomy. Recent advancements in combining Reinforcement Learning with Deep Neural Networks have shown promising results in addressing this challenge. However, the inherent complexity of these approaches, characterized by multi-layer networks and intricate reward objectives, limits their autonomy, increases memory footprint, and complicates adaptation to energy-efficient edge hardware. To overcome these challenges, we propose a brain-inspired method that employs a shallow architecture trained by a local learning rule for self-supervised navigation in uncharted environments. Our approach achieves performance comparable to a state-of-the-art Deep Q Network (DQN) method with respect to goal-reaching accuracy and path length, with a similar (slightly lower) number of parameters, operations, and training iterations. Notably, our self-supervised approach combines novelty-based and random walks to alleviate the need for objective reward definition and enhance agent autonomy. At the same time, the shallow architecture and local learning rule do not call for error backpropagation, decreasing the memory overhead and enabling implementation on edge neuromorphic processors. These results contribute to the potential of embodied neuromorphic agents utilizing minimal resources while effectively handling variability. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3389/frobt.2024.1407519,Frontiers in Robotics and AI,"Predicting the consequences of the agent’s actions on its environment is a pivotal challenge in robotic learning, which plays a key role in developing higher cognitive skills for intelligent robots. While current methods have predominantly relied on vision and motion data to generate the predicted videos, more comprehensive sensory perception is required for complex physical interactions such as contact-rich manipulation or highly dynamic tasks. In this work, we investigate the interdependence between vision and tactile sensation in the scenario of dynamic robotic interaction. A multi-modal fusion mechanism is introduced to the action-conditioned video prediction model to forecast future scenes, which enriches the single-modality prototype with a compressed latent representation of multiple sensory inputs. Additionally, to accomplish the interactive setting, we built a robotic interaction system that is equipped with both web cameras and vision-based tactile sensors to collect the dataset of vision-tactile sequences and the corresponding robot action data. Finally, through a series of qualitative and quantitative comparative study of different prediction architecture and tasks, we present insightful analysis of the cross-modality influence between vision, tactile and action, revealing the asymmetrical impact that exists between the sensations when contributing to interpreting the environment information. This opens possibilities for more adaptive and efficient robotic control in complex environments, with implications for dexterous manipulation and human-robot interaction. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3389/frobt.2025.1534346,Frontiers in Robotics and AI,"The increasing integration of autonomous robotic systems across various industries necessitates adaptable social interaction capabilities. This paper presents a novel software architecture for socially adaptable robots, emphasizing simplicity, domain independence, and user influence on robotic behaviour. The architecture leverages a marketplace-based agent selection system to dynamically adapt social interaction patterns to diverse users and scenarios. Implemented using ROS2, the framework comprises four core components: scene analysis, a bidding platform, social agents, and a feedback service. A Validation through simulated experiments shows the architecture’s feasibility and adaptability, with respect to varying feedback conditions and learning rates. This work lays the foundation for scalable, adaptable, and user-friendly robotic systems, addressing key challenges in industrial and social robotics. Future improvements include enhanced scene analysis, integration of machine learning techniques, and support for more complex behavioural scripts. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3389/frobt.2025.1565837,Frontiers in Robotics and AI,"Outfitting and maintenance are important to an in-space architecture consisting of long duration missions. During such missions, crew is not continuously present; robotic agents become essential to the construction, maintenance, and servicing of complicated space assets, requiring some degree of autonomy to plan and execute tasks. There has been significant research into manipulation planning for rigid elements for in-space assembly and servicing, but flexible electrical cables, which fall under the domain of Deformable Linear Objects (DLOs), have not received such attention despite being critical components of powered space systems. Cables often have a non-zero bend equilibrium configuration, which the majority of DLO research does not consider. This article implements a model-based optimization approach to estimate cable configuration, where a design parameter of the model’s discretization level enables trading model accuracy vs computational complexity. Observed 2D cable configurations are used to improve the model via parameter estimation. The parameter estimation is validated through comparing predicted configurations based on estimated parameters to that of a real cable. The incorporation of parameter estimation to the cable model is shown to reduce prediction errors by an order of magnitude. The results of this work demonstrate some of the challenges present with robotic cable manipulation, exploring the complexities of outfitting and maintenance operations of in-space facilities, and puts forth a method for reducing the size of the state space of a cable payload while accounting for non-zero equilibrium configurations. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3389/frsip.2022.842477,Frontiers in Signal Processing,"In this paper we present Active Inference-Based Design Agent (AIDA), which is an active inference-based agent that iteratively designs a personalized audio processing algorithm through situated interactions with a human client. The target application of AIDA is to propose on-the-spot the most interesting alternative values for the tuning parameters of a hearing aid (HA) algorithm, whenever a HA client is not satisfied with their HA performance. AIDA interprets searching for the “most interesting alternative” as an issue of optimal (acoustic) context-aware Bayesian trial design. In computational terms, AIDA is realized as an active inference-based agent with an Expected Free Energy criterion for trial design. This type of architecture is inspired by neuro-economic models on efficient (Bayesian) trial design in brains and implies that AIDA comprises generative probabilistic models for acoustic signals and user responses. We propose a novel generative model for acoustic signals as a sum of time-varying auto-regressive filters and a user response model based on a Gaussian Process Classifier. The full AIDA agent has been implemented in a factor graph for the generative model and all tasks (parameter learning, acoustic context classification, trial design, etc.) are realized by variational message passing on the factor graph. All verification and validation experiments and demonstrations are freely accessible at our GitHub repository. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/a14090269,Algorithms,"The integration of different energy resources from traditional power systems presents new challenges for real-time implementation and operation. In the last decade, a way has been sought to optimize the operation of small microgrids (SMGs) that have a great variety of energy sources (PV (photovoltaic) prosumers, Genset CHP (combined heat and power), etc.) with uncertainty in energy production that results in different market prices. For this reason, metaheuristic methods have been used to optimize the decision-making process for multiple players in local and external markets. Players in this network include nine agents: three consumers, three prosumers (consumers with PV capabilities), and three CHP generators. This article deploys metaheuristic algorithms with the objective of maximizing power market transactions and clearing price. Since metaheuristic optimization algorithms do not guarantee global optima, an exhaustive search is deployed to find global optima points. The exhaustive search algorithm is implemented using a parallel computing architecture to reach feasible results in a short amount of time. The global optimal result is used as an indicator to evaluate the performance of the different metaheuristic algorithms. The paper presents results, discussion, comparison, and recommendations regarding the proposed set of algorithms and performance tests. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/a16070323,Algorithms,"Reinforcement Learning is one of the many machine learning paradigms. With no labelled data, it is concerned with balancing the exploration and exploitation of an environment with one or more agents present in it. Recently, many breakthroughs have been made in the creation of these agents for video game machine learning development, especially in first-person shooters with platforms such as ViZDoom, DeepMind Lab, and Unity’s ML-Agents. In this paper, we review the state-of-the-art of creation of Reinforcement Learning agents for use in multiplayer deathmatch first-person shooters. We selected various platforms, frameworks, and training architectures from various papers and examined each of them, analysing their uses. We compared each platform and training architecture, and then concluded whether machine learning agents can now face off against humans and whether they make for better gameplay than traditional Artificial Intelligence. In the end, we thought about future research and what researchers should keep in mind when exploring and testing this area. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/a16090412,Algorithms,"For mobile cleaning robot navigation, it is crucial to not only base the motion decisions on the ego agent’s capabilities but also to take into account other agents in the shared environment. Therefore, in this paper, we propose a deep reinforcement learning (DRL)-based approach for learning motion policy conditioned not only on ego observations of the environment, but also on incoming information about other agents. First, we extend a replay buffer to collect state observations on all agents at the scene and create a simulation setting from which to gather the training samples for DRL policy. Next, we express the incoming agent information in each agent’s frame of reference, thus making it translation and rotation invariant. We propose a neural network architecture with edge embedding layers that allows for the extraction of incoming information from a dynamic range of agents. This allows for generalization of the proposed approach to various settings with a variable number of agents at the scene. Through simulation results, we show that the introduction of edge layers improves the navigation policies in shared environments and performs better than other state-of-the-art DRL motion policy methods. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/a16100488,Algorithms,"The extent of myocardial infarction (MI) can be evaluated thanks to delayed enhancement (DE) cardiac MRI. DE MRI is an imaging technique acquired several minutes after the injection of a contrast agent where MI appears with a bright signal. The automatic myocardium segmentation in DE MRI is quite challenging, especially when MI is present, since these areas usually showcase a heterogeneous aspect in terms of shape and intensity, thus obstructing the myocardium visibility. To overcome this issue, we propose an image processing-based data augmentation algorithm where diverse synthetic cases of MI were created in two different ways: fixed and adaptive. In the first one, the training set is enlarged by a specific factor, whereas in the second, the method receives feedback from the segmentation model during training and performs the augmentation exclusively on complex cases. The method performance was evaluated in single and multi-modality settings. In this latter, information from kinetic images (Cine MRI), which are acquired along DE MRI in the same examination, is also used, and the extracted features from both modalities are fused. The results show that applying the data augmentation in a fixed fashion on a multi-modality setting leads to a more consistent segmentation of the myocardium in DE MRI. The segmentation models, which were all UNet-based architectures, can better relate MI areas with the myocardium, thus increasing its overall robustness to pathology-specific local pattern perturbations. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/a17120570,Algorithms,"This paper presents a systematic exploration of deep reinforcement learning (RL) for portfolio optimization and compares various agent architectures, such as the DQN, DDPG, PPO, and SAC. We evaluate these agents’ performance across multiple market signals, including OHLC price data and technical indicators, while incorporating different rebalancing frequencies and historical window lengths. This study uses six major financial indices and a risk-free asset as the core instruments. Our results show that CNN-based feature extractors, particularly with longer lookback periods, significantly outperform MLP models, providing superior risk-adjusted returns. DQN and DDPG agents consistently surpass market benchmarks, such as the S&P 500, in annualized returns. However, continuous rebalancing leads to higher transaction costs and slippage, making periodic rebalancing a more efficient approach to managing risk. This research offers valuable insights into the adaptability of RL agents to dynamic market conditions, proposing a robust framework for future advancements in financial machine learning. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/a18070388,Algorithms,"We examine how site-based path planning algorithms for enclosed spaces can be enhanced with situational detail. Addressing this question has led to value propositions in facility design, where there is often a call to match, map, and merge infrastructure considerations and configurations with potential implications for individual, group, and crowd flow through enclosed spaces. Responding to this question also invokes computational propositions, as facility design software is often computationally conservative with few resources devoted to simulation. We show that situational factors—the peculiarities and momentarily fleeting shifts in an individualized context that embody people in their movement through spaces—can be embedded into traditional, computationally lean path planning heuristics in ways that are actionable in widely used facility design software. We achieve this with algorithmic expansion of well-known planning algorithms using node-based architectures that permit the inclusion detail if, when, and where needed in a hyper-localized situational context that nests within site considerations. We demonstrate a proof of concept for use in the popular Unity 3D modeling platform, showing that situationally sensitive path planning can be achieved during the simulation run time of prototypical design scenarios for enclosed spaces with moving individuals, groups, and crowds. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/a18070411,Algorithms,"This paper presents an integrated digital training twin framework for adaptive aircraft maintenance education, combining real-time competence modeling, algorithmic orchestration, and cloud–edge deployment architectures. The proposed system dynamically evaluates learner skill gaps and assigns individualized training resources through a multi-objective optimization function that balances skill alignment, Bloom’s cognitive level, fidelity tier, and time efficiency. A modular orchestration engine incorporates reinforcement learning agents for policy refinement, federated learning for privacy-preserving skill analytics, and knowledge graph-based curriculum models for dependency management. Simulation results were conducted on the Pneumatic Systems training module. The system’s validation matrix provides full-cycle traceability of instructional decisions, supporting regulatory audit-readiness and institutional reporting. The digital training twin ecosystem offers a scalable, regulation-compliant, and data-driven solution for next-generation aviation maintenance training, with demonstrated operational efficiency, instructional precision, and extensibility for future expansion. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/a18080530,Algorithms,"In recent years, self-autonomous intelligent transportation applications such as drones and autonomous vehicles have seen rapid development and deployment across various countries. Within the domain of artificial intelligence, self-autonomous agents are defined as software entities capable of independently operating drones in an intelligent transport system (ITS) without human intervention. The integration of these agents into autonomous vehicles and their deployment across distributed cloud networks have increased significantly. These systems, which include drones, ground vehicles, and aircraft, are used to perform a wide range of tasks such as delivering passengers and packages within defined operational boundaries. Despite their growing utility, practical implementations face significant challenges stemming from the heterogeneity of network resources, as well as persistent issues related to security, privacy, and processing costs. To overcome these challenges, this study proposes a novel blockchain-enabled self-autonomous intelligent transport system designed for drone workflow applications. The proposed system architecture is based on a remote method invocation (RMI) client–server model and incorporates a serverless computing framework to manage processing costs. Termed the self-autonomous blockchain-enabled cost-efficient system (SBECES), the framework integrates a client and system agent mechanism governed by Q-learning and deep-learning-based policies. Furthermore, it incorporates a blockchain-based hash validation and fault-tolerant (HVFT) mechanism to ensure data integrity and operational reliability. A deep reinforcement learning (DRL)-enabled adaptive scheduler is utilized to manage drone workflow execution while meeting quality of service (QoS) constraints, including deadlines, cost-efficiency, and security. The overarching objective of this research is to minimize the total processing costs that comprise execution, communication, and security overheads, while maximizing operational rewards and ensuring the timely execution of drone-based tasks. Experimental results demonstrate that the proposed system achieves a 30% reduction in processing costs and a 29% improvement in security and privacy compared to existing state-of-the-art solutions. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/aerospace10010070,Aerospace,"The increasing number of satellites for specific space tasks makes it difficult for traditional satellite task planning that relies on ground station planning and on-board execution to fully exploit the overall effectiveness of satellites. Meanwhile, the complex and changeable environment in space also poses challenges to the management of multi-satellite systems (MSS). To address the above issues, this paper formulates a mixed integer optimization problem to solve the autonomous task planning for MSS. First, we constructed a multi-agent-based on-board autonomous management and multi-satellite collaboration architecture. Based on this architecture, we propose a hybrid genetic algorithm with simulated annealing (H-GASA) to solve the multi-satellite cooperative autonomous task planning (MSCATP). With the H-GASA, a heuristic task scheduling scheme was developed to deal with possible task conflicts in MSCATP. Finally, a simulation scenario was established to validate our proposed H-GASA, which exhibits a superior performance in terms of computational power and success rate compared to existing algorithms. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/aerospace11100812,Aerospace,"Single-Pilot Operations (SPO) mode is set to reshape the decision-making process between human-machine and air-ground operations. However, the limited on-board computing resources impose greater demands on the organization of performance parameters and the optimization of process efficiency in SPO mode. To address this challenge, this paper first investigates the flexible requirements of avionics systems arising from changes in SPO operational scenarios, then analyzes the architecture of Reconfigurable Integrated Modular Avionics (RIMA) and its resource allocation framework in the context of scarcity and configurability. A “mission-function-resource” mapping relationship is established between the reconfiguration service elements of SPO mode and avionics resources. Subsequently, the Proximal Policy Optimization (PPO) algorithm is introduced to simulate the resource allocation process of IMA reconfiguration in SPO mode. The objective optimization process is transformed into a sequential decision-making problem by considering constraints and optimization criteria such as load, latency, and power consumption within the feasible domain of avionics system resources. Finally, the resource allocation scheme for avionics system reconfiguration is determined by controlling the probability of action selection during the interaction between the agent and the environment. The experimental results show that the resource allocation scheme based on the PPO algorithm can effectively reduce power consumption and latency, and the DRL model has strong anti-interference and generalization. This enables avionics resources to respond dynamically to the capabilities required in SPO mode and enhances their ability to support the aircraft mission at all stages. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/aerospace12080687,Aerospace,"Unmanned aerial vehicles (UAVs) are widely used in surveillance and combat for their efficiency and autonomy, whilst complex, dynamic environments challenge the modeling of inter-agent relations and information transmission. This research proposes a novel UAV tactical choice-making algorithm utilizing graph neural networks to tackle these challenges. The proposed algorithm employs a graph neural network to process the observed state information, the convolved output of which is then fed into a reconstructed critic network incorporating a Laplacian convolution kernel. This research first enhances the accuracy of obtaining unstable state information in hostile environments. The proposed algorithm uses this information to train a more precise critic network. In turn, this improved critic network guides the actor network to make decisions that better meet the needs of the battlefield. Coupled with a policy transfer mechanism, this architecture significantly enhances the decision-making efficiency and environmental adaptability within the multi-agent system. Results from the experiments show that the average effectiveness of the proposed algorithm across the six planned scenarios is 97.4%, surpassing the baseline by 23.4%. In addition, the integration of transfer learning makes the network convergence speed three times faster than that of the baseline algorithm. This algorithm effectively improves the information transmission efficiency between the environment and the UAV and provides strong support for UAV formation combat. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/aerospace12080718,Aerospace,"Accurate fatigue life prediction of aircraft landing gear is crucial for ensuring flight safety and preventing catastrophic structural failures. However, traditional empirical methods face significant limitations in capturing complex multiaxial loading conditions, while machine learning approaches suffer from lack of interpretability in critical safety applications. To address the dual challenges of prediction accuracy and model interpretability, a multi-agent reinforced symbolic regression (MA-RSR) framework is proposed by integrating multi-agent reinforcement learning with symbolic regression (SR) techniques. Specifically, MA-RSR employs a collaborative mechanism that decomposes complex mathematical expressions into parallel components constructed by independent agents, effectively addressing the search space explosion problem in traditional SR. The system incorporates Transformer-based architecture to enhance symbolic selection capabilities, while an intelligent masking mechanism ensures mathematical rationality through multi-level constraints. To demonstrate effectiveness of the proposed method, validation is conducted using SAE4340 steel multiaxial fatigue data and landing gear finite element simulation. The MA-RSR framework successfully discovers two mathematical expressions achieving R2 of 0.96. Compared to traditional empirical formulas, MA-RSR achieves prediction accuracy improvements exceeding 50% while providing complete interpretability that machine learning methods lack. Furthermore, the multi-agent collaborative mechanism significantly enhances search efficiency through parallel expression construction compared to existing symbolic regression approaches. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/aerospace12090837,Aerospace,"An increased level of autonomy is attractive above all in the framework of proximity operations, and researchers are focusing more and more on artificial intelligence techniques to improve spacecraft’s capabilities in these scenarios. This work presents an autonomous AI-based guidance algorithm to plan the path of a chaser spacecraft for the map reconstruction of an artificial uncooperative target, coupled with Model Predictive Control for the tracking of the generated trajectory. Deep reinforcement learning is particularly interesting for enabling spacecraft’s autonomous guidance, since this problem can be formulated as a Partially Observable Markov Decision Process and because it leverages domain randomization well to cope with model uncertainty, thanks to the neural networks’ generalizing capabilities. The main drawback of this method is that it is difficult to verify its optimality mathematically and the constraints can be added only as part of the reward function, so it is not guaranteed that the solution satisfies them. To this end a convex Model Predictive Control formulation is employed to track the DRL-based trajectory, while simultaneously enforcing compliance with the constraints. Two neural network architectures are proposed and compared: a recurrent one and the more recent transformer. The trained reinforcement learning agent is then tested in an end-to-end AI-based pipeline with image generation in the loop, and the results are presented. The computational effort of the entire guidance and control strategy is also verified on a Raspberry Pi board. This work represents a viable solution to apply artificial intelligence methods for spacecraft’s autonomous motion, still retaining a higher level of explainability and safety than that given by more classical guidance and control approaches. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/aerospace12100914,Aerospace,"Agile satellites leverage rapid and flexible maneuvering to image more targets per orbital cycle, which is essential for time-sensitive emergency operations, particularly disaster assessment. Correspondingly, the increasing observation data volumes necessitate the use of on-orbit computing to bypass storage and transmission limitations. However, coordinating precedence-dependent observation, computation, and downlink operations within limited time windows presents key challenges for agile satellite service optimization. Therefore, this paper proposes a deep reinforcement learning (DRL) approach to solve the joint observation and on-orbit computation scheduling (JOOCS) problem for agile satellite constellations. First, the infrastructure under study consists of observation satellites, a GEO satellite (dedicated to computing), ground stations, and communication links interconnecting them. Next, the JOOCS problem is described using mathematical formulations, and then a partially observable Markov decision process model is established with the objective of maximizing task completion profits. Finally, we design a joint scheduling decision algorithm based on multiagent proximal policy optimization (JS-MAPPO). Concerning the policy network of agents, a problem-specific encoder–decoder architecture is developed to improve the learning efficiency of JS-MAPPO. Simulation results show that JS-MAPPO surpasses the genetic algorithm and state-of-the-art DRL methods across various problem scales while incurring lower computational costs. Compared to random scheduling, JOOCS achieves up to 82.67% higher average task profit, demonstrating enhanced operational performance in agile satellite constellations. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/aerospace9100599,Aerospace,"Air traffic flow management (ATFM) is of crucial importance to the European Air Traffic Control System due to two factors: first, the impact of ATFM, including safety implications on ATC operations; second, the possible consequences of ATFM measures on both airports and airlines operations. Thus, the central flow management unit continually seeks to improve traffic flow management to reduce delays and congestion. In this work, we investigated the use of reinforcement learning (RL) methods to compute policies to solve demand–capacity imbalances (a.k.a. congestion) during the pre-tactical phase. To address cases where the expected demands exceed the airspace sector capacity, we considered agents representing flights who have to decide on ground delays jointly. To overcome scalability issues, we propose using raw pixel images as input, which can represent an arbitrary number of agents without changing the system’s architecture. This article compares deep Q-learning and deep deterministic policy gradient algorithms with different configurations. Experimental results, using real-world data for training and validation, confirm the effectiveness of our approach to resolving demand–capacity balancing problems, showing the robustness of the RL approach presented in this article. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/agriengineering1020017,AgriEngineering,"Tofu is an ancient soybean product that is produced by heating soymilk containing a coagulation agent. Owing to its benefits to human health, it has become popular all over the world. An important index that determines the final product’s (tofu’s) quality is firmness. Coagulants such as CaSO<inf>4</inf> and MgCl<inf>2</inf> affect the firmness. With the increasing demand for tofu, a monitoring methodology that ensures high-quality tofu is needed. In our previous paper, an opportunity to monitor changes in the physical properties of soymilk by studying its optical properties during the coagulation process was implied. To ensure this possibility, whether soymilk and tofu can be discriminated via their optical properties should be examined. In this study, a He–Ne laser (Thorlabs Japan Inc., Tokyo, Japan, 2015) with a wavelength of 633 nm was emitted to soymilk and tofu. The images of the scattered light on their surfaces were discriminated using a type of deep learning technique. As a result, the images were classified with an accuracy of about 99%. We adjusted the network architecture and hyperparameters for the learning, and this contributed to the successful classification. The construction of a network that is specific to our task led to the successful classification result. In addition to this monitoring method of the tofu coagulation process, the classification methodology in this study is worth noting for possible use in many relevant agricultural fields. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/analytics2030031,Analytics,"We present a hierarchical reinforcement learning (RL) architecture that employs various low-level agents to act in the trading environment, i.e., the market. The highest-level agent selects from among a group of specialized agents, and then the selected agent decides when to sell or buy a single asset for a period of time. This period can be variable according to a termination function. We hypothesized that, due to different market regimes, more than one single agent is needed when trying to learn from such heterogeneous data, and instead, multiple agents will perform better, with each one specializing in a subset of the data. We use k-meansclustering to partition the data and train each agent with a different cluster. Partitioning the input data also helps model-based RL (MBRL), where models can be heterogeneous. We also add two simple decision-making models to the set of low-level agents, diversifying the pool of available agents, and thus increasing overall behavioral flexibility. We perform multiple experiments showing the strengths of a hierarchical approach and test various prediction models at both levels. We also use a risk-based reward at the high level, which transforms the overall problem into a risk-return optimization. This type of reward shows a significant reduction in risk while minimally reducing profits. Overall, the hierarchical approach shows significant promise, especially when the pool of low-level agents is highly diverse. The usefulness of such a system is clear, especially for human-devised strategies, which could be incorporated in a sound manner into larger, powerful automatic systems. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app10030945,Applied Sciences (Switzerland),"Arbuscular mycorrhizal fungi (AMF) and plant growth-promoting rhizobacteria (PGPR) are considered highly-efficient agents for conferring salt tolerance in host plants and improving soil fertility in rhizosphere. However, information about the inoculation of beneficial microbes on halophytes in arid and semi-arid regions remains inadequate. The objective of this study was to evaluate the influence of AMF (Glomus mosseae) inoculation, alone or in combination with PGPR (Bacillus amyloliquefaciens), on biomass accumulation, morphological characteristics, photosynthetic capacity, and rhizospheric soil enzyme activities of Elaeagnus angustifolia L., a typical halophyte in the northwest of China. The results indicate that, for one-year-old seedlings of Elaeagnus angustifolia L., AMF significantly promoted biomass accumulation in aboveground organs, increased the numbers of leaves and branches, and improved the leaf areas, stem diameters and plant height. AMF-mediated morphological characteristics of aboveground organs favored light interception and absorption and maximized the capacities for photosynthesis, transpiration, carbon dioxide assimilation and gas exchange of Elaeagnus angustifolia L. seedlings in saline soil. AMFalso promoted root growth, modified root architecture, and enhanced soil enzyme activities. Elaeagnus angustifolia L. was more responsive to specific inoculation by AMF than by a combination of AMF and PGPR or by solely PGPR in saline soils. Therefore, we suggest that G. mosseae can be used in saline soil to enhance Elaeagnus angustifolia L. seedlings growth and improve soil nutrient uptake. This represents a biological technique to aid in restoration of saline-degraded areas. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app10031086,Applied Sciences (Switzerland),"Almost every research project that focuses on the cooperation of autonomous robots for underwater operations designs their own architectures. As a result, most of these architectures are tightly coupled with the available robots/vehicles for their respective developments, and therefore the mission plan and management is done using an ad-hoc solution. Typically, this solution is tightly coupled to just one underwater autonomous vehicle (AUV), or a restricted set of them selected for the specific project. However, as the use of AUVs for underwater operations increases, there is the need to identify some commonalities and weaknesses of these architectures, specifically in relation to mission planning and management. In this paper, we review a selected number of architectures and frameworks that in one way or another make use of different approaches to mission planning and management. Most of the selected works were developed for underwater operations. Still, we have included some other architectures and frameworks from other domains that can be of interest for the survey. The explored works have been assessed using selected features related to mission planning and management, considering that underwater operations are performed in an uncertain and unreliable environment, and where unexpected events are not strange. Furthermore, we have identified and highlighted some potential challenges for the design and implementation of mission managers. This provides a reference point for the development of a mission manager component to be integrated in architectures for cooperative robotics in underwater operations, and it can serve for the same purposes in other domains of application. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app10114011,Applied Sciences (Switzerland),"Persistent congestions which are varying in strength and duration in the dense traffic networks are the most prominent obstacle towards sustainable mobility. Those types of congestions cannot be adequately resolved by the traditional Adaptive Traffic Signal Control (ATSC). The introduction of Reinforcement Learning (RL) in ATSC as tackled those types of congestions by using on-line learning, which is based on the trial and error approach. Furthermore, RL is prone to the dimensionality curse related to the state-action space size based on which a non-linear quality function is derived. The Deep Reinforcement Learning (DRL) framework uses Deep Neural Networks (DNN) to digest raw traffic data to approximate the quality function of RL. This paper provides a comprehensive analysis of the most recent DRL approaches used for the ATSC algorithm design. Special emphasis is set to overview of the traffic state representation and multi-agent DRL frameworks applied for the large traffic networks. Best practices are provided for choosing the adequate DRL model, hyper-parameters tuning, and model architecture design. Finally, this paper provides a discussion about the importance of the open traffic data concept for the extensive application of DRL in the real world ATSC. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app10238386,Applied Sciences (Switzerland),"In this paper, we formulate the active SLAM paradigm in terms of model-free Deep Reinforcement Learning, embedding the traditional utility functions based on the Theory of Optimal Experimental Design in rewards, and therefore relaxing the intensive computations of classical approaches. We validate such formulation in a complex simulation environment, using a state-of-the-art deep Q-learning architecture with laser measurements as network inputs. Trained agents become capable not only to learn a policy to navigate and explore in the absence of an environment model but also to transfer their knowledge to previously unseen maps, which is a key requirement in robotic exploration. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app10249013,Applied Sciences (Switzerland),"In this investigation, the nonlinear swing-up problem associated with the cart-pole system modeled as a multibody dynamical system is solved by developing a deep Reinforcement Learning (RL) controller. Furthermore, the sensitivity analysis of the deep RL controller applied to the cart-pole swing-up problem is carried out. To this end, the influence of modifying the physical properties of the system and the presence of dry friction forces are analyzed employing the cumulative reward during the task. Extreme limits for the modifications of the parameters are determined to prove that the neural network architecture employed in this work features enough learning capability to handle the task under modifications as high as 90% on the pendulum mass, as well as a 100% increment on the cart mass. As expected, the presence of dry friction greatly affects the performance of the controller. However, a post-training of the agent in the modified environment takes only thirty-nine episodes to find the optimal control policy, resulting in a promising path for further developments of robust controllers. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app11083710,Applied Sciences (Switzerland),"In this paper, we present and discuss an innovative approach to solve Job Shop scheduling problems based on machine learning techniques. Traditionally, when choosing how to solve Job Shop scheduling problems, there are two main options: either use an efficient heuristic that provides a solution quickly, or use classic optimization approaches (e.g., metaheuristics) that take more time but will output better solutions, closer to their optimal value. In this work, we aim to create a novel architecture that incorporates reinforcement learning into scheduling systems in order to improve their overall performance and overcome the limitations that current approaches present. It is also intended to investigate the development of a learning environment for reinforcement learning agents to be able to solve the Job Shop scheduling problem. The reported experimental results and the conducted statistical analysis conclude about the benefits of using an intelligent agent created with reinforcement learning techniques. The main contribution of this work is proving that reinforcement learning has the potential to become the standard method whenever a solution is necessary quickly, since it solves any problem in very few seconds with high quality, approximate to the optimal methods. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app11136097,Applied Sciences (Switzerland),"The importance of electricity in people’s daily lives has made it an indispensable commodity in society. In electricity market, the price of electricity is the most important factor for each of those involved in it, therefore, the prediction of the electricity price has been an essential and very important task for all the agents involved in the purchase and sale of this good. The main problem within the electricity market is that prediction is an arduous and difficult task, due to the large number of factors involved, the non-linearity, non-seasonality and volatility of the price over time. Data Science methods have proven to be a great tool to capture these difficulties and to be able to give a reliable prediction using only price data, i.e., taking the problem from an univariate point of view in order to help market agents. In this work, we have made a comparison among known models in the literature, focusing on Deep Learning architectures by making an extensive tuning of parameters using data from the Spanish electricity market. Three different time periods have been used in order to carry out an extensive comparison among them. The results obtained have shown, on the one hand, that Deep Learning models are quite effective in predicting the price of electricity and, on the other hand, that the different time periods and their particular characteristics directly influence the final results of the models. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app112110308,Applied Sciences (Switzerland),"Chemical reconnaissance, defined as hazards detection, identification, and monitoring, requires tools and solutions which provide reliable and precise data. In this field, the advances of artificial intelligence can be applied. This article aims to propose a novel approach for developing a chemical reconnaissance system that relies on machine learning, modelling algorithms, as well as the contaminant dispersion model to combine signals from different sensors and reduce false alarm rates. A case study of the European Union Horizon 2020 project–EU-SENSE is used and the main features of the system are analysed: heterogeneous sensor nodes components, chemical agents to be detected, and system architecture design. Through the proposed approach, chemical reconnaissance capabilities are improved, resulting in more effective crisis management. The idea for the system design can be used and developed in other areas, namely, in biological or radiological threat reconnaissance. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app112110337,Applied Sciences (Switzerland),"Scaling end-to-end learning to control robots with vision inputs is a challenging problem in the field of deep reinforcement learning (DRL). While achieving remarkable success in complex sequential tasks, vision-based DRL remains extremely data-inefficient, especially when dealing with high-dimensional pixels inputs. Many recent studies have tried to leverage state representation learning (SRL) to break through such a barrier. Some of them could even help the agent learn from pixels as efficiently as from states. Reproducing existing work, accurately judging the improvements offered by novel methods, and applying these approaches to new tasks are vital for sustaining this progress. However, the demands of these three aspects are seldom straightforward. Without signifi-cant criteria and tighter standardization of experimental reporting, it is difficult to determine whether improvements over the previous methods are meaningful. For this reason, we conducted ablation studies on hyperparameters, embedding network architecture, embedded dimension, regularization methods, sample quality and SRL methods to compare and analyze their effects on representation learning and reinforcement learning systematically. Three evaluation metrics are summarized, including five baseline algorithms (including both value-based and policy-based methods) and eight tasks are adopted to avoid the particularity of each experiment setting. We highlight the variability in reported methods and suggest guidelines to make future results in SRL more reproducible and stable based on a wide number of experimental analyses. We aim to spur discussion about how to assure continued progress in the field by minimizing wasted effort stemming from results that are non-reproducible and easily misinterpreted. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app112110445,Applied Sciences (Switzerland),"Path planning is a fundamental issue in robotic systems because it requires coordination between the environment and an agent. The path-planning generator is composed of two modules: perception and planning. The first module scans the environment to determine the location, detect obstacles, estimate objects in motion, and build the planner module’s restrictions. On the other hand, the second module controls the flight of the system. This process is computationally expensive and requires adequate performance to avoid accidents. For this reason, we propose a novel solution to improve conventional robotic systems’ functions, such as systems having a small-capacity battery, a restricted size, and a limited number of sensors, using fewer elements. A navigation dataset was generated through a virtual simulator and a generative adversarial network to connect the virtual and real environments under an end-to-end approach. Furthermore, three path generators were analyzed using deep-learning solutions: a deep convolutional neural network, hierarchical clustering, and an auto-encoder. Since the path generators share a characteristic vector, transfer learning approaches complex problems by using solutions with fewer features, minimizing the costs and optimizing the resources of conventional system architectures, thus improving the limitations with respect to the implementation in embedded devices. Finally, a visualizer applying augmented reality was used to display the path generated by the proposed system. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app12094712,Applied Sciences (Switzerland),"Object tracking is the process of estimating in time N the location of one or more moving element through an agent (camera, sensor, or other perceptive device). An important application in object tracking is the analysis of animal behavior to estimate their health. Traditionally, experts in the field have performed this task. However, this approach requires a high level of knowledge in the area and sufficient employees to ensure monitoring quality. Another alternative is the application of sensors (inertial and thermal), which provides precise information to the user, such as location and temperature, among other data. Nevertheless, this type of analysis results in high infrastructure costs and constant maintenance. Another option to overcome these problems is to analyze an RGB image to obtain information from animal tracking. This alternative eliminates the reliance on experts and different sensors, yet it adds the challenge of interpreting image ambiguity correctly. Taking into consideration the aforementioned, this article proposes a methodology to analyze lamb behavior from an approach based on a predictive model and deep learning, using a single RGB camera. This method consists of two stages. First, an architecture for lamb tracking was designed and implemented using CNN. Second, a predictive model was designed for the recognition of animal behavior. The results obtained in this research indicate that the proposed methodology is feasible and promising. In this sense, according to the experimental results on the used dataset, the accuracy was 99.85% for detecting lamb activities with YOLO<inf>V4</inf>, and for the proposed predictive model, a mean accuracy was 83.52% for detecting abnormal states. These results suggest that the proposed methodology can be useful in precision agriculture in order to take preventive actions and to diagnose possible diseases or health problems. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app12136629,Applied Sciences (Switzerland),"In this paper, the application of the policy gradient Reinforcement Learning-based (RL) method for obstacle avoidance is proposed. This method was successfully used to control the move-ments of a robot using trial-and-error interactions with its environment. In this paper, an approach based on a Deep Deterministic Policy Gradient (DDPG) algorithm combined with a Hindsight Experience Replay (HER) algorithm for avoiding obstacles has been investigated. In order to ensure that the robot avoids obstacles and reaches the desired position as quickly and as accurately as possible, a special approach to the training and architecture of two RL agents working simultaneously was proposed. The implementation of this RL-based approach was first implemented in a simulation environment, which was used to control the 6-axis robot simulation model. Then, the same algorithm was used to control a real 6-DOF (degrees of freedom) robot. The results obtained in the simulation were compared with results obtained in laboratory conditions. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app12147186,Applied Sciences (Switzerland),"Imitation learning is a discipline of machine learning primarily concerned with replicating observed behavior of agents known to perform well on a given task, collected in demonstration data sets. In this paper, we set out to introduce a pipeline for collecting demonstrations and training models that can produce motion plans for industrial robots. Object throwing is defined as the motivating use case. Multiple input data modalities are surveyed, and motion capture is selected as the most practicable. Two model architectures operating autoregressively are examined—feedforward and recurrent neural networks. Trained models execute throws on a real robot successfully, and a battery of quantitative evaluation metrics is proposed. Recurrent neural networks outperform feedforward ones in most respects, but this advantage is not universal or conclusive. The data collection, pre-processing and model training aspects of our proposed approach show promise, but further work is required in developing Cartesian motion planning tools before it is applicable in production applications. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app12157690,Applied Sciences (Switzerland),"The ubiquity of smart devices and intelligent technologies embedded in e-learning settings fuels the drive to tackle the grand challenge of personalised adaptive learning. Personalised adaptive learning, which combines the core concepts of personalised learning and adaptive learning, attempts to take individual needs and features into account for personal development through adaptive adjustment. Personalised adaptive learning is supported at its heart by efficient real-time monitoring of the learning process and robust managerial capabilities, which are driven by data, as well as human intuition. The absence of reusable personalised content and logic is one of the key limitations of systems that adopt personalised learning. This is mostly due to the fact that business logic is frequently entangled with the system’s primary functionality. As a result, such systems are unable to interact with other systems that do not adhere to identical design standards. The application of modular frameworks and the semantic web has the potential to be leading technologies that foster reusable personalised content and systems that can efficiently share information. WASPEC, a modular framework for personalised adaptive learning, is evaluated in this paper. An improved architecture, WASPEC 2.0, ensuring more flexibility is also presented in the concluding sections. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app122010343,Applied Sciences (Switzerland),"Media applications are amongst the most demanding services. They require high amounts of network capacity as well as computational resources for synchronous high-quality audio–visual streaming. Recent technological advances in the domain of new generation networks, specifically network virtualization and Multiaccess Edge Computing (MEC) have unlocked the potential of the media industry. They enable high-quality media services through dynamic and efficient resource allocation taking advantage of the flexibility of the layered architecture offered by 5G. The presented work demonstrates the potential application of Artificial Intelligence (AI) capabilities for multimedia services deployment. The goal was targeted to optimize the Quality of Experience (QoE) of real-time video using dynamic predictions by means of Deep Reinforcement Learning (DRL) algorithms. Specifically, it contains the initial design and test of a self-optimized cloud streaming proof-of-concept. The environment is implemented through a virtualized end-to-end architecture for multimedia transmission, capable of adapting streaming bitrate based on a set of actions. A prediction algorithm is trained through different state conditions (QoE, bitrate, encoding quality, and RAM usage) that serves the optimizer as the encoding values of the environment for action prediction. Optimization is applied by selecting the most suitable option from a set of actions. These consist of a collection of predefined network profiles with associated bitrates, which are validated by a list of reward functions. The optimizer is built employing the most prominent algorithms in the DRL family, with the use of two Neural Networks (NN), named Advantage Actor–Critic (A2C). As a result of its application, the ratio of good quality video segments increased from 65% to 90%. Furthermore, the number of image artifacts is reduced compared to standard sessions without applying intelligent optimization. From these achievements, the global QoE obtained is clearly better. These results, based on a simulated scenario, increase the interest in further research on the potential of applying intelligence to enhance the provisioning of media services under real conditions. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app122211797,Applied Sciences (Switzerland),"Facial emotion recognition (FER) is an important and developing topic of research in the field of pattern recognition. The effective application of facial emotion analysis is gaining popularity in surveillance footage, expression analysis, activity recognition, home automation, computer games, stress treatment, patient observation, depression, psychoanalysis, and robotics. Robot interfaces, emotion-aware smart agent systems, and efficient human–computer interaction all benefit greatly from facial expression recognition. This has garnered attention as a key prospect in recent years. However, due to shortcomings in the presence of occlusions, fluctuations in lighting, and changes in physical appearance, research on emotion recognition has to be improved. This paper proposes a new architecture design of a convolutional neural network (CNN) for the FER system and contains five convolution layers, one fully connected layer with rectified linear unit activation function, and a SoftMax layer. Additionally, the feature map enhancement is applied to accomplish a higher detection rate and higher precision. Lastly, an application is developed that mitigates the effects of the aforementioned problems and can identify the basic expressions of human emotions, such as joy, grief, surprise, fear, contempt, anger, etc. Results indicate that the proposed CNN achieves 92.66% accuracy with mixed datasets, while the accuracy for the cross dataset is 94.94%. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app13053090,Applied Sciences (Switzerland),"Neural network-based solutions have revolutionized the field of computer vision by achieving outstanding performance in a number of applications. Yet, while these deep learning models outclass previous methods, they still have significant shortcomings relating to generalization and robustness to input disturbances, such as occlusion. Most existing methods that tackle this latter problem use passive neural network architectures that are unable to act on and, thus, influence the observed scene. In this paper, we argue that an active observer agent may be able to achieve superior performance by changing the parameters of the scene, thus, avoiding occlusion by moving to a different position in the scene. To demonstrate this, a reinforcement learning environment is introduced that implements OpenAI Gym’s interface, and allows the creation of synthetic scenes with realistic occlusion. The environment is implemented using differentiable rendering, allowing us to perform direct gradient-based optimization of the camera position. Moreover, two additional methods are also presented, one utilizing self-supervised learning to predict occlusion segments, and optimal camera positions, while the other learns to avoid occlusion using Reinforcement Learning. We present comparative experiments of the proposed methods to demonstrate their efficiency. It was shown, via Bayesian t-tests, that the neural network-based methods credibly outperformed the gradient-based avoidance strategy by avoiding occlusion with an average of 5.0 fewer steps in multi-object scenes. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app13084808,Applied Sciences (Switzerland),"The ability to supply increasingly individualized market demand in a short period of time while maintaining costs to a bare minimum might be considered a vital factor for industrialized countries’ competitive revival. Despite significant advances in the field of Industry 4.0, there is still an open gap in the literature regarding advanced methodologies for production planning and control. Among different production and control approaches, hybrid architectures are gaining huge interest in the literature. For such architectures to operate at their best, reliable models for performance prediction of the supervised production system are required. In an effort to advance the development of hybrid architecture, this paper develops a model able to predict the performance of the controlled system when it is structured as a controlled work-in-progress (CONWIP) flow-shop with generalized stochastic processing times. To achieve this, we employed a simulation tool using both discrete-event and agent-based simulation techniques, which was then utilized to generate data for training a deep learning neural network. This network was proposed for estimating the throughput of a balanced system, together with a normalization method to generalize the approach. The results showed that the developed estimation tool outperforms the best-known approximated mathematical models while allowing one-shot training of the network. Finally, the paper develops preliminary insights about generalized performance estimation for unbalanced lines. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app131810160,Applied Sciences (Switzerland),"Dynamic Contrast Enhanced Magnetic Resonance Imaging (DCE-MRI) is regarded as one of the main diagnostic tools for breast cancer. Several methodologies have been developed to automatically localize suspected malignant breast lesions. Changes in tissue appearance in response to the injection of the contrast agent (CA) are indicative of the presence of malignant breast lesions. However, these changes are extremely similar to the ones of internal organs, such as the heart. Thus, the task of chest cavity segmentation is necessary for the development of lesion detection. In this work, a data-efficient approach is proposed, to automatically segment breast MRI data. Specifically, a study on several UNet-like architectures (Dynamic UNet) based on ResNet is presented. Experiments quantify the impact of several additions to baseline models of varying depth, such as self-attention and the presence of a bottlenecked connection. The proposed methodology is demonstrated to outperform the current state of the art both in terms of data efficiency and in terms of similarity index when compared to manually segmented data. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app14199018,Applied Sciences (Switzerland),"When multiple objects are positioned close together or stacked, pre-grasp operations such as pushing objects can be used to create space for the grasp, thereby improving the grasping success rate. This study develops a model based on a deep Q-learning network architecture and introduces a fully convolutional network to accurately identify pixels in the workspace image that correspond to target locations for exploration. In addition, this study incorporates image masking to limit the exploration area of the robotic arm, ensuring that the agent consistently explores regions containing objects. This approach effectively addresses the sparse reward problem and improves the convergence rate of the model. Experimental results from both simulated and real-world environments show that the proposed method accelerates the learning of effective grasping strategies. When image masking is applied, the success rate in the grasping task reaches 80% after 600 iterations. The time required to reach 80% success rate is 25% shorter when image masking is used compared to when it is not used. The main finding of this study is the direct integration of image masking technique with a deep reinforcement learning (DRL) algorithm, which offers significant advancement in robotic arm control. Furthermore, this study shows that image masking technique can substantially reduce training time and improve the object grasping success rate. This innovation enables the robotic arm to better adapt to scenarios that conventional DRL methods cannot handle, thereby improving training efficiency and performance in complex and dynamic industrial applications. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app15010162,Applied Sciences (Switzerland),"A reinforcement learning control method for a solid attitude and divert propulsion system is proposed. The system in this study includes four divert thrust nozzles, six attitude thrust nozzles, and a common combustion chamber. To achieve the required thrust, the pressure in the combustion chamber is first adjusted by controlling the total opening of the nozzles to generate the gas source. Next, by controlling the opening of nozzles at different positions, the required thrust is produced in the five-axis direction. Finally, the motor speed is regulated to drive the valve core to the specified position, completing the closed-loop control of the nozzle opening. The control algorithm used is the Proximal Policy Optimization (PPO) reinforcement learning algorithm. Through system identification and numerical modeling, the training environment for the intelligent agent is created. To accommodate different training objectives, multiple reward functions are implemented. Ultimately, through training, a multi-layer intelligent agent architecture for pressure, thrust, and nozzle opening is established, achieving effective system pressure and thrust control. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app15052473,Applied Sciences (Switzerland),"In recent years, multi-task learning (MTL) has been shown to have considerable potential for enhancing model performance through the inter-task sharing of knowledge. Nevertheless, the effective balancing of optimization across diverse tasks remains a significant challenge. This paper presents a novel Deep Reinforcement Learning (DRL)-based framework that employs an Actor-Critic architecture to dynamically adjust task weights. In contrast to traditional methodologies that depend on heuristic rules or predefined assumptions about inter-task relationships, our approach autonomously learns optimal weighting strategies through interactions between an intelligent agent and the multi-task environment. The experimental results obtained across multiple datasets demonstrate that our method not only enhances overall performance and achieves a more balanced distribution of tasks but also maintains high training efficiency. Furthermore, the framework’s robust generalization and adaptability make it well-suited for addressing complex and dynamic learning scenarios. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app15052490,Applied Sciences (Switzerland),"The Minesweeper game is modeled as a sequential decision-making task, for which a neural network architecture, state encoding, and reward function were herein designed. Both a Deep Q-Network (DQN) and supervised learning methods were successfully applied to optimize the training of the game. The experiments were conducted on the AutoDL platform using an NVIDIA RTX 3090 GPU for efficient computation. The results showed that in a 6 × 6 grid with four mines, the DQN model achieved an average win rate of 93.3% (standard deviation: 0.77%), while the supervised learning method achieved 91.2% (standard deviation: 0.9%), both outperforming human players and baseline algorithms and demonstrating high intelligence. The mechanisms of the two methods in the Minesweeper task were analyzed, with the reasons for the faster training speed and more stable performance of supervised learning explained from the perspectives of means–ends analysis and feedback control. Although there is room for improvement in sample efficiency and training stability in the DQN model, its greater generalization ability makes it highly promising for application in more complex decision-making tasks. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app15094851,Applied Sciences (Switzerland),"With the rapid advancement of network technologies, cyberthreats have become increasingly sophisticated, posing significant challenges to traditional intrusion detection systems. Conventional machine learning and deep learning approaches frequently experience performance degradation when confronted with imbalanced datasets and novel attack vectors. To address these limitations, this study proposes a deep learning-based intrusion detection framework that employs feature fusion through incremental transfer learning between source and target domains. The proposed architecture integrates convolutional neural networks (CNNs) with an attention mechanism to extract and aggregate salient features, thereby enhancing the model’s discriminative capacity between normal traffic and various network attack categories. Experimental results demonstrate that the proposed model achieves a detection accuracy of 94.21% even when trained on only 33% of the available data, outperforming conventional models. These findings underscore the effectiveness of the proposed feature fusion strategy via transfer learning in improving detection capabilities within dynamic and evolving cyberthreat environments. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app15137579,Applied Sciences (Switzerland),"Multi-agent large language models promise flexible, modular architectures for delivering personalized educational content. Drawing on a pilot randomized controlled trial with middle school students (n = 23), we introduce a two-agent GPT-4 framework in which a Profiler agent infers learner-specific preferences and a Rewrite agent dynamically adapts science passages via an explicit message-passing protocol. We implement structured system and user prompts as inter-agent communication schemas to enable real-time content adaptation. The results of an ordinal logistic regression analysis hinted that students may be more likely to prefer texts aligned with their profile, demonstrating the feasibility of multi-agent system-driven personalization and highlighting the need for additional work to build upon this pilot study. Beyond empirical validation, we present a modular multi-agent architecture detailing agent roles, communication interfaces, and scalability considerations. We discuss design best practices, ethical safeguards, and pathways for extending this framework to collaborative agent networks—such as feedback-analysis agents—in K-12 settings. These results advance both our theoretical and applied understanding of multi-agent LLM systems for personalized learning. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app15158411,Applied Sciences (Switzerland),"Vision-based end-to-end navigation systems have shown impressive capabilities, especially when combined with Imitation Learning (IL) and advanced Deep Learning architectures, such as Transformers. One such example is CIL++, a Transformer-based architecture that learns to map navigation states to vehicle controls based on expert demonstrations only. Nevertheless, reliance on experts’ datasets limits generalization and can lead to failures in unknown circumstances. Deep Reinforcement Learning (DRL) can address this issue by fine-tuning the pretrained policy, using a reward function that aims to improve its weaknesses through interaction with the environment. However, fine-tuning with DRL can lead to the Catastrophic Forgetting (CF) problem, where a policy forgets the expert behaviors learned from the demonstrations as it learns to optimize the new reward function. In this paper, we present CILRLv3, a DRL-based training method that is immune to CF, enabling pretrained navigation agents to improve their driving skills across new scenarios. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app15158508,Applied Sciences (Switzerland),"This study presents a DIKWP-driven artificial consciousness framework for IoT-enabled smart healthcare, integrating a Data–Information–Knowledge–Wisdom–Purpose (DIKWP) cognitive architecture with a software-defined IoT infrastructure. The proposed system deploys DIKWP agents at edge and cloud nodes to transform raw sensor data into high-level knowledge and purpose-driven actions. This is achieved through a structured DIKWP pipeline—from data acquisition and information processing to knowledge extraction, wisdom inference, and purpose-driven decision-making—that enables semantic reasoning, adaptive goal-driven responses, and privacy-preserving decision-making in healthcare environments. The architecture integrates wearable sensors, edge computing nodes, and cloud services to enable dynamic task orchestration and secure data fusion. For evaluation, a smart healthcare scenario for early anomaly detection (e.g., arrhythmia and fever) was implemented using wearable devices with coordinated edge–cloud analytics. Simulated experiments on synthetic vital sign datasets achieved approximately 98% anomaly detection accuracy and up to 90% reduction in communication overhead compared to cloud-centric solutions. Results also demonstrate enhanced explainability via traceable decisions across DIKWP layers and robust performance under intermittent connectivity. These findings indicate that the DIKWP-driven approach can significantly advance IoT-based healthcare by providing secure, explainable, and adaptive services aligned with clinical objectives and patient-centric care. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app15168972,Applied Sciences (Switzerland),"Autonomous driving is a complex and fast-evolving domain at the intersection of robotics, machine learning, and control systems. This paper provides a systematic review of recent developments in reinforcement learning (RL) and imitation learning (IL) approaches for autonomous vehicle control, with a dedicated focus on the CARLA simulator, an open-source, high-fidelity platform that has become a standard for learning-based autonomous vehicle (AV) research. We analyze RL-based and IL-based studies, extracting and comparing their formulations of state, action, and reward spaces. Special attention is given to the design of reward functions, control architectures, and integration pipelines. Comparative graphs and diagrams illustrate performance trade-offs. We further highlight gaps in generalization to real-world driving scenarios, robustness under dynamic environments, and scalability of agent architectures. Despite rapid progress, existing autonomous driving systems exhibit significant limitations. For instance, studies show that end-to-end reinforcement learning (RL) models can suffer from performance degradation of up to 35% when exposed to unseen weather or town conditions, and imitation learning (IL) agents trained solely on expert demonstrations exhibit up to 40% higher collision rates in novel environments. Furthermore, reward misspecification remains a critical issue—over 20% of reported failures in simulated environments stem from poorly calibrated reward signals. Generalization gaps, especially in RL, also manifest in task-specific overfitting, with agents failing up to 60% of the time when faced with dynamic obstacles not encountered during training. These persistent shortcomings underscore the need for more robust and sample-efficient learning strategies. Finally, we discuss hybrid paradigms that integrate IL and RL, such as Generative Adversarial IL, and propose future research directions. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app15169218,Applied Sciences (Switzerland),"The rapid development of the Internet of Things (IoT) has enabled the implementation of interconnected intelligent systems in extremely dynamic contexts with limited resources. However, traditional paradigms, such as those using ECC-based heuristics and centralised decision-making frameworks, cannot be modernised to ensure resilience, scalability and security while taking quantum threats into account. In this case, we propose a modular architecture that integrates quantum-inspired cryptography (QI), epistemic uncertainty reasoning, the multiscale blockchain MuReQua, and the quantum-inspired decentralised storage engine (DeSSE) with fragmented entropy storage. Each component addresses specific cybersecurity weaknesses of IoT devices: quantum-resistant communication on epistemic agents that facilitate cognitive decision-making under uncertainty, lightweight adaptive consensus provided by MuReQua, and fragmented entropy storage provided by DeSSE. Tested through simulations and use case analyses in industrial, healthcare and automotive networks, the architecture shows exceptional latency, decision accuracy and fault tolerance compared to conventional solutions. Furthermore, its modular nature allows for incremental integration and domain-specific customisation. By adding reasoning, trust and quantum security, it is possible to design intelligent decentralised architectures for resilient IoT ecosystems, thereby strengthening system defences alongside architectures. In turn, this work offers a specific architectural response and a broader perspective on secure decentralised computing, even for the imminent advent of quantum computers. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app15179782,Applied Sciences (Switzerland),"Featured Application: This study supports the use of magnetic scaffolds with triply periodic minimal surface architecture as engineered agents for radiofrequency hyperthermia, highlighting their potential in targeted cancer treatment through improved thermal planning and predictable heat transfer behavior. Deep-seated tumors are challenging pathologies to treat. Currently available approaches are limited, prompting innovative solutions. Hyperthermia treatment (HT) is a thermal oncological therapy that raises tumor temperature (40–44 °C for 60 min), enhancing radio- and chemotherapy. Biomaterials loaded with magnetic particles, called magnetic scaffolds (MagSs), are used as HT agents for cancer treatment using radiofrequency (RF) heating. MagSs can be manufactured via 3D printing using fused deposition modeling to create biomimetic architectures based on triply periodic minimal surfaces (TPMSs). TPMS-based MagSs have been tested in vitro for RF HT. However, there is a lack of understanding regarding the thermal properties of TPMS MagSs for RF hyperthermia. Significant discrepancies between simulated and measured temperatures have been reported, attributed to limited knowledge of the apparent thermal conductivity of MagSs. Since planning is crucial for HT, it is fundamental to determine the thermal properties of these heterogeneous and porous composite biomaterials. Magnetic polylactic acid (PLA) scaffolds, shaped in different TPMS geometries and variable porosities, were thermally investigated in this research study. A linear relationship was found between the apparent thermal conductivity of parallelepiped and cylindrical scaffolds, and the measured values were validated using a numerical model of the RF HT test. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app151910634,Applied Sciences (Switzerland),"Language learners increasingly rely on intelligent digital tools to supplement their learning experiences, yet existing chatbots often provide limited support, lacking adaptability, personalization, or domain-specific intelligence. This study introduces a novel AI-powered multi-agent chatbot architecture designed to support English–Arabic translation and language learning. Developed through a three-phase methodology, offline preparation, real-time deployment, and evaluation, the system employs both retrieval-based and generative AI models, with specialized agents managing tasks such as translation, example retrieval, user translation review, and learning feedback. The chatbot was developed using a hybrid architecture incorporating fine-tuned Generative Pre-trained Transformer (GPT) model, sentence embedding techniques, and similarity evaluation metrics. A user study involving 40 undergraduate students and 4 faculty members evaluated the system across usability, effectiveness, and pedagogical value. Results show that the multi-agent chatbot significantly enhanced learner engagement, provided accurate and contextually appropriate language support, and was positively received by both students and instructors. These findings demonstrate the value of multi-agent design in language learning applications and highlight the potential of AI-driven chatbots as intelligent educational assistants. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app152010945,Applied Sciences (Switzerland),"The increasing complexity of urban traffic networks has highlighted the potential of Multi-Agent Reinforcement Learning (MARL) for Traffic Signal Control (TSC). However, most existing MARL methods assume homogeneous observation and action spaces among agents, ignoring the inherent heterogeneity of real-world intersections in topology and signal phasing, which limits their practical applicability. To address this gap, we propose HAPS-PPO (Heterogeneity-Aware Policy Sharing Proximal Policy Optimization), a novel MARL framework for coordinated signal control in heterogeneous road networks. HAPS-PPO integrates two key mechanisms: an Observation Padding Wrapper (OPW) that standardizes varying observation dimensions, and a Dynamic Multi-Strategy Grouping Learning (DMSGL) mechanism that trains dedicated policy heads for agent groups with distinct action spaces, enabling adequate knowledge sharing while maintaining structural correctness. Comprehensive experiments in a high-fidelity simulation environment based on a real-world road network demonstrate that HAPS-PPO significantly outperforms Fixed-time control and mainstream MARL baselines (e.g., MADQN, FMA2C), reducing average delay time by up to 44.74% and average waiting time by 59.60%. This work provides a scalable and plug-and-play solution for deploying MARL in realistic, heterogeneous traffic networks. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app152011053,Applied Sciences (Switzerland),"STEM (Science, Technology, Engineering, and Mathematics) education faces the challenge of incorporating advanced technologies that foster motivation, collaboration, and hands-on learning. This study proposes a portable system capable of transforming ordinary surfaces into interactive learning spaces through gamification and spatial perception. A prototype based on multi-agent architecture was developed on the PANGEA (Platform for automatic coNstruction of orGanizations of intElligent agents) platform, integrating LIDAR (Light Detection and Ranging) sensors for gesture detection, an ultra-short-throw projector for visual interaction and a web platform to manage educational content, organize activities and evaluate student performance. The data from the sensors is processed in real time using ROS (Robot Operating System), generating precise virtual interactions on the projected surface, while the web allows you to configure physical and pedagogical parameters. Preliminary tests show that the system accurately detects gestures, translates them into digital interactions, and maintains low latency in different classroom environments, demonstrating robustness, modularity, and portability. The results suggest that the combination of multi-agent architectures, LIDAR sensors, and gamified platforms offers an effective approach to promote active learning in STEM, facilitate the adoption of advanced technologies in diverse educational settings, and improve student engagement and experience. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app7080832,Applied Sciences (Switzerland),"Technological advancements have revolutionized the proliferation and availability of information to users, which has created more complex and intensive interactions between users and systems. The learning process of users is essential in the construction of new knowledge when pursuing improvements in user experience. In this paper, the interruption factor is considered in relation to interaction quality due to human-computer interaction (HCI) being seen to affect the learning process. We present the results obtained from 500 users in an interactive museum in Tijuana, Mexico as a case study. We model the HCI of an interactive exhibition using belief-desire-intention (BDI) agents; we adapted the BDI architecture using the Type-2 fuzzy inference system to add perceptual human-like capabilities to agents, in order to describe the interaction and interruption factor on user experience. The resulting model allows us to describe content adaptation through the creation of a personalized interaction environment. We conclude that managing interruptions can enhance the HCI, producing a positive learning process that influences user experience. A better interaction may be achieved if we offer the right kind of content, taking the interruptions experienced into consideration. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app8010047,Applied Sciences (Switzerland),"This paper presents a plant root behavior-based approach to defining the control architecture of a plant-root-inspired robot, which is composed of three root-agents for nutrient uptake and one shoot-agent for nutrient redistribution. By taking inspiration and extracting key principles from the uptake of nutrient, movements and communication strategies adopted by plant roots, we developed an uptake-kinetics feedback control for the robotic roots. Exploiting the proposed control, each root is able to regulate the growth direction, towards the nutrients that are most needed, and to adjust nutrient uptake, by decreasing the absorption rate of the most plentiful one. Results from computer simulations and implementation of the proposed control on the robotic platform, Plantoid, demonstrate an emergent swarming behavior aimed at optimizing the internal equilibrium among nutrients through the self-organization of the roots. Plant wellness is improved by dynamically adjusting nutrients priorities only according to local information without the need of a centralized unit delegated for wellness monitoring and task allocation among the agents. Thus, the root-agents can ideally and autonomously grow at the best speed, exploiting nutrient distribution and improving performance, in terms of exploration capabilities and exploitation of resources, with respect to the tropism-inspired control previously proposed by the same authors. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app8030432,Applied Sciences (Switzerland),"In this paper, we present a conceptual study on a Virtual Power Plant (VPP) architecture for the optimal management of Distributed Energy Resources (DERs) owned by prosumers participating in Demand-Side Management (DSM) programs. Compared to classical VPP architectures, which aim to aggregate several DERs dispersed throughout the electrical grid, in the proposed VPP architecture the supervised physical domain is limited to single users, i.e., to single Points of Delivery (PODs) of the distribution network. The VPP architecture is based on a service-oriented approach, where multiple agents cooperate to implement the optimal management of the prosumer's assets, by also considering different forms of Demand Response (DR) requests. The considered DR schemes range from Price-Based DRs to Event-Based DRs, covering both the normal operating functions and the emergency control requests applied in modern distribution networks. With respect to centralized approaches, in this study the control perspective is moved from the system level to the single prosumer's level, who is allowed to independently provide flexible power profiles through the aggregation of multiple DERs. A generalized optimization model, formulated as a Mixed-Integer Linear Programming (MILP) problem, is also introduced. Such a model is able to compute the optimal scheduling of a prosumer's assets by considering both DR requests and end-users' requirements in terms of comfort levels while minimizing the costs. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app9204400,Applied Sciences (Switzerland),"The education sector is a major generator, consumer, and depositary of educational content. Thanks to technological advances, today's educators and learners have ubiquitous and on-demand access to information. Technology has made it possible for us to communicate and share information effortlessly from anywhere in the world. However, the availability of vast amounts of heterogeneous educational content will not be useful unless we search, retrieve and integrate it, creating interoperable educational environments. The current challenges to integrating educational content arise from its distribution over several repositories. This research proposes AIREH (architecture for intelligent retrieval of educational content from heterogeneous environments), for the retrieval of digital content through agent-based virtual organizations. This flexible architecture facilitates the search for and integration of heterogeneous content through an information retrieval model that involves both case-based reasoning and federated search. Moreover, AIREH is based on an adaptive organization model for distributed planning, thanks to which, it manages open systems flexibly, dynamically, and effectively. The conducted case study gives very promising results and demonstrates the advantages of using agent-based virtual organizations in the retrieval of labeled digital content. The proposed model is flexible, customizable, comprehensive and efficient. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app9224802,Applied Sciences (Switzerland),"A multi-agent data-analytics-based approach to ubiquitous healthcare monitoring is presented in this paper. The proposed architecture gathers a patient's vital data using wireless body area networks, and the transmitted information is separated into binary component parts and divided into related dataset categories using several classification techniques. A probabilistic procedure is then used that applies a normal (Gaussian) distribution to the analysis of new medical entries in order to assess the gravity of the anomalies detected. Finally, a data examination is carried out to gain insight. The results of the model and simulation show that the proposed architecture is highly efficient in applying smart technologies to a healthcare system, as an example of a research direction involving the Internet of Things, and offers a data platform that can be used for both medical decision making and the patient's wellbeing and satisfaction with their medical treatment. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.3390/app9235084,Applied Sciences (Switzerland),"This paper describes an intensive design leading to the implementation of an intelligent lab companion (ILC) agent for an intelligent virtual laboratory (IVL) platform. An IVL enables virtual labs (VL) to be used as online research laboratories, thereby facilitating and improving the analytical skills of students using agent technology. A multi-agent system enhances the capability of the learning system and solves students' problems automatically. To ensure an exhaustive Agent Unified Modeling Language (AUML) design, identification of the agents' types and responsibilities on well-organized AUML strategies is carried out. This work also traces the design challenge of IVL modeling and the ILC agent functionality of six basic agents: the practical coaching agent (PCA), practical dispatcher agent (PDA), practical interaction and coordination agent (PICA), practical expert agent (PEA), practical knowledge management agent (PKMA), and practical inspection agent (PIA). Furthermore, this modeling technique is compatible with ontology mapping based on an enabling technology using the Java Agent Development Framework (JADE), Cognitive Tutor Authoring Tools (CTAT), and Protégé platform integration. The potential Java Expert System Shell (Jess) programming implements the cognitive model algorithm criteria that are applied to measure progress through the CTAT for C++ programming concept task on IVL and successfully deployed on the TutorShop web server for evaluation. The results are estimated through the learning curve to assess the preceding knowledge, error rate, and performance profiler to engage cognitive Jess agent effciency as well as practicable and active decisions to improve student learning. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.3390/bdcc8120177,Big Data and Cognitive Computing,"Unmanned aerial vehicles (UAVs), commonly known as drones, are being seen as the most promising type of autonomous vehicles in the context of intelligent transportation system (ITS) technology. A key enabling factor for the current development of ITS technology based on autonomous vehicles is the task allocation architecture. This approach allows tasks to be efficiently assigned to robots of a multi-agent system, taking into account both the robots’ capabilities and service requirements. Consequently, this study provides an overview of the application of drones in ITSs, focusing on the applications of task allocation algorithms for UAV networks. Currently, there are different types of algorithms that are employed for task allocation in drone-based intelligent transportation systems, including market-based approaches, game-theory-based algorithms, optimization-based algorithms, machine learning techniques, and other hybrid methodologies. This paper offers a comprehensive literature review of how such approaches are being utilized to optimize the allocation of tasks in UAV-based ITSs. The main characteristics, constraints, and limitations are detailed to highlight their advantages, current achievements, and applicability to different types of UAV-based ITSs. Current research trends in this field as well as gaps in the literature are also thoughtfully discussed. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/biomimetics10100701,Biomimetics,"Collagen, as the predominant structural protein in vertebrates, represents a promising biomimetic material for scaffold development. Fibre-based scaffolds produced through textile technologies enable precise modulation of structural characteristics to closely mimic the extracellular matrix architecture using wet-spun collagen fibres. However, this in vitro fibre formation lacks natural crosslinking, resulting in collagen fibres with compromised mechanical strength, enzymatic resistance, and thermal stability compared to their native counterparts, thus restricting their biomedical applicability. Post-fabrication crosslinking is therefore imperative to enhance the durability and functional performance of collagen fibre-based scaffolds. Although traditional crosslinkers like glutaraldehyde effectively improve mechanical strength and stability, their clinical utility is hindered by cytotoxicity and associated adverse biological responses. Alternative synthetic crosslinking agents, such as hexamethylene diisocyanate, 1-Ethyl-3-(3’-dimethyl amino propyl) carbodiimide, and 1,4-Butanediol diglycidyl ether, have demonstrated superior cytocompatibility while effectively improving collagen fibre properties. Nonetheless, synthetic compounds may induce more pronounced foreign body reaction than natural agents, necessitating further investigation into their cytocompatibility across varying concentrations. In contrast, plant-based crosslinking offers a promising, cytocompatible alternative, significantly enhancing the thermal and mechanical stability of collagen fibres, provided that potential fibre discolouration is acceptable for intended biomedical applications. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/biomimetics9070416,Biomimetics,"The neural or mental simulation of actions is a powerful tool for allowing cognitive agents to develop Prospection Capabilities that are crucial for learning and memorizing key aspects of challenging skills. In previous studies, we developed an approach based on the animation of the redundant human body schema, based on the Passive Motion Paradigm (PMP). In this paper, we show that this approach can be easily extended to hyper-redundant serpentine robots as well as to hybrid configurations where the serpentine robot is functionally integrated with a traditional skeletal infrastructure. A simulation model is analyzed in detail, showing that it incorporates spatio-temporal features discovered in the biomechanical studies of biological hydrostats, such as the elephant trunk or octopus tentacles. It is proposed that such a generative internal model could be the basis for a cognitive architecture appropriate for serpentine robots, independent of the underlying design and control technologies. Although robotic hydrostats have received a lot of attention in recent decades, the great majority of research activities have been focused on the actuation/sensorial/material technologies that can support the design of hyper-redundant soft/serpentine robots, as well as the related control methodologies. The cognitive level of analysis has been limited to motion planning, without addressing synergy formation and mental time travel. This is what this paper is focused on. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/buildings13030743,Buildings,"Building information modeling (BIM) has traditionally been considered as a tool for the graphical representation of architectural and engineering projects. This technology has become a key instrument for the development of virtual models that simulate the constructive process and facilitate the analysis of the designed solutions to detect incidents linked to traditional bi-dimensional projects. This article focuses on the use of this technology to optimize the design of MEP (mechanical, electrical, plumbing) facilities and architecture by developing virtual BIM models. Therefore, the purpose of this research is to analyze two experiences of complex buildings that have developed a BIM Execution Plan to improve the coordination of all disciplines involved, in order to explore how these real experiences can contribute to the implementation of the use of this technology in the construction industry. The results of the research are divided into two aspects: on the one hand, the improvements that BIM brings to the coordination and optimization of MEP facilities, linked to the typification of design incidents detected to anticipate conflicts between disciplines, facilitate collaborative design between different agents, keep graphic documentation updated and avoid execution problems and additional costs; and on the other hand, the keys to facilitating the extension of the use of this technology in the industry. Therefore, the conclusions of the research point out to the need for improvement in the automation of incident detection and the reduction in design process deadlines, as well as the need to simplify the virtual modeling process to bring it closer to unqualified personnel involved in the workflow and facilitate the implementation of this technology in the construction industry. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/buildings14030847,Buildings,"Contemporary studies largely concentrate on the physical aspects of architecture, yet within the sphere of design, the gap between user experience and the designer’s intention is an undeniable fact. This gap, illustrating the contrast between the spatial perception and the actual physical space, to some degree, mirrors preferences in human spatial behavior. It accentuates the complex relationship between human cognitive functions and spatial layout, underlining the critical role of spatial perception in architectural design and planning. This prompts the question of whether perceptions of internal traffic flow within buildings also suffer from spatial distortions. Focusing on museums, and by examining circulation paths and spatial features, a virtual museum model is devised. The research employs a holistic and reductionist approach (complex systems theory) to forge a link between circulation components and the spatial experience of architecture. Utilizing agent-based modeling tools for simulating pedestrian movements, it investigates how different circulation patterns and spatial relationships influence pedestrian behavior. The study proposes a museum circulation optimization strategy, grounded in quantifying spatial experience through Anylogic software analysis. This strategy is aimed at enhancing the design of internal traffic flows in future museum projects, offering fresh insights into museum design research, and probing into new possibilities for using pedestrian simulation software. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/buildings15121970,Buildings,"This study focuses on the systematic conservation of historical architectural heritage in Heilongjiang Province, particularly addressing the challenges of point-based protection and spatial fragmentation. It explores the construction of a connected and conductive heritage corridor network, using historical building clusters across the province as empirical cases. A comprehensive analytical framework is established by integrating the nearest neighbor index, kernel density estimation, minimum cumulative resistance (MCR) model, entropy weighting, circuit theory, and network structure metrics. Kernel density analysis reveals a distinct spatial aggregation pattern, characterized by “one core, multiple zones.” Seven resistance factors—including elevation, slope, land use, road networks, and service accessibility—are constructed, with weights assigned through an entropy-based method to generate an integrated resistance surface and suitability map. Circuit theory is employed to simulate cultural “current” flows, identifying 401 potential corridors at the provincial, municipal, and district levels. A hierarchical station system is further developed based on current density, forming a coordinated structure of primary trunks, secondary branches, and complementary nodes. The corridor network’s connectivity is evaluated using graph-theoretic indices (α, β, and γ), which indicate high levels of closure, structural complexity, and accessibility. The results yield the following key findings: (1) Historical architectural resources in Heilongjiang demonstrate significant coupling with the Chinese Eastern Railway and multi-ethnic cultural corridors, forming a “one horizontal, three vertical” spatial configuration. The horizontal axis (Qiqihar–Harbin–Mudanjiang) aligns with the core cultural route of the railway, while the three vertical axes (Qiqihar–Heihe, Harbin–Heihe, and Mudanjiang–Luobei) correspond to ethnic cultural pathways. This forms a framework of “railway as backbone, ethnicity as wings.” (2) Comparative analysis of corridor paths, railways, and highways reveals structural mismatches in certain regions, including absent high-speed connections along northern trunk lines, insufficient feeder lines in secondary corridors, sparse terminal links, and missing ecological stations near regional boundaries. To address these gaps, a three-tier transportation coordination strategy is recommended: it comprises provincial corridors linked to high-speed rail, municipal corridors aligned with conventional rail, and district corridors connected via highway systems. Key enhancement zones include Yichun–Heihe, Youyi–Hulin, and Hegang–Wuying, where targeted infrastructure upgrades and integrated station hubs are proposed. Based on these findings, this study proposes a comprehensive governance paradigm for heritage corridors that balances multi-level coordination (provincial–municipal–district) with ecological planning. A closed-loop strategy of “identification–analysis–optimization” is developed, featuring tiered collaboration, cultural–ecological synergy, and multi-agent dynamic evaluation. The framework provides a replicable methodology for integrated protection and spatial sustainability of historical architecture in Heilongjiang and other cold-region contexts. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/buildings15203746,Buildings,"Accurate depth image inpainting in complex urban environments remains a critical challenge due to occlusions, reflections, and sensor limitations, which often result in significant data loss. We propose a hybrid deep learning framework that explicitly combines local and global modelling through Convolutional Neural Networks (CNNs) and Transformer modules. The model employs a multi-branch parallel architecture, where the CNN branch captures fine-grained local textures and edges, while the Transformer branch models global semantic structures and long-range dependencies. We introduce an optimized attention mechanism, Agent Attention, which differs from existing efficient/linear attention methods by using learnable proxy tokens tailored for urban scene categories (e.g., façades, sky, ground). A content-guided dynamic fusion module adaptively combines multi-scale features to enhance structural alignment and texture recovery. The frame-work is trained with a composite loss function incorporating pixel accuracy, perceptual similarity, adversarial realism, and structural consistency. Extensive experiments on the Paris StreetView dataset demonstrate that the proposed method achieves state-of-the-art performance, outperforming existing approaches in PSNR, SSIM, and LPIPS metrics. The study highlights the potential of multi-scale modeling for urban depth inpainting and discusses challenges in real-world deployment, ethical considerations, and future directions for multimodal integration. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/computers10030025,Computers,"Given the ever-growing body of knowledge, healthcare improvement hinges more than ever on efficient knowledge transfer to clinicians and patients. Promoted initially by the Institute of Medicine, the Learning Health System (LHS) framework emerged in the early 2000s. It places focus on learning cycles where care delivery is tightly coupled with research activities, which in turn is closely tied to knowledge transfer, ultimately injecting solid improvements into medical practice. Sensitive health data access across multiple organisations is therefore paramount to support LHSs. While the LHS vision is well established, security requirements to support them are not. Health data exchange approaches have been implemented (e.g., HL7 FHIR) or proposed (e.g., blockchain-based methods), but none cover the entire LHS requirement spectrum. To address this, the Sensitive Data Access Model (SDAM) is proposed. Using a representation of agents and processes of data access systems, specific security requirements are presented and the SDAM layer architecture is described, with an emphasis on its mix-network dynamic topology approach. A clinical application benefiting from the model is subsequently presented and an analysis evaluates the security properties and vulnerability mitigation strategies offered by a protocol suite following SDAM and in parallel, by FHIR. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/computers13070161,Computers,"Equipping autonomous agents for dynamic interaction and navigation is a significant challenge in intelligent transportation systems. This study aims to address this by implementing a brain-inspired model for decision making in autonomous vehicles. We employ active inference, a Bayesian approach that models decision-making processes similar to the human brain, focusing on the agent’s preferences and the principle of free energy. This approach is combined with imitation learning to enhance the vehicle’s ability to adapt to new observations and make human-like decisions. The research involved developing a multi-modal self-awareness architecture for autonomous driving systems and testing this model in driving scenarios, including abnormal observations. The results demonstrated the model’s effectiveness in enabling the vehicle to make safe decisions, particularly in unobserved or dynamic environments. The study concludes that the integration of active inference with imitation learning significantly improves the performance of autonomous vehicles, offering a promising direction for future developments in intelligent transportation systems. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/computers13120334,Computers,"Monitoring natural phenomena using a variety of methods to predict disasters is a trend that is growing over time. However, there is a great disunity among methods and means of data analysis, formats and interfaces of storing and providing data, and software and information systems for data processing. As part of a large project to create a planetary observatory that combines data from spatially distributed geosphere monitoring systems, the efforts of leading institutes of the Russian Academy of Sciences are also aimed at creating an information and computing ecosystem to unite researchers processing and analyzing the data obtained. This article provides a brief overview of the current state of publications on information ecosystems in various applied fields, and it also proposes a concept for an ecosystem on a multiagent basis with unique technical features. The concept of the ecosystem includes the following: the ability to function in a heterogeneous environment on federal principles, the parallelization of data processing between agents using Petri nets as a mechanism ensuring the correct execution of data processing scenarios, the concept of georeferenced alarm events requiring ecosystem reactions and possible notification of responsible persons, and multilevel information protection allowing data owners to control access at each stage of information processing. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/computers14060236,Computers,"Efficient congestion management in Software-Defined Networks (SDNs) remains a significant challenge due to dynamic traffic patterns and complex topologies. Conventional congestion control techniques based on static or heuristic rules often fail to adapt effectively to real-time network variations. This paper proposes a data-driven framework based on Multi-Agent Reinforcement Learning (MARL) to enable intelligent, adaptive congestion control in SDNs. The framework integrates two collaborative agents: a Congestion Classification Agent that identifies congestion levels using metrics such as delay and packet loss, and a Decision-Making Agent based on Deep Q-Learning (DQN or its variants), which selects the optimal actions for routing and bandwidth management. The agents are trained offline using both synthetic and real network traces (e.g., the MAWI dataset), and deployed in a simulated SDN testbed using Mininet and the Ryu controller. Extensive experiments demonstrate the superiority of the proposed system across key performance metrics. Compared to baseline controllers, including standalone DQN and static heuristics, the MARL system achieves up to 3.0% higher throughput, maintains end-to-end delay below 10 ms, and reduces packet loss by over 10% in real traffic scenarios. Furthermore, the architecture exhibits stable cumulative reward progression and balanced action selection, reflecting effective learning and policy convergence. These results validate the benefit of agent specialization and modular learning in scalable and intelligent SDN traffic engineering. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/computers14090367,Computers,"Recent developments in large language models allow for real time, context-aware tutoring. AI Gem, presented in this article, is a layered architecture that integrates personalization, adaptive feedback, and curricular alignment into transformer based tutoring agents. The architecture combines retrieval augmented generation, Bayesian learner model, and policy-based dialog in a verifiable and deployable software stack. The opportunities are scalable tutoring, multimodal interaction, and augmentation of teachers through content tools and analytics. Risks are factual errors, bias, over reliance, latency, cost, and privacy. The paper positions AI Gem as a design framework with testable hypotheses. A scenario-based walkthrough and new diagrams assign each learner step to the ten layers. Governance guidance covers data privacy across jurisdictions and operation in resource constrained environments. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/computers14100433,Computers,"Content Delivery Networks (CDNs) have evolved to meet surging data demands and stringent low-latency requirements driven by emerging applications like high-definition video streaming, virtual reality, and IoT. This paper proposes a hybrid CDN architecture that synergistically combines edge caching, Multi-access Edge Computing (MEC) offloading, and reinforcement learning (Q-learning) for adaptive routing. In the proposed system, popular content is cached at radio access network edges (e.g., base stations) and computation-intensive tasks are offloaded to MEC servers, while a Q-learning agent dynamically routes user requests to the optimal service node (cache, MEC server, or origin) based on the network state. The study presented detailed system design and provided comprehensive simulation-based evaluation. The results demonstrate that the proposed hybrid approach significantly improves cache hit ratios and reduces end-to-end latency compared to traditional CDNs and simpler edge architectures. The Q-learning-enabled routing adapts to changing load and content popularity, converging to efficient policies that outperform static baselines. The proposed hybrid model has been tested against variants lacking MEC, edge caching, or the RL-based controller to isolate each component’s contributions. The paper concludes with a discussion on practical considerations, limitations, and future directions for intelligent CDN networking at the edge. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/drones5020033,Drones,"Multi-agent unmanned aerial vehicle (UAV) teaming becomes an essential part in science mission, modern warfare surveillance, and disaster rescuing. This paper proposes a decentralized UAV swarm persistent monitoring strategy in realizing continuous sensing coverage and network service. A two-layer (high altitude and low altitude) UAV teaming hierarchical structure is adopted in realizing the accurate object tracking in the area of interest (AOI). By introducing the UAV communication channel model in its path planning, both centralized and decentralized control schemes would be evaluated in the waypoint tracking simulation. The UAV swarm network service and object tracking are measured by metrics of communication link quality and waypoints tracking accuracy. UAV swarm network connectivity are evaluated over different aspects, such as stability and volatility. The comparison of proposed algorithms is presented with simulations. The result shows that the decentralized scheme outperforms the centralized scheme in the mission of persistent surveillance, especially on maintaining the stability of inner UAV swarm network while tracking moving objects. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/drones7010010,Drones,"Unmanned aerial vehicles (UAVs) are important in reconnaissance missions because of their flexibility and convenience. Vitally, UAVs are capable of autonomous navigation, which means they can be used to plan safe paths to target positions in dangerous surroundings. Traditional path-planning algorithms do not perform well when the environmental state is dynamic and partially observable. It is difficult for a UAV to make the correct decision with incomplete information. In this study, we proposed a multi-UAV path planning algorithm based on multi-agent reinforcement learning which entails the adoption of centralized training–decentralized execution architecture to coordinate all the UAVs. Additionally, we introduced a hidden state of the recurrent neural network to utilize the historical observation information. To solve the multi-objective optimization problem, We designed a joint reward function to guide UAVs to learn optimal policies under the multiple constraints. The results demonstrate that by using our method, we were able to solve the problem of incomplete information and low efficiency caused by partial observations and sparse rewards in reinforcement learning, and we realized kdiff multi-UAV cooperative autonomous path planning in unknown environment. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/drones7010030,Drones,"We consider multipath TCP (MPTCP) flows over the data networking dynamics of IEEE 802.11ay for drone surveillance of areas using high-definition video streaming. Mobility-induced handoffs are critical in IEEE 802.11ay (because of the smaller coverage of mmWaves), which adversely affects the performance of such data streaming flows. As a result of the enhanced 802.11ay network events and features (triggered by beamforming, channel bonding, MIMO, mobility-induced handoffs, channel sharing, retransmissions, etc.), the time taken for packets to travel end-to-end in 802.11ay are inherently time-varying. Several fundamental assumptions inherent in stochastic TCP models, including Poisson arrivals of packets, Gaussian process, and parameter certainty, are challenged by the improved data traffic dynamics over IEEE 802.11ay networks. The MPTCP model’s state estimation differs largely from the actual network values. We develop a new data-driven stochastic framework to address current deficiencies of MPTCP models and design a foundational architecture for intelligent multipath scheduling (at the transport layer) considering lower layer (hybrid) beamforming. At the heart of our cross-layer architecture is an intelligent learning agent for actuating and interfacing, which learns from experience optimal packet cloning, scheduling, aggregation, and beamforming using successful features of multi-armed bandits and federated learning. We demonstrate that the proposed framework can estimate and optimize jointly (explore–exploit) and is more practicable for designing the next generation of low-delay and robust MPTCP models. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/drones7070462,Drones,"This paper is concerned with the problem of multi-UAV roundup inspired by hierarchical cognition consistency learning based on an interaction mechanism. First, a dynamic communication model is constructed to address the interactions among multiple agents. This model includes a simplification of the communication graph relationships and a quantification of information efficiency. Then, a hierarchical cognition consistency learning method is proposed to improve the efficiency and success rate of roundup. At the same time, an opponent graph reasoning network is proposed to address the prediction of targets. Compared with existing multi-agent reinforcement learning (MARL) methods, the method developed in this paper possesses the distinctive feature that target assignment and target prediction are carried out simultaneously. Finally, to verify the effectiveness of the proposed method, we present extensive experiments conducted in the scenario of multi-target roundup. The experimental results show that the proposed architecture outperforms the conventional approach with respect to the roundup success rate and verify the validity of the proposed model. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/drones8020049,Drones,"Traditional Internet of Things (IoT) networks have limited coverage and may experience failures due to natural disasters affecting critical IoT devices, making it difficult for them to provide communication services. Therefore, how to establish network communication service more efficiently in the presence of fault points is the problem we solve in this paper. To address this issue, this study constructs a hierarchical multi-domain data transmission architecture for an emergency network with unmanned aerial vehicles (UAVs) employed as core communication devices. This architecture expands the functionality of UAVs as key network devices and provides a theoretical basis for their feasibility as intelligent network controllers and switches. Firstly, the UAV controllers perceive the network status and learn the spatio-temporal characteristics of air-to-ground network links. Secondly, a routing algorithm within the domain based on federated reinforcement distillation (FedRDR) is developed, which enhances the generalization capability of the routing decision model by increasing the training data samples. Simulation experiments are conducted, and the results show that the average communication data size between each domain controller and the server is approximately 45.3 KB when using the FedRDR algorithm. Compared to the transmission of parameters through federated reinforcement learning algorithms, FedRDR reduces the transmitted parameter size by approximately 29%. Therefore, the FedRDR routing algorithm helps to facilitate knowledge transfer, accelerate the training process of intelligent agents within the domain, and reduce communication costs in resource-constrained scenarios for UAV networks and has practical value. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/drones8040155,Drones,"Multi-unmanned systems have demonstrated significant applications across various fields under complex or extreme operating environments. In order to make such systems highly efficient and reliable, cooperative decision-making methods have been utilized as a critical technology for successful future applications. However, current multi-agent decision-making algorithms pose many challenges, including difficulties understanding human decision processes, poor time efficiency, and reduced interpretability. Thus, a real-time online collaborative decision-making model simulating human cognition is presented in this paper to solve those problems under unknown, complex, and dynamic environments. The provided model based on the Soar cognitive architecture aims to establish domain knowledge and simulate the process of human cooperation and adversarial cognition, fostering an understanding of the environment and tasks to generate real-time adversarial decisions for multi-unmanned systems. This paper devised intricate forest environments to evaluate the collaborative capabilities of agents and their proficiency in implementing various tactical strategies while assessing the effectiveness, reliability, and real-time action of the proposed model. The results reveal significant advantages for the agents in adversarial experiments, demonstrating strong capabilities in understanding the environment and collaborating effectively. Additionally, decision-making occurs in milliseconds, with time consumption decreasing as experience accumulates, mirroring the growth pattern of human decision-making. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/drones8050173,Drones,"Unmanned aerial vehicles (UAVs) provide benefits through eco-friendliness, cost-effectiveness, and reduction of human risk. Deep reinforcement learning (DRL) is widely used for autonomous UAV navigation; however, current techniques often oversimplify the environment or impose movement restrictions. Additionally, most vision-based systems lack precise depth perception, while range finders provide a limited environmental overview, and LiDAR is energy-intensive. To address these challenges, this paper proposes VizNav, a modular DRL-based framework for autonomous UAV navigation in dynamic 3D environments without imposing conventional mobility constraints. VizNav incorporates the Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm with Prioritized Experience Replay and Importance Sampling (PER) to improve performance in continuous action spaces and mitigate overestimations. Additionally, VizNav employs depth map images (DMIs) to enhance visual navigation by accurately estimating objects’ depth information, thereby improving obstacle avoidance. Empirical results show that VizNav, by leveraging TD3, improves navigation, and the inclusion of PER and DMI further boosts performance. Furthermore, the deployment of VizNav across various experimental settings confirms its flexibility and adaptability. The framework’s architecture separates the agent’s learning from the training process, facilitating integration with various DRL algorithms, simulation environments, and reward functions. This modularity creates a potential to influence RL simulation in various autonomous navigation systems, including robotics control and autonomous vehicles. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/drones8060226,Drones,"With the rapid development of Artificial Intelligence, AI-enabled Uncrewed Aerial Vehicles have garnered extensive attention since they offer an accessible and cost-effective solution for executing tasks in unknown or complex environments. However, developing secure and effective AI-based algorithms that empower agents to learn, adapt, and make precise decisions in dynamic situations continues to be an intriguing area of study. This paper proposes a hybrid intelligent control framework that integrates an enhanced Soft Actor–Critic method with a fuzzy inference system, incorporating pre-defined expert experience to streamline the learning process. Additionally, several practical algorithms and approaches within this control system are developed. With the synergy of these innovations, the proposed method achieves effective real-time path planning in unpredictable environments under a model-free setting. Crucially, it addresses two significant challenges in RL: dynamic-environment problems and multi-target problems. Diverse scenarios incorporating actual UAV dynamics were designed and simulated to validate the performance in tracking multiple mobile intruder aircraft. A comprehensive analysis and comparison of methods relying solely on RL and other influencing factors, as well as a controller feasibility assessment for real-world flight tests, are conducted, highlighting the advantages of the proposed hybrid architecture. Overall, this research advances the development of AI-driven approaches for UAV safe autonomous navigation under demanding airspace conditions and provides a viable learning-based control solution for different types of robots. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/drones8080378,Drones,"Most existing multi-UAV collaborative search methods only consider scenarios of two-dimensional path planning or static target search. To be close to the practical scenario, this paper proposes a path planning method based on an action-mask-based multi-agent proximal policy optimization (AM-MAPPO) algorithm for multiple UAVs searching for moving targets in three-dimensional (3D) environments. In particular, a multi-UAV high–low altitude collaborative search architecture is introduced that not only takes into account the extensive detection range of high-altitude UAVs but also leverages the benefit of the superior detection quality of low-altitude UAVs. The optimization objective of the search task is to minimize the uncertainty of the search area while maximizing the number of captured moving targets. The path planning problem for moving target search in a 3D environment is formulated and addressed using the AM-MAPPO algorithm. The proposed method incorporates a state representation mechanism based on field-of-view encoding to handle dynamic changes in neural network input dimensions and develops a rule-based target capture mechanism and an action-mask-based collision avoidance mechanism to enhance the AM-MAPPO algorithm’s convergence speed. Experimental results demonstrate that the proposed algorithm significantly reduces regional uncertainty and increases the number of captured moving targets compared to other deep reinforcement learning methods. Ablation studies further indicate that the proposed action mask mechanism, target capture mechanism, and collision avoidance mechanism of the AM-MAPPO algorithm can improve the algorithm’s effectiveness, target capture capability, and UAVs’ safety, respectively. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/drones8090475,Drones,"Unmanned aerial vehicle (UAV) formation flying is an efficient and economical operation mode for air transportation systems. To improve the effectiveness of synergetic formation control for UAVs, this paper proposes a pairwise conflict resolution approach for UAV formation through mathematical analysis and designs a dynamic pairing and deep reinforcement learning framework (P-DRL formation control framework). Firstly, a new pairwise UAV formation control theorem is proposed, which breaks down the multi-UAVs formation control problem into multiple sequential control problems involving UAV pairs through a dynamic pairing algorithm. The training difficulty of Agents that only control each pair (two UAVs) is lower compared to controlling all UAVs directly, resulting in better and more stable formation control performance. Then, a deep reinforcement learning model for a UAV pair based on the Environment–Agent interaction is built, where segmented reward functions are designed to reduce the collision possibility of UAVs. Finally, P-DRL completes the formation control task of the UAV fleet through continuous pairing and Agent-based pairwise formation control. The simulations used the dynamic pairing algorithm combined with the DRL architectures of asynchronous advantage actor–critic (P-A3C), actor–critic (P-AC), and double deep q-value network (P-DDQN) to achieve synergetic formation control. This approach yielded effective control results with a strong generalization ability. The success rate of controlling dense, fast, and multi-UAV (10–20) formations reached 96.3%, with good real-time performance (17.14 Hz). © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/drones8100537,Drones,"In this paper, we introduce a fault-tolerant multi-agent reinforcement learning framework called SERT-DQN to optimize the operations of UAVs with UGV central control in coverage path planning missions. Our approach leverages dual learning systems that combine individual agent autonomy with centralized strategic planning, thus enhancing the efficiency of cooperative path planning missions. This framework is designed for high performance in environments with fault uncertainty detected and operational challenges such as interruptions in connectivity and compromised sensor reliability. With the integration of an innovative communication system between agents, our system appropriately handles both static and dynamic environments. Also, we introduce similarity-based shared experience replay to attain faster convergence and sample efficiency in the multi-agent system. The architecture is specially designed to respond adaptively to such irregularities by effectively showing enhanced resilience in scenarios where data integrity is impaired due to faults or the UAV faces disruptions. Simulation results indicate that our fault tolerance algorithms are very resilient and do indeed improve mission outcomes, especially under dynamic and highly uncertain operating conditions. This approach becomes critical for the most recent sensor-based research in autonomous systems. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/drones8100553,Drones,"With the rapid development of digital intelligence, drones can provide many conveniences for people’s lives, especially in executing rescue missions in special areas. When executing rescue missions in remote areas, communication cannot be fully covered. Therefore, to improve the online adaptability of the task chain link in task planning with a complex system structure as the background, a distributed source-task-capability allocation (DSTCA) problem was constructed. The first task chain coordination mechanism scheme was proposed, and a DSTCA architecture based on the task chain coordination mechanism was constructed to achieve the online adaptability of the swarm. At the same time, the existing algorithms cannot achieve this idea, and the DSTCA-CBBA algorithm based on CNP is proposed. The efficiency change, agent score, and time three indicators are evaluated through specific cases. In response to sudden changes in nodes in the task chain link, the maximum spanning tree algorithm is used to reconstruct the task chain link in a short time, thereby completing the mission task assigned to the drone entity. Meanwhile, the experimental results also prove the effectiveness of the proposed algorithm. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/drones8100592,Drones,"The evolution of beyond fifth generation (B5G) wireless networks poses significant technical and economic challenges across urban, suburban, and rural areas, demanding increased capacity for users whose positions continually change. This study investigated the dynamic positioning of an unmanned aerial vehicle (UAV), acting as a mobile base station (MoBS) to enhance network efficiency and meet ground terminals (GTs) expectations for data rates, particularly in emergency scenarios or temporary events. While UAVs show great promise, existing research often assumes certainty in network architecture, overlooking the complexities of unpredictable user movements. We introduce a decision-making framework utilizing the ordered weighted averaging (OWA) operator to address uncertainties in GT locations, enabling the optimization of UAV trajectories to maximize the overall network data rate. An optimization problem is formulated by modeling GT dynamics through a Markov process and discretizing UAV movements while accounting for communication thresholds and movement constraints. Extensive simulations reveal that our approach significantly improves expected data rates by up to 48% compared to traditional fixed base stations (BSs) and predefined UAV movement patterns. This research underscores the potential of UAV-assisted networks to bolster communication reliability while effectively managing dynamic user movements to maintain optimal quality of service (QoS). © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/drones8120720,Drones,"Existing multi-agent deep reinforcement learning (MADRL) methods for multi-UAV navigation face challenges in generalization, particularly when applied to unseen complex environments. To address these limitations, we propose a Dual-Transformer Encoder-Based Proximal Policy Optimization (DTPPO) method. DTPPO enhances multi-UAV collaboration through a Spatial Transformer, which models inter-agent dynamics, and a Temporal Transformer, which captures temporal dependencies to improve generalization across diverse environments. This architecture allows UAVs to navigate new, unseen environments without retraining. Extensive simulations demonstrate that DTPPO outperforms current MADRL methods in terms of transferability, obstacle avoidance, and navigation efficiency across environments with varying obstacle densities. The results confirm DTPPO’s effectiveness as a robust solution for multi-UAV navigation in both known and unseen scenarios. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/drones8120782,Drones,"The capability of UAVs for efficient autonomous navigation and obstacle avoidance in complex and unknown environments is critical for applications in agricultural irrigation, disaster relief and logistics. In this paper, we propose the DPRL (Distributed Privileged Reinforcement Learning) navigation algorithm, an end-to-end policy designed to address the challenge of high-speed autonomous UAV navigation under partially observable environmental conditions. Our approach combines deep reinforcement learning with privileged learning to overcome the impact of observation data corruption caused by partial observability. We leverage an asymmetric Actor–Critic architecture to provide the agent with privileged information during training, which enhances the model’s perceptual capabilities. Additionally, we present a multi-agent exploration strategy across diverse environments to accelerate experience collection, which in turn expedites model convergence. We conducted extensive simulations across various scenarios, benchmarking our DPRL algorithm against state-of-the-art navigation algorithms. The results consistently demonstrate the superior performance of our algorithm in terms of flight efficiency, robustness and overall success rate. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/drones9060410,Drones,"Autonomy in Unmanned Aerial Vehicle (UAV) navigation has enabled applications in diverse fields such as mining, precision agriculture, and planetary exploration. However, challenging applications in complex environments complicate the interaction between the agent and its surroundings. Conditions such as the absence of a Global Navigation Satellite System (GNSS), low visibility, and cluttered environments significantly increase uncertainty levels and cause partial observability. These challenges grow when compact, low-cost, entry-level sensors are employed. This study proposes a model-based reinforcement learning (RL) approach to enable UAVs to navigate and make decisions autonomously in environments where the GNSS is unavailable and visibility is limited. Designed for search and rescue operations, the system enables UAVs to navigate cluttered indoor environments, detect targets, and avoid obstacles under low-visibility conditions. The architecture integrates onboard sensors, including a thermal camera to detect a collapsed person (target), a 2D LiDAR and an IMU for localization. The decision-making module employs the ABT solver for real-time policy computation. The framework presented in this work relies on low-cost, entry-level sensors, making it suitable for lightweight UAV platforms. Experimental results demonstrate high success rates in target detection and robust performance in obstacle avoidance and navigation despite uncertainties in pose estimation and detection. The framework was first assessed in simulation, compared with a baseline algorithm, and then through real-life testing across several scenarios. The proposed system represents a step forward in UAV autonomy for critical applications, with potential extensions to unknown and fully stochastic environments. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/drones9070484,Drones,"Unmanned Aerial Vehicles (UAVs) have become increasingly prevalent in both governmental and civilian applications, offering significant reductions in operational costs by minimizing human involvement. There is a growing demand for autonomous, scalable, and intelligent coordination strategies in complex aerial missions involving multiple Unmanned Aerial Vehicles (UAVs). Traditional control techniques often fall short in dynamic, uncertain, or large-scale environments where decentralized decision-making and inter-agent cooperation are crucial. A potentially effective technique used for UAV fleet operation is Multi-Agent Reinforcement Learning (MARL). MARL offers a powerful framework for addressing these challenges by enabling UAVs to learn optimal behaviors through interaction with the environment and each other. Despite significant progress, the field remains fragmented, with a wide variety of algorithms, architectures, and evaluation metrics spread across domains. This survey aims to systematically review and categorize state-of-the-art MARL approaches applied to UAV control, identify prevailing trends and research gaps, and provide a structured foundation for future advancements in cooperative aerial robotics. The advantages and limitations of these techniques are discussed along with suggestions for further research to improve the effectiveness of MARL application to UAV fleet management. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/e21070674,Entropy,"An optimal feedback controller for a given Markov decision process (MDP) can in principle be synthesized by value or policy iteration. However, if the system dynamics and the reward function are unknown, a learning agent must discover an optimal controller via direct interaction with the environment. Such interactive data gathering commonly leads to divergence towards dangerous or uninformative regions of the state space unless additional regularization measures are taken. Prior works proposed bounding the information loss measured by the Kullback-Leibler (KL) divergence at every policy improvement step to eliminate instability in the learning dynamics. In this paper, we consider a broader family of f -divergences, and more concretely a-divergences, which inherit the beneficial property of providing the policy improvement step in closed form at the same time yielding a corresponding dual objective for policy evaluation. Such entropic proximal policy optimization view gives a unified perspective on compatible actor-critic architectures. In particular, common least-squares value function estimation coupled with advantage-weighted maximum likelihood policy improvement is shown to correspond to the Pearson χ2-divergence penalty. Other actor-critic pairs arise for various choices of the penalty-generating function f . On a concrete instantiation of our framework with the α-divergence, we carry out asymptotic analysis of the solutions for different values of a and demonstrate the effects of the divergence function choice on common standard reinforcement learning problems. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.3390/E22050564,Entropy,"It is crucial to ask how agents can achieve goals by generating action plans using only partial models of the world acquired through habituated sensory-motor experiences. Although many existing robotics studies use a forward model framework, there are generalization issues with high degrees of freedom. The current study shows that the predictive coding (PC) and active inference (AIF) frameworks, which employ a generative model, can develop better generalization by learning a prior distribution in a low dimensional latent state space representing probabilistic structures extracted from well habituated sensory-motor trajectories. In our proposed model, learning is carried out by inferring optimal latent variables as well as synaptic weights for maximizing the evidence lower bound, while goal-directed planning is accomplished by inferring latent variables for maximizing the estimated lower bound. Our proposed model was evaluated with both simple and complex robotic tasks in simulation, which demonstrated sufficient generalization in learning with limited training data by setting an intermediate value for a regularization coefficient. Furthermore, comparative simulation results show that the proposed model outperforms a conventional forward model in goal-directed planning, due to the learned prior confining the search of motor plans within the range of habituated trajectories. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.3390/e23060783,Entropy,"Drawing from both enactivist and cognitivist perspectives on mind, I propose that explaining teleological phenomena may require reappraising both “Cartesian theaters” and mental homunculi in terms of embodied self-models (ESMs), understood as body maps with agentic prop-erties, functioning as predictive-memory systems and cybernetic controllers. Quasi-homuncular ESMs are suggested to constitute a major organizing principle for neural architectures due to their initial and ongoing significance for solutions to inference problems in cognitive (and affective) de-velopment. Embodied experiences provide foundational lessons in learning curriculums in which agents explore increasingly challenging problem spaces, so answering an unresolved question in Bayesian cognitive science: what are biologically plausible mechanisms for equipping learners with sufficiently powerful inductive biases to adequately constrain inference spaces? Drawing on models from neurophysiology, psychology, and developmental robotics, I describe how embodiment provides fundamental sources of empirical priors (as reliably learnable posterior expectations). If ESMs play this kind of foundational role in cognitive development, then bidirectional linkages will be found between all sensory modalities and frontal-parietal control hierarchies, so infusing all senses with somatic-motoric properties, thereby structuring all perception by relevant affordances, so solving frame problems for embodied agents. Drawing upon the Free Energy Principle and Active Inference framework, I describe a particular mechanism for intentional action selection via con-sciously imagined (and explicitly represented) goal realization, where contrasts between desired and present states influence ongoing policy selection via predictive coding mechanisms and back-ward-chained imaginings (as self-realizing predictions). This embodied developmental legacy suggests a mechanism by which imaginings can be intentionally shaped by (internalized) partially-expressed motor acts, so providing means of agentic control for attention, working memory, imag-ination, and behavior. I further describe the nature(s) of mental causation and self-control, and also provide an account of readiness potentials in Libet paradigms wherein conscious intentions shape causal streams leading to enaction. Finally, I provide neurophenomenological handlings of proto-typical qualia including pleasure, pain, and desire in terms of self-annihilating free energy gradients via quasi-synesthetic interoceptive active inference. In brief, this manuscript is intended to illustrate how radically embodied minds may create foundations for intelligence (as capacity for learning and inference), consciousness (as somatically-grounded self-world modeling), and will (as deployment of predictive models for enacting valued goals). © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/e26080616,Entropy,"This paper develops an outline for a hierarchically embedded architecture of an artificial agent that models human translation processes based on principles of active inference (AIF) and predictive processing (PP). AIF and PP posit that the mind constructs a model of the environment which guides behavior by continually generating and integrating predictions and sensory input. The proposed model of the translation agent consists of three processing strata: a sensorimotor layer, a cognitive layer, and a phenomenal layer. Each layer consists of a network of states and transitions that interact on different time scales. Following the AIF framework, states are conditioned on observations which may originate from the environment and/or the embedded processing layer, while transitions between states are conditioned on actions that implement plans to optimize goal-oriented behavior. The AIF agent aims at simulating the variation in translational behavior under various conditions and to facilitate investigating the underlying mental mechanisms. It provides a novel framework for generating and testing new hypotheses of the translating mind. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/e26121036,Entropy,"The traditional maneuver decision-making approaches are highly dependent on accurate and complete situation information, and their decision-making quality becomes poor when opponent information is occasionally missing in complex electromagnetic environments. In order to solve this problem, an autonomous maneuver decision-making approach is developed based on deep reinforcement learning (DRL) architecture. Meanwhile, a Transformer network is integrated into the actor and critic networks, which can find the potential dependency relationships among the time series trajectory data. By using these relationships, the information loss is partially compensated, which leads to maneuvering decisions being more accurate. The issues of limited experience samples, low sampling efficiency, and poor stability in the agent training state appear when the Transformer network is introduced into DRL. To address these issues, the measures of designing an effective decision-making reward, a prioritized sampling method, and a dynamic learning rate adjustment mechanism are proposed. Numerous simulation results show that the proposed approach outperforms the traditional DRL algorithms, with a higher win rate in the case of opponent information loss. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/e27090977,Entropy,"In this work, we propose a novel quantum-informed epistemic framework that extends the classical notion of probability by integrating plausibility, credibility, and possibility as distinct yet complementary measures of uncertainty. This enriched quadruple (P, Pl, Cr, Ps) enables a deeper characterization of quantum systems and decision-making processes under partial, noisy, or ambiguous information. Our formalism generalizes the Born rule within a multi-valued logic structure, linking Positive Operator-Valued Measures (POVMs) with data-driven plausibility estimators, agent-based credibility priors, and fuzzy-theoretic possibility functions. We develop a hybrid classical–quantum inference engine that computes a vectorial aggregation of the quadruples, enhancing robustness and semantic expressivity in contexts where classical probability fails to capture non-Kolmogorovian phenomena such as entanglement, contextuality, or decoherence. The approach is validated through three real-world application domains—quantum cybersecurity, quantum AI, and financial computing—where the proposed model outperforms standard probabilistic reasoning in terms of accuracy, resilience to noise, interpretability, and decision stability. Comparative analysis against QBism, Dempster–Shafer, and fuzzy quantum logic further demonstrates the uniqueness of architecture in both operational semantics and practical outcomes. This contribution lays the groundwork for a new theory of epistemic quantum computing capable of modelling and acting under uncertainty beyond traditional paradigms. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/educsci15070900,Education Sciences,"Ubiquitous blended learning, leveraging mobile devices, has democratized education by enabling autonomous and readily accessible knowledge acquisition. However, its reliance on traditional interfaces often limits learner immersion and meaningful interaction. The emergence of the wearable metaverse offers a compelling solution, promising enhanced multisensory experiences and adaptable learning environments that transcend the constraints of conventional ubiquitous learning. This research proposes a novel framework for ubiquitous blended learning in the wearable metaverse, aiming to address critical challenges, such as multi-source data fusion, effective human–computer collaboration, and efficient rendering on resource-constrained wearable devices, through the integration of embodied interaction and multi-agent collaboration. This framework leverages a real-time multi-modal data analysis architecture, powered by the MobileNetV4 and xLSTM neural networks, to facilitate the dynamic understanding of the learner’s context and environment. Furthermore, we introduced a multi-agent interaction model, utilizing CrewAI and spatio-temporal graph neural networks, to orchestrate collaborative learning experiences and provide personalized guidance. Finally, we incorporated lightweight SLAM algorithms, augmented using visual perception techniques, to enable accurate spatial awareness and seamless navigation within the metaverse environment. This innovative framework aims to create immersive, scalable, and cost-effective learning spaces within the wearable metaverse. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electricity4030014,Electricity,"The battery-based multilevel inverter has grown in popularity due to its ability to boost a system’s safety while increasing the effective battery life. Nevertheless, the system’s high degree of freedom, induced by a large number of switches, provides difficulties. In the past, central computation systems that needed extensive communication between the master and the slave module on each cell were presented as a solution for running such a system. However, because of the enormous number of slaves, the bus system created a bottleneck during operation. As an alternative to conventional multilevel inverter systems, which rely on a master–slave architecture for communication, decentralized controllers represent a feasible solution for communication capacity constraints. These controllers operate autonomously, depending on local measurements and decision-making. With this approach, it is possible to reduce the load on the bus system by approximately 90 percent and to enable a balanced state of charge throughout the system with an absolute maximum standard deviation of (Formula presented.). This strategy results in a more reliable and versatile multilevel inverter system, while the load on the bus system is reduced and more precise switching instructions are enabled. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics10192392,Electronics (Switzerland),"Many security problems in software systems are because of vulnerabilities caused by improper configurations. A poorly configured software system leads to a multitude of vulnerabilities that can be exploited by adversaries. The problem becomes even more serious when the architecture of the underlying system is static and the misconfiguration remains for a longer period of time, enabling adversaries to thoroughly inspect the software system under attack during the reconnaissance stage. Employing diversification techniques such as Moving Target Defense (MTD) can minimize the risk of exposing vulnerabilities. MTD is an evolving defense technique through which the attack surface of the underlying system is continuously changing. However, the effectiveness of such dynamically changing platform depends not only on the goodness of the next configuration setting with respect to minimization of attack surfaces but also the diversity of set of configurations generated. To address the problem of generating a diverse and large set of secure software and system configurations, this paper introduces an approach based on Reinforcement Learning (RL) through which an agent is trained to generate the desirable set of configurations. The paper reports the performance of the RL-based secure and diverse configurations through some case studies. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics10212711,Electronics (Switzerland),"This paper presents a new approach to generate datasets for cyber threat research in a multi-node system. For this purpose, the proof-of-concept of such a system is implemented. The system will be used to collect unique datasets with examples of information hiding techniques. These techniques are not present in publicly available cyber threat detection datasets, while the cyber threats that use them represent an emerging cyber defense challenge worldwide. The network data were collected thanks to the development of a dedicated application that automatically generates random network configurations and runs scenarios of information hiding techniques. The generated datasets were used in the data-driven research workflow for cyber threat detection, including the generation of data representations (network flows), feature selection based on correlations, data augmentation of training datasets, and preparation of machine learning classifiers based on Random Forest and Multilayer Perceptron architectures. The presented results show the usefulness and correctness of the design process to detect information hiding techniques. The challenges and research directions to detect cyber deception methods are discussed in general in the paper. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics10232949,Electronics (Switzerland),"Pneumonia is an inflammation of the lung parenchyma that is caused by a variety of infectious microorganisms and non-infective agents. All age groups can be affected; however, in most cases, fragile groups are more susceptible than others. Radiological images such as Chest X-ray (CXR) images provide early detection and prompt action, where typical CXR for such a disease is characterized by radiopaque appearance or seemingly solid segment at the affected parts of the lung due to inflammatory exudate formation replacing the air in the alveoli. The early and accurate detection of pneumonia is crucial to avoid fatal ramifications, particularly in children and seniors. In this paper, we propose a novel 50 layers Convolutional Neural Network (CNN)-based architecture that outperforms the state-of-the-art models. The suggested framework is trained using 5852 CXR images and statistically tested using five-fold cross-validation. The model can distinguish between three classes: viz viral, bacterial, and normal; with 99.7% ± 0.2 accuracy, 99.74% ± 0.1 sensitivity, and 0.9812 Area Under the Curve (AUC). The results are promising, and the new architecture can be used to recognize pneumonia early with cost-effectiveness and high accuracy, especially in remote areas that lack proper access to expert radiologists, and therefore, reduces pneumonia-caused mortality rates. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics11152346,Electronics (Switzerland),"Planning the optimal trajectory of emergency avoidance maneuvers for highly automated vehicles is a complex task with many challenges. The algorithm needs to decrease accident risk by reducing the severity and keeping the car in a controllable state. Optimal trajectory generation considering all aspects of vehicle and environment dynamics is numerically complex, especially if the object to be avoided is moving. This paper presents a hierarchical method for the avoidance of moving objects in an autonomous vehicle, where a reinforcement learning agent is responsible for local planning, while longitudinal and lateral control is performed by the low-level model-predictive controller and Stanley controllers. In the developed architecture, the agent is responsible for the optimization. It is trained in various scenarios to provide the necessary parameters for a polynomial-based path and a velocity profile in a neural network output. The vehicle performs only the first step of the trajectory, which is redesigned repeatedly by the planner based on the new state. In the training phase, the vehicle executes the entire trajectory via low-level controllers to determine the reward value, which realizes a prediction for the future. The agent receives feedback and can further improve its performance. Finally, the proposed framework was tested in a simulation environment and was also compared to human drivers’ abilities. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics11182853,Electronics (Switzerland),"The paper introduces a proposal of an Autonomous Navigation System for Unmanned Surface Vessels. The system architecture is presented with a special emphasis on collision avoidance and maneuver auto-negotiation. For the purpose of maneuver auto-negotiation, the concept of multi-agent systems has been applied. The algorithm developed for the task of collision avoidance is briefly described and the results of the simulation tests, confirming the effectiveness of applied method, are also given. Presented outcomes include solutions of test scenarios from the perspectives of different ships taking part in the considered situations, confirming the applicability of the collision avoidance algorithm in the process of maneuver auto-negotiation. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics11203371,Electronics (Switzerland),"The advancing applications based on machine learning and deep learning in communication networks have been exponentially increasing in the system architectures of enabled software-defined networking, network functions virtualization, and other wired/wireless networks. With data exposure capabilities of graph-structured network topologies and underlying data plane information, the state-of-the-art deep learning approach, graph neural networks (GNN), has been applied to understand multi-scale deep correlations, offer generalization capability, improve the accuracy metrics of prediction modelling, and empower state representation for deep reinforcement learning (DRL) agents in future intelligent network management and orchestration. This paper contributes a taxonomy of recent studies using GNN-based approaches to optimize the control policies, including offloading strategies, routing optimization, virtual network function orchestration, and resource allocation. The algorithm designs of converged DRL and GNN are reviewed throughout the selected studies by presenting the state generalization, GNN-assisted action selection, and reward valuation cooperating with GNN outputs. We also survey the GNN-empowered application deployment in the autonomous control of optical networks, Internet of Healthcare Things, Internet of Vehicles, Industrial Internet of Things, and other smart city applications. Finally, we provide a potential discussion on research challenges and future directions. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics11223716,Electronics (Switzerland),"Motion planning has been used in robotics research to make movement decisions under certain movement constraints. Deep Reinforcement Learning (DRL) approaches have been applied to the cases of motion planning with continuous state representations. However, current DRL approaches suffer from reward sparsity and overestimation issues. It is also challenging to train the agents to deal with complex task specifications under deep neural network approximations. This paper considers one of the fragments of Linear Temporal Logic (LTL), Generalized Reactivity of rank 1 (GR(1)), as a high-level reactive temporal logic to guide robots in learning efficient movement strategies under a stochastic environment. We first use the synthesized strategy of GR(1) to construct a potential-based reward machine, to which we save the experiences per state. We integrate GR(1) with DQN, double DQN and dueling double DQN. We also observe that the synthesized strategies of GR(1) could be in the form of directed cyclic graphs. We develop a topological-sort-based reward-shaping approach to calculate the potential values of the reward machine, based on which we use the dueling architecture on the double deep Q-network with the experiences to train the agents. Experiments on multi-task learning show that the proposed approach outperforms the state-of-art algorithms in learning rate and optimal rewards. In addition, compared with the value-iteration-based reward-shaping approaches, our topological-sort-based reward-shaping approach has a higher accumulated reward compared with the cases where the synthesized strategies are in the form of directed cyclic graphs. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics11223816,Electronics (Switzerland),"A main barrier for autonomous and general learning systems is their inability to understand and adapt to new environments—that is, to apply previously learned abstract solutions to new problems. Supervised learning system functions such as classification require data labeling from an external source and do not have the ability to learn feature representation autonomously. This research details an unsupervised learning method for multi-modal feature detection and evaluation to be used for preprocessing in general learning systems. The learning method details a clustering algorithm that can be applied to any generic IoT sensor data, and a seeded stimulus labeling algorithm impacted and evolved by cross-modal input. The method is implemented and tested in two agents consuming audio and image data, each with varying innate stimulus criteria. Their run-time stimulus changes over time depending on their experiences, while newly experienced features become meaningful without preprogrammed labeling of distinct attributes. The architecture provides interfaces for higher-order cognitive processes to be built on top of the unsupervised preprocessor. This method is unsupervised and modular, in contrast to the highly constrained and pretrained learning systems that exist, making it extendable and well-disposed for use in artificial general intelligence. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics12030666,Electronics (Switzerland),"Sentiment analysis is a major area of natural language processing (NLP) research, and its sub-area of sarcasm detection has received growing interest in the past decade. Many approaches have been proposed, from basic machine learning to multi-modal deep learning solutions, and progress has been made. Context has proven to be instrumental for sarcasm and many techniques that use context to identify sarcasm have emerged. However, no NLP research has focused on sarcasm-context detection as the main topic. Therefore, this paper proposes an approach for the automatic detection of sarcasm context, aiming to develop models that can correctly identify the contexts in which sarcasm may occur or is appropriate. Using an established dataset, MUStARD, multiple models are trained and benchmarked to find the best performer for sarcasm-context detection. This performer is proven to be an attention-based long short-term memory architecture that achieves an F1 score of 60.1. Furthermore, we tested the performance of this model on the SARC dataset and compared it with other results reported in the literature to better assess the effectiveness of this approach. Future directions of study are opened, with the prospect of developing a conversational agent that could identify and even respond to sarcasm. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics12132984,Electronics (Switzerland),"The limited coverage extension of mobile edge computing (MEC) necessitates exploring cooperation with unmanned aerial vehicles (UAV) to leverage advanced features for future computation-intensive and mission-critical applications. Moreover, the workflow for task offloading in software-defined networking (SDN)-enabled 5G is significant to tackle in UAV-MEC networks. In this paper, deep reinforcement learning (DRL) SDN control methods for improving computing resources are proposed. DRL-based SDN controller, termed DRL-SDNC, allocates computational resources, bandwidth, and storage based on task requirements, upper-bound tolerable delays, and network conditions, using the UAV system architecture for task exchange between MECs. DRL-SDNC configures rule installation based on state observations and agent evaluation indicators, such as network congestion, user equipment computational capabilities, and energy efficiency. This paper also proposes the training deep network architecture for the DRL-SDNC, enabling interactive and autonomous policy enforcement. The agent learns from the UAV-MEC environment through experience gathering and updates its parameters using optimization methods. DRL-SDNC collaboratively adjusts hyperparameters and network architecture to enhance learning efficiency. Compared with baseline schemes, simulation results demonstrate the effectiveness of the proposed approach in optimizing resource efficiency and achieving satisfied quality of service for efficient utilization of computing and communication resources in UAV-assisted networking environments. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics12153255,Electronics (Switzerland),"The rapid progress of 6G mobile communication technologies has sparked a great deal research interests. The 6G core network architecture faces formidable challenges due to the escalating complexity of network service demands and diverse application scenarios. In response, our research endeavors to tackle these challenges by proposing a self-evolving architecture based on intelligent decision making. Inspired by the principles of biological morphological evolution, our architecture empowers the core network to dynamically adapt and reshape itself in order to effectively address the evolving communication environments. To facilitate this self-evolutionary process, we introduce a comprehensive framework encompassing mechanisms, architecture, agents, and algorithms that enable the network to autonomously generate and optimize its own structure, thereby ensuring adaptability to a wide range of application scenarios. By conducting concept proof simulation experiments, we have demonstrated the effectiveness of our self-evolution algorithm, which enables the 6G core network to make rational evolving decisions and exhibit remarkable adaptability to various application scenarios. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics12153288,Electronics (Switzerland),"Effective dynamic scheduling of twin Automated Stacking Cranes (ASCs) is essential for improving the efficiency of automated storage yards. While Deep Reinforcement Learning (DRL) has shown promise in a variety of scheduling problems, the dynamic twin ASCs scheduling problem is challenging owing to its unique attributes, including the dynamic arrival of containers, sequence-dependent setup and potential ASC interference. A novel DRL method is proposed in this paper to minimize the ASC run time and traffic congestion in the yard. Considering the information interference from ineligible containers, dynamic masked self-attention (DMA) is designed to capture the location-related relationship between containers. Additionally, we propose local information complementary attention (LICA) to supplement congestion-related information for decision making. The embeddings grasped by the LICA-DMA neural architecture can effectively represent the system state. Extensive experiments show that the agent can learn high-quality scheduling policies. Compared with rule-based heuristics, the learned policies have significantly better performance with reasonable time costs. The policies also exhibit impressive generalization ability in unseen scenarios with various scales or distributions. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics12163404,Electronics (Switzerland),"Service mesh is gaining popularity as a microservice architecture paradigm due to its lightness, transparency, and scalability. However, fully releasing configurations to the data plane during the business development phase can result in noticeable performance degradation. Therefore, fine-grained traffic management of microservice applications is crucial to service performance. This paper proposes a novel configuration distribution algorithm, DATM, which utilizes inter-service dependencies from the service call chain to manage data-plane traffic and dynamically maintain cluster services. The proposed algorithms enable on-demand distribution based on the obtained service dependency relationships by combining monitoring, information processing, and policy distribution. We validate the proposed mechanism and algorithms via extensive experiments. We show that the approach reduces the memory usage of data-plane agents and improves system resource utilization. Additionally, this reduces the time to issue configuration while effectively saving storage space and significantly reducing the number of cluster updates. Consequently, this approach ensures application performance and guarantees the quality of microservice applications in clusters. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics12194056,Electronics (Switzerland),"Heterogeneous architecture-based systems-on-chip enable the development of flexible and powerful multifunctional RF systems. In complex and dynamic environments where applications arrive continuously and stochastically, real-time scheduling of multiple applications to appropriate processor resources is crucial for fully utilizing the heterogeneous SoC’s resource potential. However, heterogeneous resource-scheduling algorithms still face many problems in practical situations, including generalized abstraction of applications and heterogeneous resources, resource allocation, efficient scheduling of multiple applications in complex mission scenarios, and how to ensure the effectiveness combining with real-world applications of scheduling algorithms. Therefore, in this paper, we design the Multi-Application Scheduling Algorithm, named MASA, which is a two-phase scheduler architecture based on Deep Reinforcement Learning. The algorithm is made up of neural network scheduler-based task prioritization for dynamic encoding of applications and heuristic scheduler-based task mapping for solving the processor resource allocation problem. In order to achieve stable and fast training of the network scheduler based on the actor–critic strategy, we propose optimization methods for the training of MASA: reward dynamic alignment (RDA), earlier termination of the initial episodes, and asynchronous multi-agent training. The performance of the MASA is tested with classic directed acyclic graph and six real-world application datasets, respectively. Experimental results show that MASA outperforms other neural scheduling algorithms and heuristics, and ablation experiments illustrate how these training optimizations improve the network’s capacity. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics13122387,Electronics (Switzerland),"In the mobile edge computing (MEC) architecture, base stations with computational capabilities are subject to service coverage limitations, and the mobility of devices leads to dynamic changes in their connections, directly impacting the offloading decisions of agents. The connections between base stations and mobile devices, as well as the connections between base stations themselves, are abstracted into an MEC structural diagram due to the difficulty of deep reinforcement learning (DRL) in capturing the complex relationships between nodes and their multi-order neighboring nodes in the graph; decisions solely generated by DRL have limitations. To address this issue, this study proposes a hierarchical mechanism strategy based on Graph Neural Reinforcement Learning (M-GNRL) under multiple constraints. Specifically, the MEC structural graph constructed with the current device as an observation point aggregates to learn node features, thus comprehensively considering the contextual information of nodes, and the learned graph information serves as the environment for deep reinforcement learning, effectively integrating a graph neural network (GNN) with DRL. In the M-GNRL strategy, edge features from GNN are introduced into the architecture of the DRL network to enhance the accuracy of agents’ decision-making. Additionally, this study proposes an updated algorithm to obtain graph data that change with observation points. Comparative experiments demonstrate that the M-GNRL algorithm outperforms other baseline algorithms in terms of system cost and convergence performance. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics13122424,Electronics (Switzerland),"While using multirotor UAVs for transport of suspended payloads, there is a need for stability along the desired path, in addition to avoidance of any excessive payload oscillations, and a good level of precision in maintaining the desired path of the vehicle. However, due to the nonlinear and underactuated nature of the system, in addition to the presence of mismatched uncertainties, the development of a control system for this application poses an interesting research problem. This paper proposes a control architecture for a multirotor slung load system by integrating a Multi-Surface Sliding Mode Control, aided by a Radial Basis Function Neural Network, with a Deep Q-Network Reinforcement Learning agent. The former will be used to ensure asymptotic tracking stability, while the latter will be used to suppress payload oscillations. First, we will present the dynamics of a multirotor slung load system, represented here as a quadrotor with a single pendulum load suspended from it. We will then propose a control method in which a multi-surface sliding mode controller, based on an adaptive RBF Neural Network for trajectory tracking of the quadrotor, works in tandem with a Deep Q-Network Reinforcement Learning agent whose reward function aims to suppress the oscillations of the single pendulum slung load. Simulation results demonstrate the effectiveness and potential of the proposed approach in achieving precise and reliable control of multirotor slung load systems. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics13142764,Electronics (Switzerland),"With the expansion of the very-high-throughput satellite (VHTS) system, the uneven distribution of traffic demands in time and space has become increasingly significant and cannot be ignored. It is a significant challenge to efficiently and dynamically allocate scarce on-board resources to ensure capacity and demand matching. The advancement of flexible payload technology provides the possibility to overcome this challenge. However, computational complexity is increasing due to the unsynchronized resource adjustment and the time-varying demands of the VHTS system. Therefore, we propose a double-timescale bandwidth and power allocation (DT-BPA) scheme to effectively manage the available resources in the flexible payload architecture. We use a multi-agent deep reinforcement learning (MADRL) algorithm aiming to meet the time-varying traffic demands of each beam and improve resource utilization. The simulation results demonstrate that the proposed DT-BPA algorithm enhanced the matching degree of capacity and demand as well as reduced the system’s power consumption. Additionally, it can be trained offline and implemented online, providing a more cost-effective solution for the VHTS system. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics13163189,Electronics (Switzerland),"One of the core features of 5G networks is the ability to support multiple services on the same infrastructure, with network slicing being a key technology. However, existing network slicing architectures have limitations in efficiently handling slice requests with different requirements, particularly when addressing high-reliability and high-demand services, where many issues remain unresolved. For example, predicting whether actual physical resources can meet network slice request demands and achieving flexible, on-demand resource allocation for different types of slice requests are significant challenges. To address the need for more flexible and efficient service demands, this paper proposes a 5G network slicing deployment algorithm based on the Multi-Agent Deep Deterministic Policy Gradient (MADDPG). Firstly, a new 5G network slicing deployment system framework is established, which measures resources for three typical 5G network slicing scenarios (eMBB, mMTC, uRLLC) and processes different types of slice requests by predicting slice request traffic. Secondly, by adopting the multi-agent approach of MADDPG, the algorithm enhances cooperation between multiple service requests, decentralizes action selection for requests, and schedules resources separately for the three types of slice requests, thereby optimizing resource allocation. Finally, simulation results demonstrate that the proposed algorithm significantly outperforms existing algorithms in terms of resource efficiency and slice request acceptance rate, showcasing the advantages of multi-agent approaches in slice request handling. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics13224416,Electronics (Switzerland),"Control in multi-agent decision-making systems is an important issue with a wide variety of existing approaches. In this work, we offer a new comprehensive framework for distributed control. The main contributions of this paper are summarized as follows. First, we propose PHIMEC (physics-informed meta control)—an architecture for learning optimal control by employing a physics-informed neural network when the state space is too large for reward-based learning. Second, we offer a way to leverage impulse response as a tool for system modeling and control. We propose IMPULSTM, a novel approach for incorporating time awareness into recurrent neural networks designed to accommodate irregular sampling rates in the signal. Third, we propose DIMAS, a modular approach to increasing computational efficiency in distributed control systems via domain-knowledge integration. We analyze the performance of the first two contributions on a set of corresponding benchmarks and then showcase their combined performance as a domain-informed distributed control system. The proposed approaches show satisfactory performance both individually in their respective applications and as a connected system. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics14030476,Electronics (Switzerland),"Deep Reinforcement Learning (DRL) has demonstrated promising capabilities for routing optimization in Software-Defined Networks (SDNs). However, existing DRL-based routing algorithms are struggling to extract graph-structured information and constrained to a fixed topology, suffering from the lack of robustness. In this paper, we strengthen the advantages of Graph Neural Networks (GNNs) for DRL-based routing optimization and propose a novel algorithm named Graph Transformer Star Routing (GTSR) to enhance robustness against topology changes. GTSR utilizes the multi-agent architecture to enable each node to make routing decisions independently, and introduces a Graph Transformer to equip agents with the capabilities of handling topology changes. Furthermore, we carefully design a global message-passing mechanism with a virtual star node and a path-based readout method, enhancing the long-range perception of traffic and the detection of potential congestion for routing decision-making. Moreover, we construct a multi-agent cooperation mechanism to facilitate the learning of universal perceptual strategies and reduce the amount of computation. Extensive experiments on multiple real-world network topologies demonstrate that GTSR is capable of adapting to unseen topology changes without retraining and decreases end-to-end latency by at least 47% and packet loss rate by at least 10% compared to all baselines, highlighting strong robustness. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics14071323,Electronics (Switzerland),"This paper presents a federated learning framework for multi-agent robotic systems, leveraging the ROS 2 framework to enable decentralized collaboration in both simulated and real-world environments. Traditional centralized machine learning approaches face challenges such as data privacy concerns, communication overhead, and limited scalability. To address these issues, we propose a federated reinforcement learning architecture where multiple robotic agents train local models and share their knowledge while preserving data privacy. The framework integrates deep reinforcement learning techniques, utilizing Unity for high-fidelity simulation. Experimental evaluations compare our federated approach against classical centralized learning, demonstrating that our proposal improves model generalization, stabilizes reward distribution, and reduces training variance. Additionally, results indicate that increasing the number of robots enhances task efficiency, reducing the number of steps required for successful navigation while maintaining consistent performance. This study highlights the potential of federated learning in robotics, offering a scalable and privacy-preserving approach to distributed multi-agent learning. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics14081527,Electronics (Switzerland),"This study proposes an advanced intelligent vehicle path-following control system using deep reinforcement learning, with a particular focus on the role of road geometry perception in motion planning and control. The system is structured around a three-degree-of-freedom (3-DOF) vehicle model, which facilitates the extraction of critical dynamic features necessary for robust control. The longitudinal control architecture integrates a Deep Deterministic Policy Gradient (DDPG) agent to optimise longitudinal velocity and acceleration, while lateral vehicle control is handled by a Deep Q-Network (DQN). To enhance situational awareness and adaptability, the system incorporates key input variables, including ego vehicle speed, speed error, lateral deviation, lateral error, and safety distance to the preceding vehicle, all in the context of road geometry and vehicle dynamics. In addition, the influence of road curvature is embedded into the control framework through perceived acceleration (sensed by vehicle occupants), allowing for more accurate and responsive adaptation to varying road conditions. The vehicle control system is tested in a simulated environment with a lead car in front with realistic speed profiles. The system outputs continuous values for acceleration and steering angle. The results of this study suggest that the proposed intelligent control system not only improves driver assistance but also has potential applications in autonomous driving. This framework contributes to the development of more autonomous, efficient, safety-aware, and comfortable vehicle control systems. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics14112270,Electronics (Switzerland),"As renewable energy sources are integrated into power grids on a large scale, modular multilevel converter-high voltage direct current (MMC-HVDC) systems face two significant challenges: traditional PI (proportional integral) controllers have limited dynamic regulation capabilities due to their fixed parameters, while improved PI controllers encounter implementation difficulties stemming from the complexity of their control strategies. This article proposes a dual-agent adaptive control framework based on the twin delayed deep deterministic policy gradient (TD3) algorithm. This framework facilitates the dynamic adjustment of PI parameters for both voltage and current dual-loop control and capacitor voltage balancing, utilizing a collaboratively optimized agent architecture without reliance on complex control logic or precise mathematical models. Simulation results demonstrate that, compared with fixed-parameter PI controllers, the proposed method significantly reduces DC voltage regulation time while achieving precise dynamic balance control of capacitor voltage and effective suppression of circulating current, thereby notably enhancing system stability and dynamic response characteristics. This approach offers new solutions for dynamic optimization control in MMC-HVDC systems. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics14122422,Electronics (Switzerland),"Malware remains a central tool in cyberattacks, and systematic research into adversarial attack techniques targeting malware is crucial in advancing detection and defense systems that can evolve over time. Although numerous review articles already exist in this area, there is still a lack of comprehensive exploration into emerging artificial intelligence technologies such as reinforcement learning from the attacker’s perspective. To address this gap, we propose a foundational reinforcement learning (RL)-based framework for adversarial malware generation and develop a systematic evaluation methodology to dissect the internal mechanisms of generative models across multiple key dimensions, including action space design, state space representation, and reward function construction. Drawing from a comprehensive review and synthesis of the existing literature, we identify several core findings. (1) The scale of the action space directly affects the model training efficiency. Meanwhile, factors such as the action diversity, operation determinism, execution order, and modification ratio indirectly influence the quality of the generated adversarial samples. (2) Comprehensive and sensitive state feature representations can compensate for the information loss caused by binary feedback from real-world detection engines, thereby enhancing both the effectiveness and stability of attacks. (3) A multi-dimensional reward signal effectively mitigates the policy fragility associated with single-metric rewards, improving the agent’s adaptability in complex environments. (4) While the current RL frameworks applied to malware generation exhibit diverse architectures, they share a common core: the modeling of discrete action spaces and continuous state spaces. In addition, this work explores future research directions in the area of adversarial malware generation and outlines the open challenges and critical issues faced by defenders in responding to such threats. Our goal is to provide both a theoretical foundation and practical guidance for building more robust and adaptive security detection mechanisms. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics14152992,Electronics (Switzerland),"This paper proposes a novel Twin Delayed Deep Deterministic Policy Gradient (TDDPG)-based joint optimization algorithm for hybrid reconfigurable intelligent surface (RIS)-assisted integrated sensing and communication (ISAC) systems in Internet of Vehicles (IoV) scenarios. The proposed system model achieves deep integration of sensing and communication by superimposing the communication and sensing signals within the same waveform. To decouple the complex joint design problem, a dual-DDPG architecture is introduced, in which one agent optimizes the transmit beamforming vector and the other adjusts the RIS phase shift matrix. Both agents share a unified reward function that comprehensively considers multi-user interference (MUI), total transmit power, RIS noise power, and sensing accuracy via the CRLB constraint. Simulation results demonstrate that the proposed TDDPG algorithm significantly outperforms conventional DDPG in terms of sum rate and interference suppression. Moreover, the adoption of a hybrid RIS enables an effective trade-off between communication performance and system energy efficiency, highlighting its practical deployment potential in dynamic IoV environments. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics14163307,Electronics (Switzerland),"Low-Earth-orbit (LEO) satellite networks face significant vulnerabilities to malicious jamming and co-channel interference, compounded by dynamic topologies, resource constraints, and complex electromagnetic environments. Traditional anti-jamming approaches lack adaptability, centralized intelligent methods incur high overhead, and distributed intelligent methods fail to achieve global optimization. To address these limitations, this paper proposed a value decomposition network (VDN)-based multi-agent deep reinforcement learning (DRL) anti-jamming spectrum access approach with a centralized training and distributed execution architecture. Following offline centralized ground-based training, the model was deployed distributedly on satellites for real-time spectrum-access decision-making. The simulation results demonstrate that the proposed method effectively balances training costs with anti-jamming performance. The method achieved near-optimal user satisfaction (approximately 97%) with minimal link overhead, confirming its effectiveness for resource-constrained LEO satellite networks. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics14173516,Electronics (Switzerland),"Alzheimer’s disease is a growing global health concern, demanding innovative solutions for early detection, continuous monitoring, and patient support. This article reviews recent advances in Smart Wearable Medical Devices (SWMDs), Internet of Things (IoT) systems, and mobile applications used to monitor physiological, behavioral, and cognitive changes in Alzheimer’s patients. We highlight the role of wearable sensors in detecting vital signs, falls, and geolocation data, alongside IoT architectures that enable real-time alerts and remote caregiver access. Building on these technologies, we present LumiCare, a conceptual, context-aware mobile system that integrates multimodal sensor data, chatbot-based interaction, and emerging 6G network capabilities. LumiCare uses machine learning for behavioral analysis, delivers personalized cognitive prompts, and enables emergency response through adaptive alerts and caregiver notifications. The system includes the LumiCare Companion, an interactive mobile app designed to support daily routines, cognitive engagement, and safety monitoring. By combining local AI processing with scalable edge-cloud architectures, LumiCare balances latency, privacy, and computational load. While promising, this work remains at the design stage and has not yet undergone clinical validation. Our analysis underscores the potential of wearable, IoT, and mobile technologies to improve the quality of life for Alzheimer’s patients, support caregivers, and reduce healthcare burdens. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics14204063,Electronics (Switzerland),"As an important supplement to ground computing, edge computing can effectively alleviate the computational burden on ground systems. In the context of integrating edge computing with low-Earth-orbit satellite networks, this paper proposes an edge computing task offloading algorithm based on distributed multi-agent deep reinforcement learning (DMADRL) to address the challenges of task offloading, including low transmission rates, low task completion rates, and high latency. Firstly, a Ground–UAV–LEO (GUL) three-layer architecture is constructed to improve offloading transmission rate. Secondly, the task offloading problem is decomposed into two sub-problems: offloading decisions and resource allocation. The former is addressed using a distributed multi-agent deep Q-network, where the problem is formulated as a Markov decision process. The Q-value estimation is iteratively optimized through the online and target networks, enabling the agent to make autonomous decisions based on ground and satellite load conditions, utilize the experience replay buffer to store samples, and achieve global optimization via global reward feedback. The latter employs the gradient descent method to dynamically update the allocation strategy based on the accumulated task data volume and the remaining resources, while adjusting the allocation through iterative convergence error feedback. Simulation results demonstrate that the proposed algorithm increases the average transmission rate by 21.7%, enhances the average task completion rate by at least 22.63% compared with benchmark algorithms, and reduces the average task processing latency by at least 11.32%, thereby significantly improving overall system performance. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics8030338,Electronics (Switzerland),"Today’s mobility management (MM) architectures, such as Mobile Internet Protocol (IP) and Proxy Mobile IP, feature integration of data and control planes, as well as centralized mobility control. In the existing architecture, however, the tight integration of the data and control planes can induce a non-optimal routing path, because data packets are delivered via a central mobility agent, such as Home Agent and Local Mobility Anchor. Furthermore, the centralized mobility control mechanism tends to increase traffic overhead due to the processing of both data and control packets at a central agent. To address these problems, a new Internet architecture for the future mobile network was proposed, named Mobile-Oriented Future Internet (MOFI). The MOFI architecture was mainly designed as follows: (1) separation of data and control planes for getting an optimal data path; (2) distributed identifier–locator mapping control for alleviating traffic overhead at a central agent. In this article, we investigate the validity of the MOFI architecture through implementation and experimentations over the European Union (EU)–Korea testbed network. For this purpose, the MOFI architecture is implemented using OpenFlow and Click Modular Router over a Linux platform, and then it is evaluated over the locally and internationally configured EU–Korea testbed network. In particular, we operate two realistic communication scenarios over the EU–Korea testbed network. From the experimentation results, we can see that the proposed MOFI architecture can not only provide the mobility management efficiently, but also support the backward compatibility for the current IP version 6 (IPv6) applications and an Internet Protocol network. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.3390/electronics9010162,Electronics (Switzerland),"The connection between collaborative learning and the new mobile technology has become tighter. Mobile learning enhances collaborative learning as learners can access information and learning materials from anywhere and at any time. However, supporting efficient mobile learning in education is a critical challenge. In addition, incorporating technological and educational components becomes a new, complex dimension. In this paper, an efficient collaborative mobilelearning architecture based on mobile agents is proposed to enhance learning activity and to allow teachers and students to collaborate in knowledge and information transfer. A mobile agent can control its own actions, is able to communicate with other agents, and adapts in accordance with previous experience. The proposed model consists of four components: The learner agent, the teacher agent, the device agent and the social agent. The social agent plays the main role in the collaborative tasks since it is responsible for evaluating the collaborative interactions among different learners. Additionally, it offers an evaluation indicator for the learners’ collaboration and supplies the teacher with learner’s collaboration reports. The proposed model is evaluated by introducing a collaborative mobile-learning case study applied to two full classes of undergraduate students. To conduct the model experiments, students were asked to complete a questionnaire after they used the proposed model. The questionnaire results statistically revealed that the proposed architecture is easy to use and access, well-organized, convenient, and facilitates the learning process. The students thought the proposed m-learning application should complement rather than replace the traditional lectures. Moreover, the experimental results show that the proposed collaborative mobile learning model enhances the learner’s skills in problem solving, increases the learner’s knowledge in comparison with individual learning, and social agent encourages learners for more participation in the learning tasks. Based on the experiments conducted, the authors found that the proposed model can improve the quality of the learning process by assessing learners’ and groups’ collaboration, and it can help teachers make learners improve how they work in groups. This also provides various ways of assessing learners abilities and skills in groups. It is also possible to integrate the collaborative e-learning with the proposed collaborative m-learning. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.3390/en11040844,Energies,"This paper presents a novel architecture for rural distribution grids. This architecture is designed to modernize traditional rural networks into new Smart Grid ones. The architecture tackles innovation actions on both the power plane and the management plane of the system. In the power plane, the architecture focuses on exploiting the synergies between telecommunications and innovative technologies based on power electronics managing low scale electrical storage. In the management plane, a decentralized management system is proposed based on the addition of two new agents assisting the typical Supervisory Control And Data Acquisition (SCADA) system of distribution system operators. Altogether, the proposed architecture enables operators to use more effectively-in an automated and decentralized way-weak rural distribution systems, increasing the capability to integrate new distributed energy resources. This architecture is being implemented in a real Pilot Network located in Spain, in the frame of the European Smart Rural Grid project. The paper also includes a study case showing one of the potentialities of one of the principal technologies developed in the project and underpinning the realization of the new architecture: the so-called Intelligent Distribution Power Router. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.3390/en14041169,Energies,"A vehicle ad hoc network (VANET) is a solution for road safety, congestion management, and infotainment services. Integration of cognitive radio (CR), known as CR-VANET, is needed to solve the spectrum scarcity problems of VANET. Several research efforts have addressed the concerns of CR-VANET. However, more reliable, robust, and faster spectrum sensing is still a challenge. A novel segment-based CR-VANET (Seg-CR-VANET) architecture is therefore proposed in this paper. Roads are divided equally into segments, and they are sub-segmented based on the probability value. Individual vehicles or secondary users produce local sensing results by choosing an optimal spectrum sensing (SS) technique using a hybrid machine learning algorithm that includes fuzzy and naïve Bayes algorithms. We used dynamic threshold values for the sensing techniques. In this proposed cooperative SS, the segment spectrum agent (SSA) made the global decision using the tri-agent reinforcement learning (TA-RL) algorithm. Three environments (network, signal, and vehicle) are learned by this proposed algorithm to determine primary (licensed) users’ activities. The simulation results indicate that, compared to current works, the proposed Seg-CR-VANET produces better results in spectrum sensing. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/en14082071,Energies,"The problem of high power consumption in data centers is becoming more and more prominent. In order to improve the energy efficiency of data centers, cooperatively optimizing the energy of IT systems and cooling systems has become an effective way. In this paper, a model-free deep reinforcement learning (DRL)-based joint optimization method MAD3C is developed to overcome the high-dimensional state and action space problems of the data center energy optimization. A hybrid AC-DDPG cooperative multi-agent framework is devised for the improvement of the cooperation between the IT and cooling systems for further energy efficiency improvement. In the framework, a scheduling baseline comparison method is presented to enhance the stability of the framework. Meanwhile, an adaptive score is designed for the architecture in consideration of multi-dimensional resources and resource utilization improvement. Experiments show that our proposed approach can effectively reduce energy for data centers through the cooperative optimization while guaranteeing training stability and improving resource utilization. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/en14133949,Energies,"This study focuses on a modeling framework to support mobility planners and energy providers in the sustainable development of electric mobility in urban areas. Specifically, models are provided to simulate measures for the optimal management of energy demand and thoughtful planning of charging infrastructures in order to avoid congestion on the power grid. The measures, and consequently the models, are classified according to short-term initiatives based on multimodality between electric vehicles and public transport (Park and Ride), as well as medium to long-term initiatives based on the development of an energy-oriented land use of the city. All the models are data-driven, and different sets of floating car data available for the city of Rome (Italy) have been exploited for this aim. The models are currently being implemented in an agent-based simulator for electric urban mobility adopted by the National Agency for Energy and Environment in Italy (ENEA). © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/en15134726,Energies,"The present paper deals with selected aspects of energy prosumers’ security needs. The analysis reported aim to illustrate the concept of the implementation of intrusion-detection systems (IDS)/intrusion-prevention systems (IPS), as supporting agent systems for smart grids. The contribu-tion proposes the architecture of an agent system aimed at collecting, processing, monitoring, and possibly reacting to changes in the smart grid. Furthermore, an algorithm is proposed to support the construction of a smart-grid-operating profile, based on a set of parameters describing the devices. Its application is presented in the example of data collected from the network, indicating the process of building a device-operation profile and a possible mechanism for detecting its changes. The proposed algorithm for building the operating profile of devices in the smart grid, based on the mechanism of continuous learning by the system, allows for detecting network malfunctions not only in terms of individual events but also regarding limits of the scope of system alerts, by determining the typical behavior of devices in the smart grid. The paper gives recommendations to a software-agent system development, which is dedicated to detecting and preventing anomalies in smart grids. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/en15145117,Energies,"This paper presents the development and implementation of a reinforcement learning agent as the mode selector for a multi-chamber actuator in a load-sensing architecture. The agent selects the mode of the actuator to minimise system energy losses. The agent was trained in a simulated environment and afterwards deployed to the real system. Simulation results indicated the capability of the agent to reduce energy consumption, while maintaining the actuation performance. Experimental results showed the capability of the agent to learn via simulation and to control the real system. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/en15155383,Energies,"Thermal power plants, TPP, are one of the main players in the phosphoric acid and fertilizer production value chain. The control of power plant assets involves considerable complexity and is subject to several constraints, affecting the asset’s reliability and, most importantly, plant operators’ safety. The main focus of this paper is to investigate the potential of an agent-based digital twin architecture for collaborative prognostic of power plants. Based on the ISO 13374:2015 scheme for smart condition monitoring, the proposed architecture consists of a collaborative prognostics system governed by several smart DT agents connected to both physical and virtual environments. In order to apprehend the potential of the developed agent-based architecture, experiments on the architecture are conducted in a real industrial environment. We show throughout the paper that our proposed architecture is robust and reproduces TPP static and dynamic behavior and can contribute to the smart monitoring of the plant in case of critical conditions. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/en15197217,Energies,"After the massive integration of distributed energy resources, energy storage systems and the charging stations of electric vehicles, it has become very difficult to implement an efficient grid energy management system regarding the unmanageable behavior of the power flow within the grid, which can cause many critical problems in different grid stages, typically in the substations, such as failures, blackouts, and power transformer explosions. However, the current digital transition toward Energy 4.0 in Smart Grids allows the integration of smart solutions to substations by integrating smart sensors and implementing new control and monitoring techniques. This paper is proposing a hybrid artificial intelligence multilayer for power transformers, integrating different diagnostic algorithms, Health Index, and life-loss estimation approaches. After gathering different datasets, this paper presents an exhaustive algorithm comparative study to select the best fit models. This developed architecture for prognostic (PHM) health management is a hybrid interaction between evolutionary support vector machine, random forest, k-nearest neighbor, and linear regression-based models connected to an online monitoring system of the power transformer; these interactions are calculating the important key performance indicators which are related to alarms and a smart energy management system that gives decisions on the load management, the power factor control, and the maintenance schedule planning. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/en15217856,Energies,"The accurate prediction of building heat demand plays the critical role in refined management of heating, which is the basis for on-demand heating operation. This paper proposed a prediction model framework for building heat demand based on reinforcement learning. The environment, reward function and agent of the model were established, and experiments were carried out to verify the effectiveness and advancement of the model. Through the building heat demand prediction, the model proposed in this study can dynamically control the indoor temperature within the acceptable interval (19–23 °C). Moreover, the experimental results showed that after the model reached the primary, intermediate and advanced targets in training, the proportion of time that the indoor temperature can be controlled within the target interval (20.5–21.5 °C) was over 35%, 55% and 70%, respectively. In addition to maintaining indoor temperature, the model proposed in this study also achieved on-demand heating operation. The model achieving the advanced target, which had the best indoor temperature control performance, only had a supply–demand error of 4.56%. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/en16052456,Energies,"The need for a greener and more sustainable energy system evokes a need for more extensive energy system transition research. The penetration of distributed energy resources and Internet of Things technologies facilitate energy system transition towards the next generation of energy system concepts. The next generation of energy system concepts include “integrated energy system”, “multi-energy system”, or “smart energy system”. These concepts reveal that future energy systems can integrate multiple energy carriers with autonomous intelligent decision making. There are noticeable trends in using the agent-based method in research of energy systems, including multi-energy system transition simulation with agent-based modeling (ABM) and multi-energy system management with multi-agent system (MAS) modeling. The need for a comprehensive review of the applications of the agent-based method motivates this review article. Thus, this article aims to systematically review the ABM and MAS applications in multi-energy systems with publications from 2007 to the end of 2021. The articles were sorted into MAS and ABM applications based on the details of agent implementations. MAS application papers in building energy systems, district energy systems, and regional energy systems are reviewed with regard to energy carriers, agent control architecture, optimization algorithms, and agent development environments. ABM application papers in behavior simulation and policy-making are reviewed with regard to the agent decision-making details and model objectives. In addition, the potential future research directions in reinforcement learning implementation and agent control synchronization are highlighted. The review shows that the agent-based method has great potential to contribute to energy transition studies with its plug-and-play ability and distributed decision-making process. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/en18030613,Energies,"This paper presents a blockchain-enabled Multi-Agent System (MAS) for real-time power management in Virtual Prosumer (VP) Networks, integrating Plug-in Electric Vehicles (PEVs) and Renewable Energy Sources (RESs). The proposed framework addresses critical challenges related to scalability, security, and operational efficiency by developing a hierarchical MAS architecture that optimizes the scheduling and coordination of geographically distributed PEVs and RESs. Unlike conventional business management systems, this study integrates a blockchain-based security mechanism within the MAS framework, leveraging Proof of Authority (PoA) consensus to enhance transaction security while addressing scalability and energy consumption concerns. The system further employs advanced Particle Swarm Optimization (PSO) to dynamically compute optimal power set-points, enabling adaptive and efficient energy distribution. Additionally, hierarchical aggregation of transactions at lower MAS layers enhances computational efficiency and system resilience under high-traffic and partial network failure conditions. The proposed framework is validated through large-scale simulations spanning four major cities in Greece, demonstrating its scalability, reliability, and efficiency under diverse operational scenarios. Results confirm that the system effectively balances energy supply and demand while maintaining secure and transparent transactions. Despite these advancements, practical deployment challenges remain, including synchronization delays in geographically distributed agents, legacy system integration, and blockchain energy consumption. Future research directions include investigating more advanced consensus mechanisms (e.g., Proof of Task), machine learning-driven predictive optimization, real-world large-scale testing, and federated learning models for decentralized decision-making. The proposed framework offers a scalable, secure, and efficient solution for decentralized real-time energy management in Virtual Prosumer Networks. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/en18040842,Energies,"Accurate oil and gas production forecasting is essential for optimizing field development and operational efficiency. Steady-state capacity prediction models based on machine learning techniques, such as Linear Regression, Support Vector Machines, Random Forest, and Extreme Gradient Boosting, effectively address complex nonlinear relationships through feature selection, hyperparameter tuning, and hybrid integration, achieving high accuracy and reliability. These models maintain relative errors within acceptable limits, offering robust support for reservoir management. Recent advancements in spatiotemporal modeling, Physics-Informed Neural Networks (PINNs), and agent-based modeling have further enhanced transient production forecasting. Spatiotemporal models capture temporal dependencies and spatial correlations, while PINN integrates physical laws into neural networks, improving interpretability and robustness, particularly for sparse or noisy data. Agent-based modeling complements these techniques by combining measured data with numerical simulations to deliver real-time, high-precision predictions of complex reservoir dynamics. Despite challenges in computational scalability, data sensitivity, and generalization across diverse reservoirs, future developments, including multi-source data integration, lightweight architectures, and real-time predictive capabilities, can further improve production forecasting, addressing the complexities of oil and gas production while supporting sustainable resource management and global energy security. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/en18123194,Energies,"This paper introduces an Enhanced-Dueling Deep Q-Network (EDDQN) specifically designed to bolster the physical security of electric power substations. We model the intricate substation security challenge as a Markov Decision Process (MDP), segmenting the facility into three zones, each with potential normal, suspicious, or attacked states. The EDDQN agent learns to strategically select security actions, aiming for optimal threat prevention while minimizing disruptive errors and false alarms. This methodology integrates Double DQN for stable learning, Prioritized Experience Replay (PER) to accelerate the learning process, and a sophisticated neural network architecture tailored to the complexities of multi-zone substation environments. Empirical evaluation using synthetic data derived from historical incident patterns demonstrates the significant advantages of EDDQN over other standard DQN variations, yielding an average reward of 7.5, a threat prevention success rate of 91.1%, and a notably low false alarm rate of 0.5%. The learned action policy exhibits a proactive security posture, establishing EDDQN as a promising and reliable intelligent solution for enhancing the physical resilience of power substations against evolving threats. This research directly addresses the critical need for adaptable and intelligent security mechanisms within the electric power infrastructure. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/en18154097,Energies,"The accelerating integration of electric vehicles (EVs) into contemporary transportation infrastructure has underscored significant limitations in traditional charging paradigms, particularly in accommodating heterogeneous user requirements within dynamic operational environments. This study presents a differentiated optimization framework for EV charging strategies through the systematic classification of user types. A multidimensional decision-making environment is established for three representative user categories—residential, commercial, and industrial—by synthesizing time-variant electricity pricing models with dynamic carbon emission pricing mechanisms. A bi-level optimization architecture is subsequently formulated, leveraging deep reinforcement learning (DRL) to capture user-specific demand characteristics through customized reward functions and adaptive constraint structures. Validation is conducted within a high-fidelity simulation environment featuring 90 autonomous EV charging agents operating in a metropolitan parking facility. Empirical results indicate that the proposed typology-driven approach yields a 32.6% average cost reduction across user groups relative to baseline charging protocols, with statistically significant improvements in expenditure optimization (p < 0.01). Further interpretability analysis employing gradient-weighted class activation mapping (Grad-CAM) demonstrates that the model’s attention mechanisms are well aligned with theoretically anticipated demand prioritization patterns across the distinct user types, thereby confirming the decision-theoretic soundness of the framework. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/en18174537,Energies,"Accurate state-of-charge (SOC) estimation is crucial in smart-building energy management systems, where rooftop photovoltaics and lithium-ion energy storage systems must be coordinated to align renewable generation with real-time demand. This paper introduces a novel, modular hybrid framework for SOC estimation, which synergistically combines the predictive power of artificial neural networks (ANNs), the logical consistency of finite state automata (FSA), and an adaptive dynamic supervisor layer. Three distinct ANN architectures—feedforward neural network (FFNN), long short-term memory (LSTM), and 1D convolutional neural network (1D-CNN)—are employed to extract comprehensive temporal and spatial features from raw data. The inherent challenge of ANNs producing physically irrational SOC values is handled by processing their raw predictions through an FSA module, which constrains physical validity by applying feasible transitions and domain constraints based on battery operational states. To further enhance the adaptability and robustness of the framework, two advanced supervisor mechanisms are developed for model selection during estimation. A lightweight rule-based supervisor picks a model transparently using recent performance scores and quick signal heuristics, whereas a more advanced double deep Q-network (DQN) reinforcement-learning supervisor continuously learns from reward feedback to adaptively choose the model that minimizes SOC error under changing conditions. This RL agent dynamically selects the most suitable ANN+FSA model, significantly improving performance under varying and unpredictable operational conditions. Comprehensive experimental validation demonstrates that the hybrid approach consistently outperforms raw ANN predictions and conventional extended Kalman filter (EKF)-based methods. Notably, the RL-based supervisor exhibits good adaptability and achieves lower error results in challenging high-variance scenarios. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/en18174620,Energies,"The diversity of energy resources in distribution networks requires new strategies for planning and operation. In this context, microgrids are solutions that can integrate renewable energy sources, energy storage systems (ESSs), and demand response (DR), thereby decentralizing operations and utilizing digital technologies to create more proactive energy markets. Given the above, this work proposes a distributed optimal dispatch strategy for microgrids with multiple energy resources, with a focus on scalability. Simulations are performed using agent modeling on the Python Agent Development (PADE) platform, leveraging distributed computing resources and agent communication. A co-simulation environment, coordinated by Mosaik, synchronizes data exchange, while a plug-and-play system allows dynamic agent modification. The main contribution of the present study relies on a system integration approach, combining a multi-agent system (MAS) and Mosaik co-simulation framework with plug-and-play agent support for the very short-term (five-minute) dispatch of energy resources. Optimization algorithms, namely particle swarm optimization (PSO) and multi-agent particle swarm optimization (MAPSO), are framed as an incremental improvement tailored to this distributed architecture. Case studies show that distributed MAPSO performs better, with lower objective function values and a smaller relative standard deviation (15.6%), while distributed PSO had a higher deviation (33.9%). Although distributed MAPSO takes up to three times longer to provide a solution, with an average of 9.0 s, this timeframe is compatible with five-minute dispatch intervals. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/en18184795,Energies,"This paper presents a deep reinforcement learning-based demand response (DR) optimization framework for active distribution networks under uncertainty and user heterogeneity. The proposed model utilizes a Double Deep Q-Network (Double DQN) to learn adaptive, multi-period DR strategies across residential, commercial, and electric vehicle (EV) participants in a 24 h rolling horizon. By incorporating a structured state representation—including forecasted load, photovoltaic (PV) output, dynamic pricing, historical DR actions, and voltage states—the agent autonomously learns control policies that minimize total operational costs while maintaining grid feasibility and voltage stability. The physical system is modeled via detailed constraints, including power flow balance, voltage magnitude bounds, PV curtailment caps, deferrable load recovery windows, and user-specific availability envelopes. A case study based on a modified IEEE 33-bus distribution network with embedded PV and DR nodes demonstrates the framework’s effectiveness. Simulation results show that the proposed method achieves significant cost savings (up to 35% over baseline), enhances PV absorption, reduces load variance by 42%, and maintains voltage profiles within safe operational thresholds. Training curves confirm smooth Q-value convergence and stable policy performance, while spatiotemporal visualizations reveal interpretable DR behavior aligned with both economic and physical system constraints. This work contributes a scalable, model-free approach for intelligent DR coordination in smart grids, integrating learning-based control with physical grid realism. The modular design allows for future extension to multi-agent systems, storage coordination, and market-integrated DR scheduling. The results position Double DQN as a promising architecture for operational decision-making in AI-enabled distribution networks. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/en18195225,Energies,"The growing complexity of electric vehicle charging station (EVCS) operations—driven by grid constraints, renewable integration, user variability, and dynamic pricing—has positioned reinforcement learning (RL) as a promising approach for intelligent, scalable, and adaptive control. After outlining the core theoretical foundations, including RL algorithms, agent architectures, and EVCS classifications, this review presents a structured survey of influential research, highlighting how RL has been applied across various charging contexts and control scenarios. This paper categorizes RL methodologies from value-based to actor–critic and hybrid frameworks, and explores their integration with optimization techniques, forecasting models, and multi-agent coordination strategies. By examining key design aspects—including agent structures, training schemes, coordination mechanisms, reward formulation, data usage, and evaluation protocols—this review identifies broader trends across central control dimensions such as scalability, uncertainty management, interpretability, and adaptability. In addition, the review assesses common baselines, performance metrics, and validation settings used in the literature, linking algorithmic developments with real-world deployment needs. By bridging theoretical principles with practical insights, this work provides comprehensive directions for future RL applications in EVCS control, while identifying methodological gaps and opportunities for safer, more efficient, and sustainable operation. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/en18205429,Energies,"The rapid expansion of electric vehicles in high-altitude Andean cities, such as the Metropolitan District of Quito, Ecuador’s capital, presents unique challenges for electrical infrastructure planning, necessitating advanced methodologies that capture behavioral heterogeneity and mass synchronization effects in high-penetration scenarios. This study introduces a hybrid approach that combines agent-based modelling with Monte Carlo simulation and a TimescaleDB architecture project charging demand with quarter-hour resolution through 2040. The model calibration deployed real-world data from 764 charging points collected over 30 months, which generated 2.1 million charging sessions. A dynamic coincidence factor ((Formula presented.)) was incorporated, resulting in a 52% reduction in demand overestimation compared to traditional models. The results for the 2040 project show a peak demand of 255 MW (95% CI: 240–270 MW) and an annual consumption of 800 GWh. These findings reveal that non-optimized time-of-use tariffs can generate a critical “cliff effect,” increasing peak demand by 32%, whereas smart charging management with randomization reduces it by 18 ± 2.5%. Model validation yields a MAPE of 4.2 ± 0.8% and an RMSE of 12.3 MW. The TimescaleDB architecture demonstrated processing speeds of 2398.7 records/second and achieved 91% data compression. This methodology offers robust tools for urban energy planning and demand-side management policy optimization in high-altitude contexts, with the source code available to ensure reproducibility. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/en7042317,Energies,"Electricity consumption in the world is constantly increasing, making our lives become more and more dependent on electricity. There are several new paradigms proposed in the field of power grids. In Japan, especially after the Great East Japan Earthquake in March 2011, the new power grid paradigms are expected to be more resilient to survive several difficulties during disasters. In this paper, we focus on microgrids and propose priority-based hierarchical operational management for multiagent-based microgrids. The proposed management is a new multiagent-based load shedding scheme and multiagent-based hierarchical architecture to realize such resilient microgrids. We developed a prototype system and performed an evaluation of the proposed management using the developed system. The result of the evaluation shows the effectiveness of our proposal in power shortage situations, such as disasters. © 2014 by the authors. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.3390/en9030142,Energies,"This paper describes the complete integration of a fuzzy control of multiple evaporator systems with the IEEE 802.15.4 standard, in which we study several important aspects for this kind of system, like a detailed analysis of the end-to-end real-time flows over wireless sensor and actuator networks (WSAN), a real-time kernel with an earliest deadline first (EDF) scheduler, periodic and aperiodic tasking models for the nodes, lightweight and flexible compensation-based control algorithms for WSAN that exhibit packet dropouts, an event-triggered sampling scheme and design methodologies. We address the control problem of the multi-evaporators with the presence of uncertainties, which was tackled through a wireless fuzzy control approach, showing the advantages of this concept where it can easily perform the optimization for a set of multiple evaporators controlled by the same smart controller, which should have an intelligent and flexible architecture based on multi-agent systems (MAS) that allows one to add or remove new evaporators online, without the need for reconfiguring, while maintaining temporal and functional restrictions in the system. We show clearly how we can get a greater scalability, the self-configuration of the network and the least overhead with a non-beacon or unslotted mode of the IEEE 802.15.4 protocol, as well as wireless communications and distributed architectures, which could be extremely helpful in the development process of networked control systems in large spatially-distributed plants, which involve many sensors and actuators. For this purpose, a fuzzy scheme is used to control a set of parallel evaporator air-conditioning systems, with temperature and relative humidity control as a multi-input and multi-output closed loop system; in addition, a general architecture is presented, which implements multiple control loops closed over a communication network, integrating the analysis and validation method for multi-loop control networks designed for multi-evaporator systems. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.3390/fi16050152,Future Internet,"Efficient spectrum sharing is essential for maximizing data communication performance in Vehicular Networks (VNs). In this article, we propose a novel hybrid framework that leverages Multi-Agent Reinforcement Learning (MARL), thereby combining both centralized and decentralized learning approaches. This framework addresses scenarios where multiple vehicle-to-vehicle (V2V) links reuse the frequency spectrum preoccupied by vehicle-to-infrastructure (V2I) links. We introduce the QMIX technique with the Deep Q Networks (DQNs) algorithm to facilitate collaborative learning and efficient spectrum management. The DQN technique uses a neural network to approximate the Q value function in high-dimensional state spaces, thus mapping input states to (action, Q value) tables that facilitate self-learning across diverse scenarios. Similarly, the QMIX is a value-based technique for multi-agent environments. In the proposed model, each V2V agent having its own DQN observes the environment, receives observation, and obtains a common reward. The QMIX network receives Q values from all agents considering individual benefits and collective objectives. This mechanism leads to collective learning while V2V agents dynamically adapt to real-time conditions, thus improving VNs performance. Our research finding highlights the potential of hybrid MARL models for dynamic spectrum sharing in VNs and paves the way for advanced cooperative learning strategies in vehicular communication environments. Furthermore, we conducted an in-depth exploration of the simulation environment and performance evaluation criteria, thus concluding in a comprehensive comparative analysis with cutting-edge solutions in the field. Simulation results show that the proposed framework efficiently performs against the benchmark architecture in terms of V2V transmission probability and V2I peak data transfer. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/fi17050205,Future Internet,"Blockchain technology is emerging as a pivotal framework to enhance the security of internet-based systems, especially as advancements in machine learning (ML), artificial intelligence (AI), and cyber–physical systems such as smart grids and IoT applications in healthcare continue to accelerate. Although these innovations promise significant improvements, security remains a critical challenge. Blockchain offers a secure foundation for integrating diverse technologies; however, vulnerabilities—including adversarial exploits—can undermine performance and compromise application reliability. To address these risks effectively, it is essential to comprehensively analyze the vulnerability landscape of blockchain systems. This paper contributes in two key ways. First, it presents a unique layer-based framework for analyzing and illustrating security attacks within blockchain architectures. Second, it introduces a novel taxonomy that classifies existing research on blockchain vulnerability detection. Our analysis reveals that while ML and deep learning offer promising approaches for detecting vulnerabilities, their effectiveness often depends on access to extensive and high-quality datasets. Additionally, the layer-based framework demonstrates that vulnerabilities span all layers of a blockchain system, with attacks frequently targeting the consensus process, network integrity, and smart contract code. Overall, this paper provides a comprehensive overview of blockchain security threats and detection methods, emphasizing the need for a multifaceted approach to safeguard these evolving systems. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/fi17070291,Future Internet,"To address the fact that changes in network topology can have an impact on the performance of routing, this paper proposes an Elastic Routing Algorithm based on Multi-Agent Deep Deterministic Policy Gradient (ERA-MADDPG), which is implemented within the framework of Multi-Agent Deep Deterministic Policy Gradient (MADDPG) in deep reinforcement learning. The algorithm first builds a three-layer architecture based on Software-Defined Networking (SDN). The top-down layers are the multi-agent layer, the controller layer, and the data layer. The architecture’s processing flow, including real-time data layer information collection and dynamic policy generation, enables the ERA-MADDPG algorithm to exhibit strong elasticity by quickly adjusting routing decisions in response to topology changes. The actor-critic framework combined with Convolutional Neural Networks (CNN) to implement the ERA-MADDPG routing algorithm effectively improves training efficiency, enhances learning stability, facilitates collaboration, and improves algorithm generalization and applicability. Finally, simulation experiments demonstrate that the convergence speed of the ERA-MADDPG routing algorithm outperforms that of the Multi-Agent Deep Q-Network (MADQN) algorithm and the Smart Routing based on Deep Reinforcement Learning (SR-DRL) algorithm, and the training speed in the initial phase is improved by approximately 20.9% and 39.1% compared to the MADQN algorithm and SR-DRL algorithm, respectively. The elasticity performance of ERA-MADDPG is quantified by re-convergence speed: under 5–15% topology node/link changes, its re-convergence speed is over 25% faster than that of MADQN and SR-DRL, demonstrating superior capability to maintain routing efficiency in dynamic environments. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/fi17100434,Future Internet,"Cloud-native applications have significantly advanced the development and scalability of online services through the use of microservices and modular architectures. However, achieving adaptability, resilience, and efficient performance management within cloud environments remains a key challenge. This work systematically reviews 111 publications from the last eight years on self-adaptive cloud design and operations patterns, classifying them by objectives, control scope, decision-making approach, automation level, and validation methods. Our analysis reveals that performance optimization dominates research goals, followed by cost reduction and security enhancement, with availability and reliability underexplored. Reactive feedback loops prevail, while proactive approaches—often leveraging machine learning—are increasingly applied to predictive resource provisioning and application management. Resource-oriented adaptation strategies are common, but direct application-level reconfiguration remains scarce, representing a promising research gap. We further catalog tools, platforms, and more than 30 publicly accessible datasets used in validation, and that dataset usage is fragmented without a de facto standard. Finally, we map the research findings on a generic application and system-level design for self-adaptive applications, including a proposal for a federated learning approach for SaaS application Agents. This blueprint aims to guide future work toward more intelligent, context-aware cloud automation. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms19051265,International Journal of Molecular Sciences,"Kalanchoe brasiliensis and Kalanchoe pinnata are used interchangeably in traditional medicine for treating peptic ulcers and inflammatory problems. In this context, this study aims to characterize the chemical constituents and evaluate the gastroprotective activity of the leaf juices of the two species in acute gastric lesions models. Thin Layer Chromatography (TLC) and Ultra High Performance Liquid Chromatography coupled to Mass Spectrometer (UHPLC-MS) were performed for chemical characterization. Wistar rats were pre-treated orally with leaf juices (125, 250 and 500 mg/kg) or ranitidine (50 mg/kg). The peaks observed in the chromatogram of K. brasiliensis showed similar mass spectra to flavonoid glycosides derived from patuletin and eupafolin, while K. pinnata showed mass spectra similar to compounds derived from quercetin, patuletin, eupafolin and kaempferol. K. brasiliensis at all doses and K. pinnata at doses of 250 mg/kg and 500 mg/kg significantly reduced the lesions in the ethanol induction model. In the indomethacin induction model, both species showed significant results at doses of 250 and 500 mg/kg. Also, the pre-treatment with leaf juices increased the antioxidant defense system, glutathione (GSH), whereas malondialdehyde (MDA), myeloperoxidase (MPO), interleukin-1β (IL-1 β) and tumor necrosis factor-α (TNF-α) levels were significantly decreased. Treatment with leaf juices led to the upregulation of zone occludes-1 (ZO-1) and the downregulation of inducible nitric oxide synthase (iNOS) and factor nuclear- κβ transcription (NF-κB-p65), while also showing a cytoprotective effect and maintaining mucus production. These findings show that the leaf juices of the two species showed gastroprotective effects on ethanol and gastric indomethacin injury which were a consequence of gastric inflammation suppression, antioxidant activity and the maintenance of cytoprotective defenses and mucosal structure architecture. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms20133172,International Journal of Molecular Sciences,"Flexibility in carbon metabolism is pivotal for the survival and propagation of many human fungal pathogens within host niches. Indeed, flexible carbon assimilation enhances pathogenicity and affects the immunogenicity of Candida albicans. Over the last decade, Candida glabrata has emerged as one of the most common and problematic causes of invasive candidiasis. Despite this, the links between carbon metabolism, fitness, and pathogenicity in C. glabrata are largely unexplored. Therefore, this study has investigated the impact of alternative carbon metabolism on the fitness and pathogenic attributes of C. glabrata. We confirm our previous observation that growth on carbon sources other than glucose, namely acetate, lactate, ethanol, or oleate, attenuates both the planktonic and biofilm growth of C. glabrata, but that biofilms are not significantly affected by growth on glycerol. We extend this by showing that C. glabrata cells grown on these alternative carbon sources undergo cell wall remodeling, which reduces the thickness of their β-glucan and chitin inner layer while increasing their outer mannan layer. Furthermore, alternative carbon sources modulated the oxidative stress resistance of C. glabrata as well as the resistance of C. glabrata to an antifungal drug. In short, key fitness and pathogenic attributes of C. glabrata are shown to be dependent on carbon source. This reaffirms the perspective that the nature of the carbon sources available within specific host niches is crucial for C. glabrata pathogenicity during infection. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms20143490,International Journal of Molecular Sciences,"Biomedical imaging modalities in clinical practice have revolutionized oncology for several decades. State-of-the-art biomedical techniques allow visualizing both normal physiological and pathological architectures of the human body. The use of nanoparticles (NP) as contrast agents enabled visualization of refined contrast images with superior resolution, which assists clinicians in more accurate diagnoses and in planning appropriate therapy. These desirable features are due to the ability of NPs to carry high payloads (contrast agents or drugs), increased in vivo half-life, and disease-specific accumulation. We review the various NP-based interventions for treatments of deep-seated tumors, involving “seeing better” to precisely visualize early diagnosis and “going deeper” to activate selective therapeutics in situ. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms20143597,International Journal of Molecular Sciences,"Transposable elements (TEs) are agents of genetic variability in phytopathogens as they are a source of adaptive evolution through genome diversification. Although many studies have uncovered information on TEs, the exact mechanism behind TE-induced changes within the genome remains poorly understood. Furthermore, convergent trends towards bigger genomes, emergence of novel genes and gain or loss of genes implicate a TE-regulated genome plasticity of fungal phytopathogens. TEs are able to alter gene expression by revamping the cis-regulatory elements or recruiting epigenetic control. Recent findings show that TEs recruit epigenetic control on the expression of effector genes as part of the coordinated infection strategy. In addition to genome plasticity and diversity, fungal pathogenicity is an area of economic concern. A survey of TE distribution suggests that their proximity to pathogenicity genes TEs may act as sites for emergence of novel pathogenicity factors via nucleotide changes and expansion or reduction of the gene family. Through a systematic survey of literature, we were able to conclude that the role of TEs in fungi is wide: ranging from genome plasticity, pathogenicity to adaptive behavior in evolution. This review also identifies the gaps in knowledge that requires further elucidation for a better understanding of TEs’ contribution to genome architecture and versatility. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms21113901,International Journal of Molecular Sciences,"The aim of this study is to optimize and evaluate the effectiveness of vitrification, droplet-vitrification, and encapsulation-vitrification techniques in the cryopreservation of Lamprocapnos spectabilis (L.) Fukuhara ‘Gold Heart’, a popular medicinal and ornamental plant species. In vitro-derived shoot tips were used in the experiments. All three techniques were based on explant dehydration with plant vitrification solution 3 (PVS3; 50% glycerol and 50% sucrose) for 0, 30, 60, 90, 120, 150, or 180 min. The recovered microshoots were subjected to morphometric, biochemical, and molecular analyses (RAPD, ISSR, SCoT). The highest recovery level was reported with the encapsulation-vitrification protocol based on 150 min dehydration (73.1%), while the vitrification technique was the least effective (maximum 25.8% recovery). Explants cryopreserved with the encapsulation-vitrification technique produced the highest mean number of shoots (4.9); moreover, this technique was optimal in terms of rooting efficiency. The highest fresh weight of shoots, on the other hand, was found with the vitrification protocol based on a 30-min PVS3 treatment. The concentrations of chlorophyll a and b were lower in all cryopreservation-derived plants, compared to the untreated control. On the other hand, short dehydration and cryopreservation of non-encapsulated explants stimulated the synthesis of anthocyanins. A small genetic variation in 5% of all samples analyzed was detected by RAPD and ISSR marker systems. Only plants recovered from the encapsulation-vitrification protocol had no DNA sequence alternations. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms21186505,International Journal of Molecular Sciences,"Allotetraploid cotton (Gossypium hirsutum and Gossypium barbadense) are cultivated worldwide for its white fiber. For centuries, conventional breeding approaches increase cotton yield at the cost of extensive erosion of natural genetic variability. Sea Island cotton (G. barbadense) is known for its superior fiber quality, but show poor adaptability as compared to Upland cotton. Here, in this study, we use ethylmethanesulfonate (EMS) as a mutagenic agent to induce genome-wide point mutations to improve the current germplasm resources of Sea Island cotton and develop diverse breeding lines with improved adaptability and excellent economic traits. We determined the optimal EMS experimental procedure suitable for construction of cotton mutant library. At M<inf>6</inf> generation, mutant library comprised of lines with distinguished phenotypes of the plant architecture, leaf, flower, boll, and fiber. Genome-wide analysis of SNP distribution and density in yellow leaf mutant reflected the better quality of mutant library. Reduced photosynthetic efficiency and transmission electron microscopy of yellow leaf mutants revealed the effect of induced mutations at physiological and cellular level. Our mutant collection will serve as the valuable resource for basic research on cotton functional genomics, as well as cotton breeding. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms22052546,International Journal of Molecular Sciences,"Determination and comparisons of complete mitochondrial genomes (mitogenomes) are important to understand the origin and evolution of mitochondria. Mitogenomes of unicellular protists are particularly informative in this regard because they are gene-rich and display high structural diversity. Ciliates are a highly diverse assemblage of protists and their mitogenomes (linear structure with high A+T content in general) were amongst the first from protists to be characterized and have provided important insights into mitogenome evolution. Here, we report novel mitogenome sequences from three representatives (Strombidium sp., Strombidium cf. sulcatum, and Halteria grandinella) in two dominant ciliate lineages. Comparative and phylogenetic analyses of newly sequenced and previously published ciliate mitogenomes were performed and revealed a number of important insights. We found that the mitogenomes of these three species are linear molecules capped with telomeric repeats that differ greatly among known species. The genomes studied here are highly syntenic, but larger in size and more gene-rich than those of other groups. They also all share an AT-rich tandem repeat region which may serve as the replication origin and modulate initiation of bidirectional transcription. More generally we identified a split version of ccmf, a cytochrome c maturation-related gene that might be a derived character uniting taxa in the subclasses Hypotrichia and Euplotia. Finally, our mitogenome comparisons and phylogenetic analyses support to reclassify Halteria grandinella from the subclass Oligotrichia to the subclass Hypotrichia. These results add to the growing literature on the unique features of ciliate mitoge-nomes, shedding light on the diversity and evolution of their linear molecular architecture. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms22062922,International Journal of Molecular Sciences,"Tumor necrosis factor-alpha (TNF-α) is a multifunctional Th1 cytokine and one of the most important inflammatory cytokines. In pregnancy, TNF-α influences hormone synthesis, placental architecture, and embryonic development. It was also shown that increased levels of TNF-α are associated with pregnancy loss and preeclampsia. Increased TNF-α levels in complicated pregnancy draw attention to trophoblast biology, especially migratory activity, syncytialisation, and endocrine function. Additionally, elevated TNF-α levels may affect the maternal-fetal relationship by altering the secretory profile of placental immunomodulatory factors, which in turn affects maternal immune cells. There is growing evidence that metabolic/pro-inflammatory cytokines can program early placental functions and growth in the first trimester of pregnancy. Furthermore, early pregnancy placenta has a direct impact on fetal development and maternal immune system diseases that release inflammatory (e.g., TNF-α) and immunomodulatory factors, such as chronic inflammatory rheumatic, gastroenterological, or dermatological diseases, and may result in an abnormal release of cytokines and chemokines in syncytiotrophoblasts. Pregnancy poses a challenge in the treatment of chronic disease in patients who plan to have children. The activity of the disease, the impact of pregnancy on the course of the disease, and the safety of pharmacotherapy, including anti-rheumatic agents, in pregnancy should be considered. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms22105314,International Journal of Molecular Sciences,"Drought response in wheat is considered a highly complex process, since it is a multigenic trait; nevertheless, breeding programs are continuously searching for new wheat varieties with characteristics for drought tolerance. In a previous study, we demonstrated the effectiveness of a mutant known as RYNO3936 that could survive 14 days without water. In this study, we reveal another mutant known as BIG8-1 that can endure severe water deficit stress (21 days without water) with superior drought response characteristics. Phenotypically, the mutant plants had broader leaves, including a densely packed fibrous root architecture that was not visible in the WT parent plants. During mild (day 7) drought stress, the mutant could maintain its relative water content, chlorophyll content, maximum quantum yield of PSII (Fv/Fm) and stomatal conductance, with no phenotypic symptoms such as wilting or senescence despite a decrease in soil moisture content. It was only during moderate (day 14) and severe (day 21) water deficit stress that a decline in those variables was evident. Furthermore, the mutant plants also displayed a unique preservation of metabolic activity, which was confirmed by assessing the accumulation of free amino acids and increase of antioxidative enzymes (peroxidases and glutathione S-transferase). Proteome reshuffling was also observed, allowing slow degradation of essential proteins such as RuBisCO during water deficit stress. The LC-MS/MS data revealed a high abundance of proteins involved in energy and photosynthesis under well-watered conditions, particularly Serpin-Z2A and Z2B, SGT1 and Calnexin-like protein. However, after 21 days of water stress, the mutants expressed ABC transporter permeases and xylanase inhibitor protein, which are involved in the transport of amino acids and protecting cells, respectively. This study characterizes a new mutant BIG8-1 with drought-tolerant characteristics suited for breeding programs. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms22137136,International Journal of Molecular Sciences,"The best-characterized members of the M23 family are glycyl-glycine hydrolases, such as lysostaphin (Lss) from Staphylococcus simulans or LytM from Staphylococcus aureus. Recently, enzymes with broad specificities were reported, such as EnpA<inf>CD</inf> from Enterococcus faecalis, that cleaves D,L peptide bond between the stem peptide and a cross-bridge. Previously, the activity of EnpA<inf>CD</inf> was demonstrated only on isolated peptidoglycan fragments. Herein we report conditions in which EnpA<inf>CD</inf> lyses bacterial cells live with very high efficiency demonstrating great bacteriolytic potential, though limited to a low ionic strength environment. We have solved the structure of the EnpA<inf>CD</inf> H109A inactive variant and analyzed it in the context of related peptidoglycan hydrolases structures to reveal the bases for the specificity determination. All M23 structures share a very conserved β-sheet core which constitutes the rigid bottom of the substrate-binding groove and active site, while variable loops create the walls of the deep and narrow binding cleft. A detailed analysis of the binding groove architecture, specificity of M23 enzymes and D,L peptidases demonstrates that the substrate groove, which is particularly deep and narrow, is accessible preferably for peptides composed of amino acids with short side chains or subsequent L and D-isomers. As a result, the bottom of the groove is involved in interactions with the main chain of the substrate while the side chains are protruding in one plane towards the groove opening. We concluded that the selectivity of the substrates is based on their conformations allowed only for polyglycine chains and alternating chirality of the amino acids. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms222212391,International Journal of Molecular Sciences,"The imbalance between bone resorption and bone formation in favor of resorption results in bone loss and deterioration of bone architecture. Osteoblast differentiation is a sequential event accompanying biogenesis of matrix vesicles and mineralization of collagen matrix with hydroxyapatite crystals. Considerable efforts have been made in developing naturally-occurring plant compounds, preventing bone pathologies, or enhancing bone regeneration. Coumarin aesculetin inhibits osteoporosis through hampering the ruffled border formation of mature osteoclasts. However, little is known regarding the effects of aesculetin on the impairment of matrix vesicle biogenesis. MC3T3-E1 cells were cultured in differentiation media with 1–10 µM aesculetin for up to 21 days. Aesculetin boosted the bone morphogenetic protein-2 expression, and alkaline phosphatase activation of differentiating MC3T3-E1 cells. The presence of aesculetin strengthened the expression of collagen type 1 and osteoprotegerin and transcription of Runt-related transcription factor 2 in differentiating osteoblasts for 9 days. When ≥1–5 µM aesculetin was added to differentiating cells for 15–18 days, the induction of non-collagenous proteins of bone sialoprotein II, osteopontin, osteocalcin, and osteonectin was markedly enhanced, facilitating the formation of hydroxyapatite crystals and mineralized collagen matrix. The induction of annexin V and PHOSPHO 1 was further augmented in ≥5 µM aesculetin-treated differentiating osteoblasts for 21 days. In addition, the levels of tissue-nonspecific alkaline phosphatase and collagen type 1 were further enhanced within the extracellular space and on matrix vesicles of mature osteoblasts treated with aesculetin, indicating matrix vesicle-mediated bone mineralization. Finally, aesculetin markedly accelerated the production of thrombospondin-1 and tenascin C in mature osteoblasts, leading to their adhesion to preformed collagen matrix. Therefore, aesculetin enhanced osteoblast differentiation, and matrix vesicle biogenesis and mineralization. These findings suggest that aesculetin may be a potential osteo-inductive agent preventing bone pathologies or enhancing bone regeneration. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms23031401,International Journal of Molecular Sciences,"Cannabis is one of the most commonly used recreational drugs worldwide. Rrecent epidemi-ology studies have linked increased cardiac complications to cannabis use. However, this literature is predominantly based on case incidents and post-mortem investigations. This study elucidates the molecular mechanism of ∆9-tetrahydrocannabinol (THC), and its primary metabolites 11-Hydroxy-∆9-THC (THC-OH) and 11-nor-9-carboxy-∆9-tetrahydrocannabinol (THC-COOH). Treatment of cardiac myocytes with THC-OH and THC-COOH increased cell migration and proliferation (p < 0.05), with no effect on cell adhesion, with higher doses (250–100 ng/mL) resulting in increased cell death and significant deterioration in cellular architecture. Conversely, no changes in cell morphology or viability were observed in response to THC. Expression of key ECM proteins α-SMA and collagen were up-regulated in response to THC-OH and THC-COOH treatments with concomitant modulation of PI3K and MAPK signalling. Investigations in the planarian animal model Polycelis nigra demonstrated that treatments with cannabinoid metabolites resulted in increased protein deposition at transection sites while higher doses resulted in significant lethality and decline in regeneration. These results highlight that the key metabolites of cannabis elicit toxic effects independent of the parent and psychoactive compound, with implications for cardiotoxicity relating to hypertrophy and fibrogenesis. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms232012342,International Journal of Molecular Sciences,"Natural products are a vital source for agriculture, medicine, cosmetics and other fields. Lipodepsipeptides (LPDs) are a wide group of natural products distributed among living organisms such as bacteria, fungi, yeasts, virus, insects, plants and marine organisms. They are a group of compounds consisting of a lipid connected to a peptide, which are able to self-assemble into several different structures. They have shown different biological activities such as phytotoxic, antibiotic, antiviral, antiparasitic, antifungal, antibacterial, immunosuppressive, herbicidal, cytotoxic and hemolytic activities. Their biological activities seem to be due to their interactions with the plasma membrane (MP) because they are able to mimic the architecture of the native membranes interacting with their hydrophobic segment. LPDs also have surfactant properties. The review has been focused on the lipodepsipeptides isolated from fungal and bacterial sources, on their biological activity, on the structure–activity relationships of some selected LPD subgroups and on their potential application in agriculture and medicine. The chemical and biological characterization of lipodepsipeptides isolated in the last three decades and findings that resulted from SCI-FINDER research are reported. A critical evaluation of the most recent reviews dealing with the same argument has also been described. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms232012432,International Journal of Molecular Sciences,"Diabetes has become a critical challenge to the global health concerns. Cytotoxicity and development of resistance against available drugs for management of diabetes have shifted the focus of global scientific researchers from synthetic to herbal medications. Therefore, the current study was conducted to investigate the possible anti-hyperglycemic potential of Dryopteris stewartii using Swiss albino mice. To evaluate any possible toxic effect of the plant, acute oral toxicity test was performed while the anti-diabetic effects of aqueous and ethanol extracts at 500 mg/kg, positive, negative and normal control were assessed simultaneously. The anti-diabetic study revealed that aqueous extract has higher anti-diabetic potential than ethanol extract while lowered blood glucose level at second week reaching 150 mg/dL, exerting stronger anti-diabetic effects, compared to ethanol extract (190 mg/dL). Oral glucose tolerance findings revealed that aqueous extract decreased blood glucose level by −0.41-fold, compared to ethanol extract showing a decrease by only −0.29-folds. The histopathological evaluation of liver and pancreas of all groups revealed normal cell architecture with no morphological abnormalities. These results suggested the possible use of D. stewartii as anti-diabetic herbal drug in near future. However, these recommendations are conditioned by deep mechanistic studies. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms232315355,International Journal of Molecular Sciences,"Despite their great benefits for debilitated patients, indwelling devices are prone to become easily colonized by resident and opportunistic microorganisms, which have the ability to attach to their surfaces and form highly specialized communities called biofilms. These are extremely resistant to host defense mechanisms and antibiotics, leading to treatment failure and device replacement, but also to life-threatening complications. In this study, we aimed to optimize a silica (SiO<inf>2</inf>)-coated magnetite (Fe<inf>3</inf>O<inf>4</inf>)-based nanosystem containing the natural antimicrobial agent, eugenol (E), suitable for MAPLE (matrix-assisted pulsed laser evaporation) deposition as a bioactive coating for biomedical applications. X-ray diffraction, thermogravimetric analysis, Fourier-transform infrared spectroscopy, and transmission electron microscopy investigations were employed to characterize the obtained nanosystems. The in vitro tests evidenced the superior biocompatibility of such nanostructured coatings, as revealed by their non-cytotoxic activity and ability to promote cellular proliferation and sustain normal cellular development of dermal fibroblasts. Moreover, the obtained nanocoatings did not induce proinflammatory events in human blood samples. Our studies demonstrated that Fe<inf>3</inf>O<inf>4</inf> NPs can improve the antimicrobial activity of E, while the use of a SiO<inf>2</inf> matrix may increase its efficiency over prolonged periods of time. The Fe<inf>3</inf>O<inf>4</inf>@SiO<inf>2</inf> nanosystems showed excellent biocompatibility, sustaining human dermal fibroblasts’ viability, proliferation, and typical architecture. More, the novel coatings lack proinflammatory potential as revealed by the absence of proinflammatory cytokine expression in response to human blood sample interactions. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms24054328,International Journal of Molecular Sciences,"Cancer is one of the leading diseases threatening human life and health worldwide. Peptide-based therapies have attracted much attention in recent years. Therefore, the precise prediction of anticancer peptides (ACPs) is crucial for discovering and designing novel cancer treatments. In this study, we proposed a novel machine learning framework (GRDF) that incorporates deep graphical representation and deep forest architecture for identifying ACPs. Specifically, GRDF extracts graphical features based on the physicochemical properties of peptides and integrates their evolutionary information along with binary profiles for constructing models. Moreover, we employ the deep forest algorithm, which adopts a layer-by-layer cascade architecture similar to deep neural networks, enabling excellent performance on small datasets but without complicated tuning of hyperparameters. The experiment shows GRDF exhibits state-of-the-art performance on two elaborate datasets (Set 1 and Set 2), achieving 77.12% accuracy and 77.54% F1-score on Set 1, as well as 94.10% accuracy and 94.15% F1-score on Set 2, exceeding existing ACP prediction methods. Our models exhibit greater robustness than the baseline algorithms commonly used for other sequence analysis tasks. In addition, GRDF is well-interpretable, enabling researchers to better understand the features of peptide sequences. The promising results demonstrate that GRDF is remarkably effective in identifying ACPs. Therefore, the framework presented in this study could assist researchers in facilitating the discovery of anticancer peptides and contribute to developing novel cancer treatments. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms241411819,International Journal of Molecular Sciences,"Garlic (Allium sativum L.) is a popular condiment used as both medicine and food. Garlic production in China is severely affected by continuous cropping and is especially affected by leaf blight disease. Garlic is sterile, so it is very important to develop specialized genotypes, such as those for disease resistance, nutritional quality, and plant architecture, through genetic modification and innovation. In this experiment, we applied the induction method using EMS to mutate garlic cloves of cultivar G024. From the mutations, 5000 M<inf>0</inf> mutants were generated and planted in the field. Then, 199 M<inf>1</inf> mutant lines were screened according to growth potential and resistance to leaf blight. From M<inf>2</inf> to M<inf>3</inf>, 169 generational lines were selected that grew well and were resistant to leaf blight in the field. Thereafter, their resistance to leaf blight was further analyzed in the lab; 21 lines resistant to leaf blight that had good growth potential were identified, among which 3 mutants were significantly different, and these were further screened. Also, transcriptome analysis of two mutants infected with Pleospora herbarum, A150 and G024, was performed, and the results revealed 2026 and 4678 differentially expressed genes (DEGs), respectively. These DEGs were highly enriched in hormone signaling pathway, plant–pathogen interaction, and MAPK signaling pathway. Therefore, the results provide a theoretical and technical basis for the creation of garlic germplasm resistant to leaf blight. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms242015490,International Journal of Molecular Sciences,"Melon (Cucumis melo L.) is an important crop that is cultivated worldwide for its fleshy fruit. Understanding the genetic basis of a plant’s qualitative and quantitative traits is essential for developing consumer-favored varieties. This review presents genetic and molecular advances related to qualitative and quantitative phenotypic traits and biochemical compounds in melons. This information guides trait incorporation and the production of novel varieties with desirable horticultural and economic characteristics and yield performance. This review summarizes the quantitative trait loci, candidate genes, and development of molecular markers related to plant architecture, branching patterns, floral attributes (sex expression and male sterility), fruit attributes (shape, rind and flesh color, yield, biochemical compounds, sugar content, and netting), and seed attributes (seed coat color and size). The findings discussed in this review will enhance demand-driven breeding to produce cultivars that benefit consumers and melon breeders. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms25052606,International Journal of Molecular Sciences,"The use of gene-editing tools, such as zinc finger nucleases, TALEN, and CRISPR/Cas, allows for the modification of physiological, morphological, and other characteristics in a wide range of crops to mitigate the negative effects of stress caused by anthropogenic climate change or biotic stresses. Importantly, these tools have the potential to improve crop resilience and increase yields in response to challenging environmental conditions. This review provides an overview of gene-editing techniques used in plants, focusing on the cultivated tomatoes. Several dozen genes that have been successfully edited with the CRISPR/Cas system were selected for inclusion to illustrate the possibilities of this technology in improving fruit yield and quality, tolerance to pathogens, or responses to drought and soil salinity, among other factors. Examples are also given of how the domestication of wild species can be accelerated using CRISPR/Cas to generate new crops that are better adapted to the new climatic situation or suited to use in indoor agriculture. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms25052723,International Journal of Molecular Sciences,"Chamaecyparis obtusa (Siebold & Zucc.) Endl., which belongs to the Cupressaceae family, occurs naturally in North America and Asia, especially in Korea, Taiwan and Japan, where it is an evergreen, coniferous, sacred, ethnic tree. It has many useful varieties that are widespread throughout the world and grown for decorative purposes. It is most commonly used as an ornamental plant in homes, gardens or parks. It is also widely used in many areas of the economy; for example, its wood is used in architecture as well as furniture production. In addition, oil extracted from Chamaecyparis obtusa is increasingly used in cosmetology for skin care. Due to its wide economic demand, mainly in Japan, it represents the largest area of plantation forest. Despite this, it is on the red list of endangered species. Its use in ethnopharmacology has led to more and more research in recent years in an attempt to elucidate the potential mechanisms of its various biological activities, such as antimicrobial, antioxidant, anticancer, antidiabetic, antiasthmatic, anti-inflammatory, antiallergic, analgesic and central nervous system effects. It has also been shown that Chamaecyparis obtusa can be used as an insect repellent and an ingredient in plant disease treatment. This thesis provides a comprehensive review of the biological studies to date, looking at different areas of the economic fields of potential use of Chamaecyparis obtusa. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms25073597,International Journal of Molecular Sciences,"Limonoids are extremely diversified in plants, with many categories of products bearing an intact, rearranged or fragmented oxygenated scaffold. A specific subgroup of fragmented or degraded limonoids derives from the tetranortriterpenoid prieurianin, initially isolated from the tree Trichilia prieuriana but also found in other plants of the Meliaceae family, including the more abundant species Aphanamixis polystachya. Prieurianin-type limonoids include about seventy compounds, among which are dregeanin and rohitukin. Prieurianin and analogs exhibit insecticidal, antimicrobial, antiadipogenic and/or antiparasitic properties but their mechanism of action remains ill-defined at present. Previous studies have shown that prieurianin, initially known as endosidin 1, stabilizes the actin cytoskeleton in plant and mammalian cells via the modulation of the architecture and dynamic of the actin network, most likely via interference with actin-binding proteins. A new mechanistic hypothesis is advanced here based on the recent discovery of the targeting of the chaperone protein Hsp47 by the fragmented limonoid fraxinellone. Molecular modeling suggested that prieurianin and, to a lesser extent dregeanin, can form very stable complexes with Hsp47 at the protein–collagen interface. Hsp-binding may account for the insecticidal action of the product. The present review draws up a new mechanistic portrait of prieurianin and provides an overview of the pharmacological properties of this atypical limonoid and its chemical family. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms25073902,International Journal of Molecular Sciences,"Strigolactones (SLs) are plant hormones that regulate several key agronomic traits, including shoot branching, leaf senescence, and stress tolerance. The artificial regulation of SL biosynthesis and signaling has been considered as a potent strategy in regulating plant architecture and combatting the infection of parasitic weeds to help improve crop yield. DL1b is a previously reported SL receptor inhibitor molecule that significantly promotes shoot branching. Here, we synthesized 18 novel compounds based on the structure of DL1b. We performed rice tillering activity assay and selected a novel small molecule, C6, as a candidate SL receptor inhibitor. In vitro bioassays demonstrated that C6 possesses various regulatory functions as an SL inhibitor, including inhibiting germination of the root parasitic seeds Phelipanche aegyptiaca, delaying leaf senescence and promoting hypocotyl elongation of Arabidopsis. ITC analysis and molecular docking experiments further confirmed that C6 can interact with SL receptor proteins, thereby interfering with the binding of SL to its receptor. Therefore, C6 is considered a novel SL receptor inhibitor with potential applications in plant architecture control and prevention of root parasitic weed infestation. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms25168944,International Journal of Molecular Sciences,"Rosa davurica Pall. is widely used in traditional oriental herbal therapy, but its components and molecular mechanisms of action remain unclear. This study investigates the antidiabetic potential of Rosa davurica Pall. root extract (RDR) and elucidates its underlying molecular mechanisms with in vitro and in vivo models. Data from the current study show that RDR exhibits strong antioxidant activity and glucose homeostasis regulatory effects. It significantly impacts glucose homeostasis in C2C12 skeletal muscle cells by inhibiting α-glucosidase activity. Further molecular mechanistic studies revealed that RDR promoted glucose uptake by phosphorylation of AMP-activated protein kinase (AMPK)/acetyl-CoA carboxylase (ACC), but not Phosphatidylinositol 3-kinase (PI 3-kinase)/Akt in C2C12 skeletal muscle cells. These actions increased the expression and translocation of glucose transporter type 4 (GLUT4) to the plasma membrane. In addition, RDR treatment in the STZ-induced diabetic rats remarkably improved the low body weight, polydipsia, polyphagia, hyperglycemia, and islet architecture and increased the insulin/glucose ratio. The liver (ALT and AST) and kidney marker enzyme (BUN and creatinine) levels were restored by RDR treatment as well. Phytochemical analysis identified eight major constituents in RDR, crucial for its antioxidant and antidiabetic activity. Through the molecular docking of representative glucose transporter GLUT4 with these compounds, it was confirmed that the components of RDR had a significantly high binding score in terms of structural binding. These findings from the current study highlight the antidiabetic effects of RDR. Collectively, our data suggest that RDR might be a potential pharmaceutical natural product for diabetic patients. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms252413674,International Journal of Molecular Sciences,"Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is a member of the large coronavirus family with high infectivity and pathogenicity and is the primary pathogen causing the global pandemic of coronavirus disease 2019 (COVID-19). Phosphorylation is a major type of protein post-translational modification that plays an essential role in the process of SARS-CoV-2–host interactions. The precise identification of phosphorylation sites in host cells infected with SARS-CoV-2 will be of great importance to investigate potential antiviral responses and mechanisms and exploit novel targets for therapeutic development. Numerous computational tools have been developed on the basis of phosphoproteomic data generated by mass spectrometry-based experimental techniques, with which phosphorylation sites can be accurately ascertained across the whole SARS-CoV-2-infected proteomes. In this work, we have comprehensively reviewed several major aspects of the construction strategies and availability of these predictors, including benchmark dataset preparation, feature extraction and refinement methods, machine learning algorithms and deep learning architectures, model evaluation approaches and metrics, and publicly available web servers and packages. We have highlighted and compared the prediction performance of each tool on the independent serine/threonine (S/T) and tyrosine (Y) phosphorylation datasets and discussed the overall limitations of current existing predictors. In summary, this review would provide pertinent insights into the exploitation of new powerful phosphorylation site identification tools, facilitate the localization of more suitable target molecules for experimental verification, and contribute to the development of antiviral therapies. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms26073108,International Journal of Molecular Sciences,"Alzheimer’s disease (AD) is a neurodegenerative disorder characterized by cognitive decline, neuroinflammation and neuronal damage. This study aimed to investigate the neuroprotective effects of cilomilast (CILO), a phosphodiesterase-4 (PDE4) inhibitor, alone and in combination with chlorogenic acid (CGA), a natural polyphenol, against scopolamine (SCOP)-induced cognitive impairment in mice. Forty male albino mice were divided into five groups: normal control, SCOP control, CGA + SCOP, CILO + SCOP and CILO + CGA + SCOP. Behavioral assessments, including the Y-maze and pole climbing tests, demonstrated that SCOP significantly impaired cognition, while treatment with CILO and CGA reversed these deficits, with the combination group showing the greatest improvement. Histopathological analyses revealed that CILO and CGA reduced neuronal damage and amyloid beta (Aβ) accumulation. Immunohistochemical and biochemical assessments confirmed a decrease in neuroinflammatory markers, including tumor necrosis factor-alpha (TNF-α) and nuclear factor kappa B (NF-κB). Molecular analyses showed that CILO restored cyclic adenosine monophosphate (cAMP) levels, leading to activation of protein kinase A (PKA), cAMP response element-binding protein (CREB) and brain-derived neurotrophic factor (BDNF), key regulators of neuronal plasticity and survival. CGA enhanced these effects by further inhibiting PDE4, amplifying the neuroprotective response. These findings suggest that PDE4 inhibitors, particularly in combination with CGA, may represent promising therapeutic strategies for AD-related cognitive impairment. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms26125446,International Journal of Molecular Sciences,"Ulcerative colitis (UC) is a chronic inflammatory bowel disease with unmet therapeutic needs. This study investigates the therapeutic potential of Periplaneta americana L. extract (PAE) and its molecular mechanisms, integrating network pharmacology and experimental validation. Liquid chromatography–mass spectrometry identified 1355 compounds in PAE. Network pharmacology analysis revealed that inosine, vidarabine, and adenosine 5′-monophosphate (AMP) were core components and the core components synergistically regulated key targets and acted on inflammation-related pathways, thereby establishing a multi-target anti-inflammatory regulatory network. In vivo experiments demonstrated that these compounds significantly alleviated colitis symptoms in dextran sulfate sodium-induced mice, as evidenced by reduced disease activity index scores, preserved colonic mucosal architecture, and decreased inflammatory infiltration. Mechanistically, core compounds down-regulated granulocyte-macrophage colony-stimulating factor (GM-CSF), inducible nitric oxide synthase (iNOS)/NOS2, monocyte chemoattractant protein 1 (MCP-1), and transforming growth factor beta 1 (TGF-β1), while they up-regulated interleukin-10 (IL-10) and epidermal growth factor (EGF). Additionally, they activated epidermal growth factor receptor (EGFR)-mediated pathways. Molecular docking analysis revealed that adenosine analogs preferentially bound to A1/A2a receptors, triggering signaling cascades essential for epithelial repair and inflammation resolution. This study established the multi-component, multi-pathway mechanism of PAE in UC, highlighting its dual role in suppressing inflammation and promoting mucosal healing. By bridging traditional herbal use with modern molecular insights, these findings provided a translational foundation for developing PAE-based therapies for UC. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/ijms26209945,International Journal of Molecular Sciences,"Dysferlinopathies are progressive muscular dystrophies caused by DYSF mutations, leading to impaired membrane repair, chronic inflammation, lipid accumulation, and muscle degeneration. No approved therapies currently halt the progression of this disease. Here, we evaluated the effects of daily oral administration of pulverized Boldo (Peumus boldus) leaves, commonly used as a nutraceutical, to blAJ mice, a model of dysferlinopathy. Symptomatic bIAJ mice were treated for four weeks with Boldo and presented significantly improved grip strength and restored endothelial-dependent vasodilation. Muscle perfusion and capillary density in the gastrocnemius were both enhanced by treatment. Histological analyses revealed that Boldo prevented myofiber atrophy, reduced centrally nucleated fibers, and improved muscle tissue architecture. Lipid accumulation observed in blAJ muscles was absent in Boldo-treated mice. At the cellular level, Boldo normalized sarcolemma membrane permeability (dye uptake) and reduced mRNA levels of inflammasome components (NLRP3, ASC, and IL-1β), suggesting anti-inflammatory activity. These findings indicate that Boldo improves vascular and muscle integrity, supporting its potential as a complementary therapeutic strategy for dysferlinopathy. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/info10060205,Information (Switzerland),"Text information extraction is an important natural language processing (NLP) task, which aims to automatically identify, extract, and represent information from text. In this context, event extraction plays a relevant role, allowing actions, agents, objects, places, and time periods to be identified and represented. The extracted information can be represented by specialized ontologies, supporting knowledge-based reasoning and inference processes. In this work, we will describe, in detail, our proposal for event extraction from Portuguese documents. The proposed approach is based on a pipeline of specialized natural language processing tools; namely, a part-of-speech tagger, a named entities recognizer, a dependency parser, semantic role labeling, and a knowledge extraction module. The architecture is language-independent, but its modules are language-dependent and can be built using adequate AI (i.e., rule-based or machine learning) methodologies. The developed system was evaluated with a corpus of Portuguese texts and the obtained results are presented and analysed. The current limitations and future work are discussed in detail. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.3390/info12110435,Information (Switzerland),"In recent years, information integration systems have become very popular in mashup-type applications. Information sources are normally presented in an individual and unrelated fashion, and the development of new technologies to reduce the negative effects of information dispersion is needed. A major challenge is the integration and implementation of processing pipelines using different technologies promoting the emergence of advanced architectures capable of processing such a number of diverse sources. This paper describes a semantic domain-adaptable platform to integrate those sources and provide high-level functionalities, such as recommendations, shallow and deep natural language processing, text enrichment, and ontology standardization. Our proposed intelligent domain-adaptable platform (IDAP) has been implemented and tested in the tourism and biomedicine domains to demonstrate the adaptability, flexibility, modularity, and utility of the platform. Questionnaires, performance metrics, and A/B control groups’ evaluations have shown improvements when using IDAP in learning environments. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/jimaging7120276,Journal of Imaging,"The recent spread of Deep Learning (DL) in medical imaging is pushing researchers to explore its suitability for lesion segmentation in Dynamic Contrast-Enhanced Magnetic-Resonance Imaging (DCE-MRI), a complementary imaging procedure increasingly used in breast-cancer analysis. Despite some promising proposed solutions, we argue that a “naive” use of DL may have limited effectiveness as the presence of a contrast agent results in the acquisition of multimodal 4D images requiring thorough processing before training a DL model. We thus propose a pipelined approach where each stage is intended to deal with or to leverage a peculiar characteristic of breast DCE-MRI data: the use of a breast-masking pre-processing to remove non-breast tissues; the use of Three-Time-Points (3TP) slices to effectively highlight contrast agent time course; the application of a motion-correction technique to deal with patient involuntary movements; the leverage of a modified U-Net architecture tailored on the problem; and the introduction of a new “Eras/Epochs” training strategy to handle the unbalanced dataset while performing a strong data augmentation. We compared our pipelined solution against some literature works. The results show that our approach outperforms the competitors by a large margin (+9.13% over our previous solution) while also showing a higher generalization ability. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/math10020166,Mathematics,"Constitutional processes are a cornerstone of modern democracies. Whether revolutionary or institutionally organized, they establish the core values of social order and determine the institutional architecture that governs social life. Constitutional processes are themselves evolutionary practices of mutual learning in which actors, regardless of their initial political positions, continuously interact with each other, demonstrating differences and making alliances regarding different topics. In this article, we develop Tree Augmented Naive Bayes (TAN) classifiers to model the behavior of constituent agents. According to the nature of the constituent dynamics, weights are learned by the model from the data using an evolution strategy to obtain a good classification performance. For our analysis, we used the constituent agents’ communications on Twitter during the installation period of the Constitutional Convention (July–October 2021). In order to differentiate political positions (left, center, right), we applied the developed algorithm to obtain the scores of 882 ballots cast in the first stage of the convention (4 July to 29 September 2021). Then, we used k-means to identify three clusters containing right-wing, center, and left-wing positions. Experimental results obtained using the three constructed datasets showed that using alternative weight values in the TAN construction procedure, inferred by an evolution strategy, yielded improvements in the classification accuracy measured in the test sets compared to the results of the TAN constructed with conditional mutual information, as well as other Bayesian network classifier construction approaches. Additionally, our results may help us to better understand political behavior in constitutional processes and to improve the accuracy of TAN classifiers applied to social, real-world data. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/math12162469,Mathematics,"The rapid development of artificial intelligence (AI) and 5G paradigm brings infinite possibilities for data annotation for new applications in the industrial Internet of Things (IIoT). However, the problem of data annotation consistency under distributed architectures and growing concerns about issues such as data privacy and cybersecurity are major obstacles to improving the quality of distributed data annotation. In this paper, we propose a reputation-based asynchronous federated learning approach for digital twins. First, this paper integrates digital twins into an asynchronous federated learning framework, and utilizes a smart contract-based reputation mechanism to enhance the interconnection and internal interaction of asynchronous mobile terminals. In addition, in order to enhance security and privacy protection in the distributed smart annotation system, this paper introduces blockchain technology to optimize the data exchange, storage, and sharing process to improve system security and reliability. The data results show that the consistency of our proposed FedDTrep distributed intelligent labeling system reaches 99%. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/math13182971,Mathematics,"Delegation of authority remains a critical yet insufficiently addressed capability in Self-Sovereign Identity (SSI) systems. Building on an existing delegation model that introduced the concept of a Verifiable Mandate (VM) for expressing authority and access rights, this paper extends the approach with a rigorous formalization of delegation semantics, enabling unambiguous reasoning over roles, grants, and constraints. The formal model is aligned with standards from the World Wide Web Consortium (W3C), and its constructs are embedded into an extended credential schema that preserves compatibility with the Verifiable Credentials (VC) data model while introducing delegation-specific attributes. A generalized VM schema is defined, supporting both generic and business-specific instantiations, and ensuring structural and semantic interoperability. Policy compliance is operationalized through a policy-based enforcement architecture, where rules are authored in the Rego language and evaluated at runtime by the Open Policy Agent (OPA). The architecture incorporates trusted registries for schema and policy distribution, allowing verifiers to define and enforce context-specific delegation rules in a modular and interoperable manner. Validation through realistic scenarios, such as postal service and academic use cases, demonstrates how formal semantics, schema validation, and language-based policy enforcement can be combined to enable secure, verifiable, and context-aware delegation in SSI ecosystems. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/mti7040039,Multimodal Technologies and Interaction,"Stimulus Equivalence (SE) is a behavioural phenomenon in which organisms respond functionally to stimuli without explicit training. SE provides a framework in the experimental analysis of behaviour to study language, symbolic behaviour, and cognition. It is also a frequently discussed matter in interdisciplinary research, linking behaviour analysis with linguistics and neuroscience. Previous research has attempted to replicate SE with computational agents, mostly based on Artificial Neural Network (ANN) models. The aim of this paper was to analyse the effect of three Training Structures (TSs) on stimulus class formation in a simulation with ANNs as computational agents performing a classification task, in a matching-to-sample procedure. Twelve simulations were carried out as a product of the implementation of four ANN architectures on the three TSs. SE was not achieved, but two agents showed an emergent response on half of the transitivity test pairs on linear sequence TSs and reflexivity on one member of the class. The results suggested that an ANN with a large enough number of units in a hidden layer can perform a limited number of emergent relations within specific experimental conditions: reflexivity on B and transitivity on AC, when pairs AB and BC are trained on a three-member stimulus class and tested in a classification task. Reinforcement learning is proposed as the framework for further simulations. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/mti9040031,Multimodal Technologies and Interaction,"Artificial agents are expected to increasingly interact with humans and to demonstrate multimodal adaptive emotional responses. Such social integration requires both perception and production mechanisms, thus enabling a more realistic approach to emotional alignment than existing systems. Indeed, existing emotion recognition methods rely on behavioral signals, predominantly facial expressions, as well as non-invasive brain recordings, such as Electroencephalograms (EEGs) and functional Magnetic Resonance Imaging (fMRI), to identify humans’ emotions, but accurate labeling remains a challenge. This paper introduces a novel approach examining how behavioral and physiological signals can be used to predict activity in emotion-related regions of the brain. To this end, we propose a multimodal deep learning network that processes two categories of signals recorded alongside brain activity during conversations: two behavioral signals (video and audio) and one physiological signal (blood pulse). Our network enables (1) the prediction of brain activity from these multimodal inputs, and (2) the assessment of our model’s performance depending on the nature of interlocutor (human or robot) and the brain region of interest. Results demonstrate that the proposed architecture outperforms existing models in anterior insula and hypothalamus regions, for interactions with a human or a robot. An ablation study evaluating subsets of input modalities indicates that local brain activity prediction was reduced when one or two modalities are omitted. However, they also revealed that the physiological data (blood pulse) achieve similar levels of predictions alone compared to the full model, further underscoring the importance of somatic markers in the central nervous system’s processing of social emotions. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/robotics10010017,Robotics,"Multifunctional Robot On Topological Notions (MROTN) is a research program that has as one of its goals to develop qualitative algorithms that make navigation decisions. This article presents new research from MROTN that extends previous results by allowing an agent to carry out qualitative reasoning about direction and spinning. The main result is a new heuristic, the Heuristic of Directional Qualitative Semantic (HDQS), which allows for selecting a spinning action to establish a directional relation between an agent and an object. The HDQS is based on the key idea of encoding directional information into topological relations. The new heuristic is important to the MROTN because it permits the continued development of qualitative navigation methods based on topological notions. We show this by presenting a new version of the Topological Qualitative Architecture of Navigation that uses the HDQS to address situations that require spinning. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/robotics10030084,Robotics,"The transportation of large payloads can be made possible with Multi-Robot Systems (MRS) implementing cooperative strategies. In this work, we focus on the coordinated MRS trajectory planning task exploiting a Model Predictive Control (MPC) framework addressing both the acting robots and the transported load. In this context, the main challenge is the possible occurrence of a temporary mismatch among agents’ actions with consequent formation errors that can cause severe damage to the carried load. To mitigate this risk, the coordination scheme may leverage a leader–follower approach, in which a hierarchical strategy is in place to trade-off between the task accomplishment and the dynamics and environment constraints. Nonetheless, particularly in narrow spaces or cluttered environments, the leader’s optimal choice may lead to trajectories that are infeasible for the follower and the load. To this aim, we propose a feasibility-aware leader– follower strategy, where the leader computes a reference trajectory, and the follower accounts for its own and the load constraints; moreover, the follower is able to communicate the trajectory infeasibility to the leader, which reacts by temporarily switching to a conservative policy. The consistent MRS co-design is allowed by the MPC formulation, for both the leader and the follower: here, the prediction capability of MPC is key to guarantee a correct and efficient execution of the leader–follower coordinated action. The approach is formally stated and discussed, and a numerical campaign is conducted to validate and assess the proposed scheme, with respect to different scenarios with growing complexity. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/robotics11020044,Robotics,"The foundation and emphasis of robotic manipulator control is Inverse Kinematics (IK). Due to the complexity of derivation, difficulty of computation, and redundancy, traditional IK solutions pose numerous challenges to the operation of a variety of robotic manipulators. This paper develops a Deep Reinforcement Learning (RL) approach for solving the IK problem of a 7-Degree of Freedom (DOF) robotic manipulator using Product of Exponentials (PoE) as a Forward Kinematics (FK) computation tool and the Deep Q-Network (DQN) as an IK solver. The selected approach is architecturally simpler, making it faster and easier to implement, as well as more stable, because it is less sensitive to hyperparameters than continuous action spaces algorithms. The algorithm is designed to produce joint-space trajectories from a given end-effector trajectory. Different network architectures were explored and the output of the DQN was implemented experimentally on a Sawyer robotic arm. The DQN was able to find different trajectories corresponding to a specified Cartesian path of the end-effector. The network agent was able to learn random Bézier and straight-line end-effector trajectories in a reasonable time frame with good accuracy, demonstrating that even though DQN is mainly used in discrete solution spaces, it could be applied to generate joint space trajectories. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/robotics12050133,Robotics,"Recent advancements in artificial intelligence have enabled reinforcement learning (RL) agents to exceed human-level performance in various gaming tasks. However, despite the state-of-the-art performance demonstrated by model-free RL algorithms, they suffer from high sample complexity. Hence, it is uncommon to find their applications in robotics, autonomous navigation, and self-driving, as gathering many samples is impractical in real-world hardware systems. Therefore, developing sample-efficient learning algorithms for RL agents is crucial in deploying them in real-world tasks without sacrificing performance. This paper presents an advisor-based learning algorithm, incorporating prior knowledge into the training by modifying the deep deterministic policy gradient algorithm to reduce the sample complexity. Also, we propose an effective method of employing an advisor in data collection to train autonomous navigation agents to maneuver physical platforms, minimizing the risk of collision. We analyze the performance of our methods with the support of simulation and physical experimental setups. Experiments reveal that incorporating an advisor into the training phase significantly reduces the sample complexity without compromising the agent’s performance compared to various benchmark approaches. Also, they show that the advisor’s constant involvement in the data collection process diminishes the agent’s performance, while the limited involvement makes training more effective. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/robotics14070086,Robotics,"Deep Reinforcement Learning (DRL) is a powerful framework for solving complex sequential decision-making problems, particularly in robotic control. However, its practical deployment is often hindered by the substantial amount of experience required for learning, which results in high computational and time costs. In this work, we propose a novel integration of DRL with semantic knowledge in the form of Knowledge Graph Embeddings (KGEs), aiming to enhance learning efficiency by providing contextual information to the agent. Our architecture combines KGEs with visual observations, enabling the agent to exploit environmental knowledge during training. Experimental validation with robotic manipulators in environments featuring both fixed and randomized target attributes demonstrates that our method achieves up to 60% reduction in learning time and improves task accuracy by approximately 15 percentage points, without increasing training time or computational complexity. These results highlight the potential of semantic knowledge to reduce sample complexity and improve the effectiveness of DRL in robotic applications. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/s140916486,Sensors,"In this paper, a remote lab for experimenting with a team of mobile robots is presented. Robots are built with the LEGO Mindstorms technology and user-defined control laws can be directly coded in the Matlab programming language and validated on the real system. The lab is versatile enough to be used for both teaching and research purposes. Students can easily go through a number of predefined mobile robotics experiences without having to worry about robot hardware or low-level programming languages. More advanced experiments can also be carried out by uploading custom controllers. The capability to have full control of the vehicles, together with the possibility to define arbitrarily complex environments through the definition of virtual obstacles, makes the proposed facility well suited to quickly test and compare different control laws in a real-world scenario. Moreover, the user can simulate the presence of different types of exteroceptive sensors on board of the robots or a specific communication architecture among the agents, so that decentralized control strategies and motion coordination algorithms can be easily implemented and tested. A number of possible applications and real experiments are presented in order to illustrate the main features of the proposed mobile robotics remote lab. © 2017 Elsevier B.V., All rights reserved.",TOPIC
10.3390/s19010017,Sensors,"Mobile multirobot systems play an increasing role in many disciplines. Their capabilities can be used, e.g., to transport workpieces in industrial applications or to support operational forces in search and rescue scenarios, among many others. Depending on the respective application, the hardware design and accompanying software of mobile robots are of various forms, especially for integrating different sensors and actuators. Concerning this design, robots of one system compared to each other can be classified to exclusively be either homogeneous or heterogeneous, both resulting in different system properties. While homogeneously configured systems are known to be robust against failures through redundancy but are highly specialized for specific use cases, heterogeneously designed systems can be used for a broad range of applications but suffer from their specialization, i.e., they can only hardly compensate for the failure of one specialist. Up to now, there has been no known approach aiming to unify the benefits of both these types of system. In this paper, we present our approach to filling this gap by introducing a reference architecture for mobile robots that defines the interplay of all necessary technologies for achieving this goal. We introduce the class of robot systems implementing this architecture as multipotent systems that bring together the benefits of both system classes, enabling homogeneously designed robots to become heterogeneous specialists at runtime. When many of these robots work together, we call the structure of this cooperation an ensemble. To achieve multipotent ensembles, we also integrate reconfigurable and self-descriptive hardware (i.e., sensors and actuators) in this architecture, which can be freely combined to change the capabilities of robots at runtime. Because typically a high degree of autonomy in such systems is a prerequisite for their practical usage, we also present the integration of necessary mechanisms and algorithms for achieving the systems’ multipotency. We already achieved the first results with robots implementing our approach of multipotent systems in real-world experiments as well as in a simulation environment, which we present in this paper. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.3390/s19204539,Sensors,"This paper presents an intelligent system designed to increase the treatment adherence of hypertensive patients. The architecture was developed to allow communication among patients, physicians, and families to determine each patient’s medication intake and self-monitoring of blood pressure rates. Concerning the medication schedule, the system is designed to follow a predefined prescription, adapting itself to undesired events, such as mistakenly taking medication or forgetting to take medication on time. When covering the blood pressure measurement, it incorporates best medical practices, registering the actual values in recommended frequency and form, trying to avoid the known “white-coat effect.” We assume that taking medicine precisely and measuring blood pressure correctly may lead to good adherence to the treatment. The system uses commercial consumer electronic devices and can be replicated in any home equipped with a standard personal computer and Internet access. The resulting architecture has four layers. The first is responsible for adding electronic devices that typically exist in today’s homes to the system. The second is a preprocessing layer that filters the data generated from the patient’s behavior. The third is a reasoning layer that decides how to act based on the patient’s activities observed. Finally, the fourth layer creates messages that should drive the reactions of all involved actors. The reasoning layer takes into consideration the patient’s schedule and medication-taking activity data and uses implicit algorithms based on the J48, RepTree, and RandomTree decision tree models to infer the adherence. The algorithms were first adjusted using one academic machine learning and data mining tool. The system communicates with users through smartphones (anytime and anywhere) and smart TVs (in the patient’s home) by using the 3G/4G and WiFi infrastructure. It interacts automatically through social networks with doctors and relatives when changes or mistakes in medication intake and blood pressure mean values are detected. By associating the blood pressure data with the history of medication intake, our system can indicate the treatment adherence and help patients to achieve better treatment results. Comparisons with similar research were made, highlighting our findings. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.3390/s20185058,Sensors,"(1) Background: People living with type 1 diabetes (T1D) require self-management to maintain blood glucose (BG) levels in a therapeutic range through the delivery of exogenous insulin. However, due to the various variability, uncertainty and complex glucose dynamics, optimizing the doses of insulin delivery to minimize the risk of hyperglycemia and hypoglycemia is still an open problem. (2) Methods: In this work, we propose a novel insulin bolus advisor which uses deep reinforcement learning (DRL) and continuous glucose monitoring to optimize insulin dosing at mealtime. In particular, an actor-critic model based on deep deterministic policy gradient is designed to compute mealtime insulin doses. The proposed system architecture uses a two-step learning framework, in which a population model is first obtained and then personalized by subject-specific data. Prioritized memory replay is adopted to accelerate the training process in clinical practice. To validate the algorithm, we employ a customized version of the FDA-accepted UVA/Padova T1D simulator to perform in silico trials on 10 adult subjects and 10 adolescent subjects. (3) Results: Compared to a standard bolus calculator as the baseline, the DRL insulin bolus advisor significantly improved the average percentage time in target range (70–180 mg/dL) from 74.1% ± 8.4% to 80.9% ± 6.9% (p < 0.01) and 54.9% ± 12.4% to 61.6% ± 14.1% (p < 0.01) in the the adult and adolescent cohorts, respectively, while reducing hypoglycemia. (4) Conclusions: The proposed algorithm has the potential to improve mealtime bolus insulin delivery in people with T1D and is a feasible candidate for future clinical validation. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.3390/s21124060,Sensors,"Recent advances in Deep Reinforcement Learning allow solving increasingly complex problems. In this work, we show how current defense mechanisms in Wireless Sensor Networks are vulnerable to attacks that use these advances. We use a Deep Reinforcement Learning attacker architecture that allows having one or more attacking agents that can learn to attack using only partial observations. Then, we subject our architecture to a test-bench consisting of two defense mechanisms against a distributed spectrum sensing attack and a backoff attack. Our simulations show that our attacker learns to exploit these systems without having a priori information about the defense mechanism used nor its concrete parameters. Since our attacker requires minimal hyperparameter tuning, scales with the number of attackers, and learns only by interacting with the defense mechanism, it poses a significant threat to current defense procedures. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/s22041499,Sensors,"Due to the relevant penetration of solar PV power plants, an accurate power generation forecasting of these installations is crucial to provide both reliability and stability of current grids. At the same time, PV monitoring requirements are more and more demanded by different agents to provide reliable information regarding performances, efficiencies, and possible predictive maintenance tasks. Under this framework, this paper proposes a methodology to evaluate different LoRa-based PV monitoring architectures and node layouts in terms of short-term solar power generation forecasting. A random forest model is proposed as forecasting method, simplifying the forecasting problem especially when the time series exhibits heteroscedasticity, nonstationarity, and multiple seasonal cycles. This approach provides a sensitive analysis of LoRa parameters in terms of node layout, loss of data, spreading factor and short time intervals to evaluate their influence on PV forecasting accuracy. A case example located in the southeast of Spain is included in the paper to evaluate the proposed analysis. This methodology is applicable to other locations, as well as different LoRa configurations, parameters, and networks structures; providing detailed analysis regarding PV monitoring performances and short-term PV generation forecasting discrepancies. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/s22062099,Sensors,"Autonomous collision avoidance technology provides an intelligent method for unmanned surface vehicles’ (USVs) safe and efficient navigation. In this paper, the USV collision avoidance problem under the constraint of the international regulations for preventing collisions at sea (COLREGs) was studied. Here, a reinforcement learning collision avoidance (RLCA) algorithm is proposed that complies with USV maneuverability. Notably, the reinforcement learning agent does not require any prior knowledge about USV collision avoidance from humans to learn collision avoidance motions well. The double-DQN method was used to reduce the overestimation of the action-value function. A dueling network architecture was adopted to clearly distinguish the difference between a great state and an excellent action. Aiming at the problem of agent exploration, a method based on the characteristics of USV collision avoidance, the category-based exploration method, can improve the exploration ability of the USV. Because a large number of turning behaviors in the early steps may affect the training, a method to discard some of the transitions was designed, which can improve the effectiveness of the algorithm. A finite Markov decision process (MDP) that conforms to the USVs’ maneuverability and COLREGs was used for the agent training. The RLCA algorithm was tested in a marine simulation environment in many different USV encounters, which showed a higher average reward. The RLCA algorithm bridged the divide between USV navigation status information and collision avoidance behavior, resulting in successfully planning a safe and economical path to the terminal. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/s22072654,Sensors,"On-road behavior analysis is a crucial and challenging problem in the autonomous driving vision-based area. Several endeavors have been proposed to deal with different related tasks and it has gained wide attention recently. Much of the excitement about on-road behavior understanding has been the labor of advancement witnessed in the fields of computer vision, machine, and deep learning. Remarkable achievements have been made in the Road Behavior Understanding area over the last years. This paper reviews 100+ papers of on-road behavior analysis related work in the light of the milestones achieved, spanning over the last 2 decades. This review paper provides the first attempt to draw smart mobility researchers’ attention to the road behavior understanding field and its potential impact on road safety to the whole road agents such as: drivers, pedestrians, stuffs, etc. To push for an holistic understanding, we investigate the complementary relationships between different elementary tasks that we define as the main components of road behavior understanding to achieve a comprehensive understanding of approaches and techniques. For this, five related topics have been covered in this review, including situational awareness, driver-road interaction, road scene understanding, trajectories forecast, driving activities, and status analysis. This paper also reviews the contribution of deep learning approaches and makes an in-depth analysis of recent benchmarks as well, with a specific taxonomy that can help stakeholders in selecting their best-fit architecture. We also finally provide a comprehensive discussion leading us to identify novel research directions some of which have been implemented and validated in our current smart mobility research work. This paper presents the first survey of road behavior understanding-related work without overlap with existing reviews. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/s22134944,Sensors,"In this paper, we present a methodology based on generative adversarial network architecture to generate synthetic data sets with the intention of augmenting continuous glucose monitor data from individual patients. We use these synthetic data with the aim of improving the overall performance of prediction models based on machine learning techniques. Experiments were per-formed on two cohorts of patients suffering from type 1 diabetes mellitus with significant differences in their clinical outcomes. In the first contribution, we have demonstrated that the chosen methodology is able to replicate the intrinsic characteristics of individual patients following the statistical distributions of the original data. Next, a second contribution demonstrates the potential of synthetic data to improve the performance of machine learning approaches by testing and comparing different prediction models for the problem of predicting nocturnal hypoglycemic events in type 1 diabetic patients. The results obtained for both generative and predictive models are quite encouraging and set a precedent in the use of generative techniques to train new machine learning models. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/s22197243,Sensors,"Recent developments in unmanned aerial vehicles (UAVs) have led to the introduction of a wide variety of innovative applications, especially in the Mobile Edge Computing (MEC) field. UAV swarms are suggested as a promising solution to cope with the issues that may arise when connecting Internet of Things (IoT) applications to a fog platform. We are interested in a crucial aspect of designing a swarm of UAVs in this work, which is the coordination of swarm agents in complicated and unknown environments. Centralized leader–follower formations are one of the most prevalent architectural designs in the literature. In the event of a failed leader, however, the entire mission is canceled. This paper proposes a framework to enable the use of UAVs under different MEC architectures, overcomes the drawbacks of centralized architectures, and improves their overall performance. The most significant contribution of this research is the combination of distributed formation control, online leader election, and collaborative obstacle avoidance. For the initial phase, the optimal path between departure and arrival points is generated, avoiding obstacles and agent collisions. Next, a quaternion-based sliding mode controller is designed for formation control and trajectory tracking. Moreover, in the event of a failed leader, the leader election phase allows agents to select the most qualified leader for the formation. Multiple possible scenarios simulating real-time applications are used to evaluate the framework. The obtained results demonstrate the capability of UAVs to adapt to different MEC architectures under different constraints. Lastly, a comparison is made with existing structures to demonstrate the effectiveness, safety, and durability of the designed framework. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/s22218452,Sensors,"We propose a framework for optimizing personalized treatment outcomes for patients with neurological diseases. A typical consequence of such diseases is gait disorders, partially explained by command and muscle tone problems associated with spasticity. Intramuscular injection of botulinum toxin type A is a common treatment for spasticity. According to the patient’s profile, offering the optimal treatment combined with the highest possible benefit-risk ratio is important. For the prediction of knee and ankle kinematics after botulinum toxin type A (BTX-A) treatment, we propose: (1) a regression strategy based on a multi-task architecture composed of LSTM models; (2) to introduce medical treatment data (MTD) for context modeling; and (3) a gating mechanism to model treatment interaction more efficiently. The proposed models were compared with and without metadata describing treatments and with serial models. Multi-task learning (MTL) achieved the lowest root-mean-squared error (RMSE) (5.60°) for traumatic brain injury (TBI) patients on knee trajectories and the lowest RMSE (3.77°) for cerebral palsy (CP) patients on ankle trajectories, with only a difference of 5.60° between actual and predicted. Overall, the best RMSE ranged from 5.24° to 6.24° for the MTL models. To the best of our knowledge, this is the first time that MTL has been used for post-treatment gait trajectory prediction. The MTL models outperformed the serial models, particularly when introducing treatment metadata. The gating mechanism is efficient in modeling treatment interaction and improving trajectory prediction. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/s22228863,Sensors,"Unmanned aerial vehicles (UAV), also known as drones have been used for a variety of reasons and the commercial drone market growth is expected to reach remarkable levels in the near future. However, some drone users can mistakenly or intentionally fly into flight paths at major airports, flying too close to commercial aircraft or invading people’s privacy. In order to prevent these unwanted events, counter-drone technology is needed to eliminate threats from drones and hopefully they can be integrated into the skies safely. There are various counter-drone methods available in the industry. However, a counter-drone system supported by an artificial intelligence (AI) method can be an efficient way to fight against drones instead of human intervention. In this paper, a deep reinforcement learning (DRL) method has been proposed to counter a drone in a 3D space by using another drone. In a 2D space it is already shown that the deep reinforcement learning method is an effective way to counter a drone. However, countering a drone in a 3D space with another drone is a very challenging task considering the time required to train and avoid obstacles at the same time. A Deep Q-Network (DQN) algorithm with dueling network architecture and prioritized experience replay is presented to catch another drone in the environment provided by an Airsim simulator. The models have been trained and tested with different scenarios to analyze the learning progress of the drone. Experiences from previous training are also transferred before starting a new training by pre-processing the previous experiences and eliminating those considered as bad experiences. The results show that the best models are obtained with transfer learning and the drone learning progress has been increased dramatically. Additionally, an algorithm which combines imitation learning and reinforcement learning is implemented to catch the target drone. In this algorithm, called deep q-learning from demonstrations (DQfD), expert demonstrations data and self-generated data by the agent are sampled and the agent continues learning without overwriting the demonstration data. The main advantage of this algorithm is to accelerate the learning process even if there is a small amount of demonstration data. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/s22249753,Sensors,"Levodopa administration is currently the most common treatment to alleviate Parkinson’s Disease (PD) symptoms. Nevertheless, prolonged use of Levodopa leads to a wearing-off (WO) phenomenon, causing symptoms to reappear. To build a personalized treatment plan aiming to manage PD and its symptoms effectively, there is a need for a technological system able to continuously and objectively assess the WO phenomenon during daily life. In this context, this paper proposes a WO tracker able to exploit neuromuscular data acquired by a dedicated wireless sensor network to discriminate between a Levodopa benefit phase and the reappearance of symptoms. The proposed architecture has been implemented on a heterogeneous computing platform, that statistically analyzes neural and muscular features to identify the best set of features to train the classifier model. Eight models among shallow and deep learning approaches are analyzed in terms of performance, timing and complexity metrics to identify the best inference engine. Experimental results on five subjects experiencing WO, showed that, in the best case, the proposed WO tracker can achieve an accuracy of ~84%, providing the inference in less than 41 ms. It is possible by employing a simple fully-connected neural network with 1 hidden layer and 32 units. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3390/s23010255,Sensors,"This article is a graphical, analytical survey of the literature, over the period 2010–2020, on the measurement of power consumption and relevant power models of virtual entities as they apply to the telco cloud. We present a novel review method, that summarizes the dynamics as well as the results of the research. Our method lends insight into trends, research gaps, fallacies and pitfalls. Notably, we identify limitations of the widely used linear models and the progression towards Artificial Intelligence/Machine Learning techniques as a means of dealing with the seven major dimensions of variability: workload type; computer virtualization agents; system architecture and resources; concurrent, co-hosted virtualized entities; approaches towards the attribution of power consumption to virtual entities; frequency; and temperature. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/s23031600,Sensors,"A Software Defined Vehicular Network (SDVN) is a new paradigm that enhances programmability and flexibility in Vehicular Adhoc Networks (VANETs). There exist different architectures for SDVNs based on the degree of control of the control plane. However, in vehicular communication literature, we find that there is no proper mechanism to collect data. Therefore, we propose a novel data collection methodology for the hybrid SDVN architecture by modeling it as an Integer Quadratic Programming (IQP) problem. The IQP model optimally selects broadcasting nodes and agent (unicasting) nodes from a given vehicular network instance with the objective of minimizing the number of agents, communication delay, communication cost, total payload, and total overhead. Due to the dynamic network topology, finding a new solution to the optimization is frequently required in order to avoid node isolation and redundant data transmission. Therefore, we propose a systematic way to collect data and make optimization decisions by inspecting the heterogeneous normalized network link entropy. The proposed optimization model for data collection for the hybrid SDVN architecture yields a 75.5% lower communication cost and 32.7% lower end-to-end latency in large vehicular networks compared to the data collection in the centralized SDVN architecture while collecting 99.9% of the data available in the vehicular network under optimized settings. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/s23094381,Sensors,"Blind people often encounter challenges in managing their clothing, specifically in identifying defects such as stains or holes. With the progress of the computer vision field, it is crucial to minimize these limitations as much as possible to assist blind people with selecting appropriate clothing. Therefore, the objective of this paper is to use object detection technology to categorize and detect stains on garments. The defect detection system proposed in this study relies on the You Only Look Once (YOLO) architecture, which is a single-stage object detector that is well-suited for automated inspection tasks. The authors collected a dataset of clothing with defects and used it to train and evaluate the proposed system. The methodology used for the optimization of the defect detection system was based on three main components: (i) increasing the dataset with new defects, illumination conditions, and backgrounds, (ii) introducing data augmentation, and (iii) introducing defect classification. The authors compared and evaluated three different YOLOv5 models. The results of this study demonstrate that the proposed approach is effective and suitable for different challenging defect detection conditions, showing high average precision (AP) values, and paving the way for a mobile application to be accessible for the blind community. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/s24041216,Sensors,"With the rapid advancement of the Internet of Things (IoT), there is a global surge in network traffic. Software-Defined Networks (SDNs) provide a holistic network perspective, facilitating software-based traffic analysis, and are more suitable to handle dynamic loads than a traditional network. The standard SDN architecture control plane has been designed for a single controller or multiple distributed controllers; however, a logically centralized single controller faces severe bottleneck issues. Most proposed solutions in the literature are based on the static deployment of multiple controllers without the consideration of flow fluctuations and traffic bursts, which ultimately leads to a lack of load balancing among controllers in real time, resulting in increased network latency. Moreover, some methods addressing dynamic controller mapping in multi-controller SDNs consider load fluctuation and latency but face controller placement problems. Earlier, we proposed priority scheduling and congestion control algorithm (eSDN) and dynamic mapping of controllers for dynamic SDN (dSDN) to address this issue. However, the future growth of IoT is unpredictable and potentially exponential; to accommodate this futuristic trend, we need an intelligent solution to handle the complexity of growing heterogeneous devices and minimize network latency. Therefore, this paper continues our previous research and proposes temporal deep Q learning in the dSDN controller. A Temporal Deep Q learning Network (tDQN) serves as a self-learning reinforcement-based model. The agent in the tDQN learns to improve decision-making for switch-controller mapping through a reward–punish scheme, maximizing the goal of reducing network latency during the iterative learning process. Our approach—tDQN—effectively addresses dynamic flow mapping and latency optimization without increasing the number of optimally placed controllers. A multi-objective optimization problem for flow fluctuation is formulated to divert the traffic to the best-suited controller dynamically. Extensive simulation results with varied network scenarios and traffic show that the tDQN outperforms traditional networks, eSDNs, and dSDNs in terms of throughput, delay, jitter, packet delivery ratio, and packet loss. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/s24082481,Sensors,"This paper designed and developed an online digital imaging excitation sensor for wind power gearbox wear condition monitoring based on an adaptive deep learning method. A digital imaging excitation sensing image information collection architecture for magnetic particles in lubricating oil was established to characterize the wear condition of mechanical equipment, achieving the real-time online collection of wear particles in lubricating oil. On this basis, a mechanical equipment wear condition diagnosis method based on online wear particle images is proposed, obtaining data from an engineering test platform based on a wind power gearbox. Firstly, a foreground segmentation preprocessing method based on the U-Net network can effectively eliminate the interference of bubbles and dark fields in online wear particle images, providing high-quality segmentation results for subsequent image processing, A total of 1960 wear particle images were collected in the experiment, the average intersection union ratio of the validation set is 0.9299, and the accuracy of the validation set is 0.9799. Secondly, based on the foreground segmentation preprocessing of wear particle images, by using the watered algorithm to obtain the number of particles in each size segment, we obtained the number of magnetic particle grades in three different ranges: 4–38 µm, 39–70 µm, and >70 µm. Thirdly, we proposed a method named multidimensional transformer (MTF) network. Mean Square Error (MSE), Root Mean Square Error (RMSE), and Mean Absolute Error (MAE) are used to obtain the error, and the maintenance strategy is formulated according to the predicted trend. The experimental results show that the predictive performance of our proposed model is better than that of LSTM and TCN. Finally, the online real-time monitoring system triggered three alarms, and at the same time, our offline sampling data analysis was conducted, the accuracy of online real-time monitoring alarms was verified, and the gearbox of the wind turbine was shut down for maintenance and repair. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/s24123987,Sensors,"This paper proposes a convolutional neural network (CNN) model of the signal distribution control algorithm (SDCA) to maximize the dynamic vehicular traffic signal flow for each junction phase. The aim of the proposed algorithm is to determine the reward value and new state. It deconstructs the routing components of the current multi-directional queuing system (MDQS) architecture to identify optimal policies for every traffic scenario. Initially, the state value is divided into a function value and a parameter value. Combining these two scenarios updates the resulting optimized state value. Ultimately, an analogous criterion is developed for the current dataset. Next, the error or loss value for the present scenario is computed. Furthermore, utilizing the Deep Q-learning methodology with a quad agent enhances previous study discoveries. The recommended method outperforms all other traditional approaches in effectively optimizing traffic signal timing. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/s25082590,Sensors,"The carbon footprint associated with human activity, particularly from energy-intensive industries such as iron and steel, aluminium, cement, oil and gas, and petrochemicals, contributes significantly to global warming. These industries face unique challenges in achieving Industry 4.0 goals due to the widespread adoption of industrial Internet of Things (IIoT) technologies, which require reliable and efficient power solutions. Conventional wireless devices powered by lithium batteries have limitations, including a reduced lifespan in high-temperature environments, incompatibility with explosive atmospheres, and high maintenance costs. This paper proposes a novel approach to address these challenges by leveraging residual heat to power IIoT devices, eliminating the need for batteries and enabling autonomous operation. Based on the Seebeck effect, thermoelectric energy harvesters transduce waste heat from industrial surfaces, such as pipes or chimneys, into sufficient electrical energy to power IoT nodes for applications like the condition monitoring and predictive maintenance of rotating machinery. The methodology presented standardises the modelling and simulation of Waste Heat Recovery Systems (IoT-WHRSs), demonstrating their feasibility through statistical analysis of IoT-WHRS architectures. Furthermore, this technology has been successfully implemented in a petroleum refinery, where it benefits from the NB-IoT standard for long-range, robust, and secure communications, ensuring reliable data transmission in harsh industrial environments. The results highlight the potential of this solution to reduce costs, improve safety, and enhance efficiency in demanding industrial applications, making it a valuable tool for the energy transition. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/s25103241,Sensors,"Highlights: What are the main findings? A novel multi-modal fusion model HFWC-Net (Hybrid–Modal Fusion Waste Classification Network) for efficient waste classification is proposed. What is the implication of the main finding? HFWC-Net effectively reduces the amount of calculation and training time while maintaining high performance. HFWC-Net can improve the accuracy of automatic garbage sorting and protect the natural environment. With rapid urbanization, effective waste classification is a critical challenge. Traditional manual methods are time-consuming, labor-intensive, costly, and error-prone, resulting in reduced accuracy. Deep learning has revolutionized this field. Convolutional neural networks such as VGG and ResNet have dramatically improved automated sorting efficiency, and Transformer architectures like the Swin Transformer have further enhanced performance and adaptability in complex sorting scenarios. However, these approaches still struggle in complex environments and with diverse waste types, often suffering from limited recognition accuracy, poor generalization, or prohibitive computational demands. To overcome these challenges, we propose an efficient hybrid-modal fusion method, the Hybrid-modal Fusion Waste Classification Network (HFWC-Net), for precise waste image classification. HFWC-Net leverages a Transformer-based hierarchical architecture that integrates CNNs and Transformers, enhancing feature capture and fusion across varied image types for superior scalability and flexibility. By incorporating advanced techniques such as the Agent Attention mechanism and the LionBatch optimization strategy, HFWC-Net not only improves classification accuracy but also significantly reduces classification time. Comparative experimental results on the public datasets Garbage Classification, TrashNet, and our self-built MixTrash dataset demonstrate that HFWC-Net achieves Top-1 accuracy rates of 98.89%, 96.88%, and 94.35%, respectively. These findings indicate that HFWC-Net attains the highest accuracy among current methods, offering significant advantages in accelerating classification efficiency and supporting automated waste management applications. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/s25133864,Sensors,"IoT devices are typically resource-constrained, with limited computational power, storage, and energy. Holochain, an emerging distributed ledger technology (DLT), offers the benefits of blockchain while overcoming its limitations, such as the reliance on consensus algorithms and a globally synchronized ledger. As a result, Holochain has garnered attention in the research community as a promising solution for distributed IoT applications. This paper reviews various DLTs in IoT distributed networks, focusing on the motivation for utilizing Holochain in these environments. We explore its key applications, challenges, and research insights. We propose the HoloSec framework, a conceptual security framework for IoT distributed networks that leverages Holochain’s agent-centric architecture, advanced cryptography, and machine learning (ML). The paper also illustrates the setup and implementation of a Holochain-based IoT network for a healthcare scenario and compares the performance of Holochain with traditional blockchain solutions. Initial experimental results show that Holochain achieves a latency of around 50 ms for data publishing and 30 ms for retrieval, with a throughput of approximately 20 transactions per second (TPS) on a single node, significantly outperforming blockchain, which shows higher latency (200 ms publish, 100 ms retrieve) and lower throughput (10 TPS). Finally, we examine key challenges associated with Holochain and outline future research directions aimed at enhancing its interoperability, scalability, security, and regulatory compliance in IoT environments. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/s25134017,Sensors,"In a multi-cell network, interference management between adjacent cells is a key factor that determines the performance of the entire cellular network. In particular, in order to control inter-cell interference while providing a high data rate to users, it is very important for the base station (BS) of each cell to appropriately control the transmit power in the downlink. However, as the number of cells increases, controlling the downlink transmit power at the BS becomes increasingly difficult. In this paper, we propose a multi-agent deep reinforcement learning (MADRL)-based transmit power control scheme to maximize the sum rate in multi-cell networks. In particular, the proposed scheme incorporates a long short-term memory (LSTM) architecture into the MADRL scheme to retain state information across time slots and to use that information for subsequent action decisions, thereby improving the sum rate performance. In the proposed scheme, the agent of each BS uses only its local channel state information; consequently, it does not need to receive signal messages from adjacent agents. The simulation results show that the proposed scheme outperforms the existing MADRL scheme by reducing the amount of signal messages exchanged between links and improving the sum rate. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/su12072698,Sustainability (Switzerland),"Virtual solutions for exhibiting museum collections are no longer a novelty, as such experiences already exist in the world, but the remote use ofmuseum collections for learning purposes has so far not been widely used in the educational environment. This article analyzes virtual museum applications by evaluating them from a learning perspective, including 25 criteria in the evaluation rubric divided into three groups: (i) Technical performance; (ii) information architecture; and (iii) educational value. This will enable educators to select the most appropriate material for their specific learning purpose and to plan the most appropriate learning strategies by organizing training sessions to acquire knowledge that can be enhanced by museum information and teaching students digital skills in evaluating information available in the digital environment, analyzing its pros and cons to teach them how to develop new innovative solutions. The research is carried out from a phenomenological perspective; to be more precise, virtual museums are analyzed using the principles of transcendental design and a hermeneutic design is used to interpret the resulting data. A total of 36 applications of virtual museums were analyzed, whereupon the results were compiled using static data analysis software, while 13 applications were used for the hermeneutic data analysis. The results suggest that the strength of virtual museums is in information architecture, but less attention is paid to the educational value of the material, which points to the need to change the principles of virtual museum design and emphasizes the role of teachers in using virtual museums as learning agents. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/su12072831,Sustainability (Switzerland),"It has been found that a cloud building energy management system (BEMS) alone cannot support increasing numbers of end devices (e.g., energy equipment and IoT devices) and emerging energy services efficiently. To resolve these limitations, this paper proposes Fog BEMS, which applies an emerging fog computing concept to a BEMS. Fog computing places small computing resources (fog nodes) just next to end devices, and these nodes process data in real time and manage local contexts. In this way, the BEMS becomes distributed and scalable. However, existing fog computing models have barely considered scenarios where many end devices and fog nodes are deployed and interconnected. That is, they do not scale up and cannot be applied to scalable applications like BEMS. To solve the problem, this paper (i) designs a fog network where a list of functionally heterogeneous nodes is deployed in a hierarchy for collaboration and (ii) designs an agent-based, modular programming model that eases the development and management of computing services at a fog node. We develop a prototype of a fog node and build a real-world testbed on a campus to demonstrate the feasibility of the proposed system. We also conduct experiments, and results show that Fog BEMS is scalable enough for a node to connect up to 900 devices and that network traffic is reduced by 27.22-97.63%, with varying numbers of end devices. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/su13020757,Sustainability (Switzerland),"Learning from the sustainability of traditional architecture, as a solution to the current ecological crisis, seems more challenging in societies where a cultural imposition has occurred. In Burkina Faso, vernacular architecture has experienced a process of transformation, still in course, relying heavily on foreign resources and losing its adaptation to environmental conditions. As in other contexts, the dynamics of transformation are being examined. Joining this line of work, this research aims to explain the causes of the current local perception of traditional building techniques in Burkina Faso in order to consider how a sustainable development of its architecture would be possible. To this end, a historical analysis is conducted by reviewing the literature, consulting historical documents and collecting data during two stays in 2018. The study shows how earth has ceased to be appreciated by progressively becoming associated with “non-definitive constructions”; this perception is due to the narratives put forward by foreign agents since the end of the 19th century. The sustainable development of architecture in Burkina Faso seems to demand a return to the use of earth, local resource par excellence, but this will only be possible if the devaluation of this building material is reversed. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/su13073945,Sustainability (Switzerland),"As a consequence of the Sars-CoV-2 pandemic, the causative agent of the COVID-19 coronavirus, the world is currently witnessing profound changes in everyday life. The infection and the resulting death number forecasts generate an increasing threat to the lives of people and the economics of countries. As the acute phase of the pandemic ends, the greatest challenge that most governments are currently undergoing is the lack of tools to certify the immunity status of citizens and the related infection risk of the spread of the COVID-19 virus. To mitigate this challenge, this study proposes an innovative approach to implement a set of IT tools, here named VPassport, that assist large-scale test execution/result management in a distributed way and store the results of all tests made through all channels in a blockchain under country authority control. The proposed approach aims to produce an effective system able to support governments, health authorities, and citizens to take informed decisions on which services and social activities can be accessed respecting policies and rules set by the authorities. This aims to allow a controlled restart of the activities of the country, giving to all citizens the possibility to manage their immunity tests while allowing the authorities to manage the reopening of services and social activities. The proposed model helps in managing this phase and, therefore, the resulting outcome can be used to authorize possible behaviors (e.g., going to the office, production plants, public transportation, theaters, cinemas, etc.). The knowledge of being infected or not in a secure and not modifiable way that can be shown in a simple way, accessible to all, will be the real change in managing the coexistence with the virus until a vaccine will be available for all people. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/su14010124,Sustainability (Switzerland),"This paper presents the results of the second phase of the international project “Improving Educational Innovation, Competitiveness, and Quality of Higher Education through Collaboration between University and Companies (EKT)”. The use of adaptive learning supported by learning analytics is proposed as a pedagogical strategy to work on the collaborative and personalized learning process that takes place during the school placement period of initial teacher education. Learning analytics is expected to facilitate the analysis of the different sources of information and data generated in the learning process. The collected data will be centralized in a learning record store (LRS), which will serve as a repository for xAPI compatible traces from the tools that make up EKT intelligent system. The system is expected to provide a strong support to decision-making so that participant agents can collaborate, advise, and contribute to the future teacher’s personalized training according to his or her progress and the context in which the practice takes place. The need analysis of tutors in the five pilot countries is presented, which has made it possible to define the process variables that make up the learning analysis architecture of the EKT system. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/su15043204,Sustainability (Switzerland),"The construction of an automatic voice pathology detection system employing machine learning algorithms to study voice abnormalities is crucial for the early detection of voice pathologies and identifying the specific type of pathology from which patients suffer. This paper’s primary objective is to construct a deep learning model for accurate speech pathology identification. Manual audio feature extraction was employed as a foundation for the categorization process. Incorporating an additional piece of information, i.e., voice gender, via a two-level classifier model was the most critical aspect of this work. The first level determines whether the audio input is a male or female voice, and the second level determines whether the agent is pathological or healthy. Similar to the bulk of earlier efforts, the current study analyzed the audio signal by focusing solely on a single vowel, such as /a/, and ignoring phrases and other vowels. The analysis was performed on the Saarbruecken Voice Database,. The two-level cascaded model attained an accuracy and F1 score of 88.84% and 87.39%, respectively, which was superior to earlier attempts on the same dataset and provides a steppingstone towards a more precise early diagnosis of voice complications. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/su15075959,Sustainability (Switzerland),"Soilless systems, such as hydroponics and aquaponics, are gaining popularity as a sustainable alternative to traditional soil-based agriculture, aiming at maximizing plant productivity while minimizing resource use. Nonetheless, the absence of a soil matrix poses challenges that require precise management of nutrients, effective control of salinity stress, and proactive strategies to master disease management. Plant growth-promoting microorganisms (PGPM) have emerged as a promising solution to overcome these issues. Research demonstrated that Bacillus, Pseudomonas, and Azospirillum are the most extensively studied genera for their effectiveness as growth promoters, inducing changes in root architecture morphology. Furthermore, PGPM inoculation, either alone or in synergy, can reverse the effects of nutrient deficiency and salt stress. The genera Pseudomonas and Trichoderma were recognized for their solid antagonistic traits, which make them highly effective biocontrol agents in hydroponic systems. The latest findings indicate their ability to significantly reduce disease severity index (DSI) through mycoparasitism, antibiosis, and induced systemic resistance. In aquaponic systems, the inoculation with Bacillus subtilis and Azospirillum brasilense demonstrated increased dissolved oxygen, improving water quality parameters and benefiting plant and fish growth and metabolism. This review also establishes the interaction variability between PGPM and growing media, implying the specificity for determining inoculation strategies to maximize the productivity of soilless cultivation systems. These findings suggest that using PGPM in soil-free settings could significantly contribute to sustainable crop production, addressing the challenges of nutrient management, disease control, and salinity issues. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/su151511774,Sustainability (Switzerland),"The concepts of green infrastructures, nature-based solutions and ecosystem services are today considered an integral part of the broader theme of the urban bioregion, with an intrinsic character of complexity. It is certainly difficult to structure bioregional processes in a balanced and sustainable way, able to keep local energy production and consumption cycles closed. It is a complex issue of knowledge bases, and problems are increased by the participatory dimension of environmental planning. In fact, when rational planning models have failed in the face of prominent individual needs and environmental complexity, a path has emerged towards the inclusion of multiple citizens’ and stakeholders’ knowledge. The cognitive structure of the plans has thus changed from systems of exclusively expert, formal knowledge to systems of diffused, multi-agent knowledge. This has involved richness but also significant problems in understanding and managing knowledge bases. In this complexity, there are some common peculiarities when it comes to socio-environmental systems. A common feature of the reference domains of ecosystem services, nature-based solutions and green infrastructures is the water resource. A management model of hydrological data, which are structurally relevant and cross-sectoral in environmental planning actions, could represent a flagship initiative. The used approach could be conveyed to more complex and extensive areas of the environmental domain in a perspective of sustainable planning. The present paper is part of a research work oriented toward handling complex environmental subjects, such as green infrastructures, nature-based solutions or ecosystem services, with a knowledge modelling approach. This approach is based on semantic extensions, elaborated form the concept of semantic web, to allow shared interpretations of knowledge coming from different languages and scientific domains. It is also based on using applied ontologies, elaborated from the concept of ontology-based classification, to support a structured organization of knowledge contents. The main research objective is therefore to investigate about a knowledge management system with semantic extensions, populated with hydrological knowledge contents, as well as to propose a preliminary functional architecture. A simple ontology of data is extracted, aiming at clarifying and improving inter-domain communication, so as to enhance a common semantic understanding in a complex environmental system. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/su151813931,Sustainability (Switzerland),"The continuous increase in cultural tourism, together with the deficient planning of public use, increases the risk of heritage resource degradation. Currently, there are collaborative methodologies enabling all the agents involved in the conservation of a heritage site to work in a coordinated way (HBIM), such as in the management of public use. However, in this study, through a review of the scientific literature, the lack of a method and tool that allows sustainable conservation management and the planning of cultural tourism of heritage assets in a specific geographical environment is demonstrated. The objective of this research is thus to explore and identify the possibilities of interoperability between HBIM and GIS for the development of a protocol aimed at synchronizing the information concerning heritage architecture across the management and cultural tourism planning and preventive conservation. This protocol was implemented for three monumental buildings in the historic centre of the city of Valencia (Spain). This novel protocol provides a new technological system that fosters the cultural development and preservation and conservation of heritage assets through a single tool integrating HBIM and GIS. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/su17167284,Sustainability (Switzerland),"With the accelerated commercialization of autonomous vehicles, new accident types and complex risk factors have emerged beyond the scope of existing traffic safety management systems. This study aims to contribute to sustainable safety by establishing a quantitative basis for early recognition and response to high-risk situations in urban traffic environments where autonomous and conventional vehicles coexist. To this end, high-risk factors were identified through a combination of literature meta-analysis, accident history and image analysis, autonomous driving video review, and expert seminars. For analytical structuring, the six-layer scenario framework from the PEGASUS project was redefined. Using the analytic hierarchy process (AHP), 28 high-risk factors were identified. A risk prediction model framework was then developed, incorporating observational indicators derived from expert rankings. These indicators were structured as input variables for both road segments and autonomous vehicles, enabling spatial risk assessment through agent-based strategies. This space–object integration-based prediction model supports the early detection of high-risk situations, the designation of high-enforcement zones, and the development of preventive safety systems, infrastructure improvements, and policy measures. Ultimately, the findings offer a pathway toward achieving sustainable safety in mixed traffic environments during the initial deployment phase of autonomous vehicles. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/su5031095,Sustainability (Switzerland),"As it touches all aspects of human activity and society in general, energy has become an object of discourse. Two main discourses have formed on the use of energy: risk discourse and security discourse. While environmental changes and oil depletion continue, a new application for the term security has appeared: energy security. This concept can be interpreted within the terms of risk discourse, which is oriented towards rational consensus and decision making, or as an exercise of power, sovereignty and hegemony. The boundaries between interpretations are often unclear. Thus, in an institutional framework that has fragmented principles, norms and rules, opposing discourses will overlap. Political agents and institutions deploy strategies based on these discourses. With this overlapping of discourses, the performative powers of different institutions clash, thus creating conflictive fragmentation in a governance architecture. The purpose of this investigation is to analyze the use of, replication of, and ambiguities surrounding the concept of energy security, so as to understand how and why these discourses overlap and the profound consequences that this overlap may have for present and future energy use, environmental negotiations, and political climate. © 2013 by the authors. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/SYM13101914,Symmetry,"Background and objective: Arrhythmia is a widely seen cardiologic ailment worldwide, and is diagnosed using electrocardiogram (ECG) signals. The ECG signals can be translated manually by human experts, but can also be scheduled to be carried out automatically by some agents. To easily diagnose arrhythmia, an intelligent assistant can be used. Machine learning-based automatic arrhythmia detection models have been proposed to create an intelligent assistant. Materials and Methods: In this work, we have used an ECG dataset. This dataset contains 1000 ECG signals with 17 categories. A new hand-modeled learning network is developed on this dataset, and this model uses a 3D shape (prismatoid) to create textural features. Moreover, a tunable Q wavelet transform with low oscillatory parameters and a statistical feature extractor has been applied to extract features at both low and high levels. The suggested prismatoid pattern and statistical feature extractor create features from 53 sub-bands. A neighborhood component analysis has been used to choose the most discriminative features. Two classifiers, k nearest neighbor (kNN) and support vector machine (SVM), were used to classify the selected top features with 10-fold cross-validation. Results: The calculated best accuracy rate of the proposed model is equal to 97.30% using the SVM classifier. Conclusion: The computed results clearly indicate the success of the proposed prismatoid pattern-based model. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3390/systems11020075,Systems,"The Edu-Metaverse, a vast ensemble of different technologies, has initiated a great and unprecedented change in the field of education. This change has been effected through the following Edu-Metaverse characteristics: embodied and multimodal interaction; immersive teaching scenarios, which can accelerate learning and skill acquisition; and the emergence of AI-enabled agents. In comparison to traditional classroom teaching models, smart education is a collaborative and visual model that adopts the latest AI technologies to reach a learning outcome. However, a problem that should be considered is how a smart education model, enabled by the Edu-Metaverse, can be developed to enhance better learning outcomes for students. Such a model should highlight smart pedagogy in the context of the Edu-Metaverse, together with a smart teaching environment, multimodal teaching resources, and AI-enabled assessment. In this study, we focused on the teaching of college English to 60 students from Zhejiang Open University. We investigated the effectiveness of a smart education model, which was empowered by the Edu-Metaverse, in enhancing better learning outcomes for the students, using a combination of qualitative and quantitative research. After the one-semester-long experiment, questionnaires were sent out to complement the interview findings. It was found that the students who engaged in the smart education model in the Edu-Metaverse yielded higher scores in oral English, vocabulary and grammar, reading comprehension, English-to-Chinese translation, and writing than those who engaged in traditional instruction. Therefore, this study suggests that a smart education model enabled by the Edu-Metaverse, which is characterized by a highly immersive experience, multimodal interaction, and a high degree of freedom for resource sharing and creation can help learners to realize deep learning, develop their capacity for high-order thinking, and help them to become intelligent individuals in an online learning space. In order to facilitate this smart learning, we make the following suggestions for educational institutions: (1) teachers should improve the design of teaching scenarios, (2) teachers should focus on learning assessment that is based on core literacy, and (3) teachers’ knowledge of the architecture of the Edu-Metaverse should be enhanced. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/systems13050385,Systems,"For mobile agent path planning, traditional path planning algorithms frequently induce abrupt variations in path curvature and steering angles, increasing the risk of lateral tire slippage and undermining operational safety. Concurrently, conventional reinforcement learning methods struggle to converge rapidly, leading to an insufficient efficiency in planning to meet the demand for energy economy. This study proposes LSTM Bézier–Double Deep Q-Network (LB-DDQN), an advanced path-planning framework for mobile agents based on deep reinforcement learning. The architecture first enables mapless navigation through a DDQN foundation, subsequently integrates long short-term memory (LSTM) networks for the fusion of environmental features and preservation of training information, and ultimately enhances the path’s quality through redundant node elimination via an obstacle–path relationship analysis, combined with Bézier curve-based trajectory smoothing. A sensor-driven three-dimensional simulation environment featuring static obstacles was constructed using the ROS and Gazebo platforms, where LiDAR-equipped mobile agent models were trained for real-time environmental perception and strategy optimization prior to deployment on experimental vehicles. The simulation and physical implementation results reveal that LB-DDQN achieves effective collision avoidance, while demonstrating marked enhancements in critical metrics: the path’s smoothness, energy efficiency, and motion stability exhibit average improvements exceeding 50%. The framework further maintains superior safety standards and operational efficiency across diverse scenarios. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/technologies12030034,Technologies,"Artificial Intelligence bots are extensively used in multiplayer First-Person Shooter (FPS) games. By using Machine Learning techniques, we can improve their performance and bring them to human skill levels. In this work, we focused on comparing and combining two Reinforcement Learning training architectures, Curriculum Learning and Behaviour Cloning, applied to an FPS developed in the Unity Engine. We have created four teams of three agents each: one team for Curriculum Learning, one for Behaviour Cloning, and another two for two different methods of combining Curriculum Learning and Behaviour Cloning. After completing the training, each agent was matched to battle against another agent of a different team until each pairing had five wins or ten time-outs. In the end, results showed that the agents trained with Curriculum Learning achieved better performance than the ones trained with Behaviour Cloning by a matter of 23.67% more average victories in one case. In terms of the combination attempts, not only did the agents trained with both devised methods had problems during training, but they also achieved insufficient results in the battle, with an average of 0 wins. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/technologies13100470,Technologies,"The rapid development of the Internet of Things (IoT) poses significant problems in securing heterogeneous, massive, and high-volume network traffic against cyber threats. Traditional intrusion detection systems (IDSs) are often found to be poorly scalable, or are ineffective computationally, because of the presence of redundant or irrelevant features, and they suffer from high false positive rates. Addressing these limitations, this study proposes a hybrid intelligent model that combines quantum computing, chaos theory, and deep learning to achieve efficient feature selection and effective intrusion classification. The proposed system offers four novel modules for feature optimization: chaotic swarm intelligence, quantum diffusion modeling, transformer-guided ranking, and multi-agent reinforcement learning, all of which work with a graph-based classifier enhanced with quantum attention mechanisms. This architecture allows as much as 75% feature reduction, while achieving 4% better classification accuracy and reducing computational overhead by 40% compared to the best-performing models. When evaluated on benchmark datasets (NSL-KDD, CICIDS2017, and UNSW-NB15), it shows superior performance in intrusion detection tasks, thereby marking it as a viable candidate for scalable and real-time IoT security analytics. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/technologies9030044,Technologies,"The fast emergence of IoT devices and its accompanying big and complex data has necessitated a shift from the traditional networking architecture to software-defined networks (SDNs) in recent times. Routing optimization and DDoS protection in the network has become a necessity for mobile network operators in maintaining a good QoS and QoE for customers. Inspired by the recent advancement in Machine Learning and Deep Reinforcement Learning (DRL), we propose a novel MADDPG integrated Multiagent framework in SDN for efficient multipath routing optimization and malicious DDoS traffic detection and prevention in the network. The two MARL agents cooperate within the same environment to accomplish network optimization task within a shorter time. The state, action, and reward of the proposed framework were further modelled mathematically using the Markov Decision Process (MDP) and later integrated into the MADDPG algorithm. We compared the proposed MADDPG-based framework to DDPG for network metrics: delay, jitter, packet loss rate, bandwidth usage, and intrusion detection. The results show a significant improvement in network metrics with the two agents. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3390/wevj15060253,World Electric Vehicle Journal,"The proliferation of wireless technologies, particularly the advent of 5G networks, has ushered in transformative possibilities for enhancing vehicular communication systems, particularly in the context of autonomous driving. Leveraging sensory data and mapping information downloaded from base stations using I2V links, autonomous vehicles in these networks present the promise of enabling distant perceptual abilities essential to completing various tasks in a dynamic environment. However, the efficient down-link transmission of vehicular network data via base stations, often relying on spectrum sharing, presents a multifaceted challenge. This paper addresses the intricacies of spectrum allocation in vehicular networks, aiming to resolve the thorny issues of cross-station interference and coupling while adapting to the dynamic and evolving characteristics of the vehicular environment. A novel approach is suggested involving the utilization of a multi-agent option-critic reinforcement learning algorithm. This algorithm serves a dual purpose: firstly, it learns the most efficient way to allocate spectrum resources optimally. Secondly, it adapts to the ever-changing dynamics of the environment by learning various policy options tailored to different situations. Moreover, it identifies the conditions under which a switch between these policy options is warranted as the situation evolves. The proposed algorithm is structured in two layers, with the upper layer consisting of policy options that are shared across all agents, and the lower layer comprising intra-option policies executed in a distributed manner. Through experimentation, we showcase the superior spectrum efficiency and communication quality achieved by our approach. Specifically, our approach outperforms the baseline methods in terms of training average reward convergence stability and the transmission success rate. Control-variable experiments also reflect the better adaptability of the proposed method as the environmental conditions change, underscoring the significant potential of the proposed method in aiding successful down-link transmissions in vehicular networks. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3390/wevj16040225,World Electric Vehicle Journal,"This study presents the first investigation into the problem of autonomous vehicle (AV) merging into existing platoons, proposing a multi-agent deep reinforcement learning (MA-DRL)-based cooperative control framework. The developed MA-DRL architecture enables coordinated learning among multiple autonomous agents to address the multi-objective coordination challenge through synchronized control of platoon longitudinal acceleration, AV steering and acceleration. To enhance training efficiency, we develop a dual-layer multi-agent maximum Q-value proximal policy optimization (MAMQPPO) method, which extends the multi-agent PPO algorithm (a policy gradient method ensuring stable policy updates) by incorporating maximum Q-value action selection for platoon gap control and discrete command generation. This method simplifies the training process by using maximum Q-value action policy optimization to learn platoon gap selection and discrete action commands. Furthermore, a partially decoupled reward function (PD-Reward) is designed to properly guide the behavioral actions of both AVs and platoons while accelerating network convergence. Comprehensive highway simulation experiments show the proposed method reduces merging time by 37.69% (12.4 s vs. 19.9 s) and energy consumption by 58% (3.56 kWh vs. 8.47 kWh) compared to existing methods (the quintic polynomial-based + PID (Proportional–Integral–Differential)). © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/wevj16050284,World Electric Vehicle Journal,"In intelligent cluster systems, the spatio-temporal complexity of agent data collection and resource allocation, as well as the problems in collaborative organizations, present substantial challenges to efficient resource distribution. To address this, a novel self-organizing prediction method for spatio-temporal resource allocation is proposed. In the spatio-temporal modeling part, dilated convolution is applied for time modeling. Its dilation rate grows exponentially with the layer depth, allowing it to effectively capture the time trends of graph nodes and handle long time series data. For spatial modeling, an innovative dual-view dynamic graph convolutional network architecture is utilized to accurately explore the static and dynamic correlation information of the spatial layout of charging piles. Meanwhile, a composite self-organizing mechanism integrating a trust model is put forward. The trust model assists agents in choosing partners, and the Q-learning algorithm of the intelligent cluster realizes the independent evaluation of rewards and the optimization of relationship adaptation. In the experimental scenario of electric vehicle charging, considering charging piles as agents, under the home charging mode, the self-organizing charging scheduling can reduce the total load range by up to 90.37%. It effectively shifts the load demand from peak periods to valley periods, minimizes the total peak–valley load difference, and significantly improves the security and reliability of the microgrid, thus providing a practical solution for resource allocation in intelligent clusters. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/wevj16070343,World Electric Vehicle Journal,"Although cooperative perception enhances situational awareness by enabling vehicles to share intermediate features, real-world deployment faces challenges due to heterogeneity in sensor modalities, architectures, and encoder parameters across agents. These domain gaps often result in semantic inconsistencies among the shared features, thereby degrading the quality of feature fusion. Existing approaches either necessitate the retraining of private models or fail to adapt to newly introduced agents. To address these limitations, we propose PnPDA+, a unified and modular domain adaptation framework designed for heterogeneous multi-vehicle cooperative perception. PnPDA+ consists of two key components: a Meta Feature Extraction Network (MFEN) and a Plug-and-Play Domain Adapter (PnPDA). MFEN extracts domain-aware and frame-aware meta features from received heterogeneous features, encoding domain-specific knowledge and spatial-temporal cues to serve as high-level semantic priors. Guided by these meta features, the PnPDA module performs adaptive semantic conversion to enhance cross-agent feature alignment without modifying existing perception models. This design ensures the scalable integration of emerging vehicles with minimal fine-tuning, significantly improving both semantic consistency and generalization. Experiments on OPV2V show that PnPDA+ outperforms state-of-the-art methods by 4.08% in perception accuracy while preserving model integrity and scalability. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3390/wevj16070347,World Electric Vehicle Journal,"In regions where electric vehicles (EVs) are widely adopted and charging stations (CSs) are being built in large numbers, CSs are becoming a critical load-side resource for low-inertia power systems. In this paper, a physics-data fusion enhanced frequency control strategy for multiple CSs is proposed. Firstly, the power grid frequency control architecture is improved, where CSs as multi-agent (MA) can participate in frequency response (FR). Besides, a physics-driven adaptive inertia for CS virtual synchronous generators (VSGs) is proposed to improve system dynamic FR characteristics. Building upon this, the physics-data fusion concept is introduced, wherein the MA-soft-actor-critic (MA-SAC) algorithm dynamically adjusts coordination coefficients with the consideration of CSs’ FR capabilities. To validate the proposed strategy, comparative case studies are conducted on the IEEE 39-node system. The simulation results demonstrate that compared to a single physics-driven method, the proposed control strategy exhibits enhanced adaptability and improved FR characteristics across various scenarios. Under intact MA communication conditions, the proposed strategy reduces the frequency disturbance index to 49.872% and the CS response power oscillation index to 79.542%; Even with MA communication impairments, the strategy maintains significant improvements, reducing these indexes to 48.897% and 86.733% respectively. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.34028/18/4/14,International Arab Journal of Information Technology,"ASAF is a multiple agent robotic system where Unmanned Aerial Vehicles (UAV) and Ground Vehicles (UGV) agents perform coordinated tasks. Our research group built this system based on Multiple Unmanned Autonomous Vehicle Experimental Testbed (MAUVET), an in-house platform that we have introduced as well. The challenge in the development of a mobile robotic system is that performance in real time deployment differs from the original plan. This case is clearer when planning the traversal path of an agent, where error happens because of mechanical and environmental factors. The aim of this paper is to investigate the agent traversal execution via system experimentation and computer simulation. The outcome of this investigation is understanding this behavior under different sets of circumstances and finding some optimization factors. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.34133/icomputing.0046,Intelligent Computing,"Recently, extensive studies on photonic reinforcement learning to accelerate the process of calculation by exploiting the physical nature of light have been conducted. Previous studies utilized quantum interference of photons to achieve collective decision-making without choice conflicts when solving the competitive multi-armed bandit problem, a fundamental example in reinforcement learning. However, the bandit problem deals with a static environment where the agent’s actions do not influence the reward probabilities. This study aims to extend the conventional approach to a more general type of parallel reinforcement learning targeting the grid world problem. Unlike the conventional approach, the proposed scheme deals with a dynamic environment where the reward changes because of the agent’s actions. A successful photonic reinforcement learning scheme requires both a photonic system that contributes to the quality of learning and a suitable algorithm. This study proposes a novel learning algorithm, a modified bandit Q-learning method, in view of a potential photonic implementation. Here, state–action pairs in the environment are regarded as slot machines in the context of the bandit problem and a change in Q-value is regarded as the reward of the bandit problem. We perform numerical simulations to validate the effectiveness of the bandit algorithm. In addition, we propose a parallel architecture in which multiple agents are indirectly connected through quantum interference of light and quantum principles ensure the conflict-free property of state–action pair selections among agents. We demonstrate that parallel reinforcement learning can be accelerated owing to conflict avoidance among multiple agents. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.35470/2226-4116-2019-8-4-257-261,Cybernetics and Physics,"The paper presents the multi-agent approach for developing cyber-physical system for managing precise farms with digital twins of plants. It discusses complexity of the problem caused by a priori incompleteness of knowledge about factors of plant growth and development, high uncertainty of crops cultivation, variety of weather, business and technical requirements, etc. The approach proposes knowledge bases and multi-agent technology in combination with machine learning methods for designing considered systems. Digital twin of plant is specified as an agent based on ontology model of objects relevant for plant cultivation (specific sort of plant, soil, etc) associated with history of operations and environment conditions. The architecture and functions of system components are designed. The expected results of system implementation and the benefits for farmers are discussed. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.35470/2226-4116-2023-12-4-275-281,Cybernetics and Physics,"Augmented Reality (AR) is one of the modern ways of providing users with different types of information. In applications based on this technology, the main influence on the subjective assessment of product quality is the speed of interaction between the system and the user and between users of the system. The main purpose of the work series are creation and modification for algorithms to assessing and improving the quality of AR-services. This paper describes and justifies an adaptive communication protocol for multi-agent interaction. We consider a general nonlinear dynamic system with introducing feedback control which is based on measurements under almost arbitrary noise. In practice, this control is realized as a superposition of neural networks with the estimation of the result of mutual additional learning based on the system identification method (M.K.Campi and E.Weyer’s LSCR is used). The prototype is built for a system with a distributed server architecture and multi-agent behavior of both clients and servers in the system. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.35833/MPCE.2018.000782,Review of Service Restoration for Distribution Networks,"With the rapid deployment of the advanced metering infrastructure (AMI) and distribution automation (DA), self-healing has become a key factor to enhance the resilience of distribution networks. Following a permanent fault occurrence, the distribution network operator (DNO) implements the self-healing scheme to locate and isolate the fault and to restore power supply to out-of-service portions. As an essential component of self-healing, service restoration has attracted considerable attention. This paper mainly reviews the service restoration approaches of distribution networks, which requires communication systems. The service restoration approaches can be classified as centralized, distributed, and hierarchical approaches according to the communication architecture. In these approaches, different techniques are used to obtain service restoration solutions, including heuristic rules, expert systems, metaheuristic algorithms, graph theory, mathematical programming, and multi-agent systems. Moreover, future research areas of service restoration for distribution networks are discussed.",TOPIC
10.35833/MPCE.2022.000671,Low-Carbon Economic Dispatch of Electricity-Heat-Gas Integrated Energy Systems Based on Deep Reinforcement Learning,"The optimal dispatch methods of integrated energy systems (IESs) currently struggle to address the uncertainties resulting from renewable energy generation and energy demand. Moreover, the increasing intensity of the greenhouse effect renders the reduction of IES carbon emissions a priority. To address these issues, a deep reinforcement learning (DRL)-based method is proposed to optimize the low-carbon economic dispatch model of an electricity-heat-gas IES. In the DRL framework, the optimal dispatch model of the IES is formulated as a Markov decision process (MDP). A reward function based on the reward-penalty ladder-type carbon trading mechanism (RPLT-CTM) is introduced to enable the DRL agents to learn more effective dispatch strategies. Moreover, a distributed proximal policy optimization (DPPO) algorithm, which is a novel policy-based DRL algorithm, is employed to train the DRL agents. The multithreaded architecture enhances the exploration ability of the DRL agents in complex environments. Experimental results illustrate that the proposed DPPO-based IES dispatch method can mitigate carbon emissions and reduce the total economic cost. The RPLT-CTM-based reward function outperforms the CTM-based methods, providing a 4.42% and 6.41% decrease in operating cost and carbon emission, respectively. Furthermore, the superiority and computational efficiency of DPPO compared with other DRL-based methods are demonstrated by a decrease of more than 1.53% and 3.23% in the operating cost and carbon emissions of the IES, respectively.",TOPIC
10.35940/ijrte.B2843.078219,International Journal of Recent Technology and Engineering,"Arya is an autonomous underwater vehicle (AUV) modeled and developed by team DTU-AUV comprising of undergraduate students from multidisciplinary backgrounds of Delhi Technological University (DTU), India, to participate in an IEEE backed Singapore AUV Challenge (SAUVC). This paper entails the rationale and methodology employed to design and integrate various systems onboard. Significant improvisations have been made in the structural design of the vehicle to enhance its hydrodynamic stability and maneuverability to perform discrete tasks in comparison to the previous vehicles developed by the team. The focus is laid on the embedded and power system to enhance reliability, modularity, and power distribution. The software stack is designed to run in decentralized multi-threaded agent architecture, with the threads handling pressure sensor, cameras, control system, IMU, mission planner each performing input and output operations in continuous loops. PID control algorithms achieve the desired dynamic control. The vision system is devised to monitor the marine environment and detect underwater contoured objects. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.35940/ijrte.C4282.098319,International Journal of Recent Technology and Engineering,"In a mobile agent system, if agents’ functionality can be assessed and evaluated between peers of environmental modelling, it can reduce the exploration burden of unvisited states and unseen situations, thus an effectual learning process has to be accelerated. So as to construct an accurate and effectual model in certain time period is a significant problem, specifically in complex environment. To overcome this crisis, the investigation anticipates a model based data mining approach based on tree structure to achieve co-ordination amongst the mobile agent, effectual modelling and less memory utilization. The anticipated model suggests Mobi-X architecture to mobile agent system with a tree structure for effectual modelling. The construction of tree for real time mobile agent system is utilized to generate virtual experiences like elapse time during mining of tree structure. In addition, this model is appropriate for knowledge mining. This work is inspired by knowledge mining concept in mobile agent systems where an agent can built a global model from scattered local model held by individual agents. Subsequently, it increases modelling accuracy to offer valid simulation outcome for indirect learning at initial stage of mining. In order to simplify mining procedure, this anticipated model relies on re-sampling approach with associative rule mining to grafting branches of constructed tree. The tree structure provides the functions of mobile agents with useful experience from peer to peer connectivity, indeed of combining all the available agents. The simulation outcomes shows that proposed re-sampling can attain efficiency and accelerate the functionality of mobile agents based cooperation applications. © 2019 Elsevier B.V., All rights reserved.",TOPIC
10.3745/JIPS.01.0008,Journal of Information Processing Systems,"The localization of multi-agents, such as people, animals, or robots, is a requirement to accomplish several tasks. Especially in the case of multi-robotic applications, localization is the process for determining the positions of robots and targets in an unknown environment. Many sensors like GPS, lasers, and cameras are utilized in the localization process. However, these sensors produce a large amount of computational resources to process complex algorithms, because the process requires environmental mapping. Currently, combination multi-robots or swarm robots and sensor networks, as mobile sensor nodes have been widely available in indoor and outdoor environments. They allow for a type of efficient global localization that demands a relatively low amount of computational resources and for the independence of specific environmental features. However, the inherent instability in the wireless signal does not allow for it to be directly used for very accurate position estimations and making difficulty associated with conducting the localization processes of swarm robotics system. Furthermore, these swarm systems are usually highly decentralized, which makes it hard to synthesize and access global maps, it can be decrease its flexibility. In this paper, a simple pyramid RAM-based Neural Network architecture is proposed to improve the localization process of mobile sensor nodes in indoor environments. Our approach uses the capabilities of learning and generalization to reduce the effect of incorrect information and increases the accuracy of the agent's position. The results show that by using simple pyramid RAM-base Neural Network approach, produces low computational resources, a fast response for processing every changing in environmental situation and mobile sensor nodes have the ability to finish several tasks especially in localization processes in real time. Copyright. © 2016 Elsevier B.V., All rights reserved.",TOPIC
10.3837/tiis.2018.06.025,KSII Transactions on Internet and Information Systems,"Security has become one of the major concerns in mobile adhoc networks (MANETs). Data and voice communication amongst roaming battlefield entities (such as platoon of soldiers, inter-battlefield tanks and military aircrafts) served by MANETs throw several challenges. It requires complex securing strategy to address threats such as unauthorized network access, man in the middle attacks, denial of service etc., to provide highly reliable communication amongst the nodes. Intrusion Detection and Prevention System (IDPS) undoubtedly is a crucial ingredient to address these threats. IDPS in MANET is managed by Command Control Communication and Intelligence (C3I) system. It consists of networked computers in the tactical battle area that facilitates comprehensive situation awareness by the commanders for timely and optimum decision-making. Key issue in such IDPS mechanism is lack of Smart Learning Engine. We propose a novel behavioral based ""Smart Multi-Instance Multi-Label Intrusion Detection and Prevention System (MIML-IDPS)""that follows a distributed and centralized architecture to support a Robust C3I System. This protocol is deployed in a virtually clustered non-uniform network topology with dynamic election of several virtual head nodes acting as a client Intrusion Detection agent connected to a centralized server IDPS located at Command and Control Center. Distributed virtual client nodes serve as the intelligent decision processing unit and centralized IDPS server act as a Smart MIML decision making unit. Simulation and experimental analysis shows the proposed protocol exhibits computational intelligence with counter attacks, efficient memory utilization, classification accuracy and decision convergence in securing C3I System in a Tactical Battlefield environment. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.3837/tiis.2025.09.005,KSII Transactions on Internet and Information Systems,"Power dispatch automation systems face significant challenges in managing containerized applications, particularly during sudden load fluctuations and complex grid events that demand rapid and reliable resource scaling. Traditional orchestration methods often fail to ensure both system stability and efficient resource utilization across highly dynamic grid services. To address these limitations, we present SCOT, a scalable container orchestration system specifically designed for power grid environments. SCOT introduces three core innovations: an end-to-end fusion architecture that integrates a Transformer-based model for precise workload forecasting, a multi-agent reinforcement learning (MARL) framework for coordinated container-level scheduling, and a Lamarckian learning mechanism that enables continuous self-adaptation by retaining effective policies from past scenarios. In addition, SCOT embeds grid-specific constraints and dynamic service priorities into its decision-making process, significantly enhancing its responsiveness and robustness under volatile conditions. Extensive evaluation using real-world grid workload traces demonstrates SCOT’s effectiveness: it achieves a 14% improvement in resource utilization over Dynamic Scalable Task Scheduling (DSTS), reaches 88.7% accuracy in predicting and handling demand spikes, and limits SLA violations to just 1.2%. SCOT also exhibits strong responsiveness, provisioning 128 containers in 4.9 seconds—2.8× faster than DSTS—and successfully orchestrating 2,500 containers across 1,000 VMs within 3.5 seconds, while reducing post-surge stabilization time by a factor of 3. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3844/jcssp.2014.995.1002,Journal of Computer Science,"Student location detection in Learning Management System (LMS) by utilizing Multi-Agent System (MAS) which contains sensor nodes is a new area of research. This study reviews several studies to ascertain the potential of integrating these two technologies to automate students' class attendance in Higher Learning Institutions (HLIs). Currently, the HLIs are using paper-based process to record students' attendance in the class, that is time consuming and is not possible to monitor students all the time, that they suppose to be in learning environment. Introducing the sensor networks and MAS in LMS system is to enable the instructors or lecturers to be aware of the presence of their students once they reach the system's domain. The collaboration using MAS facilitates the retrieval and recording of students' details from the sensors and then sends them to LMS servers through Cluster Head Sensor. The information that is collected and recorded by the agents include the signal strength of the students' device and their profiles which can facilitate to know the exactly locations of the students, by comparing such information with the information already stored in LMS database. Therefore, a system architecture that comprises MAS with sensor networks in LMS is presented in this study for monitoring students' attendance in the classes and labs. This type of system architecture with improved LMS features is more focused and intended for HLIs that follow the blended learning system. This proposed system has potential of boosting learning process in HLIs by providing new feature in LMS that monitor students' activities in blended systems, that support classroom and online teachings. © 2014 Science Publications. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.3844/jcssp.2022.743.756,Journal of Computer Science,"Intelligent Transportation System (ITS) offers outstanding features, including security applications and emergency alerts. Unfortunately, ITS limits traffic control services, adaptability, and adjustability due to the traffic volume. Hence, expanding the standard Vehicular Ad hoc Networks (VANET) framework is a requirement. As a result, in the latest days, the concept of Software-Defined Networking based Vehicular Ad hoc Networks (SDN-VANETs) has drawn considerable attention, creating VANETs smarter. The SDN-VANETs design is capable of addressing the aforementioned VANET issues. The integrated (analytically) SDN architecture is customizable and it also contains domain knowledge about the VANET architecture. Packet forwarding is a fundamental challenge in VANET wherein a router, as in the form of an RSU, determines the next hop of every signal in the pipeline to provide it to its recipient as fast as possible. Reinforcement Learning (RL) is used to develop autonomous routing protocol rules; however, the limitation of RL's depth prevents it from representing more comprehensively dynamic network conditions, restricting its true value. In this research, we present a VANET infrastructure based on SDN + EDGE with a new Deep Reinforcement Learning (DRL) route optimization framework, ""Gated Recurrent Reinforcement Learning (GRRL)"" neural network, whereby each router has its hybrid GRU + Feed Forward Neural Network (NN) for learning and making decisions in an entirely distributed environment. The GRRL collects routing characteristics from valuable information about huge backlog packets and previous operations, substantially approximating the weighting scheme of Q-learning. We also enable every route to connect with its immediate neighbors regularly such that a more comprehensive view of network topology may be integrated. Trial findings demonstrated that the multi-agent GRRL strategy could achieve a delicate balance between congestion awareness and the fastest routes, considerably reducing packet transmission time in general network topologies compared to its competitors. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3846/jau.2024.17793,Journal of Architecture and Urbanism,"This article examines the transformative impact of Sergio Fajardo’s mayoral administration (2003– 2007) in Medellín, Colombia, focusing on architecture and urban design projects that have promoted equity. Central to this urban renaissance was the Proyecto Urbano Integral (PUI) Nororiental, which revitalized informal settlements in the city’s northeastern zone. The initiative leveraged financing from Empresas Públicas de Medellín (EPM), a city-owned utility company, ensuring sustainable investment in public works without reliance on international loans. This financial model enabled the redistribution of funds to Medellín’s poorest neighborhoods, fostering transparency and combating corruption. Key to this urban strategy was the involvement of the Empresa de Desarrollo Urbano (EDU) which implemented the PUI with an intersectional planning approach combining public transit, education, culture, recreation, health, and safety initiatives. The PUI emphasized community participation through “Imaginary Workshops” promoting ownership and engagement among residents. The PUI Nororiental, enhanced by the Metrocable transit system and associated public spaces, has successfully integrated isolated neighborhoods while reducing violence and fostering social cohesion. Despite critiques of high costs, this article argues that quality public spaces and civic buildings promote community pride and destigmatization. Medellín’s “social urbanism” serves as a model for addressing inequity in Latin America and the broader Global South, demonstrating how architecture and urban design can drive social change. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.3906/elk-1111-46,Turkish Journal of Electrical Engineering and Computer Sciences,"The first part of this paper examines cycles at the network level of sensing and control architectures that are needed to maintain the shape of a multiagent formation in 2-dimensional space, while the formation moves as a cohesive whole. The key tools used in the paper are rigidity theory and graph theory. The second part of the paper focuses on the planner level and controller level of the architecture by designing the fuzzy planner and fuzzy controller of individual agents. This permits the decomposition of the complex coordination problem into a series of smaller ones. The fuzzy planner and the fuzzy controller on kinematic unicycles are simulated for an exemplary cyclic formation generated by the results obtained in the first half of the paper. The validity of the proposed approach in the shape control of multiagent formations is verified through simulation experiments. © Tübi̇tak.. © 2013 Elsevier B.V., All rights reserved.",TOPIC
10.3906/elk-1304-130,Turkish Journal of Electrical Engineering and Computer Sciences,"A curriculum vitae or a résumé, in general, consists of personal details, education, work experience, qualifications, and references. The overall objective of this study was to extract such data as experience, features, and business and education information from résumés stored in human resources repositories. In this article, we propose an ontology-driven information extraction system that is planned to operate on several million free-format textual résumés to convert them to a structured and semantically enriched version for use in semantic data mining of data essential in human resources processes. The architecture and working mechanism of the system, similarity of the concept and matching techniques, and an inference mechanism are introduced, and a case study is presented. © 2015 Elsevier B.V., All rights reserved.",TOPIC
10.3923/itj.2013.1717.1726,Information Technology Journal,"This study proposed an integral concept and methodology of knowledge management with procedural methods to enhance the efficiency and productivity of managing knowledge-Knowledge State Transition. It provides flexible treatments for promoting the feasibilities of knowledge management. This article also proposes a suitable model for managing and presenting knowledge by using computer aspect and shows the important of learning mechanism. At first, the knowledge map architecture is proposed to achieve knowledge navigation, knowledge dissemination and knowledge sharing in this study. In learning model, this study constructed the models by information technology, it not only could quantify these extract data and infer some formulas. It can help us to use the right method to learning and choose the useful knowledge to management. It will focus on that, major is that let learner achieve auxiliary effect during learning process by information technology and can quantify and modularize, not infer automatically. © 2031 Asian Network for Scientific Information. © 2013 Elsevier B.V., All rights reserved.",TOPIC
10.3923/jse.2013.46.67,Journal of Software Engineering,"SLAM (Simultaneous Localization and Mapping) and path planning are two important research directions in the field of robotics. How to explore an entirely unknown dynamic environment efficiently is a difficult problem for intelligent mobile robots. In this study, a new method of information fusion i.e. DSmT (Dezert-Smarandache Theory) which is an extension of DST (Dempster-Shafer Theory) is introduced to deal with high conflicting and uncertain information and then multi-agent robot system with GREM (Generalized Evidence Reasoning Machine) based on DSmT is presented for mobile robot's SLAM and efficiently planning smooth paths in unknown dynamic environment. The single robot is treated as a multi-agent system and the corresponding architecture combined with cooperative control is constructed. Considering the characteristics of sonar sensor, the grid map method is adopted and a sonar sensor mathematical model is constructed based on DSmT. Meanwhile a few of gbbaf (general basic belief assignment functions) are constructed for fusion. In order to make the A* algorithm which is the classical method for the global path planning suitable for local path planning, safety guard district search method and an optimizing approach for searched paths are proposed. Finally, SLAM and path planning experiments are carried out with Pioneer 2-DXe mobile robot. The experimental results testify the validity of hybrid DSm (Dezert-Smarandache) model under DSmT framework for fusing imprecise information during map building and also reveal the validity and superiority of the multi-agent system for path planning in unknown dynamic environment. © 2013 Academic Journals Inc. © 2013 Elsevier B.V., All rights reserved.",TOPIC
10.3926/jiem.3597,Journal of Industrial Engineering and Management,"Purpose: Developments in Industry 4.0 technologies and Artificial Intelligence (AI) have enabled data-driven manufacturing. Predictive maintenance (PdM) has therefore become the prominent approach for fault detection and diagnosis (FD/D) of induction motors (IMs). The maintenance and early FD/D of IMs are critical processes, considering that they constitute the main power source in the industrial production environment. Machine learning (ML) methods have enhanced the performance and reliability of PdM. Various deep learning (DL) based FD/D methods have emerged in recent years, providing automatic feature engineering and learning and thereby alleviating drawbacks of traditional ML based methods. This paper presents a comprehensive survey of ML and DL based FD/D methods of IMs that have emerged since 2015. An overview of the main DL architectures used for this purpose is also presented. A discussion of the recent trends is given as well as future directions for research. Design/methodology/approach: A comprehensive survey has been carried out through all available publication databases using related keywords. Classification of the reviewed works has been done according to the main ML and DL techniques and algorithms Findings: DL based PdM methods have been mainly introduced and implemented for IM fault diagnosis in recent years. Novel DL FD/D methods are based on single DL techniques as well as hybrid techniques. DL methods have also been used for signal preprocessing and moreover, have been combined with traditional ML algorithms to enhance the FD/D performance in feature engineering. Publicly available datasets have been mostly used to test the performance of the developed methods, however industrial datasets should become available as well. Multi-agent system (MAS) based PdM employing ML classifiers has been explored. Several methods have investigated multiple IM faults, however, the presence of multiple faults occurring simultaneously has rarely been investigated. Originality/value: The paper presents a comprehensive review of the recent advances in PdM of IMs based on ML and DL methods that have emerged since 2015. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.3934/electreng.2025024,AIMS Electronics and Electrical Engineering,"As contemporary industrial enterprises and manufacturing facilities expand in scale, the judicious scheduling of numerous in-house equipment clusters has become a critical factor in enhancing operational efficiency and reducing production costs. Traditional static algorithms merely sustain the baseline functionality of factory apparatuses, thereby failing to unlock the latent synergy among integrated equipment. In response to the advent of artificial intelligence and the maturation of machine learning algorithms, innovative solutions have emerged to address such operational scheduling challenges. This paper presents an algorithm predicated on a deep reinforcement learning-based optimization strategy, integrated with the localized time-of-use electricity tariff framework, to diminish the operating expenses of dryer clusters within the facility. Initially, an objective function aimed at minimizing total operating costs was constructed, alongside the formulation of constraint conditions derived from the operational protocols of the dryer clusters. Subsequently, under a reinforcement learning paradigm, the dryer clusters were modeled by delineating the state and action spaces and formulating a reward function contingent upon the tariff schedule and the degree of completion of gas-drying tasks. Ultimately, a neural network employing a double-DQN architecture was developed and utilized to resolve the scheduling strategy through model training. Empirical results from multiple training iterations with dryer clusters validated that the proposed algorithm can reduce electricity expenditures without necessitating alterations to the existing equipment, while also providing recommendations for the optimal number of additional standby dryers to further reduce operational costs. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3934/mbe.2023765,Mathematical Biosciences and Engineering,"Multicast communication technology is widely applied in wireless environments with a high device density. Traditional wireless network architectures have difficulty flexibly obtaining and maintaining global network state information and cannot quickly respond to network state changes, thus affecting the throughput, delay, and other QoS requirements of existing multicasting solutions. Therefore, this paper proposes a new multicast routing method based on multiagent deep reinforcement learning (MADRL-MR) in a software-defined wireless networking (SDWN) environment. First, SDWN technology is adopted to flexibly configure the network and obtain network state information in the form of traffic matrices representing global network links information, such as link bandwidth, delay, and packet loss rate. Second, the multicast routing problem is divided into multiple subproblems, which are solved through multiagent cooperation. To enable each agent to accurately understand the current network state and the status of multicast tree construction, the state space of each agent is designed based on the traffic and multicast tree status matrices, and the set of AP nodes in the network is used as the action space. A novel single-hop action strategy is designed, along with a reward function based on the four states that may occur during tree construction: progress, invalid, loop, and termination. Finally, a decentralized training approach is combined with transfer learning to enable each agent to quickly adapt to the dynamic changes of network link information and accelerate convergence. Simulation experiments show that MADRL-MR outperforms existing algorithms in terms of throughput, delay, packet loss rate, etc., and can establish more intelligent multicast routes. Code and model are available at https://github.com/GuetYe/MADRL-MR code. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.3991/ijim.v19i14.56871,International Journal of Interactive Mobile Technologies,"This study explores digital shifts in human resource management (HRM) through content co-occurrence analysis, examining trends and the role of mobile technologies. A bibliometric content co-occurrence analysis was conducted on 28 papers from 2014 to 2024, sourced from the Scopus database. Cite space software visualized the scientific landscape and themes. The findings reveal that advanced technologies—including artificial intelligence (AI), big data analytics, cloud computing, Internet of Things (IoT), blockchain, and mobile computing—are increasingly integrated into HRM practices. These advancements have reinforced HRM’s centrality in digital transformation, focusing on data-driven decision-making, employee engagement, and strategic alignment with business goals. However, challenges remain, such as data privacy concerns, skill gaps, and balancing technology with human-centric approaches. Mobile technology is growing, particularly in M-learning applications, mobile web and video conferencing, remote laboratories, and wireless networks, in reshaping HRM processes. Integrating mobile computing and smart agent technologies enhances adaptive environments for HR professionals and employees. This study emphasizes the need for research to navigate these complexities and improve HRM outcomes. Future research should focus on mobile architectures integration, cost-effectiveness, applications, and the social impact of next-generation mobile technologies on human resource management. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.3991/ijoe.v17i12.25455,International Journal of Online and Biomedical Engineering,"Multi-agent systems MASs have been widely used to interoperate hospital information systems (HISs). The use of MASs for HISs interoperability has become a central solution, especially in the field of emergency medicine. In emergencies, the notion of delay is relative, because responders only have a few minutes to react. This emergency response time has an important role in the event that an accident occurs on the road. Existing procedures for the emergency ambulance (EA) dispatch strategy are based on manual dispatch. In this work, we are introducing a distributed emergency ambulance (DEA) routing system to control emergency latency time, which includes driving route planning to guide emergency vehicles and the allocation of distributed emergency resources (emergency ambulances and hospitals) to reduce the EA response time caused by traffic or the wrong human decision to transport ambulance to the accident site. The allocation of resources (hospitals) is ensured through a recommendation system based on the interoperability of several interconnected HISs using a multi-agent system. The proposed solution takes into consideration dynamic traffic flow information during the day to build dynamic paths for EA. The improved method is based on a distributed architecture to calculate and find the optimal pathway for a set of emergency vehicles based on ACO ant colony optimization techniques. The results of the simulation show that the proposed method can decrease the total travel time of the ambulance to reach the accident position compared to conventional methods that use lights and sirens to warn other vehicles to free up the road for the ambulance or use a traditional approach based on the vision/reflection of the driver to choose in a random way the paths to take. Based on such a solution, ambulance staff will be able to save lives by optimizing the total journey with the minimum travel. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.4018/IJeC.357993,International Journals of e-Collaboration,"Preserving cultural heritage is essential for maintaining cultural diversity and promoting sustainable development. This study investigates the application of multi-agent networks in the protection and management of traditional village cultural heritage, capitalizing on their inherent distributed, collaborative, and adaptable characteristics. By integrating advanced technologies such as big data, data mining, and machine learning, the research meticulously develops a comprehensive system architecture and functional modules aimed at revitalizing traditional village spaces. The findings demonstrate significant enhancements in protection efficiency, while simultaneously fostering cultural inheritance and innovation within village communities. Through these innovative approaches, this study provides valuable insights into the preservation of traditional village cultural heritage and contributes to the broader objectives of cultural diversity conservation. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.4018/JOEUC.368009,Journal of Organizational and End User Computing,"In domains such as e-commerce and media recommendations, personalized recommendation systems effectively alleviate the issue of information overload. However, existing systems still face challenges in multimodal data processing, data sparsity, and dynamic changes in user preferences. This paper proposes a Hierarchical Generative Reinforcement Learning Recommendation Optimization framework (HG-RLRO) that addresses these issues by integrating multimodal data, Generative Adversarial Networks (GAN), Inverse Reinforcement Learning (IRL), and Hierarchical Temporal Difference Learning (HTD). HG-RLRO employs a multi-agent architecture to handle textual and image data and utilizes GAN to generate simulated user behavior data to mitigate data sparsity. IRL dynamically infers user preferences across multiple time scales. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.4031/002533207787442321,Marine Technology Society Journal,"The need for data and information that can be used to enhance community resilience to coastal inundation and erosion has been highlighted by the devastating impacts of recent events such as Hurricane Katrina and the 2004 Indian Ocean tsunami. The physical systems causing coastal inundation and erosion are governed by a complex combination of oceanic, atmospheric, and terrestrial processes interacting across a broad range of temporal and spatial scales. Depending on time and place the expression of these processes may variously take the form of episodic storm-induced surge or wave overtopping and undercutting, chronic flooding and erosion associated with long-term relative sea level rise, or catastrophic inundation attributable to tsunami. Differences related to geographic setting, such as sea ice in Alaska or coral reefs in Hawai'i and the Pacific Islands, enhance this phenomenological variability. Anticipating the expression of these phenomena is also complicated by observed and projected changes in climate. Combined with these physical systems are social systems made up of diverse cultural, economic, and environmental conditions. Like the physical systems, the social systems are changing, largely because of increases in population and infrastructure along coastlines. These diverse conditions and systems reveal wide-ranging needs for the content, format, and timing of data and information to support decision-making. In addition, other considerations complicate these requirements for data and information: (1) the decentralized acquisition of information from a variety of platforms (e.g., tide gauges, wave buoys, satellites, radars); (2) data and models of varying complexity and spatial and temporal application; and (3) gaps and overlaps in agency, institutional, and organizational activity and authority. This systemic complexity presents a challenge to scientists, planners, managers, and others working to increase community resilience in the face of the risks associated with inundation and erosion. This paper describes a conceptual framework for an integrating architecture that would support program planning and product development toward hazard resilient communities. Central to this framework is a comprehensive, horizontally and vertically integrated view of the physical and social systems that shape the risks associated with coastal inundation and erosion, and the kinds of information needed to manage those risks. Equally important, the framework addresses the necessary connections among systems and scales. This integrated approach also emphasizes the needs of planners, managers, and decision-makers in a changing physical and social environment, as well as the necessity of an iterative, nested, collaborative, and participatory process. © 2012 Elsevier B.V., All rights reserved.",TOPIC
10.4108/airo.8895,EAI Endorsed Transactions on AI and Robotics,"Modern software applications demand efficient and reliable testing methodologies to ensure robust user interface functionality. This paper introduces an autonomous reinforcement learning (RL) agent integrated within a Behavior-Driven Development (BDD) framework to enhance UI testing. By leveraging the adaptive decision-making capabilities of RL, the proposed approach dynamically generates and refines test scenarios aligned with specific business expectations and actual user behavior. A novel system architecture is presented, detailing the state representation, action space, and reward mechanisms that guide the autonomous exploration of UI states. Experimental evaluations on open-source web applications demonstrate significant improvements in defect detection, test coverage, and a reduction in manual testing efforts. This study establishes a foundation for integrating advanced RL techniques with BDD practices, aiming to transform software quality assurance and streamline continuous testing processes. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.4108/eai.27-8-2020.2294611,International Conference on Mobile Multimedia Communications (MobiMedia),"In view of the low efficiency of traditional system planning, a multi-agent based decision-making system for building space planning is proposed. The spatial characteristics of traditional villages in southeastern chongqing are analyzed and the overall structure is designed. B/S three-layer architecture is adopted, MapObject functional components are selected, and web browsers are set up to facilitate information retrieval. According to the actual situation, the Web server is divided into application hierarchy or scale scale, server structure and hardware type. Design the spatial decision-making information system by using various data and information, and process the business and basic information of the enterprise according to the information processing system of public participation. Two kinds of distributed database systems are designed to accommodate different databases for different purposes and improve the performance of the whole system. Under the natural environment, agricultural production and living conditions, design the spatial planning decision plan. According to the experimental results, the maximum planning efficiency of the system can reach 97%, providing a guarantee for building safety construction. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.4108/eai.31-5-2022.174087,EAI Endorsed Transactions on Scalable Information Systems,"Android devices like smartphones and tablets have become immensely popular and are an integral part of our daily lives. However, it has also attracted malware developers to design android malware which have grown aggressively in the last few years. Research shows that machine learning, ensemble, and deep learning models can successfully be used to detect android malware. However, the robustness of these models against well-crafted adversarial samples is not well investigated. Therefore, we first stepped into the adversaries’ shoes and proposed the ACE attack that adds limited perturbations in malicious applications such that they are forcefully misclassified as benign and remain undetected by different malware detection models. The ACE agent is designed based on an actor-critic architecture that uses reinforcement learning to add perturbations (maximum ten) while maintaining the structural and functional integrity of the adversarial malicious applications. The proposed attack is validated against twenty-two different malware detection models based on two feature sets and eleven different classification algorithms. The ACE attack accomplished an average fooling rate (with maximum of ten perturbations) of 46.63% across eleven permission based malware detection models and 95.31% across eleven intent based detection models. The attack forced a massive number of misclassifications that led to an average accuracy drop of 18.07% and 36.62% in the above permission and intent based malware detection models. Later we also design a defense mechanism using the adversarial retraining strategy, which uses adversarial malware samples with correct class labels to retrain the models. The defense mechanism improves the average accuracy by 24.88% and 76.51% for the eleven permission and eleven intent based malware detection models. In conclusion, we found that malware detection models based on machine learning, ensemble, and deep learning perform poorly against adversarial samples. Thus malware detection models should be investigated for vulnerabilities and mitigated to enhance their overall forensic knowledge and adversarial robustness. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.4108/EETINIS.V9I31.1059,EAI Endorsed Transactions on Industrial Networks and Intelligent Systems,"Interference has always been the main threat to the performance of traditional WiFi networks and next-generation moving forward. The problem can be solved with transmit power control(TPC). However, to accomplish this, an information-gathering process is required. But this brings overhead concerns that decrease the throughput. Moreover, mitigation of interference relies on the selection of transmit powers. In other words, the control scheme should select the optimum configuration relative to other possibilities based on the total interference, and this requires an extensive search. Furthermore, bidirectional communication in real-time needs to exist to control the transmit powers based on the current situation. Based on these challenges, we propose a complete solution with Digital Twin WiFi Networks (DTWN). Contrarily to other studies, with the agent programs installed on the APs in the physical layer of this architecture, we enable information-gathering without causing overhead to the wireless medium. Additionally, we employ Q-learning-based TPC in the Brain Layer to find the best configuration given the current situation. Consequently, we accomplish real-time monitoring and management thanks to the digital twin. Then, we evaluate the performance of the proposed approach through total interference and throughput metrics over the increasing number of users. Furthermore, we show that the proposed DTWN model outperforms existing schemes. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.4108/icst.bodynets.2013.253578,,"The deployment of home-based smart health services requires effective and reliable systems for personal and environmental data management. Cooperation between Home Area Networks (HAN) and Body Area Networks (BAN) can provide smart systems with ad hoc reasoning information to support health care. This paper details the implementation of an architecture that integrates BAN, HAN and intelligent agents to manage physiological and environmental data to proactively detect risk situations at the digital home. The system monitors dynamic situations and timely adjusts its behavior to detect user risks concerning to health. Thus, this work provides a reasoning framework to infer appropriate solutions in cases of health risk episodes. Proposed smart health monitoring approach integrates complex reasoning according to home environment, user profile and physiological parameters defined by a scalable ontology. As a result, health care demands can be detected to activate adequate internal mechanisms and report public health services for requested actions. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.4114/ia.v14i46.1540,Inteligencia Artificial,"In this work we present a BDI agent architecture to provide mobile soccer robots a high level reasoning mechanism. This architecture is build on top of layered system, where each layer is associated with a different level of abstraction in terms of robotic specification. The proposed approach allows the declarative specification of goal driven robot behavior. However in order to cope with the dynamics of mobile robotics the reasoning mechanism allows reactivity when needed. Syntax, semantics and interactions of the proposed architecture mental components are defined and studied. © AEPIA and the authors. © 2010 Elsevier B.V., All rights reserved.",LANGUAGE
10.4114/intartif.vol25iss69pp183-200,Inteligencia Artificial,"Several Cloud services may be composed in order to respond quickly to the users’ needs. Unfortunately, when running such a service some faults may occur. The outcome of fault control is a big challenge. In this paper, the authors propose a new approach based back recovery and multi-agent planning methods. The proposed architecture based MAS (Multi-Agent System) is composed of two main types of Agents: a Composition Manager Agent (CMA) and a Supervisor Agent (SA). The role of the CMA is to create a set of plans as an oriented graph where the nodes are the Cloud services and the valued arcs represent the composition order of these services. This agent saves checkpoints (nodes) in a stable memory so that there are at least one possible path. However, the SA ensures that the running plan is working properly; otherwise, it informs the CMA to select another sub-plan. Experimental results show the performance of the proposed approach in term of different metrics such as response time, cost and total cost of different alternatives of cloud services. © 2022 Elsevier B.V., All rights reserved.",LANGUAGE
10.4271/2004-01-3122,SAE Technical Papers,"Aviation Data Integration System (ADIS) project explores methods and techniques for integrating heterogeneous aviation data to support aviation problem-solving activity. Aviation problem-solving activities include: engineering troubleshooting, incident and accident investigation, routine flight operations monitoring, flight plan deviation monitoring, safety assessment, maintenance procedure debugging, and training assessment. To provide optimal quality of service, ADIS utilizes distributed intelligent agents including data collection agents, coordinator agents and mediator agents. This paper describes the proposed agent-based architecture of the Aviation Data Integration System (ADIS). Copyright © 2004 SAE International. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.4271/2023-01-0064,SAE International Journal of Advances and Current Practices in Mobility,"The development of a future hydrogen energy economy will require the development of several hydrogen market and industry segments including a hydrogen based commercial freight transportation ecosystem. For a sustainable freight transportation ecosystem, the supporting fueling infrastructure and the associated vehicle powertrains making use of hydrogen fuel will need to be co-established. This paper develops a long-term plan for refueling infrastructure deployment using the OR-AGENT (Optimal Regional Architecture Generation for Electrified National Transportation) tool developed at the Oak Ridge National Laboratory, which has been used to optimize the hydrogen refueling infrastructure requirements on the I-75 corridor for heavy duty (HD) fuel cell electric commercial vehicles (FCEV). This constraint-based optimization model considers existing fueling locations, regional specific vehicle fuel economy and weight, vehicle origin and destination (OD), vehicle volume by class and infrastructure costs to characterize in-mission refueling requirements for a given freight corridor. The authors applied this framework to determine the ideal long term public access locations for hydrogen refueling (constrained by existing fueling stations and dispensing technology), the minimal viable cost to deploy sufficient hydrogen fuel dispensers, and associated equipment, to accommodate a growing population of hydrogen fuel cell trucks. The framework discussed in this paper can be expanded and applied to additional electrified powertrains as well as a larger interstate system, expanded regional corridor, or other transportation networks. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.46338/ijetae0922_06,International Journal of Emerging Technology and Advanced Engineering,"The rapid penetration of Web technologies and strong economic pressure have led to an irresistible proliferation of Web services. In this paper, we are interested in the discovery and composition of Web services. In this sense, we propose a conceptual architecture and technical tools to carry out our approach. The originality of the proposed solution lies in the use of mixed tools ranging from multi-agents systems to Business Process Management (BPM) techniques, including Matchmaking algorithms and semantic models. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.46354/i3m.2022.dhss.005,,"This paper proposes an architecture to deal Strategic Decision Making within Urban Area and Industrial Plants due to Risks related to TIC/TIM (Toxic Industrial Chemical, Toxic Industrial Material) that nowadays represent a major issues in our Society due to their diffusion and potential impact. The problem is addressed by comprehensive models in order to provide an effective support to high level Decision Makers thanks to the use of the innovative architecture proposed, based on Strategic Engineering approach. A case study and related Models and AI Solutions are presented to validate the proposed concepts in a specific case study. It is proposed an innovative architecture where the use of IA (Intelligent Agents) and M&S (Modeling and Simulation) are combined to process Big Data arriving from sensor networks and digital systems and to support decision by evaluating alternative COAs (Courses of Actions) were population, countermeasures as well as potential antagonists are simulated by IA together with physical models of critical phenomena (e.g. hazardous material spills, explosions, contamination, fires). © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.47738/jads.v5i2.196,Journal of Applied Data Sciences,"Integrating Artificial Intelligence (AI) within Industry 4.0 has propelled the evolution of fault diagnosis and predictive maintenance (PdM) strategies, marking a significant shift towards smarter maintenance paradigms in the mechatronics sector. With the advent of Industry 4.0, mechatronic systems have become increasingly sophisticated, highlighting the critical need for advanced maintenance methodologies that are both efficient and effective. This paper delves into the confluence of cutting-edge AI techniques, including machine learning (ML) and deep learning (DL), with multi-agent systems (MAS) to enhance fault diagnosis precision and facilitate PdM in the context of Industry 4.0. Specifically, we explore the use of various ML models, including Support Vector Machines (SVMs) and Random Forests (RFs), and DL architectures like Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), which have been effectively oriented to analyses complex industrial data. Initially, the study examines the progress in AI algorithms that accelerate fault identification by leveraging data from system operations, sensors, and historical trends. AI-enabled fault diagnosis rapidly detects irregularities and discerns the fundamental causes, thereby minimizing downtime and enhancing system reliability and efficiency. Furthermore, this paper underscores the adoption of AI-driven PdM approaches, emphasizing prognostics that predict the Remaining Useful Life (RUL) of machinery. This predictive capability allows for the strategic scheduling of maintenance activities, optimizing resource use, prolonging the lifespan of expensive assets, and refining the management of spare parts inventory. The tangible advantages of employing AI for fault diagnosis and PdM are showcased through a case study from authentic mechatronics implementations. This case study highlights successful implementations, documenting real-world challenges such as data integration issues and system interoperability, and elaborates on the strategies deployed to navigate these obstacles. The results demonstrate improved operational reliability and cost savings and shed light on the pragmatic considerations and solutions that facilitate the adoption of AI and MAS in industrial applications. The paper also navigates the challenges and prospective research avenues in applying AI within the mechatronics domain of Industry 4.0, setting the stage for ongoing innovation and exploration in this transformative domain. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.47738/jads.v6i4.896,Journal of Applied Data Sciences,"This research proposes a CNN-based Deep Q-Network (CNN-DQN) model to enhance the navigation capabilities of autonomous vehicles in complex urban environments. The model integrates CNN for spatial abstraction with reinforcement learning to enable end-to-end decision-making based on high-dimensional sensor data. The primary objective is to evaluate the impact of CNN-DQN state abstraction on the quality and stability of the resulting policy. Using a grid-based simulator, the agent is trained on a synthetic dataset representing urban traffic scenarios. The CNN-DQN model consistently outperforms standard DQN in multiple metrics: cumulative reward increased by 14.3%, loss convergence accelerated by 22%, and mean absolute error (MAE) reduced to 0.028. Furthermore, the model achieved a Pearson correlation coefficient of 0.94 in predicted actions and demonstrated superior robustness under Gaussian noise perturbation, with reward loss limited to 6.18% compared to 18.7% in the baseline. Visualizations of CNN feature maps reveal spatial attention patterns that support efficient path planning. The action symmetry index confirms that the CNN-DQN agent exhibits consistent left-right decision behavior, validating its policy regularity. The novelty of this study lies in its combined use of deep spatial encoding and value-based reinforcement learning for structured, rule-based environments with real-time control implications. These findings indicate that CNN-enhanced reinforcement learning architectures can significantly improve autonomous navigation performance and robustness in dynamic urban settings. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.47839/ijc.20.1.2090,International Journal of Computing,"Conversation modeling is one of most important applications of natural language processing. Building response generation model for open domain conversation in a Chatbot is one of the hardest challenges in this area. The deep neural network architectures such as sequence to sequence models and its hierarchical variants provide a significant improvement in the field of conversation modeling. Although these models require large size corpus, they may cause huge data loss in training phase. Also, these models are unable to concentrate on important data in given context. It affects on generation of responses. To tackle these issues, this research work proposes a Variational Hierarchical Conversation RNN with Attention mechanism (VHCRA) model for response generation. The VHCRA uses the concept of latent variable representation to avoid data degeneracy and the attention mechanism to identify important data within context. The model is trained on large size benchmark dataset, i.e., Cornell Movie Dialog corpus which contains conversations from different movies. The model is evaluated using automatic evaluation metrics such as Negative Log-likelihood and Embedding-Based Metrics. The experimental result shows that the proposed model gains significant improvement in comparison with recently proposed approaches and generate meaningful responses according to the context. © 2021 Elsevier B.V., All rights reserved.",TOPIC
10.5117/CCR2023.1.9.ENSS,Computational Communication Research,"Reputation is essential to human interactions and shapes group dy-namics, however, it can be manipulated. In order to identify key aspects of malicious communication strategies, we have developed an agent-based simulation framework that captures aspects of the dynamics of social reputation communication: the reputation game simulation. After giving an overview of our framework, we highlight both previous and new results obtained with it. Similarly to other works in the literature on trust and reputation networks, probability functions and Bayesian logic are used in the reputation game simulation to represent uncertain-ties in agents’ beliefs. A new aspect of our framework is how bounded rationality of humans is modeled. It is regarded as a consequence of the necessary data compression step minds with limited capacity have to perform. Although this tries to minimize the loss of relevant infor-mation, for which we discuss two theoretically plausible options, it introduces cognitive imperfections. The resulting imperfect reasoning due to this and other cognitive shortcomings makes agents vulnerable to deception. This eventually leads to the emergence of communication and behavioral patterns in reputation game simulations that resemble reality, such as for example echo chambers, self-deception, deception symbiosis, and freezing of group opinions. As a result, the framework we propose could be used to develop methods to mitigate the impact of harmful communication strategies, i.e. in social media. We illustrate the potential for this via simulation experiments. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.5194/isprs-archives-XLVIII-2-W8-2024-327-2024,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","Historical buildings and monuments are typically subject to degradation over time due to the passage of time and constant exposure to external agents. The use of artificial intelligence (AI) to support the work of conservation and restoration specialists in identifying surface decay is a research topic of considerable interest at present. This study presents two approaches: ChatGPT and an object detection architecture (YOLOv5). Specifically, this investigation sought to evaluate the ChatGPT's ability to identify and describe surface degradation pathologies by exploiting its pre-trained models for image analysis. The ICOMOS-ISCS: Illustrated Glossary on Stone Deterioration Patterns (2008) was provided as a reference to guide the use of specific terminology. In the first test phase, to verify the accuracy of the ChatGPT results, benchmark images (depicting different types of damage) extracted from the UNI 11182 (2006) standard referring to the definition of degradation types were used. Only later were images from literature studies and other photographic datasets also used. In general, the results of the analysis were validated with the conclusions of professionals and with the conclusions of other AI techniques, as well as with the descriptions provided by reference manuals in the literature. In particular, the decay annotations predicted by the pre-trained object detection model were compared with those made by human experts. The capabilities and limitations of both approaches as tools for identifying deterioration pathologies are illustrated. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.5194/isprs-archives-XLVIII-2-W9-2025-57-2025,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","This paper presents a novel reinforcement learning (RL) framework for automated vectorization of high-resolution aerial imagery, addressing key challenges in geospatial analysis through adaptive feature extraction and sequential decision-making. Our hybrid architecture combines a modified ResNet-50 backbone with atrous spatial pyramid pooling (ASPP) for multi-scale feature extraction and bidirectional GRUs for spatial context modeling, integrated with a dueling double DQN agent that optimizes vectorization through reward-driven policy learning. The proposed method demonstrates significant improvements over conventional approaches, achieving about 10% increase in mean Intersection-over-Union (mIoU) on the CrowdAI Mapping Challenge dataset while reducing processing time by 29% through optimized RL-based decision sequences. A multi-component reward system balances geometric accuracy (boundary F1-score: 0.79), topological correctness (94.1% Cycle Consistency and 93.4% Junction Accuracy), and computational efficiency, enabling robust performance across diverse urban and rural landscapes. This work establishes a new paradigm for adaptive geospatial vectorization that combines deep learning’s representational power with RL’s sequential optimization capabilities. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.5194/isprs-archives-XLVIII-M-9-2025-391-2025,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","This paper introduces an integrated digital reconstruction of the ancient city of Pergamon, combining Virtual Reality (VR), Artificial Intelligence (AI), and photorealistic 3D modeling to establish a historically informed and immersive virtual environment. Beginning with the production of precise architectural plans using AutoCAD®, the project develops detailed three-dimensional models of major Hellenistic and Roman-era structures-such as the Temple of Athena, the Altar of Zeus, and the Pergamon Theatre-through 3ds Max® and Blender®, followed by their spatial deployment in Unreal Engine®, incorporating terrain data, realistic lighting, and authentic textures. To elevate user engagement, historically accurate avatars were created using Character Creator® and animated with iClone®, while AI capabilities were integrated via Unreal Engine® and Convai® to allow real-time, context-sensitive interaction with users. These AI-driven characters function as narrative agents, guiding visitors through the virtual city and delivering interpretive content tied to specific landmarks. The resulting platform not only reconstructs architectural forms but also revives elements of social life and public space, offering an experiential mode of engagement with ancient urbanism. By uniting archaeological data, digital media, and conversational AI, this study exemplifies how emerging technologies can expand both the pedagogical and experiential dimensions of cultural heritage interpretation. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.5194/isprsarchives-XLI-B2-349-2016,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","With growing populations, economic pressures, and the need for sustainable practices, many urban regions are rapidly densifying developments in the vertical built dimension with mid- And high-rise buildings. The location of these buildings can be projected based on key factors that are attractive to urban planners, developers, and potential buyers. Current research in this area includes various modelling approaches, such as cellular automata and agent-based modelling, but the results are mostly linked to raster grids as the smallest spatial units that operate in two spatial dimensions. Therefore, the objective of this research is to develop a geospatial model that operates on irregular spatial tessellations to model mid- And high-rise buildings in three spatial dimensions (3D). The proposed model is based on the integration of GIS, fuzzy multi-criteria evaluation (MCE), and 3D GIS-based procedural modelling. Part of the City of Surrey, within the Metro Vancouver Region, Canada, has been used to present the simulations of the generated 3D building objects. The proposed 3D modelling approach was developed using ESRI's CityEngine software and the Computer Generated Architecture (CGA) language. © 2016 Elsevier B.V., All rights reserved.",TOPIC
10.5194/ms-16-87-2025,Mechanical Sciences,"Trajectory planning has undergone remarkable strides in recent times, especially in the behavior prediction of traffic participants. Given that strong coupling conditions such as pedestrians, vehicles, and roads restrict the interactive behavior of autonomous vehicles and other traffic participants, it has become critical to design a trajectory prediction algorithm based on traffic scenarios for autonomous-driving technology. In this paper, we propose a novel trajectory prediction algorithm based on Transformer networks, a data-driven method that ingeniously harnesses dual-input channels. The rationale underlying this approach lies in its seamless fusion of scene context modeling and multi-modal prediction within a neural network architecture. At the heart of this innovative framework resides the multi-headed attention mechanism, ingeniously deployed in both the agent attention layer and the scene attention layer. This finessing not only captures the profound interdependence between agents and their surroundings but also imbues the algorithm with a better real-time predictive prowess, enhancing computational efficiency. Eventually, substantial experiments with the Argoverse dataset will demonstrate improved trajectory accuracy, with the minimum average displacement error (MADE) and minimum final displacement error (MFDE) being reduced by 12 % and 31 %, respectively. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0001996503470350,,"The production of steel normally constitutes the inception of many supply chains in different areas of industry. Steel manufacturing companies are strongly affected by bull whip effects and other unpredictable influences along their production chains. Improving their operational efficiency is required to keep a competitive position on the market. Hence, flexible planning and scheduling systems are needed to support these processes, which are based on considerable amounts of data, hardly processable manually anymore. MasDISPO-xt is an agent-based generic online planning and scheduling system for the observation on MES-level of the complete supply chain of Saarstahl AG, a globally respected steel manufacturer. This paper concentrates on the horizontal and vertical integration of influences of rough planning on detailed and the other way around. Based on model-driven engineering business processes are modeled on CIM-level, a service oriented architecture is presented for the interoperability of all components, legacy systems and others wrapped behind services. Finally, an agent-based detailed planning and scheduling ensuring interoperability in horizontal and vertical direction is approached effectively. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0004820001640171,,"The increasing demand for energy and the availability of several solutions of renewable energy sources has stimulated the formulation of plans aiming at expanding and upgrading existing power grids in several countries. According to NIST, smart grid will be one of the greatest achievements of the 21st century. By linking information technologies with the electric power grid to provide electricity with a brain, the smart grid promises many benefits, including increased energy efficiency, reduced carbon emissions, and improved power reliability. In this paper we present an agent based architecture for supporting collection and processing of information about local energy production and storage resources of neighborhoods of individual houses and to schedule the energy flows using negotiation protocols. Copyright © 2014 SCITEPRESS. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0004823305180525,,"The use of Video Games as learning tool is becoming increasingly widespread. Indeed, these games are well known as educational games or serious games. They mainly aim at providing to the learner an interactive, motivational and educational environment at the same time. In order to better study the necessary characteristics for the development of an effective serious game (both motivational and educational), we evaluated the physiological responses of participants during their interaction with our serious game, called HeapMotiv. We essentially measured a physiological index of engagement through an EEG wifi headset and studied the evolution of this index with the different missions and motivational strategies of HeapMotiv. Focusing on the gaming aspects, the analysis of this engagement index behavior showed the significant impact of motivational strategies on skills acquisition and motivational experience. An agent-based architecture is proposed as a methodological basis for serious games conception. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0004841103180323,,"The impact of the evolution of the global economic ecosystem, has forced and still force again organizations to either adopt new behaviour schemas and to deeply change their structure, also to be more open to their environment as well. These impacts require a new cooperation philosophy from organizations side. Several studies have focused on the problem of the intercompany cooperation, proposing approaches that provide interoperability mechanisms. But this remains an open research domain. In this work we will propose a mediation architecture between different companies. A mediator allows us to create an intercompany cooperative process, the purpose of this solution is to keep the company architecture and ask the mediator which is a software-based agent to play an intermediary role between companies, and involve it in making the transformation between companies. We define a dynamic and cooperative inter-companies model that combines the agent technology and the decision trees paradigm. This last facilitates making decision by selecting the services that best meet customer needs, in order to create a composite service. Copyright © 2014 SCITEPRESS. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0005010702800287,,"In decentralized control of discrete event systems, two main agents contribute to the computation of decisions: local supervisors and fusion modules. The local supervisors process the information detected on the plant and its environment, and transmit their results to the fusion modules. The latter process what is received from the local supervisors in order to decide actions to be applied to the plant. In the existing decentralized control architectures, the local supervisors execute complex operations, while the fusion modules execute simple operations. In the present article, we propose to move the decision computation complexity from local supervisors to fusion modules, that is what we term: moving decisions closer to actions. We justify this movement of decision and develop a simple architecture based on it. With the proposed architecture, the local supervisors are simple local observers, while all decisions are computed by the fusion modules. We characterize the class of languages achievable with the new architecture and compare it with the classes of languages achievable with the existing decentralized architectures and the centralized architecture. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0005139002820287,,"The extension of our integration to technologies brings about the possibility of inserting moral prototypes into artificial agents, no matter if they are going to interact with other artificial agents or biological creatures. We describe here MultiA, a computational model for simulating moral behavior derived from changes over a biologically inspired architecture. MultiA uses reinforcement learning techniques and is intended to produce selective cooperative behavior as a consequence of a biologically plausible model of morality inspired from a perusal of empathy. MultiA has its sensorial information translated into emotions and homeostatic variable values, which feed cognitive and learning systems. The moral behavior is expected to emerge from the artificial social emotion of sympathy and its associated feeling of empathy, based on an ability to internally emulate other agents internal states. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0005153603200325,,"Recently an increasing amount of research focuses on improving agents believability by adding affective features to the traditional agent-based modeling. This is probably due to the demand of reaching ever more realistic behaviors on agent-based simulations which extends to several and diverse application fields. The present work proposes 03A: an Open Affective Agent Architecture, which extends a traditional BDI agent architecture improving a practical reasoning with more ""human"" characteristics. This architecture tries to address disperse definitions combining the main elements of supporting psychological and neurological theories. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0005159604450453,,"Nowadays an enormous quantity of heterogeneous and distributed information is stored in the digital University. Exploring online collections to find knowledge relevant to a user's interests is a challenging work. The artificial intelligence and Semantic Web provide a common framework that allows knowledge to be shared and reused in an efficient way. In this work we propose a comprehensive approach for discovering E-learning objects in large digital collections based on analysis of recorded semantic metadata in those objects and the application of expert system technologies. We have used Case Based-Reasoning methodology to develop a prototype for supporting efficient retrieval knowledge from online repositories. We suggest a conceptual architecture for a semantic search engine. OntoUS is a collaborative effort that proposes a new form of interaction between users and digital libraries, where the latter are adapted to users and their surroundings. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0005185000050014,,"Partially observable Markov decision processes (POMDPs) and the belief-desire-intention (BDI) framework have several complimentary strengths. We propose an agent architecture which combines these two powerful approaches to capitalize on their strengths. Our architecture introduces the notion of intensity of the desire for a goal's achievement. We also define an update rule for goals' desire levels. When to select a new goal to focus on is also defined. To verify that the proposed architecture works, experiments were run with an agent based on the architecture, in a domain where multiple goals must continually be achieved. The results show that (i) while the agent is pursuing goals, it can concurrently perform rewarding actions not directly related to its goals, (ii) the trade-off between goals and preferences can be set effectively and (iii) goals and preferences can be satisfied even while dealing with stochastic actions and perceptions. We believe that the proposed architecture furthers the theory of high-level autonomous agent reasoning. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0005197003610369,,"This paper outlines the research and development of a Conversational Intelligent tutoring System (CITS) named Abdullah focusing on the novel application of learning theories. Abdullah CITS is a software program intended to converse with students aged 10 to 12 years old about the essential topics in Islam in natural language. The CITS aims to mimic human Arabic tutor by engaging the students in dialogue using Modern Arabic language (MAL), and classical Arabic language (CAL), utilizing supportive evidence from the Quran and Hadith. Abdullah CITS is able to capture the user's level of knowledge and adapt the tutoring session and tutoring style to suit that particular learner's level of knowledge. This is achieved through the inclusion of several learning theories implemented in Abdullah's architecture, which are applied to make the tutoring suited to an individual learner. There are no known specific learning theories for CITS therefore the novelty of the approach is in the combination of well-known learning theories typically employed in a classroom environment. The system was evaluated through end user testing with the target age group in schools in Jordan and the UK. The initial evaluation has produced some positive results, indicating that Abdullah is gauging the individual learner's knowledge level and adapting the tutoring session to ensure learning gain is achieved. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0005208600660074,,"The development of innovative and intelligent multiagent applications based on Distributed Constraints Reasoning techniques is obviously a fastidious task, especially to tackle new combinatorial problems (e.i. distributed resource management, distributed air traffic management, Distributed Sensor Network (Béjar et al., 2005)). However, there are very few open-source platforms dedicated to solve such problems within realistic uses. Given the difficulty that researchers are facing, simplifying assumptions and simulations uses are commonly used techniques. Nevertheless, these techniques may not be able to capture all the details about the problem to be solved. Hence, transition from the simulation to the actual development context causes a loss of accuracy and robustness of the applications to be implemented. In this paper, we present preliminary results of a new distributed constraints programming platform, namely JChoc DisSolver. Thanks to the extensibility of JADE communication model and the robustness of Choco Solver, JChoc brings a new added value to Distributed Constraints Reasoning. The platform is user-friendly and the development of multiagent applications based on Constraints Programming is no longer a mystery to users. A real distributed problem is used to illustrate how the platform can be appropriated by an unsophisticated user and the experimental results are encouraging for more investigations. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0005215901310142,,"The dual-process theory of human cognition proposes the existence of two systems for decision-making: a slower, deliberative, ""problem-solving"" system and a quicker, reactive, ""pattern-recognition"" system. The aim of this work is to explore the effect on agent performance of altering the balance of these systems in an environment of varying complexity. This is an important question, both in the realm of explanations of expert behaviour and to AI in general. To achieve this, we implement three distinct types of agent, embodying different balances of their problem-solving and pattern-recognition systems, using a novel, hybrid, humanlike cognitive architecture. These agents are then situated in the virtual, stochastic, multi-agent ""Tileworld"" domain, whose intrinsic and extrinsic environmental complexity can be precisely controlled and widely varied. This domain provides an adequate test-bed to analyse the research question posed. A number of computational simulations are run. Our results indicate that there is a definite performance benefit for agents which use a mixture of problem-solving and pattern-recognition systems, especially in highly complex environments. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0005224001830195,,"Planning under uncertainty in multiagent settings is highly intractable because of history and plan space complexities. Probabilistic graphical models exploit the structure of the problem domain to mitigate the computational burden. In this paper, we introduce the first parallelization of planning in multiagent settings on a CPU-GPU heterogeneous system. In particular, we focus on the algorithm for exactly solving interactive dynamic influence diagrams, which is a recognized graphical models for multiagent planning. Beyond parallelizing the standard Bayesian inference, the computation of decisions' expected utilities are parallelized. The GPU-based approach provides significant speedup on two benchmark problems. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0005326301600167,,"This paper describes the architecture and functionality of a generic agent that is in charge of handling a given environment in an Ambient Intelligence context, ensuring suitable contextualized and personalized support to the user's actions, adaptivity to the user's peculiarities and to changes over time, and automated management of the environment itself. The architecture is implemented in a multi-agent system, where different types of agents are endowed with different levels of reasoning and learning capabilities. In addition to controlling normal operations of the environment, the system may identify user's needs and goals and activate suitable workflows to satisfy them. Some actions in these workflow involve the execution of semantic services. When a single service is not available for fulfilling a given need, an automatic service composer is used to obtain a suitable combination of services. The architecture has been implemented in a prototypical agent-based system that works in a Smart Home Environment. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0005639004240428,,"In recent years, the steel industry has significantly raised its demands regarding product quality, optimization of production cost, environmental issues and lead-time. The demand for improved production performance has in turn increased the demand on information systems, in particular highlighting the need for improved factory- and company-wide collaboration and information exchange. The heterogeneity in structure, technology and architecture of the information systems deployed in manufacturing plants presents further challenges to the design and implementation of a data exchange system for process optimization. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0005686500310041,,"In this paper, we propose a multi-agent recommender system based on the Belief-Desire-Intention (BDI) model applied to multi-context systems. First, we extend the BDI model with additional contexts to deal with sociality and information uncertainty. Second, we propose an ontological representation of planning and intention contexts in order to reason about plans and intentions. Moreover, we show a simple real-world scenario in healthcare in order to illustrate the overall reasoning process of our model. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0005824702810286,,"Agent architectures and parallelization are, with a few exceptions, rarely to encounter in traditional automated theorem proving systems. This situation is motivating our ongoing work in the higher-order theorem prover Leo-III. In contrast to its predecessor - the well established prover LEO-II - and most other modern provers, Leo-III is designed from the very beginning for concurrent proof search. The prover features a multiagent blackboard architecture for reasoning agents to cooperate and to parallelize proof construction on the term, clause and search level. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0005833003040310,,"Due to the computational complexity (NP-Complete) of Constraint Programming (CP), several researchers have abandoned its use in robotic research field. In the last decade, as many approaches of real-time constraint handling have been proposed, constraint programming has proved to be a stand-alone technology that can be used in several research fields. Even if mobile robotics is a complex research area, in this paper, we prove that distributed constraint reasoning techniques can be utilized as a very elegant formalism for multi-robot decision making. First, we describe dynamic distributed constraint satisfaction formalism, the new platform architecture ""RoboChoc"" and specify how decision making can be controlled in multi-robots environment using dynamic communication protocols. Then we provide an example application that illustrates how our platform can be used to solve multi-robot problems using constraint programming techniques. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0005956801300139,,"Holonic Control Architecture is a successful solution model for reconfigurable manufacturing problems. Two well-known different technologies have been used separately to implement the holonic control model. The first technology is IEC 61499 standard, and the second is autonomous reactive agent. Both of the previous mentioned technologies have its own pros and cons. Therefore this research is merging the two technologies together in one solution body, to magnifying their pros and reduce their cons. Ultimately; it provides a novel implementation model for the manufacturing holons, to be followed in similar reconfigurable manufacturing problems. A human worker in cooperation with a safe industrial robot, has been selected as a case study of a reconfigurable manufacturing problem. The proposed holonic control solution has been applied to the case study, to evaluate the ability of the solution to satisfy the requirements of the case study. The results show the ability of the proposed control solution to provide a flexible physical and logical interaction framework, which can be scaled over more workers in cooperation with more industrial robots. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0006253101070118,,"Traditional search techniques are difficult to apply to cooperative negotiation games, due to the often enormous search trees and the difficulty in calculating the value of a players position or move. We propose a generic agent architecture that ensembles negotiation, trust and opponent modeling, simplifying the development of agents capable of playing these games effectively by introducing modules to handle these challenges. We demonstrate the application of this modular architecture by instantiating it in two different games and testing the designed agents in a variety of scenarios; we also assess the role of the negotiation, trust and opponent modeling modules in each of the games. Results show that the architecture is generic enough to be applied in a wide variety of games. Furthermore, we conclude that the inclusion of the three modules allows for more effective agents to be built. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0006590402000207,,"This paper presents an intelligent approach to support engineers with performing computational simulation of new developments and prototypes. With multiple interacting physical effects and large three dimensional models the choice of the right solution strategy is crucial for a correct solution and an acceptable calculation time. The presented multi-agent system can solve these simulation tasks using distributed heterogeneous computation resources with the objective to reduce the calculation time. An important factor for the criterion time is the choice of the linear solver. Here a case-based reasoning concept is introduced to improve the decisions in the multi-agent system. Allowing each agent to solve its problem part by using appropriate solution methods, a decentralized architecture with autonomous software agents is provided. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0006590700480057,,"Agent-based recommender systems have been exploited in the last years to provide informative suggestions to users, showing the advantage of exploiting components like beliefs, goals and trust in the recommendations' computation. However, many real-world scenarios, like the traffic one, require the additional feature of representing and reasoning about spatial and temporal knowledge, considering also their vague connotation. This paper tackles this challenge and introduces CARS, a spatio-temporal agent-based recommender system based on the Belief-Desire-Intention (BDI) architecture. Our approach extends the BDI model with spatial and temporal information to represent and reason about fuzzy beliefs and desires dynamics. An experimental evaluation about spatio-temporal reasoning in the traffic domain is carried out using the NetLogo platform, showing the improvements our recommender system introduces to support agents in achieving their goals. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0006600602440249,,"Context-aware systems are capable of perceiving the physical environment where they are deployed and adapt their behavior accordingly. Multiagent systems based on the BDI architecture can be used to process contextual information in the form of beliefs. Contextual information can be divided and structured in the form of information domains. Information and experience sharing enables a single agent to receive data on different information domains from another agent. In this scenario, establishing a trust model between agents can take into account the relative perceptions each agent has of the others, as well as different trust degrees for different information domains. The objective of this work is to adapt an epistemic model to be used by agents with their belief revision in order to establish a mechanism of domain-specific relative trust attribution. Such mechanism will allow for each agent to possess different trust degrees associated with other agents regarding different information domains. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0006606304540463,,"Data integration of enterprise systems typically involves combining heterogeneous data residing in different sources into a unified, homogeneous whole. This heterogeneity takes many forms and there are all sorts of significant practical and theoretical challenges to managing this, particularly at the semantic level. In this paper, we consider a type of semantic heterogeneity that is common in Model Driven Architecture (MDA) Computation Independent Models (CIM); one that arises due to the data’s dependence upon the system it resides in. There seems to be no relevant work on this topic in Conceptual Modelling, so we draw upon research done in philosophy and linguistics on formalizing pure indexicals – ‘I’, ‘here’ and ‘now’ – also known as de se (Latin ‘of oneself’) or the deitic centre. This reveals firstly that the core dependency is essential when the system is agentive and the rest of the dependency can be designed away. In the context of MDA, this suggests a natural architectural layering; where a new concern ‘system dependence’ is introduced and used to divide the CIM model into two parts; a system independent ontology model and a system dependent agentology model. We also show how this dependence complicates the integration process – but, interestingly, not reuse in the same context. We explain how this complication usually provides good pragmatic reasons for maximizing the ontology content in an ‘Ontology First’, or ‘Ontology then Agentology’ approach. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0007345701460153,,"Optimizing decision quality in large scale, distributed, resource allocation problems requires selecting the appropriate decision network architecture. Such resource allocation problems occur in distributed sensor networks, military air campaign planning, logistics networks, energy grids, etc. Optimal solutions require that demand, resource status, and allocation decisions are shared via messaging between geographically distributed, independent decision nodes. Jamming of wireless links, cyber attacks against the network, or infrastructure damage from natural disasters interfere with messaging and, thus, the quality of the allocation decisions. Our contribution described in the paper is a decentralized resource allocation architecture and algorithm that is robust to significant message loss and to uncertain demand arrival, and provides fine-grained, many-to-many combinatorial task allocation. Most importantly, it enables a conscious choice of the best level of decentralization under the expected degree of communications denial and quantifies the benefits of approximating status of peer nodes using proxy agents during temporary communications loss. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0007360901230133,,"The online game Agar.io has become massively popular on the internet due to its intuitive game design and its ability to instantly match players with others around the world. The game has a continuous input and action space and allows diverse agents with complex strategies to compete against each other. In this paper we focus on the pellet eating task in the game, in which an agent has to learn to optimize its navigation strategy to grow maximally in size within a specific time period. This work first investigates how different state representations affect the learning process of a Q-learning algorithm combined with artificial neural networks which are used for representing the Q-function. The representations examined range from raw pixel values to extracted handcrafted feature vision grids. Secondly, the effects of using different resolutions for the representations are examined. Finally, we compare the performance of different value function network architectures. The architectures examined are two convolutional Deep Q-networks (DQN) of varying depth and one multilayer perceptron. The results show that the use of handcrafted feature vision grids significantly outperforms the direct use of raw pixel input. Furthermore, lower resolutions of 42×42 lead to better performances than larger resolutions of 84×84. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0007385401860193,,"The development of new information and communication technologies is contributing to the emergence of a new generation of real-time services in various fields of application. In the area of intelligent transport systems, these new services also include connected vehicles that enable vehicles to collect and disseminate information, safety alerts and make driving smarter and more environmentally friendly. More and more, they concern power-assisted or fully autonomous vehicles. In this paper we propose an architecture of agents and we project it on a multi-agent transport simulator (MATSim). In order to improve the performance of the DriverAgent in the simulation an alternative approach to score the DriverAgent plans is proposed. The results show that the proposed scoring function is able to ensure that agents improve their plans at each iteration performing on the same if not better level than the current scoring function. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0010232504400449,International Conference on Information Systems Security and Privacy,"Reinforcement learning (RL) is a widely used machine learning method for optimal decision-making compared to rule-based methods. Because of that advantage, RL has also recently been used a lot in penetration testing (PT) problems to assist in planning and deploying cyber attacks. Although the complexity and size of networks keep increasing vastly every day, RL is currently applied only for small scale networks. This paper proposes a double agent architecture (DAA) approach that is able to drastically increase the size of the network which can be solved with RL. This work also examines the effectiveness of using current popular deep reinforcement learning algorithms including DQN, DDQN, Dueling DQN and D3QN algorithms for PT. The A2C algorithm using Wolpertinger architecture is also adopted as a baseline for comparing the results of the methods. All algorithms are evaluated using a proposed network simulator which is constructed as a Markov decision process (MDP). Our results demonstrate that DAA with A2C algorithm far outweighs other approaches when dealing with large network environments reaching up to 1000 hosts. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0010898000003116,International Conference on Agents and Artificial Intelligence,"Machine and Deep Learning techniques have been widely used in the PowerTAC competition to forecast the price of energy as a bulk, amongst other ends. In order to allow agents to quickly set up, train, and test python-built models, we developed a framework based on a micro-service architecture suitable for predicting wholesale market prices in PowerTAC. The architecture allows for algorithms to be implemented in Python as opposed to the language used in PowerTAC, Java. This paper also presents two datasets, one for the task of classifying whether trades occur, and another for the task of predicting the clearing price of trades that occur. We benchmark these results with basic methods like linear regression, random forest, and a neural network. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0011046100003188,"International Conference on Information and Communication Technologies for Ageing Well and e-Health, ICT4AWE - Proceedings","We explore how machine learning (ML) and Bayesian networks (BNs) can be combined in a personal health agent (PHA) for the detection and interpretation of electrocardiogram (ECG) characteristics. We propose a PHA that uses ECG data from wearables to monitor heart activity, and interprets and explains the observed readings. We focus on atrial fibrillation (AF), the commonest type of arrhythmia. The absence of a P-wave in an ECG is the hallmark indication of AF. Four ML models are trained to classify an ECG signal based on the presence or absence of the P-wave: multilayer perceptron (MLP), logistic regression, support vector machine, and random forest. The MLP is the best performing model with an accuracy of 89.61% and an F1 score of 88.68%. A BN representing AF risk factors is developed based on expert knowledge from the literature and evaluated using Pitchforth and Mengersen’s validation framework. The P-wave presence or absence as determined by the ML model is input into the BN. The PHA is evaluated using sample use cases to illustrate how the BN can explain the occurrence of AF using diagnostic reasoning. This gives the most likely AF risk factors for the individual. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0011268400003271,"Proceedings of the International Conference on Informatics in Control, Automation and Robotics","Traffic simulation has gained a lot of interest for autonomous driving companies for qualitative safety evaluation of self driving vehicles. In order to improve self driving systems from synthetic simulated experiences, traffic agents need to adapt to various situations while behaving as a human driver would do. However, simulating realistic traffic agents is still challenging because human driving style cannot easily be encoded in a driving policy. Adversarial Imitation learning (AIL) already proved that realistic driving policies could be learnt from demonstration but mainly on highways (NGSIM Dataset). Nevertheless, traffic interactions are very restricted on straight lanes and practical use cases of traffic simulation requires driving agents that can handle more various road topologies like roundabouts, complex intersections or merging. In this work, we analyse how to learn realistic driving policies on real and highly interactive driving scenes of Interaction Dataset based on AIL algorithms. We introduce a new driving policy architecture built upon the Lanelet2 map format which combines a path planner and an action space in curvilinear coordinates to reduce exploration complexity during learning. We leverage benefits of reward engineering and variational information bottleneck to propose an algorithm that outperforms all AIL baselines. We show that our learning agent is not only able to imitate humane like drivers but can also adapts safely to situations unseen during training. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0011850100003488,"International Conference on Cloud Computing and Services Science, CLOSER - Proceedings","The evolution of virtualization technologies and of distributed computing architectures has inspired the so-called cloud native applications development approach. A cornerstone of this approach is the decomposition of a monolithic application into small and loosely coupled components (i.e., microservices). In this way, application’s performance, flexibility, and robustness can be improved. However, most orchestration algorithms assume generic application workloads that cannot serve efficiently the specific requirements posed by the applications, regarding latency and low communication delays between their dependent microservices. In this work, we develop advanced mechanisms for automating the allocation of computing resources, in order to optimize the service of cloud-native applications in a layered edge-cloud continuum. We initially present the Mixed Integer Linear Programming formulation of the problem. As the execution time can be prohibitively large for real-size problems, we develop a fast heuristic algorithm. To efficiently exploit the performance–execution time trade-off, we employ a novel multi-agent Rollout, the simplest and most reliable among the Reinforcement Learning methods, that leverages the heuristic’s decisions to further optimize the final solution. We evaluate the results through extensive simulations under various inputs that demonstrate the quality of the generated sub-optimal solutions. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.5220/0012178300003598,"International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management, IC3K - Proceedings","Instant Search is a paradigm where a search system retrieves answers on the fly while typing. The naïve implementation of an Instant Search system would hit the search back-end for results each time a user types a key, imposing a very high load on the underlying search system. In this paper, we propose to address the load issue by identifying tokens that are semantically more salient toward retrieving relevant documents and utilizing this knowledge to trigger an instant search selectively. We train a reinforcement agent that interacts directly with the search engine and learns to predict the word's importance in relation to the search engine. Our proposed method treats the search system as a black box and is more universally applicable to diverse architectures. To further support our work, a novel evaluation framework is presented to study the trade-off between the number of triggered searches and the system's performance. We utilize the framework to evaluate and compare the proposed reinforcement method with other baselines. Experimental results demonstrate the efficacy of the proposed method in achieving a superior trade-off. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.52842/conf.acadia.2020.1.084,,"The worldwide lockdowns during the first wave of the COVID-19 pandemic had an immense effect on the public space. The events brought up an opportunity to redesign mobility plans, streets, and sidewalks, making cities more resilient and adaptable. This paper builds on previous research of the authors that focused on the development of a graphene-based sensing material system applied to a smart pavement and utilized to obtain pedestrian spatiotemporal data. The necessary steps for gradual integration of the material system within the urban fabric are introduced as milestones toward predictive modeling and dynamic mobility reconfiguration. Based on the capacity of the smart pavement, the current research presents how data acquired through an agent-based pedestrian simulation is used to gain insight into mobility patterns. A range of maps representing pedestrian density, flow, and distancing are generated to visualize the simulated behavioral patterns. The methodology is used to identify areas with high density and. thus, high risk of transmitting airborne diseases. The insights gained are used to identify streets where additional space for pedestrians is needed to allow safe use of the public space. It is proposed that this is done by creating a dynamic mobility plan where temporal pedestrianization takes place at certain times of the day with minimal disruption of road traffic. Although this paper focuses mainly on the agent-based pedestrian simulation, the method can be used with real-time data acquired by the sensing material system for informed decision-making following otherwise-unpredictable pedestrian behavior. Finally, the simulated data is used within a predictive modeling framework to identify further steps for each agent; this is used as a proof-of-concept through which more insights can be gained with additional exploration. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.52842/conf.caadria.2018.1.473,,"The last three decades have witnessed the explosion of technology and its impact on the architecture discipline which has drastically changed the methods of design. New techniques such as Agent-based modeling (ABM) and Virtual Reality (VR) have been widely implemented in architectural and urban design domains, yet the potential integration between these two methods remains arguably unexploited. The investigation in this paper aims to probe the following questions: How can architects and urban designers be informed more comprehensively by melding ABM and VR techniques at the preliminary/conceptual design stage? Which platform is considered more appropriate to facilitate a user-friendly system and reduces the steep learning curve? And what are the potential benefits of this approach in architectural education, particularly for the design studio environment? With those questions, we proposed a prototype in Unity, a multi-platform development tool that originated from the game industry, to simulate and visualize pedestrian behaviors in urban environments with immersive design experience and tested it in a scenario-based case study. This approach has also been further tested in an architectural design studio, demonstrating its technical feasibility as well as the potential contributions to the pedagogy. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.52842/conf.caadria.2019.2.231,,"In recent years, with the development of artificial intelligence and digital architecture, more architects begin to wonder how to generate urban planning and urban design through computational method. For the purpose of generating urban planning digitally using computational algorithms, we design a series of algorithms to develop a system that evaluates initial features of the site such as the strength of sunlight, water, landscape. These parameters related to the function zoning of the town were determined based on the data extracted from case studies. These data were integrated into a Markov chain mathematical model for the sake of analyzing the function of grid points. Finally, an algorithm of a multi-agent system was used to optimize the function that could evaluate the grade of each raster point of the town, which could be used to decide the function of a specific region. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.52842/conf.caadria.2021.1.171,,"This paper discusses the potentials of reinforcement learning in game engine for design, implementation, and construction of architecture. It inaugurates a new design tool that promotes a material-informed design-build workflow for architectural design and construction industries that achieves a comprehensive circular economy. As a proof of concept, it uses the project ""Reform Standard"", a machine-learning-based searching system that designs new shell structures composed of existing wasted materials, as a demonstration to discuss how reinforcement learning, machine vision and automated searching algorithm in the game engine can promote a material-aware design and converts wastes into construction materials. The demonstrator project sorts and transforms irregular chunks of wasted broken plastics into a new form. Instead of recycling those wastes in an energy-intensive process, the game engine is capable of finding the intricacy and new machine-oriented aesthetics in those otherwise neglected wastes. Furthermore, future research directions such as robotic-aided construction are discussed by exposing the potentials and problems in the demonstrated project. Finally, the future circular strategy is discussed beyond the demonstrated tests and local uses. The standardization of material, legislation and material lifecycle needs to be comprehensively considered and designed by architects and designers during conceptual design phase. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.52842/conf.caadria.2022.1.373,Proceedings of the International Conference on Computer-Aided Architectural Design Research in Asia,"This paper reports a pedagogical experience that incorporates deep learning to design in the context of a recently created course at the Carnegie Mellon University School of Architecture. It analyses an exercise called Bubble2Floor (B2F), where students design floor plans for a multi-story row-house complex. The pipeline for B2F includes a parametric workflow to synthesise an image dataset with pairs of apartment floor plans and corresponding bubble diagrams, a modified Pix2Pix model that maps bubble diagrams to floor plan diagrams, and a computer vision workflow to translate images to the geometric model. In this pedagogical research, we provide a series of observations on challenges faced by students and how they customised different elements of B2F, to address their personal preferences and problem constraints of the housing complex as well as the obstacles from the computational workflow. Based on these observations, we conclude by emphasising the importance of training architects to be active agents in the creation of deep learning workflows and make them accessible for socially relevant and constrained design problems, such as housing. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.52842/conf.caadria.2023.1.109,Proceedings of the International Conference on Computer-Aided Architectural Design Research in Asia,"In architectural theory, the spatial experience is dynamic, evolving from sequences of interconnected views shaped by past encounters and future expectations. Traditional computational methods such as Isovists provide geometric insights but fall short in representing their sequential nature. To address this gap, the paper introduces a novel methodology that combines agent-driven simulation, 3D Isovist sampling, and deep learning for quantitative analysis and comparison of spatial experiences in architecture. This approach leverages the Grasshopper plugin Pedsim for simulating pedestrian paths and a self-supervised video representation learning model MemDPC for processing depth panorama sequences and extracting numerical features for each sequence. The methodology is first validated through a controlled experiment with various sequence typologies, affirming its efficacy in recognizing typological similarities. A case study is conducted comparing Louis Kahn's designs with Roman architecture, quantitatively analysing their intertwined spatial experiences. This research offers a framework for quantitatively comparing spatial experiences across buildings and interpreting the nuanced impact of historical references on modern spaces. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.52842/conf.caadria.2023.2.521,Proceedings of the International Conference on Computer-Aided Architectural Design Research in Asia,"Machine Learning (ML) in architecture is an emerging field with myriad potentials to impact the design process. Despite its many possibilities, ML is typically employed when the design problem is sufficiently defined, and further, is only integrated within software environments. Desk Mate is collaborative drawing machine that can be used early in the design process by coupling tangible tools like pens and trace paper with ML driven feedback and generation. Embedding physical tools that are familiar and intuitive with digital intelligence offers designers new ways of engaging with ML algorithms interactively, potentially changing the way the architectural industry approaches design problems. Desk Mate chains together image retrieval methods from machine vision with generative ML models like variational autoencoders (VAE) and generative adversarial networks (GANS) to react to design sketches as they are drawn. This pipeline allows Desk Mate to iterate through designs with the designer. Thus, Desk Mate demonstrates an interactive platform that collocates designer and machine as creative agents, facilitating drawing with ML driven feedback, potentially accelerating design iteration in the early stages of ideation. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.52842/conf.ecaade.2016.1.261,Proceedings of the International Conference on Education and Research in Computer Aided Architectural Design in Europe,"In this paper we present a framework that allows to introduce architecture students to agent-based simulations in the context of urban planning. It provides them with an understanding of how such simulations work by instructing them to learn how to program and develop an agent on their own. Along with the framework we explain our didactic concept of teaching complexity-science-methods to students from other fields such as architecture. In the discussion we report on that theory and practise should be alternated at very short intervals. Additionally we emphasize the importance to teach a good understanding of the capabilities of modelling and simulation tools, since uneducated students tend to trust them too blindly. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.52842/conf.ecaade.2023.2.471,Proceedings of the International Conference on Education and Research in Computer Aided Architectural Design in Europe,"While isovists have been used widely to quantify and analyze architectural space, its utilization for generative design still needs to be explored. On the other hand, advanced deep learning has shown opportunities for data-driven generative design. This research revisits the isovist capacity to represent architecture as a series of spatial sequences and extends the role of isovists beyond merely a perception model to projective agents. This paper presents the development of GIsT: Generative Isovists Transformer in sampling, learning, and generating architectural spatial sequences. By coupling isovists with discrete representation and generative deep learning models, we untapped the generative potential of isovist representation for spatial sequence synthesis. We demonstrated its capacity to learn the architectural spatial sequence and extendability via few-shots learning. The results show a promising direction toward integrating data-driven experiential spatial synthesis in future computational design tools. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.5334/AH.475,Architectural Histories,"Electric light became popular as a source of illumination in Japan between the late 1910s and the early 1930s. It created novel sensory spaces that made the former darkness of domestic architecture a thing of the past. This article explores the ways in which domestic spaces became overwhelmingly lit by electric lights and how the architect Fujii Koji reacted to them in lighting and architectural design. The shift from embedded local illumination to general lighting entailed changing perceptions about indoor light conditions and how the light-body-space triad revolved around the rejection of interior darkness by electricity-related businesses, manufacturers, and academia. From the mid-1920s onward, this process was further enhanced by the Domestic Electricity Promotion Association, whose illumination planning, exhibitions, and model houses manifested its functionalist approach to effectively distributing light throughout the house, an approach subtly underpinned by a romantic vision of the domestic use of electric light. Functionalism in interior lighting, and the excessive brightness of electric light in domestic spaces, meanwhile, were questioned by Fujii and some lighting engineers. The disharmony between the glare of electric light and the Japanese style of rooms led him to create distinctive papered light fittings installed in his experimental houses, including Chōchikukyo. Fujii’s endeavours to scientifically understand and architecturalise diffused light through washi (Japanese paper) are conceptually similar to cultural critic Tanizaki Jun’ichiro’s In Praise of Shadows, an essay that rediscovered the systematically manipulable agents that produced Japaneseness: shadows in response to aesthetic discord caused by the emergence of electric light. © 2022 Elsevier B.V., All rights reserved.",TOPIC
10.54364/AAIML.2023.1170,Advances in Artificial Intelligence and Machine Learning,"Autonomous Ground Vehicles (AGVs) are essential tools for a wide range of applications stemming from their ability to operate in hazardous environments with minimal human operator input. Effective motion planning is paramount for successful operation of AGVs. Conventional motion planning algorithms are dependent on prior knowledge of environment characteristics and offer limited utility in information poor, dynamically altering environments such as areas where emergency hazards like fire and earthquake occur, and unexplored subterranean environments such as tunnels and lava tubes on Mars. We propose a Deep Reinforcement Learning (DRL) framework for intelligent AGV exploration without a-priori maps utilizing Actor-Critic DRL algorithms to learn policies in continuous and high-dimensional action spaces directly from raw sensor data. The DRL architecture comprises feedforward neural networks for the critic and actor representations in which the actor network strategizes linear and angular velocity control actions given current state inputs, that are evaluated by the critic network which learns and estimates Q-values to maximize an accumulated reward. Three off-policy DRL algorithms, DDPG, TD3 and SAC, are trained and compared in two environments of varying complexity, and further evaluated in a third with no prior training or knowledge of map characteristics. The agent is shown to learn optimal policies at the end of each training period to chart quick, collision-free exploration trajectories, and is extensible, capable of adapting to an unknown environment without changes to network architecture or hyperparameters. The best algorithm is further evaluated in a realistic 3D environment. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.55056/jec.572,Journal of Edge Computing,"Edge computing is an extension of cloud computing where physical servers are deployed closer to the users in order to reduce latency. Edge data centers face the challenge of serving a continuously increasing number of applications with a reduced capacity compared to traditional data center. This paper introduces ImpalaE, an agent based on Deep Reinforcement Learning that aims at optimizing the resource usage in edge data centers. First, it proposes modeling the problem as a Markov Decision Process, with two optimization objectives: reducing the number of physical servers used and maximize number of applications placed in the data center. Second, it introduces an agent based on Proximal Policy Optimization, for finding the optimal consolidation policy, and an asynchronous architecture with multiple workers-shared learner that enables for faster convergence, even with reduced amount of data. We show the potential in a simulated edge data center scenario with different VM sizes based on Microsoft Azure real traces, considering CPU, memory, disk and network requirements. Experiments show that ImpalaE effectively increases the number of VMs that can be placed per episode and that it quickly converges to an optimal policy.1. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.55417/fr.2022005,Autonomous Cooperative Multi-Vehicle System for Interception of Aerial and Stationary Targets,"This paper presents the design, development, and testing of hardware-software systems by the IISc-TCS team for Challenge 1 of the Mohamed Bin Zayed International Robotics Challenge 2020. The goal of Challenge 1 was to grab a ball suspended from a maneuvering UAV and pop balloons anchored to the ground, using suitable manipulators. The important tasks carried out to address this challenge include the design and development of a hardware system with efficient grabbing and popping mechanisms, considering the restrictions in volume and payload, design of accurate target interception algorithms using visual information suitable for outdoor environments, and development of a software architecture for dynamic, multi-agent, aerial systems performing complex tasks. In this paper, we discuss the design of a custom end-effector mounted on a single degree of freedom manipulator, and robust algorithms for the interception of targets in an uncertain environment. Vision-based guidance and tracking strategies are developed based on the concept of pursuit engagement and artificial potential function. The software architecture presented in this work develops an Operation Management System (OMS) architecture that allocates static and dynamic tasks collaboratively among multiple UAVs to perform any given task. An important aspect of this work is that all the systems developed were designed to operate in completely autonomous mode. A detailed description of the architecture along with simulations of complete challenge in the Gazebo environment and field experiment results are also included in this work. The developed hardware-software system is useful for counter-UAV systems and can be used for other applications.",TOPIC
10.55417/fr.2022047,NeBula: TEAM CoSTAR's Robotic Autonomy Solution that Won Phase II of DARPA Subterranean Challenge,"This paper presents and discusses algorithms, hardware, and software architecture developed by the TEAM CoSTAR (Collaborative SubTerranean Autonomous Robots), competing in the DARPA Subterranean Challenge. Specifically, it presents the techniques utilized within the Tunnel (2019) and Urban (2020) competitions, where CoSTAR achieved second and first place, respectively. We also discuss CoSTAR's demonstrations in Martian-analog surface and subsurface (lava tubes) exploration. The paper introduces our autonomy solution, referred to as NeBula (Networked Belief-aware Perceptual Autonomy). NeBula is an uncertainty-aware framework that aims at enabling resilient and modular autonomy solutions by performing reasoning and decision making in the belief space (space of probability distributions over the robot and world states). We discuss various components of the NeBula framework, including (i) geometric and semantic environment mapping, (ii) a multi-modal positioning system, (iii) traversability analysis and local planning, (iv) global motion planning and exploration behavior, (v) risk-aware mission planning, (vi) networking and decentralized reasoning, and (vii) learning-enabled adaptation. We discuss the performance of NeBula on several robot types (e.g., wheeled, legged, flying), in various environments. We discuss the specific results and lessons learned from fielding this solution in the challenging courses of the DARPA Subterranean Challenge competition.",TOPIC
10.55417/fr.2023015,From Warfighting Needs to Robot Actuation: A Complete Rapid Integration Swarming Solution,"Swarm robotics systems have the potential to transform warfighting in urban environments but until now have not seen large-scale field testing. We present the Rapid Integration Swarming Ecosystem (rise), a platform for future multi-agent research and deployment. rise enables rapid integration of third-party swarm tactics and behaviors, which was demonstrated using both physical and simulated swarms. Our physical testbed is composed of more than 250 networked heterogeneous agents and has been extensively tested in mock warfare scenarios at five urban combat training ranges. rise implements live, virtual, constructive simulation capabilities to allow the use of both virtual and physical agents simultaneously, while our “fluid fidelity” simulation enables adaptive scaling between low and high fidelity simulation levels based on dynamic runtime requirements. Both virtual and physical agents are controlled with a unified gesture-based interface that enables a greater than 150:1 agent-to-operator ratio. Through this interface, we enable efficient swarm-based mission execution. rise translates mission needs to robot actuation with rapid tactic integration, a reliable testbed, and efficient operation.",TOPIC
10.55417/fr.2023020,TC-Driver: A Trajectory Conditioned Reinforcement Learning Approach to Zero-Shot Autonomous Racing,"Autonomous racing is becoming popular for academic and industry researchers as a test for general autonomous driving by pushing perception, planning, and control algorithms to their limits. While traditional control methods such as model predictive control are capable of generating an optimal control sequence at the edge of the vehicles' physical controllability, these methods are sensitive to the accuracy of the modeling parameters, such as tire modeling coefficients. As model mismatch is inevitable in reality, the heuristic nature of Reinforcement Learning (RL) offers a viable approach to modeling robustness. This paper presents TC-Driver, an RL approach for robust control in autonomous racing. In particular, the TC-Driver agent is conditioned by a trajectory generated by any arbitrary traditional high-level trajectory planner. The proposed TC-Driver architecture addresses the tire parameter modeling inaccuracies by exploiting the learning capabilities of RL while utilizing the reliability of traditional planning methods in a hybrid fashion. We train the agent under varying tire conditions, allowing it to generalize to different model parameters, aiming to increase the racing capabilities of the system in practice. Experimental results demonstrate that the proposed hybrid RL architecture of the TC-Driver improves the generalization robustness of autonomous racing agents when compared to a previous state-of-the-art end-to-end-based architecture. Namely, the proposed controller yields a 29-fold improvement in crash ratio when facing model mismatch and can zero-shot transfer its behavior on unseen tracks which present completely new features, while the end-to-end baseline fails. When deployed on a physical system, the proposed architecture demonstrates zero-shot Sim2Real capabilities that outperform end-to-end agents 10-fold in terms of crash ratio while exhibiting similar driving characteristics in reality as in simulation.",TOPIC
10.5755/j01.itc.43.1.4600,Information Technology and Control,"This paper presents a multi-agent system that handles unit micromanagement using online machine learning in real time strategy games. We used rtNEAT algorithm in order to obtain customized neural network topologies, thus avoiding to complex network architecture. We use an ontology based template to create suitable input and outputs for unit agents enabling them to cooperate and form teams for their mutual benefit and eliminating communication overhead. The AI system was implemented using the JADE framework and the BWAPI handled communication between our system and the game. We have chosen Starcraft as a testbed. As a baseline we compared the in game AI as well as several other AI solutions that use adaptive mechanisms. © 2014 Elsevier B.V., All rights reserved.",TOPIC
10.5772/10533,International Journal of Advanced Robotic Systems,"This article presents an agent based framework for coordinated motion planning of multiple robots. The emerging paradigm of agent based systems is implemented to address various issues related to safe and fast task execution when multiple robots share a common workspace. In the proposed agent based framework, each issue vital for coordinated motion planning of multiple robots and every robot participating in coordinated task is considered as an agent. The identified agents are interfaced with each other in order to incorporate the desired flexibility in the developed framework. This framework gives a complete strategy for determination of optimal trajectories of robots working in coordination with due consideration to their kinematic, dynamic and payload constraint. The complete architecture of the proposed framework and the detailed discussion on various modules are covered in this paper. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5772/5711,International Journal of Advanced Robotic Systems,"The focus of this research is to introduce the concept of combined intelligent control (CIC) as an effective architecture for decision-making and control of intelligent agents and multi-robot sets. Basically, the CIC is a combination of various architectures and methods from fields such as artificial intelligence, Distributed Artificial Intelligence (DAI), control and biological computing. Although any intelligent architecture may be very effective for some specific applications, it could be less for others. Therefore, CIC combines and arranges them in a way that the strengths of any approach cover the weaknesses of others. In this paper first, we introduce some intelligent architectures from a new aspect. Afterward, we offer the CIC by combining them. CIC has been executed in a multi-agent set. In this set, robots must cooperate to perform some various tasks in a complex and nondeterministic environment with a low sensory feedback and relationship. In order to investigate, improve, and correct the combined intelligent control method, simulation software has been designed which will be presented and considered. To show the ability of the CIC algorithm as a distributed architecture, a central algorithm is designed and compared with the CIC. © 2020 Elsevier B.V., All rights reserved.",TOPIC
10.5815/ijcnis.2023.06.03,International Journal of Computer Network and Information Security,"A mobile agent is a small piece of software which works on direction of its source platform on a regular basis. Because mobile agents roam around wide area networks autonomously, the protection of the agents and platforms is a serious worry. The number of mobile agents-based software applications has increased dramatically over the past year. It has also enhanced the security risks associated with such applications. Most of the security mechanisms in the mobile agent architecture focus solely on platform security, leaving mobile agent safety to be a significant challenge. An efficient authentication scheme is proposed in this article to address the situation of protection and authentication of mobile agent at the hour of migration of across multiple platforms in malicious environment. An authentication mechanism for the mobile agent based on the Hopfield neural network proposed. The mobile agent’s identity and password are authenticate using the specified mechanism at the moment of execution of assigned operation. An evaluative assessment has been offered, along with their complex character, in comparison to numerous agent authentication approaches. The proposed method has been put into practice, and its different aspects have been put to the test. In contrasted to typical client-server and code-on-demand approaches, the analysis shows that computation here is often more safe and simpler. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.5815/IJISA.2016.04.04,International Journal of Intelligent Systems and Applications,"Today, Massive Open Online Courses (MOOCs) have the potential to enable free online education on an enormous scale. However, a concern often raised about MOOCs is the consistently high drop-out rate of MOOC learners. Although many thousands of learners enroll on these courses, a very small proportion actually complete the course. This work is at the heart of this issue. It is interested in contributing on multi-agents systems and ontologies to describe the learning preferences and adapt educational resources to learner profile in MOOCs platforms. The primary aim of this work is to exploit the potential of multi-agents systems and ontologies to improve learners' engagement and motivation in MOOCs platforms and therefore reduce the drop-out rates. As part of the contribution of this work, the paper proposes a model of Multi-Agent System (MAS), based on ontologies for adapting the learning resources proposed to a learner in a MOOCs platform according to his learning preferences. To model an adequate online course, the determination of learner's preferences is done through the analysis of learner behavior relying on his indicator MBTI (Myers Briggs Type Indicator). The proposed model integrates the main functionalities of an intelligent tutoring system: profiling, updating of the profile, selection, adaptation and presentation of adequate resources. The architecture of the proposed system is composed on two main agents, four ontologies and a set of modules implemented. © 2018 Elsevier B.V., All rights reserved.",TOPIC
10.58286/29606,,"This contribution presents a semi-active control technique intended for mitigation of structural vibrations. The control law is derived in a repeated trial-and-error interaction between the control agent and a simulated environment. The experience-based training approach is used which is the defining feature of the machine learning techniques of reinforcement learning (RL), implemented here using the framework provided by Deep Q Learning (DQN). The involved artificial neural network not only determines the control action, but additionally identifies structural damages, which is a nontrivial task due to the nonlinearity of the control. This requires a specific multi-head architecture, which allows the network to be damage-aware, and a specific training procedure, where the memory pool preserved for the RL stage of experience replay is populated with not only the observations, control actions, and rewards, but also with the momentary status of structural damage. Such an approach can be used to explicitly promote the damage-awareness of the control agent. The proposed technique is tested and verified in a numerical example of a shear-type building model subjected to a random seismic-type excitation. A tuned mass damper (TMD) with a controllable level of viscous damping is used to implement the semi-active actuation, and the optimally tuned classical TMD provides the reference response. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.5937/jaes0-26386,Journal of Applied Engineering Science,"The mobile robots are devices with great boom given the possibilities that their utilities offer, and to a greater extent, those freelancers who do not require an operator to perform their functions. In order to consolidate the autonomy it is necessary to generate a system of planning of ways that allows a viable route and as far as possible optimal. This study develops a reactive two-dimensional path planning method with neural networks trained under the reinforcement learning method. The complexity of the scenario between the initial and final point is due to warning and forbidden obstacle zones, and the experimentation is carried out on different neural network architectures, each one as an agent of the learning-by-reinforcement algorithm, being these DQN and DDQN types. The best results are obtained with the DDQN training, reaching the objective in 89% in the validation episodes, although the DQN method shows to be 15.63% faster in its success cases. This work was carried out within the research group DIGITI of the Universidad Distrital Francisco José de Caldas. © 2023 Elsevier B.V., All rights reserved.",TOPIC
10.59490/footprint.19.1.7497,Footprint,"The evolution of architecture calls for a redefinition of materialism, urging a departure from deterministic systems towards non-linear causality and systems far from equilibrium. This entails recognising the dissolution of human-inhuman boundaries and advocating for tactile and sensory bodies that initiate metabolic changes by penetrating environments. Isabelle Stengers critiques the tendency to frame thought within pre-existing planes, labelling it as stupidity, and advocates for an architecture that proliferates rather than condemns. With this article, we propose to explore architecture’s singular conditions through the concept of trans-scalability, akin to transitioning from micro-subatomic to macro scales. We look at what enables transitions between scales, agents, fields and the realms of theory and practice. Additionally, we scrutinise how spatial construction practices, influenced by non-cartographic scale considerations and engaged with micro-subatomic dimensions, can impact contemporary architectural practices. To illustrate this, we present an alternative approach to transscalability through the work of Rachel Armstrong. With this new material reading, our aim is to view architecture as an interface between the world’s multiplicities and to explore how an architectural practice more attuned to the intersecting dynamics of various fluxes can be realised. With this approach, we aim to contribute to perceiving the world through its unstable and temporary material dimensions, thereby resisting stupidity. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.7717/peerj-cs.2025,PeerJ Computer Science,"As the diversity and volume of images continue to grow, the demand for efficient fine-grained image retrieval has surged across numerous fields. However, the current deep learning-based approaches to fine-grained image retrieval often concentrate solely on the top-layer features, neglecting the relevant information carried in the middle layer, even though these information contains more fine-grained identification content. Moreover, these methods typically employ a uniform weighting strategy during hash code mapping, risking the loss of critical region mapping-an irreversible detriment to fine-grained retrieval tasks. To address the above problems, we propose a novel method for fine-grained image retrieval that leverage feature fusion and hash mapping techniques. Our approach harnesses a multi-level feature cascade, emphasizing not just top-layer but also intermediate-layer image features, and integrates a feature fusion module at each level to enhance the extraction of discriminative information. In addition, we introduce an agent self-attention architecture, marking its first application in this context, which steers the model to prioritize on long-range features, further avoiding the loss of critical regions of the mapping. Finally, our proposed model significantly outperforms existing state-of-the-art, improving the retrieval accuracy by an average of 40% for the 12-bit dataset, 22% for the 24-bit dataset, 16% for the 32-bit dataset, and 11% for the 48-bit dataset across five publicly available fine-grained datasets. We also validate the generalization ability and performance stability of our proposed method by another five datasets and statistical significance tests. Our code can be downloaded from https://github.com/BJFU-CS2012/MuiltNet.git. © 2024 Elsevier B.V., All rights reserved.",TOPIC
10.9781/ijimai.2023.01.002,International Journal of Interactive Multimedia and Artificial Intelligence,"Spain is the second country in Europe with the most swimming pools. However, the legal literature estimates that 20% of swimming pools are not declared or irregular.The administration has a corps of people who manually analyze satellite or drone images to detect illegal or irregular structures. This method is costly in terms of effort and time, and it is also a method based on the subjectivity of the person carrying it out. This proposal aims to design a platform that allows the automatic detection of irregular pools. Using geographic information tools (GIS) based on orthophotography, combined with advanced machine learning techniques for object detection, allows this work. Furthermore, using a multi-agent architecture allows the system to be modular, with the possibility of the different parts of the system working together, balancing the workload. The proposed system has been validated by testing it in different towns in Spain. The system has shown promising results in performing this task, with an F1-Score of 97.1%. © 2023 Elsevier B.V., All rights reserved.",TOPIC
JMM/JMM.2010.11074389,Situation Aware Cognitive Assistance in Smart Homes,"Smart Homes (SH) have emerged as a realistically viable solution capable of providing technology-driven assistive living for the elderly and disabled. Nevertheless, it still remains a challenge to provide situation-aware cognitive assistance for those in need in their Activity of Daily Living (ADL). This paper introduces a systematic approach to providing situation-aware ADL assistances in a smart home environment. The approach makes use of semantic technologies for sensor data modeling, fusion and management, thus creating machine understandable and processable situational data. It exploits intelligent agents for interpreting and reasoning semantic situational (meta)data to enhance situation-aware decision support for cognitive assistance. We analyze the nature and issues of SH-based healthcare for cognitively deficient inhabitants. We discuss the ways in which semantic technologies enhance situation comprehension. We describe a cognitive agent for realizing high-level cognitive capabilities such as prediction and explanation. We outline the implementation of a prototype assistive system and illustrate the proposed approach through simulated and real-time ADL assistance scenarios in the context of situation aware assistive living.",PUBLICATION_TYPE
