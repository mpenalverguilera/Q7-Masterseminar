DOI,Document title,Abstract,REASON
10.1007/978-3-030-82017-6_9,Towards Explainable Visionary Agents: License to Dare and Imagine,"Since their appearance, computer programs have embodied discipline and structured approaches and methodologies. Yet, to this day, equipping machines with imaginative and creative capabilities remains one of the most challenging and fascinating goals we pursue. Intelligent software agents can behave intelligently in well-defined scenarios, relying on Machine Learning (ML), symbolic reasoning, and the ability of their developers for tailoring smart behaviors to specific application domains. However, to forecast the evolution of all possible scenarios is unfeasible. Thus, intelligent agents should autonomously/creatively adapt to the world’s mutability. This paper investigates the meaning of imagination in the context of cognitive agents. In particular, it addresses techniques and approaches to let agents autonomously imagine/simulate their course of action and generate explanations supporting it, and formalizes thematic challenges. Accordingly, we investigate research areas including: (i) reasoning and automatic theorem proving to synthesize novel knowledge via inference; (ii) automatic planning and simulation, used to speculate over alternative courses of action; (iii) machine learning and data mining, exploited to induce new knowledge from experience; and (iv) biochemical coordination, which keeps imagination dynamic by continuously reorganizing it. © 2021, Springer Nature Switzerland AG.",
10.1007/978-3-031-19842-7_29,Learning Efficient Multi-agent Cooperative Visual Exploration,"We tackle the problem of cooperative visual exploration where multiple agents need to jointly explore unseen regions as fast as possible based on visual signals. Classical planning-based methods often suffer from expensive computation overhead at each step and a limited expressiveness of complex cooperation strategy. By contrast, reinforcement learning (RL) has recently become a popular paradigm for tackling this challenge due to its modeling capability of arbitrarily complex strategies and minimal inference overhead. In this paper, we propose a novel RL-based multi-agent planning module, Multi-agent Spatial Planner (MSP). MSP leverages a transformer-based architecture, Spatial-TeamFormer, which effectively captures spatial relations and intra-agent interactions via hierarchical spatial self-attentions. In addition, we also implement a few multi-agent enhancements to process local information from each agent for an aligned spatial representation and more precise planning. Finally, we perform policy distillation to extract a meta policy to significantly improve the generalization capability of final policy. We call this overall solution, Multi-Agent Active Neural SLAM (MAANS). MAANS substantially outperforms classical planning-based baselines for the first time in a photo-realistic 3D simulator, Habitat. Code and videos can be found at https://sites.google.com/view/maans. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",
10.1007/978-3-031-26412-2_4,Oracle-SAGE: Planning Ahead in Graph-Based Deep Reinforcement Learning,"Deep reinforcement learning (RL) commonly suffers from high sample complexity and poor generalisation, especially with high-dimensional (image-based) input. Where available (such as some robotic control domains), low dimensional vector inputs outperform their image based counterparts, but it is challenging to represent complex dynamic environments in this manner. Relational reinforcement learning instead represents the world as a set of objects and the relations between them; offering a flexible yet expressive view which provides structural inductive biases to aid learning. Recently relational RL methods have been extended with modern function approximation using graph neural networks (GNNs). However, inherent limitations in the processing model for GNNs result in decreased returns when important information is dispersed widely throughout the graph. We outline a hybrid learning and planning model which uses reinforcement learning to propose and select subgoals for a planning model to achieve. This includes a novel action selection mechanism and loss function to allow training around the non-differentiable planner. We demonstrate our algorithms effectiveness on a range of domains, including MiniHack and a challenging extension of the classic taxi domain. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.",
10.1007/978-3-031-44851-5_28,Semantic Knowledge-Based Mission Planning Method According to Robot Characteristics in Outdoor Environment,"In the field of robots, many studies have been proposed to introduce advanced cognitive science into robot systems based on existing numerical information. These research directions allow robots to utilize their knowledge to simplify, understand, and efficiently plan their tasks. In this paper, we propose a semantic knowledge-based robot mission planning method in an irregular three-dimensional environment. We introduce an advanced robot mission planning method that defines the knowledge of robots and driving places based on ontology and utilizes the defined semantic knowledge. To this end, we define a robot domain based on Planning Domain Definition Language (PDDL) and solve it through a classical planner to plan the mission. Finally, we validate the suitability of the proposed method by conducting experiments with real-world robots within the campus environment and comparing them with general PDDL-based methods. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.",
10.1007/978-3-032-00642-4_15,Supporting Human-Robot Collaboration and Safety with the Proposed Explainable Neuro-Symbolic Reasoning,"In this article, an overview of the innovative architecture of a hybrid AI neuro-symbolic architecture which uses high-resolution deep vision with probabilistic first-order logic for safety monitoring and anomaly detection in Human-Robot Collaboration environment is proposed. Firstly, the problem and the proposed solution and its application to human-robot collaboration scenarios is outlined. Then, the performance of the proposed method for anomaly detection and its conformity to the requirements defined by the end-users in realistic scenarios is discussed. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.",
10.1007/978-981-96-7956-0_22,"The A-BDI Metamodel for Human-Level AI: Argumentation as Balancing, Dialogue and Inference","In this paper, we introduce A-BDI, the first metamodel for formal and computational argumentation. It contains three models, conceptualizing argumentation as balancing, argumentation as dialogue, and argumentation as inference respectively. Each model looks at argumentation from a different perspective, addressing its own concerns and using its own formal and computational methods. Whereas balancing is inspired by the scale metaphor and uses quantitative techniques typically found in theories in economics and neural computing, dialogue is developed in multiagent communication and interaction and uses chatbot and Large Language Models (LLMs) technology, and inference is derived from theoretical investigations in knowledge representation and reasoning and uses techniques from symbolic reasoning. By bringing together new and traditional Artificial Intelligence (AI) approaches, the A-BDI metamodel provides a formal and computational framework for human-level, neuro-symbolic, and hybrid AI. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.",
10.1007/s00354-024-00243-8,Neuro-Symbolic Reasoning for Multimodal Referring Expression Comprehension in HMI Systems,"Conventional Human–Machine Interaction (HMI) interfaces have predominantly relied on GUI and voice commands. However, natural human communication also consists of non-verbal communication, including hand gestures like pointing. Thus, recent works in HMI systems have tried to incorporate pointing gestures as an input, making significant progress in recognizing and integrating them with voice commands. However, existing approaches often treat these input modalities independently, limiting their capacity to handle complex multimodal instructions requiring intricate reasoning of language and gestures. On the other hand, multimodal tasks requiring complex reasoning are being challenged in the language and vision domain, but these typically do not include gestures like pointing. To bridge this gap, we explore one of the challenging multimodal tasks, called Referring Expression Comprehension (REC), within multimodal HMI systems incorporating pointing gestures. We present a virtual setup in which a robot shares an environment with a user and is tasked with identifying objects based on the user’s language and gestural instructions. Furthermore, to address this challenge, we propose a hybrid neuro-symbolic model combining deep learning’s versatility with symbolic reasoning’s interpretability. Our contributions include a challenging multimodal REC dataset for HMI systems, an interpretable neuro-symbolic model, and an assessment of its ability to generalize the reasoning to unseen environments, complemented by an in-depth qualitative analysis of the model’s inner workings. © The Author(s) 2024.",
10.1007/s10846-021-01480-5,A Hybrid Planning Approach for Accompanying Information-gathering in Plan Execution Monitoring,"Autonomous robots that execute plans in real-world environments may easily get failed due to unexpected environment dynamics. For robust plan execution, a great number of plan execution monitoring works has been proposed to estimate plan execution effects and make recovery plans for any detected plan failures. However, most works have assumed the full observability of environment states and accessibility of complete information about environment dynamics, which shows limitations when executing plans under environment dynamics and partial observability. To efficiently and effectively monitor robot plans in dynamic and partially observable environments, this paper first proposes an accompanying action policy that specifies an interaction pattern between information-gathering plan and the task plan to estimate and monitor task plan execution. To provide a concrete implementation of the above pattern, we first identify the task achievement and execution monitoring as two separated goals in a robot task, and then propose a hybrid planning approach that integrates two planners to solve the goals. For a task-achievement goal, we utilize a classical planning framework ROSPlan to efficiently compute the global task plan. While executing each action of the plan, we cast the execution monitoring problem as a Partially Observable Markov Decision Process (POMDP), which plans the information-gathering plans for monitors the action execution effects and recover failures when necessary. We further implement a typical robotic service task to verify the efficiency and effectiveness of our approach. By comparing with both the baseline plan-invariant execution monitoring approach and a full POMDP planning approach, the hybrid planning approach is efficient in task planning and execution monitoring and effectively recovering plan failures in unknown environments. © 2021, The Author(s), under exclusive licence to Springer Nature B.V.",
10.1007/s12369-024-01192-4,"A Hybrid Cognitive Architecture to Generate, Control, Plan, and Monitor Behaviors for Interactive Autonomous Robots","Interactive robots not only need to react in predefined or deterministic scenarios but also learn and adapt in real-time, mirroring cognitive flexibility akin to human intelligence. Achieving this autonomy entails developing cognitive architectures that integrate reactive, deliberative and emergent capabilities. Thus, this paper presents MERLIN2, a hybrid cognitive architecture to generate, control, plan, and monitor behaviors in autonomous robots. This architecture combines reactive, deliberative, and emergent components, aiming to enhance adaptability in dynamic environments and make intelligent real-time decisions, thereby improving autonomy and performance. MERLIN2 comprises a deliberative system, based on a knowledge base and a symbolic planner; and a behavioral system composed of reactive components and several emergent components. It addresses core cognitive aspects like action selection, perception, memory, learning, reasoning, and explainability. MERLIN2 is evaluated in a simulated world and in the real world Carry My Luggage task from the RoboCup@Home. Therefore, the experimentation presented in this article showcases the architecture as a valid solution for autonomous robots. © The Author(s) 2024.",
10.1007/s13748-025-00394-9,Synthesizing Evolving Symbolic Representations for Autonomous Systems,"This work presents a novel architecture for an open-ended learning system that integrates intrinsic motivation (IM) and classical planning to enable agents continuously learn and improve their knowledge over time in an unsupervised fashion. The main goal is to allow the agent to autonomously distill its experience into Probabilistic Planning Domain Definition Language (PPDDL) terms, thereby making causal relationships explicit and supporting automated planning. Starting with a virtually empty set of predefined tasks or goals, the agent harnesses intrinsic motivation to explore the environment autonomously, continuously using and enriching the high-level knowledge acquired through its experience in a virtuous cycle. Experimental evaluation in the Treasure Game domain demonstrates the effectiveness of the proposed approach: starting with only a small set of primitive actions, we show how an agent can autonomously build and refine a high-level representation of the environment. Planning-based strategies grounded in this representation significantly outperform uninformed exploration by reaching intermediate sub-goals more efficiently and substantially reducing the time required to achieve the final objective. © The Author(s) 2025.",
10.1016/j.artint.2024.104181,Planning with mental models – Balancing explanations and explicability,"Human-aware planning involves generating plans that are explicable, i.e. conform to user expectations, as well as providing explanations when such plans cannot be found. In this paper, we bring these two concepts together and show how an agent can achieve a trade-off between these two competing characteristics of a plan. To achieve this, we conceive a first-of-its-kind planner MEGA that can reason about the possibility of explaining a plan in the plan generation process itself. We will also explore how solutions to such problems can be expressed as “self-explaining plans” – and show how this representation allows us to leverage classical planning compilations of epistemic planning to reason about this trade-off at plan generation time without having to incur the computational burden of having to search in the space of differences between the agent model and the mental model of the human in the loop in order to come up with the optimal trade-off. We will illustrate these concepts in two well-known planning domains, as well as with a robot in a typical search and reconnaissance task. Human factor studies in the latter highlight the usefulness of the proposed approach. © 2024",
10.1016/j.is.2020.101639,A knowledge-intensive adaptive business process management framework,"Business process management has been the driving force of optimization and operational efficiency for companies until now, but the digitalization era we have been experiencing requires businesses to be agile and responsive as well. In order to be a part of this digital transformation, delivering new levels of automation-fueled agility through digitalization of BPM itself is required. However, the automation of BPM cannot be achieved by solely focusing on process space and classical planning techniques. It requires a holistic approach that also captures the social aspects of the business environment, such as corporate strategies, organization policies, negotiations, and cooperation. For this purpose, we combine BPM, knowledge-intensive systems and intelligent agent technologies, and yield one consolidated intelligent business process management framework, namely agileBPM, that governs the entire BPM life-cycle. Accordingly, agileBPM proposes a modeling methodology to semantically capture the business interests, enterprise environment and process space in accordance with the agent-oriented software engineering paradigm. The proposed agent-based process execution environment provides cognitive capabilities (such as goal-driven planning, norm compliance, knowledge-driven actions, and dynamic cooperation) on top of the developed business models to support knowledge workers’ multi-criteria decision making tasks. The context awareness and exception handling capabilities of the proposed approach have been presented with experimental studies. Through comparative evaluations, it is shown that agileBPM is the most comprehensive knowledge-intensive process management solution. © 2020",
10.1016/j.robot.2023.104415,A memory system of a robot cognitive architecture and its implementation in ArmarX,"Cognitive agents such as humans and robots perceive their environment through an abundance of sensors producing streams of data that need to be processed to generate intelligent behavior. A key question of cognition-enabled and AI-driven robotics is how to organize and manage such data and knowledge efficiently in a cognitive robot control architecture. We argue, that memory is a central active component of such architectures that mediates between semantic and sensorimotor representations, orchestrates the flow of data streams and events between different processes and provides the components of a cognitive architecture with data-driven services for learning semantics from sensorimotor data, the parametrization of symbolic plans for execution and prediction of action effects. Based on related work, and the experience gained in developing our ARMAR humanoid robot systems, we identified conceptual and technical requirements of a memory system as central component of cognitive robot control architecture that facilitate the realization of high-level cognitive abilities such as explaining, reasoning, prospection, simulation and augmentation. Conceptually, a memory should be active, support multi-modal data representations, associate knowledge, be introspective, and have an inherently episodic structure. Technically, the memory should support a distributed design, be access-efficient and capable of long-term data storage. We introduce the memory system for our cognitive robot control architecture and its implementation in the robot software framework ArmarX. We evaluate the efficiency of the memory system with respect to transfer speeds, compression, reproduction and prediction capabilities. © 2023",
10.1016/j.simpa.2023.100477,MERLIN2: MachinEd Ros 2 pLanINg[Formula presented],"Any service robot should be able to make decisions and schedule tasks to reach predefined goals such as opening a door or assisting users at home. However, these processes are not single short-term tasks anymore and it is required to set long-term skills for establishing a control architecture that allows robots to perform daily tasks. This paper presents MERLIN2, a hybrid cognitive architecture based on symbolic planning and state machine decision-making systems that allows performing robot behaviors. The architecture can run in any robot running ROS 2, the latest version of the Robot Operative System. MERLIN2 is available at https://github.com/MERLIN2-ARCH/merlin2. © 2023 The Author(s)",
10.1093/logcom/exad036,ECHO: A hierarchical combination of classical and multi-agent epistemic planning problems,"The continuous interest in Artificial Intelligence (AI) has brought, among other things, the development of several scenarios where multiple artificial entities interact with each other. As for all the other autonomous settings, these multi-agent systems require orchestration. This is, generally, achieved through techniques derived from the vast field of Automated Planning. Notably, arbitration in multi-agent domains is not only tasked with regulating how the agents act, but must also consider the interactions between the agents' information flows and must, therefore, reason on an epistemic level. This brings a substantial overhead that often diminishes the reasoning process's usability in real-world situations. To address this problem, we present ECHO, a hierarchical framework that embeds classical and multi-agent epistemic (epistemic, for brevity) planners in a single architecture. The idea is to combine (i) classical; and(ii) epistemic solvers to model efficiently the agents' interactions with the (i) 'physical world'; and(ii) information flows, respectively. In particular, the presented architecture starts by planning on the 'epistemic level', with a high level of abstraction, focusing only on the information flows. Then it refines the planning process, due to the classical planner, to fully characterize the interactions with the 'physical' world. To further optimize the solving process, we introduced the concept of macros in epistemic planning and enriched the 'classical' part of the domain with goal-networks. Finally, we evaluated our approach in an actual robotic environment showing that our architecture indeed reduces the overall computational time. © 2023 The Author(s). Published by Oxford University Press. All rights reserved.",
10.1109/ACCESS.2020.3003991,A Software Architecture for Service Robots Manipulating Objects in Human Environments,"This paper presents a software architecture for robots providing manipulation services autonomously in human environments. In an unstructured human environment, a service robot often needs to perform tasks even without human intervention and prior knowledge about tasks and environments. For autonomous execution of tasks, varied processes are necessary such as perceiving environments, representing knowledge, reasoning with the knowledge, and planning for task and motion. While developing each of the processes is important, integrating them into a working system for deployment is also important as a robotic system can bring tangible outcomes when it works in real world. However, such an architecture has been rarely realized in the literature owing to the difficulties of a full integration, deployment, understanding high-level goals without human interventions. In this work, we suggest a software architecture that integrates the components necessary to perform tasks by a real robot without human intervention. We show our architecture composed of deep learning based perception, symbolic reasoning, AI task planning, and geometric motion planning. We implement a deep neural network that produces information about the environment, which are then stored in a knowledge base. We implement a reasoner that processes the knowledge to use the result for task planning. We show our implementation of the symbolic task planner that generates a sequence of motion predicates. We implement an interface that computes geometric information necessary for motion planning to execute the symbolic task plans. We describe the deployment of the architecture through the result of lab tests and a public demonstration. The architecture is developed based on Robot Operating System (ROS) so compatible with any robot that is capable of object manipulation and mobile navigation running in ROS. We deploy the architecture to two different robot platforms to show the compatibility.",
10.1109/ACCESS.2020.3034524,Real-Time Object Navigation With Deep Neural Networks and Hierarchical Reinforcement Learning,"In the last years, deep learning and reinforcement learning methods have significantly improved mobile robots in such fields as perception, navigation, and planning. But there are still gaps in applying these methods to real robots due to the low computational efficiency of recent neural network architectures and their poor adaptability to robotic experiments' realities. In this article, we consider an important task in mobile robotics - navigation to an object using an RGB-D camera. We develop a new neural network framework for robot control that is fast and resistant to possible noise in sensors and actuators. We propose an original integration of semantic segmentation, mapping, localization, and reinforcement learning methods to improve the effectiveness of exploring the environment, finding the desired object, and quickly navigating to it. We created a new HISNav dataset based on the Habitat virtual environment, which allowed us to use simulation experiments to pre-train the model and then upload it to a real robot. Our architecture is adapted to work in a real-time environment and fully implements modern trends in this area.",
10.1109/ACCESS.2024.3406548,Business Process Automation in SMEs: A Systematic Literature Review,"Business Process Automation has been gaining increasing importance in the management of companies and organizations since it reduces the time needed to carry out routine tasks, freeing employees for other, more creative and exciting things. It can be applied in the most varied business areas. Organizations from any sector of activity can also adopt it. Given these benefits, the granted success in transforming business processes would be expected. However, automation initiatives still fail. Adopting this technology can raise social, technological, ethical, methodical, and organizational issues. These facts have triggered the necessity for a summary that could extract more information about how to implement Business Process Automation (BPA), attending to the administrative processes, especially when applied in Small and Medium-sized Enterprises (SMEs). This study aims not only to review the available literature on how to implement BPA but also to typify the processes that can be automated, which technologies or tools exist for making that change, and influence factors in the procedure of BPA. We have covered more than 300 research papers published between 2016 and 2023 in reputable scientific data sources like Scopus, Web of Science/Clarivate, and ScienceDirect/Elsevier. The review revealed some paths for BPA, with some common steps. In addition, some common process characteristics fundamental to automation are exposed, as well as factors that are critical to an organization for successful automation. The results indicate that BPA is an established area in Business Process Management related to technologies/tools like Robotic Process Automation (RPA) or Cognitive-Robotic Process Automation (C-RPA), Workflow Management Systems (WfMS), Enterprise Resource Planning (ERP), and Blockchain. As far as we observed, this Systematic Literature Review (SLR) is a unique study that covers all the environmental variables for applying automation in business processes.",
10.1109/ACCESS.2025.3583469,Knowledge-Based Planning for Human-Robot Collaborative Tasks,"Human-robot collaboration is a promising alternative to full automation and manual labour. Collaborative robots are considered safe and individual robot actions can often be easily programmed, for example, by physical hand-guiding. Coordinated collaboration, where tasks and the environment are shared, cannot be so easily achieved, due to continuously changing conditions and actions that need to be triggered at unknown instances. Besides, knowledge required for collaboration is difficult to program into robotic systems. This paper presents a system architecture that aims at facilitating human-robot collaboration by alleviating the need for pre-programmed information and exploring ways to teach new skills. This is done by reducing the amount of information required to program tasks by utilizing a knowledge base that represents knowledge on tasks, actions and the world. Automatic reasoning over conditions and properties of the knowledge is then utilized to generate available actions and action plans in order to complete the shared tasks. Moreover, learning new tasks is enabled by extending the original knowledge base, concatenating available actions and tasks into news bricks of knowledge. Two examples, a kitting task and a handover task, serve to validate the system architecture and exemplify its usage. Experiments demonstrate that by combining reasoning methods and knowledge-based planning, high-level shared tasks can be generated and executed, and robots can act reliable as teammate to human operators.",
10.1109/ACCESS.2025.3598864,A Digital Twin-Empowered Framework for Interactive Consumers in Manufacturing Using Wearable Device,"In the cyber-physical world, human-robot interaction (HRI) plays an increasingly important role in digital twin (DT)-enabled development, particularly in smart manufacturing. This investigation introduces a novel DT-based robotic framework for HRI (DTbRF-HRI), aiming to further productivity, automation, and safety. Our framework includes major elements such as real-time data communication, a common digital model, and a simulation environment for obstacle avoidance and autonomous manipulation. One contribution of our works is the application of an enhanced A-star algorithm for motion planning to support fast generation of paths and avoiding collisions. The data exchange between the physical and virtual agent is supported through system architecture and communication protocols, which meet with being very fast. The resulting framework is validated using numerical simulation and physical experiments in a common electronic consumer manufacturing scenario. Findings demonstrate the effectiveness, robustness, and practicability of DTbRF-HRI in improving intelligent robotic process in a cyber-physical system.",
10.1109/ACCESS.2025.3603738,An Adaptive Human–Robot Interaction Framework Using Real-Time Emotion Recognition and Context-Aware Task Planning,"Existing approaches often operate poorly in noisy or occluded conditions, rely on cloud-based inference subject to latency and privacy issues, and do not take emotional context into consideration while planning for a task. This research introduces the Emotion–Context Reinforced Planner, a novel human–robot interaction framework designed to deliver emotionally and contextually adaptive behaviors in real-time. The objective is to enhance social coherence and responsiveness while enabling intelligent action sequencing on low-power robotic platforms. The framework utilizes a multimodal emotion recognition system that relies on a confidence-weighted estimate of how facial and vocal features should be fused, a context encoder, and a reinforcement learning policy based on a Double Deep Q-Network. The framework’s architecture was engineered to be readily deployed on low-power embedded systems (Jetson Nano, Raspberry Pi 4) and evaluated via TensorRT quantization and kernel fusion. Experimental evaluations reveal a 92.1% F1-score in emotion classification, 94.2% task-switching accuracy, and 34.8 ms response latency outperforming state-of-the-art models including CLEF and Pepper-based multimodal planners. Performance in real-time was achieved with up to 30 FPS on edge devices. A user satisfaction rating of 4.4/5 indicates strong perceived coherence and empathy in social interaction scenarios. ECRP offers a robust, scalable, and socially coherent solution for real-time human–robot interaction, outperforming existing methods both in accuracy and latency. Its fusion of emotional understanding and adaptive task planning significantly improves human engagement, making it suitable for use in elderly care, education, and customer service domains.",
10.1109/ACCESS.2025.3610890,UnifiedKP: A Unified Network Knowledge Plane for Large Model-Enabled 6G Networks,"The emergence of large language models (LLMs) and agentic systems is revolutionizing the landscape of 6G networks by enabling unprecedented levels of autonomous intelligence, including self-configuration, self-optimization, and self-healing capabilities. However, current implementations face significant challenges. Individual intelligence tasks require isolated knowledge retrieval pipelines. This isolation results in redundant data flows, inconsistent interpretations, and increased operational complexity. Inspired by the service model unification efforts in Open-RAN that promote interoperability and vendor diversity, we propose UnifiedKP: a unified Network Knowledge Plane specifically designed for large model-enabled autonomous 6G network intelligence. By decoupling network knowledge acquisition and management from intelligence logic, UnifiedKP streamlines development workflows and significantly reduces maintenance complexity for intelligence engineers. Through an intuitive and consistent knowledge interface, UnifiedKP enhances interoperability for network intelligence agents while maintaining semantic consistency across diverse intelligence tasks. We demonstrate the effectiveness of UnifiedKP through two representative intelligence applications: live network knowledge question-answering and edge AI service orchestration. Experimental results show that UnifiedKP reduces knowledge retrieval latency by 47%, improves knowledge consistency by 82%, and decreases development complexity by 65% compared to traditional isolated approaches. Our framework achieves 94.3% accuracy in network anomaly detection and reduces service orchestration time by 38% in dynamic edge computing environments. These findings establish UnifiedKP as a foundational architecture for realizing truly autonomous and intelligent 6G networks.",
10.1109/ACCESS.2025.3612015,Agentic Reasoning for Social Event Extrapolation: Integrating Knowledge Graphs and Language Models,"Accurate prediction of socio-political events is a longstanding challenge with profound implications for risk management, policy planning, and international relations. Traditional machine learning approaches, such as graph neural networks and recurrent neural networks, have achieved notable progress but often struggle to integrate rich textual context and provide interpretable reasoning. Recent advances in large language models (LLMs) have demonstrated unprecedented capabilities across diverse tasks, including text generation, code synthesis, and complex multimodal reasoning, making them promising candidates for event prediction in dynamic, data-rich environments. This research presents an agentic reasoning framework combining temporal knowledge graphs, large language models (LLMs), and a modular tool-based architecture to address event extrapolation in complex, real-world settings. The methodology integrates agent-based reasoning, iterative tool invocation, and explicit validation mechanisms to ensure logical consistency and transparency in predictions. Experiments on country-specific subsets of the POLECAT dataset employ multiple LLM architectures and multiple evaluation metrics, including Hit@k, MRR, F1-scores and Prediction Entropy. Comparative analyses demonstrate that the agentic framework achieves robust predictive performance and interpretability, complementing fine-tuned LLM baselines. Furthermore, the ethical implications of deploying AI in social computing are addressed, including bias, transparency, and accountability. This study advances event prediction by demonstrating how agentic LLMs, equipped with explicit reasoning and validation, provide scalable and ethically grounded solutions for complex social event extrapolation.",
10.1109/ACCESS.2025.3630344,Cognitive Architectures in Autonomous Robotics: A Systematic Review of Behavior Generation Approaches and Evaluation Strategies,"Cognitive architectures are an essential component in the development of intelligent autonomous robots, enabling planning, learning, and adaptation to dynamic environments. This paper presents a systematic review of the literature focused on cognitive architectures applied to behavior generation in autonomous robotics. A structured search and selection process was conducted using multiple scientific databases, applying explicit inclusion, exclusion, and quality assessment criteria. From an initial set of 502 studies, 22 publications (2018–mid-2025) were selected for in-depth analysis. The review identifies a growing trend toward hybrid architectures that integrate symbolic reasoning with data-driven methods, such as neural networks and behavior trees. The types of architectures, tools used (such as symbolic planners, neural networks, and behavior trees), middleware employed (with a predominance of Robot Operating System), as well as the methods and metrics used in their evaluation, are analyzed. This review provides a detailed overview of the state of the art and highlights the technologies and approaches currently most widely used in the design of cognitive robotic systems.",
10.1109/ACSOS-C52956.2021.00066,BDI-Dojo: developing robust BDI agents in evolving adversarial environments,"The Belief-Desire-Intention (BDI) architecture is a widely-used model for developing multi-agent systems. BDI agents pursue their goals over time using a collection of plan recipes that are programmed by the developers. Thus, traditional BDI agents are limited in dealing with dynamic environments where uncertainties are not known beforehand, such as those introduced by adversarial forces. In this paper, we present the BDI-Dojo framework for developing robust BDI agents by training them using reinforcement learning against similarly learning-equipped adversarial agents. This adversarial training approach empowers BDI agents to become more resilient in uncertain, dynamic environments.",
10.1109/ACSOS61780.2024.00018,ReBeT: Architecture-based Self-adaptation of Robotic Systems through Behavior Trees,"Robotics software needs to be self-adaptive. Self-adaptation in robotics can, among others, take the form of changing a robot’s task plan or its software architecture at runtime. The latter has shown to be effective in satisfying quality requirements such as minimizing energy consumption and operating safely. However, most self-adaptive robotic systems perform architecture-based self-adaptation to meet the functional goal of completing an assigned mission. Additionally, the mechanisms to accomplish architectural adaptations are mostly adhoc and not oriented towards reuse. We in turn investigate how quality requirements and architecture-based self-adaptation can be facilitated in robotics software while integrating into existing practices to promote practitioners’ adoption and reuse. To this end, we design and implement an extension to the Behavior Trees (BTs) task plan formalism which introduces an explicit consideration of quality requirements. Additionally, we implement a general architectural adaptation layer for ROS2 systems and an extension to BTs which showcases its utilization. Finally, we perform quantitative experiments to evaluate the effectiveness of our approach in satisfying quality requirements via architectural adaptation on a mobile terrestrial robot. We find our approach to be an effective means to address a variety of self-adaptation scenarios within the mission of the system.",
10.1109/AERO50100.2021.9438257,Autonomous Robot Planning System for In-Space Assembly of Reconfigurable Structures,"Large-scale space structures, such as telescopes or spacecrafts, require suitable in-situ assembly technologies in order to overcome the limitations on payload size and mass of current launch vehicles. In many application scenarios, manual assembly by astronauts is either highly cost-inefficient or not feasible at all due to orbital constraints. However, (semi-) autonomous robotic assembly systems may provide the means to construct larger structures in space in the near future. Modularity is a key concept for such structures, and also for reducing costs in novel spacecraft designs. The advantage of the modular approach lies in the capability to generate a high number of unique assets from a reduced number of building blocks. Thus, spacecrafts can be easily adapted to particular use cases, and could even be reconfigured during their lifetime using a robotic manipulation system. These ideas lie at the core of our current EU project MOSAR (MOdular Spacecraft Assembly and Reconfiguration). Teleoperating a space robotic system from Earth to assemble a modular structure is not straightforward. Major difficulties are related to time delays, communication losses, limited control modalities, and low immersion for the operator. Autonomous robotic operations are then preferred, and with this goal we propose a fully autonomous system for planning in-space assembly tasks. Our system is able to generate assembly and reconfiguration plans for modular structures in terms of high-level actions that can autonomously be executed by a robot. Through multiple simulation layers, the system automatically verifies the feasibility and correctness of action sequences created by the planner. The layers implement different levels of abstraction, hierarchically stacked to detect infeasible transitions and initiate replanning at an early stage. Levels of abstraction increase in complexity, ranging from a basic geometric description of the spacecraft, over kinematics of the robotic setup, to full representations of the actions. The system reuses information from failed checks in all layers to avoid similar situations during replanning. We use a hybrid approach where symbolic reasoning is combined with considerations of physical constraints to generate a holistic sequence of actions. We demonstrate our planner for large space structures in a simulation environment. In particular, we consider the reconfiguration of a given modular structure, i.e. disassemble parts and reassemble them in a new configuration. The adaptability of our planning system is shown by executing the assembly plans on robots with different sets of skills and in scenarios with simulated hardware failures.",
10.1109/AERO50100.2021.9438399,Hybrid Planning System for In-Space Robotic Assembly of Telescopes using Segmented Mirror Tiles,"The use of large telescopes is increasingly important in the field of astronomy. However, for larger telescopes there is a technological limit for producing primary mirrors made of a single rigid piece. A similar problem arises for space-based telescopes, where the cargo areas of launch vehicles provide an upper limit for the maximum aperture of the telescope, even if it is deployable as the James Webb Space Telescope. As larger telescopes are required, in-space assembly emerges as a feasible alternative, making use of a highly autonomous robotic system that directly constructs the structure on orbit. Although this might reduce the overall costs of construction and maintenance of the structures, such robotization brings additional challenges for an automatic planning system. This paper presents the study and implementation of an autonomous assembly planner for in-space robotic assembly of telescopes using segmented mirror tiles. The proposed planner takes into consideration different constraints. On the one hand, robot physical constraints such as joint position and torque limits, and moments of inertia of the sub-assemblies must be considered. On the other hand, semantic constraints representing the possible types of connections between tiles must be specified to ensure the mechanical stability and electric and data connectivity within the structure. In order to generate a plan that considers these constraints, we propose a hybrid assembly planner with a global and a local layer. The global layer uses graph search strategies to explore a graph representation of possible assembly sequences, ensuring that the potential solutions fulfill all the semantic constraints describing the allowed connections between tiles. The local layer uses a constrained path planning algorithm combined with a dynamic simulation to ensure that the transitions between states (representing sub-assemblies) fulfill the required physical constraints. The final assembly sequence to be executed is selected by minimizing a suitable cost function. The planner is integrated into a ground-based demonstrator for autonomous robotic assembly of mirror tiles, developed within the PULSAR EU Project. Simulations for larger telescope structures demonstrate the generality of the approach. In order to illustrate the flexibility of the planner, different physical constraints and optimization goals were implemented and verified. The planner successfully adapts the assembly plan accordingly.",
10.1109/AERO50100.2021.9438470,FRESCO: A Framework for Spacecraft Systems Autonomy,"Achieving the science exploration and defense goals of the following decades will require flight systems capable of operations with limited operator contact, system mode changes and retasking based on sensor data, and complex robotic operations. To support these capabilities, increasingly autonomous flight systems are required that can perform dedicated mission functions, e.g. payload targeting and communications, and system-level functions, e.g. planning and goal monitoring. Architecting an autonomous system requires a well-reasoned, self-consistent framework to avoid ad hoc design choices that will introduce complexity and risk. The Framework for Robust Execution and Scheduling of Commands On-Board, FRESCO, is the result of lessons learned in developing a software architecture to enable autonomous solar system exploration. FRESCO generalizes this work to offer a modular, software-agnostic approach to developing verifiable architecture for autonomous space systems. FRESCO specifies guiding principles, functions, interfaces, and interactions from which mission-specific autonomous control architectures can be derived. FRESCO is a principled framework relying on explicit, state-based goal definitions, centralized management of state knowledge, clearly separated control boundaries, and hierarchical reasoning. Using components from FRESCO reference architecture, an autonomous decision-making architecture can be designed for spacecraft which can then be mapped to flight software architecture. FRESCO is flexibly defined to enable autonomous control of flight systems built using extensive software and hardware heritage. Finally, FRESCO-derived architectures support a spectrum of operator/spacecraft interactions, ranging from traditional commanding to goal-driven commanding with the ability to change mission goals autonomously. FRESCO has been used in defining the autonomy architectures for the ASTERIA mission and have been demonstrated in laboratory and software simulation for small body rendezvous and in-space servicing missions.",
10.1109/AERO58975.2024.10521103,Collaborative Moonwalkers,"We present the results of an advanced concept research for a collective of robotic rovers named Moonwalkers that implement bio-inspired motivations, distributed intelligence, and integrated deep learning techniques to demonstrate autonomous cooperative goal-directed lunar exploration with minimum human interventions. By borrowing concepts from biology, the Moonwalker rovers are driven by a set of balanced motivations (ex. Energy, safety, operating temperature, achievements, respect) to accomplish mission goals while maintaining safety from potential dangers. Drawing from contemporary neuroscience and computer science research, the Moonwalker rovers are equipped with system 1 (low-level) and system 2 (high-level) cognitive functions based on a two-level memory architecture utilizing a pre-trained multi-modal model in conjunction with a graph knowledgebase, which leverages knowledge graph embeddings. This neuro-symbolic approach enables the rovers to learn from and be guided by human knowledge, facilitating zero-shot learning, collaborative planning, and reasoning like human explorers under uncertain conditions. We also describe the construction of a virtual simulation environment with high-fidelity visualizations and prototype rover agents. By addressing selected problems, we demonstrate that physics informed machine learning can enhance the effectiveness of the virtual lunar test environment.",
10.1109/AERO58975.2024.10521154,METIS: An AI Assistant Enabling Autonomous Spacecraft Operations for Human Exploration Missions,"Today, human space exploration faces persistent and new challenges. Most prominently limited crew size, limits on crew time and utilization, as well as the costs of 24/7/365 operations are the main drivers for innovations towards increased autonomy. Furthermore, in the future, when considering destinations beyond lunar orbit, signal delay simply prevents the conventional operational concept of real-time monitoring and control for crewed missions. To overcome those challenges, this paper will introduce METIS, the Mars Exploration Telemetry-driven Information System. METIS is a novel intelligent assistant enabling autonomous operations of crewed spacecraft based on artificial intelligence (AI) and machine learning (ML). METIS is currently being developed at the Columbus Control-Center (Col-CC), which is part of the German Space Operations Center (GSOC). On behalf of the European Space Agency (ESA), Col-CC is responsible for the operation of the Columbus module of the International Space Station (ISS). Columbus was launched on February 7, 2008, docked to the ISS a few days later on February 11 and has been a part of the ISS since then. It is the basis on which METIS is developed. The assistant is designed after John L. Boyds OODA (Observe-Orient-Decide-Act) loop for human decision making, where each function in the model is developed as an individual computerized agent. This paper will introduce the high-level system architecture of this multi-agent-system (MAS), as well as human interaction embedded in the system. Furthermore, we will show each of the agents in greater detail, their functions and the interaction between the agents. Since some agents rely on machine learning (ML) from the field of artificial intelligence (AI) we use multiple data sources from the Columbus module, including but not limited to on-board telemetry, operational data files (ODFs, i.e. procedures), and anomaly reports, to train and test the system. We will highlight how these data sources are brought together and the database we deploy to enable access to the data in a machine-readable format. Since METIS is intended to be used by both ground personnel, as well as on-board crew, we will show how METIS is planned to be utilized within Col-CC and on-board. For this we envision a step-wise approach, where METIS is first used and tested in conjunction with the Columbus simulator to perform certain ground and on-board activities and react to a set of known anomalies. In this first step ground controllers will still be heavily involved in development, to identify areas that need further improvements and further increase the capabilities of the system. This work represents a significant step towards full crew autonomy by supporting quick and reliable decision making in the highly dynamic environment that is human space exploration. AI/ML enabled solutions to new and old challenges have the potential to revolutionize the space sector and METIS represents one possible contribution to make space more accessible to humans, increase system reliability, reduce cost of operations and help prepare for deep space exploration beyond lunar orbit.",
10.1109/AERO58975.2024.10521425,Multi-Agent Autonomy for Space Exploration on the CADRE Lunar Technology Demonstration,"CADRE (Cooperative Autonomous Distributed Robotic Exploration) is a lunar technology demonstration mission of multi-agent autonomy on a team of three rovers and a base station. The mission is slated land at the Moon’s Reiner Gamma region as a CLPS (Commercial Lunar Payload Services) pay-load on the IM-3 mission in 2024. The goal of CADRE is to demonstrate how a team of autonomous rovers, receiving only high-level tasks from Earth, can autonomously explore a region of the Lunar surface, as well as perform a distributed measurement in coordination with a multi-static ground-penetrating radar. We envision that multi-agent autonomy will enable future missions to address hitherto-unanswered questions in planetary science on the Moon, Mars, and beyond. In this paper, we describe the autonomy architecture developed for CADRE, both for multi-agent coordination, and for single-agent driving surface mobility, and discuss the requirements and constraints that led to the selection of this architecture.",
10.1109/AI2E64943.2025.10983871,The Museum Guide Robot: Enhancing Visitor Experience Through Autonomous Robotics,"This paper presents the design, implementation, and evaluation of the Museum Guide Robot (MGR), an autonomous robotic system aimed at enhancing visitor experiences in museum environments. Driven by advancements in artificial intelligence (AI) and robotics, the MGR integrates sophisticated navigation and interaction technologies to facilitate personalized museum tours. Employing a combination of mechanical design features, including a lightweight chassis and Mecanum wheels for omnidirectional movement, the robot effectively navigates crowded spaces while maintaining stability and performance. Its electronic architecture incorporates motor drivers, cameras, LiDAR sensors to ensure precise navigation, obstacle avoidance, and screen with a real-time interface to interact with visitors. The system operates on the Robot Operating System (ROS), which supports modular development, enabling efficient integration of various functionalities, such as path planning and natural language processing. Simulation results demonstrate the MGR's high navigation accuracy and effective user interaction, while real-world testing highlights its potential to enrich the museum experience.",
10.1109/AIM43001.2020.9158905,Robotic Wire Pinning for Wire Harness Assembly Automation,"An integrated robotic system is presented that demonstrates feasibility of automating dexterous manipulation of small and flexible components enabling wire pinning associated with industrial wire harness assembly. The task is shared by a human technician and a collaborative robot endowed with advanced intelligence via learned motion primitives and vision-guided control. The developed system and software architecture are described along with features of its primary software modules that provide the enabling robotic intelligence and control including robot manipulation skills, dynamic motion planning, and perception. The first prototype system achieves cycle times comparable to fully manual assembly with high-performing trajectory learning-from-demonstration and vision-guided manipulation as underlying intelligent capabilities. Performance results and thoughts on improvements through future work are presented.",
10.1109/AIM55361.2024.10636988,Hybrid-AI Grasp Planning System that Integrates Rule-Based and DNN-Based Methods for Throughput Improvement of Picking Robots,"In the logistics field, due to the declining birthrate, aging population, and shrinking workforce, there is growing demand for automation of manual handling tasks. Focusing on robotic picking operations, we developed two grasping methods for various items: rule-based grasp planning that considers the physical characteristics of the items and environment, and DNN-based grasp planning that can learn the grasping points obtained by the same method. Rule-based grasp planning is computationally time-consuming, and DNN-based grasp planning has a lower success rate. Therefore, this paper proposes hybrid-AI grasp planning that integrates these grasp planning methods. We effectively demonstrated that selecting an appropriate grasp planning method by the developed selector can improve throughput because it can combine a high success rate with fast calculation time.",
10.1109/AISTS66100.2025.11232814,Agentic AI: A Paradigm Shift in Autonomous Decision-Making and Intelligent Systems,"In this work, we offer a broad survey, and an original hybrid model for Agentic AI intelligent systems that reason, plan, and act with little human guidance. It investigates the intersection between reinforcement learning, symbolic reasoning, long term memory architectures and explainable AI to build scaled out intelligent systems that are transparent and adaptive. Comparison between Generative AI and Agentic AI is presented to pinpoint the main differences in the exploration of decision-making, memory learning, interactivity, and collaboration. The paper identifies key gaps including lack of explainability and scalability challenges and outlines future research directions such as blockchain-based solutions, federated learning, and ethical governance for trustworthy agentic systems.",
10.1109/BCCA66705.2025.11229637,A Framework for Embedding Generative and Agentic AI in Open Source Intelligence,"Open Source Intelligence (OSINT) plays a critical role in cybersecurity and threat intelligence. However, traditional methods are slow, manual, and difficult to scale. Although Large Language Models (LLMs) and Generative AI have been explored for OSINT, most existing approaches apply them to isolated tasks without developing an integrated and autonomous architecture. This paper proposes a novel Agentic AI-driven OSINT framework that enables autonomous information gathering, reasoning, and tool orchestration across heterogeneous open-source data streams. The system uses retrieval-augmented generation (RAG), chain-of-thought reasoning, and adaptive agent planning to determine which tools to invoke, how to process intermediate outputs, and when to escalate findings for human review. The proposed architecture includes modules for multi-source data ingestion, LLM-powered analysis, generative scenario simulation, and ethical safeguard enforcement. A proof-of-concept use case involving the location of missing persons from public data demonstrates how the framework improves coverage, accuracy, and decision speed when compared to conventional OSINT workflows. This work introduces the first unified and reproducible design for an Agentic AI OSINT system that incorporates transparency, accountability, and ethical compliance into its operational core.",
10.1109/BIBM62325.2024.10822109,ArgMed-Agents: Explainable Clinical Decision Reasoning with LLM Disscusion via Argumentation Schemes,"There are two main barriers to using large language models (LLMs) in clinical reasoning. Firstly, while LLMs exhibit significant promise in Natural Language Processing (NLP) tasks, their performance in complex reasoning and planning falls short of expectations. Secondly, LLMs use uninterpretable methods to make clinical decisions that are fundamentally different from the clinician’s cognitive processes. This leads to user distrust. In this paper, we present a multi-agent framework called ArgMed-Agents, which aims to enable LLM-based agents to make explainable clinical decision reasoning through interaction. ArgMed-Agents performs self-argumentation iterations via Argumentation Scheme for Clinical Discussion (a reasoning mechanism for modeling cognitive processes in clinical reasoning), and then constructs the argumentation process as a directed graph representing conflicting relationships. Ultimately, use symbolic solver to identify a series of rational and coherent arguments to support decision. We construct a formal model of ArgMed-Agents and present conjectures for theoretical guarantees. ArgMed-Agents enables LLMs to mimic the process of clinical argumentative reasoning by generating explanations of reasoning in a self-directed manner. The setup experiments show that ArgMed-Agents not only improves accuracy in complex clinical decision reasoning problems compared to other prompt methods, but more importantly, it provides users with decision explanations that increase their confidence.",
10.1109/BIBM62325.2024.10822186,MedGen: An Explainable Multi-Agent Architecture for Clinical Decision Support through Multisource Knowledge Fusion,"Agents in medical decision support have been extensively researched, particularly in areas like evidence support, multimorbidity management, and patient-specific needs. However, current approaches lack a unified method to address real-time evidence updates, manage multiple diseases independently, and incorporate personalized patient needs. Existing Large Language Model (LLM) agents are limited by their reliance on static knowledge bases, hindering their ability to promptly update clinical guidelines and meet diverse patient requirements. Moreover, the interpretability of LLMs remains a significant concern, leading to skepticism in their medical application. To address these challenges, we developed MedGen, a multi-agent architecture that decomposes the clinical decision-making process into stages such as clinical goal setting, data collection, argumentation linking, and plan selection. This structured approach allows LLM agents to provide both reasoning evidence and a transparent reasoning process, enhancing the reliability and interpretability of outcomes. Finally, a case study of breast cancer and depression is combined to illustrate our architecture.",
10.1109/CACRE66141.2025.11119567,Enhanced Human-Robot Interaction for Robotic Container Unloading Systems Utilizing Digital Cousin and LLM,"Existing robotic container unloading systems lack the adaptability and semantic reasoning required for robust performance due to dynamic environments and unstructured cargo arrangements. This paper proposes a novel LLM and Digital Cousins-driven robotic automation system to address these limitations. By leveraging the DeepSeek-V3LLM (large language model), the system integrates contextual understanding, real-time decision-making, and adaptive grasping strategies to handle irregular or occluded objects. A hybrid architecture synergizes LLM-based high-level planning with low-level robotic control, while a synchronized digital cousin framework ensures real-time physical-virtual synchronization. The digital cousin technique constructs semantically consistent virtual scenes from single RGB images using a 3D asset library, enabling cost-effective, automated synthesis while preserving core geometric and functional attributes. Experimental results demonstrate significant improvements in operational efficiency and robustness compared to conventional methods. This work bridges AI-driven cognitive capabilities with industrial robotics, offering a scalable and intelligent solution for autonomous logistics.",
10.1109/CASE58245.2025.11163777,Intelligent Indoor Navigation for Home Robots based on Large Language Models,"Natural language understanding is crucial for home robots to help people in their daily lives. However, existing home robots mainly rely on keyword matching to understand explicit commands, while struggling with understanding human instructions expressed more implicitly and naturally. Recently, large language models (LLMs) have demonstrated great potential in human language understanding. In this paper, we explore the application of LLM in home robots with a focus on navigation, one of the core capabilities in mobile robots. First, we designed and implemented an LLM-assisted robot navigation framework which adopts a modular architecture to integrate human-robot interaction, semantic mapping, and motion planning, thereby enhancing scalability and deployment flexibility. Second, we established a systematic method and benchmarks to evaluate the performance of LLMs in robot navigation applications, quantifying the performance differences between cloud-based and local LLM models. Finally, we conducted experiments on a custom-designed mobile robot in a real apartment setting. Our findings provide practical insight in selecting and optimizing LLMs for robotic applications.",
10.1109/CASE58245.2025.11163830,Embodied Intelligence in Disassembly: Multimodal Perception Cross-valiation and Continual Learning in Neuro-Symbolic TAMP,"With the rapid development of the new energy vehicle industry, the efficient disassembly and recycling of power batteries have become a critical challenge for the circular economy. In current unstructured disassembly scenarios, the dynamic nature of the environment severely limits the robustness of robotic perception, posing a significant barrier to autonomous disassembly in industrial applications. This paper proposes a continual learning framework based on Neuro-Symbolic task and motion planning (TAMP) to enhance the adaptability of embodied intelligence systems in dynamic environments. Our approach integrates a multimodal perception cross-validation mechanism into a bidirectional reasoning flow: the forward working flow dynamically refines and optimizes action strategies, while the backward learning flow autonomously collects effective data from historical task executions to facilitate continual system learning, enabling self-optimization. Experimental results show that the proposed framework improves the task success rate in dynamic disassembly scenarios from 81.9% to 100%, while reducing the average number of perception misjudgments from 3.389 to 1.128. This research provides a new paradigm for enhancing the robustness and adaptability of embodied intelligence in complex industrial environments.",
10.1109/CASE58245.2025.11164082,Knowledge Driven Robotics (KDR),"This paper presents a software architecture that enables practical deployment of robotic systems in roles that require the execution of tasks not well-defined at design time. The paradigm employed is a maximization of reuse, generalization, and interoperability of logical structures and robot tasks which can readily be composited, supporting a robust and flexible autonomy stack. The Knowledge Driven Robotics (KDR) software architecture achieves this by offering a unique set of interactions between symbolic planning, Behavior Trees, and database information. New composite tasks can readily be composed of highly parameterized atomic tasks to manipulate known classes of task objects. Key contributions include the ability of the behavior layer to query, transform, and utilize data in a flexible manner and to act as data management systems during execution, as well as surrounding infrastructure enabling the treatment of data as a first-class citizen.",
10.1109/CASE58245.2025.11164085,Self-Coordinating Multi-AGV Scheduling in Self-Organizing Manufacturing Shop Floor via Multi-Agent Reinforcement Learning,"With the increasing automation and digitalization of cognitive manufacturing systems (CMS), efficient scheduling of automated guided vehicles (AGVs), which is an integral component of CMS, has become crucial for achieving high operational efficiency. Traditional rule-based and centralized control methods struggle to adapt to dynamic and uncertain shop floor environments. To address these challenges, a novel multi-agent reinforcement learning (MARL) to optimize AGV coordination in next-generation self-organizing manufacturing systems. Our method jointly coordinates order dispatching and path planning to achieve cost-effective and timely material delivery. The proposed MARL framework consists of three key components: the Order Dispatching Attention Network (ODAN), the Path Planning-Repositioning Dual-Action Network (PPRDAN), and the Centralized Value Network (CVN). Experimental results in grid-based manufacturing scenarios demonstrate significant improvements in on-time delivery rate, total travel distance, and waiting time compared to baseline models. This study highlights the potential of MARL for enhancing AGV coordination in intelligent manufacturing environments.",
10.1109/CASE59546.2024.10711577,Cognitive Programming Interface : from Task Level Programming to Coherent Task Level Programming,"One of the main barriers to the uptake of robotics in industry is the cost of integration. For small and medium-sized enterprises with small production runs and frequent changes to their robotic cells, the cost of integration and programming is too high an investment. To tackle this problem, a number of techniques exist in the literature to perform Task-Level-Programming.However most provide a set of tasks without defining, or in a very limited way, their context of use and their effects on the robot’s environment. As a result, users need to master a wide range of skills and the context in which they can be used.In this paper, we propose a different approach considering object’s interfaces level instead of object level, to allow the user to perform Coherent Task Level Programming where available skills/tasks are context dependent. We describe a Cognitive Programming Interface based on a multimodal planner relying on semantic reasoning that allows two programming modalities: programming by selecting a feasible skill according to the context, or programming by demonstration. These two methods are complementary and can be used in the same programming sequence if required. They rely on an ontological skill definition that replaces the classical Planning Domain Definition Language approach. Consequently, we propose a new method to recognize demonstrated skills from demonstration.",
10.1109/CogSIMA64436.2025.11079504,Innate-Values-Driven Reinforcement Learning Based Cooperative Multi-Agent Cognitive Modeling,"In multi-agent systems (MAS), the dynamic interaction among multiple decision-makers is driven by their innate values, affecting the environment's state, and can cause specific behavioral patterns to emerge. On the other hand, innate values in cognitive modeling reflect individual interests and preferences for specific tasks and drive them to develop diverse skills and plans, satisfying their various needs and achieving common goals in cooperation. Therefore, building the awareness of AI agents to balance the group utilities and system costs and meet group members' needs in their cooperation is a crucial problem for individuals learning to support their community and even integrate into human society in the long term. However, the current MAS reinforcement learning domain lacks a general intrinsic model to describe agents' dynamic motivation for decision-making and learning from an individual needs perspective in their cooperation. To address the gap, this paper proposes a general MAS innate-values reinforcement learning (IVRL) architecture from the individual preferences angle. We tested the Multi-Agent IVRL Actor-Critic Model in different StarCraft Multi-Agent Challenge (SMAC) settings, which demonstrated its potential to organize the group's behaviours to achieve better performance.",
10.1109/COMCONF63340.2024.00024,Emergent Intelligence Platform for Developing Autonomous Resource Management Systems,"The paper introduces new platform for developing autonomous resource management systems to increase adaptability and efficiency of enterprises. One of the perspective new classes of Enterprise 5.0 systems is Autonomous Resource Management Systems (ARMS), based on models, methods and algorithms for collective decision-making, ontologies and multi-agent technologies. The platform is based on the concept of Emergent Intelligence (EI), inspired by theory of complex adaptive systems, based on self-organization processes with non-equilibrium thermodynamics. The fundamentals, functionality and architecture of the developed EI platform are discussed. The core functionality of ARMS is to make adaptive resources allocation, planning and optimization, combined with monitoring and control of resources in real time. The core components of EI platform support formalization of domain knowledge and collective decision making of collaborative software and hardware robots for real time scheduling, optimization and controlling of resources. As an example the Super-EI system is considered for managing driverless trucks for Moscow-Saint Petersburg cargo delivery. The ARMS allows to automate routine work on resource management, transfering routine work from managers, dispatchers, economists and logisticians to the ARMS to improve business adaptability and efficiency.",
10.1109/COMPSAC61105.2024.00013,Verifying Multi -Agent Coordination Correctness for BDI Agents,"The popular Belief-Desire-Intention (BDI) architecture structures agents' behavior around beliefs, desires, and intentions, enabling effective pursuit of collective objectives and optimal system performance. Many complex situations require agent developers to design a coordination model/plan involving multiple BDI agents working together to achieve a given goal. However, a semantic notion of state has been missing in most current accounts of BDI agent execution, making it impossible to assess at design time if a coordination model/plan is able to achieve the goal. Thus, in this paper, we introduce a framework that permits us to identify the state that accrues at any point in agent execution. This enables us to determine, at design time, if a multi-agent coordination model/plan accomplishes a given goal. Our framework facilitates the verification of coordination correctness in such complex multi-agent systems.",
10.1109/CONECCT62155.2024.10677317,Embodied Reasoning with Self-Feedback,"Large Language Models (LLMs) based on Transformer architecture have achieved remarkable success in Natural Language Processing (NLP). However, translating open-ended instructions into granular action plans for robotic systems remains a challenge. This paper proposes a self-supervised learning framework that enables an embodied multi-modal agent to comprehensively understand and perform tasks based on complex natural language interactions. The methodology focuses on an agentic workflow and self-refinement process, where the LLM actively engages in the task-solving process by generating its own problems, decomposing them, and refining the solutions through iterative self-feedback. The proposed methodology is evaluated on a maze navigation task, where an agent must extract sub-tasks from natural language instructions and navigate a grid while satisfying constraints. Experimental results demonstrate the effectiveness of the proposed approach in solving problems with multiple sub-tasks. Such capabilities could transform human-computer interaction and automated decision support.",
10.1109/CSCN67557.2025.11230734,Toward Intelligent Bandwidth Prioritization in Distributed 6G ISAC: An Agentic AI Perspective,"Integrated Sensing and Communication (ISAC) is a cornerstone of sixth-generation (6G) networks that is designed to offer situational awareness in real-time and intelligent coordination across increasingly sophisticated IoT environments. Yet, most existing ISAC systems are still not effective in dynamic environments, especially where semantic relevance, bandwidth-limited environments, and asynchronous data streams require adaptive, intelligent decision-making. This work provides a distributed ISAC framework integrating Agentic Artificial Intelligence (Agentic AI) with a Semantic-aware Asynchronous Federated Learning (S3A-AFL) architecture. The framework empowers edge agents to make timely context-aware decisions to dynamically allocate bandwidth, adjust sensing plans, and trigger model updates only when necessary, rather than employing pre-fixed schedules. By semantic encoding and distributed learning, S3A-AFL evades regular synchronization needs, enabling efficient performance in realistic scenarios. Compared to a static baseline, approach achieves a 32% improvement in average latency and an 18% reduction in packet loss, proving the benefit of adaptive, agent controlled. To demonstrate practical applicability, we evaluate and test the system with a storm forecasting scenario and apply a real-world environmental dataset, thereby showing how S3A-AFL enables key operations under limited network conditions. This work demonstrates the promise the framework for smart and resilient 6G applications.",
10.1109/CSCWD49262.2021.9437879,An Agent-Based Approach for Dynamic Scheduling in Hybrid Flow Shops,"Today, manufacturing enterprises must respond quickly to the ever-changing market environment in order to survive. At the same time, dynamic disturbances in production sites such as machine failures, reworking caused by quality problems, and changes of processing time and personnel will also have negative impacts on the effectiveness of the original plan. In order to ensure the feasibility of scheduling algorithms in highly dynamic environment, this paper presents agent-based rescheduling negotiation mechanisms with five dynamic disturbances, and verifies its feasibility through simulations. A multi-agent system structure with quick responses and simple communication networks is designed according to characteristics of hybrid flow shops, with which the processing of jobs can be easily traced back.",
10.1109/CSIS-IAC65538.2025.11162018,Hierarchical Task Scheduling and Robotic Manipulation for Autonomous Materials Discovery,"The use of mobile manipulator (MM) in materials laboratories remains limited due to several key challenges, including the difficulty for non-expert users to control the MM using natural language instructions and the difficulty for MM to execute long-horizon tasks. As a result, MM often fails to replace manual operations effectively. In recent years, large language models (LLMs) have made significant progress in supporting robots to perform complex tasks, showing great potential for enabling autonomous materials laboratories. In this study, we introduce an innovative AI-automation framework, named Large Language Model-Graph Reinforcement Learning (LLM-GRL), to improve the efficiency of ceramic materials research. We adopt a hierarchical architecture in which the upper layer uses LLM for robotic task planning while the lower layer leverages graph-based reinforcement learning to train the robot's basic skills. We designed a typical experimental scene for a materials lab and conducted experiments in both simulated and realworld environments. Experimental results demonstrate that the proposed approach improves the task success rate to 85.7 % and provides a practical solution for building automated material research systems.",
10.1109/CYBER67662.2025.11168397,SURTR: Semantic Understanding and Reinforced Trajectory Robotics via Collaborative Multi-LLMs and Offline Reinforcement Learning,"In this paper, we propose and implement an intelligent robotic arm system that integrates large language model (LLM) technology and offline reinforcement learning (RL) technology to achieve the robot's cognitive and motion capabilities, respectively. We design a hierarchical multi-model collaborative workflow that decomposes the analysis of user instructions and robot task planning into stages such as instruction parsing, high-level motion macro-planning, low-level motion fine-planning, and re-planning, enabling the robot to utilize the LLM for reasoning and planning the required tasks. For the robotic arm's motion control tasks, we employ inverse kinematics (IK) to compute the target pose, followed by an offline RL algorithm based on long-horizon path constraints to sequentially accomplish path planning and motion decision-making, guiding the robotic arm's end-effector to reach the target position.",
10.1109/DDCLS61622.2024.10606757,InspectionGPT: A Large Language Model-Based System for Inspection Task Planning,"This paper addresses the problem of insufficient advanced cognitive and decision-making capabilities of traditional inspection robots in complex environments by proposing an intelligent inspection task planning system based on Large Language Models (LLMs) - InspectionGPT. This system effectively enhances the language understanding and generation capabilities of inspection robots, thereby enabling rapid response and precise execution of complex instructions. To achieve this goal, the paper utilizes a lightweight LLM, combined with a robotic function library (covering map, language, motion, and vision functions), a task manager, and a two-stage reasoning mechanism. The system first parses instructions using natural language processing, then generates a task plan using coarse-grained and fine-grained reasoning methods, and finally executes the task with the help of the robotic function library. We tested our system in real scenarios for various inspection tasks, and the experimental results show that our system outperforms existing inspection robot systems in language understanding and generation capabilities, especially when using an LLM with 14 billion parameters. Moreover, ablation studies prove the significant impact of different parameter scales of LLMs on system performance, as well as the effectiveness and necessity of the two-stage reasoning mechanism. Although this research has made certain progress in inspection task planning, there are still limitations and challenges such as LLM training costs, diversity and complexity of instructions, and robot execution capabilities. In the future, we plan to further optimize the system, explore more application scenarios, and conduct cross-disciplinary research.",
10.1109/ERAS63351.2025.11135698,Conduct Governance Assurance - An Architecture Implementation for High-Risk Autonomous Systems,"As we place robotic systems into more complex environments and introduce increased reliance on autonomous decision making, trust in autonomous robotic planners becomes essential. Real-world environments can require a system to moderate its actions according to legal or ethical requirements as well as the usual functional requirements. In this paper, we present an implementation of a reference architecture for a robotic system that integrates conduct governance within the perception, tracking, and response pipeline. We define conduct governance as the concept that an autonomous system can interpret a set of rules for its operating domain, and implement components that are designed to act as a safeguard to ensure that autonomous decisions are aligned with these rules and ethical and safety-oriented system requirements. We implemented the reference’s patterns and practices to react to visual targets, while adhering to changing sets of high-level conduct rules. We found that, compared to traditional uses of machine learning models, the conduct governance architecture enables a higher level of observability and traceability into autonomous and intelligent systems, and provides tunable guardrails around systems that may be running one or more machine learning models. We also present lessons learned from implementing such an architecture.",
10.1109/ERAS63351.2025.11135852,Reliable Robot Missions in Dynamic Environments Using Agent-based Controllers,"Controllers for real-world robots are constructed based on expectation models which cannot account for all unexpected events. If unexpected events occur, the robot might either stop working altogether or do something that violates its given mission specification. In this paper, we aim to provide a more principled mechanism for dealing with specifications when encountering the inherent uncertainty of the real-world. We utilise agent-based control of a robotic system wherein a rational agent, programmed using a Belief-Desire-Intention (BDI) agent programming language, acts as a high-level robot controller. This agent is aware of its mission specification and is able to recognise violations of this specification caused by unexpected events. On recognising such a violation, the agent can switch to a more suitable plan. However, if there are no suitable plans, the agent can also weaken its mission specification dynamically. The agent can output not only which parts of the mission specification have been achieved but which parts have been weakened and why.",
10.1109/ETFA52439.2022.9921683,Behavior Trees based Flexible Task Planner Built on ROS2 Framework,"As modern industrial robotic systems become smarter and more flexible, they are rather tailored for specific, large-scale applications, making its implementation too complex and costly for smaller operators. The ACROBA project aims to develop and demonstrate a novel concept of cognitive robotic platforms based on a modular approach able to be smoothly adapted to virtually any industrial scenario applying agile manufacturing principles. The flexible task planner introduced here is developed as part of this European project. It aims at providing a user-friendly tool allowing the user to reconfigure the robotic cell in quick and cheap way. The main characteristics of the task planner are the behavior tree-based control (which avoids the implementation of complex Functional States Machines), the embedded HMI interface (providing basic functionalities like start, pause, resume, manual selection of skill to run…), the embedded PDDL solver (which allows the task planner to automatically rewrite the task at run time based on factory or sensors inputs), an easy interface with a GUI to design the task manually, and a work-in-progress Assembly Sequence Planner (ASP)",
10.1109/ETFA65518.2025.11205636,An Architecture for Integrating Large Language Models with Digital Twins and Automation Systems,"Large Language Models (LLMs) offer flexible reasoning capability but lack physical embodiment, while traditional automation systems can execute physical processes yet lack cognitive capability. This paper presents a layered architecture that bridges this gap by integrating LLMs with digital twins and physical automation systems, with reference to practical case studies as proof of concept. The proposed architecture comprises three layers: a cognitive layer powered by LLMs, a bridging layer based on digital twins, and a physical layer consisting of technical process and automation system. Within the digital twin layer, we introduce three design paradigms for structuring information to support effective LLM integration: state snapshot modeling, event message modeling, and plan sequence modeling. These paradigms are demonstrated through prototypical case studies on robotic automation control and process simulation. To address challenges such as hallucination, task complexity, and system reliability, we distill a set of practical strategies, including multi-agent system design, human validation, and test-driven development. Additionally, we propose the concept of ""Return on Intelligence"" as a conceptual tool for evaluating the efficacy of investments in intelligent automation. This research contributes to the theoretical foundation and the architecture design for developing intelligent, adaptive automation systems powered by LLMs.",
10.1109/ETFA65518.2025.11205791,Towards a Skill-Based Framework for User-Centric QoS-Based Orchestration of Human-Robot Collaboration Workflows,"Human-Robot Collaboration (HRC) offers potential for flexible manufacturing, especially in small and medium-sized enterprises, but existing systems often lack adaptability to dynamic environments and human needs. This paper presents a novel, skill-based framework for user-centric, Quality of Service (QoS) based orchestration of HRC workflows. Our three-layer architecture separates non-real-time orchestration and workflow management from real-time, safety-critical execution, coordinated via a user-friendly interface using our Gantt chart-based Robot Collaboration Language. The framework allows users to define QoS goals (e.g., speed, energy efficiency, ergonomics), influencing high-level orchestration and low-level motion planning. This paper details the implementation and demonstrates the framework’s structure. It contributes towards more flexible, efficient, and human-aware robotic systems by providing an integrated approach to adaptive HRC workflow execution.",
10.1109/ETNCC63262.2024.10767440,Multi-Agent Deep Reinforcement Learning for Hybrid Motion Planning in Dynamic Environments,"This research presents a novel approach to addressing the challenges of gesture forecasting in impenetrable and dynamic atmospheres by integrating a hybrid algorithm within a multi-agent system framework. Traditional methods such as Force-based motion planning (FMP) & deep reinforcement learning (RL) often struggle to handle complex scenarios involving multiple autonomous agents due to their inherent limitations. To overcome these challenges, we propose a hybrid algorithm that seamlessly combines the strengths of RL and FMP while leveraging the coordination capabilities of a multi-agent system. By integrating this hybrid algorithm into a multi-agent framework, we demonstrate its effectiveness in enabling multiple agents to navigate densely populated environments with dynamic obstacles. Through extensive simulation studies, we illustrate the superior performance of our approach compared to traditional methods, achieving higher success rates and improved efficiency in scenarios involving simultaneous motion planning for multiple agents. A hybrid motion planning algorithm is also introduced in this very research. Performance Comparison of Hybrid Algorithm, Deep RL, and FMP are also discussed in the result section. This research paves the way for the development of robust and scalable solutions for motion planning in real-world applications such as collaborative robotics, autonomous vehicle fleets, and intelligent transportation systems.",
10.1109/FarEastCon50210.2020.9271331,Multi-agent Planning of Autonomous Robots Based on Declarative Rules,"In this work, we consider the rules declaratively describing the goal states of environment. A multi-agent autonomous system based on such rules has the ability to distribute subtasks between agents and complete its goals. There is a need to create a set of rules that would fully describe the behavior of both individual agents and the behavior of a multi-agent system. The work describes syntax of the rules and system architecture of an autonomous robot. We have implemented a rule parser, a dependency network, and an interpreter. The interpreter was integrated with applied software that implements search algorithms and provides decision trees for decision making. In the process of global planning, the search for the optimal solution is carried out, taking into account time spent and resources. Planning is a continuous action that allows you to react to unexpected situations and to correct inaccuracies in the modeling. Finally, we wrote declarative rules and carried out an experimental test of the rules processing system in a virtual environment.",
10.1109/GACLM67198.2025.11231998,Adversarial and Multilingual Threats in Retrieval-Augmented Generation: From Prompt Injection to Model Exploitation,"Retrieval-Augmented Generation (RAG) systems have emerged as a cornerstone of modern generative AI by coupling large language models (LLMs) with external knowledge retrieval, thereby enabling more grounded, accurate, and context-aware outputs. Yet this paradigm simultaneously broadens the attack surface—extending vulnerabilities from generation into retrieval pipelines, language interfaces, and exposed APIs. In this paper, we propose a comprehensive threat taxonomy and adversarial framework targeting both conventional and agentic RAG systems, in which LLMs autonomously plan and execute multi-step tasks using retrieved knowledge. Our analysis spans a wide spectrum of adversarial techniques, including prompt injection, jailbreak exploits, API-driven model extraction, and multilingual prompt manipulation. Unlike prior work that primarily focuses on English-only vulnerabilities, we show that multilingual RAG pipelines—particularly those involving language blending (e.g., Arabic-English code-switching)—introduce novel attack vectors that bypass safety filters and induce unintended behaviors. To study these risks, we develop a multilingual adversarial benchmark suite that integrates both synthetic and real-world corpora across English, Arabic, and Spanish. Through systematic evaluation, we demonstrate how the retrieval layer not only amplifies leakage and inversion risks but also enables adversaries to infer system logic, extract private data from vector stores, and manipulate autonomous agent behavior through tool-integrated APIs. To mitigate these threats, we assess multiple defense strategies, including prompt sanitization, cross-lingual content filtering, retriever-stage anomaly detection, and behavior-based profiling of API interactions. Our findings reveal that existing safeguards are insufficient—particularly in agentic or low-resource language scenarios—underscoring the need for architecture-specific and multilingual defenses. This work fills a critical gap in GenAI security by presenting the first holistic, multilingual, and agent-aware security framework for RAG, offering actionable guidance for building robust and trustworthy generative AI applications across diverse linguistic and deployment contexts.",
10.1109/ICAACE65325.2025.11019820,Dynamic Priority-Driven Multi-Agent Path Planning for Warehouse Logistics: Spatiotemporal Constraint Optimization,"To address challenges in multi-agent path planning (MAPF) for high-density warehouse logistics scenarios-including frequent spatiotemporal conflicts, narrow-passage deadlocks, and inefficiencies in large-scale cluster scheduling - this paper proposes a hierarchical cooperative planning architecture. The architecture integrates upper-layer dynamic priority scheduling with spatiotemporal constraint propagation and lower-layer safe interval path planning (SIPP) guided by reverse resumable A* (RRA*) global heuristic search, achieving conflict preemption and path optimization. Core algorithmic innovations include: (1) A sliding temporal window-based dynamic priority adjustment strategy to alleviate long-term blocking of low-priority agents; (2) Narrow-passage conflict prediction and alternative path pre-planning mechanisms to reduce deadlock risks; (3) RRA* historical state reuse and spatiotemporal constraint recursion to compress redundant search spaces. Experiments demonstrate that in high-density warehouse maps, the algorithm achieves collision-free planning success rates in multi-agent scenarios, with significant makespan reduction and improved computational efficiency compared to existing MAPF methods. Despite local path suboptimality caused by temporal window discretization, its advantages in continuous task support, dynamic environment adaptability, and balanced computational efficiency provide a reliable solution for large-scale cluster scheduling in logistics automation.",
10.1109/ICAD65464.2025.11114062,Probing a Vision-Language-Action Model for Symbolic States and Integration into a Cognitive Architecture,"Vision-language-action (VLA) models hold promise as generalist robotics solutions by translating visual and linguistic inputs into robot actions, yet they lack reliability due to their black-box nature and sensitivity to environmental changes. In contrast, cognitive architectures (CA) excel in symbolic reasoning and state monitoring but are constrained by rigid predefined execution. This work bridges these approaches by probing OpenVLA's hidden layers to uncover symbolic representations of object properties, relations, and action states, enabling integration with a CA for enhanced interpretability and robustness. Through experiments on LIBERO-spatial pick-and-place tasks, we analyze the encoding of symbolic states across different layers of OpenVLA's Llama backbone. Our probing results show consistently high accuracies (>0.90) for both object and action states across most layers, though contrary to our hypotheses, we did not observe the expected pattern of object states being encoded earlier than action states. We demonstrate an integrated DIARCOpenVLA system that leverages these symbolic representations for real-time state monitoring, laying the foundation for more interpretable and reliable robotic manipulation. © 2025 IEEE.",
10.1109/ICAIBD64986.2025.11082089,A Multi-Agent Reinforcement Learning Approach for Optimizing Shared Spare Parts Procurement Management,"Power plant operations critically depend on effective spare parts management, where traditional shared procurement strategies often employ simplistic single-factor prioritization methods that fail to consider comprehensive allocation factors. These approaches lead to suboptimal resource utilization, increased costs, and potential safety risks. We address these limitations by proposing a novel Multi-Agent Deep Deterministic Policy Gradient framework integrated with Transformer Encoder architecture (TE-MADDPG) for multi-plant spare parts management. Our innovation lies in modeling each power plant as an independent decision-making agent within a Markov Decision Process that dynamically incorporates inter-plant distances, spare part values, criticality indexes, and real-time demand patterns. The Transformer Encoder component effectively solves the challenge of handling variable-length observation spaces across different plants—a significant limitation in previous approaches. Experimental validation with operational data from 8 power plants demonstrates that TE-MADDPG consistently outperforms traditional methods, achieving an average 2.3% reduction in procurement costs and substantial improvements in transfer efficiency, particularly during high-demand periods. Our framework provides a scalable, adaptable solution that enhances both operational safety and economic performance in power generation facilities.",
10.1109/ICAIDT66272.2025.00064,Research on the Development of 3D Intelligent Modeling Platform Based on Agent Model,"To address the bottlenecks in traditional 3D pipeline embedded iron modeling, such as frequent manual intervention and low efficiency in multi-disciplinary collaboration, this study proposes an intelligent modeling platform architecture based on multi-Agent cooperation. The platform adopts a hierarchical collaborative design, comprising four layers: the user interaction layer (3D visualization and dynamic parameter configuration), the core decision-making layer (task scheduling and conflict coordination), the data layer (structured knowledge base and real-time caching), and the execution layer (specialized Agent cluster), collectively forming a closed-loop autonomous decision-making system. By leveraging knowledge graph technology, the platform encodes design rules and historical cases into structured knowledge, while integrating a dynamic path planning mechanism to enable cross-disciplinary collaborative optimization-for example, automatically adjusting anchoring strategies when civil engineering model accuracy is insufficient. The multi-Agent negotiation mechanism significantly enhances adaptability in complex engineering scenarios. Experimental results demonstrate that the platform can substantially reduce modeling cycles and minimize human errors. This research provides an extensible technical paradigm for intelligent engineering design. Future work will focus on deep integration with digital twin technologies to strengthen full lifecycle management capabilities.",
10.1109/ICAIRC64177.2024.10900132,Construction of a Cognitive Graph for Intelligent Manufacturing Robot Behavior,"The forms of tasks in intelligent manufacturing are diverse, and their operating environment is also dynamically changing. Effective knowledge representation and reasoning are key foundations for enhancing robots' understanding and execution capabilities of complex tasks. Therefore, this article constructs a cognitive graph of robot behavior in the field of intelligent manufacturing based on BERT-BiLSTM-CRF. Firstly, based on the multi-level requirements in robotic operation, a robot behavior corpus is constructed, and the robotic behavior ontology layers Task, Skill, Action, Location, Agent (H), and Object are defined to standardize the semantic structure of behavior. Then, using the BERT model to extract language structure and semantic relationship information, deep-level feature representations are obtained from the text; Capture contextual semantic relationships of behavior through the BiLSTM network, and combine the CRF model to globally constrain and optimize the predicted behavior results. Finally, the extracted triplets are stored using neo4j to form a cognitive graph of intelligent manufacturing robot behavior (IMRBCG). The experimental results show that the P, R, and F1-score of the proposed method are 95.51%, 90.66%, and 93.02%, respectively, effectively extracting 8763 behavioral triplets. This cognitive graph provides technical support for the task of the use of planning and collaboration for intelligent manufacturing robots.",
10.1109/ICARM62033.2024.10715872,Embodied AI with Large Language Models: A Survey and New HRI Framework,"The study aims to develop an emotional logic engine based on a large language model (LLM), providing emotional connections, personalized interactions, knowledge representation, and logical inference. Using this emotional logic engine, we intend to realize the goals of high-level cognition, autonomous knowledge reasoning, long-horizon planning, and action execution described in embodied artificial intelligence (embodied AI). Ultimately, we will implement an efficient intelligent companion interaction robot (ICIR) based on a novel human-robot interaction (HRI) framework to enhance the interaction between humans and robots. The proposed framework integrates multiple components including a visual language model (VLM), logic reasoning model, pre-trained database integration, and the development of a multi-modal template. Additionally, we introduce a complementary framework termed perception-action loop (PALoop), which is meticulously modeled and constructed to facilitate seamless interactions between human operators and robotic systems. Detailed design aspects of both frameworks are elucidated, providing insights into their architecture and functionality. The research outcomes will be practically applied, offering the robotics industry innovative and practical technology solutions.",
10.1109/ICBASE66587.2025.11181399,Multi-agent Collaborative Decision-making Mechanism Combining Reinforcement Learning and Graph Attention Network,"Multi-agent collaborative decision-making faces three core problems: inefficient modeling of relationships between agents in partially observable environments, poor scalability of traditional reinforcement learning algorithms, and inaccurate global reward allocation mechanisms. This study proposes a collaborative framework that integrates graph attention networks (GAT) and multi-agent deep deterministic policy gradients (MADDPG), aiming to build a relationship-aware agent decisionmaking mechanism: first, GAT is used to dynamically learn the adjacency matrix, and the agent interaction relationship is encoded through a two-layer attention mechanism; then a joint reward function is designed, and the centralized critic network is combined to evaluate the collaborative utility; the Centralized Training architecture is used to verify it in the StarCraft II multiagent challenge environment. Experiments show that in the 15agent pursuit task, the success rate of this framework reaches 95.7%; in the heterogeneous agent formation task, the path planning efficiency is improved by 36.4 seconds. This method explicitly models the agent dependencies through a graph structure, solving the problem of traditional methods in complex collaboration.",
10.1109/ICCCN65249.2025.11133883,Large Language Model Enhanced Multi-UAV Direct Cross-boundary Maritime Data Collection Scheme,"The cross-boundary communication between unmanned aerial vehicles (UAVs) and autonomous underwater vehicles (AUVs) constitutes a pivotal component in achieving full coverage of the space-air-ground-sea integrated network of 6G. In such hybrid networks, it is imperative to intelligently plan the trajectory of UAVs by exploiting the deep reinforcement learning (DRL) technique and direct optical wireless communication (OWC) technology to ensure timely data collection. However, the traditional DRL technique suffers from issues such as sparse rewards and low sampling efficiency, which leads to a decrease in the freshness of data. To address these issues, in this paper, we investigate the trajectory planning problem for swarms of UAVs conducting data collection with age of information awareness. Leveraging the prior knowledge of large language models (LLMs) and multi-agent reinforcement learning technique, we propose a novel multi-UAV maritime data collection scheme. Firstly, we extract the prior knowledge strategies of LLMs in the form of expert trajectories through structured prompts. Then, initial strategy models are rapidly generated for UAVs through multi-agent behavior cloning method, which reduce ineffective exploration and accelerates learning. Finally, the MATD3 algorithm is used to fine-tune these strategy models, enhancing their policy learning capability in sparse reward environments. We also conduct simulations to validate the effectiveness of the proposed algorithms.",
10.1109/ICCES63552.2024.10859659,"Marching Forward: Redefining Human-Machine Interactions in Conversational AI Through Hybrid Intelligence, Blockchain Security, and Autonomous Agents","Conversational AI has emerged as an essential instrument in enhancing human-computer interaction, with applications spanning customer service to personal assistants. This paper offers a comprehensive examination of recent developments in conversational AI, including novel techniques in natural language generation (NLG), dialogue systems, and dynamic response optimization. We analyze advancements including transformer-based architectures, reinforcement learning for dialogue generation, and retrieval-augmented models, emphasizing their roles in enhancing the quality and contextual accuracy of conversations. Additionally, we examine the feasibility of blockchain technology as the foundation for decentralized AI, promoting secure, transparent, and distributed frameworks for AI applications, hence improving privacy and control in data exchanges. Hybrid methodologies that combine symbolic reasoning with deep learning are analyzed, highlighting their effectiveness in addressing complex dialogues. These advancements, supported by empirical research and benchmark performance, signify the evolution towards more personalized, intelligent, and decentralized conversational systems. © 2024 IEEE.",
10.1109/ICDEW67478.2025.00007,Orchestrating Agents and Data for Enterprise: A Blueprint Architecture for Compound AI,"Large language models (LLMs) have gained significant interest in industry due to their impressive capabilities across a wide range of tasks. However, the widespread adoption of LLMs presents several challenges, such as integration into existing applications and infrastructure, utilization of company proprietary data, models, and APIs, and meeting cost, quality, responsiveness, and other requirements. To address these challenges, there is a notable shift from monolithic models to compound AI systems, with the premise of more powerful, versatile, and reliable applications. However, progress thus far has been piecemeal, with proposals for agentic workflows, programming models, and extended LLM capabilities, without a clear vision of an overall architecture. In this paper, we propose a ‘blueprint architecture’ for compound AI systems for orchestrating agents and data for enterprise applications. In our proposed architecture the key orchestration concept is ‘streams' to coordinate the flow of data and instructions among agents. Existing proprietary models and APIs in the enterprise are mapped to ‘agents', defined in an ‘agent registry’ that serves agent metadata and learned representations for search and planning. Agents can utilize proprietary data through a ‘data registry’ that similarly registers enterprise data of various modalities. Tying it all together, data and task ‘planners' break down, map, and optimize tasks and queries for given quality of service (QoS) requirements such as cost, accuracy, and latency. We illustrate an implementation of the architecture for a use-case in the HR domain and discuss opportunities and challenges for ‘agentic AI’ in the enterprise.",
10.1109/ICHMS65439.2025.11154346,The Impact of HAT on Team Dynamics and Coordination: A Teaming-Oriented Study for MUM-T,"This paper investigates team structures and dynamics in team-based collaborative environments, which can be adapted to design Human-Agent Teams (HAT). Coordination between team members is critical to mission success, especially in dynamic, time-critical environments. As highly automated agents become more prevalent, effective HAT become crucial to maintain effective coordination. This especially applies to our domain of Manned-Unmanned Teaming (MUM-T) in which manned and unmanned aircraft act as collaborative teammates, with pilots acting as integrated combat members and decision-makers. We see a clear need for design patterns that support the development of agents that meet the requirements of effective HAT. The development of these patterns focuses on MUM-T and is carried out in two steps. Firstly, we conduct a review study to identify the general behavioural patterns, coordination mechanisms, and enablers of effective teaming. Secondly, these findings are then compared with organizational paradigms from Multi-Agent Systems (MAS). The requirements for effective HAT are then used to propose a hybrid two-layer cognitive work system that can be used for MUM-T missions. The first layer of this design pattern represents the tactical planning team, where the pilot and an agent collaborate on mission planning. The second layer represents tactical execution, where agents and UAVs jointly execute this plan. To realize this two-layer approach, the architecture combines a hierarchical planning layer with a holarchical execution layer. Lastly, we discuss how this work system can be realized in a coordinated intercept MUM-T mission. The architecture is intended to support the development of cognitive agents that show high teaming capabilities in MUM-T missions and cooperatively support pilots.",
10.1109/ICICCS48265.2020.9121120,An Autonomous Diet Recommendation Bot Using Intelligent Automation,"Robotic process automation(RPA) and intelligent automation have been replacing manual automation across various industries due to their significant ROI(return on investment). While Artificial intelligence is a simulation of the cognitive approach, RPA is merely mimicking that process by the use of bots. RPA and IA are emerging and transforming businesses across various sectors such as finance and accounting, payroll, human resources, supply chain, customer service, sales and marketing, IT etc.[5] One such industry where bots are being used for automating processes is the food and lifestyle industry. Various applications like healthify me and room suggest users a diet based on their specifications like height, weight, age, gender etc. Some of these applications make use of E-mail automation to suggest users with a user-specific, specially curated diet at timed intervals(daily/weekly/monthly..). Various tools such as Automation Anywhere, Blue prism, UI-Path, Pega etc.[4] are used to create bots and automate tasks/compute algorithms. The tool used for the creation of this diet recommendation system is Automation Anywhere. By making use of automation anywhere, a recommender system is created that can act as a meal planner. There are three types of bots in Automation Anywhere – task bots, meta bots and IQ bots. Task bots need to be edited manually with application updates. Metabots on the other hand, are more advanced. They are designed in such a way that bot-recalibration is automatically applied with changes in the application interface. IQ bots use cognitive technology when working with unstructured data[11]. Here, For this particular application, taskbots and metabots are used. The proposed solution is capable of sending a large number of diet recommendations to hundreds of users in a database at a very expeditious rate.",
10.1109/ICICNCT66124.2025.11232599,Large Model Scheduling Method in Collaborative Decision Making of Intelligent Agents,"In multi-agent collaborative decision-making, increasing agent numbers and decision complexity exacerbate computational demands, causing resource competition and communication delays in traditional centralized scheduling methods. This paper proposes a hierarchical task scheduling architecture that decouples global intention reasoning from local behavior planning, integrating a dynamic priority allocation mechanism optimized via the PPO algorithm. To enhance computational efficiency, asynchronous gradient synchronization and model cache pooling are introduced for resource optimization. Experiments demonstrate a 60% reduction in communication delay, an 11.1% improvement in task completion rate, 56.3% lower GPU memory usage, and 60.8% higher computational efficiency compared to centralized approaches. The method significantly improves scheduling performance and resource utilization in large-scale multi-agent systems, though further adaptations are needed for highly dynamic environments.",
10.1109/ICIMIBD58123.2022.00022,An Intelligent MAV-UAV Cooperative Combat Planning Method Based on Deep Reinforcement Learning,"With the development of intelligent airforce combat, deep reinforcement learning (DRL) has been widely applied in various combat systems. Among these systems, the hybrid system of the manned aerial vehicle (MAV) and unmanned aerial vehicle (UAV) with cooperative combat mode shows bright foreground. However, the heterogeneity and dynamics in the formation pose challenges to the cooperative combat planning algorithm. To this end, this paper proposes an intelligent MAV-UAV cooperative combat planning method based on discretized proximal policy optimization (PPO). A 5×5 rule-based action space is constructed based on the knowledge of air combat. The state space and the corresponding reward function are introduced to stably train the policy. In contrast to other continuous DRL methods and multi-agent DRL, the proposed method is easier to be reproduced and be trained, and the defined rule-based formation actions can be expanded to suit other scenes. The feasibility and effectiveness of the proposed planning method are validated by numerical experiments based on the XSimStudio.",
10.1109/ICIP40778.2020.9190659,Task-Oriented Multi-Modal Question Answering for Collaborative Applications,"Cobots that can work in human workspaces and adapt to human need to understand and respond to human's inquiry and instruction. In this paper, we propose new question answering (QA) task and dataset for human-robot collaboration on task-oriented operation, i.e., task-oriented collaborative QA (TCQA). Differing from conventional video QA for answering questions about what happened in video clips constrained by scripts and subtitles, TC-QA aims to share common ground for task-oriented operation through question answering. We propose an open-end (OE) format of answer with text reply, image with annotated related objects, and video with operation duration to guide operation execution. Designed for grounding, the TC-QA dataset comprises query videos and questions to seek acknowledgement, correction, attention to task-related objects, and information on objects or operation. Due to the flexibility of real-world task with limited training sample, we propose and evaluate a baseline method based on a hybrid approach. The hybrid approach employs deep learning methods for object detection, hand detection and gesture recognition, and symbolic reasoning to ground question on observation for providing the answer. Our experiments show that the hybrid method is effective for the TC-QA task. © 2020 IEEE.",
10.1109/ICMLT65785.2025.11193354,Enhancing Cognitive Functions in Large Language Models Towards AGI: A State-of-the-Art Survey and Exploratory Review,"This paper presents a comprehensive state-of-the-art survey and exploratory review of current methodologies aimed at enhancing the reasoning capabilities of Large Language Models (LLMs) on the path toward Artificial General Intelligence (AGI). The paper presents a novel synthesis of enhancement strategies across four complementary cognitive dimensions: planning, memory, world modeling, and neuro-symbolic integration. Although LLMs have shown remarkable performance in language-based tasks, their reasoning abilities remain limited, particularly in areas such as causal inference, long-term planning, and common sense understanding, capabilities vital for domains like satellite mission engineering design and spacecraft operations. This paper systematically examine these cognitive bottlenecks and the challenges posed by hallucinations, which undermine trust and reliability. The review then explores promising strategies for augmenting LLM capabilities, including integration with knowledge graphs and symbolic reasoning systems, the development of internal ""world models,"" memory and attention-based architectural innovations, and advanced training techniques such as instruction tuning, reinforcement learning from human feedback, and chain-of-thought prompting. Furthermore, we analyze hybrid neuro-symbolic approaches and multi-agent architectures as emerging paradigms that blend deep learning with structured reasoning. Overall, this work aims to provide a foundation for advancing LLMs toward more robust, generalizable, and cognitively grounded artificial intelligence systems by mapping the landscape of current research and identifying the most promising directions for future development.",
10.1109/ICMNWC63764.2024.10872131,Neuromorphic-Driven Agentic AI for Autonomous Decision-Making Systems,"Agentic AI represents a paradigm shift in the development of intelligent systems capable of adaptive and proactive interactions in dynamic and complex environments. By integrating reinforcement learning (RL) with cognitive frameworks, Agentic AI goes beyond traditional rule-based and reactive models, enabling autonomous systems to make informed decisions, anticipate future states, and learn from experience. This paper explores the theoretical foundations and practical applications of Agentic AI, highlighting its potential to transform a variety of fields, including robotics, autonomous driving, finance, and healthcare. Through a detailed review of state-of-the-art research, we illustrate how cognitive architectures such as ACT-R and Soar, combined with advanced RL techniques like Deep Q-Networks (DQN) and Proximal Policy Optimization (PPO), contribute to the development of AI agents with human-like reasoning and decision-making capabilities. Experimental results demonstrate that Agentic AI significantly outperforms conventional AI approaches in terms of adaptability, learning efficiency, and decision accuracy. The findings suggest that Agentic AI offers a robust framework for creating intelligent systems capable of complex problem-solving, long-term planning, and proactive behavior, paving the way for the next generation of AI-driven applications.",
10.1109/ICMTMA52658.2021.00124,An Improved Multi-Satellite Cooperative Task Planning Method Based on Distributed Multi-agent System,"Autonomous task planning plays a vital role in the application of the earth observation satellites constellation as it can make full use of satellite resources and increase task revenue. In this paper, a multi-satellite cooperative task planning architecture based on the distributed multi-agent system is established. And an improved multi-satellite cooperative task planning algorithm (MSCTP-CEM) based on co-evolution mechanism is designed. Finally, the advantages of the proposed architecture and MSCTP-CEM algorithm are verified through multiple simulation experiments.",
10.1109/ICNP61940.2024.10858566,SatFlow: Scalable Network Planning for LEO Mega-Constellations,"Low-earth-orbit (LEO) satellite communication networks have evolved into mega-constellations with hundreds to thousands of satellites inter-connecting with inter-satellite links (ISLs). Network planning, which plans for network resources and architecture to improve the network performance and save operational costs, is crucial for satellite network management. However, due to the large scale of mega-constellations, high dynamics of satellites, and complex distribution of real-world traffic, it is extremely challenging to conduct scalable network planning on mega-constellations with high performance. In this paper, we propose SATFLOW, a distributed and hierarchical network planning framework to plan for the network topology, traffic allocation, and fine-grained ISL terminal power allocation for mega-constellations. To tackle the hardness of the original problem, we decompose the grand problem into two hierarchical sub-problems, tackled by two-tier modules. A multi-agent reinforcement learning approach is proposed for the upper-level module so that the overall laser energy consumption and ISL operational costs can be minimized; A distributed alternating step algorithm is proposed for the lower-level module so that the laser energy consumption could be minimized with low time complexity for a given topology. Extensive simulations on various mega-constellations validate SATFLOW's scalability on the constellation size, reducing the flow violation ratio by up to $21.0 \%$ and reducing the total costs by up to $89.4 \%$, compared with various state-of-the-art benchmarks.",
10.1109/ICOCT64433.2025.11118474,Structured Intelligence: Merging Neural and Symbolic AI,"In order to close the gap between statistical learning and explicit knowledge representation, a new interdisciplinary field called neuro-symbolic AI combines deep learning with symbolic reasoning. Symbolic reasoning offers structured decision-making and logical inference, while deep learning excels at pattern recognition and feature extraction. Key architectures, hybrid models, and differentiable symbolic reasoning techniques are all covered in this paper's thorough analysis of recent developments in neuro-symbolic AI. We investigate its uses in a number of fields, such as automated reasoning, natural language processing, robotics, and explainable AI. We also examine issues like scalability, interpretability, and knowledge transfer that arise when combining neural and symbolic approaches. We conclude by outlining possible avenues for future research, emphasizing the necessity of enhancing neuro-symbolic AI systems' generalization, resilience, and effectiveness. © 2025 IEEE.",
10.1109/ICPS65515.2025.11087877,Toward the Trust-Enhanced MAPE-K Loop: A Novel Robotic Software Architecture,"Modern robotic applications frequently employ the MAPE-K (Monitor, Analyze, Plan, Execute, and Knowledge) loop for adaptive behavior. However, in unprecedented situations, the functionality of the MAPE-K loop often degrades, limiting its effectiveness. Moreover, In robotic applications, a distributed MAPE-K loop may be necessary for enabling adaptability across diverse deployment environments. To address this challenge, we propose a novel robotic software architecture designed to enhance trustworthiness, modularity and portability within the MAPE-K framework. Our approach introduces placeholders for trustworthiness checks to ensure robust operation in dynamic environments. Additionally, the architecture is developed in a distributed manner to enable scalability and portability across diverse robotic systems. The architecture is implemented using Python, with distributed backend for knowledge and communication handling to validate its performance, we conducted tests using a TurtleBot 4 use case, demonstrating the feasibility and benefits of our design.",
10.1109/ICRA48506.2021.9562028,Visual Perspective Taking for Opponent Behavior Modeling,"In order to engage in complex social interaction, humans learn at a young age to infer what others see and cannot see from a different point-of-view, and learn to predict others’ plans and behaviors. These abilities have been mostly lacking in robots, sometimes making them appear awkward and socially inept. Here we propose an end-to-end long-term visual prediction framework for robots to begin to acquire both these critical cognitive skills, known as Visual Perspective Taking (VPT) and Theory of Behavior (TOB). We demonstrate our approach in the context of visual hide-and-seek – a game that represents a cognitive milestone in human development. Unlike traditional visual predictive model that generates new frames from immediate past frames, our agent can directly predict to multiple future timestamps (25 s), extrapolating by 175% beyond the training horizon. We suggest that visual behavior modeling and perspective taking skills will play a critical role in the ability of physical robots to fully integrate into real-world multi-agent activities.",
10.1109/ICRA48891.2023.10160530,Active Predictive Coding: Brain-Inspired Reinforcement Learning for Sparse Reward Robotic Control Problems,"In this article, we propose a backpropagation-free approach to robotic control through the neuro-cognitive computational framework of neural generative coding (NGC), designing an agent completely built from predictive processing circuits that facilitate dynamic, online learning from sparse rewards, embodying the principles of planning-as-inference. Concretely, we craft an adaptive agent system, which we call active predictive coding (ActPC), that balances an internally-generated epistemic signal (meant to encourage intelligent exploration) with an internally-generated instrumental signal (meant to encourage goal-seeking behavior) to learn how to control various simulated robotic systems as well as a complex robotic arm using a realistic simulator, i.e., the Surreal Robotics Suite, for the block lifting task and the can pick-and-place problem. Notably, our results demonstrate that the proposed ActPC agent performs well in the face of sparse (extrinsic) reward signals and is competitive with or outperforms several powerful backpropagation-based reinforcement learning approaches.",
10.1109/ICRA48891.2023.10160545,Learning Neuro-symbolic Programs for Language Guided Robot Manipulation,"Given a natural language instruction and an input scene, our goal is to train a model to output a manipulation program that can be executed by the robot. Prior approaches for this task possess one of the following limitations: (i) rely on hand-coded symbols for concepts limiting generalization beyond those seen during training [1] (ii) infer action sequences from instructions but require dense sub-goal supervision [2] or (iii) lack semantics required for deeper object-centric reasoning inherent in interpreting complex instructions [3]. In contrast, our approach can handle linguistic as well as perceptual variations, end-to-end trainable and requires no intermediate supervision. The proposed model uses symbolic reasoning constructs that operate on a latent neural object-centric representation, allowing for deeper reasoning over the input scene. Central to our approach is a modular structure consisting of a hierarchical instruction parser and an action simulator to learn disentangled action representations. Our experiments on a simulated environment with a 7-DOF manipulator, consisting of instructions with varying number of steps and scenes with different number of objects, demonstrate that our model is robust to such variations and significantly outperforms baselines, particularly in the generalization settings. The code, dataset and experiment videos are available at https://nsrmp.github.io © 2023 IEEE.",
10.1109/ICRA55743.2025.11127480,Closed Loop Interactive Embodied Reasoning for Robot Manipulation,"Embodied reasoning systems integrate robotic hardware and cognitive processes to perform complex tasks, typically in response to a natural language query about a specific physical environment. This usually involves changing the belief about the scene or physically interacting and changing the scene (e.g. sort the objects from lightest to heaviest). In order to facilitate the development of such systems we introduce a new modular Closed Loop Interactive Embodied Reasoning (CLIER) approach that takes into account the measurements of non-visual object properties, changes in the scene caused by external disturbances as well as uncertain outcomes of robotic actions. CLIER performs multi-modal reasoning and action planning and generates a sequence of primitive actions that can be executed by a robot manipulator. Our method operates in a closed loop, responding to changes in the environment. Our approach is developed with the use of MuBle simulation environment and tested in $\mathbf{1 0}$ interactive benchmark scenarios. We extensively evaluate our reasoning approach in simulation and in real-world manipulation tasks with a success rate above $\mathbf{7 6 \%}$ and 64%, respectively.",
10.1109/ICRA55743.2025.11127486,Enhancing Multi-Agent Systems via Reinforcement Learning with LLM-Based Planner and Graph-Based Policy,"Multi-agent systems (MAS) have shown great potential in executing complex tasks, but coordination and safety remain significant challenges. Multi-Agent Reinforcement Learning (MARL) offers a promising framework for agent collaboration, but it faces difficulties in handling complex tasks and designing reward functions. The introduction of Large Language Models (LLMs) has brought stronger reasoning and cognitive abilities to MAS, but existing LLM-based systems struggle to respond quickly and accurately in dynamic environments. To address these challenges, we propose LLM-based Graph Collaboration MARL (LGC-MARL), a framework that efficiently combines LLMs and MARL. This framework decomposes complex tasks into executable subtasks and achieves efficient collaboration among multiple agents through graph-based coordination. Specifically, LGC-MARL consists of two main components: an LLM planner and a graph-based collaboration meta policy. The LLM planner transforms complex task instructions into a series of executable subtasks, evaluates the rationality of these subtasks using a critic model, and generates an action dependency graph. The graph-based collaboration meta policy facilitates communication and collaboration among agents based on the action dependency graph, and adapts to new task environments through meta-learning. Experimental results on the AI2-THOR simulation platform demonstrate the superior performance and scalability of LGC-MARL in completing various complex tasks.",
10.1109/ICRA55743.2025.11127617,Fast and Accurate Task Planning using Neuro-Symbolic Language Models and Multi-Level Goal Decomposition,"In robotic task planning, symbolic planners using rule-based representations like PDDL are effective but struggle with long-sequential tasks in complicated environments due to exponentially increasing search space. Meanwhile, LLM-based approaches, which are grounded in artificial neural networks, offer faster inference and commonsense reasoning but suffer from lower success rates. To address the limitations of the current symbolic (slow speed) or LLM-based approaches (low accuracy), we propose a novel neuro-symbolic task planner that decomposes complex tasks into subgoals using LLM and carries out task planning for each subgoal using either symbolic or MCTS-based LLM planners, depending on the subgoal complexity. This decomposition reduces planning time and improves success rates by narrowing the search space and enabling LLMs to focus on more manageable tasks. Our method significantly reduces planning time while maintaining high success rates across three task planning domains, as well as real-world and simulated robotics environments. More details are available at http://graphics.ewha.ac.kr/LLMTAMP/.",
10.1109/ICRA55743.2025.11127692,Neuro-Symbolic Imitation Learning: Discovering Symbolic Abstractions for Skill Learning,"Imitation learning is a popular method for teaching robots new behaviors. However, most existing methods focus on teaching short, isolated skills rather than long, multistep tasks. To bridge this gap, imitation learning algorithms must not only learn individual skills but also an abstract understanding of how to sequence these skills to perform extended tasks effectively. This paper addresses this challenge by proposing a neuro-symbolic imitation learning framework. Using task demonstrations, the system first learns a symbolic representation that abstracts the low-level state-action space. The learned representation decomposes a task into easier subtasks and allows the system to leverage symbolic planning to generate abstract plans. Subsequently, the system utilizes this task decomposition to learn a set of neural skills capable of refining abstract plans into actionable robot commands. Experimental results in three simulated robotic environments demonstrate that, compared to baselines, our neuro-symbolic approach increases data efficiency, improves generalization capabilities, and facilitates interpretability.",
10.1109/ICRA55743.2025.11128650,Curiosity-Driven Imagination: Discovering Plan Operators and Learning Associated Policies for Open-World Adaptation,"Adapting quickly to dynamic, uncertain environments—often called “open worlds” —remains a major challenge in robotics. Traditional Task and Motion Planning (TAMP) approaches struggle to cope with unforeseen changes, are data-inefficient when adapting, and do not leverage world models during learning. We address this issue with a hybrid planning and learning system that integrates two models: a low-level neural network-based model that learns stochastic transitions and drives exploration via an Intrinsic Curiosity Module (ICM), and a high-level symbolic planning model that captures abstract transitions using operators, enabling the agent to plan in an “imaginary” space and generate reward machines. Our evaluation in a robotic manipulation domain with sequential novelty injections demonstrates that our approach converges faster and outperforms state-of-the-art hybrid methods.",
10.1109/ICRA55743.2025.11128836,Work Smarter Not Harder: Simple Imitation Learning with CS-PIBT Outperforms Large-Scale Imitation Learning for MAPF,"Multi-Agent Path Finding (MAPF) is the problem of effectively finding efficient collision-free paths for a group of agents in a shared workspace. The MAPF community has largely focused on developing high-performance heuristic search methods. Recently, several works have applied various machine learning (ML) techniques to solve MAPF, usually involving sophisticated architectures, reinforcement learning techniques, and set-ups, but none using large amounts of high-quality supervised data. Our initial objective in this work was to show how simple large-scale imitation learning of high-quality heuristic search methods can lead to state-of-the-art ML MAPF performance. However, we find that, at least with our model architecture, simple large-scale (700k examples with hundreds of agents per example) imitation learning does not produce impressive results. Instead, we find that by using prior work that post-processes MAPF model predictions to resolve 1-step collisions (CS-PIBT), we can train a simple ML MAPF policy in minutes that dramatically outperforms existing ML MAPF policies. This has serious implications for all future ML MAPF policies (with local communication) which currently struggle to scale. In particular, this finding implies that future learnt policies should always (1) use smart 1-step collision shields (e.g, CS-PIBT) and (2) include the collision shield with greedy actions as a baseline (e.g. PIBT), as well as (3) motivates future models to focus on longer horizon / more complex planning as 1-step collisions can be efficiently resolved.",
10.1109/ICRA57147.2024.10610434,CoPAL: Corrective Planning of Robot Actions with Large Language Models,"In the pursuit of fully autonomous robotic systems capable of taking over tasks traditionally performed by humans, the complexity of open-world environments poses a considerable challenge. Addressing this imperative, this study contributes to the field of Large Language Models (LLMs) applied to task and motion planning for robots. We propose a system architecture that orchestrates a seamless interplay between multiple cognitive levels, encompassing reasoning, planning, and motion generation. At its core lies a novel replanning strategy that handles physically grounded, logical, and semantic errors in the generated plans. We demonstrate the efficacy of the proposed feedback architecture, particularly its impact on executability, correctness, and time complexity via empirical evaluation in the context of a simulation and two intricate real-world scenarios: blocks world, barman and pizza preparation.",
10.1109/ICRA57147.2024.10610676,Scalable Multi-Robot Collaboration with Large Language Models: Centralized or Decentralized Systems?,"A flurry of recent work has demonstrated that pre-trained large language models (LLMs) can be effective task planners for a variety of single-robot tasks. The planning performance of LLMs is significantly improved via prompting techniques, such as in-context learning or re-prompting with state feedback, placing new importance on the token budget for the context window. An under-explored but natural next direction is to investigate LLMs as multi-robot task planners. However, long-horizon, heterogeneous multi-robot planning introduces new challenges of coordination while also pushing up against the limits of context window length. It is therefore critical to find token-efficient LLM planning frameworks that are also able to reason about the complexities of multi-robot coordination. In this work, we compare the task success rate and token efficiency of four multi-agent communication frameworks (centralized, decentralized, and two hybrid) as applied to four coordination-dependent multi-agent 2D task scenarios for increasing numbers of agents. We find that a hybrid framework achieves better task success rates across all four tasks and scales better to more agents. We further demonstrate the hybrid frameworks in 3D simulations where the vision-to-text problem and dynamical errors are considered. See our project website 4 for prompts, videos, and code.",
10.1109/ICRAE53653.2021.9657781,An Switchable Multi-resolution Architecture of Cyber-Physical Manufacturing Systems (CPMS) for Industrial Robots Collaboration,"For complex manufacturing systems, fast, accurate, and reliable modeling and simulation of the real world, as well as the interaction from the simulation world to the real world, is required. The development of Cyber-Physical Systems (CPS) and Internet of Things (IoT) enable real-world manufacturing systems and their cyber world to form a manufacturing-oriented Cyber-Physical Systems - Cyber-Physical Manufacturing Systems (CPMS). However, the low performance of the edge, and the heavy storage and computing burden of the cloud, cannot meet the fast and accurate requirements of CPMS. To address these issues, this paper proposes an cloud-edge collaboration architecture of Cyber-Physical Manufacturing Systems intended for industrial robots collaboration. In the architecture, the key planning and decision are placed at a central computing station and the trivial calculation tasks are placed at the information shell of the manufacturing equipment. Specifically, robotic arms, AGVs and other manufacturing nodes are designed to store and perceive the environment and self-state, run with basic kinematics and kinetics. Reconfigurable computing nodes based on FPGA performs trivial logical calculation tasks. The manufacturing could is designed to plan and control all holonic nodes based on multi-agent deep reinforcement learning. The collaboration between robotic arm and AGV is studied as a case. The solution based on the proposed framework is given for the issue. The feasibility of the framework is verified by simulation and derivation.",
10.1109/ICSA-C65153.2025.00053,Dynamic Architectures Leveraging AI Agents and Human-in-the-Loop for Data Center Management,"To address the growing data needs, data centers are being established in new and unexplored terrains. This necessitates the development of robust data center management platforms capable of self-management. To make these systems adaptable to new uncertainties, especially in space, underwater, and remote data centers aimed at long-running or mission-critical operations, the architectures of these robust data center management platforms need to be accurately modeled to be dynamic and evolve during execution. We argue that, in addition to making systems self-managing and autonomous, there is a need for a human-centric adaptive architecture in the data center management domain. This involves incorporating human-in-the-loop mechanisms to oversee the system's self-adaptation and control anomalies and other drifting pointers that could affect the system's quality attributes. This paper also introduces AI Agents in the self-managing system, which can further enhance autonomous management flexibility by enabling dynamic system architecture changes through these agentic “digital workers.“ We propose a dynamic architecture framework combining AI Agents and Human-in-the-Loop for continuously improving data center management. The architecture expands the MAPE-K loop by introducing human-in-the-loop at the Plan phase and AI Agents at the Execute phase to enhance the dynamic architecture setup for autonomous self-managing data centers. This paper details the foundational AI Agents that need to be set at the Execute phase and provides a use case simulation evaluating one of the AI Agents from the proposed architecture. We also define the quality requirements, which may change at runtime in such dynamic architectures, and outline the scope of future work in this domain.",
10.1109/ICTAACS60400.2023.10449565,NorAGR: a NORmative Agent Groupe Role Model for Organizational Centered Open Multi-Agent Systems,"In Open Multi-Agent Systems (Open MAS), agents' architectures are heterogeneous or unspecified. In addition, unknown agents can freely join and leave the system in keeping with their own plans. Consequently, the interactions' results are inherently unmanageable likewise predicting the system's overall behavior due to the high likelihood of unwanted behavior (i.e., emergence). Hence, Agent, Group and Role (AGR) organizational model provides a support to design Open MAS where agent architecture and their implementation issues are left unspecified. However, the basic concepts proposed by the core AGR model make the control task of AGR-based Open MAS extremely difficult. For that end, the intent of this work is to extend the basic AGR model with normative concepts in order to provide a solution for the openness related problems in MAS. Also, the agent must satisfy the regular notions associated with the requested role in role assignment task. Normative extension satisfies a set of axioms, we proposed, in order to specify the declarative and operational new provided concepts.",
10.1109/IHCIT66787.2025.11198926,Multi-Agent Collaborative Closed-Loop Planning - Evaluation - Assessment Framework: Optimization and Interpretability Evaluation,"Service robots operating in open environments face two core challenges in semantic task planning: adaptation to dynamic scenes and uncertainty in symbol-to-motion mapping. This paper proposes a multi-agent collaborative closed-loop planning-evaluation framework, an LLM-driven, closed-loop optimization pipeline for task planning and feasibility auditing aimed at robust planning in complex, dynamic settings. The framework adopts a layered architecture with three LLM-based agents: a planning agent, an evaluation (validation) agent, and an assessment agent. Using a unified geometric-semantic-constraint representation, the planner generates symbolic task sequences, maps them to a predefined skill library, and performs self-checks to revise plans. The evaluation agent audits plans against preset criteria, outputs feasibility judgments and corrective suggestions, and iterates with the planner until a feasible solution is obtained. A fine-tuned assessment agent produces quantitative scores by combining task completion, efficiency, and replanning penalties, forming a human preference-aligned evaluation system. Experiments on mobile manipulation in household scenarios show task success rates of 96.9% (simple short tasks), 87.4% (simple long tasks), and $72.4 \%$ (complex long tasks), substantially improving over classical symbolic planning (PDDL) and Chain-of-Thought-guided LLM baselines. Ablation studies validate the contribution of each module. The correlation between the assessment agent’s scores and human ratings reaches 0.87. This work provides an explainable, closed-loop optimization paradigm for perception-decision-execution in embodied AI, advancing practical autonomy in open-world robotic operation.",
10.1109/IJCNN64981.2025.11228706,RA-Gen: A Controllable Code Generation Framework Using ReAct for Multi-Agent Task Execution,"Code generation models based on large language models (LLMs) have gained wide adoption, but challenges remain in ensuring safety, accuracy, and controllability, especially for complex tasks. Existing methods often lack dynamic integration of external tools, transparent reasoning, and user control over safety. To address these issues, we propose a controllable code generation framework utilizing the ReAct paradigm for multi-agent task execution. This framework is a multi-agent system designed to enable efficient, precise, and interpretable code generation through dynamic interactions between LLMs and external resources. The framework adopts a collaborative architecture comprising four specialized agents: a Planner for task decomposition, a Searcher that leverages the ReAct framework for reasoning and tool integration, a CodeGen agent for accurate code generation, and an Extractor for structured data retrieval. The ReAct-based Searcher alternates between generating reasoning traces and executing actions, facilitating seamless integration of internal knowledge with external tools (such as search engines) to enhance accuracy and user control. Experimental results show the framework’s effectiveness across multiple languages, achieving a 94.8% security rate on the SVEN dataset with CodeQL, outperforming existing approaches. Its transparent reasoning process fosters user trust and improves controllability.",
10.1109/IPDPSW66978.2025.00156,Towards Orchestrating Agentic Applications as FaaS Workflows,"Agentic applications consist of multiple agents that encapsulate tools that can be selected by an Large Language Model (LLM) to execute real-world tasks while also collaborating with other agents to solve complex applications, including scientific tasks. However, creating these agentic applications require substantial user effort, involving model selection, prompt engineering and guardrails. There are also limitation in deploying these applications on cloud platforms. In this early work, we take a step towards addressing these limitations by proposing an intuitive pattern comprising of a planner, executor, evaluator and judge agents to compose these as agentic workflows with simple prompt specifications. We also propose to model these as Function as a Service (FaaS) workflows on public/private clouds to simplify their deployment and outsourcing their orchestration. A preliminary implementation of our AgentX platform provides Python modules for these roles, which are used to compose AWS Step Functions. Our initial results on local machine and AWS using Open AI and Claude show promise in simpler compositions, but also expose challenges due to diverse behavior of LLMs. As future work, we will explore the use of our XFaaS hybrid cloud orchestration platform to deploy these on hybrid public/private clouds to leverage cost arbitrage, and offer flexible and automated selection of model to trade-off latency, accuracy and reliability.",
10.1109/IROS47612.2022.9981440,Learning Neuro-Symbolic Relational Transition Models for Bilevel Planning,"In robotic domains, learning and planning are complicated by continuous state spaces, continuous action spaces, and long task horizons. In this work, we address these challenges with Neuro-Symbolic Relational Transition Models (NSRTs), a novel class of models that are data-efficient to learn, compatible with powerful robotic planning methods, and generalizable over objects. NSRTs have both symbolic and neural components, enabling a bilevel planning scheme where symbolic AI planning in an outer loop guides continuous planning with neural models in an inner loop. Experiments in four robotic planning domains show that NSRTs can be learned very data-efficiently, and then used for fast planning in new tasks that require up to 60 actions and involve many more objects than were seen during training.",
10.1109/IROS47612.2022.9981488,A Hierarchical Deliberative Architecture Framework based on Goal Decomposition,"Performing a complex autonomous mission with a multi-robot system requires to integrate several deliberative approaches to perform task allocation, optimization, and execution control. Implementing such a deliberative architecture is a complex task: it requires the developer to master the decision algorithms themselves (e.g., automated planning models), to have a good knowledge of the involved robotic platforms, and to think about how these elements will be assembled as a system architecture. We propose a framework to help designing such deliberative architectures. The framework relies on the concept of a hierarchical structure of actors, each actor managing goals with specific planning or optimization approaches, and delegating sub-goals to other actors.",
10.1109/IROS51168.2021.9635941,Learning Symbolic Operators for Task and Motion Planning,"Robotic planning problems in hybrid state and action spaces can be solved by integrated task and motion planners (TAMP) that handle the complex interaction between motion-level decisions and task-level plan feasibility. TAMP approaches rely on domain-specific symbolic operators to guide the task-level search, making planning efficient. In this work, we formalize and study the problem of operator learning for TAMP. Central to this study is the view that operators define a lossy abstraction of the transition model of a domain. We then propose a bottom-up relational learning method for operator learning and show how the learned operators can be used for planning in a TAMP system. Experimentally, we provide results in three domains, including long-horizon robotic planning tasks. We find our approach to substantially outperform several baselines, including three graph neural network-based model-free approaches from the recent literature. Video: https://youtu.be/iVfpX9BpBRo. Code: https://git.io/JCT0g",
10.1109/IROS58592.2024.10801627,A Framework for Neurosymbolic Goal-Conditioned Continual Learning in Open World Environments,"In dynamic open-world environments, agents continually face new challenges due to sudden and unpredictable novelties, hindering Task and Motion Planning (TAMP) in autonomous systems. We introduce a novel TAMP architecture that integrates symbolic planning with reinforcement learning to enable autonomous adaptation in such environments, operating without human guidance. Our approach employs symbolic goal representation within a goal-oriented learning framework, coupled with planner-guided goal identification, effectively managing abrupt changes where traditional reinforcement learning, re-planning, and hybrid methods fall short. Through sequential novelty injections in our experiments, we assess our method's adaptability to continual learning scenarios. Extensive simulations conducted in a robotics domain corroborate the superiority of our approach, demonstrating faster convergence to higher performance compared to traditional methods. The success of our framework in navigating diverse novelty scenarios within a continuous domain underscores its potential for critical real-world applications. © 2024 IEEE.",
10.1109/IROS58592.2024.10801900,Behavior Tree Based Decentralized Multi-agent Coordination for Balanced Servicing of Time Varying Task Queues,"In this article, we present a reactive multi-agent coordination architecture for the management of material flows between production/pickup stages and delivery/drop-off stages, in scenarios such as underground mines and automated factory floors. The pickup and delivery stages are modelled as variable task queues, with no a priori information about the inflow into the production queues. The proposed solution coordinates the movement of a group of mobile agents operating between the two stages in a reactive and scalable manner, so that the material is transported from multiple production queues to multiple delivery queues in a balanced/equalized manner. In such a scenario, centralized planners suffer from low reactivity and poor scaling, as the number of agents and number of queues increases. To overcome this problem, we propose a decentralized approach comprising of two separate auction-based task distribution systems for the production and delivery stages, along with behavior-tree based management of agent autonomy and task bidding. Each auction system tracks the length of production/delivery queues and solves the optimal task assignment, based on the bids submitted by the agents. The agents participate in one of the two auction systems at any given time, based on the status of the behavior tree executing the two-stage tasks. We analytically show that the proposed decentralized auctioning approach along with agent autonomy and bidding managed by behavior trees, offers better scalability and reactiveness compared to the centralized approach. The proposed methodology is experimentally validated in a lab environment, in three illustrative material flow management scenarios, using TurtleBot3 robots as agents.",
10.1109/ISGTEurope52324.2021.9639918,Centralized/Decentralized Power Management Strategy for the Distribution Networks based on OPF and Multi-Agent Systems,"This paper proposes a two-stage strategy to enhance the performance of active distribution network (ADN) by optimally controlling the active/reactive power of the distributed generation (DG) to improve the power quality while maintaining the network constraints within the allowable limits. The proposed stages are executed in two-time frames: operational planning and real-time operation. The first stage is a centralized control implemented using optimal power flow (OPF) via particle swarm optimization to dispatch the DGs active/reactive power to minimize the real losses. In the second stage, a decentralized architecture of intelligent agents is proposed using Multi-Agent System (MAS) developed in Java Agent Development Framework (JADE) to manage the network by ensuring that the difference between the power generated from DGs and power consumed by loads is preserved in each zone until the OPF is implemented again in next timestep. To validate the proposed strategy, the IEEE 33-bus distribution network has been used and the results proved the efficacy of the proposed strategy in enhancing the performance and operation of ADNs.",
10.1109/ISGTEUROPE62998.2024.10863570,Crossover-BPSO Driven Multi-Agent Technology for Managing Local Energy Systems,"This article presents a new hybrid algorithm, crossover binary particle swarm optimization (crBPSO), for allocating resources in local energy systems via multi-agent (MA) technology. Initially, a hierarchical MA-based architecture in a grid-connected local energy setup is presented. In this architecture, task specific agents operate in a master-slave manner. Where, the master runs a well-formulated optimization routine aiming at minimizing costs of energy procurement, battery degradation, and load scheduling delay. The slaves update the master on their current status and receive optimal action plans accordingly. Simulation results demonstrate that the proposed algorithm outperforms selected existing ones by 21% in terms average energy system costs while satisfying customers’ energy demand and maintaining the required quality of service.",
10.1109/ISIE45063.2020.9152210,Survey on Security Concepts to Adapt Flexible Manufacturing and Operations Management based upon Multi-Agent Systems,"The increasing digitalization brings new opportunities but also puts new challenges to modern industrial systems. Software agents are one of the key technologies towards self-optimizing factories and are currently used to address the needs of cyber-physical production systems (CPPS). However their interplay in industrial settings needs to be understood better.This paper focusses on securing a cloud infrastructure for multi-agent systems for industrial sites. An industrial site contains multiple production processes that need to communicate with each other and each physical resource is abstracted with a software agent. This volatile architecture needs to be managed and protected from manipulation. The proposed infrastructure presents a security concept for TCP/IP communication between agents, machines, and external networks. It is based on open-source software and tested on a three-node edge cloud controlling a model-plant.",
10.1109/ISoIRS65690.2025.11168047,Research on Task Planning Methods for Embodied Intelligence Based on Large Language Models,"Embodied intelligence, as an interdisciplinary frontier that integrates artificial intelligence and robotics, relies fundamentally on robust task planning capabilities to enable autonomous decision-making in dynamic and complex environments. This paper systematically reviews the methods of embodied intelligence task planning that are grounded in large language models (LLMs), conducting a comprehensive multidimensional analysis across theoretical frameworks, technical pathways, and multi-agent collaboration dynamics. The study reveals that LLMs, through their advanced mechanisms of natural language comprehension, multimodal fusion, and dynamic reasoning, effectively address the inherent limitations of conventional rule-based systems in terms of flexibility, adaptability, and interactivity. The array of single-agent strategies, which encompasses end-to-end planning, phased planning, and dynamic planning, along with the diverse multi-agent collaborative frameworks involving centralized, distributed, and hybrid architectures, collectively establish novel paradigms for task decomposition and execution in intricate real-world scenarios. Furthermore, the paper critically examines key challenges like logical consistency, energy efficiency, and safety verification that impede the widespread use of LLM-based systems, while proposing future directions such as neuro-symbolic hybrid architectures and lightweight model optimization to boost practicality. Notably, these advancements not only strengthen the technical foundations of embodied intelligence but also facilitate smoother integration of intelligent agents into daily life and industrial environments.",
10.1109/ISSE63315.2024.10741086,Emergent Structure in Multi-agent Systems Using Geometric Embeddings,"This work investigates the self-organization of multi-agent systems into closed trajectories, a common requirement in unmanned aerial vehicle (UAV) surveillance tasks. In such scenarios, smooth, unbiased control signals save energy and mitigate mechanical strain. We propose a decentralized control system architecture that produces a globally stable emergent structure from local observations only; there is no requirement for agents to share a global plan or follow prescribed trajectories. Central to our approach is the formulation of an injective virtual embedding induced by rotations from the actual agent positions. This embedding serves as a structure-preserving map around which all agent stabilize their relative positions and permits the use of well-established linear control techniques. We construct the embedding such that it is topologically equivalent to the desired trajectory (i.e., a homeomorphism), thereby preserving the stability characteristics. We demonstrate the versatility of this approach through implementation on a swarm of Quanser QDrone quadcopters. Results demonstrate the quadcopters self-organize into the desired trajectory while maintaining even separation.",
10.1109/ITECAsia-Pacific63159.2024.10738543,Electric Vehicle Charging Guidance Strategy Based on Hierarchical Multi-Agent Deep Reinforcement Learning,"To address effectively the stochastic charging demand of electric vehicles, this paper proposes a charging guidance strategy for electric vehicles based on hierarchical multi-agent deep reinforcement learning. This strategy refines the charging guidance task into a double-layer finite Markov decision process for the complex feature information in the coupled system of electric vehicles, charging stations, and transportation networks. In this architecture, the upper network adopts a centralized learning and decentralized execution strategy, and each electric vehicle is regarded as an independent agent. These agents cooperate in diverse incentives and competitive environments to jointly recommend the best charging station locations. At the same time, the action decision outputs of the upper network are integrated into the state considerations of the lower multi-agents. The lower network adopts the same solution method as the upper network, and the lower multi-agent plans the optimal driving paths based on the latest EV and traffic network states after receiving the upper decision. Further, a multi-agent hybrid Q learning algorithm is introduced to solve the problem, and constraints are imposed on the agent rewards to guide the multi-agent learning. Finally, simulation results validate that the proposed strategy enhances electric vehicle charging efficiency and promotes efficient road network operation.",
10.1109/ITNT52450.2021.9649143,Intelligent System for Adaptive Planning of Targeted Application of Advanced Space Systems for Earth Remote Sensing,"The author has developed an intelligent system for adaptive planning of targeted application of advanced space systems for Earth remote sensing, which is based on the expanded use of the multi-agent approach to managing resources of complex systems. The key concept in this approach is assigning an intelligent software agent to each application for imaging the object of observation. The agent’s goal is to occupy the most advantageous placement in the schedule synthesized in accordance with a variety of optimization criteria. The problem solution is obtained as a result of reaching a consensus in numerous negotiations between agents. Application of this approach to resource management of a space observation system helps quickly draw up the imaging schedule for dozens of satellites and ground stations, as well as thousands of observation objects. The paper provides a brief problem statement and a description of the proposed approach to scheduling applications entering the system. The system architecture with a description of the main services is also proposed. Furthermore, the paper describes results obtained in experimental studies and prospects for further development.",
10.1109/ITNT57377.2023.10139177,Development of a digital twin of plant based on the principles of emergent intelligence,"The paper discusses development of a smart digital twin of plants (DTP) based on the principles of emergent intelligence. The described methodology is part of the approach proposed by the authors earlier. It proposes implementation of a smart DTP as a multilevel complex adaptive system with the use of ontologies and multi-agent technologies. Models for interaction between agents of plant parts and subsystems can provide more accurate planning of each stage of plant growth. The paper describes the architecture of the DTP prototype, as well as a scenario of an experiment with it. Development of methodology will improve the accuracy of real plant simulation and simplify scaling of the system when developing ontological models of new crops.",
10.1109/ITNT60778.2024.10582352,Multiparametric Variety Models in Digital Twin of Plant for Winter Wheat,"The article describes the development of variety models for winter wheat varieties for the digital twin of plants - software for production process simulation of crops based on environmental factors and agronomic characteristics of the crops. Based on the previously developed ontology of crop cultivation, which describes the fundamental concepts and relationships of the production process for any crop, this article provides a description and principles of variety models of winter wheat. These models take into account the genetic characteristics influencing plants under different factors, as well as the specifics of their development, enabling the calculation of an expanding set of parameters for each phenological stage of the wheat crop. The application of such variety models is able due to the existing architecture of the multi-agent model of the digital twin of plants (DTP) and significantly expands the scope and functionality of DTP in terms of predicting the state of crops. Specific parameters of the variety model for the winter wheat variety “Viyuga” are provided, which estimates susceptibility of this variety to various factors. The results of developing variety models are presented, and the prospects for their further application in the DTP are discussed.",
10.1109/ITSC55140.2022.9922515,An Enhanced Graph Representation for Machine Learning Based Automatic Intersection Management,"The improvement of traffic efficiency at urban intersections receives strong research interest in the field of automated intersection management. So far, mostly non-learning algorithms like reservation or optimization-based ones were proposed to solve the underlying multi-agent planning problem. At the same time, automated driving functions for a single ego vehicle are increasingly implemented using machine learning methods. In this work, we build upon a previously presented graph-based scene representation and graph neural network to approach the problem using reinforcement learning. The scene representation is improved in key aspects by using edge features in addition to the existing node features for the vehicles. This leads to an increased representation quality that is leveraged by an updated network architecture. The paper provides an in-depth evaluation of the proposed method against baselines that are commonly used in automatic intersection management. Compared to a traditional signalized intersection and an enhanced first-in-first-out scheme, a significant reduction of traversal duration is observed at varying traffic densities. Finally, the generalization capability of the graph-based representation is evaluated by testing the policy on intersection layouts not seen during training. The model generalizes virtually without restrictions to smaller intersection layouts and within certain limits to larger ones.",
10.1109/ITSC58415.2024.10919634,Mars Planner: Improved Batch Spatio-Temporal Path Planning for Multi-Ackerman Robotic Systems,"This paper introduces an innovative multi-agent path finding (MAPF) system specifically designed for navigating multi-Ackerman robotic systems in intricate environments. The Mars Planner, the proposed solution, enhances path planning by tackling collision-free path challenges encountered by groups of intelligent agents. Our contributions include the development of two key algorithms: the Fast Batch Path Finding (FBPF) and the Batch Spatio-Temporal Path Refinement (BSTPR). FBPF utilizes a hybrid A* approach to generate preliminary coarse paths within free configuration spaces, while BSTPR refines these paths using topological homotopy strategies to optimize time allocation and effectively resolve internal conflicts. Through simulations and physical experiments, we demonstrate significant enhancements in computational efficiency and path quality compared to existing methods. In conclusion, the Mars Planner stands as an efficient solution capable of managing large-scale complexity in real-world applications. It offers a robust and scalable framework suitable for diverse environments and scenarios.",
10.1109/ITSC58415.2024.10919719,TASF: Terrestrial-Aerial Synergistic Framework for a New Generation of Intelligent Transportation,"Terrestrial-Aerial Synergistic Framework (TASF) represents a novel approach to intelligent transportation, integrating terrestrial and aerial vehicles to enhance urban transportation efficiency and capacity. In this paper, we offer an in-depth analysis of TASF, emphasizing its innovative applications in urban transportation, parcel delivery, and emergency response services. TASF incorporates a five-layer architecture comprising perception, communication, planning, control, and interaction. With the five-layer architecture, TASF can achieve effective collaboration among terrestrial and aerial vehicles, encompassing two principal features: terrestrial-aerial synergistic parallel perception and multi-agent parallel management. Parallel perception results from fusing Bird's Eye View (BEV) representations from Unmanned Aerial Vehicles (UAVs) and Unmanned Ground Vehicles (UGVs), whereas decentralized multi-agent management employs foundational models to enhance decision-making capabilities. Additionally, we consider challenges and potential solutions related to TASF, including safety, reliability, energy efficiency, management and integration. TASF marks a paradigm-shifting leap in the realm of intelligent transportation systems, providing a scalable and efficacious solution tailored to the dynamic requirements of urban mobility and emergency services.",
10.1109/IUCC65928.2024.00072,Verify-Agent: Large Language Model Multi-Agent for Intelligent Verification,"An AI agent is an intelligent framework that can perceive, plan and decompose, perform actions, and reflect. The multi-agent mode is a distributed computing mode that collaborates to complete different tasks in a group of AI intelligent agent environments. After discussion, inspection, reasoning, and evaluation, accurate conclusions are drawn. Multi AI intelligent agents play a crucial role in enhancing the performance of large models. Research and optimization of multi-agent architecture provide more perspectives and insights for system architecture design. In network planning, there are various application scenarios for reviewing planning template documents. This paper studies a multi-agent architecture based on open-source large language models, which is applied to planning document templates and data review to enhance the efficiency of processing and analyzing.",
10.1109/LRA.2022.3190076,"SGL: Symbolic Goal Learning in a Hybrid, Modular Framework for Human Instruction Following","This paper investigates human instruction following for robotic manipulation via a hybrid, modular system with symbolic and connectionist elements. Symbolic methods build modular systems with semantic parsing and task planning modules for producing sequences of actions from natural language requests. Modern connectionist methods employ deep neural networks that learn visual and linguistic features for mapping inputs to a sequence of low-level actions, in an end-to-end fashion. The hybrid, modular system blends these two approaches to create a modular framework: it formulates instruction following as symbolic goal learning via deep neural networks followed by task planning via symbolic planners. Connectionist and symbolic modules are bridged with Planning Domain Definition Language. The vision-and-language learning network predicts its goal representation, which is sent to a planner for producing a task-completing action sequence. For improving the flexibility of natural language, we further incorporate implicit human intents with explicit human instructions. To learn generic features for vision and language, we propose to separately pretrain vision and language encoders on scene graph parsing and semantic textual similarity tasks. Benchmarking evaluates the impacts of different components of, or options for, the vision-and-language learning model and shows the effectiveness of pretraining strategies. Manipulation experiments conducted in the simulator AI2THOR show the robustness of the framework to novel scenarios.",
10.1109/LRA.2025.3627381,VLM-SFD: VLM-Assisted Siamese Flow Diffusion Framework for Dual-Arm Cooperative Manipulation,"Dual-arm cooperative manipulation holds great promise for tackling complex real-world tasks that demand seamless coordination and adaptive dynamics. Despite substantial progress in learning-based motion planning, most approaches struggle to generalize across diverse manipulation tasks and adapt to dynamic, unstructured environments, particularly in scenarios involving interactions between two objects such as assembly, tool use, and bimanual grasping. To address these challenges, we introduce a novel VLM-Assisted Siamese Flow Diffusion (VLM-SFD) framework for efficient imitation learning in dual-arm cooperative manipulation. The proposed VLM-SFD framework exhibits outstanding adaptability, significantly enhancing the ability to rapidly adapt and generalize to diverse real-world tasks from only a minimal number of human demonstrations. Specifically, we propose a Siamese Flow Diffusion Network (SFDNet) employs a dual-encoder-decoder Siamese architecture to embed two target objects into a shared latent space, while a diffusion-based conditioning process—conditioned by task instructions—generates two-stream object-centric motion flows that guide dual-arm coordination. We further design a dynamic task assignment strategy that seamlessly maps the predicted 2D motion flows into 3D space and incorporates a pre-trained vision-language model (VLM) to adaptively assign the optimal motion to each robotic arm over time. Experiments validate the effectiveness of the proposed method, demonstrating its ability to generalize to diverse manipulation tasks while maintaining high efficiency and adaptability.",
10.1109/MED61351.2024.10566142,Local Bidding Strategies for Reactive and Scalable Auction-Based Multi-Agent Coordination,"This article proposes local bidding strategies for autonomous agents participating in an auction-based multi-agent coordination system, in order to improve the scalability and reactivity of the architecture in large-scale coordination scenarios. Based on a careful analysis of the reactivity requirements and the computational costs of the central auctioneer (costs for solving Linear Integer Programs) and the local agents (costs for path-planning and task execution), this article explores the idea of each agent bidding for a subset of available tasks that are locally relevant to the agent. Each agent first employs a computationally light euclidean distance-based and percentile-based screening method to choose a subset of available tasks, followed by a more computationally complex, but realistic path-planning based cost-estimation and bidding for the chosen subset. The proposed strategy not only reduces the overall computational cost at the agents, but also at the central auctioneer, by reducing the size of the combinatorial optimization problems and the overall communication requirements of the architecture, thereby improving the scalability and reactivity of the overall system. It is shown that, through a one-time simulation-guided design of the bidding parameters, the improved reactivity and scaling is achieved while retaining the optimality or near-optimality of the resulting task-allocation. The performance of the proposed bidding strategies is evaluated in two large-scale simulation scenarios and the reduction in computational costs and the near-optimality of the task allocation is demonstrated.",
10.1109/MELECON53508.2022.9843001,Designing a Testing Environment for the CAPABLE Telemonitoring and Coaching Platform,"The CAPABLE project has been funded by the European Union to develop a telemonitoring and coaching platform improving the quality of life for cancer patients. The platform, based on a multi agent blackboard architecture, is classified as a medical device according to the current EU regulation. Thus it needs extensive tests before being put into service for the planned clinical trials, which calls for a dedicated simulating and testing environment. Materials and Methods: Coordination in CAPABLE is achieved through the Case Manager, a component able to generate and notify events to other interested agent components. For representing and exchanging health care information we have adopted HL7 FHIR as a semantic interoperability standard. Results: FHIR has been exploited to design a structured history of a real patient affected by renal cell carcinoma. A simulator has been developed for automating the whole testing process represented by specific scenarios of the patient’s history. Conclusions: The simulator relies on the events produced by the Case Manager for coordinating the agents. This proved to be effective in checking that the agents reactions to new data showing up on the blackboard comply with the expected behavior.",
10.1109/MetroAgriFor52389.2021.9628826,farMAS: Multi-Agent based farm activity planning and execution system,"Based on a conceptual model and ontology of a farm, this paper describes a multi-agent architecture for operations management activities (both planning and execution). The approach focusses on the identification of the relevant actors, their roles and the relationship between actors and defines the interactions to support the implementation of an experimental simulator. Cooperative interaction is ensured by governing decision policies, and by considering the farmers expertise in strategical and tactical decisions.The adoption of farMAS is expected to make farming operations more sustainable by helping to use resources efficiently even in particular challenging situations like extreme weather phenomena, the introduction of new, stress-tolerant crop varieties, more controlled use of pesticides, employment of advanced sensing technologies, sharing of farming equipment, the processing of the data obtained with the latter, and the near real-time reaction to it.",
10.1109/MITP.2025.3532388,Bridging the Gap: The Rise of Neurosymbolic Artificial Intelligence in Advanced Computing,"Neurosymbolic artificial intelligence (AI) has emerged as a transformative approach, integrating the reasoning capabilities of symbolic AI with the data-driven nature of neural networks. This article discusses the evolution of AI, identifying the distinct advantages and limitations of symbolic and deep learning methodologies. Neurosymbolic AI aims to leverage the strengths of both approaches to enhance decision-making transparency and efficiency, which are crucial in high-stakes domains like health care and law. We explore techniques like embedding symbolic reasoning within neural architectures and utilizing neural networks for feature extraction. These strategies enable the application of neurosymbolic AI across various sectors, including health-care diagnostics, automated financial advising, and robotics. Case studies demonstrate its potential in improving diagnosis accuracy, ensuring regulatory compliance in finance, and enabling adaptive responses in robotics. The article concludes by highlighting emerging trends that are aimed at refining the interaction between neural and symbolic components, fostering more robust and versatile AI applications. © 2025 IEEE.",
10.1109/MLISE66443.2025.11100192,Advancements in SQL Query Optimization: A Review of Join Order and Index Selection,"Efficient SQL Query Optimization (QO) is a fundamental aspect of database management systems, aimed at enhancing query performance and reducing resource consumption typically involves selecting the most efficient execution plan for a given query, considering factors such as join order, access methods, and the use of indexes. This review paper focuses on two key agents in SQL QO: the Join Order Agent (JOA) and the Index Selection Agent (ISA). The JOA seeks to determine the optimal sequence for joining multiple tables, minimizing intermediate results and improving query execution time. The ISA identifies the most effective indexes to speed up data retrieval, considering various database schema configurations and query patterns. We review existing approaches for both agents, including heuristic-based methods, cost-based models, and machine learning (ML) techniques. The paper also highlights the challenges faced in these areas, such as the scalability of existing methods, the need for dynamic adaptation to changing workloads, and the integration of multiple optimization strategies. Finally, the paper discusses how multi-agent systems (MAS), and hybrid optimization techniques can address these challenges, offering significant improvements in QO for modern relational DBMS.",
10.1109/MMAR49549.2021.9528474,A Novel Software Architecture of Anticipatory Harvesting Robot Teams,"This paper presents a novel application of anticipatory coordination and optimization principles, previously developed for autonomous inspection robot teams. The core tenet behind our research is to build a team of agile and relatively small robots, each equipped with two synergistically operating robotic arms, one arm with a soft gripper, the other arm with a set of cameras and a fruit cutting mechanism, all controlled by innovative anticipatory network (AN) algorithms. This allows the plantation management to efficiently supervise the team, coordinated and optimized by an adaptive anticipatory decision engine. Another key component of the robotic software architecture that allows the team of robots to efficiently harvest soft fruits such as strawberries or raspberries is a package of information fusion algorithms in the world model, associated with a knowledge base and a digital twin of the cover crops. We will show that AN coordination principles ensure the reliable operation of robots in case of communication disturbances or when uncertain or incomplete instructions are entered by the operator in the management and supervision system. The flexible design of the overall robotic architecture will make it possible to further develop the robot teams to respond to additional needs such as harvesting other fruits and working in various horticultural environments.",
10.1109/MNET.2025.3579680,Generative AI-Enhanced Neuro-Symbolic Quantum Architectures for Secure Communications and Networking,"The rapid convergence of generative AI (GAI), neuro-symbolic reasoning, and quantum computing has redefined secure communication and networking. Owing to the massive amounts of data, the need for extensive computing power, and the necessity to find and mitigate threats in real-time, traditional security measures cannot keep up with changing cyber threats as the communication infrastructure becomes more complicated. Therefore, this paper investigates the potential of a GAI-enhanced neuro-symbolic quantum framework for building security systems that are strong, scalable, and self-sufficient. This method improves threat detection, encryption, and real-time adversarial defense by combining symbolic reasoning for logic, deep learning for pattern recognition, and quantum intelligence to accelerate computations. This work has made progress in creating the next generation of secure networks that can automatically and adaptively make security decisions in real-time, providing robust protection in communication environments that change over time. © 1986-2012 IEEE.",
10.1109/NICE65350.2025.11065704,A Grid Cell-Inspired Structured Vector Algebra for Cognitive Maps,"The entorhinal-hippocampal formation is the mammalian brain's navigation system, encoding both physical and abstract spaces via grid cells. This system is well-studied in neuroscience, and its efficiency and versatility make it attractive for applications in robotics and machine learning.While continuous attractor networks (CANs) successfully model entorhinal grid cells for encoding physical space, integrating both continuous spatial and abstract spatial computations into a unified framework remains challenging. Here, we attempt to bridge this gap by proposing a mechanistic model for versatile information processing in the entorhinal-hippocampal formation inspired by CANs and Vector Symbolic Architectures (VSAs), a neuro-symbolic computing framework. The novel grid-cell VSA (GC-VSA) model employs a spatially structured encoding scheme with 3D neuronal modules mimicking the discrete scales and orientations of grid cell modules, reproducing their characteristic hexagonal receptive fields.In experiments, the model demonstrates versatility in spatial and abstract tasks: (1) accurate path integration for tracking locations, (2) spatio-temporal representation for querying object locations and temporal relations, and (3) symbolic reasoning using family trees as a structured test case for hierarchical relationships. © 2025 IEEE.",
10.1109/NMITCON65824.2025.11187968,An Open VLA Powered Robot with ROS2 for Autonomous Elder Care Assistance,"This paper presents a novel robotic system leveraging Vision-Language-Action (VLA) models and ROS2 to autonomously address key needs in eldercare settings. The system interprets spoken commands through OpenAI's Whisper for realtime speech-to-text conversion and SpaCy for natural language understanding, detects objects via a Logitech webcam integrated with the PaliGemma vision-language model, and estimates spatial relationships using Intel's MiDaS monocular depth estimation algorithm. The robotic manipulation subsystem employs MoveIt2 for motion planning and a suction-based end effector for secure grasping, all orchestrated through a modular ROS2 architecture running on an NVIDIA Jetson AGX Orin platform. Experimental evaluations demonstrate a 90.2% task completion rate, 95.3% object detection accuracy, and 2.8-second average response latency across 150 trials with common eldercare objects. This work demonstrates the viability of edge-deployed VLA models for eldercare applications, offering a practical approach to enhancing independence through intuitive, voice-activated robotic assistance.",
10.1109/NOMS57970.2025.11073647,Multi-Agentic Plan-and-Solve Engine for Managing System of Systems via Natural Language,"The management of complex Systems of Systems (SoS) often requires interacting with a variety of heterogeneous user interfaces and APIs across different components. This task becomes especially challenging when trying to dynamically manage resources real-time. In this paper, we propose a novel multi-agent architecture for an intent based solver engine, which leverages Large Language Models (LLMs) to facilitate system management via natural language interactions. Our engine utilizes multiple LLM agents to autonomously plan and execute user-intended tasks across various RESTful microservices, such as querying data or modifying system resources. The architecture is designed to support multimodal user input, offering transparency and explainability by allowing users to review and modify plans and workflow steps during execution. This approach combines LLM reasoning capabilities, prompt engineering, and multi-agentic patterns to automate decision-making while ensuring a high level of control for the user. The paper details the architecture and reference implementation of the proposed engine and showcases its capabilities through a practical use case.",
10.1109/OCEANS58557.2025.11104515,iCADME: A Modular Autonomy Architecture for Robotic Heterogeneous Networks in Communication-Limited Environments,"Autonomy and cooperation are essential features in robotic networks, especially in the underwater domain where communications are severely limited. Robots should be able to carry out any assigned task autonomously, yet cooperate with other robots when allowed to by the environmental conditions. To enable this, there is a growing interest in robotic software solutions which are modular, scalable and easy to test. In this paper, we introduce iCADME, a novel autonomy architecture, which achieves such features thanks to a software eco-system which relies on a hierarchy of tasks, in charge of perception and decision-making, and of behaviour strategies, which act as the interface towards the robot lower level control architecture. The modularity and the attention to the system configuration are instrumental for the user to reuse the software and to expand the task portfolio. Thanks to the strong decoupling between perception/decision-making and action, achieved also with the design of an interface layer with the external middleware, iCADME can be easily integrated with various planning and control systems and with different middleware software. On top of that, a behaviour trees (BTs) mission management system is introduced. BTs enable the building of complex missions by assembling a portfolio of tasks, with features of high modularity and reactivity. All these iCADME's features were succesfully tested during MEDASWAN23 trial. They are a step forward towards the actual use in the field of increasingly cooperative robotic networks.",
10.1109/PESGM48719.2022.9916732,Efficient Bidding of a PV Power Plant with Energy Storage Participating in Day-Ahead and Real-Time Markets Using Artificial Neural Networks,"This paper proposes the use of Artificial Neural Networks (ANN) for the efficient bidding of a Photovoltaic power plant with Energy Storage System (PV-ESS) participating in Day-Ahead (DA) and Real-Time (RT) energy and reserve markets under uncertainty. The Energy Management System (EMS) is based on Multi-Agent Deep Reinforcement Learning (MADRL). The MADRL scheme aims to maximize the profit of the hybrid PV-ESS plant through an efficient bidding in both markets. Results show that the MADRL framework can fulfill both the financial and physical constraints faced by the PV-ESS plant while providing energy and ancillary services. Daily market incomes have comparable mean values regarding traditional optimization approaches (average value of 1839 USD), but with a 45.3% smaller variance. Furthermore, it maintains a reference-tracking performance of 86.63% for one-year-round participation, against a 73.05% and 79.13% performance obtained with scenario-based robust and stochastic programming implementations, respectively.",
10.1109/PIMRC59610.2024.10817447,Joint Communication-Motion Planning for UAV Swarm against Jamming with Multi-Agent Deep Reinforcement Learning,"In this paper, we investigate the joint communication-motion planning problem for unmanned aerial vehicle (UAV) swarm in the presence of jammers. Specifically, we consider a cluster-based UAV swarm architecture, where multiple cluster member (CM) UAVs transmit messages to a cluster head (CH) UAV through air-to-air links affected by malicious jammers. Our objective is to maximize the sum uplink rate of the UAV swarm by optimizing the trajectories and the transmit power of all UAVs. To achieve this goal, we formulate a joint multi-UAV trajectories and transmit power optimization problem under speed, transmit power, trajectories and received signal-to-interference-plus-noise ratio (SINR) constraints. In order to solve the problem, we establish a Markov decision process (MDP). For the multi-agent environment and the high-dimensional continuous action space, we adopt a multi-agent twin delayed deep deterministic (MATD3) policy gradient-based algorithm. Simulation results show that the proposed scheme can effectively improve the sum uplink rate of the UAV swarm compared to the baseline schemes.",
10.1109/PSGEC66102.2025.11150990,Mingyue: A Multi-Agent System for Human-AI Collaborative Decision-Making Under Safety Constraints in Complex Power Grids,"To address the conflict between the high complexity and uncertainty of modern power systems and the extreme safety requirements for dispatch decision-making, this paper introduces ‘Mingyue,’ a multi-agent system for human-AI collaborative decision-making. Traditional dispatch methods rely on manual experience, which is inefficient and prone to errors. Conversely, applying general artificial intelligence, such as large language models (LLMs), directly to this safety-critical domain poses fundamental risks of factual hallucination and unreliable actions. The Mingyue system overcomes these challenges through three key innovations: 1) A unified knowledge representation framework for power dispatch that transforms vast, heterogeneous domain knowledge (e.g., regulations, case studies, and operational procedures) into a machine-readable and traceable knowledge base, providing a reliable foundation for all decisions. 2) A decoupled ‘Intent-Plan-Tool’ architecture that leverages LLMs for task planning while invoking a deterministic professional toolset for execution, fundamentally isolating the non-deterministic nature of AI from the precise control required in the physical world. 3) A hierarchical multi-agent collaborative mechanism for complex dispatch workflows, which automates end-to-end tasks through the coordination of specialized agents (e.g., safety supervision, decision-making, and operation agents). The system has been deployed in the Guangdong power grid, the world's largest provincial grid. Experimental results show that compared to traditional manual modes and standalone AI tools, Mingyue improves efficiency by over 85 % in key tasks such as risk analysis, emergency response, and operational ticket generation, significantly enhancing the safety and intelligence of power grid operations.",
10.1109/RAIIE65740.2025.11140070,Embodied AI: Bridging Simulation and Reality in Robotics,"This paper presents a comprehensive review of simulation-to-reality (Sim2Real) transfer techniques in the context of embodied artificial intelligence (embodied AI). Embodied AI refers to artificial intelligence systems that interact with the environment through a physical or virtual body (e.g., robots, virtual agents), enabling perception, decision-making, and action in real or simulated spaces. We focus on their applications in robotic learning and control. By critically comparing the capabilities of mainstream simulation platforms such as Habitat and Isaac Gym, the study identifies core trade-offs between physical realism and computational efficiency. It further analyzes transfer methodologies, including domain randomization, domain adaptation, and hybrid techniques, highlighting their effectiveness and limitations in dynamic and unstructured environments. The review also investigates the emerging role of large multimodal models, such as PaLM-E and RT-2, in bridging semantic understanding with robotic action. While these models offer significant improvements in generalization and task planning, challenges remain in achieving real-time performance and physical grounding. The findings suggest that simulation fidelity alone does not guarantee successful transfer, hybrid transfer methods outperform single-strategy approaches in complex settings, and large language models hold promise for enhancing robot intelligence but must be optimized for embedded deployment. This study offers practical insights for developing scalable and cost-effective Sim2Real pipelines in industrial applications such as autonomous navigation and robotic manipulation. It further outlines future directions in edge computing, lightweight modeling, and ethics-aware simulation, promoting the integration of physics-aware AI in real-world robotic systems.",
10.1109/RAIIE65740.2025.11140132,Design and Experimental Study of a Parallel RHCR Algorithm for Real-Time Multi-Agent Scheduling,"With the continuous expansion of multi-agent systems, path planning is increasingly challenged by high agent density, dynamic task arrivals, and real-time responsiveness. The Rolling Horizon Collision Resolution (RHCR) algorithm demonstrates strong adaptability in dynamic scheduling scenarios due to its local replanning strategy and path stability. However, its current serial architecture limits scalability and computational efficiency in large-scale environments. To address this bottleneck, this paper proposes a parallel optimization framework for RHCR, incorporating multi-threaded path replanning and parallel conflict detection to enhance overall planning performance and system scalability. A modular parallel architecture is designed and implemented, and extensive simulation experiments are conducted. The results show that the proposed algorithm significantly outperforms traditional approaches in terms of planning time, path quality, and system throughput, demonstrating strong practical value and promising potential for future research.",
10.1109/REW66121.2025.00038,Generating Context-Aware Learning Materials for Software Security via LLM Agents and Traceability,"This paper presents a prototype that embeds security-focused, contextualised learning directly into the software-development workflow. By using trace links which already bind security standards, risk analyses, and vulnerability scan results. The prototype takes advantage of a multi-agent AI architecture to turn a security problem description and trace links from real life cases from a company into tailored learning material, lesson plans, and multimedia examples. This design positions real-life evidence at the centre of instruction and shows how LLMs can scale high-quality security training across projects. Questionnaire studies with professional developers reveal the educational impact of the LLM-generated learning material. Participants improved significantly between pre- and post-report assessments, with statistical tests confirming the gains. Furthermore, the learning material was subjectively rated above expert-written equivalents for clarity and relevance by questionnaire participants. Perceived quality correlated with actual learning, underscoring the pedagogical soundness of the contextualised, LLM generated content. Finally, we discuss the potential for integrating such adaptive, trace-link powered training examples into everyday development practices and suggest a portable framework for broader industrial adoption.",
10.1109/RO-MAN50785.2021.9515543,The Director Task: a Psychology-Inspired Task to Assess Cognitive and Interactive Robot Architectures,"Assessing robotic architecture for Human-Robot Interaction can be challenging due to the number of features a robot has to endow to perform an acceptable interaction. While everyday-inspired tasks are interesting as reflecting a realistic use of such robots, they often contain a lot of unknown and uncontrolled conditions and specific robot behavior can be hard to test. In this paper, we propose a new psychology-inspired task, gathering perspective-taking, planning, knowledge representation with theory of mind, manipulation, and communication. Along with a precise description of the task allowing its replication, we present a cognitive robot architecture able to perform it in its nominal cases. We finally suggest some challenges and evaluations for the Human-Robot Interaction research community, all derived from this easy-to-replicate task.",
10.1109/RO-MAN57019.2023.10309517,Nice and Nasty Theory of Mind for Social and Antisocial Robots,"The objective of this work is to develop computational cognitive models embedded in a humanoid robot. We focus on Dark Triad constructs and the so-called “Nice and Nasty” Theory of Mind that have never been investigated through a robotic approach. To this end, DT and ToM conceptual models in psychology have been taken as a reference for developing a framework based on the popular PDDL planning language. Next, a cognitive architecture has been implemented on a humanoid robot, with the final objective of making adverse personalities emerge. The motivations of the present work are both theoretical and practical. On the one side, we aim to provide researchers with new insights into DT constructs through simulated and robotic setups. On the other side, we aim to provide a tool to train psychologists to deal with social and antisocial behaviour in a controlled setup. The article includes all the details about the model and the experiments performed.",
10.1109/ROBIO64047.2024.10907494,LAC: Using LLM-based Agents as the Controller to Realize Embodied Robot,"The rapid development of Large Language Models (LLMs) facilitates the application of robotics, especially for robotic control. LLM-based robots are a way to realize embodied intelligence, but they still lack a general control paradigm to achieve embodied robot. We propose LAC (LLM-based Agents as the Controller), a new formulation to enable embodied robots to autonomously react to high-level tasks like humans. Specifically, the controller in LAC is LLM-based agents that can plan, decompose tasks and make decisions based on linguistic input. Two agents operate in parallel within the controller to replicate both instinctive reaction and deep consideration. The output of the controller consists of linguistic parameters that activate task-specific tools, enabling autonomous execution of low-level actions. LAC translates multi-modal feedback information into linguistic messages, which are then transmitted back to the controller to establish a closed-loop control flow. Once equipped with appropriate tools, the proposed LAC can be applied across various applications. A straightforward simulated office task, TASK0, illustrates the successful completion of the embodied task by LAC. Furthermore, testing five comparative LLMs on TASK0 also demonstrates that LAC serves as a potential test platform for validating the capability of LLMs to function as the cognitive center of embodied robots.",
10.1109/RoEduNet68395.2025.11208388,A Multi - Agent Framework for Auditing Smart Contracts,"Smart contracts power a vast array of blockchain applications, securing billions of dollars on decentralized finance, but their immutable nature turns every vulnerability into a permanent exploitable liability. Although automated security tools can efficiently detect many issues, their high false positive rates and lack of trust still require manual audits, which are costly and introduce deployment delays. In this paper, we present an end to end AI augmented auditing framework that leverages a multi-agent pipeline for comprehensive vulnerability detection and automated exploit generation. First, we review existing approaches such as static analysis, fuzzing, symbolic execution, formal verification, and machine learning methods, highlighting their strengths, limitations, and real world deployment experience. Building on this survey, we introduce a multi agent architecture composed of a Distributor Agent, an Attack Planner Agent, an Exploit Generator Agent, and an Audit Report Generator Agent. The pipeline ingests smart contract source code, documen-tation, and test suites to outline stepwise attack strategies and synthesize ready to compile Solidity exploit code. Exploits are compiled and validated in a containerized environment, enabling automated verification of attack effectiveness. We outline a validation strategy for future work, more specifically, applying the pipeline to capture the flag challenges and online bug bounty platforms, and we describe plans for prompt fine tuning, retrieval augmented generation, and formal verification integration to further enhance detection accuracy and exploit reliability. Our proposed framework promises a more comprehensive, scalable, and cost effective approach to smart contract security verification.",
10.1109/SIMPAR62925.2025.10979036,Towards Trustworthy and Explainable Socially Assistive Robots: A Cognitive Architecture for Dietary Guidance,"Socially Assistive Robots (SARs) are rising as promising tools for promoting healthy lifestyle habits. To achieve such a goal, it is necessary that they are able to perform trustworthy and legible behaviors. In this work, we propose a cognitive architecture that integrates multimodal perception, symbolic reasoning, memory-enhanced decision-making, and adaptive interaction strategies to create an explainable and engaging dietary assistant. The key idea is to provide the robot with the capability to iteratively interact with a user and adapt the dietary plan based on their current state, preferences, and food restrictions, while conveying explicitly the inner decision and thought process. To achieve this, we employ a graph-enhanced Large Language Model (LLM), which queries contextual, semantic, and episodic acquired knowledge to generate personalized meal recommendations. These must subsequently be refined through a verification process that enforces constraints such as caloric limits and ingredient intolerances, ensuring dietary adherence. To have a transparent decision-verification process, the robot has to progressively verbalize the reasoning process while providing justifications for the recommendations to also enhance the user's trust. Non-verbal context-relevant movements are also generated to allow the robot to express empathy. We expect our framework to increase user trust, engagement, and adherence to healthy behaviors, allowing SARs to function as credible and effective health assistants. © 2025 IEEE.",
10.1109/SIU59756.2023.10223865,Deep Multi-Object Symbol Learning with Self-Attention Based Predictors,"This paper proposes an architecture that can learn symbolic representations from the continuous sensorimotor experience of a robot interacting with a varying number of objects. Unlike previous works, this work aims to remove constraints on the learned symbols such as a fixed number of interacted objects or pre-defined symbolic structures. The proposed architecture can learn symbols for single objects and relations between them in a unified manner. The architecture is an encoder-decoder network with a binary activation layer followed by self-attention layers. Experiments are conducted in a robotic manipulation setup with a varying number of objects. Results showed that the robot successfully encodes the interaction dynamics between a varying number of objects using the discovered symbols. We also showed that the discovered symbols can be used for planning to reach symbolic goal states by training a higher-level neural network.",
10.1109/SMC53654.2022.9945350,PyMES: Distributed Manufacturing Execution System for Flexible Industry 4.0 Cyber-Physical Production Systems,"Industry 4.0 production systems have to support flexibility in products, processes, and production resources. To meet the required level of flexibility, Industry 4.0 production systems have to be capable of interpreting and executing production plans, which consist of generic actions (such as robotic manipulations or transport of material and products). In industrial practice, Manufacturing Execution Systems (MES) together with Supervisory Control and Data Acquisition (SCADA) systems are usually responsible for such tasks. This paper proposes a new architecture of MES implemented in Python that is able to verify, interpret, and execute production plans automatically generated by an AI planner. Moreover, the proposed MES supports running in a distributed way in several instances, where each instance is able to interpret a location-specific part of a production plan. All MES instances are synchronized and the current global or partial (per each instance) production progress can be observed via HTTP/REST API. The proposed approach is demonstrated in practice on the Industry 4.0 Testbed use-case, utilized for evaluation.",
10.1109/SSCI52147.2023.10371893,GLocal: A Hybrid Approach to the Multi-Agent Mission Re-Planning Problem,"Multi-agent systems can be prone to failures during the execution of a mission, depending on different circumstances, such as the harshness of the environment they are deployed in. As a result, initially devised plans for completing a mission may no longer be feasible, and a re-planning process needs to take place to re-allocate any pending tasks. There are two main approaches to solve the re-planning problem (i) global re-planning techniques using a centralized planner that will redo the task allocation with the updated world state and (ii) decentralized approaches that will focus on the local plan reparation, i.e., the re-allocation of those tasks initially assigned to the failed robots, better suited to a dynamic environment and less computationally expensive. In this paper, we propose a hybrid approach, named GLocal, that combines both strategies to exploit the benefits of both, while limiting their respective drawbacks. GLocal was compared to a planner-only, and an agent-only approach, under different conditions. We show that GLocal produces shorter mission make-spans as the number of tasks and failed agents increases, while also balancing the tradeoff between the number of messages exchanged and the number of requests to the planner.",
10.1109/SUMMA50634.2020.9280796,Solving the Regional Power Grid Restoration Problem with the Prototype of the Hybrid Intelligent Multi-Agent System of Heterogeneous Thinking,"The practical problem solving process in dynamic environments, besides, is characterized by a lack of time for decision-making, the interdependence of the performed actions and the complexity of correcting erroneous decisions. The traditionally applied collective problem solving in such conditions is ineffective, because by the time the agreed decision is made it becomes irrelevant. In this regard, it is necessary to develop informational intelligent systems capable of relevantly simulating the collective reasoning of experts and offering recommendations to the user of the systems, reducing the time of his reaction to events occurring in the control object. For these purposes, hybrid intelligent multi-agent systems of heterogeneous thinking have been proposed. In this paper, the use of the laboratory prototype of such a system to solve one of the problems with dynamic environment is considered, namely regional power grid restoration planning after large-scale emergencies.",
10.1109/SUMMA57301.2022.9973910,Cohesive Hybrid Intelligent Multi-Agent Systems for Power Restoration Planning,"The paper develops an approach to solving practical problems by modeling teams of specialists with hybrid intelligent multi-agent systems. The paper discusses the phenomenon of cohesion, which occurs in long-term teams of specialists that jointly solve practical problems, as well as approaches to its multiagent computer modeling based on the exchange of information about agent's interests, knowledge, experience, development and coordination of common goals, values, norms, means and methods of activity. These mechanisms will simplify the process of integrating heterogeneous intelligent agents into a single system, which is especially important when they are created by independent development teams. The paper proposes the functional structure of the cohesive hybrid intelligent multi-agent system, the architectures of its agents, which are necessary for the implementation of the above mechanisms, and also considers the use of the system to solve the problem of planning the restoration of power supply after large-scale accidents.",
10.1109/SYNASC54541.2021.00031,Continuous Operations and Fully Autonomy of a Social Service Robotic System,"Service robots will be a necessity for humans in many areas where robots will provide varied daily services that will become more sophisticated and superior to the capabilities of robots. We show how our robotic system can handle multiple required tasks either sequentially, simultaneously, or concurrently. These tasks can be requested from internal processes or even from any external systems. Moreover, the robotic system can perform tasks in a discrete way or in a more intelligent way as the case of overlapping tasks based on the available resources. Regardless of the presence of the cloud, where the proposed architecture follows a fog paradigm to somehow enable the robot to achieve human-like capabilities, but this system works and is only partially affected if the cloud is lost. In this paper, we provide an overview of how this system outperforms while we are assuming that this architecture could be one of the most systems that can raising the bar for tasks demanded from a social service robot in the near future. However, the planning system is integrated with such a system as a service or as a black box to fully comply with the fog paradigm, and at the same time, an innovative method is presented to generate plans and carry out more than one task. Finally, a use case scenario describes how the system accepts and handles either sequential tasks or even merged tasks, and at the same time, how the system creates and executes plans to achieve these required tasks. We describe the most relevant terminology required to understand the proposed system.",
10.1109/TASE.2021.3137769,Data-Driven Strategies for Hierarchical Predictive Control in Unknown Environments,"This article proposes a hierarchical learning architecture for safe data-driven control in unknown environments. We consider a constrained nonlinear dynamical system and assume the availability of state-input trajectories solving control tasks in different environments. In addition to task-invariant system state and input constraints, a parameterized environment model generates task-specific state constraints, which are satisfied by the stored trajectories. Our goal is to use these trajectories to find a safe and high-performing policy for a new task in a new, unknown environment. We propose using the stored data to learn generalizable control strategies. At each time step, based on a local forecast of the new task environment, the learned strategy consists of a target region in the state space and input constraints to guide the system evolution to the target region. These target regions are used as terminal sets by a low-level model predictive controller. We show how to i) design the target sets from past data and then ii) incorporate them into a model predictive control scheme with shifting horizon that ensures safety of the closed-loop system when performing the new task. We prove the feasibility of the resulting control policy, and apply the proposed method to robotic path planning, racing, and computer game applications. Note to Practitioners—This paper was motivated by the challenge of designing safe controllers for autonomous systems navigating through new environments. We consider scenarios where trajectory data from control tasks in different environments is available to the control designer. Possible applications include autonomous vehicles racing on new tracks or robotic manipulators performing tasks in the presence of new obstacles. Existing approaches to model-based control design for new environments generally use trajectory libraries, systematically adapting stored trajectories to the constraints of the new environment. This typically requires a priori knowledge of the entire task environment as well as resources to store and maintain the growing library. This paper suggests a new hierarchical control approach, in which stored trajectories are used to learn high-level strategies that can be applied while solving the new task. The strategies are learned offline, and only the parameterized strategy function needs to be stored for online control. Strategies only require knowledge of the nearby task environment, and provide navigation guidelines for the system. In this paper we show how to find such strategies from previous task data and how to integrate them into a low-level controller to safely and efficiently solve the new task. We also show how to adapt the modular framework as needed for a user’s desired application. Simulation experiments in robotic manipulator, autonomous vehicle, and computer game examples suggest that our approach can be used in a wide range of applications. In future research, we will address how to adapt the method for time-varying or stochastic environments.",
10.1109/TASE.2022.3183233,A Multiagent Mission Coordination System for Continuous Situational Awareness of Bushfires,"This paper devises a multi-agent Mission Coordinating Architecture (MCA) to achieve continuous situational awareness (SA) in bushfires, which can help with quick detection and accurate response to the hazards. In this paper, we use Unmanned Aerial Vehicles (UAVs) as instantiations of physical agents. MCA is a scalable architecture and aims to provide the UAVs with parallel mission plans, adopting a fire spread probability map and the Fuzzy C-means method to avoid mission overlap and duplicate information. The architecture is then enhanced by integrating a synchronized communication framework to facilitate UAVs’ adaptive cooperation and total flight time optimization. Furthermore, integrating the communication framework minimizes the number of deployed UAVs to fully cover the same area, saving considerable cost and energy compared to the Parallel Mode. The scalability challenge of the Parallel Mode, determining the required number of UAVs to cover the entire area, and the efficiency of the mission planning algorithm are thoroughly investigated and compared to the performance of the Communication Mode. Finally, the simulation results prove the MCA’s effectiveness in enhancing the UAVs’ exploration capability, resulting in comprehensive monitoring of all affected areas. Note to Practitioners—The proposed architecture in this research could offer flexibility to increase the number of UAVs on demand without requiring a change and adjustment of the parameters. Furthermore, a synchronized communication framework enhances MCA, enabling all UAVs to share their resources and exploit residual battery time to assist each other, manage the overall operation time, and reduce the total operation cost.",
10.1109/TASE.2024.3385412,"Multi-Agent Deep Reinforcement Learning for Persistent Monitoring With Sensing, Communication, and Localization Constraints","Determining multi-robot motion policies for persistently monitoring a region with limited sensing, communication, and localization constraints in non-GPS environments is a challenging problem. To take the localization constraints into account, in this paper, we consider a heterogeneous robotic system consisting of two types of agents: anchor agents with accurate localization capability and auxiliary agents with low localization accuracy. To localize itself, the auxiliary agents must be within the communication range of an anchor, directly or indirectly. The robotic team’s objective is to minimize environmental uncertainty through persistent monitoring. We propose a multi-agent deep reinforcement learning (MARL) based architecture with graph convolution called Graph Localized Proximal Policy Optimization (GALOPP), which incorporates the limited sensor field-of-view, communication, and localization constraints of the agents along with persistent monitoring objectives to determine motion policies for each agent. We evaluate the performance of GALOPP on open maps with obstacles having a different number of anchor and auxiliary agents. We further study 1) the effect of communication range, obstacle density, and sensing range on the performance and 2) compare the performance of GALOPP with area partition, greedy search, random search, and random search with communication constraint strategies. For its generalization capability, we also evaluated GALOPP in two different environments– 2-room and 4-room. The results show that GALOPP learns the policies and monitors the area well. As a proof-of-concept, we perform hardware experiments to demonstrate the performance of GALOPP. Note to Practitioners—Persistent monitoring is performed in various applications like search and rescue, border patrol, wildlife monitoring, etc. Typically, these applications are large-scale, and hence using a multi-robot system helps achieve the mission objectives effectively. Often, the robots are subject to limited sensing range and communication range, and they may need to operate in GPS-denied areas. In such scenarios, developing motion planning policies for the robots is difficult. Due to the lack of GPS, alternative localization mechanisms, like SLAM, high-accurate INS, UWB radio, etc. are essential. Having SLAM or a highly accurate INS system is expensive, and hence we use agents having a combination of expensive, accurate localization systems (anchor agents) and low-cost INS systems (auxiliary agents) whose localization can be made accurate using cooperative localization techniques. To determine efficient motion policies, we use a multi-agent deep reinforcement learning technique (GALOPP) that takes the heterogeneity in the vehicle localization capability, limited sensing, and communication constraints into account. GALOPP is evaluated using simulations and compared with baselines like random search, random search with ensured communication, greedy search, and area partitioning. The results show that GALOPP outperforms the baselines. The GALOPP approach offers a generic solution that be adopted with various other applications.",
10.1109/TASE.2024.3398663,Iterative Planning for Multi-Agent Systems: An Application in Energy-Aware UAV-UGV Cooperative Task Site Assignments,"This paper presents an iterative planning framework for multi-agent systems with hybrid state spaces. The framework uses transition systems to mathematically represent planning tasks and employs multiple solvers to iteratively improve the plan until computational resources are exhausted. When integrating different solvers for iterative planning, we establish theoretical guarantees for recursive feasibility. The proposed framework enables continual improvement of solutions to reduce sub-optimality, efficiently using allocated computational resources. The proposed method is validated by applying it to an energy-aware UAV-UGV cooperative task site assignment problem. The results demonstrate continual solution improvement while preserving real-time implementation ability compared to algorithms proposed in the literature.Note to Practitioners—This paper presents an iterative planning solution for cooperative planning problems in multi-agent systems, which integrates multiple solvers to create an optimization framework. The proposed planning framework has been theoretically validated and applied in an energy-aware cooperative planning scenario for multi-vehicle task site assignments. The proposed framework can be applied to plan for any generalized task site assignment using multiple solvers iteratively.",
10.1109/TASE.2024.3401456,Hierarchical Q-Learning Path Planning for Cooperative Tracking Control of Multi-Agent Systems With Lumped Uncertainties,"This paper presents the hierarchical Q-learning path planning (HQPP) architecture for solving the cooperative tracking control problem of multi-agent systems (MASs) with lumped uncertainties in an unknown environment. The presented architecture consists of three layers, namely, the decision layer, the distributed estimated layer, and the local control layer. Specifically, in the decision layer, we propose the dynamic parameter and trajectory fitting Q-learning (DPTF-Q-learning) algorithm to find a feasible continuous trajectory to the target in an unknown environment. In addition, two dynamic parameters are proposed and introduced into the DPTF-Q-learning algorithm to shorten the required minimum number of steps in the training process. Then, the distributed estimated layer is designed to broadcast the continuous trajectory generated from the decision layer based on the directed communication topology containing a spanning tree. In the local control layer, the cooperative tracking control (CTC) algorithm is proposed to achieve cooperative tracking for MASs in the presence of uncertain dynamics and external disturbances. The sufficient conditions for achieving cooperative tracking control are rigorously derived by employing Lyapunov argument. Finally, numerical simulations are presented to verify the effectiveness of the proposed architecture.Note to Practitioners—This paper is motivated by the need of developing an integrated path planning and control method for cooperative tracking of multi-agent systems in a no-signal environment and without the presence of users. Most related works are limited to separate fields: 1) most existing path planning techniques are only applicable to a single agent and discrete environments, and 2) most existing cooperative tracking algorithms focus on guaranteeing control stability and error convergence without decision-making capabilities. To address the above issues, this work proposes a hierarchical control architecture based on reinforcement learning for multi-agent systems to achieve path planning and cooperative tracking tasks. In addition, multi-agent systems exhibit strong robustness and fault tolerance due to their inherent characteristics, so the above mentioned research can be well applied to post-disaster rescue, intelligent logistics, future war, and so on. Numerical simulations based on Matlab and Python verify the effectiveness of the proposed architecture.",
10.1109/TASE.2024.3452149,Toward Cognitive Digital Twin System of Human-Robot Collaboration Manipulation,"Multielement decision-making is crucial for the robust deployment of human-robot collaboration (HRC) systems in flexible manufacturing environments with personalized tasks and dynamic scenes. Large Language Models (LLMs) have recently demonstrated remarkable reasoning capabilities in various robotic tasks, potentially offering this capability. However, the application of LLMs to actual HRC systems requires the timely and comprehensive capturing of real-scene information. In this study, we suggest incorporating real scene data into LLMs using digital twin (DT) technology and present a cognitive digital twin prototype system of HRC manipulation, known as HRC-CogiDT. Specifically, we initially construct a scene semantic graph encoding the geometric information of entities, spatial relations between entities, actions of humans and robots, and collaborative activities. Subsequently, we devise a prompt that merges scene semantics with prior knowledge of activities, linking the real scene with LLMs. To evaluate performance, we compile an HRC scene understanding dataset and set up a laboratory-level experimental platform. Empirical results indicate that HRC-CogiDT can swiftly perceive scene changes and make high-level decisions based on varying task requirements, such as task planning, anomaly detection, and schedule reasoning. This study provides promising insights for the future applications of LLMs in robotics.Note to Practitioners—Recently, LLMs have demonstrated significant success in various robotic tasks, suggesting their potential as a powerful tool for robotic decision-making. Motivated by this, to improve the production efficiency of HRC in flexible manufacturing, we innovatively combine LLMs with DT technology, and propose a cognitive DT system for HRC, aiming to integrate LLMs into the decision-making loop of HRC system. Experiments conducted in a laboratory-scale platform indicate that the proposed system can handle different decision-making needs in different HRC activities. This system can provide professional guidance to operators in a comprehensible form and serve as a medium for monitoring the safety and standardization of the manipulation process. Future work will explore the use of virtual space provided by the proposed system to optimize the decision outputs of LLMs to make the proposed system more broadly applicable.",
10.1109/TASE.2024.3487219,Hierarchical Reinforcement Learning for Swarm Confrontation With High Uncertainty,"In swarm robotics, confrontation including the pursuit-evasion game is a key scenario. High uncertainty caused by unknown opponents’ strategies, dynamic obstacles, and insufficient training complicates the action space into a hybrid decision process. Although the deep reinforcement learning method is significant for swarm confrontation since it can handle various sizes, as an end-to–end implementation, it cannot deal with the hybrid process. Here, we propose a novel hierarchical reinforcement learning approach consisting of a target allocation layer, a path planning layer, and the underlying dynamic interaction mechanism between the two layers, which indicates the quantified uncertainty. It decouples the hybrid process into discrete allocation and continuous planning layers, with a probabilistic ensemble model to quantify the uncertainty and regulate the interaction frequency adaptively. Furthermore, to overcome the unstable training process introduced by the two layers, we design an integration training method including pre-training and cross-training, which enhances the training efficiency and stability. Experiment results in both comparison, ablation, and real-robot studies validate the effectiveness and generalization performance of our proposed approach. In our defined experiments with twenty to forty agents, the win rate of the proposed method reaches around ninety percent, outperforming other traditional methods. Note to Practitioners—With artificial intelligence rapidly developing, robots will play a significant role in the future. Especially, the swarm formed by many robots holds promising potential in civil and military applications. Promoting the swarm into games or battles is rather riveting. The reinforcement learning method provides a plausible solution to realize the battle of robotic swarms. There are still some issues that need to be addressed. On one hand, we focus on the uncertainty caused by the battlefield nature and the environment which limits our ability for the implementation of swarms. On the other hand, we solve the problem that the decision process combined with commands and actions is a hybrid system, which cannot be directly reflected in the confrontation of swarms. Overall, our approaches throw light on artificial general intelligence and also reveal a solution to interpretable intelligence.",
10.1109/TASE.2025.3566461,Learning 6-DoF Fine-Grained Grasp Detection Based on Part Affordance Grounding,"Robotic grasping is a fundamental ability for a robot to interact with the environment. Current methods focus on how to obtain a stable and reliable grasping pose in object level, while little work has been studied on part (shape)-wise grasping which is related to fine-grained grasping and robotic affordance. Parts can be seen as atomic elements to compose an object, which contains rich semantic knowledge and a strong correlation with affordance. However, lacking a large part-wise 3D robotic dataset limits the development of part representation learning and downstream applications. In this paper, we propose a new large Language-guided SHape grAsPing datasEt (named LangSHAPE) to promote 3D part-level affordance and grasping ability learning. From the perspective of robotic cognition, we design a two-stage fine-grained robotic grasping framework (named LangPartGPD), including a novel 3D part language grounding model and a part-aware grasp pose detection model, in which explicit language input from human or large language models (LLMs) could guide a robot to generate part-level 6-DoF grasping pose with textual explanation. Our method combines the advantages of human-robot collaboration and LLMs’ planning ability using explicit language as a symbolic intermediate. To evaluate the effectiveness of our proposed method, we perform 3D part grounding and fine-grained grasp detection experiments on both simulation and physical robot settings, following language instructions across different degrees of textual complexity. Results show our method achieves competitive performance in 3D geometry fine-grained grounding, object affordance inference, and 3D part-aware grasping tasks. Our dataset and code are available on our project website https://sites.google.com/view/lang-shape. Note to Practitioners—This paper was motivated by the problem of pragmatic 6 DoF robotic grasping for a robot in a real-world scenario. Different from existing work focusing on task-oriented solutions, our research attempts to consider fine-grained grasping as a general and essential modeling problem (i.e. Point 1: which part to grasp; Point 2: how to grasp the specific part). For that, our method fully considers the scalability and compatibility with subsequently developed functional modules. A two-stage loosely-coupled fine-grained grasping framework (LangPartGPD) is designed, including a 3D part language grounding model and a part-aware 6 DoF grasping pose detection model (Point 1). The former is used to link the symbolic-level grasped part representation to the specific region of an object. The latter is to realize kinematic-level grasping point generation based on the constraint of parts (Point 2). To realize the designed model, we propose a newly large-scale language-pointcloud-grasp dataset (LangSHAPE) to train fine-grained 3D part-level grounding and part-constrained grasping detection models. It is noted that our method is purely concerned with the target object, grasped part, and functionality to realize to model the essential fine-grained graspability, which is an insufficiently explored direction currently and could promote task-level grasping performance. The symbolic-level description of grasping in the form of natural language provides an explainable decision and a user-friendly interface for human-robot collaboration. Experiments in simulations and real-robot settings show our method can effectively enable a robot to make a cognitive decision for fine-grained manipulation. Summarily, our work is a preliminary exploration to link symbolic-level cognitive space to kinematic-level control space directly. In future research, we will further combine more complicated cognitive knowledge from public multimodal knowledge graphs and multimodal LLMs, to build a general robotic cognitive decision system using LangPartGPD as the basic components.",
10.1109/TASE.2025.3614996,Dual-Agent-Based Robotic Ultrasound Path Planning and Interaction Control in External-Vision-Independent Environments,"Ultrasound imaging has emerged as a crucial tool for the diagnosis and navigation of spinal diseases. However, high-quality image acquisition heavily relies on experienced sonographers, which restricts its further popularization. In this paper, a robotic system designed for automated spinal ultrasound scanning is proposed. Drawing inspiration from the spinal anatomy and the actions of seasoned sonographers, the system integrates both a deep learning agent and a reinforcement learning agent to collaboratively guide the adjustment of the ultrasound probe in external-vision-independent environments, relying on real-time ultrasound images and contact force. Then, a hybrid force-to-velocity control framework is proposed to ensure proper ultrasound coupling during the scanning process. Experimental results on a phantom and human participants demonstrated that this system can accurately track spinal features (mean error: less than 1 mm) and maintain normal probe orientation (out-of-plane angular error:  $1.61~\pm ~1.1^{\circ }$ , in-plane angular error:  $1.27~\pm ~0.9^{\circ }$ ), resulting in high-quality and reproducible ultrasound images. Overall, our system shows great potential for clinical applications. Note to Practitioners—This paper is motivated by the increasing needs of human-robot interaction in medical applications, with a specific emphasis on robotic ultrasound imaging. Clinical sonographers suffer from repetitive workload during the diagnostic process, highlighting the significance of automated scanning solutions. In this work, we propose a modular control framework for ultrasound probe positioning that supports a multi-modal autonomous ultrasound scanning system. The system operates independently of external optics or prior geometric knowledge of the scanning object. Comprehensive experimental results demonstrate that the system can effectively cover the region of interest of the spine, facilitating high-quality ultrasound image acquisition and related disease assessment. This advancement is expected to enhance the efficiency of human-robot interaction in healthcare settings and holds promising clinical applications. Furthermore, our research offers valuable insights for the implementation of robotic ultrasound scanning systems applicable to other human tissues.",
10.1109/TCAD.2023.3246386,Ulgen: A Runtime Assurance Framework for Programming Safe Cyber–Physical Systems,"We present Ulgen, a runtime assurance (RTA) framework for programming safe cyber–physical systems (CPSs). In Ulgen, a system is implemented as a collection of asynchronous processes executing RTA modules which are generalizations of the well-known Simplex architecture. An RTA module is composed of a set of safe controllers (SCs), designed to guarantee certain safety specifications, and a set of advanced controllers (ACs), optimized for performance, each defined to run under the specific conditions of the operating environment, and a decision module implementing the switching logic between the controllers. A source of complexity in achieving safe CPS is that these systems often involve concurrently interacting components with different execution semantics. To this end, Ulgen allows for the definition of RTA modules with either event-driven or time-driven execution semantics and encapsulates such components into RTA modules. It further provides primitives for implementing priority-based communication between asynchronous processes, which is a necessary feature for task prioritization mechanisms, such as contingency plans and interrupt service routines. The framework also provides formal guarantees on the safe execution of RTA modules based on a formal definition of well-formedness. In Ulgen, a well-formed RTA module combines SCs and ACs in a way that guarantees the underlying safety specifications assured by the SCs while delivering the desired performance offered by the ACs. We compare the safety guarantees of Ulgen against other state-of-the-art RTA frameworks and demonstrate its efficacy in implementing safe and performant CPS by presenting an extensive experimental evaluation of five case studies both in a simulation environment and on a real robotic platform.",
10.1109/TCCN.2025.3528892,AutoHMA-LLM: Efficient Task Coordination and Execution in Heterogeneous Multi-Agent Systems Using Hybrid Large Language Models,"Heterogeneous multi-agent systems (HMAS) comprise various intelligent agents with specialized functions, such as drones, ground robots, and automated devices, working in coordinated settings. This paper presents AutoHMA-LLM, a novel framework that combines Large Language Models (LLMs) with classical control algorithms to address the challenges of task coordination and scheduling in complex, dynamic environments. The framework is designed with a multi-tier architecture, utilizing a cloud-based LLM as the central planner alongside device-specific LLMs and Generative Agents to improve task execution efficiency and accuracy. Specifically targeting dynamic scenarios, the system enhances resource utilization and stabilizes task execution through refined task scheduling and real-time feedback mechanisms. In experiments conducted across logistics, inspection, and search & rescue scenarios, AutoHMA-LLM demonstrated a 5.7% improvement in task completion accuracy, a 46% reduction in communication steps, and a 31% decrease in token usage and API calls compared to baseline methods. These results highlight our framework’s scalability and efficiency, offering substantial support for effective multi-agent collaboration in complex, resource-constrained environments.",
10.1109/TCDS.2022.3145915,Collision-Free Navigation in Human-Following Task Using a Cognitive Robotic System on Differential Drive Vehicles,"As human–robot collaboration increases tremendously in real-world applications, a fully autonomous and reliable mobile robot for the collaboration has been a central research topic and investigated extensively in a large number of studies. One of the most pressing issues in such topic is the collision-free navigation that has a moving goal and unknown obstacles under the unstructured environment. In this article, a cognitive robotic system (CRS) is proposed for the robot to navigate itself to the moving target person without obstacle collision. This CRS consists of a cognitive agent, which is created based on the Soar cognitive architecture to reason its current situation and make action decision for the robot to avoid obstacles and reach the target position, and a speed planning module, which is based on dynamic window approach (DWA) to generate appropriate linear and angular velocities for driving the robot’s motors. For the implementation of the proposed system, we use a differential drive wheel robot equipped with two ultrawideband (UWB) sensors and a color depth camera as the experimental platform. Finally, to evaluate the performance of our system in actual operating conditions, we conduct experiments with a scenario that includes main tasks: avoiding consecutive unknown obstacles and turning at corner while the robot follows continuously human user along the corridor.",
10.1109/TCSII.2022.3184322,Consensus in Multi-Agent Systems: A Transfer Function-Based Controller Design Approach,"In this brief, the problem of output consensus in a multi-agent system is considered, where a distributed dynamic output feedback control architecture is proposed. The control architecture consists of two components, one is local controllers for the agents, and another is a gain for the network. The transfer function of local controller is designed based on the number of positive real axis (in the complex plane) zeros of the agent transfer function, and then network gain is selected by sketching the root-locus of a unity feedback system. It is shown that the output consensus can be achieved with an integral type controller for a class of agents, irrespective of their order. Moreover, with the proposed control architecture, there is no need of communication between the local controllers. The effectiveness of the developed approach is demonstrated through numerical examples.",
10.1109/TG.2024.3487416,Large Language Models as Narrative Planning Search Guides,"Symbolic planning algorithms and large language models have different strengths and weaknesses for story generation, suggesting hybrid models might leverage advantages from both. Others have proposed using a language model in combination with a partial order planning style algorithm to avoid the need for a hand-written symbolic domain of actions, or generating these domains from natural language input. This article offers a complementary approach. We propose to use a state space planning algorithm to plan coherent multiagent stories using hand-written symbolic domains, but with a language model acting as a guide to estimate, which events are worth exploring first. We present an initial evaluation of this approach on a set of benchmark narrative planning problems. © 2018 IEEE.",
10.1109/TITS.2022.3162850,Smart Underwater Pollution Detection Based on Graph-Based Multi-Agent Reinforcement Learning Towards AUV-Based Network ITS,"The exploitation/utilization of marine resources and the rapid development of urbanization along coastal cities result in serious marine pollution, especially underwater diffusion pollution. It is a non-trivial task to detect the source of diffusion pollution, such that the disadvantageous effect of the pollution can be reduced. With the vision of 6G framework, we employ Autonomous Underwater Vehicle (AUV) flock and introduce the concept of AUV-based network. In particular, we utilize the Software-Defined Networking (SDN) technique to update the controllability of the AUV-based network, leading to the paradigm of SDN-enabled multi-AUVs network Intelligent Transportation Systems (SDNA-ITS). For SDNA-ITS, we utilize artificial potential field theories to model the control model. To optimize the system output, we introduce the graph-based Soft Actor-Critic (SAC) algorithm, i.e., a category of Multi-Agent Reinforcement Learning (MARL) mechanism where each AUV can be regarded as a node in a graph. In particular, we improve the optimization model based on Centralized Training Decentralized Execution (CTDE) architecture with the assistance of the SDN controller, by which each AUV can efficiently adjust its speed towards the diffusion source. Further, to achieve exact path planning for detecting the diffusion source, a dynamic detection scheme is proposed to output the united control policy to schedule the SDNA-ITS dynamically. Simulation results demonstrate that our approaches are available to detect the underwater diffusion source when the actual scenario is taken into account and perform better than some recent research products.",
10.1109/TITS.2023.3337334,Hierarchical Optimization Scheduling Algorithm for Logistics Transport Vehicles Based on Multi-Agent Reinforcement Learning,"How to effectively improve the cargo assembly and multi-vehicle stratified planning has become an urgent problem to be solved. In this paper, Multi-Agent Reinforcement Learning Hierarchical Optimal Scheduling Algorithm (MARLHOSA) is proposed to solve the hierarchical scheduling problem of logistics transport vehicles. We model the hierarchical scheduling problem of logistics transport vehicles as an infinite Markov decision process and set constraints to simulate the actual operating environment. To solve the Markov decision process corresponding to the economic scheduling problem of logistics transport vehicles, this paper uses the close-range strategy optimization algorithm, and uses multi-agent reinforcement learning algorithm based on the clipping mechanism to improve the loss function of the short-range strategy optimization algorithm. In addition, a distributed training architecture was designed for the training process of the close-range strategy optimization algorithm, so as to improve the speed of data collection and training speed and quality. According to a demand order put forward by the company, a path-loading collaborative optimization model was established. After solving the model, the number of vehicles dispatched by each vehicle type according to the optimal path-loading scheme of each vehicle type was determined. The simulation results show that the proposed improved distributed proximity strategy optimization algorithm can achieve the same economic performance as the numerical optimization method. Compared with the traditional algorithm, MARLHOSA can reduce the total vehicle mileage by 34.5% and increase the average loading rate of the carriage by 28.6%. The optimization effect is significant.",
10.1109/TITS.2024.3357479,A Hierarchical Hybrid Learning Framework for Multi-Agent Trajectory Prediction,"Accurate trajectory prediction for neighboring agents is crucial for autonomous vehicles navigating complex scenes. Recent deep learning (DL) methods excel in encoding complex interactions but often generate invalid predictions due to difficulties in modeling transient and contingency interactions. This paper proposes a hierarchical hybrid framework that combines DL and reinforcement learning (RL) for multi-agent trajectory prediction, capturing multi-scale interactions that shape future motion. In the DL stage, Transformer-style graph neural network (GNN) is employed to encode heterogeneous interactions at intermediate and global scales, predicting multi-modal intentions as key future positions for agents. In the RL stage, we divide the scene into local scenes based on DL predictions. A Transformer-based Proximal Policy Optimization (PPO) model, incorporated with vehicle kinematics, generates future trajectories in the form of motion planning shaped by microscopic interactions and guided by a multi-objective reward for balanced agent-centric accuracy and scene-wise compatibility. Experimental results on the Argoverse benchmark and driver-in-loop simulations demonstrate that our framework enhances trajectory prediction feasibility and plausibility in interactive scenes.",
10.1109/TIV.2024.3488793,KoMA: Knowledge-Driven Multi-Agent Framework for Autonomous Driving With Large Language Models,"Large language models (LLMs) as autonomous agents offer a novel avenue for tackling real-world challenges through a knowledge-driven manner. These LLM-enhanced methodologies excel in generalization and interpretability. However, the complexity of driving tasks often necessitates the collaboration of multiple, heterogeneous agents, underscoring the need for such LLM-driven agents to engage in cooperative knowledge sharing and cognitive synergy. Despite the promise of LLMs, current applications predominantly center around single-agent scenarios. To broaden the horizons of knowledge-driven strategies and bolster the generalization capabilities of autonomous agents, we propose the KoMA framework consisting of multi-agent interaction, multi-step planning, shared-memory, and ranking-based reflection modules to enhance multi-agents' decision-making in complex driving scenarios. Based on the framework's generated text descriptions of driving scenarios, the multi-agent interaction module enables LLM agents to analyze and infer the intentions of surrounding vehicles based on scene information, akin to human cognition. The multi-step planning module enables LLM agents to analyze and obtain final action decisions layer by layer to ensure consistent goals for short-term action decisions. The shared memory module can accumulate collective experience to make superior decisions, and the ranking-based reflection module can evaluate and improve agent behavior with the aim of enhancing driving safety and efficiency. The KoMA framework not only enhances the robustness and adaptability of autonomous driving agents but also significantly elevates their generalization capabilities across diverse scenarios. Empirical results demonstrate the superiority of our approach over traditional methods, particularly in its ability to handle complex, unpredictable driving environments without extensive retraining.",
10.1109/TMECH.2024.3452509,A Survey of Optimization-Based Task and Motion Planning: From Classical to Learning Approaches,"Task and motion planning (TAMP) integrates high-level task planning and low-level motion planning to equip robots with the autonomy to effectively reason over long-horizon, dynamic tasks. Optimization-based TAMP focuses on hybrid optimization approaches that define goal conditions via objective functions and are capable of handling open-ended goals, robotic dynamics, and physical interaction between the robot and the environment. Therefore, optimization-based TAMP is particularly suited to solve highly complex, contact-rich locomotion and manipulation problems. This survey provides a comprehensive review on optimization-based TAMP, covering first, planning domain representations, including action description languages and temporal logic, second, individual solution strategies for components of TAMP, including AI planning and trajectory optimization (TO), and finally, the dynamic interplay between logic-based task planning and model-based TO. A particular focus of this survey is to highlight the algorithm structures to efficiently solve TAMP, especially hierarchical and distributed approaches. In addition, the survey emphasizes the synergy between the classical methods and contemporary learning-based innovations, such as large language models. Furthermore, the future research directions for TAMP is discussed in this survey, highlighting both algorithmic and application-specific challenges.",
10.1109/TNET.2023.3289172,Ensuring Threshold AoI for UAV-Assisted Mobile Crowdsensing by Multi-Agent Deep Reinforcement Learning With Transformer,"Unmanned aerial vehicle (UAV) crowdsensing (UCS) is an emerging data collection paradigm to provide reliable and high quality urban sensing services, with age-of-information (AoI) requirement to measure data freshness in real-time applications. In this paper, we explicitly consider the case to ensure that the attained AoI always stay within a specific threshold. The goal is to maximize the total amount of collected data from diverse Point-of-Interests (PoIs) while minimizing AoI and AoI threshold violation ratio under limited energy supplement. To this end, we propose a decentralized multi-agent deep reinforcement learning framework called “DRL-UCS(&lt;inline-formula&gt; &lt;tex-math notation=""LaTeX""&gt;$text {AoI}_{th}$ &lt;/tex-math&gt;&lt;/inline-formula&gt;)” for multi-UAV trajectory planning, which consists of a novel transformer-enhanced distributed architecture and an adaptive intrinsic reward mechanism for spatial cooperation and exploration. Extensive results and trajectory visualization on two real-world datasets in Beijing and San Francisco show that, DRL-UCS(&lt;inline-formula&gt; &lt;tex-math notation=""LaTeX""&gt;$text {AoI}_{th}$ &lt;/tex-math&gt;&lt;/inline-formula&gt;) consistently outperforms all nine baselines when varying the number of UAVs, AoI threshold and generated data amount in a timeslot.",
10.1109/TNNLS.2021.3128380,Toward Cognitive Navigation: Design and Implementation of a Biologically Inspired Head Direction Cell Network,"As a vital cognitive function of animals, the navigation skill is first built on the accurate perception of the directional heading in the environment. Head direction cells (HDCs), found in the limbic system of animals, are proven to play an important role in identifying the directional heading allocentrically in the horizontal plane, independent of the animal’s location and the ambient conditions of the environment. However, practical HDC models that can be implemented in robotic applications are rarely investigated, especially those that are biologically plausible and yet applicable to the real world. In this article, we propose a computational HDC network that is consistent with several neurophysiological findings concerning biological HDCs and then implement it in robotic navigation tasks. The HDC network keeps a representation of the directional heading only relying on the angular velocity as an input. We examine the proposed HDC model in extensive simulations and real-world experiments and demonstrate its excellent performance in terms of accuracy and real-time capability.",
10.1109/TNNLS.2023.3247160,Representation Learning and Reinforcement Learning for Dynamic Complex Motion Planning System,"Indoor motion planning challenges researchers because of the high density and unpredictability of moving obstacles. Classical algorithms work well in the case of static obstacles but suffer from collisions in the case of dense and dynamic obstacles. Recent reinforcement learning (RL) algorithms provide safe solutions for multiagent robotic motion planning systems. However, these algorithms face challenges in convergence: slow convergence speed and suboptimal converged result. Inspired by RL and representation learning, we introduced the ALN-DSAC: a hybrid motion planning algorithm where attention-based long short-term memory (LSTM) and novel data replay combine with discrete soft actor–critic (SAC). First, we implemented a discrete SAC algorithm, which is the SAC in the setting of discrete action space. Second, we optimized existing distance-based LSTM encoding by attention-based encoding to improve the data quality. Third, we introduced a novel data replay method by combining the online learning and offline learning to improve the efficacy of data replay. The convergence of our ALN-DSAC outperforms that of the trainable state of the arts. Evaluations demonstrate that our algorithm achieves nearly 100% success with less time to reach the goal in motion planning tasks when compared to the state of the arts. The test code is available at https://github.com/CHUENGMINCHOU/ALN-DSAC.",
10.1109/TNSE.2022.3188304,A Hybrid Deep Sensor Anomaly Detection for Autonomous Vehicles in 6G-V2X Environment,"Autonomous Vehicles (AVs) exchange real-time and seamless data between other AVs and the network, thus revolutionizing the Intelligent Transportation System (ITS). Automated transportation brings numerous benefits to human beings. However, the concerns such as safety, security, and privacy keep rising. In navigation and trajectory planning, the AVs require exchanging sensory information from their own and other AVs. In such cases, when a malicious AV or faulty sensor-equipped AV comes into connectivity, it can have disruptive consequences. This paper proposes a Hybrid Deep Anomaly Detection (HDAD) approach for effective anomaly detection and cyber-attack mitigation in AVs. The Multi-Agent Reinforcement Learning (MARL) algorithm in HDAD approach acts over the 6G network to combat new-age cyber-attacks and provide a swift and accurate anomaly detection mechanism. In conjunction with Maximum Entropy Inverse Reinforcement Learning (MaxEntIRL), the HDAD approach identifies and isolates malicious AVs. It is envisioned that the obtained results prove the effectiveness of HDAD and have an 8.2% higher accuracy rate than the existing systems.",
10.1109/TRO.2022.3226144,Active Inference and Behavior Trees for Reactive Action Planning and Execution in Robotics,"In this article, we propose a hybrid combination of active inference and behavior trees (BTs) for reactive action planning and execution in dynamic environments, showing how robotic tasks can be formulated as a free-energy minimization problem. The proposed approach allows handling partially observable initial states and improves the robustness of classical BTs against unexpected contingencies while at the same time reducing the number of nodes in a tree. In this work, we specify the nominal behavior offline, through BTs. However, in contrast to previous approaches, we introduce a new type of leaf node to specify the desired state to be achieved rather than an action to execute. The decision of which action to execute to reach the desired state is performed online through active inference. This results in continual online planning and hierarchical deliberation. By doing so, an agent can follow a predefined offline plan while still keeping the ability to locally adapt and take autonomous decisions at runtime, respecting safety constraints. We provide proof of convergence and robustness analysis, and we validate our method in two different mobile manipulators performing similar tasks, both in a simulated and real retail environment. The results showed improved runtime adaptability with a fraction of the hand-coded nodes compared to classical BTs.",
10.1109/TSMC.2023.3312585,Interactive Inference: A Multi-Agent Model of Cooperative Joint Actions,"We advance a novel computational model of multi-agent, cooperative joint actions that is grounded in the cognitive framework of active inference. The model assumes that to solve a joint task, such as pressing together a red or blue button, two (or more) agents engage in a process of interactive inference. Each agent maintains probabilistic beliefs about the joint goal (e.g., Should we press the red or blue button?) and updates them by observing the other agent’s movements, while in turn selecting movements that make his own intentions legible and easy to infer by the other agent (i.e., sensorimotor communication). Over time, the interactive inference aligns both the beliefs and the behavioral strategies of the agents, hence ensuring the success of the joint action. We exemplify the functioning of the model in two simulations. The first simulation illustrates a “leaderless” joint action. It shows that when two agents lack a strong preference about their joint task goal, they jointly infer it by observing each other’s movements. In turn, this helps the interactive alignment of their beliefs and behavioral strategies. The second simulation illustrates a “leader–follower” joint action. It shows that when one agent (“leader”) knows the true joint goal, it uses sensorimotor communication to help the other agent (“follower”) infer it, even if doing this requires selecting a more costly individual plan. These simulations illustrate that interactive inference supports successful multi-agent joint actions and reproduces key cognitive and behavioral dynamics of “leaderless” and “leader–follower” joint actions observed in human–human experiments. In sum, interactive inference provides a cognitively inspired, formal framework to realize cooperative joint actions and consensus in multi-agent systems.",
10.1109/TVT.2023.3344934,Distributed Multi-Agent Reinforcement Learning for Collaborative Path Planning and Scheduling in Blockchain-Based Cognitive Internet of Vehicles,"The collaborative path planning and scheduling can overcome the limitations of single vehicle intelligence to obtain a globally optimal decision strategy in cognitive Internet of Vehicles (CIoVs). The collaboration of vehicles necessitates the exchange of environmental and decision information, generating massive collaborative computing tasks with strict latency requirements. Leveraging mobile edge computing (MEC) technology, computing tasks can be processed near the vehicles to reduce latency. However, traffic congestion and computational load imbalance seriously affect traffic efficiency and computational latency. In hybrid driving scenarios, it is challenging to fulfill the diverse service requirements of vehicles with different intelligence levels. Moreover, non-collaborative tend to result in traffic congestion due to vehicle aggregation effects, while centralized solutions lack flexibility and have high computational complexity. To address these concerns, a distributed multi-agent reinforcement learning (DMARL) algorithm is proposed for collaborative path planning and scheduling in a blockchain-based collaboration framework. In this framework, we model the communication, traffic situation and task processing of the system and formulate a joint optimization problem to minimize both travel time and computation latency. Last, we convert the scheduling problem for different types of vehicles into Markov decision processes (MDPs) and propose Q-learning-based DMARL algorithm to achieve proactive load balancing of both road infrastructures and MEC nodes (MECNs). Simulation results demonstrate that the proposed approach outperforms the comparison schemes in terms of load balance indexes of roads and MECNs, travel time, and computation latency.",
10.1109/TVT.2024.3369089,Towards Intelligent Mobile Crowdsensing With Task State Information Sharing Over Edge-Assisted UAV Networks,"With the rapid development of edge computing technology, edge-assisted unmanned aerial vehicle (UAV) networks have become popular, helping with fast and cost-effective data collection in mobile crowdsensing (MCS) environments. This paper investigates the online data collection problem for MCS over an edge-assisted UAV network architecture, where UAVs work to collect the data required by tasks at different on-ground point-of-interests (PoIs) in an autonomous and cooperative manner. Different from conventional edge-assisted UAV networks, edge nodes in our paper help distribute, aggregate, share, and update the task state information (TSI, e.g., if a task has been completed, or if it still requires more data), to support efficient and cost-effective data collection, e.g., avoiding repetitive and ineffective task execution. In particular, a UAV can exchange TSI with an edge node when it is within the signal coverage of the edge node, while making decisions on PoI selection and path planning in an online and decentralized manner. To address the issue of edge-assisted UAV data collection, we propose a multi-agent deep reinforcement learning-based algorithm using personalized training with decentralized executing (PTDE) architecture. Different from the traditional centralized training with decentralized executing (CTDE) architecture, our considered architecture adopts the agent-specific state for critic networks instead of the joint observation, thus achieving effective utilization of environmental information. Furthermore, we propose an observation enhancement algorithm based on artificial potential field (APF). Extensive simulation results demonstrate that our proposed algorithm greatly outperforms baseline algorithms in terms of total profit, data collection ratio, geographical fairness, and energy efficiency.",
10.1109/TVT.2025.3533006,Mix Q-Learning for Lane Changing: A Collaborative Decision-Making Method in Multi-Agent Deep Reinforcement Learning,"Lane-changing decisions, which are crucial for autonomous vehicle path planning, face practical challenges due to rule-based constraints and limited data. Deep reinforcement learning has become a major research focus due to its advantages in data acquisition and interpretability. However, current models often overlook collaboration, which affects not only impacts overall traffic efficiency but also hinders the vehicle's own normal driving in the long run. To address the aforementioned issue, this paper proposes a method named Mix Q-learning for Lane Changing (MQLC) that integrates a hybrid value Q network, taking into account both collective and individual benefits for the greater good. At the collective level, our method coordinates the individual Q and global Q networks by utilizing global information. This enables agents to effectively balance their individual interests with the collective benefit. At the individual level, we integrate a deep learning-based intent recognition module into our observation and enhance the decision network. These changes provide agents with richer decision information and more precise feature extraction for improved lane-changing decisions. This strategy enables the multi-agent system to learn and formulate optimal decision-making strategies effectively. Our MQLC model, through extensive experimental results, impressively outperforms other state-of-the-art multi-agent decision-making methods, effectively improving the overall efficiency.",
10.1109/UR65550.2025.11078095,Development of a Mobile Assistive Robot for Daily Living Support*,"This paper develops a Mobile Assistive Robotic System (MARS) designed to assist people with disabilities by performing daily tasks such as retrieving objects and helping meal. MARS uses ROS2 framework to connect a 7-DOF robotic arm, hybrid gripper, RGB-depth cameras, and a large language model-based planner, enabling intergration of visionbased recognition, skill affordance, and natural language task planning. Through real-world experiments in cluttered environments, MARS provides a promising solution for autonomous assistive robots in dynamic home settings.",
10.1109/WI-IAT59888.2023.00062,Implementing BDI Continual Temporal Planning for Robotic Agents,"Making autonomous agents effective in real-life applications requires the ability to decide at run-time and a high degree of adaptability to unpredictable and uncontrollable events. Reacting to events is still a fundamental ability for an agent, but it has to be boosted up with proactive behaviors that allow the agent to explore alternatives and decide at run-time for optimal solutions. This calls for a continuous planning as part of the deliberation process that makes an agent able to reconsider plans on the base of temporal constraints and changes of the environment. Online planning literature offers several approaches used to select the next action on the base of a partial exploration of the solution space. In this paper, we propose a BDI continuous temporal planning framework, where interleave planning and execution loop is used to integrate online planning with the BDI control-loop. The framework has been implemented with the ROS2 robotic framework and planning algorithms offered by JavaFF.",
10.1109/WRCSARA60131.2023.10261865,Development of a Simulation Environment for Robot Soccer Game with Deep Reinforcement Learning and Role Assignment,"The robot soccer game has been recognized as an excellent scenario to test the gaming algorithm of multi-agent systems. This paper develops a new simulation platform for the robot soccer game, and it has the advantage of open architecture, such that the formation control scheme, the path planning strategy for multiple robots, and many other algorithms can be implemented and tested. Specifically, both a Deep Reinforcement Learning (DRL) scheme and a role-assignment-based method have been successfully realized in this platform to drive multiple robots to play the soccer game, including 2V2,3V3,4V4, and so on. It is believed that the developed simulation environment can be used for data collection and transfer learning (TL), hence bridging the gap of Sim2Real technique in actual implementations.",
10.1109/WSC48552.2020.9384025,Unified Devs-Based Platform for Modeling and Simulation of Hybrid Control Systems,"Recent robotic research has led to different architectural approaches that support enactment of automatically synthesized discrete event controllers from user specifications over low-level continuous variable controllers. Simulation of these hybrid control approaches to robotics can be a useful validation tool for robot users and architecture designers, but presents the key challenge of working with discrete and continuous representations of the robot, its environment and its mission plans. In this work we address this challenge showcasing a unified DEVS-based hybrid simulation platform. We model and simulate the hybrid robotic software architecture of a fixed-wing UAV, including the full stack of controllers involved: discrete, hybrid and continuous. We validate the approach experimentally on a typical UAV mapping mission and show that with our unified approach we are able to achieve simulation speed-ups up to one order of magnitude above our previous Software In The Loop simulation setup.",
10.1117/12.3013861,"Modular, Hierarchical Machine Learning for Sequential Goal Completion","Given a maze populated with different objects, one may task a robot with a sequential goal completion task, e.g. 1) pick up a key then 2) unlock the door then 3) unlock the treasure chest. A typical machine learning (ML) solution would involve a monolithically trained artificial neural network (ANN). However, if the sequence of goals or the goals themselves change, then the ANN must be significantly (or, at worst, completely) retrained. Instead of a monolithic ANN, a modular ML component would be 1) independently optimizable (task-agnostic) and 2) arbitrarily reconfigurable with other ML modules. This work describes a modular, hierarchical ML framework by integrating two emerging ML techniques: 1) cognitive map learners (CML) and 2) hyperdimensional computing (HDC). A CML is a collection of three single layer ANNs (matrices) collaboratively trained to learn the topology of an abstract graph. Here, two CMLs were constructed, one describing locations on in 2D physical space and the other the relative distribution of objects found in this space. Each CML node states was encoded as a high-dimensional vector to utilize HDC, an ML algebra, for symbolic reasoning over these high-dimensional “symbol” vectors. In this way, each sub-goal above was described by algebraic equations of CML node states. Multiple, independently trained CMLs were subsequently assembled together to navigate a maze to solve a sequential goal task. Critically, changes to these goals required only localized changes in the CML-HDC architecture, as opposed to a global ANN retraining scheme. This framework therefore enabled a more traditional engineering approach to ML, akin to digital logic design. © 2024 SPIE.",
10.1145/3373017.3373028,A Short Survey of Pre-trained Language Models for Conversational AI-A New Age in NLP,"Building a dialogue system that can communicate naturally with humans is a challenging yet interesting problem of agent-based computing. The rapid growth in this area is usually hindered by the long-standing problem of data scarcity as these systems are expected to learn syntax, grammar, decision making, and reasoning from insufficient amounts of task-specific dataset. The recently introduced pre-trained language models have the potential to address the issue of data scarcity and bring considerable advantages by generating contextualized word embeddings. These models are considered counterpart of ImageNet in NLP and have demonstrated to capture different facets of language such as hierarchical relations, long-term dependency, and sentiment. In this short survey paper, we discuss the recent progress made in the field of pre-trained language models. We also deliberate that how the strengths of these language models can be leveraged in designing more engaging and more eloquent conversational agents. This paper, therefore, intends to establish whether these pre-trained models can overcome the challenges pertinent to dialogue systems, and how their architecture could be exploited in order to overcome these challenges. Open challenges in the field of dialogue systems have also been deliberated.",
10.1145/3375790,Exploring the Role of Common Model of Cognition in Designing Adaptive Coaching Interactions for Health Behavior Change,"Our research aims to develop intelligent collaborative agents that are human-aware: They can model, learn, and reason about their human partner’s physiological, cognitive, and affective states. In this article, we study how adaptive coaching interactions can be designed to help people develop sustainable healthy behaviors. We leverage the common model of cognition (CMC) [31] as a framework for unifying several behavior change theories that are known to be useful in human–human coaching. We motivate a set of interactive system desiderata based on the CMC-based view of behavior change. Then, we propose PARCoach, an interactive system that addresses the desiderata. PARCoach helps a trainee pick a relevant health goal, set an implementation intention, and track their behavior. During this process, the trainee identifies a specific goal-directed behavior as well as the situational context in which they will perform it. PARCCoach uses this information to send notifications to the trainee, reminding them of their chosen behavior and the context. We report the results from a 4-week deployment with 60 participants. Our results support the CMC-based view of behavior change and demonstrate that the desiderata for proposed interactive system design is useful in producing behavior change.",
10.1145/3377812.3381398,Towards DO-178C certification of adaptive learning UAV agents designed with a cognitive architecture,"Adaptive and Learning Agents (ALAs) bring computational intelligence to their Cyber Physical host systems to adapt to novel situations encountered in their complex operational environment. They do so by learning from their experience to improve their performance. RTCA DO-178C specifies a stringent certification process for airborne software which represents several challenges when applied to an ALA in regards of functional completeness, functional correctness, testability and adaptability. This research claims that it is possible to certify an Adaptive Learning Unmanned Aerial Vehicle (UAV) Agent designed as per a Cognitive Architecture with current DO-178C certification process when leveraging a qualified tool (DO-330), Model-Based Development and Verification (DO-331) and Formal Methods (DO-333). The research consists in developing, as a case study, an ALA embedded in a UAV aimed at neutralizing rogue UAVs in the vicinity of civil airports and test it in the field. This article is the plan to complete, by end 2022, a dissertation currently in its confirmation phase.",
10.1145/3387939.3391591,Software architecture and task plan co-adaptation for mobile service robots,"Self-adaptive systems increasingly need to reason about and adapt both structural and behavioral system aspects, such as in mobile service robots, which must reason about missions that they need to achieve and the architecture of the software executing them. Deciding how to best adapt these systems to run time changes is challenging because it entails considering mutual dependencies between the software architecture that the system is running and the outcome of plans for completing tasks, while also considering multiple trade-offs and uncertainties. Considering all these aspects in planning for adaptation often yields large solution spaces which cannot be adequately explored at run time. We address this challenge by proposing a planning approach able to consider the impact of mutual dependencies between software architecture and task planning on the satisfaction of mission goals. The approach is able to reason quantitatively about the outcome of adaptation decisions handling both the reconfiguration of the system's architecture and adaptation of task plans under uncertainty and in a rich trade-off space. Our results show: (i) feasibility of run-time decision-making for self-adaptation in an otherwise intractable solution space by dividing-and-conquering adaptation into architecture reconfiguration and task planning sub-problems, and (ii) improved quality of adaptation decisions with respect to decision making that does not consider dependencies between architecture and task planning.",
10.1145/3412370,Finding the Largest Successful Coalition under the Strict Goal Preferences of Agents,"Coalition formation has been a fundamental form of resource cooperation for achieving joint goals in multiagent systems. Most existing studies still focus on the traditional assumption that an agent has to contribute its resources to all the goals, even if the agent is not interested in the goal at all. In this article, a natural extension of the traditional coalitional resource games (CRGs) is studied from both theoretical and empirical perspectives, in which each agent has uncompromising, personalized preferences over goals. Specifically, a new CRGs model with agents’ strict preferences for goals is presented, in which an agent is willing to contribute its resources only to the goals that are in its own interest set. The computational complexity of the basic decision problems surrounding the successful coalition is reinvestigated. The results suggest that these problems in such a strict preference way are complex and intractable. To find the largest successful coalition for possible computation reduction or potential parallel processing, a flow-network–based exhaust algorithm, called FNetEA, is proposed to achieve the optimal solution. Then, to solve the problem more efficiently, a hybrid algorithm, named 2D-HA, is developed to find the approximately optimal solution on the basis of genetic algorithm, two-dimensional (2D) solution representation, and a heuristic for solution repairs. Through extensive experiments, the 2D-HA algorithm exhibits the prominent ability to provide reassurances that the optimal solution could be found within a reasonable period of time, even in a super-large-scale space.",
10.1145/3412841.3441942,The interplay of a conversational ontology and AI planning for health dialogue management,"Health dialogue systems are required to respect some special requirements such as predictability and reliability. While knowledge based approaches still seem to be the most appropriate for these systems, the automated generation of reliable policies remains an open problem. This work proposes an approach that integrates a conversational ontology (Convology) and Artificial Intelligence planning with the aim of automating the generation of a dialogue manager capable of handling goal-oriented dialogues for the health domain. The resulting dialogue manager is aimed to be integrated into a suitable architecture that provides the natural language components. We illustrate our approach by describing how it has been implemented into PuffBot, a multi-turn goal-oriented conversational agent for supporting patients affected by asthma.",
10.1145/3444369,Developing Conversational Agents for Use in Criminal Investigations,"The adoption of artificial intelligence (AI) systems in environments that involve high risk and high consequence decision-making is severely hampered by critical design issues. These issues include system transparency and brittleness, where transparency relates to (i) the explainability of results and (ii) the ability of a user to inspect and verify system goals and constraints; and brittleness, (iii) the ability of a system to adapt to new user demands. Transparency is a particular concern for criminal intelligence analysis, where there are significant ethical and trust issues that arise when algorithmic and system processes are not adequately understood by a user. This prevents adoption of potentially useful technologies in policing environments. In this article, we present a novel approach to designing a conversational agent (CA) AI system for intelligence analysis that tackles these issues. We discuss the results and implications of three different studies; a Cognitive Task Analysis to understand analyst thinking when retrieving information in an investigation, Emergent Themes Analysis to understand the explanation needs of different system components, and an interactive experiment with a prototype conversational agent. Our prototype conversational agent, named Pan, demonstrates transparency provision and mitigates brittleness by evolving new CA intentions. We encode interactions with the CA with human factors principles for situation recognition and use interactive visual analytics to support analyst reasoning. Our approach enables complex AI systems, such as Pan, to be used in sensitive environments, and our research has broader application than the use case discussed.",
10.1145/3457682.3457759,Multi-Perspective Reasoning Transformers,"Machine Reading Comprehension is defined as the ability of machines to read and understand unstructured text and answer questions about it. It is considered as a challenging task with wide range of enterprise applications. Wide range of natural language understanding and reasoning tasks are found embedded within machine reading comprehension datasets. This requires effective models with robust relational reasoning capabilities to answer complex questions. Reasoning in natural language is a long-term machine-learning goal and is critically needed for building intelligent agents. However, most papers heavily depend on underlying language modeling and thus pay little to no attention on creating effective reasoning models. This paper proposes a modified transformer architecture that effectively combines soft and hard attention to create multi-perspective reasoning model capable of tackling wide range of reasoning tasks. An attention mechanism that highlights the relational significance of input signals is considered as well. The result from this study shows performance gain as compared to its counterpart the transformer network on bAbI dataset, a natural language reasoning tasks.",
10.1145/3460210.3493585,Cutting Events: Towards Autonomous Plan Adaption by Robotic Agents through Image-Schematic Event Segmentation,"Autonomous robots struggle with plan adaption in uncertain and changing environments. Although modern robots can make popcorn and pancakes, they are incapable of performing such tasks in unknown settings and unable to adapt action plans if ingredients or tools are missing. Humans are continuously aware of their surroundings. For robotic agents, real-time state updating is time-consuming and other methods for failure handling are required. Taking inspiration from human cognition, we propose a plan adaption method based on event segmentation of the image-schematic states of subtasks within action descriptors. For this, we reuse action plans of the robotic architecture CRAM and ontologically model the involved objects and image-schematic states of the action descriptor cutting. Our evaluation uses a robot simulation of the task of cutting bread and demonstrates that the system can reason about possible solutions to unexpected failures regarding tool use.",
10.1145/3461615.3485413,Get Together in the Middle-earth: a First Step Towards Hybrid Intelligence Systems,"In the last decade, the number of computer systems using AI has increased dramatically. To date, indeed, AI is present in almost all the aspects of the human everyday life. This resulted in the attempt of scholars in Computer Science to endow machines with human-like socio-cognitive skills and/or human-like embodiment to try to improve interactions. Such an approach, however, highlights several crucial issues related to the substantial differences between fine-grained human skills and what machines can do and learn. So, although being expensive and sophisticated tools, machines tend to be “idiots savants”. Hybrid Intelligence (HI) is aimed to tackle this issue by proposing, as Akata and colleagues say, “systems that operate as mixed teams, where humans and machines cooperate synergistically, proactively, and purposefully to achieve shared goals”. To our knowledge, however, HI is at a very early exploratory stage, and few concrete solutions to deal with it exist. In this position paper we introduce and briefly describe “Middle-Earth”, a conceptual and experimental ground to study HI. Moreover, we present a first prototype of a software platform based on immersive VR environments, on which we plan to carry out in the future the first pioneering experiments on teams of humans and/or AI-driven agents getting together in Middle Earth to perform collaborative tasks.",
10.1145/3461702.3462515,A Multi-Agent Approach to Combine Reasoning and Learning for an Ethical Behavior,"The recent field of Machine Ethics is experiencing rapid growth to answer the societal need for Artificial Intelligence (AI) algorithms imbued with ethical considerations, such as benevolence toward human users and actors. Several approaches already exist for this purpose, mostly either by reasoning over a set of predefined ethical principles (Top-Down), or by learning new principles (Bottom-Up). While both methods have their own advantages and drawbacks, only few works have explored hybrid approaches, such as using symbolic rules to guide the learning process for instance, combining the advantages of each. This paper draws upon existing works to propose a novel hybrid method using symbolic judging agents to evaluate the ethics of learning agents' behaviors, and accordingly improve their ability to ethically behave in dynamic multi-agent environments. Multiple benefits ensue from this separation between judging and learning agents: agents can evolve (or be updated by human designers) separately, benefiting from co-construction processes; judging agents can act as accessible proxies for non-expert human stakeholders or regulators; and finally, multiple points of view (one per judging agent) can be adopted to judge the behavior of the same agent, which produces a richer feedback. Our proposed approach is applied to an energy distribution problem, in the context of a Smart Grid simulator, with continuous and multi-dimensional states and actions. The experiments and results show the ability of learning agents to correctly adapt their behaviors to comply with the judging agents' rules, including when rules evolve over time.",
10.1145/3481585,"A Cloud-based Robot System for Long-term Interaction: Principles, Implementation, Lessons Learned","Making the transition to long-term interaction with social-robot systems has been identified as one of the main challenges in human-robot interaction. This article identifies four design principles to address this challenge and applies them in a real-world implementation: cloud-based robot control, a modular design, one common knowledge base for all applications, and hybrid artificial intelligence for decision making and reasoning. The control architecture for this robot includes a common Knowledge-base (ontologies), Data-base, “Hybrid Artificial Brain” (dialogue manager, action selection and explainable AI), Activities Centre (Timeline, Quiz, Break and Sort, Memory, Tip of the Day,  ( ldots  ) ), Embodied Conversational Agent (ECA, i.e., robot and avatar), and Dashboards (for authoring and monitoring the interaction). Further, the ECA is integrated with an expandable set of (mobile) health applications. The resulting system is a Personal Assistant for a healthy Lifestyle (PAL), which supports diabetic children with self-management and educates them on health-related issues (48 children, aged 6–14, recruited via hospitals in the Netherlands and in Italy). It is capable of autonomous interaction “in the wild” for prolonged periods of time without the need for a “Wizard-of-Oz” (up until 6 months online). PAL is an exemplary system that provides personalised, stable and diverse, long-term human-robot interaction.",
10.1145/3485114.3485122,The new analog: A protocol for linking design and construction intent with algorithmic planning for robotic assembly of complex structures,"Construction robotics are increasingly popular in the architectural fabrication community due to their accuracy and flexibility. Because of their high degree of motion freedom, these tools are able to assemble complex structures with irregular designs, which advances architectural aesthetics and structural performance. However, automated task and motion planning (TAMP) for a robot to assemble non-repetitive objects can be challenging due to (1) a non-repetitive assembly pattern (2) the need for a continuous robotic motion throughout a sequence of movement (3) a congested construction scene and (4) occasional robot configuration constraints due to taught positions. Recent work has already begun to address these challenges for repetitive assembly processes, where the robot repeats a pattern of primitive behaviors (e.g. brick stacking or spatial extrusion). Yet, there are many assembly processes that can benefit from a non-repetitive pattern. For example, processes can change tools on an element-by-element level to accommodate a wider range of geometry. Our work is motivated by the necessity of robotic modeling and planning for a recently published timber assembly process which utilizes distributed robotic clamps to press together interlocking joints. In addition to pick-and-place operations, the robot needs to move numerous tools within the construction scene, similar to a tool-change operation. In order to facilitate an agile process for architectural design, construction process design, and TAMP, we introduce a flowchart-based specification language which allows various designers to describe their design and construction intent and knowledge. A compiler can then translate the assembly description, sequence, process flowchart, and robotic setup into a plan skeleton. Additionally, we present a linear and a non-linear solving algorithm that can solve the plan skeleton for a full sequence of robot motions. This algorithm can be customized to take into account designer intuition, which can speed up the planning process. We provide a comparison of the two algorithms using the timber assembly process as our case study. We validate our results by robotically executing and constructing a large-scale real-world timber structure. Finally, we demonstrate the flexibility of our flowchart by showing how custom assembly actions are modeled in our case study. We also demonstrate how other recently published robotic assembly processes can be formulated using our flowcharts to demonstrate generalizability.",
10.1145/3503161.3548281,Target-Driven Structured Transformer Planner for Vision-Language Navigation,"Vision-language navigation is the task of directing an embodied agent to navigate in 3D scenes with natural language instructions. For the agent, inferring the long-term navigation target from visual-linguistic clues is crucial for reliable path planning, which, however, has rarely been studied before in literature. In this article, we propose a Target-Driven Structured Transformer Planner (TD-STP) for long-horizon goal-guided and room layout-aware navigation. Specifically, we devise an Imaginary Scene Tokenization mechanism for explicit estimation of the long-term target (even located in unexplored environments). In addition, we design a Structured Transformer Planner which elegantly incorporates the explored room layout into a neural attention architecture for structured and global planning. Experimental results demonstrate that our TD-STP substantially improves previous best methods' success rate by 2\% and 5\% on the test set of R2R and REVERIE benchmarks, respectively. Our code is available at https://github.com/YushengZhao/TD-STP.",
10.1145/3503795,Enabling Morally Sensitive Robotic Clarification Requests,"The design of current natural language-oriented robot architectures enables certain architectural components to circumvent moral reasoning capabilities. One example of this is reflexive generation of clarification requests as soon as referential ambiguity is detected in a human utterance. As shown in previous research, this can lead robots to (1) miscommunicate their moral dispositions and (2) weaken human perception or application of moral norms within their current context. We present a solution to these problems by performing moral reasoning on each potential disambiguation of an ambiguous human utterance and responding accordingly, rather than immediately and naively requesting clarification. We implement our solution in the Distributed Integrated Cognition Affect and Reflection robot architecture, which, to our knowledge, is the only current robot architecture with both moral reasoning and clarification request generation capabilities. We then evaluate our method with a human subjects experiment, the results of which indicate that our approach successfully ameliorates the two identified concerns.",
10.1145/3510822,FAtiMA Toolkit: Toward an Accessible Tool for the Development of Socio-emotional Agents,"More than a decade has passed since the development of FearNot!, an application designed to help children deal with bullying through role-playing with virtual characters. It was also the application that led to the creation of FAtiMA, an affective agent architecture for creating autonomous characters that can evoke empathic responses. In this article, we describe the FAtiMA Toolkit, a collection of open-source tools that is designed to help researchers, game developers, and roboticists incorporate a computational model of emotion and decision-making in their work. The toolkit was developed with the goal of making FAtiMA more accessible, easier to incorporate into different projects, and more flexible in its capabilities for human-agent interaction, based upon the experience gathered over the years across different virtual environments and human-robot interaction scenarios. As a result, this work makes several different contributions to the field of Agent-Based Architectures. More precisely, the FAtiMA Toolkit’s library-based design allows developers to easily integrate it with other frameworks, its meta-cognitive model affords different internal reasoners and affective components, and its explicit dialogue structure gives control to the author even within highly complex scenarios. To demonstrate the use of the FAtiMA Toolkit, several different use cases where the toolkit was successfully applied are described and discussed.",
10.1145/3512943,Human-AI Collaboration for UX Evaluation: Effects of Explanation and Synchronization,"Analyzing usability test videos is arduous. Although recent research showed the promise of AI in assisting with such tasks, it remains largely unknown how AI should be designed to facilitate effective collaboration between user experience (UX) evaluators and AI. Inspired by the concepts of agency and work context in human and AI collaboration literature, we studied two corresponding design factors for AI-assisted UX evaluation: explanations and synchronization. Explanations allow AI to further inform humans how it identifies UX problems from a usability test session; synchronization refers to the two ways humans and AI collaborate: synchronously and asynchronously. We iteratively designed a tool-AI Assistant-with four versions of UIs corresponding to the two levels of explanations (with/without) and synchronization (sync/async). By adopting a hybrid wizard-of-oz approach to simulating an AI with reasonable performance, we conducted a mixed-method study with 24 UX evaluators identifying UX problems from usability test videos using AI Assistant. Our quantitative and qualitative results show that AI with explanations, regardless of being presented synchronously or asynchronously, provided better support for UX evaluators' analysis and was perceived more positively; when without explanations, synchronous AI better improved UX evaluators' performance and engagement compared to the asynchronous AI. Lastly, we present the design implications for AI-assisted UX evaluation and facilitating more effective human-AI collaboration.",
10.1145/3514094.3534182,Piecemeal Knowledge Acquisition for Computational Normative Reasoning,"We present a hybrid approach to knowledge acquisition and representation for machine ethics---or more generally, computational normative reasoning. Building on recent research in artificial intelligence and law, our approach is modeled on the familiar practice of decision-making under precedential constraint in the common law. We first provide a formal characterization of this practice, showing how a body of normative information can be constructed in a way that is piecemeal, distributed, and responsive to particular circumstances. We then discuss two possible applications: first, a robot childminder, and second, moral judgment in a bioethical domain.",
10.1145/3528228.3528407,Digital mentor: towards a conversational bot to identify hypotheses for software startups,"Software startups develop innovative, software-intensive product and services. This context leads to uncertainty regarding the software they are building. Experimentation, a process of testing hypotheses about the product, helps these companies to reduce uncertainty through different evidence-based approaches. The first step in experimentation is to identify the hypotheses to be tested. HyMap is a technique where a facilitator helps a software startup founder to draw a cognitive map representing her understanding of the context and, based on that, create hypotheses about the software to be built. In this paper, we present the Digital Mentor, an working-in-progress conversational bot to help creating a HyMap without the need of a human facilitator. We report the proposed solution consisting of a web application with the backend of a natural language understanding system, the current state of development, the challenges we faced so far and the next steps we plan to move forward.",
10.1145/3532105.3535018,BlueSky: Combining Task Planning and Activity-Centric Access Control for Assistive Humanoid Robots,"In the not too distant future, assistive humanoid robots will provide versatile assistance for coping with everyday life. In their interactions with humans, not only safety, but also security and privacy issues need to be considered. In this Blue Sky paper, we therefore argue that it is time to bring task planning and execution as a well-established field of robotics with access and usage control in the field of security and privacy closer together. In particular, the recently proposed activity-based view on access and usage control provides a promising approach to bridge the gap between these two perspectives. We argue that humanoid robots provide for specific challenges due to their task-universality and their use in both, private and public spaces. Furthermore, they are socially connected to various parties and require policy creation at runtime due to learning. We contribute first attempts on the architecture and enforcement layer as well as on joint modeling, and discuss challenges and a research roadmap also for the policy and objectives layer. We conclude that the underlying combination of decentralized systems' and smart environments' research aspects provides for a rich source of challenges that need to be addressed on the road to deployment.",
10.1145/3555776.3577657,Modeling a Conversational Agent using BDI Framework,"Building conversational agents to help humans in domain-specific tasks is challenging since the agent needs to understand the natural language and act over it while accessing domain expert knowledge. Modern natural language processing techniques led to an expansion of conversational agents, with recent pretrained language models achieving increasingly accurate language recognition results using ever-larger open datasets. However, the black-box nature of such pretrained language models obscures the agent's reasoning and its motivations when responding, leading to unexplained dialogues. We develop a belief-desire-intention (BDI) agent as a task-oriented dialogue system to introduce mental attitudes similar to humans describing their behavior during a dialogue. We compare the resulting model with a pipeline dialogue model by leveraging existing components from dialogue systems and developing the agent's intention selection as a dialogue policy. We show that combining traditional agent modelling approaches, such as BDI, with more recent learning techniques can result in efficient and scrutable dialogue systems.",
10.1145/3565287.3617637,Toward a Better Understanding of the Emotional Dynamics of Negotiation with Large Language Models,"Current approaches to building negotiation agents rely either on model-based techniques that explicitly implement key principles of negotiation or model-free techniques leveraging algorithms developed via training on large amounts of human-generated text. We bridge these two approaches by combining a model-based approach with large language models for natural language understanding and generation. We find large language models perform well at recognizing dialogue acts and an opponent's emotions; perform reasonably well at recognizing opponents' preferences in the negotiation; and perform worse at understanding opponent offers. We also perform a qualitative comparison of the capabilities of our hybrid approach with a model-free method and find our hybrid agent provides safeguards against hallucinations and guarantees more control over aspects of negotiation such as emotional expressions, information sharing, and concession strategies.",
10.1145/3586183.3606763,Generative Agents: Interactive Simulacra of Human Behavior,"Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents: computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent’s experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty-five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behaviors. For example, starting with only a single user-specified notion that one agent wants to throw a Valentine’s Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture—observation, planning, and reflection—each contribute critically to the believability of agent behavior. By fusing large language models with computational interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior.",
10.1145/3587259.3627561,Knowledge-enhanced Agents for Interactive Text Games,"Communication via natural language is a key aspect of machine intelligence, and it requires computational models to learn and reason about world concepts, with varying levels of supervision. Significant progress has been made on fully-supervised non-interactive tasks, such as question-answering and procedural text understanding. Yet, various sequential interactive tasks, as in text-based games, have revealed limitations of existing approaches in terms of coherence, contextual awareness, and their ability to learn effectively from the environment. In this paper, we propose a knowledge-injection framework for improved functional grounding of agents in text-based games. Specifically, we consider two forms of domain knowledge that we inject into learning-based agents: memory of previous correct actions and affordances of relevant objects in the environment. Our framework supports two representative model classes: reinforcement learning agents and language model agents. Furthermore, we devise multiple injection strategies for the above domain knowledge types and agent architectures, including injection via knowledge graphs and augmentation of the existing input encoding strategies. We experiment with four models on the 10 tasks in the ScienceWorld&nbsp;text-based game environment, to illustrate the impact of knowledge injection on various model configurations and challenging task settings. Our findings provide crucial insights into the interplay between task properties, model architectures, and domain knowledge for interactive contexts.",
10.1145/3594806.3596534,Voice-Based Conversational Agents and Knowledge Graphs for Improving News Search in Assisted Living,"As the healthcare sector faces major challenges, such as aging populations, staff shortages, and common chronic diseases, delivering high-quality care to individuals has become very difficult. Conversational agents have shown to be a promising technology to alleviate some of these issues. In the form of digital health assistants, they have the potential to improve the everyday life of the elderly and chronically ill people. This includes, for example, medication reminders, routine checks, or social chit-chat. In addition, conversational agents can satisfy the fundamental need of having access to information about daily news or local events, which enables individuals to stay informed and connected with the world around them. However, finding relevant news sources and navigating the plethora of online news articles can be overwhelming, particularly for those with limited technological literacy or health-related impairments. To address this challenge, we propose an innovative solution that combines knowledge graphs and conversational agents for news search in assisted living. By leveraging graph databases to semantically structure news data and implementing an intuitive voice-based interface, our system can help care-dependent people easily discover relevant news articles and give personalized recommendations. We explain our design choices, provide a system architecture, share insights of an initial user test, and give an outlook on planned future work.",
10.1145/3607720.3607796,"Tweets similarity classification based on Machine Learning Algorithms, TF-IDF and the Dynamic Case Based Reasoning","The research on the field of Twitter sentiment analysis, which aims to extract users’ sentiments through their public opinion about a given topic, has been increased and grown rapidly across a broad range of disciplines in the last decade. In this article, we propose a hybrid approach for Tweets similarity classification Based on Dynamic Case Based Reasoning approach, machine learning algorithms and Multi-Agent System. Our approach proposes a multi-agent adaptive system for Tweets similarity classification. It combines the Dynamic Case-Based Reasoning approach with the scientific measurement of keyword weight (Term Frequency- Inverse Document Frequency, TF-IDF). It consists of gathering and pre-processing tweets about a given topic and use a feature extraction to extract useful features. Machine Learning algorithms are then used for similarity content-based classification. Our approach is general and can be used to follow users’ tweets traces to predict their sentiments and provide them with an individualized content. In this study, Covid-19 tweets have been taken as an example.",
10.1145/3610068,How Time Pressure in Different Phases of Decision-Making Influences Human-AI Collaboration,"Human cognitive and decision-making abilities depreciate under pressure, motivating the emergence of artificial intelligence (AI) systems as decision support tools to assist people in performing tasks under stress. In this work, we study human decision-making behavior and task performance under time pressure---induced from limitedinitial observation time (time to perform the task before providing an initial response without AI input) andfinal decision time (time to weigh an AI's suggestion before reaching a collective human-AI team answer)---for spatial reasoning and count estimation tasks. Our results show that, while the impact of initial observation time on AI-assisted decision-making was dependent on task nature, participants were more likely to follow AI suggestions when they were provided with longer final decision time; moreover, although participants generally tended to adhere to their initial responses, they had more agency when they were more logically engaged in a task. Our results offer a nuanced understanding of human-AI collaboration under time pressure in different phases of the decision-making process.",
10.1145/3623385,“Do This Instead”—Robots That Adequately Respond to Corrected Instructions,"Natural language instructions are effective at tasking autonomous robots and for teaching them new knowledge quickly. Yet, human instructors are not perfect and are likely to make mistakes at times and will correct themselves when they notice errors in their own instructions. In this article, we introduce a complete system for robot behaviors to handle such corrections, during both task instruction and action execution. We then demonstrate its operation in an integrated cognitive robotic architecture through spoken language in two tasks: a navigation and retrieval task and a meal assembly task. Verbal corrections occur before, during, and after verbally taught sequences of tasks, demonstrating that the proposed methods enable fast corrections not only of the semantics generated from the instructions but also of overt robot behavior in a manner shown to be reasonable when compared to human behavior and expectations.",
10.1145/3623387,"UHTP: A User-Aware Hierarchical Task Planning Framework for Communication-Free, Mutually-Adaptive Human-Robot Collaboration","Collaborative human-robot task execution approaches require mutual adaptation, allowing both the human and robot partners to take active roles in action selection and role assignment to achieve a single shared goal. Prior works have utilized a leader-follower paradigm in which either agent must follow the actions specified by the other agent. We introduce the User-aware Hierarchical Task Planning (UHTP) framework, a communication-free human-robot collaborative approach for adaptive execution of multi-step tasks that moves beyond the leader-follower paradigm. Specifically, our approach enables the robot to observe the human, perform actions that support the human’s decisions, and actively select actions that maximize the expected efficiency of the collaborative task. In turn, the human chooses actions based on their observation of the task and the robot, without being dictated by a scheduler or the robot. We evaluate UHTP both in simulation and in a human subjects experiment of a collaborative drill assembly task. Our results show that UHTP achieves more efficient task plans and shorter task completion times than non-adaptive baselines across a wide range of human behaviors, that interacting with a UHTP-controlled robot reduces the human’s cognitive workload, and that humans prefer to work with our adaptive robot over a fixed-policy alternative.",
10.1145/3632410.3632430,DSDF: Coordinated look-ahead strategy in multi-agent reinforcement learning with noisy agents,"Existing methods of Multi-Agent Reinforcement learning, involving Centralized Training and Decentralized execution, attempt to train the agents towards learning a pattern of coordinated actions to arrive at optimal joint policy. However, during the execution phase, if some of the agents degrade and perform noisy actions (not the same actions suggested by policy) to varying degrees, the above methods provide poor coordination. In this paper, we show how such random noise in agents, which could be a result of the degradation or aging of robots, can add to the uncertainty in coordination and thereby contribute to unsatisfactory global rewards. In such a scenario, the agents which are in accordance with the policy have to understand the behavior and limitations of the noisy agents while the noisy agents have to plan in cognizance of their limitations. In our proposed method, Deep Stochastic Discount Factor (DSDF), based on the degree of degradation the algorithm tunes the discount factor for each agent uniquely, thereby altering the global planning of the agents. Moreover, given the degree of degradation in some agents is expected to change over time, our method provides a framework under which such changes can be incrementally addressed without extensive retraining. Results on benchmark environments show the efficacy of the DSDF approach when compared with existing approaches.",
10.1145/3639856.3639879,CONRAD: Cognitive Intent Driven 5G Network Slice Planning and Design,"The emergence of 5G allows the network to be sliced to meet multiple service requirements. However, current design systems are policy-driven, which limits the ability to redesign the 5G network adaptively for requirements or traffic patterns. In this paper, we propose Conrad, an autonomous and intent-driven framework that can allocate resources efficiently to meet 5G slice requirements. Via the use of a cognitive intent handling engine, the requirements are transformed to goals that may be solved using machine reasoning techniques. Four agents are registered for forecasting, design planning, evaluation and actuation to enable dynamic re-design of the 5G slices. Exploiting automated planning techniques, proposals are provided to optimally provision the network slice resources. This process is demonstrated over a radio access network (RAN) slicing use case with intents on average expected throughput.",
10.1145/3648536.3648545,A Multi-Robot Architecture Framework for Effective Robot Teammates in Mixed-Initiative Teams,"Effective robotic teammates should be able to interact with humans in natural language about all task aspects, keep track of task and team states to coordinate their actions, and handle unexpected events autonomously. In this paper, we introduce a multi-robot architectural framework for effective robot teammates that allows robots to learn new tasks on the fly and monitor task execution to be able to detect unexpected faults and events. It enables robots to generate recovery plans, assess their effectiveness, and engage with human teammates in problem solving dialogues. We demonstrate the capabilities and operation of the framework in a complex mixed-initiative human-robot medical assembly and delivery task.",
10.1145/3649158.3657034,BlueSky: How to Raise a Robot - A Case for Neuro-Symbolic AI in Constrained Task Planning for Humanoid Assistive Robots,"Humanoid robots will be able to assist humans in their daily life, in particular due to their versatile action capabilities. However, while these robots need a certain degree of autonomy to learn and explore, they also should respect various constraints, for access control and beyond. We explore the novel field of incorporating privacy, security, and access control constraints with robot task planning approaches. We report preliminary results on the classical symbolic approach, deep-learned neural networks, and modern ideas using large language models as knowledge base. From analyzing their trade-offs, we conclude that a hybrid approach is necessary, and thereby present a new use case for the emerging field of neuro-symbolic artificial intelligence.",
10.1145/3652628.3652670,Multi-Constraint Flexible Job Scheduling Algorithm Based on DDQN: A Deep Reinforcement Learning Algorithm for Solving Practical Job Scheduling Problems,"As an important part of intelligent manufacturing, reasonable scheduling of production planning is very important for reducing costs and increasing efficiency. This paper considers that the current algorithms related to intelligent scheduling do not consider the actual constraints enough, and the solution efficiency cannot satisfy the application requirements. Considering the actual industrial production and a variety of practical constraints including employee attendance time and machine start-up time, this paper proposes a deep reinforcement learning algorithm. The goal of this research is to minimize the total production cost including product processing costs, employee overtime costs, order back-order costs, finished and semi-finished product inventory costs. In this paper, the intelligent scheduling problem is modeled as a Markov decision-making process, and the agent selects and executes actions according to the state at each decision-making stage. In this paper, the Double DQN neural network architecture is built. Seven features are extracted from the scheduling environment to form a feature vector representation state, and six composite scheduling rules are designed to form an action set considering the optimization goal. A reward function closely related to the goal is designed. Numerical experiments show that the quality of the solution set obtained by the reinforcement learning algorithm is better than or similar to that of the genetic algorithm, and the solution speed is significantly better than that of other algorithms, which proves the effectiveness and feasibility of the proposed algorithm.",
10.1145/3654439,The IDEA of Us: An Identity-Aware Architecture for Autonomous Systems,"Autonomous systems, such as drones and rescue robots, are increasingly used during emergencies. They deliver services and provide situational awareness that facilitate emergency management and response. To do so, they need to interact and cooperate with humans in their environment. Human behaviour is uncertain and complex, so it can be difficult to reason about it formally. In this article, we propose IDEA: an adaptive software architecture that enables cooperation between humans and autonomous systems, by leveraging the social identity approach. This approach establishes that group membership drives human behaviour. Identity and group membership are crucial during emergencies, as they influence cooperation among survivors. IDEA systems infer the social identity of surrounding humans, thereby establishing their group membership. By reasoning about groups, we limit the number of cooperation strategies the system needs to explore. IDEA systems select a strategy from the equilibrium analysis of game-theoretic models that represent interactions between group members and the IDEA system. We demonstrate our approach using a search-and-rescue scenario, in which an IDEA rescue robot optimises evacuation by collaborating with survivors. Using an empirically validated agent-based model, we show that the deployment of the IDEA system can reduce median evacuation time by 13.6\%.",
10.1145/3659061,Generating Pattern-Based Conventions for Predictable Planning in Human–Robot Collaboration,"For humans to effectively work with robots, they must be able to predict the actions and behaviors of their robot teammates rather than merely react to them. While there are existing techniques enabling robots to adapt to human behavior, there is a demonstrated need for methods that explicitly improve humans’ ability to understand and predict robot behavior at multi-task timescales. In this work, we propose a method leveraging the innate human propensity for pattern recognition in order to improve team dynamics in human–robot teams and to make robots more predictable to the humans that work with them. Patterns are a cognitive tool that humans use and rely on often, and the human brain is in many ways primed for pattern recognition and usage. We propose pattern-aware convention-setting for teaming (PACT), an entropy-based algorithm that identifies and imposes appropriate patterns over a robot’s planner or policy over long time horizons. These patterns are autonomously generated and chosen via an algorithmic process that considers human-perceptible features and characteristics derived from the tasks to be completed, and as such, produces behavior that is easier for humans to identify and predict. Our evaluation shows that PACT contributes to significant improvements in team dynamics and teammate perceptions of the robot, as compared to robots that utilize traditionally ‘optimal’ plans and robots utilizing unoptimized patterns.",
10.1145/3665331,Generating and Evaluating Data of Daily Activities with an Autonomous Agent in a Virtual Smart Home,"Training machine learning models to identify human behavior is a difficult yet essential task to develop autonomous and adaptive systems such as smart homes. These models require large and diversified amounts of labeled data to be trained effectively. Due to the high variety of home environments and occupant behaviors, collecting datasets that are representative of all possible homes is a major challenge. In addition, privacy and cost are major hurdles to collect real home data. To avoid these difficulties, one solution consists of training these models using purely synthetic data, which can be generated through the simulation of home and their occupants. Two challenges arise from this approach: designing a methodology with a simulation able to generate credible simulated data and evaluating this credibility. In this article, we explain the methodology used to generate diversified synthetic data of daily activities, through the combination of an agent model to simulate an occupant and a simulated 3D house enriched with sensors and effectors to produce such data. We demonstrate the credibility of the generated synthetic data by comparing their efficacy for training human context understanding models against the efficacy generated by real data. To achieve this, we replicate a real dataset collection setting with our smart home simulator. The occupant is replaced by an autonomous agent following the same experimental protocol used for the real dataset collection. This agent is a BDI-based model enhanced with a scheduler designed to offer a balance between control and autonomy. This balance is useful in synthetic data generation since strong constraints can be imposed on the agent to simulate desired situations while allowing autonomous behaviors outside these constraints to generate diversified data. In our case, the constraints are those imposed during the real dataset collection that we want to replicate. The simulated sensors and effectors were configured to react to the agent’s behaviors similarly to the real ones. We experimentally show that data generated from this simulation are valuable for two human context understanding tasks: current human activity recognition and future human activity prediction. In particular, we show that models trained solely with simulated data can give reasonable predictions about real situations occurring in the original dataset. We also report experimental results regarding statistical analysis and C2ST to assess the credibility of generated data. We discuss the generality of our approach for evaluating the credibility of simulated data from their use as training data.",
10.1145/3665939.3665963,CopycHats: Question Sequencing with Artificial Agents,"Schema Matching, the task of finding correspondences among attributes of different schemata, plays an important role in data integration. The task has been extensively researched, leading to the development of multiple algorithmic approaches, many of which incorporate humans to some extent, by performing the matching, validating algorithmic solutions, or generating reliable ground truth for algorithms to be trained against. Human matching is a temporal process, in which previous decisions and ongoing cognitive processes influence future behavior. Therefore, planning a human matching task necessitates careful consideration, for example, the ordering of questions posed to the matcher. Various strategies exist for optimally choosing the sequence of matching questions and evaluating them may be limited by notable inherent human limitations. In this work, we propose to leverage Large Language Models (LLMs) to create artificial agents that emulate human agents in order to evaluate question sequencing strategies. We offer an alternative to traditional human-based evaluations, which overcome those limitations. We test our suggested evaluation framework and discuss the similarities and differences between artificial and human agents in the context of schema matching evaluation.",
10.1145/3676536.3698389,Thinking and Moving: An Efficient Computing Approach for Integrated Task and Motion Planning in Cooperative Embodied AI Systems,"Cooperative embodied AI systems, where multiple agents collaborate to accomplish complex, long-horizon tasks, show significant promise for real-world applications. These systems integrate perception, cognition, and action through integrated task and motion planning (TAMP), leveraging the advanced reasoning and communication capabilities of large language models (LLMs). However, their efficiency is often hindered by challenges such as high computational latency and redundant communication, largely due to the reliance on LLMs for sequential planning decisions.In this paper, we aim to identify the inherent characteristics and optimization opportunities in cooperative embodied AI systems. We first present a cognitive-inspired modular framework encompassing perception, memory, communication, planning, and execution. We then conduct a detailed profiling analysis of two state-of-the-art cooperative embodied systems, revealing the significance of each module and identifying critical bottlenecks such as redundant message pre-generation and excessive LLM usage in decision-making processes. Based on these insights, we propose several model- and system-level optimizations, including a planning-first communication strategy, selective multi-agent communication, and planning-guided multi-step execution. Evaluated across long-horizon cooperative tasks, these optimizations reduce the frequency of LLM inference runs, achieving an average 3.93\texttimes{} speedup in end-to-end task execution. Finally, we discuss the challenges and potential directions for embodied AI computing, to enhance system flexibility, efficiency, and scalability.",
10.1145/3677052.3698597,"FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning","Financial intelligence generation from vast data sources has typically relied on traditional methods of knowledge-graph construction or database engineering. Recently, fine-tuned financial domain-specific Large Language Models (LLMs), have emerged. While these advancements are promising, limitations such as high inference costs, hallucinations, and the complexity of concurrently analyzing high-dimensional financial data, emerge. This motivates our invention FISHNET (Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert swarming, and Task planning), an agentic architecture that accomplishes highly complex analytical tasks for more than 98,000 regulatory filings that vary immensely in terms of semantics, data hierarchy, or format. FISHNET shows remarkable performance for financial insight generation (61.8\% success rate over 5.0\% Routing, 45.6\% RAG R-Precision). We conduct rigorous ablations to empirically prove the success of FISHNET, each agent’s importance, and the optimized performance of assembling all agents. Our modular architecture can be leveraged for a myriad of use-cases, enabling scalability, flexibility, and data integrity that are critical for financial tasks.",
10.1145/3686592.3686595,Enhancing spatially-disaggregated simulations with large language models,"We present our experience integrating large language models (LLMs) and simulation engines to enhance spatially-disaggregated simulation, taking advantage of the spatial knowledge and spatial reasoning capabilities of LLMs. The examples illustrate LLM integration with different variations of compartmental epidemiological models, including agent-based models (ABM) in the context of modeling COVID-19 infection spread in a school setting, and LLM integration with a system dynamics model which supports a serious game focused on strategies for responding to disease outbreaks at the county level. We present the architecture of the integrated LLM-simulation system, demonstrate the initial results, and discuss the challenges of the current approach, related to LLM's understanding of spatial information and spatial relationships, their reasoning capabilities, and model performance and scalability.",
10.1145/3689933.3690834,Automated APT Defense Using Reinforcement Learning and Attack Graph Risk-based Situation Awareness,"Advanced Persistent Threats pose significant risks to communication and infrastructure systems. While both heuristic and reinforcement learning have been applied to address this challenge, current approaches rely on fixed assumptions or use simplistic state representations and reward functions, compromising adaptability and accuracy. In this paper, we propose a novel intelligent agent system that enhances security against APTs by leveraging MulVAL attack graphs and quantitative risk assessment. Our approach translates complex MulVAL attack graph states into a compact RL state representation, enabling efficient learning in dynamic network environments. We integrate quantitative attack graph-based risk assessment into the RL framework, employing a hybrid reward function that incorporates residual risk, risk reduction, control efficacy, and cost. This risk-based approach provides enhanced context and situation awareness to the RL agent, facilitating more informed long-term decision-making. Using both Q-learning and Proximal Policy Optimization algorithms, we train and evaluate our system on an emulated industrial control system environment under realistic APT attacks. Experimental results demonstrate the significant benefits of our risk-based approach in guiding RL agents. Compared to non-risk configurations, our method shows improved success rates in APT mitigation, reduced control costs, which imply better long-term strategic planning.",
10.1145/3691620.3695336,Towards LLM-augmented multiagent systems for agile software engineering,"A cognitive multi-agent ecosystem designed for efficient software engineering using Agile methodologies can significantly improve software development processes. Key components include the integration of Multi-Agent Systems (MAS) and Large Language Models (LLMs), utilizing Dynamic Context techniques for agent profiling, and Theory of Mind to enhance collaboration. The CogniSim Ecosystem analyzes problems, proposes solutions, constructs and validates plans, and coordinates specialized agents playing roles such as developers, executors, quality checkers, and methodology reviewers. These agents produce documentation, models, and diagrams (e.g., UML) while adhering to predefined quality and performance measures. The ecosystem also simulates the impact of various team configurations on problem-solving effectiveness, helping organizations identify optimal team structures. Case studies and simulations demonstrate its practical applications.",
10.1145/3696410.3714765,Division-of-Thoughts: Harnessing Hybrid Language Model Synergy for Efficient On-Device Agents,"The rapid expansion of web content has made on-device AI assistants indispensable for helping users manage the increasing complexity of online tasks. The emergent reasoning ability in large language models offer a promising path for next-generation on-device AI agents. However, deploying full-scale Large Language Models (LLMs) on resource-limited local devices is challenging. In this paper, we propose <u>D</u>ivision-<u>o</u> f-<u>T</u>houghts (DoT), a collaborative reasoning framework leveraging the synergy between locally deployed Smaller-scale Language Models (SLMs) and cloud-based LLMs. DoT leverages a Task Decomposer to elicit the inherent planning abilities in language models to decompose user queries into smaller sub-tasks, which allows hybrid language models to fully exploit their respective strengths. Besides, DoT employs a Task Scheduler to analyze the pair-wise dependency of sub-tasks and create a dependency graph, facilitating parallel reasoning of sub-tasks and the identification of key steps. To allocate the appropriate model based on the difficulty of sub-tasks, DoT leverages a Plug-and-Play Adapter, which is an additional task head attached to the SLM that does not alter the SLM's parameters. To boost adapter's task allocation capability, we propose a self-reinforced training method that relies solely on task execution feedback. Extensive experiments on various benchmarks demonstrate that our DoT significantly reduces LLM costs while maintaining competitive reasoning accuracy. Specifically, DoT reduces the average reasoning time and API costs by 66.12\% and 83.57\%, while achieving comparable reasoning accuracy with the best baseline methods.",
10.1145/3696673.3723065,Academic Advising Chatbot Powered with AI Agent,"Academic advising plays a crucial role in fostering student success. However, challenges such as limited advisor availability can hinder effective support. Generative AI, particularly AI-powered chatbots, offers the potential to enhance student advising in higher education by providing personalized guidance. These technologies help college students find the information and resources needed to create degree plans aligned with their academic goals. This research introduces ARGObot, an intelligent advising system that facilitates student navigation of university policies through automated interpretation of the student handbook as its primary knowledge base. ARGObot enhances accessibility to critical academic policies and procedures, supporting incoming students' success through personalized guidance. Our system integrates a multifunctional agent enhanced by a Large Language Model (LLM). The architecture employs multiple external tools to enhance its capabilities: a Retrieval-Augmented Generation (RAG) system accesses verified university sources; email integration facilitates Human-in-the-Loop (HITL) interaction; and a web search function expands the system's knowledge base beyond predefined constraints. This approach enables the system to provide contextually relevant and verified responses to various student queries. This architecture evolved from our initial implementation based on Gemini 1 Pro, which revealed significant limitations due to its lack of agent-based functionality, resulting in hallucination issues and irrelevant responses. Subsequent evaluation demonstrated that our enhanced version, integrating GPT-4 with the text-embedding-ada-002 model, achieved superior performance across all metrics. This paper also presents a comparative analysis of both implementations, highlighting the architectural improvements and their impact on system performance.",
10.1145/3698587.3701359,ClinicalAgent: Clinical Trial Multi-Agent System with Large Language Model-based Reasoning,"Large Language Models (LLMs) and multi-agent systems have shown impressive capabilities in natural language tasks but face challenges in clinical trial applications, primarily due to limited access to external knowledge. Recognizing the potential of advanced clinical trial tools that aggregate and predict based on the latest medical data, we propose an integrated solution to enhance their accessibility and utility. We introduce Clinical Agent System (ClinicalAgent), a clinical multi-agent system designed for clinical trial tasks, leveraging GPT-4, multi-agent architectures, LEAST-TO-MOST, and ReAct reasoning technology. This integration not only boosts LLM performance in clinical contexts but also introduces novel functionalities. The proposed method achieves competitive predictive performance in clinical trial outcome prediction (0.7908 PR-AUC), obtaining a 0.3326 improvement over the standard prompt Method. Publicly available code can be found at https://github.com/LeoYML/clinical-agent.",
10.1145/3701716.3715247,"Meta-Agent-Workflow: Streamlining Tool Usage in LLMs through Workflow Construction, Retrieval, and Refinement","Large language models (LLMs) have recently shown significant advancements and are increasingly used as key components in automated agents for various web-based tasks. Typically, this agentization is achieved by carefully prompting LLMs to guide their behavior in using tools for specific tasks. However, this approach can be limited by the complexity of tasks and the inherent capabilities of LLMs. To enhance task-specific performance, a pre-defined workflow approach can be employed, reducing repetitive and error-prone planning for particular tasks. This workflow-driven process is especially well-suited for industrial applications, where task-specific agents can be easily configured using visual interfaces supported by various open-source platforms. In this paper, we introduce a novel framework called Meta-Agent-Workflowto create, retrieve, and refine agent workflows. Experiments on ToolBench demonstrate that our framework effectively transforms LLM tool-reasoning processes into task-specific workflows, retrieves workflows for different tasks based on various queries, and updates them based on execution feedback. We also open-source our code and follow the workflow architecture of an open-source agent platform (e.g., Dify) to facilitate further industrial and community use. The Meta-Agent-Workflow will be open-sourced in https://github.com/testlbin/meta_agent_workflows.",
10.1145/3703323.3704277,MEQA - A Multi-modal Interactive Enterprise Query Answering System using Multi-Agent LLM,"This paper introduces a new architecture for multi-agent systems designed to support query answering over secure enterprise data. The system uses a modular approach to natural language understanding and task execution, utilizing specialized agents for query processing. Our system features a Multi-Agent Block that consists of agents for general inquiries, Text2SQL, visualization, and information consolidation. These agents work together to handle complex queries. The Answer Generation component then integrates these results into coherent responses. We demonstrate our system’s efficiency using a complex query processed by a Text2SQL agent. In this scenario, the agent interacts with multiple endpoints, including an enterprise database and LLM endpoints, while employing techniques like RISE (Recursive Introspection for Results Improvements) and STaR (Self-Taught Reasoner) to enhance reasoning. Additionally, we use an open-source utility, LLMLingua, to compress prompts and reduce computational overhead. Our approach shows strong performance across various retrieval tasks, offering a significant step toward more intuitive and efficient data interaction, with the potential to transform how organizations utilize large language models, multiple agents, and data assets.",
10.1145/3706598.3713913,Jupybara: Operationalizing a Design Space for Actionable Data Analysis and Storytelling with LLMs,"Mining and conveying actionable insights from complex data is a key challenge of exploratory data analysis (EDA) and storytelling. To address this challenge, we present a design space for actionable EDA and storytelling. Synthesizing theory and expert interviews, we highlight how semantic precision, rhetorical persuasion, and pragmatic relevance underpin effective EDA and storytelling. We also show how this design space subsumes common challenges in actionable EDA and storytelling, such as identifying appropriate analytical strategies and leveraging relevant domain knowledge. Building on the potential of LLMs to generate coherent narratives with commonsense reasoning, we contribute Jupybara, an AI-enabled assistant for actionable EDA and storytelling implemented as a Jupyter Notebook extension. Jupybara employs two strategies—design-space-aware prompting and multi-agent architectures—to operationalize our design space. An expert evaluation confirms Jupybara’s usability, steerability, explainability, and reparability, as well as the effectiveness of our strategies in operationalizing the design space framework with LLMs.",
10.1145/3707292.3707383,A Survey of Theory Foundation and Key Technology in Large Models,"The training and reasoning technology of large models continues to go deeper and more practical, and the model performance continues to hit new highs, driving the emergence of intelligent native applications and laying a solid technical foundation for new applications, new services, and new formats. This paper focuses on the technical capabilities and development directions of large models, introduces the theory foundation research of large models in detail, including scaling laws, intrinsic task subspace, low-rank decomposition optimization theory, effective model complexity theory and alignment theory foundation; it conducts in-depth research on key technology of large models such as the neural network architecture, chain of thought(CoT), multimodal fusion technology, retrieval-augmented generation(RAG) and large language model (LLM) based agent, sorts out the iteration of technology and innovative research results; it discusses technical challenges such as the professionalism, authenticity, controllability, and credibility of large models, pointing out the key technical points of innovative research; finally, it summarizes and looks forward to the high-quality development of large models.",
10.1145/3711896.3737141,Swarm Intelligence in Geo-Localization: A Multi-Agent Large Vision-Language Model Collaborative Framework,"Visual geo-localization demands in-depth knowledge and advanced reasoning skills to associate images with precise real-world geo-graphic locations. Existing image database retrieval methods are limited by the impracticality of storing sufficient visual records of global landmarks. Recently, Large Vision-Language Models (LVLMs) have demonstrated the capability of geo-localization through Visual Question Answering (VQA), enabling a solution that does not require external geo-tagged image records. However, the performance of a single LVLM is still limited by its intrinsic knowledge and reasoning capabilities. To address these challenges, we introduce smileGeo, a novel visual geo-localization framework that leverages multiple Internet-enabled LVLM agents operating within an agent-based architecture. By facilitating inter-agent communication, smileGeo integrates the inherent knowledge of these agents with additional retrieved information, enhancing the ability to effectively localize images. Furthermore, our framework incorporates a dynamic learning strategy that optimizes agent communication, reducing redundant interactions and enhancing overall system efficiency. To validate the effectiveness of the proposed framework, we conducted experiments on three different datasets, and the results show that our approach significantly outperforms current state-of-the-art methods. The source code is available at https://github.com/Applied-Machine-Learning-Lab/smileGeo.",
10.1145/3712003,"LLM-Based Multi-Agent Systems for Software Engineering: Literature Review, Vision, and the Road Ahead","Integrating Large Language Models (LLMs) into autonomous agents marks a significant shift in the research landscape by offering cognitive abilities that are competitive with human planning and reasoning. This article explores the transformative potential of integrating Large Language Models into Multi-Agent (LMA) systems for addressing complex challenges in software engineering (SE). By leveraging the collaborative and specialized abilities of multiple agents, LMA systems enable autonomous problem-solving, improve robustness, and provide scalable solutions for managing the complexity of real-world software projects. In this article, we conduct a systematic review of recent primary studies to map the current landscape of LMA applications across various stages of the software development lifecycle (SDLC). To illustrate current capabilities and limitations, we perform two case studies to demonstrate the effectiveness of state-of-the-art LMA frameworks. Additionally, we identify critical research gaps and propose a comprehensive research agenda focused on enhancing individual agent capabilities and optimizing agent synergy. Our work outlines a forward-looking vision for developing fully autonomous, scalable, and trustworthy LMA systems, laying the foundation for the evolution of Software Engineering 2.0.",
10.1145/3712255.3734367,Evolvability in Rule-Making: A Self-Amendment Game Among LLM Agents,"We introduce the Self-Amendment Game, a simulation framework where Large Language Model (LLM) agents iteratively propose, vote on, and revise the very rules that govern them. Inspired by the self-modifying game Nomic, this system enables agents to operate within a fully amendable environment in which institutional constraints are themselves subject to change. Using leading LLMs, we examine two agent strategies: ""Add"" agents that focus on introducing new rules, and ""Modify"" agents that refine existing ones. Add agents tend to generate denser but less stable rule systems, with rapid point accumulation and high leadership turnover. Modify agents foster greater stability, with fewer but more consistent leaders. Analyzing the semantic structure of proposals, we find that varied justification styles often lead to instability, while coherence in reasoning promotes rule adoption. Our findings highlight a crucial trade-off between innovation and governance stability, offering a foundation for studying adaptive, self-governing systems involving both artificial agents and hybrid human-AI institutions.",
10.1145/3712285.3759887,STELLAR: Storage Tuning Engine Leveraging LLM Autonomous Reasoning for High Performance Parallel File Systems,"I/O performance is crucial to efficiency in data-intensive scientific computing; but tuning large-scale storage systems is complex, costly, and notoriously manpower-intensive, making it inaccessible for most domain scientists. To address this problem, we propose STELLAR, an autonomous tuner for high-performance parallel file systems. Our evaluations show that STELLAR almost always selects near-optimal configurations for the parallel file systems within the first five attempts, even for previously unseen applications. STELLAR’s human-like efficiency is fundamentally different from existing autotuning methods, which often require hundreds of thousands of iterations to converge. STELLAR achieves this through autonomous end-to-end agentic tuning. Powered by large language models (LLMs), STELLAR is capable of (1) accurately extracting tunable parameters from software manuals, (2) analyzing I/O trace logs generated by applications, (3) selecting initial tuning strategies, (4) rerunning applications on real systems and collecting I/O performance feedback, (5) adjusting tuning strategies and repeating the tuning cycle, and (6) reflecting on and summarizing tuning experiences into reusable knowledge for future optimizations. STELLAR integrates retrieval-augmented generation (RAG), external tool execution, LLM-based reasoning, and a multiagent design to stabilize reasoning and combat hallucinations. We evaluate how each of these components impacts optimization outcomes, thus providing insight into the design of similar systems for other optimization problems. STELLAR’s architecture and empirical validation open new avenues for tackling complex system optimization challenges, especially those characterized by vast search spaces and high exploration costs. Its highly efficient autonomous tuning will broaden access to I/O performance optimizations for domain scientists with minimal additional resource investment.",
10.1145/3715709,Thinking Fast and Slow in Human and Machine Intelligence,"When working to build machines that have a form of intelligence, it is natural to be inspired by human intelligence. Of course, humans are very different from machines, in their embodiment and myriad other ways. Humans exploit their bodies to experience the world, create an internal model of it, and use this model to reason, learn, and make contextual and informed decisions. Machines lack the same embodiment, but often have access to both more memory and more computing power. Despite these crucial disanalogies, it is still useful to leverage our knowledge of how the human mind reasons and makes decisions to design and build machines that demonstrate behaviors similar to that of a human. In this article, we present a novel AI architecture, Slow and Fast AI (SOFAI), that is inspired by the “thinking fast and slow” cognitive theory of human decision making. SOFAI is a multi-agent architecture that employs both “fast” and “slow” solvers underneath a metacognitive agent that is able to both choose among a set of solvers as well as reflect on and learn from past experience. Experimental results on the behavior of two instances of the SOFAI architecture show that, compared to using just one of the two decision modalities, SOFAI is markedly better in terms of decision quality, resource consumption, and efficiency.Modeling AI systems on dual-process theories of human cognition can improve their ability to flexibly handle diverse tasks.",
10.1145/3715761,Integrating Large Language Models and Reinforcement Learning for Non-linear Reasoning,"Large Language Models (LLMs) were shown to struggle with long-term planning, which may be caused by the limited way in which they explore the space of possible solutions. We propose an architecture where a Reinforcement Learning (RL) Agent guides an LLM's space exploration: (1) the Agent has access to domain-specific information, and can therefore make decisions about the quality of candidate solutions based on specific and relevant metrics, which were not explicitly considered by the LLM's training objective; (2) the LLM can focus on generating immediate next steps, without the need for long-term planning. We allow non-linear reasoning by exploring alternative paths and backtracking. We evaluate this architecture on the program equivalence task, and compare it against Chain of Thought (CoT) and Tree of Thoughts (ToT). We assess both the downstream task, denoting the binary classification, and the intermediate reasoning steps. Our approach compares positively against CoT and ToT.",
10.1145/3717511.3747067,"BEE: Belief-Value-Aligned, Explainable, and Extensible Cognitive Framework for Conversational Agents","Recent advances in large language models have enabled virtual agents to exhibit increasingly believable social behaviors. However, creating social agents that remain consistent with a defined profile and explain their reasoning remains challenging. We introduce a cognitive framework designed to address these gaps. Our framework features a graph-based memory module (concept pool) and a decision-making process inspired by human cognition. The concept pool contains an agent’s beliefs, values, and background stories for context-dependent retrieval. The decision-making process uses the concept pool to produce belief-value aligned responses of the virtual agent and intuitive, human-readable explanations of the reasoning. To evaluate the effectiveness of our framework, we created two virtual agents based on historical figures and compared them to baseline agents. Our evaluation combined quantitative assessments of belief-value alignment with a user study (n=48) examining explainable agency. Results show that our framework exhibits model-agnostic improved belief-value alignment and produces more detailed, relevant, and understandable explanations. By grounding virtual agent behavior in structured memories and cognitive principles, our framework offers a compelling step toward more coherent and socially intelligent virtual agents.",
10.1145/3723498.3723702,Evaluating Large Language Models through Communication Games: An Agent-Based Framework Using Werewolf in Unity,"In this study, we explore the reasoning capabilities of Large Language Models (LLMs) within the context of the social communication game Werewolf, aiming to evaluate their performance in managing complex system states commonly found in computer games. Our agent architecture gathers data, refines them into detailed information, and plans actions based on this knowledge. To demonstrate the feasibility of using LLM based agents in computer games, we developed a simulation and evaluation tool using the Unity game engine. This software enables users to experiment with various LLMs and agent architectures and to measure model performance within the application.For evaluation, we tested three models: GPT-3.5 Turbo, Mistral-7B-OpenOrca, and Nous-Hermes-Llama2-13B. The results show that even smaller models can perform reasonably well in Werewolf. However, their error rate is significantly higher, highlighting the need for additional software modules or fine-tuning to improve their accuracy.",
10.1145/3725783.3764388,Between Promise and Pain: The Reality of Automating Failure Analysis in Microservices with LLMs,"Large Language Models (LLMs) are increasingly explored as general-purpose assistants for infrastructure operations, helping automate tasks like querying data, analyzing logs, and suggesting fixes. In this paper, we consider the more general and ambitious problem of fully automating root cause analysis (RCA) in microservice systems, where LLMs must collect information, reason about it, and interact with the environment to detect, localize and resolve issues. Anecdotal evidence offers useful insights and partial solutions, but the broader challenge remains unresolved. We systematically evaluate multiple LLM agent architectures across a range of incident scenarios. We study how different tool-augmented agents perform, and shed light on common failure modes, including hallucinated reasoning paths and inefficient use of context. Our findings reveal both the promise and the limitations of current approaches, and point to concrete directions for more robust and effective use of LLMs in this domain.",
10.1145/3731599.3767401,Agentic AI vs ML-based Autotuning: A Comparative Study for Loop Reordering Optimization,"High Performance Computing (HPC) applications rely heavily on code optimizations to achieve good performance on modern CPU and GPU architectures. Traditional Machine Learning autotuning approaches have demonstrated success in exploring high-dimensional spaces, but they often require expensive compile-run evaluations and lack adaptability for large HPC applications. The recent advances in Large Language Models (LLMs) and Agentic AI systems raise intriguing questions about the potential of these approaches to address specific optimization methodologies. This work aims to answer an essential question for the HPC community: ""How Agentic AI Systems Compare to Traditional ML Autotuning Techniques?"" To address this question, we present a comparative analysis between a traditional ML-based optimization approach and an Agentic AI system, evaluating their respective capabilities and limitations for loop-level optimization. In addition, we introduced a new Agentic AI system named LoopGen-AI using three different Large Language Models: GPT-4.1, Claude 4.0, and Gemini 2.5. A key finding is that LoopGen-AI achieves competitive performance with only a few program runs, the reasoning logs from the agents revealed that their decisions rely heavily on the combination of semantic understanding of the target kernel with dynamic feedback from the environment, highlighting a promising new dimension in performance tuning. In contrast, ML-based autotuners focus on statistical exploration, and require orders of magnitude more runs to reach peak performance. Additionally, our analysis shows that prompt engineering, particularly using Persona + Context Manager patterns, significantly impacts the effectiveness of Agentic AI. Our results indicate that while Agentic AI systems are not yet a complete replacement for ML-based autotuners, it can effectively complement traditional methods.",
10.1145/3731715.3733393,MMCNav: MLLM-empowered Multi-agent Collaboration for Outdoor Visual Language Navigation,"Navigating through real-world environments, such as urban street views, poses a significant challenge for agents searching for a clear path to the destination based on environmental information. Although existing methods leveraging large language models (LLMs) have demonstrated remarkable achievements, they often struggle to tackle scenarios that require complex visual understanding. Inspired by the classical perception-cognition-action feedback loop in cognitive neuroscience, we present a multimodal large language models (MLLMs) empowered multi-agent collaborative outdoor navigation system that significantly enhances the capability to accomplish outdoor navigation tasks by extending a single agent into multiple cooperative agents. Each agent assumes a specific role in this system and collaborates to perform their respective tasks effectively. The system begins with agents interpreting human-written navigation instructions into detailed plans. At each step of the plan, agents analyze and caption the multimodal scenarios to improve their understanding of the environment. Then agents determine the search direction based on observational captions and historical decisions. At the end of the navigation, agents adopt the map of the search process to perform a two-stage reflection for error correction. Comprehensive experiments and analyses conducted on two outdoor navigation datasets demonstrate the superiority of our approach, outperforming previous methods in terms of performance. The repository of this project is available at https://github.com/zzhaesc/MMCNav.",
10.1145/3745238.3745531,"A Survey of Multi-AI Agent Collaboration: Theories, Technologies and Applications","As an important application of large language model(LLM), artificial intelligence agent(AI Agent) have the ability to autonomously perceive, understand, plan, memory, act, and use tools. It can automate complex tasks and effectively empower various business scenarios. Single AI Agent flexible and diverse deployment, multi-AI Agent innovative interaction and collaboration, multi-AI Agent collaboration improves the autonomy of the intelligent system by integrating the capabilities of single AI Agent. This paper provides an overview of multi-AI Agent from four aspects. Firstly, the core capabilities of AI Agent were outlined, and multi-AI Agent collaboration was introduced and its characteristics were analyzed. Secondly, the theoretical basis, key technologies, and scenario applications of multi-AI Agent collaboration were discussed, and the mechanism, architecture design, communication protocol, reinforcement learning, security and trustworthiness of multi-AI Agent collaboration were deeply studied. Thirdly, the advantages and disadvantages of multi-AI Agent collaboration in technology, application, and security directions were summarized, and frontier research and innovation directions were provided. Finally, a summary and outlook were made on the high-quality development of multi-AI Agent collaboration.",
10.1145/3746027.3754542,InteractGuide: LLM-Enhanced Multimodal Reasoning for User-Centric Interaction Recommendations in AR-HRI Authoring,"Augmented Reality (AR) enhances Human-Robot Interaction (HRI) by offering diverse interaction methods. However, existing systems often fail to resolve the conflict between a user's implicit preferences and physical ergonomics, leading to suboptimal experiences. We introduce InteractGuide, a novel framework that, for the first time, uses a Large Language Model (LLM) as a central reasoning engine to dynamically balance these competing factors. Our system translates physiological signals into a symbolic ''Preference Memory'' that the LLM reasons over, alongside real-time ergonomic and contextual data, to provide personalized interaction recommendations. A 29-participant study confirms our architecture improves efficiency and experience compared to single-factor approaches, showing the potential of LLMs as reasoning engines for complex AR-HRI. This work presents a validated end-to-end architecture for user-centric interaction adaptation, demonstrating the potential of LLMs as reasoning engines in complex AR-HRI systems.",
10.1145/3746027.3754761,HM-RAG: Hierarchical Multi-Agent Multimodal Retrieval Augmented Generation,"While Retrieval-Augmented Generation (RAG) augments Large Language Models (LLMs) with external knowledge, conventional single-agent RAG remains fundamentally limited in resolving complex queries demanding coordinated reasoning across heterogeneous data ecosystems. We present HM-RAG, a novel Hierarchical Multi-agent Multimodal RAG framework that pioneers collaborative intelligence for dynamic knowledge synthesis across structured, unstructured, and graph-based data. The framework is composed of a three-tiered architecture with specialized agents: a Decomposition Agent that dissects complex queries into contextually coherent sub-tasks via semantic-aware query rewriting and schema-guided context augmentation; Multi-source Retrieval Agents that carry out parallel, modality-specific retrieval using plug-and-play modules designed for vector, graph, and web-based databases; and a Decision Agent that uses consistency voting to integrate multi-source answers and resolve discrepancies in retrieval results through Expert Model Refinement. This architecture attains comprehensive query understanding by combining textual, graph-relational, and web-derived evidence, resulting in a remarkable 12.95\% improvement in answer accuracy and a 3.56\% boost in question classification accuracy over baseline RAG systems on the ScienceQA and CrisisMMD benchmarks. Notably, HM-RAG establishes state-of-the-art results in zero-shot settings on both datasets. Its modular architecture ensures seamless integration of new data modalities while maintaining strict data governance, marking a significant advancement in addressing the critical challenges of multimodal reasoning and knowledge synthesis in RAG systems.",
10.1145/3746027.3755425,From Model Diagram to Code: A Benchmark Dataset and Multi-Agent Framework,"Model Diagram-to-Code Generation aims to translate model diagrams from research papers into implementation code that reconstructs the model's architecture. This task plays a crucial role in accelerating scientific workflows and enhancing the efficiency of industrial model deployment. While recent studies have explored various Image-to-Code Generation tasks using Multimodal Large Language Models (MLLMs), these efforts have primarily focused on reconstructing the visual appearance depicted in input images, leaving this task largely underexplored. The complex structural elements and implicit relationships in model diagrams present greater challenges for MLLMs, particularly in terms of visual reasoning and semantic interpretation. To support this task, we introduce MDCDataset, a dataset designed to evaluate the ability of MLLMs to generate code from model diagrams. It comprises 1,008 instances spanning 16 research domains, each with a model diagram, structured textual content, and the ground-truth code implementation. Furthermore, to address the inherent challenges of this task, we propose MDCAgent, a collaborative multi-agent framework composed of Parsing, Generation, and Check Agents. These agents work in coordination to analyze, extract, and verify complex elements and implicit relationships within model diagrams, thereby enhancing the visual architecture-aware reasoning capabilities of MLLMs. Our extensive experiments confirm the effectiveness of the framework.",
10.1145/3746027.3755537,GraphVideoAgent: Enhancing Long-form Video Understanding with Entity Relation Graphs,"Long-form video understanding (LVU) addresses the challenge of answering complex questions over extended video length, where informative cues are sparse and easily overwhelmed by redundant content. To tackle this, it requires selecting a small set of question-relevant keyframes and reasoning over long-range, temporally dispersed visual evidence. However, current methods typically extract frame-level features with limited temporal context and store them in sequential memory structures. As a result, they struggle to capture the evolving relations among entities and fail to maintain identity consistency when entities temporarily leave and later reappear in the video. These limitations prevent accurate keyframe localization and coherent reasoning.In this paper, we propose GraphVideoAgent, a novel agent-based LVU framework that integrates a dynamic entity relation graph with a large language model (LLM)-based multi-round reasoning. Our framework emulates human cognitive strategies by iteratively retrieving keyframes and explicitly tracking both temporal and semantic interactions among entities. Our GraphVideoAgent iteratively reflects on question cues and visual observations, while the graph memory maintains a structured representation of evolving entity states and their causal relations. This design enables accurate keyframe selection, effective reasoning over sparse visual evidence, and interpretable prediction. Extensive experiments on two LVU benchmarks, EgoSchema and NExT-QA, demonstrate that GraphVideoAgent achieves state-of-the-art performance while using only 8.2 and 8.1 frames on average, significantly improving both accuracy and efficiency.",
10.1145/3746027.3755643,The Eye of Sherlock Holmes: Uncovering User Private Attribute Profiling via Vision-Language Model Agentic Framework,"Our research reveals a new privacy risk associated with the vision language model (VLM) agentic framework: the ability to infer sensitive attributes (e.g., age and health information) and even abstract ones (e.g., personality and social traits) from a set of personal images, which we term ''image private attribute profiling.'' This threat is particularly severe given that modern apps can easily access users' photo albums, and inference from image sets enables models to exploit inter-image relations for more sophisticated profiling. However, two main challenges hinder our understanding of how well VLMs can profile an individual from a few personal photos: (1) the lack of benchmark datasets with multi-image annotations for private attributes, and (2) the limited ability of current multimodal large language models (MLLMs) to infer abstract attributes from large image collections. In this work, we construct PAPI, the largest dataset for studying private attribute profiling in personal images, comprising 2,510 images from 251 individuals with 3,012 annotated privacy attributes. We also propose HolmesEye, a hybrid agentic framework that combines VLMs and LLMs to enhance privacy inference. HolmesEye uses VLMs to extract both intra-image and inter-image information and LLMs to guide the inference process as well as consolidate the results through forensic analysis, overcoming existing limitations in long-context visual reasoning. Experiments reveal that HolmesEye achieves a 10.8\% improvement in average accuracy over state-of-the-art baselines and surpasses human-level performance by 15.0\% in predicting abstract attributes. This work highlights the urgency of addressing privacy risks in image-based profiling and offers both a new dataset and an advanced framework to guide future research in this area.",
10.1145/3746027.3755832,CogDDN: A Cognitive Demand-Driven Navigation with Decision Optimization and Dual-Process Thinking,"Mobile robots are increasingly required to navigate and interact within unknown and unstructured environments to meet human demands. Demand-driven navigation (DDN) enables robots to identify and locate objects based on implicit human intent, even when object locations are unknown. However, traditional data-driven DDN methods rely on pre-collected data for model training and decision-making, limiting their generalization capability in unseen scenarios. In this paper, we propose CogDDN, a VLM-based framework that emulates the human cognitive and learning mechanisms by integrating fast and slow thinking systems and selectively identifying key objects essential to fulfilling user demands. CogDDN identifies appropriate target objects by semantically aligning detected objects with the given instructions. Furthermore, it incorporates a dual-process decision-making module, comprising a Heuristic Process for rapid, efficient decisions and an Analytic Process that analyzes past errors, accumulates them in a knowledge base, and continuously improves performance. Chain of Thought (CoT) reasoning strengthens the decision-making process. Extensive closed-loop evaluations on the AI2Thor simulator with the ProcThor dataset show that CogDDN outperforms single-view camera-only methods by 15\%, demonstrating significant improvements in navigation accuracy and adaptability. The project page is available at https://yuehaohuang.github.io/CogDDN/.",
10.1145/3746027.3762011,Agent-MER: A Cognitive Agent with Hierarchical Deliberation for Open-Vocabulary Multimodal Emotion Recognition,"This paper focuses on Open-Vocabulary Multimodal Emotion Recognition (OV-MER) and is dedicated to solving the two challenges it faces: concept semantic misalignment and incomplete coverage of fine-grained emotion categories. To address this, we propose a novel cognitive agent framework (Agent-MER), which reframes the OV-MER task as a problem to be solved by an agent that mimics the human cognitive process through knowledge-guided deliberation. We first construct a hierarchical Emotion Tree to serve as the agent's knowledge base. Building on this, we design a Knowledge-Guided Hierarchical Deliberation reasoning process. This process systematically explores the entire emotional landscape through a three-level, coarse-to-fine iterative reasoning process, enabling the identification of a richer and deeper range of emotions. Finally, a Self-Consistent Voting mechanism is employed to aggregate the results from multiple reasoning runs, ensuring the robustness of the final output. Experiments conducted in the MER2025 Challenge demonstrate that our proposed method achieved a top-ranking score of 61.04\%, securing first place and significantly outperforming existing baselines. This work not only provides an effective solution for OV-MER but also opens up new avenues for developing more human-like affective intelligence systems.",
10.1145/3746059.3747681,StorySage: Conversational Autobiography Writing Powered by a Multi-Agent Framework,"Every individual carries a unique and personal life story shaped by their memories and experiences. However, these memories are often scattered and difficult to organize into a coherent narrative—a challenge that defines the task of autobiography writing. Existing conversational writing assistants tend to rely on generic user interactions and pre-defined guidelines, making it difficult for these systems to capture personal memories and develop a complete biography over time. We introduce StorySage, a user-driven software system designed to meet the needs of a diverse group of users that supports a flexible conversation and a structured approach to autobiography writing. Powered by a multi-agent framework composed of an Interviewer, Session Scribe, Planner, Section Writer, and Session Coordinator, our system iteratively collects user memories, updates their autobiography, and plans for future conversations. In experimental simulations, StorySage demonstrates its ability to navigate multiple sessions and capture user memories across many conversations. User studies (N = 28) highlight how StorySage maintains improved conversational flow, narrative completeness, and higher user satisfaction when compared to a baseline. In summary, StorySage contributes both a novel architecture for autobiography writing and insights into how multi-agent systems can enhance human-AI creative partnerships.",
10.1145/3746059.3747722,Creating General User Models from Computer Use,"Human-computer interaction has long imagined technology that understands us—from our preferences and habits, to the timing and purpose of our everyday actions. Yet current user models remain fragmented, narrowly tailored to specific applications, and incapable of the flexible, cross-context reasoning required to fulfill these visions. This paper presents an architecture for a general user model (GUM) that learns about you by observing any interaction you have with your computer. The GUM takes as input any unstructured observation of a user (e.g., device screenshots) and constructs confidence-weighted natural language propositions that capture that user’s behavior, knowledge, beliefs, and preferences. GUMs can infer that a user is preparing for a wedding they’re attending from a message thread with a friend. Or recognize that a user is struggling with a collaborator’s feedback on a draft paper by observing multiple stalled edits and a switch to reading related work. GUMs introduce an architecture that infers new propositions about a user from multimodal observations, retrieves related propositions for context, and continuously revises existing propositions. To illustrate the breadth of applications that GUMs enable, we demonstrate how they augment chat-based assistants with contextual understanding, manage OS notifications to surface important information only when needed, and enable interactive agents that adapt to user preferences across applications. We also instantiate a new class of proactive assistants (Gumbos) that discover and execute useful suggestions on a user’s behalf based on their GUM. In our evaluations, we find that GUMs make calibrated and accurate inferences about users, and that assistants built on GUMs proactively identify and perform actions of meaningful value that users wouldn’t think to request explicitly. Altogether, GUMs introduce new methods that leverage large multimodal models to understand unstructured user context, enabling both long-standing visions of HCI and entirely new interactive systems that anticipate user needs.",
10.1145/3746252.3760995,STARec: An Efficient Agent Framework for Recommender Systems via Autonomous Deliberate Reasoning,"While modern recommender systems are instrumental in navigating information abundance, they remain fundamentally limited by static user modeling and reactive decision-making paradigms. Current large language model (LLM)-based agents inherit these shortcomings through their overreliance on heuristic pattern matching, yielding recommendations prone to shallow correlation bias, limited causal inference, and brittleness in sparse-data scenarios. We introduce STARec, a slow-thinking augmented agent framework that endows recommender systems with autonomous deliberative reasoning capabilities. Each user is modeled as an agent with parallel cognitions: fast response for immediate interactions and slow reasoning that performs chain-of-thought rationales. To cultivate intrinsic slow thinking, we develop anchored reinforcement training-a two-stage paradigm combining structured knowledge distillation from advanced reasoning models with preference-aligned reward shaping. This hybrid approach scaffolds agents in acquiring foundational capabilities (preference summarization, rationale generation) while enabling dynamic policy adaptation through simulated feedback loops. Experiments on MovieLens 1M and Amazon CDs benchmarks demonstrate that STARec achieves substantial performance gains compared with state-of-the-art baselines, despite using only 0.4\% of the full training data.",
10.1145/3746252.3761057,On Verifiable Legal Reasoning: A Multi-Agent Framework with Formalized Knowledge Representations,"Legal reasoning requires both precise interpretation of statutory language and consistent application of complex rules, presenting significant challenges for AI systems. This paper introduces a modular multi-agent framework that decomposes legal reasoning into distinct knowledge acquisition and application stages. In the first stage, specialized agents extract legal concepts and formalize rules to create verifiable intermediate representations of statutes. The second stage applies this knowledge to specific cases through three steps: analyzing queries to map case facts onto the ontology schema, performing symbolic inference to derive logically entailed conclusions, and generating final answers using a programmatic implementation that operationalizes the ontological knowledge. This bridging of natural language understanding with symbolic reasoning provides explicit and verifiable inspection points, significantly enhancing transparency compared to end-to-end approaches. Evaluation on statutory tax calculation tasks demonstrates substantial improvements, with foundational models achieving 76.4\% accuracy compared to 18.8\% baseline performance, effectively narrowing the performance gap between reasoning and foundational models. These findings suggest that modular architectures with formalized knowledge representations can make sophisticated legal reasoning more accessible through computationally efficient models while enhancing consistency and explainability in AI legal reasoning, establishing a foundation for future research into more transparent, trustworthy, and effective AI systems for legal domain.",
10.1145/3746252.3761059,DIVAgent: A Diversified Search Agent that Mimics the Human Search Process,"Search result diversification plays a crucial role in addressing query ambiguity and multi-faceted information needs by reducing redundancy across documents. While previous supervised approaches can achieve superior performance, they require costly, large-scale annotated data. In contrast, unsupervised methods are more flexible and training-free but rely on manually designed ranking functions, often leading to suboptimal performance. Inspired by how humans explore diverse information during real-world searching, we propose a diversified search agent DIVAgent to combine the advantages of supervised and unsupervised methods. DIVAgent introduces LLMs as the ''brain'' to reason over complex and diverse search results and delineate human cognitive processes into a workflow tailored for search result diversification. Our search agent first identifies potential user intents and then analyzes the alignment of each document to the intents via an intent-aware module. To guide the generation of diversified document rankings, we design an intent-guided ranker that explicitly links documents to their dominant intents while performing greedy document selection. Experimental results demonstrate that DIVAgent significantly outperforms existing unsupervised baselines and achieves competitive performance with supervised models, highlighting the promise of LLMs for diversified ranking in realistic search scenarios.",
10.1145/3746252.3761363,Parse-LLM: A Prior-Free LLM Parser for Unknown System Logs,"Log parsing extracts structured information from unstructured logs and serves as a fundamental pre-processing step for various log-based analytics and monitoring tasks. Recent advances have leveraged Large Language Models (LLMs) to handle log format complexities and enhance parsing performance. However, these methods heavily rely on labeled data, which is often scarce in rapidly evolving industrial systems, limiting their applicability in real-world scenarios. Moreover, the sheer volume of logs results in slow parsing and high computational costs, further hindering the deployment of LLM-based log parsing systems. To address these issues, we propose Parse-LLM, an unsupervised end-to-end log parsing framework based on LLMs Specifically, we first developed a Log Decomposer Agent that leverages Chain-of-Thought (CoT) reasoning and callable tools, enabling the LLM to autonomously separate log headers from content. Next, we introduce the Hybrid Log Partition module, which segments logs by balancing commonalities and differences. Finally, we developed a novel Variation-aware Log Parsing module that allows the LLM to harness additional supervisory signals through comparative analysis of similar logs. Comprehensive experiments conducted on large-scale public datasets show that Parse-LLM outperforms state-of-the-art log parsers in an unsupervised setting, offering an effective and scalable solution for the practical application of unsupervised log parsing.",
10.1145/3746277.3760412,Multimodal Trait and Emotion Recognition via Agentic AI: An End-to-End Pipeline,"This paper describes an end-to-end, modular, agentic system for inferring personality traits and emotional states based on multimodal interview-style data, when behavioral metadata (response time, body language, speech features, etc.) are made available. The system architecture consisted of a Perception Agent for classifying the emotions, an Inference Agent for estimating Big Five personality traits, and a Dialogue Agent for producing psychologically informed responses. A retrieval-augmented memory module connected the three agents to maintain context and continuity in the dialogue. The agents used two different language model backbones, LLaMA 3.2 1B and Falcon-RW-1B, learning and reasoning within the same processing pipeline while evaluating their performance on a benchmark of 19 annotated queries across a range of emotional states, conversation scenarios, and context. The evaluation assessed processing latency, lexical diversity, and consistency of trait estimation. The key finding for this study was that integrating metadata and modular reasoning leads to more contextually relevant and empathic responses than just prompting the agent. LLaMA produced longer, richer, and more diverse output while Falcon scores a much lower latency with shorter, predictable, and consistent responses. Overall, this study demonstrates that the combination of multimodal affective signals and agentic reasoning can lead to better human–AI interaction. While the work presented here is a proof-of-concept that is constrained by a benchmark experiment, it lays the grounds for scaling response models beyond the types of responses evaluated in this study, introduces more evaluation metrics, and enables more robust personalization features in future dialogue systems.",
10.1145/3748304,Large Language Models for Information Retrieval: A Survey,"As a primary means of information acquisition, information retrieval (IR) systems, such as search engines, have integrated themselves into our daily lives. These systems also serve as components of dialogue, question-answering, and recommender systems. The trajectory of IR has evolved dynamically from its origins in term-based methods to its integration with advanced neural models. While the neural models excel at capturing complex contextual signals and semantic nuances, they still face challenges such as data scarcity, interpretability, and the generation of contextually plausible yet potentially inaccurate responses. This evolution requires a combination of traditional methods (such as term-based sparse retrieval methods with rapid response) and modern neural architectures (such as language models with powerful language understanding capacity). Meanwhile, the emergence of large language models (LLMs) has revolutionized natural language processing due to their remarkable language understanding, generation, and reasoning abilities. Consequently, recent research has sought to leverage LLMs to improve IR systems. Given the rapid evolution of this research trajectory, it is necessary to consolidate existing methodologies and provide nuanced insights through a comprehensive overview. In this survey, we delve into the confluence of LLMs and IR systems, including crucial aspects such as query rewriters, retrievers, rerankers, readers, and search agents.",
10.1145/3757110.3757143,Application of Self-Play Deep Reinforcement Learning in Task Planning for UAV Swarms under Capacity Constraints,"This paper develops an Adaptive Staircase-based Policy Space Response Oracle (ASP) architecture that uses a self-play deep reinforcement learning (DRL) method to solve the problem of planning tasks for UAV swarms in urban logistics and post-disaster rescue situations when there isn't enough time and resources. We show that UAV swarm path planning may be optimized across different scales by combining a two-player meta-game structure with adversarial instance creation and developing a staircase curriculum learning mechanism. The framework lets you learn from small amounts of pre-training (10 to 100 inspection points) and apply that knowledge to larger applications (200 to 1000 inspection points). The results of the experiments indicate that the ASP-based method works better than traditional Policy Optimization for Multi-Agent (POMO) algorithms. It cuts the average solution time by 41\% and the total flight distance by 55.6\% in tasks with a thousand nodes. This paper offers a systematic engineering approach for dynamic task planning in UAV swarms, overcoming the problem of balancing exploration and exploitation in complicated state spaces and proving that it can be used in a variety of situations.",
10.1145/3757566,"Co-Writing with AI, on Human Terms: Aligning Research with User Demands Across the Writing Process","As generative AI tools like ChatGPT become integral to everyday writing, critical questions arise about how to preserve writers' sense of agency and ownership when using these tools. Yet, a systematic understanding of how AI assistance affects different aspects of the writing process-and how this shapes writers' agency-remains underexplored. To address this gap, we conducted a systematic review of 109 HCI papers using the PRISMA approach. From this literature, we identify four overarching design strategies for AI writing support-structured guidance, guided exploration, active co-writing, and critical feedback-mapped across the four key cognitive processes in writing: planning, translating, reviewing, and monitoring. We complement this analysis with interviews of 15 writers across diverse domains. Our findings reveal that writers' desired levels of AI intervention vary across the writing process: content-focused writers (e.g., academics) prioritize ownership during planning, while form-focused writers (e.g., creatives) value control over translating and reviewing. Writers' preferences are also shaped by contextual goals, values, and notions of originality and authorship. By examining when ownership matters, what writers want to own, and how AI interactions shape agency, we surface both alignment and gaps between research and user needs. Our findings offer actionable design guidance for developing human-centered writing tools for co-writing with AI, on human terms.",
10.1145/3760269.3760299,Outdoor Multi-UAV Collaborative Task Planning System Based on Multi-Agent and Improved PPO Algorithm,"Aiming at the problem of task collaboration and path planning for multi-agent drones in unknown environments, this paper proposes a multi-agent collaborative planning architecture that integrates a large language model (LLM) and a multimodal (MM) perception network, which is used for executing the multi-agent tasks in outdoor environments. This paper innovatively proposes an improved Proximal Policy Optimization (PPO) algorithm for path planning. Through a structured reward function and a joint strategy sharing mechanism, the path planning among multiple drones were efficiently achieved. The system in this paper innovatively proposes a loop intelligent control process called UTTUT (User Instruction, Task Graph Generation, Task Allocation, UAV Feedback, and Task Graph Updating), as well as a  ({P}^3)  (Perception, Planning, Prompt) factor graph model. Theoretically analyzes the interpretability of large model collaborative task planning. The Doubao large language model is introduced as the central control unit, and the Grounding DINO perception model is deployed at the drone end. By combining RGBD, semantic information, and asynchronous scheduling task factors, the perception and positioning of targets in complex scenes are realized. In addition, this paper compares the performances of different large model collaborative frameworks and gets the optimal large model control scheme results. Simulations are carried out on different platforms to verify the superiority of the framework proposed in this paper.",
10.1145/3760269.3760353,ABCM: Agent-Based Complexity Management Method for Intelligent Manufacturing,"Modern intelligent manufacturing systems are inherently complex, driven by product variety, dynamic scheduling, and intricate interactions among humans, machines, and materials. This complexity presents significant challenges for production planning, control, and decision-making. To address these issues, we propose ABCM (Agent-Based Complexity Management), a novel method that integrates system dynamics simulation with a large language model (LLM)-based agent framework. ABCM utilizes PySD to simulate manufacturing processes and extract structured model outputs, which are analyzed through a suite of modular tools registered within a LangChain agent. These tools enable the computation of descriptive statistics, dynamic performance indicators, and complexity metrics—including entropy, rise time, overshoot, and integral errors—thus allowing for automated, data-driven complexity assessment. The agent autonomously interprets simulation results, identifies performance bottlenecks, and offers optimization recommendations. A case study demonstrates the practical application of ABCM in managing production variability and enhancing system responsiveness. The modular and extensible architecture supports scalable deployment in diverse intelligent manufacturing scenarios, contributing to improved adaptability, efficiency, and complexity control.",
10.1145/3760658.3760664,Gap-Guided Evolutionary Deep Reinforcement Learning for Hierarchical Navigation in Structured Dynamic Environments,"Multi-agent collision avoidance—where an ego-robot must navigate from a start pose to a goal pose while avoiding both static obstacles and dynamic agents—is a longstanding challenge in motion planning. Recently, reinforcement learning (RL) has been explored for this task, but most RL-based solutions address simplified scenarios, often omitting complex static obstacles and focusing primarily on dynamic agent avoidance. Consequently, these approaches are unsuitable for structured environments such as mazes or indoor layouts with significant static geometry. To address this limitation, we integrate a multi-agent collision avoidance policy—specifically the GPU-accelerated Asynchronous Advantage Actor-Critic for Collision Avoidance (Evolution GA3C-CADRL) [4]—within a hierarchical navigation framework. Our method incorporates a local waypoint planner that leverages global navigation plans and real-time sensor data to generate short-term waypoints, ensuring clear paths devoid of static obstacles between the agent and the next target. This architecture effectively mitigates the original model’s inability to handle static constraints. The full system integrates global planning, perception-informed gap-based waypoint generation, and deep RL for local control. We empirically evaluate our hierarchical planner across five structured environments and demonstrate that the integrated waypoint + RL approach consistently reduces collision rates and improves goal-reaching success compared to the standalone RL model. Results show substantial improvements in both navigation robustness and success rate under realistic, complex scenarios.",
10.1145/3764587,Contract Embeddings for Layered Control Architectures,"The design of complex cyber-physical system architectures is often hierarchical. System specifications are mapped to an implementation layer via a stepwise refinement process involving multiple intermediate layers. These layers may capture different functionalities, and the orchestration of a variety of heterogeneous techniques suited to each layer may be required to achieve the overall design objectives. Due to their heterogeneity, ensuring traceability and verifiability of such architectures is a challenging problem. In this article, we present a correct-by-construction methodology for designing heterogeneous layered architectures. We capture the specifications at each layer with assume-guarantee contracts, a specification paradigm which can encompass a variety of modeling formalisms. We then use the notion of contract embeddings to define specification refinement, rigorously and traceably mapping specifications across layers modeled with heterogeneous formalisms. We instantiate our methodology on the design of layered control architectures (LCAs), resulting in a novel approach that can verifiably orchestrate domain-specific techniques to satisfy both global planning and local safety requirements. In the context of LCAs, we derive necessary conditions for correct specification refinement and results for compositional realization of control safety specifications. We illustrate our design methodology on a motivating example and a case study derived from robotic mission planning and control.",
10.1145/3765286,TableTalk: Scaffolding Spreadsheet Development with a Language Agent,"Spreadsheet programming is challenging. Programmers use spreadsheet programming knowledge (e.g., formulas) and problem-solving skills to combine actions into complex tasks. Advancements in large language models have introduced language agents that observe, plan, and perform tasks, showing promise for spreadsheet creation. We present TableTalk, a spreadsheet programming agent embodying three design principles—scaffolding, flexibility, and incrementality—derived from studies with seven spreadsheet programmers and 85 Excel templates. TableTalk guides programmers through structured plans based on professional workflows, generating three potential next steps to adapt plans to programmer needs. It uses pre-defined tools to generate spreadsheet components and incrementally build spreadsheets. In a study with 20 programmers, TableTalk produced higher-quality spreadsheets 2.3 times more likely to be preferred than the baseline. It reduced cognitive load and thinking time by 12.6\%. From this, we derive design guidelines for agentic spreadsheet programming tools and discuss implications on spreadsheet programming, end-user programming, AI-assisted programming, and human-agent collaboration.",
10.1145/3765618,ROS-BDI robots: an agent-based approach for programming the behaviour of autonomous robots,"The Robotic Operating System (ROS) provides resources that facilitate the development of robots. However, these resources do not provide robots with some features required in complex scenarios, such as goal-oriented behaviour, autonomy, deliberative capabilities, social abilities, and proactivity combined with reactivity. On the other hand, these features are inherent to Belief-Desire-Intention (BDI) agents, whose behaviour results from reasoning over explicit representations of their beliefs (information about the environment), desires (goals to be achieved), and intentions (commitments to those goals). This work addresses the integration between ROS and BDI agents. This integration is addressed both at a conceptual level, where ROS and BDI concepts are aligned, and in a more practical level, where programming tools are presented to program the behaviour of ROS-based robots as BDI agents. The proposal is evaluated through application examples. The results of this work include an integration model and tools to develop these robots.",
10.1145/3766882.3767169,AgentSight: System-Level Observability for AI Agents Using eBPF,"Modern software infrastructure increasingly relies on LLM agents for development and maintenance, such as Claude Code and Gemini-cli. However, these AI agents differ fundamentally from traditional deterministic software, posing a significant challenge to conventional monitoring and debugging. This creates a critical semantic gap: existing tools observe either an agent's high-level intent (via LLM prompts) or its low-level actions (e.g., system calls), but cannot correlate these two views. This blindness makes it difficult to distinguish between benign operations, malicious attacks, and costly failures. We introduce AgentSight, an AgentOps observability framework that bridges this semantic gap using a hybrid approach. Our approach, boundary tracing, monitors agents from outside their application code at stable system interfaces using eBPF. AgentSight intercepts TLS-encrypted LLM traffic to extract semantic intent, monitors kernel events to observe system-wide effects, and causally correlates these two streams across process boundaries using a real-time engine and secondary LLM analysis. This instrumentation-free technique is framework-agnostic, resilient to rapid API changes, and incurs less than 3\% performance overhead. Our evaluation shows AgentSight detects prompt injection attacks, identifies resource-wasting reasoning loops, and reveals hidden coordination bottlenecks in multi-agent systems. AgentSight is released as an open-source project at https://github.com/eunomia-bpf/agentsight.",
10.1145/3766918.3766948,Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework,"With the proliferation of Large Language Models (LLMs), the detection of misinformation has become increasingly important and complex. This research proposes an innovative verifiable misinformation detection LLM agent that goes beyond traditional true/false binary judgments. The agent actively verifies claims through dynamic interaction with diverse web sources, assesses information source credibility, synthesizes evidence, and provides a complete verifiable reasoning process. Our designed agent architecture includes three core tools: precise web search tool, source credibility assessment tool and numerical claim verification tool. These tools enable the agent to execute multi-step verification strategies, maintain evidence logs, and form comprehensive assessment conclusions. We evaluate using standard misinformation datasets such as FakeNewsNet, comparing with traditional machine learning models and LLMs. Evaluation metrics include standard classification metrics, quality assessment of reasoning processes, and robustness testing against rewritten content. Experimental results show that our agent outperforms baseline methods in misinformation detection accuracy, reasoning transparency, and resistance to information rewriting, providing a new paradigm for trustworthy AI-assisted fact-checking.",
10.1145/3768292.3770347,ProtoHedge: Interpretable Hedging with Market Prototypes,"Deep hedging has emerged as a powerful framework for financial risk management, capable of learning effective hedging strategies in the presence of market frictions. However, its reliance on black-box neural networks creates a critical barrier to adoption, limiting trust, auditability, and regulatory compliance. In this work, we address this challenge by introducing a transparent alternative to the black-box Deep Hedging paradigm. Instead of relying on an opaque architecture, our model learns a finite set of representative market states, or “prototypes”. Hedging decisions are then made via a transparent, similarity-based mechanism: the agent’s action is a weighted average of learned actions associated with each prototype. We call our specific implementation of this framework ProtoHedge. The reasoning approach makes every decision traceable to understandable market scenarios. We conduct extensive experiments in both classical Black-Scholes and more realistic stochastic volatility environments. Our results demonstrate that this interpretability is achieved with minimal impact of less than 0.40\% on hedging performance, as our model’s hedging effectiveness is comparable to that of the original black-box deep hedging agent. This work shows that transparency and performance are not mutually exclusive, paving the way for more trustworthy automated risk management systems.",
10.1145/3768292.3770383,AuditAgent: Expert-Guided Multi-Agent Reasoning for Cross-Document Fraudulent Evidence Discovery,"Financial fraud detection in real-world scenarios presents significant challenges due to the subtlety and dispersion of evidence across complex, multi-year financial disclosures. In this work, we introduce a novel multi-agent reasoning framework AuditAgent, enhanced with auditing domain expertise, for fine-grained evidence chain localization in financial fraud cases. Leveraging an expert-annotated dataset constructed from enforcement documents and financial reports released by the China Securities Regulatory Commission, our approach integrates subject-level risk priors, a hybrid retrieval strategy, and specialized agent modules to efficiently identify and aggregate cross-report evidence. Extensive experiments demonstrate that our method substantially outperforms General-Purpose Agent paradigm in both recall and interpretability, establishing a new benchmark for automated, transparent financial forensics. Our results highlight the value of domain-specific reasoning and dataset construction for advancing robust financial fraud detection in practical, real-world regulatory applications.",
10.1145/3768292.3770387,"Large Language Model Agents for Investment Management: Foundations, Benchmarks, and Research Frontiers","Recent advances in Large Language Models (LLMs) have triggered a new wave of intelligent financial agents capable of complex reasoning, tool use, and autonomous decision-making. This survey presents a comprehensive review of LLM-based agents in the context of investment and trading, focusing on applications such as portfolio optimization, risk management, information retrieval, and automated strategy generation. We systematically categorize the literature by use case and architectural innovations including multi-agent collaborations, reflection mechanisms, and tool-augmented pipelines. Additionally, we review emerging evaluation frameworks and benchmark datasets tailored to finance-specific agent tasks. The survey identifies current trends, technical limitations, and open challenges related to robustness, explainability, and real-world deployment. We conclude with emerging directions for building more capable, adaptive, and trustworthy financial AI agents aligned with the demands of modern investment ecosystems.",
10.1145/3768292.3771251,Structured Agentic Workflows for Financial Time-Series Modelling with LLMs and Reflective Feedback,"Time-series data is central to decision-making in financial markets, yet building high-performing, interpretable, and auditable models remains a major challenge. While Automated Machine Learning (AutoML) frameworks streamline model development, they often lack adaptability and responsiveness to domain-specific needs and evolving objectives. Concurrently, Large Language Models (LLMs) have enabled agentic systems capable of reasoning, memory management, and dynamic code generation, offering a path toward more flexible workflow automation. In this paper, we introduce TS-Agent, a modular agentic framework designed to automate and enhance time-series modeling workflows for financial applications. The agent formalizes the pipeline as a structured, iterative decision process across three stages: model selection, code refinement, and fine-tuning, guided by contextual reasoning and experimental feedback. Central to our architecture is a planner agent equipped with structured knowledge banks, curated libraries of models and refinement strategies, which guide exploration, while improving interpretability and reducing error propagation. TS-Agent supports adaptive learning, robust debugging, and transparent auditing, key requirements for high-stakes environments such as financial services. Empirical evaluations on diverse financial forecasting and synthetic data generation tasks demonstrate that TS-Agent consistently outperforms state-of-the-art AutoML and agentic baselines, achieving superior accuracy, robustness, and decision traceability.",
10.1145/3769111,Conformal Temporal Logic Planning using Large Language Models,"This paper addresses temporal logic task planning problems for mobile robots. We consider missions that require accomplishing multiple high-level sub-tasks, expressed in natural language (NL), in a temporal and logical order. To formally define the mission, we treat these sub-tasks as atomic predicates in a Linear Temporal Logic (LTL) formula. We refer to this task specification framework as LTL-NL. Our goal is to design plans, defined as sequences of robot actions, accomplishing LTL-NL tasks. This action planning problem cannot be solved directly by existing LTL planners due to the NL nature of atomic predicates. Therefore, we propose HERACLEs, a hierarchical neuro-symbolic planner that relies on a novel integration of (i) existing symbolic planners generating high-level task plans determining the order at which the NL sub-tasks should be accomplished; (ii) pre-trained Large Language Models (LLMs) to design sequences of robot actions for each sub-task in these task plans; and (iii) conformal prediction acting as a formal interface between (i) and (ii) and managing uncertainties due to LLM imperfections. We show, both theoretically and empirically, that HERACLEs can achieve user-defined mission success rates. We demonstrate the efficiency of HERACLEs through comparative numerical experiments against recent LLM-based planners as well as hardware experiments on mobile manipulation tasks. Finally, we present examples demonstrating that our approach enhances user-friendliness compared to conventional symbolic approaches.",
10.1145/3770857,A BDI Task-oriented Agent in Belief Space,"Building conversational agents to help humans in domain-specific tasks is challenging since the agent needs to understand the natural language and act over it while accessing domain expert knowledge. Modern natural language processing techniques led to an expansion of conversational agents, with recent pretrained language models achieving increasingly accurate language recognition results using ever-larger open datasets. However, the black-box nature of such pretrained language models obscures the agent's reasoning and its motivations when responding, leading to unexplained dialogues. In this work, we develop a belief-desire-intention (BDI) agent as a task-oriented dialogue system to introduce mental attitudes similar to humans describing their behavior during a dialogue. We compare the BDI model with pipeline task-oriented dialogue system architecture by leveraging existing components from dialogue systems and developing the agent's intention selection as a dialogue policy. We show that combining traditional agent modelling approaches, such as BDI, with more recent learning techniques can result in efficient and scrutable dialogue systems.",
10.1145/3771555,VUI Testing of VPA Apps via Behavior Model-Enhanced LLM Agents,"With the increasing adoption of smart speakers, Virtual Personal Assistant (VPA) applications have become integral to daily life, enabling users to access news, entertainment, and smart device control through Voice User Interfaces (VUI). However, many VPA apps suffer from quality issues, such as unexpected terminations and failures to process common user commands, highlighting the urgent need for systematic and efficient VUI testing. Existing chatbot-style and model-based testing approaches lack global and semantic awareness, resulting in ineffective test case generation and inefficient state exploration.To address these challenges, we introduce Elevate, a model-enhanced, LLM-driven VPA testing framework that employs a multi-agent architecture to enhance VUI behavior testing. Elevate comprises three specialized LLM agents—Observer, Generator, and Planner—that collaboratively perform state extraction, test case generation, and guided state exploration. Additionally, a deterministic finite automaton (DFA)-based behavior model is designed to abstract app behavior and provide structured guidance to LLM agents, enhancing testing performance. Elevate also incorporates a feedback mechanism that refines testing strategies based on observed behaviors, ensuring continuous improvement.Implemented using GPT-4-Turbo and DeepSeek-R1, Elevate has been evaluated on problem detection, sentence/semantic coverage, and large-scale testing. Experimental results show that Elevate outperforms state-of-the-art methods (Vitas and LLM-based chatbots), detecting at least 18 and 37 more problems, respectively, and achieving over 10\% and 30\% higher state coverage. In a large-scale evaluation on 4,000 Alexa skills, Elevate further demonstrated 15\% higher coverage than Vitas, confirming its effectiveness, scalability, and potential for widespread application in VUI testing.",
10.1145/3772077,LUMEN: Enhancing IoT System Observability with Multi-Agent Large Language Models and Knowledge Graphs,"The rapid expansion of Internet of Things (IoT) systems has transformed industries through real-time monitoring and automation, generating vast and heterogeneous data streams. As IoT networks expand, the increasing volume and diversity of data, spanning real-time telemetry, device logs, and historical records, complicate the management of IoT systems, including system monitoring, analysis, and reasoning. To address this challenge, we introduce LUMEN (Large Language Models as Unified Multi-Agent Systems for IoT ENhancement), a novel approach combining multi-agent Large Language Models (LLMs), knowledge graphs, and heterogeneous databases to enable cognitive digital twins for IoT observability. LUMEN models IoT systems as knowledge graphs, capturing device relationships and metadata while monitoring data is stored in time-series or object databases. Specialized LLM-based agents collaborate dynamically to analyze IoT systems and explain the findings in natural language, generating and executing analysis code when necessary. Integrated with off-the-shelf network monitoring tools, LUMEN facilitates semantic reasoning and human-in-the-loop collaboration, delivering adaptive insights across diverse data contexts. Two industrial case studies demonstrate the ability of LUMEN to automate analysis workflows, enhance system adaptability, and provide interpretable analytics. This work advances IoT observability by integrating LLMs, semantic intelligence, and explainable analytics into a scalable and adaptive solution using a multi-agent architecture for complex IoT systems.",
10.1145/3774946,MemIndex: Agentic Event-based Distributed Memory Management for Multi-agent Systems,"Interactive applications are latency-sensitive systems that enable dynamic responses to user inputs in domains such as robotics, industrial automation, and autonomous control. These applications require efficient application protocols for communication, with the pub/sub model being one of the most promising approaches. However, existing pub/sub systems are architecturally constrained, particularly by limited memory capacity and inefficiencies in dynamic environments. Addressing these challenges requires effective distributed memory management, yet this aspect has received limited attention in existing research. This paper addresses the gap by proposing MemIndex, an adaptive and autonomous distributed memory-management framework with an intent-indexed bipartite graph architecture. It is designed for an LM-based multi-agent pub/sub systems, enabling agents to autonomously negotiate memory operations in real time through dynamic index spaces for efficient reasoning. We evaluate our proposed MemIndex using diverse models against two baselines. Experimental results show MemIndex outperforms both baselines across storage, retrieval, update, and deletion operations, achieving average reductions of about 34\% and 56\% in elapsed time, 57\% and 75\% in CPU utilization, 23\% and 76\% in memory usage. Scalability tests further demonstrate that MemIndex maintains low end-to-end delay as submissions and agents grow, confirming that its negotiation-driven offloading enables efficient distributed memory management in interactive applications.",
10.1364/JOCN.533789,Near-real-time 6G service operation enabled by distributed intelligence and in-band telemetry,"The combination of highly dynamic network services requiring stringent quality of service (QoS), especially in terms of end-to-end (e2e) delay, together with capital and operational cost reduction cannot be faced using centralized software-defined networking (SDN) solutions only. In particular, such expected dynamicity requires autonomous near-real-time operation fed with pervasive telemetry to make per-service decisions that ensure the committed QoS, while reducing overprovisioning as much as possible. In this paper, we propose a distributed control architecture based on multi-agent systems (MASs) to assist the SDN controller in the control of network services near-real-time. Per-traffic flow telemetry data are collected from the packet nodes, distributed through the agents in the control plane, and analyzed to assure performance and to anticipate any degradation. Measurements feed flow agents, which are based on deep reinforcement learning (DRL) models, to make routing decisions aiming at ensuring flow performance. In the case when QoS degradation is detected, we propose algorithms to analyze its cause, which can be a result of some bottleneck in the network. We show how the latter is detected and additional capacity is requested of the SDN controller, which in turn creates an optical bypass to provide additional capacity. The proposed solution is demonstrated experimentally on a federated testbed connecting UPC and CNIT premises. Focused first on the control plane, the feasibility of the proposed architecture and workflows is experimentally assessed. After that, the performance of the near-real-time operation is evaluated at the data plane to verify that the maximum e2e delay is not exceeded for multiple flows, showing the effectiveness of predictive QoS evaluation together with infrastructure and service reconfiguration.",
10.14778/3750601.3750611,"SagaLLM: Context Management, Validation, and Transaction Guarantees for Multi-Agent LLM Planning","This paper introduces SagaLLM, a structured multi-agent architecture designed to address four foundational limitations of current LLM-based planning systems: unreliable self-validation, context loss, lack of transactional safeguards, and insufficient inter-agent coordination. While recent frameworks leverage LLMs for task decomposition and multi-agent communication, they often fail to ensure consistency, rollback, or constraint satisfaction across distributed workflows. SagaLLM bridges this gap by integrating the Saga transactional pattern with persistent memory, automated compensation, and independent validation agents. It leverages LLMs' generative reasoning to automate key tasks traditionally requiring hand-coded coordination logic, including state tracking, dependency analysis, log schema generation, and recovery orchestration. Although SagaLLM relaxes strict ACID guarantees, it ensures workflow-wide consistency and recovery through modular checkpointing and compensable execution. Empirical evaluations across planning domains demonstrate that standalone LLMs frequently violate interdependent constraints or fail to recover from disruptions. In contrast, SagaLLM achieves significant improvements in consistency, validation accuracy, and adaptive coordination under uncertainty—establishing a robust foundation for real-world, scalable LLM-based multi-agent systems.",
10.1609/aaai.v38i18.29990,GOALNET: Interleaving Neural Goal Predicate Inference with Classical Planning for Generalization in Robot Instruction Following,"Our goal is to enable a robot to learn how to sequence its actions to perform high-level tasks specified as natural language instructions, given successful demonstrations from a human partner. Our novel neuro-symbolic solution GOALNET builds an iterative two-step approach that interleaves (i) inferring next subgoal predicate implied by the language instruction, for a given world state, and (ii) synthesizing a feasible subgoal-reaching plan from that state. The agent executes the plan, and the two steps are repeated. GOALNET combines (i) learning, where dense representations are acquired for language instruction and the world state via a neural network prediction model, enabling generalization to novel settings and (ii) planning, where the cause-effect modeling by a classical planner eschews irrelevant predicates, facilitating multistage decision making in large domains. GOALNET obtains 78% improvement in the goal reaching rate in comparison to several state-of-the-art approaches on benchmark data with multi-stage instructions. Further, GOALNET can generalize to novel instructions for scenes with unseen objects. Source code available at https://github.com/reail-iitd/goalnet. © © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",
10.1609/icaps.v34i1.31503,On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS),"Automated Planning and Scheduling is among the growing areas in Artificial Intelligence (AI) where mention of LLMs has gained popularity. Based on a comprehensive review of 126 papers, this paper investigates eight categories based on the unique applications of LLMs in addressing various aspects of planning problems: language translation, plan generation, model construction, multi-agent planning, interactive planning, heuristics optimization, tool integration, and brain-inspired planning. For each category, we articulate the issues considered and existing gaps. A critical insight resulting from our review is that the true potential of LLMs unfolds when they are integrated with traditional symbolic planners, pointing towards a promising neuro-symbolic approach. This approach effectively combines the generative aspects of LLMs with the precision of classical planning methods. By synthesizing insights from existing literature, we underline the potential of this integration to address complex planning challenges. We aim to keep the categorization of papers updated on https://ai4society.github.io/LLM-Planning-Viz/, a collaborative resource that allows researchers to contribute and add new literature to the categorization. © © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",
10.18653/v1/2022.sigdial-1.64,A System For Robot Concept Learning Through Situated Dialogue,"Robots operating in unexplored environments with human teammates will need to learn unknown concepts on the fly. To this end, we demonstrate a novel system that combines a computational model of question generation with a cognitive robotic architecture. The model supports dynamic production of back- and-forth dialogue for concept learning given observations of an environment, while the architecture supports symbolic reasoning, action representation, one-shot learning and other capabilities for situated interaction. The system is able to learn about new concepts including objects, locations, and actions, using an underlying approach that is generalizable and scalable. We evaluate the system by comparing learning efficiency to a human baseline in a collaborative reference resolution task and show that the system is effective and efficient in learning new concepts, and that it can informatively generate explanations about its behavior. © 2022 Association for Computational Linguistics.",
10.23919/APNOMS67058.2025.11181316,Intent-Driven Autonomous Reconfiguration for Telecom OSS: A Generative-AI-Empowered Hierarchical Multi-Agent Architecture,"Telecom Operation Support Systems (OSS) still depend on domain experts and ad-hoc scripts for network and service reconfiguration, a process that is labor-intensive, errorprone, and fragile whenever cross-domain dependencies-such as allocating an IP address before tearing down a VLAN—must be respected. The heterogeneity and dynamism anticipated for 6Gclass networks only magnify the shortcomings of today’s rigid, rule-based automation pipelines. This paper introduces an intent-driven, fully autonomous reconfiguration framework that integrates Generative AI with a hierarchical Multi-Agent architecture. At its core, a ReWOOenhanced Chief Agent transforms natural-language intents into a dependency-aware execution graph, utilizing a formally defined Command Pattern to explicitly specify actions and associated data for unambiguous inter-agent coordination. Atomic tasks-annotated with domain-specific constraints and keys governed by a Primary Key Pattern-are delegated to ReAct-based Specific Agents responsible for IP management, network control, cloud orchestration, and service management. Evaluation on a four-domain OSS testbed exposing over thirty RESTful APIs confirms accurate intent parsing, robust key-value consistency enforcement, strict adherence to create-before-destroy constraints, and seamless scalability from single-domain provisioning to complex cross-domain orchestration without code changes. The proposed work delivers a reusable agent blueprint decoupling global planning from domain execution; formal interagent interfaces curbing hallucination and enabling modular growth; an execution-aware extension to ReWOO for structured action planning; domain-driven guidelines for encapsulating OSS subsystems into loosely coupled agents; and a public OSS testbed for benchmarking future Agentic-AI architectures-collectively advancing OSS reconfiguration toward scalable, maintainable, and 6G-ready network operations.",
10.24963/ijcai.2025/214,SketchAgent: Generating Structured Diagrams from Hand-Drawn Sketches,"Hand-drawn sketches are a natural and efficient medium for capturing and conveying ideas. Despite significant advancements in controllable natural image generation, translating freehand sketches into structured, machine-readable diagrams remains a labor-intensive and predominantly manual task. The primary challenge stems from the inherent ambiguity of sketches, which lack the structural constraints and semantic precision required for automated diagram generation. To address this challenge, we introduce SketchAgent, a multiagent system designed to automate the transformation of hand-drawn sketches into structured diagrams. SketchAgent integrates sketch recognition, symbolic reasoning, and iterative validation to produce semantically coherent and structurally accurate diagrams, significantly reducing the need for manual effort. To evaluate the effectiveness of our approach, we propose the Sketch2Diagram Benchmark, a comprehensive dataset and evaluation framework encompassing eight diverse diagram categories, such as flowcharts, directed graphs, and model architectures. The dataset comprises over 6,000 high-quality examples with token-level annotations, standardized preprocessing, and rigorous quality control. By streamlining the diagram generation process, SketchAgent holds great promise for applications in design, education, and engineering, while offering a significant step toward bridging the gap between intuitive sketching and machine-readable diagram generation. © 2025 International Joint Conferences on Artificial Intelligence. All rights reserved.",
10.3233/FAIA240636,A Practical Operational Semantics for Classical Planning in BDI Agents,"Implementations of the Belief-Desire-Intention (BDI) architecture have a long tradition in the development of autonomous agent systems. However, most practical implementations of the BDI framework rely on a pre-defined plan library for decision-making, which places a significant burden on programmers, and still yields systems that may be brittle, struggling to achieve their goals in dynamic environments. This paper overcomes this limitation by introducing an operational semantics for BDI systems that rely on Classical Planning at run time to both cope with failures that were unforeseeable and synthesise new plans that were unspecified at design time. This semantics places particular emphasis on the interaction of the reasoning cycle and an underlying planning algorithm. We empirically demonstrate the practical feasibility and generality of such an approach in an implementation of this semantics within two popular BDI platforms together with in-depth computational evaluation. © 2024 The Authors.",
10.3233/IA-240036,Planning and learning to perceive in partially unknown environments,"For applying symbolic planning, an agent acting in an environment needs to know its symbolic state, and an abstract model of the environment dynamics. However, in the real world, an agent has low-level perceptions of the environment (e.g. its position given by a GPS sensor), rather than symbolic observations representing its current state. Furthermore, in many real-world scenarios, it is not feasible to provide an agent with a complete and correct model of the environment, e.g., when the environment is (partially) unknown a priori. Therefore, agents need to dynamically learn/adapt/extend their perceptual abilities online, in an autonomous way, by exploring and interacting with the environment where they operate. In this paper, we provide a general architecture of a planning, learning, and acting agent. Moreover, we propose solutions to the problems of automatically training a neural network to recognize object properties, learning the situations where such properties are better perceivable, and planning to get into such situations. We experimentally show the effectiveness of our approach in simulated and complex environments, and we empirically demonstrate the feasibility of our approach in a real-world scenario that involves noisy perceptions and noisy actions on a real robot. © 2024 - IOS Press. All rights reserved.",
10.3233/ICA-200624,Semantic visual recognition in a cognitive architecture for social robots,"Cognitive architectures allow robots to perform their operations by drawing on a process that aims to simulate human reasoning. This paper presents an integrated semantic artificial memory system in cognitive architecture based on symbolic reasoning and a connective representation of the knowledge. This memory system attempts to simulate how humans learn to distinguish instances of particular objects within their class using a convolutional network to detect the relevant elements of an image. We use a vector with the extracted features to learn to discriminate an instance of another element from the same class. A novel feature of our approach is its autonomous learning process during the operation of the robot, integrating a deep learning embedding with a statistical classifier. The usefulness and robustness of this method are demonstrated by applying it to a social robot that learns to differentiate people. Finally, experiments are carried out to validate our approach, comparing the detection results with several alternative methods. © 2020 - IOS Press and the authors. All rights reserved.",
10.3389/fnbot.2024.1342786,A framework for neurosymbolic robot action planning using large language models,"Symbolic task planning is a widely used approach to enforce robot autonomy due to its ease of understanding and deployment in engineered robot architectures. However, techniques for symbolic task planning are difficult to scale in real-world, highly dynamic, human-robot collaboration scenarios because of the poor performance in planning domains where action effects may not be immediate, or when frequent re-planning is needed due to changed circumstances in the robot workspace. The validity of plans in the long term, plan length, and planning time could hinder the robot's efficiency and negatively affect the overall human-robot interaction's fluency. We present a framework, which we refer to as Teriyaki, specifically aimed at bridging the gap between symbolic task planning and machine learning approaches. The rationale is training Large Language Models (LLMs), namely GPT-3, into a neurosymbolic task planner compatible with the Planning Domain Definition Language (PDDL), and then leveraging its generative capabilities to overcome a number of limitations inherent to symbolic task planners. Potential benefits include (i) a better scalability in so far as the planning domain complexity increases, since LLMs' response time linearly scales with the combined length of the input and the output, instead of super-linearly as in the case of symbolic task planners, and (ii) the ability to synthesize a plan action-by-action instead of end-to-end, and to make each action available for execution as soon as it is generated instead of waiting for the whole plan to be available, which in turn enables concurrent planning and execution. In the past year, significant efforts have been devoted by the research community to evaluate the overall cognitive capabilities of LLMs, with alternate successes. Instead, with Teriyaki we aim to providing an overall planning performance comparable to traditional planners in specific planning domains, while leveraging LLMs capabilities in other metrics, specifically those related to their short- and mid-term generative capabilities, which are used to build a look-ahead predictive planning model. Preliminary results in selected domains show that our method can: (i) solve 95.5% of problems in a test data set of 1,000 samples; (ii) produce plans up to 13.5% shorter than a traditional symbolic planner; (iii) reduce average overall waiting times for a plan availability by up to 61.4%. © © 2024 Capitanelli and Mastrogiovanni.",
10.3389/frobt.2023.1221739,Learning to reason over scene graphs: a case study of finetuning GPT-2 into a robot language model for grounded task planning,"Long-horizon task planning is essential for the development of intelligent assistive and service robots. In this work, we investigate the applicability of a smaller class of large language models (LLMs), specifically GPT-2, in robotic task planning by learning to decompose tasks into subgoal specifications for a planner to execute sequentially. Our method grounds the input of the LLM on the domain that is represented as a scene graph, enabling it to translate human requests into executable robot plans, thereby learning to reason over long-horizon tasks, as encountered in the ALFRED benchmark. We compare our approach with classical planning and baseline methods to examine the applicability and generalizability of LLM-based planners. Our findings suggest that the knowledge stored in an LLM can be effectively grounded to perform long-horizon task planning, demonstrating the promising potential for the future application of neuro-symbolic planning methods in robotics. © © 2023 Chalvatzaki, Younes, Nandha, Le, Ribeiro and Gurevych.",
10.3389/frobt.2025.1566623,Hybrid intelligence systems for reliable automation: advancing knowledge work and autonomous operations with scalable AI architectures,"Introduction: Mission-critical automation demands decision-making that is explainable, adaptive, and scalable—attributes elusive to purely symbolic or data-driven approaches. We introduce a hybrid intelligence (H-I) system that fuses symbolic reasoning with advanced machine learning via a hierarchical architecture, inspired by cognitive frameworks like Global Workspace Theory (Baars, A Cognitive Theory of Consciousness, 1988). Methods: This architecture operates across three levels to achieve autonomous, end-to-end workflows: Navigation: Using Vision Transformers, and graph-based neural networks, the system navigates file systems, databases, and software interfaces with precision. Discrete Actions: Multi-framework automated machine learning (AutoML) trains agents to execute discrete decisions, augmented by Transformers and Joint Embedding Predictive Architectures (JEPA) (Assran et al., 2023, 15619–15629) for complex time-series analysis, such as anomaly detection. Planning: Reinforcement learning, world model-based reinforcement learning, and model predictive control orchestrate adaptive workflows tailored to user requests or live system demands. Results: The system’s capabilities are demonstrated in two mission-critical applications: Space Domain Awareness, Satellite Behavior Detection: A graph-based JEPA paired with multi-agent reinforcement learning enables near real-time anomaly detection across 15,000 on-orbit objects, delivering a precision-recall score of 0.98. Autonomously Driven Simulation Setup: The system autonomously configures Computational Fluid Dynamics (CFD) setups, with an AutoML-driven optimizer enhancing the meshing step—boosting boundary layer capture propagation (BL-CP) from 8% to 98% and cutting geometry failure rates from 88% to 2% on novel aircraft geometries. Scalability is a cornerstone, with the distributed training pipeline achieving linear scaling across 2,000 compute nodes for AI model training, while secure model aggregation incurs less than 4% latency in cross-domain settings. Discussion: By blending symbolic precision with data-driven adaptability, this hybrid intelligence system offers a robust, transferable framework for automating complex knowledge work in domains like space operations and engineering simulations—and adjacent applications such as autonomous energy and industrial facility operations, paving the way for next-generation industrial AI systems. © © 2025 Grosvenor, Zemlyansky, Wahab, Bohachov, Dogan and Deighan.",
10.3390/app152011107,Interactive Environment-Aware Planning System and Dialogue for Social Robots in Early Childhood Education,"In this study, we propose an interactive environment-aware dialog and planning system for social robots in early childhood education, aimed at supporting the learning and social interaction of young children. The proposed architecture consists of three core modules. First, semantic simultaneous localization and mapping (SLAM) accurately perceives the environment by constructing a semantic scene representation that includes attributes such as position, size, color, purpose, and material of objects, as well as their positional relationships. Second, the automated planning system enables stable task execution even in changing environments through planning domain definition language (PDDL)-based planning and replanning capabilities. Third, the visual question answering module leverages scene graphs and SPARQL conversion of natural language queries to answer children’s questions and engage in context-based conversations. The experiment conducted in a real kindergarten classroom with children aged 6 to 7 years validated the accuracy of object recognition and attribute extraction for semantic SLAM, the task success rate of the automated planning system, and the natural language question answering performance of the visual question answering (VQA) module.The experimental results confirmed the proposed system’s potential to support natural social interaction with children and its applicability as an educational tool. © 2025 by the authors.",
10.3390/batteries11090332,Experience-Driven NeuroSymbolic System for Efficient Robotic Bolt Disassembly,"With the rapid growth of electric vehicles, the efficient and safe recycling of high-energy battery packs, particularly the removal of structural bolts, has become a critical challenge. This study presents a NeuroSymbolic robotic system for battery disassembly, driven by autonomous learning capabilities. The system integrates deep perception modules, symbolic reasoning, and action primitives to achieve interpretable and efficient disassembly. To improve adaptability, we introduce an offline learning framework driven by a large language model (LLM), which analyzes historical disassembly trajectories and generates optimized action sequences via prompt-based reasoning. This enables the synthesis of new action primitives tailored to familiar scenarios. The system is validated on a real-world UR10e robotic platform across various battery configurations. Experimental results show a 17 s reduction in average disassembly time per bolt and a 154.4% improvement in overall efficiency compared with traditional approaches. These findings demonstrate that combining neural perception, symbolic reasoning, and LLM-guided learning significantly enhances robotic disassembly performance and offers strong potential for generalization in future battery recycling applications. © 2025 by the authors.",
10.3390/s20226520,An automated planning model for hri: Use cases on social assistive robotics,"Using Automated Planning for the high level control of robotic architectures is becoming very popular thanks mainly to its capability to define the tasks to perform in a declarative way. However, classical planning tasks, even in its basic standard Planning Domain Definition Language (PDDL) format, are still very hard to formalize for non expert engineers when the use case to model is complex. Human Robot Interaction (HRI) is one of those complex environments. This manuscript describes the rationale followed to design a planning model able to control social autonomous robots interacting with humans. It is the result of the authors’ experience in modeling use cases for Social Assistive Robotics (SAR) in two areas related to healthcare: Comprehensive Geriatric Assessment (CGA) and non-contact rehabilitation therapies for patients with physical impairments. In this work a general definition of these two use cases in a unique planning domain is proposed, which favors the management and integration with the software robotic architecture, as well as the addition of new use cases. Results show that the model is able to capture all the relevant aspects of the Human-Robot interaction in those scenarios, allowing the robot to autonomously perform the tasks by using a standard planning-execution architecture. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.",
10.3390/su15076251,A Digital Twin-Based Distributed Manufacturing Execution System for Industry 4.0 with AI-Powered On-The-Fly Replanning Capabilities,"Industry 4.0 smart production systems comprise industrial systems and subsystems that need to be integrated in such a way that they are able to support high modularity and reconfigurability of all system components. In today’s industrial production, manufacturing execution systems (MESs) and supervisory control and data acquisition (SCADA) systems are typically in charge of orchestrating and monitoring automated production processes. This article explicates an MES architecture that is capable of autonomously composing, verifying, interpreting, and executing production plans using digital twins and symbolic planning methods. To support more efficient production, the proposed solution assumes that the manufacturing process can be started with an initial production plan that may be relatively inefficient but quickly found by an AI. While executing this initial plan, the AI searches for more efficient alternatives and forwards better solutions to the proposed MES, which is able to seamlessly switch between the currently executed plan and the new plan, even during production. Further, this on-the-fly replanning capability is also applicable when newly identified production circumstances/objectives appear, such as a malfunctioning robot, material shortage, or a last-minute change to a customizable product. Another feature of the proposed MES solution is its distributed operation with multiple instances. Each instance can interpret its part of the production plan, dedicated to a location within the entire production site. All of these MES instances are continuously synchronized, and the actual global or partial (i.e., from the instance perspective) progress of the production is handled in real-time within one common digital twin. This article presents three main contributions: (i) an execution system that is capable of switching seamlessly between an original and a subsequently introduced alternative production plan, (ii) on-the-fly AI-powered planning and replanning of industrial production integrated into a digital twin, and (iii) a distributed MES, which allows for running multiple instances that may depend on topology or specific conditions of a real production plant. All of these outcomes are demonstrated and validated on a use-case utilizing an Industry 4.0 testbed, which is equipped with an automated transport system and several industrial robots. While our solution is tested on a lab-sized production system, the technological base is prepared to be scaled up to larger systems. © 2023 by the authors.",
10.3934/mbe.2025112,Adaptive Neuro-Symbolic framework with dynamic contextual reasoning: A novel framework for semantic understanding,"Despite significant advances in image processing, achieving human-like semantic understanding and explainability remains a formidable challenge. Current deep learning models excel at feature extraction but lack the ability to reason about relationships, interpret context, or provide transparent decision-making. To address these limitations, we propose the adaptive neuro-symbolic framework with dynamic contextual reasoning (ANS-DCR), a novel architecture that seamlessly integrates neural networks with symbolic reasoning. ANS-DCR introduces four key innovations: 1) A contextual embedding layer (CEL) that dynamically converts neural features into structured symbolic embeddings tailored to the scene’s context; 2) hierarchical knowledge graphs (HKGs) that encode multi-level object relationships and update in real-time on the basis of neural feedback; 3) an adaptive reasoning engine (ARE) that performs scalable, context-aware logical reasoning; and 4) an explainable decision-making module (EDM) that generates human-readable explanations, including counterfactuals, enhancing interpretability. This framework bridges the gap between pattern recognition and logical reasoning, enabling deeper semantic understanding and dynamic adaptability. We demonstrate ANS-DCR’s efficacy in complex scenarios such as autonomous driving, where it accurately interprets traffic scenes, predicts behaviors, and provides clear explanations for decisions. Experimental results show superior performance in semantic segmentation, contextual reasoning, and explainability compared with state-of-the-art methods. By combining the strengths of neural and symbolic paradigms, ANS-DCR sets a new benchmark for intelligent, transparent, and scalable image processing systems, offering transformative potential for applications in robotics, healthcare, and beyond. The source code of the proposed ANS-DCR is at github.com/livingjesus/ANS-DCR. ©2025 the Author(s), licensee AIMS Press.",
10.4204/EPTCS.385.51,Beyond Traditional Neural Networks: Toward adding Reasoning and Learning Capabilities through Computational Logic Techniques,"Deep Learning (DL) models have become popular for solving complex problems, but they have limitations such as the need for high-quality training data, lack of transparency, and robustness issues. Neuro-Symbolic AI has emerged as a promising approach combining the strengths of neural networks and symbolic reasoning. Symbolic Knowledge Injection (SKI) techniques are a popular method to incorporate symbolic knowledge into sub-symbolic systems. This work proposes solutions to improve the knowledge injection process and integrate elements of ML and logic into multi-agent systems (MAS). © Andrea Rafanelli.",
10.5220/0013674200003982,CLIP-LLM: A Framework for Autonomous Plant Disease Management in Greenhouse,"Agricultural disease detection and intervention remain challenging due to complex crop health variations, dynamic environmental conditions, and labor-intensive fieldwork. We introduce an end-to-end, platform-agnostic robotic pipeline for autonomous disease detection and treatment systems, with a specific focus on cassava leaves as an example. The pipeline integrates a vision-language perception module based on a pretrained Contrastive Language-Image Pre-training (CLIP) model, fine-tuned on an augmented dataset of cassava leaf images for disease detection. High-level task planning is performed by a Generative Pre-trained Transformer 4 (GPT-4), which interprets perception outputs and generates symbolic action plans (e.g., navigate to target, perform treatment). The low-level control system is implemented in the PyBullet dynamic simulator. We evaluated a vision-language model (VLM) perception and a Large Language Model (LLM) based planning system (in a virtual environment with predefined 3D coordinates for plant and spray positions). The VLM achieved 83% classification accuracy in simulation and real-time tests with a static camera produced classification accuracies of 70% Cassava Brown Streak Disease (CBSD), 65% Cassava Mosaic Disease (CMD) and 52% Cassava Bacterial Blight (CBB), and under dynamic camera it achieve the accuracy of 65% (CBSD), 52% (CMD), and 32% (CBB). Currently, our low-level controller executes the LLM-generated plans with high precision (less than ±2 mm positioning error). These results demonstrate the viability of our platform-agnostic modular architecture for precision agriculture that supports closed-loop robustness and scalability. © 2025 by SCITEPRESS–Science and Technology Publications, Lda.",
10.5555/3378680.3378739,Language-capable robots may inadvertently weaken human moral norms,"Previous research in moral psychology and human-robot interaction has shown that technology shapes human morality, and research in human-robot interaction has shown that humans naturally perceive robots as moral agents. Accordingly, we propose that language-capable autonomous robots are uniquely positioned among technologies to significantly impact human morality. We therefore argue that it is imperative that language-capable robots behave according to human moral norms and communicate in such a way that their intention to adhere to those norms is clear. Unfortunately, the design of current natural language oriented robot architectures enables certain architectural components to circumvent or preempt those architectures' moral reasoning capabilities. In this paper, we show how this may occur, using clarification request generation in current dialog systems as a motivating example. Furthermore, we present experimental evidence that the types of behavior exhibited by current approaches to clarification request generation can cause robots to (1) miscommunicate their moral intentions and (2) weaken humans' perceptions of moral norms within the current context. This work strengthens previous preliminary findings, and does so within an experimental paradigm that provides increased external and ecological validity over earlier approaches.",
10.5555/3463952.3463967,Reason Explanation for Encouraging Behaviour Change Intention,"The demand for intelligent virtual advisors in our rapidly advancing world is rising and, consequently, the need for understanding the reasoning process to answer why a particular piece of advice is provided to the user is directly increasing. Personalized explanation is regarded as a reliable way to improve the user's understanding and trust in the virtual advisor. So far, cognitive explainable agents utilize reason explanation by referring to their own mental state (beliefs and goals) to explain their own behaviour. However, when the explainable agent plays the role of a virtual advisor and recommends a behaviour for the human to perform, it is best to refer to the user's mental state, rather than the agent's mental state, to form a reason explanation. In this paper, we are developing an explainable virtual advisor (XVA) that communicates with the user to elicit the user's beliefs and goals and then tailors its advice and explains it according to the user's mental state. We tested the proposed XVA with university students where the XVA provides tips to reduce the students' study stress. We measured the impact of receiving three different patterns of tailored explanations (belief-based, goal-based, and belief&amp;goal-based explanation) in terms of the students' intentions to change their behaviours. The results showed that the intention to change is not only related to the explanation pattern but also to the user context, the relationship built with the agent, the type of behaviour recommended and the user's current intention to do the behaviour.",
10.5555/3463952.3464044,Deep Implicit Coordination Graphs for Multi-agent Reinforcement Learning,"Multi-agent reinforcement learning (MARL) requires coordination to efficiently solve certain tasks. Fully centralized control is often infeasible in such domains due to the size of joint action spaces. Coordination graph based formalization allows reasoning about the joint action based on the structure of interactions. However,they often require domain expertise in their design. This paper introduces the deep implicit coordination graph (DICG) architecture for such scenarios. DICG consists of a module for inferring the dynamic coordination graph structure which is then used by a graph neural network based module to learn to implicitly reason about the joint actions or values. DICG allows learning the tradeoff between full centralization and decentralization via standard actor-critic methods to significantly improve coordination for domains with large number of agents. We apply DICG to both centralized-training-centralized-execution and centralized-training-decentralized-execution regimes. We demonstrate that DICG solves the relative over generalization pathology in predatory-prey tasks as well as outperforms various MARL baselines on the challenging StarCraft II Multi-agent Challenge (SMAC) and traffic junction environments.",
10.5555/3535850.3535884,Optimizing Multi-Agent Coordination via Hierarchical Graph Probabilistic Recursive Reasoning,"Multi-agent reinforcement learning (MARL) requires coordination by some means of interaction between agents to efficiently solve tasks. Interaction graphs allow reasoning about joint actions based on the local structure of interactions, but they disregard the potential impact of an agent's action on its neighbors' behaviors, which could rapidly alter in dynamic settings. In this paper, we thus present a novel perspective on opponent modeling in domains with only local interactions using (level-1) Graph Probabilistic Recursive Reasoning (GrPR2). Unlike previous work on recursive reasoning, each agent iteratively best-responds to other agents' policies over all possible local interactions. Agents' policies are approximated via a variational Bayes scheme for capturing their uncertainties, and we prove that an induced variant of Q-learning converges under self-play when there exists only one Nash equilibrium. In cooperative settings, we further devise a variational lower bound on the likelihood of each agent's optimality. Opposed to other models, optimizing the resulting objective prevents each agent from attaining an unrealistic modelling of others, and yields an exact tabular Q-iteration method that holds convergence guarantees. Then, we deepen the recursion to level-k via Cognitive Hierarchy GrPR2 (GrPR2-CH), which lets each level-k player best-respond to a mixture of strictly lower levels in the hierarchy. We prove that: (1) level-3 reasoning is the optimal hierarchical level, maximizing each agent's expected return; and (2) the weak spot of the classical CH models is that 0-level is uniformly distributed, as it may introduce policy bias. Finally, we propose a practical actor-critic scheme, and illustrate that GrPR2-CH outperforms strong MARL baselines in the particle environment.",
10.5555/3535850.3535953,Preference-Based Goal Refinement in BDI Agents,"Computational agents based on the BDI framework typically rely on abstract plans and plan refinement to reach a degree of autonomy in dynamic environments: agents are provided with the ability to selecthow-to achieve their goals by choosing from a set of options. In this work we focus on a related, yet under-studied feature:abstract goals. These constructs refer to the ability of agents to adopt goals that are not fully grounded at the moment of invocation, refining them only when and where needed: the ability to selectwhat-to (concretely) achieve at run-time. We present a preference-based approach to goal refinement, defining preferences based on extendedCeteris Paribus Networks (CP-Nets) for an AgentSpeak(L)-like agent programming language, and mapping the established CP-Nets logic and algorithms to guide the goal refinement step. As a technical contribution, we present an implementation of this method that solely uses a Prolog-like inference engine of the agent's belief-base to reason about preferences, thus minimally affecting the decision-making mechanisms hard-coded in the agent framework.",
10.5555/3535850.3535964,BOID*: Autonomous Goal Deliberation through Abduction,"The original BOID [5] is a cognitive architecture that unifies Belief, Obligation, Intention and Desire rules to calculate which actions should an agent undertake next. In the current paper, we adapt the original BOID with an aim to model autonomous agency. The new BOID* architecture is able to capture anticipation that we believe to be one of the hallmarks of autonomous agency. We focus on developing algorithms for anticipatory reasoning through a new BOID* goal deliberation component. The key method that BOID* introduces is abductive reasoning as a way to represent motivational attitudes, such as desires and obligations. As a result of deliberation via abduction, BOID* specifies intention revision procedures that connect motivational and informational attitudes. The BOID* is a part of the project to build autonomous AI models that make explicit the reasoning behind adopting future goals, prioritizing selected goals and forming intentions.",
10.5555/3535850.3535998,Epistemic Reasoning in Jason,"This paper presents an extension to the Jason BDI language to allow qualitative reasoning under uncertainty. We demonstrate the need for such an extension using a challenge from the 2019 Multi-Agent Programming Contest (MAPC), namely localization for navigation. Given the ability to qualitatively reason about what the agent knows and what it considers possible (or impossible), these challenges become easier to express, reason about, and act upon in a Jason program.Through the use of epistemic logic and the epistemic reasoner in Hintikka's World, our extension allows agents to express epistemic queries; specifically, utilizing the class of single-agent S5 epistemic models to model-check queries about the agent's uncertainty. This paper also provides an evaluation of the overall performance and scalability of the extension's implementation to show how it impacts the agent's reasoning time; from the evaluation results, we use the official 2019 MAPC time constraints to examine the performance tradeoffs of using the presented extension to model and reason about uncertainty.",
10.5555/3545946.3598760,Feedback-Guided Intention Scheduling for BDI Agents,"Intelligent agents, like those based on the popular BDI agent paradigm, typically pursue multiple goals in parallel. An intention scheduler is required to reason about the possible interactions between the agent's intentions to maximize some utility. An important consideration when scheduling intentions is the user's preferences over the goals and the ways in which the goals are achieved. These preferences are generally unknown in advance, time-consuming to elicit, hard to model, and difficult to incorporate into an intention scheduler. In this paper, we present a Monte Carlo Tree Search based intention scheduler (pref-MCTS) that is able to learn the user's preferences over intention schedules via low-burden comparative-type queries. It incorporates the learned preferences in guiding the search, leading to execution policies that are optimized towards the user's preferences and expectations. We evaluate our approach using an artificial oracle that shows that pref-MCTS improves over state-of-the-art baselines, even when provided with a limited number of preference queries and noisy labels. We also conducted a user study and showed that pref-MCTS is able to learn user preferences and generate schedules that are preferred by the users in real-time.",
10.5555/3545946.3598838,Value Inference in Sociotechnical Systems,"As artificial agents become increasingly embedded in our society, we must ensure that their behavior aligns with human values. Value alignment entails value inference, the process of identifying values and reasoning about how humans prioritize values. We introduce a holistic framework that connects the technical (AI) components necessary for value inference. Subsequently, we discuss how hybrid intelligence-the synergy of human and artificial intelligence---is instrumental to the success of value inference. Finally, we illustrate how value inference both poses significant challenges and provides novel opportunities for multiagent systems research.",
10.5555/3635637.3662884,Fast and Slow Goal Recognition,"Goal recognition is a crucial aspect of understanding the intentions and objectives of agents by observing some of their actions. The most prominent approaches to goal recognition can be divided into two main categories: (1) trustworthy systems, which exploit automated reasoning for computing plans compatible with the observed actions, and (2) swifter systems, which try to quickly infer goals, often overlooking complex cognitive processes, and have no formal guarantees of their results. This paper introduces a novel approach inspired by the dual process theory, which integrates these two techniques. A dual-process model is proposed, leveraging fast, experience-based recognition for immediate goal identification, and slow, deliberate analysis for deeper understanding. Machine learning techniques and classical planning techniques are employed to obtain this dual-process system. Experimental evaluations demonstrate the effectiveness of the approach, reducing the amount of resources required to compute a solution (e.g., time to find a goal), while at the same time enhancing accuracy and robustness, especially in more complex scenarios.",
10.5555/3635637.3662921,NovelGym: A Flexible Ecosystem for Hybrid Planning and Learning Agents Designed for Open Worlds,"As AI agents leave the lab and venture into the real world as autonomous vehicles, delivery robots, and cooking robots, it is increasingly necessary to design and comprehensively evaluate algorithms that tackle the ""open-world''. To this end, we introduce NovelGym, a flexible and adaptable ecosystem designed to simulate gridworld environments, serving as a robust platform for benchmarking reinforcement learning (RL) and hybrid planning and learning agents in open-world contexts. The modular architecture of NovelGym facilitates rapid creation and modification of task environments, including multi-agent scenarios, with multiple environment transformations, thus providing a dynamic testbed for researchers to develop open-world AI agents.",
10.5555/3635637.3662942,BDI Agents in Natural Language Environments,"Developing autonomous agents to deal with real-world problems is challenging, especially when developers are not necessarily specialists in artificial intelligence. This poses two key challenges regarding the interface of the programming with the developer, and the efficiency of the resulting agents. In this paper we tackle both challenges in an efficient agent architecture that leverages recent developments in natural language processing, and the intuitive folk psychology abstraction of the beliefs, desires, intentions (BDI) architecture. The resulting architecture uses existing reinforcement learning techniques to bootstrap the agent's reasoning capabilities while allowing a developer to instruct the agent more directly using natural language as its programming interface. We empirically show the efficiency gains of natural language plans over a pure machine learning approach in the ScienceWorld environment.",
10.5555/3635637.3663023,Design Patterns for Explainable Agents (XAg),"The ability to explain the behaviour of the AI systems is a key aspect of building trust, especially for autonomous agent systems - how does one trust an agent whose behaviour can not be explained? In this work, we advocate the use of design patterns for developing explainable-by-design agents (XAg), to ensure explainability is an integral feature of agent systems rather than an ""add-on"" feature. We present TriQPAN (Trigger, Query, Process, Action and Notify), a design pattern for XAg. TriQPAN can be used to explain behaviours of any agent architecture and we show how this can be done to explain decisions such as why the agent chose to pursue a particular goal, why or why didn't the agent choose a particular plan to achieve a goal, and so on. We term these queries as direct queries. Our framework also supports temporal correlation queries such as asking a search and rescue drone, ""which locations did you visit and why?"". We implemented TriQPAN in the SARL agent language, built-in to the goal reasoning engine, affording developers XAg with minimal overhead. The implementation will be made available for public use. We describe that implementation and apply it to two case studies illustrating the explanations produced, in practice.",
10.5555/3635637.3663048,Enabling BDI Agents to Reason on a Dynamic Action Repertoire in Hypermedia Environments,"Autonomy requires adaptability and persistence in pursuing long-term objectives within evolving contexts. While BDI agents can cope with dynamic and uncertain environments, their adaptability is typically constrained by static action repertoires, known a priori by designers. Through Semantic Web and Web of Things technologies, machine-readable action descriptions can be discovered in hypermedia environments, and updated dynamically to mirror the evolving landscape of actions offered by real-world environments. This paper proposes the integration of action-oriented BDI reasoning with signifiers that reveal information about action possibilities that may appear, disappear, or be modified in a hypermedia environment at any time. We extend the means-end reasoning of BDI agents with a mechanism for resolving signifiers discovered at run time into actions, which enables agents to adjust their decision-making based on action possibilities advertised in the environment. We evaluate our approach through experiments, where Jason agents discover signifiers expressed with available Web ontologies. The results demonstrate that our signifier resolution mechanism enhances action reasoning at run time towards effective goal achievement in dynamic and unknown environments.",
10.5555/3635637.3663074,Pragmatic Instruction Following and Goal Assistance via Cooperative Language-Guided Inverse Planning,"People often give instructions whose meaning is ambiguous without further context, expecting that their actions or goals will disambiguate their intentions. How can we build assistive agents that follow such instructions in a flexible, context-sensitive manner? This paper introduces cooperative language-guided inverse plan search (CLIPS), a Bayesian agent architecture for pragmatic instruction following and goal assistance. Our agent assists a human by modeling them as a cooperative planner who communicates joint plans to the assistant, then performs multimodal Bayesian inference over the human's goal from actions and language, using large language models (LLMs) to evaluate the likelihood of an instruction given a hypothesized plan. Given this posterior, our assistant acts to minimize expected goal achievement cost, enabling it to pragmatically follow ambiguous instructions and provide effective assistance even when uncertain about the goal. We evaluate these capabilities in two cooperative planning domains (Doors, Keys \&amp; Gems and VirtualHome), finding that CLIPS significantly outperforms GPT-4V, LLM-based literal instruction following and unimodal inverse planning in both accuracy and helpfulness, while closely matching the inferences and assistive judgments provided by human raters.",
10.5555/3635637.3663257,Empowering BDI Agents with Generalised Decision-Making,"While research on software agents has long focused on explicit agent communication, there is comparatively less effort on implicit communication between agents via recognising each other's intentions and desires for understanding their decision-making reasoning process. Since most human communication is not explicit, we aim to outline a research agenda to help endow autonomous agents with analogous coordination capabilities. In this paper, we formalise a framework that empowers the decision-making process of BDI agents in adversarial and cooperative environments by casting them as generalised planners using Theory of Mind. Our formalisation uses the fundamental philosophical properties of the BDI model and its reasoning process to outline a broad research agenda in agents' research.",
10.5555/3709347.3743552,Feature Engineering for Agents: An Adaptive Cognitive Architecture for Interpretable ML Monitoring,"Monitoring Machine Learning (ML) models in production environments is crucial, yet traditional approaches often yield verbose, low-interpretability outputs that hinder effective decision-making. We propose a cognitive architecture for ML monitoring that applies feature engineering principles to agents based on Large Language Models (LLMs), significantly enhancing the interpretability of monitoring outputs. Central to our approach is a Decision Procedure module that simulates feature engineering through three key steps: Refactor, Break Down, and Compile. The Refactor step improves data representation to better capture feature semantics, allowing the LLM to focus on salient aspects of the monitoring data while reducing noise and irrelevant information. Break Down decomposes complex information for detailed analysis, and Compile integrates sub-insights into clear, interpretable outputs. This process leads to a more deterministic planning approach, reducing dependence on LLM-generated planning, which can sometimes be inconsistent and overly general. The combination of feature engineering-driven planning and selective LLM utilization results in a robust decision support system, capable of providing highly interpretable and actionable insights. Experiments using multiple LLMs demonstrate the efficacy of our approach, achieving significantly higher accuracy compared to various baselines across several domains.",
10.5555/3709347.3743563,Human-Agent Coordination in Games under Incomplete Information via Multi-Step Intent,"Strategic coordination between autonomous agents and human partners under incomplete information can be modeled as turn-based cooperative games. We extend a turn-based game under incomplete information, the shared-control game, to allow players to take multiple actions per turn rather than a single action. The extension enables the use of multi-step intent, which we hypothesize will improve performance in long-horizon tasks. To synthesize cooperative policies for the agent in this extended game, we propose an approach featuring a memory module for a running probabilistic belief of the environment dynamics and an online planning algorithm called IntentMCTS. This algorithm strategically selects the next action by leveraging any communicated multi-step intent via reward augmentation while considering the current belief. Agent-to-agent simulations in the Gnomes at Night testbed demonstrate that IntentMCTS requires fewer steps and control switches than baseline methods. A human-agent user study corroborates these findings, showing an 18.52\% higher success rate compared to the heuristic baseline and a 5.56\% improvement over the single-step prior work. Participants also report lower cognitive load, frustration, and higher satisfaction with the IntentMCTS agent partner.",
10.5555/3709347.3743564,Azorus: Commitments over Protocols for BDI Agents,"Commitments support flexible interactions between agents by capturing the meaning of their interactions. However, commitment-based reasoning is not adequately supported in agent programming models. We contribute Azorus, a programming model based on declarative specifications centered on commitments and aligned with information protocols. Azorus supports reasoning about goals and commitments and combines modeling of commitments and protocols, thereby uniting three leading declarative approaches to engineering decentralized multiagent systems. Specifically, we realize Azorus over three existing technology suites: (1) Jason, a popular BDI-based programming model; (2) Cupid, a formal language and query-based model for commitments; and (3) BSPL, a language and its associated tools for information protocols, including Jason programming. We implement Azorus and demonstrate how it enables capturing interesting patterns of business logic.",
10.5555/3709347.3743782,Generalised BDI Planning,"Agent interpreters based on the Beliefs, Desires, and Intentions (BDI) model traditionally perform means-ends reasoning using plan libraries composed of reactive planning rules. However, the design of such rules often imposes a heavy knowledge engineering burden on a designer, and trades off flexibility for runtime efficiency. This use of planning rules originates from the limitations of planning technology at the time of the first BDI implementations. While these limitations have gradually been overcome by the integration of various types of planning into existing BDI theories, the corresponding interpreters remain fundamentally plan-library based. In this paper, we develop a novel BDI agent architecture driven by generalised planning as means-ends reasoning, in a radical departure from existing architectures. This architecture has two key properties. First, it more closely resembles the foundations of BDI logic and reasoning. Second, it offers substantial gains in efficiency in comparison with an architecture driven by classical planning.",
10.5555/3709347.3743788,Personality-Driven Decision Making in LLM-Based Autonomous Agents,"The embedding of Large Language Models (LLMs) into autonomous agents is a rapidly developing field which enables dynamic, configurable behaviours without the need for extensive domain-specific training. In our previous work, we introduced SANDMAN, a Deceptive Agent architecture leveraging the Five-Factor OCEAN personality model, demonstrating that personality induction significantly influences agent task planning. Building on these findings, this study presents a novel method for measuring and evaluating how induced personality traits affect task selection processes-specifically planning, scheduling, and decision-making-in LLM-based agents. Our results reveal distinct task-selection patterns aligned with induced OCEAN attributes, underscoring the feasibility of designing highly plausible Deceptive Agents for proactive cyber defense strategies.",
10.5555/3709347.3743808,"Planning, Scheduling, and Execution on the Moon: The CADRE Technology Demonstration Mission","NASA's Cooperative Autonomous Distributed Robotic Exploration (CADRE) mission, slated for flight to the Moon's Reiner Gamma region in 2025/2026, is designed to demonstrate multi-agent autonomous exploration of the Lunar surface and sub-surface. A team of three robots and a base station will autonomously explore a region near the lander, collecting the data required for 3D reconstruction of the surface with no human input; and then autonomously perform distributed sensing with multi-static ground penetrating radars (GPR), driving in formation while performing coordinated radar soundings to create a map of the subsurface. At the core of CADRE's software architecture is a novel autonomous, distributed planning, scheduling, and execution (PS&amp;E) system. The system coordinates the robots' activities, planning and executing tasks that require multiple robots' participation while ensuring that each individual robot's thermal and power resources stay within prescribed bounds, and respecting ground-prescribed sleep-wake cycles. The system uses a centralized-planning, distributed-execution paradigm, and a leader election mechanism ensures robustness to failures of individual agents. In this paper, we describe the architecture of CADRE's PS&amp;E system; discuss its design rationale; and report on verification and validation (V&amp;V) testing of the system on CADRE's hardware in preparation for deployment on the Moon.",
10.5555/3709347.3743817,Gricean Norms as a Basis for Effective Collaboration,"Effective human-AI collaboration hinges not only on the AI agent's ability to follow explicit instructions but also on its capacity to navigate ambiguity, incompleteness, invalidity, and irrelevance in communication. Gricean conversational and inference norms facilitate collaboration by aligning unclear instructions with cooperative principles. We propose a normative framework that integrates Gricean norms and cognitive frameworks---common ground, relevance theory, and theory of mind---into large language model (LLM) based agents. The normative framework adopts the Gricean maxims of quantity, quality, relation, and manner, along with inference, as Gricean norms to interpret unclear instructions, which are: ambiguous, incomplete, invalid, or irrelevant. Within this framework, we introduce Lamoids, GPT-4 powered agents designed to collaborate with humans. To assess the influence of Gricean norms in human-AI collaboration, we evaluate two versions of a Lamoid: one with norms and one without. In our experiments, a Lamoid collaborates with a human to achieve shared goals in a grid world (Doors, Keys, and Gems) by interpreting both clear and unclear natural language instructions. Our results reveal that the Lamoid with Gricean norms achieves higher task accuracy and generates clearer, more accurate, and contextually relevant responses than the Lamoid without norms. This improvement stems from the normative framework, which enhances the agent's pragmatic reasoning, fostering effective human-AI collaboration and enabling context-aware communication in LLM-based agents.",
10.5555/3709347.3743841,Logic of Knowledge and Cognitive Ability,"Along with the convenience brought by the increasing usage of autonomous systems, unexpected accidents happened. These accidents emphasize the need for autonomous systems to possess the ability to recognize potential hazards, effectively communicate these hazards to human operators, and facilitate retrospective analyses. This ability, including recognition, prejudgment, post-analysis, and reasoning, falls within the realm of cognitive ability, which is important in improving the safety and outcomes in the decision-making process of such systems. In this paper, we present a foundational step toward addressing the safety challenges involving the cognitive ability of artificial agents. We study the interplay between knowledge and the cognitive ability of intelligent agents. The main technical result is a sound and complete bimodal logical system that describes the interplay between the knowledge and cognitive ability modalities.",
10.5555/3709347.3744035,The Next Level of Long-Term Agent Autonomy -- Proactively Acquiring Knowledge and Abilities,"For an artificial agent operating long-term under real-world conditions it is not enough to be able to act on orders given by the human. Even being able to act proactively (anticipatory, self-initiated) does not suffice. The reason roots in the unrealistic assumption that the proactive agent from the start and always knows everything it needs to know and has all the abilities it requires. We argue that the agent has to be able to proactively learn new knowledge and abilities according to how the dynamic environment evolves. We identify challenges and directions towards proactive learning. Our focus is on formal methods which lend themselves to doing the necessary reasoning but also give suggestions how these might be integrated with machine learning. The ideas envisioned in this paper can advance (M)AS (Multi-Agent Systems) research and have the potential to enhance collaborations of hybrid human-AI systems.",
10.5555/3709347.3744038,Grounding Agent Reasoning in Image Schemas: A Neurosymbolic Approach to Embodied Cognition,"Despite advances in embodied AI, agent reasoning systems still struggle to capture the fundamental conceptual structures that humans naturally use to understand and interact with their environment. To address this, we propose a novel framework that bridges embodied cognition theory and agent systems by leveraging a formal characterization of image schemas, which are defined as recurring patterns of sensorimotor experience that structure human cognition. By customizing LLMs to translate natural language descriptions into formal representations based on these sensorimotor patterns, we will be able to create a neurosymbolic system that grounds the agent's understanding in fundamental conceptual structures. We argue that such an approach enhances both efficiency and interpretability while enabling more intuitive human-agent interactions through shared embodied understanding.",
10.5555/3709347.3744045,Responsible Autonomy for Hybrid Intelligence,"In hybrid intelligence (HI) systems, artificial intelligence (AI) agents and humans work together to solve complex tasks. In these interactions, each agent is expected to work autonomously and be responsible for their actions. By capturing consent as a regulation of actions in a normative environment (such as a HI system), an agent can determine an appropriate action within the normative environment, and reason on the moral and ethical requirements and effects of the action. Current consent representations do not allow agents to reason on normative actions, which limit agent autonomy. We are developing a representation of consent that captures the nuances of consent from human-human interaction, and expresses them computationally to allow the AI agent to responsibly practice autonomy in a HI system. In future work, the proposed representation will be evaluated against human intuitions about consent, and compared to current consent representations to ensure a robust and domain-agnostic formalisation. Further research includes developing a consent representation that can manage multi-party consent and shared resources, specifying accounts for consent violations to determine culpability, and exploring a developmental approach to norm representation and management for greater perceived agent responsibility and autonomy in a HI system.",
10.5555/3709347.3744089,SmartPilot:Agent-Based CoPilot for Intelligent Manufacturing,"In the dynamic landscape of Industry 4.0, achieving efficiency, precision, and adaptability is essential for optimizing manufacturing operations. SmartPilot is a neurosymbolic and agent-based CoPilot designed to enhance real-time decision-making capabilities in manufacturing. The system addresses three key challenges: anomaly prediction, production forecasting, and domain-specific question answering through an agent-based framework. SmartPilot leverages multimodal data and a compact architecture optimized for edge devices. This paper highlights its innovative combination of agent-based design and neurosymbolic reasoning to enable contextual decision-making in complex environments. The demonstration video, datasets, and supplementary materials are available at https://github.com/ChathurangiShyalika/SmartPilot.",
