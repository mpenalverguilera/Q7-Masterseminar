DOI,Source title,Abstract,REASON
10.1007/s10462-025-11381-w,Artificial Intelligence Review,"Conventional treatment methods make even the most basic healthcare issues more complicated, which in turn increases the number of parties involved. Classical computing lacks the speed and accuracy needed for effective stakeholder collaboration in COVID-19 healthcare solutions, such as patients, insurance agents, healthcare practitioners, pharmaceutical suppliers, etc. The research uses organizational information processing theory (OIPT) to examine how quantum computing which is applications of artificial intelligence (AI) could transform the healthcare business, creating a more sustainable and less burdened system. The study of quantum computing (QC) has the potential to bring about “quantum leaps,” which might have unforeseen consequences for healthcare. The discovery of new medications, the personalization of medicinal treatments, and the acceleration of DNA sequencing are just a few of the many possible applications of this method. The potential of QC to transform compute-intensive healthcare tasks like drug-discovery, personalized-medicine, DNA-sequencing, medical-imaging, and operational-optimization is the primary focus of this survey paper, which offers the first comprehensive analysis of QCs diverse capabilities in improving healthcare systems. After a thorough literature study, we created taxonomies on the healthcare QC paradigm’s history and supporting technologies, applications, needs, architectures, security, outstanding questions, and future research prospects. We hope that by conducting this survey, researchers with varying levels of experience in quantum computing and healthcare will better understand the state of the art, assess opportunities and threats, and make informed decisions as they develop novel architectures and applications for this emerging field. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1007/s43503-025-00072-8,AI in Civil Engineering,"The expansion of rail transport infrastructures necessitates accurate and efficient soil surveys to ensure long-term stability and performance, particularly in regions prone to soil heaving. This study aimed to demonstrate the potential of non-destructive spectral analysis combined with Agentic Artificial Intelligence for automating the identification of soil heaving potential, providing a transformative approach to soil assessment in railway construction. A robust AI-agent was developed to predict soil heaving potential across temperature regimes (ranging from 0°C to -5°C and back), enabling characterization of the relative acoustic compressibility coefficient (β) based on the physical and mechanical properties of the soil. The main objective was to develop a framework that integrated spectral reflectance data with machine learning algorithms to predict soil heaving potential and reduce the reliance on traditional invasive methods. The experimental setup employed digital techniques to process and record longitudinal and transverse acoustic pulse signals reflected from piezoelectric sensors mounted on soil specimens. The processed signals were automatically transferred via a USB adapter to a PC for further analysis by the AI-agent. Acoustic diagnostics of the soils were performed using Fast-Fourier Transform (FFT) Spectral Analysis, followed by correlation of waveform spectra with heaving deformation. The AI-agent utilized a hybrid architecture combining Convolutional Neural Network (CNN), Support Vector Machine (SVM), and Random Forest (RF) algorithms to address the complexities of heterogeneous soil data and multifaceted prediction tasks—including heaving classification and deformation regression—while mitigating overfitting. Soil heaving potential was accurately predicted by the AI agent, with minor variations attributed to equipment sensitivity. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.atech.2025.101412,Smart Agricultural Technology,"Digital twins and artificial intelligence are increasingly explored to support decision-making. In this work, we introduce a modular and interoperable architecture that combines digital twins with reinforcement learning for adaptive decision-making in complex environmental systems. We apply this approach to smart farming, where efficient resource use is critical to balance productivity with environmental impact. Our contributions are threefold: (a) the augmentation of agricultural models as digital twins—specifically the crop growth model WOFOST and the plant disease model A-scab—that assimilate field data to reflect current crop conditions; (b) the integration of reinforcement learning agents that generate recommendations for pesticide and fertilizer application—the first to demonstrate interoperable reinforcement learning-integrated digital twins in operational agriculture; and (c) the development of a FIWARE-based interoperability layer that integrates a diverse set of (edge) components. We demonstrate our approach in two pilot studies—apple scab management and nitrogen application in winter wheat—showcasing its potential for real-world application in diverse agricultural contexts and its transferability to other domains. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.commtr.2025.100165,Communications in Transportation Research,"Designing an optimal departure trajectory for an airport can minimize fuel emissions within the surrounding airspace and noise perceived by nearby populations, which brings positive sociological and economic implications in addition to environmental benefits. Yet, designing a trajectory that considers realistic operational constraints could be complex and, consequently, computationally expensive. Traditional trajectory optimization methods often simplify the problem to manage computational costs, which leads to compromised accuracy. To overcome this challenge, we propose a reinforcement learning (RL) approach that can satisfy multidisciplinary constraints by leveraging accurately modeled flight dynamics, high-fidelity population data, and topological data. This is achieved by establishing a comprehensive, physically-consistent simulated environment for the learning algorithm, while keeping the computational cost low. Instead of directly designing the trajectory itself, we train an RL agent to control the aircraft, whose trajectory is then considered as optimal. We model the RL problem as a continuous Markov decision process and employ the soft actor-critic architecture. By changing the relative importance of fuel consumption and noise in the optimization objective, we can obtain different optimum trajectories that are well-suited to the specific region of interest. Not surprisingly, a trade-off between fuel consumption and noise impact is observed in our results. This developed framework provides a more accurate and sophisticated approach for departure trajectory optimization, whose results are beneficial for future airspace design and can support sustainable aviation efforts. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1016/j.engappai.2025.112222,Engineering Applications of Artificial Intelligence,"The degradation of fuel cell systems (FCS) affects the energy management performance of fuel cell hybrid electric vehicles (FCHEVs), especially in the case of severe degradation. This study develops a novel predictive energy management architecture, which consists of the Extended Long Short-Term Memory (xLSTM) and Soft Actor-Critic (SAC). Specifically, the speed predictor is built using xLSTM network and leverages the speed and position information of the preceding and following vehicles. In order to provide a reliable basis for energy management in degradation scenarios, an FCS degradation model is developed, which enables the dynamic mapping of output efficiency curves under varying state-of-health (SOH) conditions. Sequentially, a SAC-based agent is employed as the energy management strategy (EMS), which innovatively takes full account of the impact of the FCS SOH on energy allocation, achieving proactive degradation-aware energy allocation. Simulation results demonstrate that the developed xLSTM architecture achieves a 71 % improvement in speed prediction accuracy compared to Transformer-based models within the Next Generation Simulation validated scenario. Moreover, at SOH = 90 %, the newly designed EMS reduces operational costs by 8.7 % and 10.7 % compared to conventional methods under the New European Driving Cycle and Worldwide Harmonized Light Vehicles Test Procedure, while decreasing FCS degradation costs by 17 % and 51 %, respectively. The innovative approach not only elevates energy efficiency but also prolongs FCS operational longevity via intelligent SOH-aware, which establishes a new paradigm for lifecycle-optimized energy management in FCHEVs. © 2025 Elsevier B.V., All rights reserved.",TOPIC
10.1109/ACCESS.2021.3083087,Federated Reinforcement Learning Acceleration Method for Precise Control of Multiple Devices,"Nowadays, Reinforcement Learning (RL) is applied to various real-world tasks and attracts much attention in the fields of games, robotics, and autonomous driving. It is very challenging and devices overwhelming to directly apply RL to real-world environments. Due to the reality gap simulated environment does not match perfectly to the real-world scenario and additional learning cannot be performed. Therefore, an efficient approach is required for RL to find an optimal control policy and get better learning efficacy. In this paper, we propose federated reinforcement learning based on multi agent environment which applying a new federation policy. The new federation policy allows multi agents to perform learning and share their learning experiences with each other e.g., gradient and model parameters to increase their learning level. The Actor-Critic PPO algorithm is used with four types of RL simulation environments, OpenAI Gym's CartPole, MoutainCar, Acrobot, and Pendulum. In addition, we did real experiments with multiple Rotary Inverted Pendulum (RIP) to evaluate and compare the learning efficiency of the proposed scheme with both environments.",TOPIC
10.1109/ACCESS.2025.3573419,Strategic Implementation of Super-Agents in Heterogeneous Multi-Agent Training for Advanced Military Simulation Adaptability,"This study focuses on the application of reinforcement learning in tactical military simulation environments involving heterogeneous multi-agent systems. Optimizing Heterogeneous Multi-Agent Training (HMAT) through scenario-specific adjustments to the Proximal Policy Optimization (PPO) algorithm, we tackle the complexity of tactical simulations. Utilizing an advanced simulation platform, a diverse range of Reinforcement Learning (RL) agents are rigorously trained across various combat scenarios. A ‘super-agent’, an Artificial Intelligence (AI) orchestrator for multi-agent systems, marks a significant advancement in collaborative AI, enhancing operational performance. Comparative analysis highlights the strengths of both traditional RL approaches and HMAT in a unified computational framework. While independent learning agents excel in predictable environments with fast training capabilities, HMAT stands out in dynamic scenarios for its adaptability and superior performance. The integration of HMAT with ‘super-agents’ is shown to markedly improve the fidelity and adaptive capacity of military simulations. Experimental results demonstrate that our fine-tuned super-agent framework achieves up to 92% mission success rate, outperforming scenario-specific baselines by 15–20% in complex Suppression of Enemy Air Defenses (SEAD) and air-to-ground tasks.These enhancements have far-reaching implications, potentially revolutionizing strategic military training and operational planning and underscoring AI’s critical role in modern defense strategies.",TOPIC
10.1109/ACCESS.2025.3610526,"A Multi-Layered AI-Driven Cybersecurity Architecture: Integrating Entropy Analytics, Fuzzy Reasoning, Game Theory, and Multi-Agent Reinforcement Learning for Adaptive Threat Defense","In the face of increasingly sophisticated cyberattacks, including adaptive adversaries and stealthy anomalies, key features of defense mechanisms should be effective, interpretable, and theoretically rooted. Conventional intrusion detection systems are typically based on a single-paradigm machine learning model which can be effective (because it is optimized for conditions), but fail in generalizability and falling back on an explanation of its prediction. This paper outlines a multi-layered AI-enabled cyber defense framework that integrates entropy analytics, fuzzy inference, game-theoretic defense, and multi-agent reinforcement learning (MARL) inside a closed-loop adaptive architecture. In its simplest form, the novelty of the paper is that, four functional paradigms - uncertainty quantification, interpretability, strategic adversarial thinking, and live policy adaptation - are placed into a single coherent system. The framework operates as sequential and feedback salients - entropy analytics quantify the uncertainty in are states, fuzzy inference end maps the uncertainty into qualitative decision rules, game theory shapes defender - attacker towards equilibrium strategies, and MARL dynamically updates those strategies for convergence and long term adaptation. The empirical work on appropriate benchmark intrusion detection datasets consistently outperformed baseline systems including the DDN, Fed-ID, AG-IDS, DL-FL systems producing a 6-12% increase in detection accuracy, lower false positive rates from non-intrusions, and a faster convergence, with adversarial examples across multiple epochs. Also, practical case studies reveal a level of improved explainability in threat classification and anomaly detection, which equates to practical interpretability for security analysts from the framework. The major contributions of the work are threefold: 1) an integrated multi-layered AI-based cybersecurity framework, 2) theoretical robustness results in bounded adversarial models, and 3) performance and interpretability form the systematic empirical evaluations over multiple datasets.",TOPIC
10.1109/ACCESS.2025.3622382,Herbguard: An Ensemble Deep Learning Framework With Efficientnet and Vision Transformers for Fine-Grained Classification of Medicinal and Poisonous Plants,"Classifying whether a plant is herbal or poisonous is a significant challenge for trekkers, hikers, and nature enthusiasts, particularly in remote areas where several unfamiliar plant species are encountered. Consumption or even close contact with some poisonous plant species may lead to serious health risks, highlighting the need for an intelligent and real-time classification system. In this study, we propose an approach based on deep-learning to classify plants into several species under herbal and poisonous categories. The system employs Convolutional Neural Network (CNN) based EfficientNetV2-S, designed for local feature extraction, trained on segmented images, and transformer-based ViT-Tiny, capable of capturing global dependencies in images, fine-tuned on unsegmented raw images. Both models are trained using a two-stage fine-tuning strategy with label smoothing, MixUp, and CutMix augmentations. Preprocessing steps include CLAHE-based contrast enhancement, HSV masking and GrabCut segmentation, that are applied to training images to focus on relevant plant regions. The models are evaluated on 48 different plant species, consisting of 40 herbal and 8 poisonous species, ultimately achieving species-level accuracies of 95.86% (EfficientNet) and 96.69% (ViT) on the validation dataset. A soft-voting ensemble of the two models further improves species-level accuracy to 97.10% upon validation and 98.43% upon testing, while category-level accuracy remains consistently above 99.7% for all the models. These results demonstrate that combining convolutional and transformer-based approaches leads to a robust, highly accurate classification system that is capable of distinguishing varieties of medicinal and poisonous plants, offering a practical tool for safe trekking, biodiversity monitoring, and herbal medicine research.",TOPIC
10.23919/JSEE.2021.000121,UAV cooperative air combat maneuver decision based on multi-agent reinforcement learning,"In order to improve the autonomous ability of unmanned aerial vehicles (UAV) to implement air combat mission, many artificial intelligence-based autonomous air combat maneuver decision-making studies have been carried out, but these studies are often aimed at individual decision-making in 1v1 scenarios which rarely happen in actual air combat. Based on the research of the 1v1 autonomous air combat maneuver decision, this paper builds a multi-UAV cooperative air combat maneuver decision model based on multi-agent reinforcement learning. Firstly, a bidirectional recurrent neural network (BRNN) is used to achieve communication between UAV individuals, and the multi-UAV cooperative air combat maneuver decision model under the actor-critic architecture is established. Secondly, through combining with target allocation and air combat situation assessment, the tactical goal of the formation is merged with the reinforcement learning goal of every UAV, and a cooperative tactical maneuver policy is generated. The simulation results prove that the multi-UAV cooperative air combat maneuver decision model established in this paper can obtain the cooperative maneuver policy through reinforcement learning, the cooperative maneuver policy can guide UAVs to obtain the overall situational advantage and defeat the opponents under tactical cooperation.",TOPIC
10.26599/JICV.2023.9210039,Development of Deep-Learning-Based Autonomous Agents for Low-Speed Maneuvering in Unity,"This study provides a systematic analysis of the resource-consuming training of deep reinforcement-learning (DRL) agents for simulated low-speed automated driving (AD). In Unity, this study established two case studies: garage parking and navigating an obstacle-dense area. Our analysis involves training a path-planning agent with real-time-only sensor information. This study addresses research questions insufficiently covered in the literature, exploring curriculum learning (CL), agent generalization (knowledge transfer), computation distribution (CPU vs. GPU), and mapless navigation. CL proved necessary for the garage scenario and beneficial for obstacle avoidance. It involved adjustments at different stages, including terminal conditions, environment complexity, and reward function hyperparameters, guided by their evolution in multiple training attempts. Fine-tuning the simulation tick and decision period parameters was crucial for effective training. The abstraction of high-level concepts (e.g., obstacle avoidance) necessitates training the agent in sufficiently complex environments in terms of the number of obstacles. While blogs and forums discuss training machine learning models in Unity, a lack of scientific articles on DRL agents for AD persists. However, since agent development requires considerable training time and difficult procedures, there is a growing need to support such research through scientific means. In addition to our findings, we contribute to the R&D community by providing our environment with open sources.",TOPIC
