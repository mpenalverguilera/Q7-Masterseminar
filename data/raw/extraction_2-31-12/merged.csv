DOI,Document title,Abstract
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,[No abstract available]
,,"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. © 2017 Neural information processing systems foundation. All rights reserved."
10.1002/wcs.1488,,"ACT-R is a hybrid cognitive architecture. It is comprised of a set of programmable information processing mechanisms that can be used to predict and explain human behavior including cognition and interaction with the environment. We start by reviewing its history, which shapes its current form, contrasts and relates it to other architectures, and helps readers to anticipate where it is going. Based on this history, we then describe it as a theory of cognition that is realized as a computer program. After this, we briefly discuss tools for working with ACT-R, and also note several major accomplishments that have been gained by working with ACT-R in both basic and applied science, including summarizing some of the insights about human behavior. We conclude by discussing its future, which we believe will include adding emotions and physiology, increasing usability, and the use of nongenerative models. This article is categorized under: Computer Science > Artificial Intelligence Psychology > Reasoning and Decision Making Psychology > Theory and Methods. © 2018 Wiley Periodicals, Inc."
10.1038/s41562-023-01659-w,,"The recent advent of large language models has reinvigorated debate over whether human cognitive capacities might emerge in such generic models given sufficient training data. Of particular interest is the ability of these models to reason about novel problems zero-shot, without any direct training. In human cognition, this capacity is closely tied to an ability to reason by analogy. Here we performed a direct comparison between human reasoners and a large language model (the text-davinci-003 variant of Generative Pre-trained Transformer (GPT)-3) on a range of analogical tasks, including a non-visual matrix reasoning task based on the rule structure of Raven’s Standard Progressive Matrices. We found that GPT-3 displayed a surprisingly strong capacity for abstract pattern induction, matching or even surpassing human capabilities in most settings; preliminary tests of GPT-4 indicated even better performance. Our results indicate that large language models such as GPT-3 have acquired an emergent ability to find zero-shot solutions to a broad range of analogy problems. © 2023, The Author(s), under exclusive licence to Springer Nature Limited."
10.1109/EIECS63941.2024.10799986,,"Although Large Language Models (LLMs) have achieved significant results in the field of natural language processing, there are still challenges in handling long-term memory in open domain dialogue systems. Processing lengthy conversation histories requires a significant amount of computational resources, which limits the input window of LLM and makes it unable to effectively handle tasks that require long-term memory. To this end, this article proposes a memory enhancement mechanism based on behavioral memory, which enhances the long-term memory ability of LLM by extracting, storing, and retrieving key behavioral information from conversations through association. This method does not require modifying the internal structure of LLM and is compatible with various open source and closed source models. We conducted experiments on the Generated Virtual Dataset and the results showed that compared to methods based on abstracts and vector databases, the behavioral memory mechanism significantly improved memory retrieval accuracy, response accuracy, and contextual coherence.  © 2024 IEEE."
10.1109/ICPADS63350.2024.00042,,"In recent years, large language models (LLMs) have shown rapid development, becoming one of the most popular topics in the field of artificial intelligence. LLMs have demonstrated powerful generalization and learning capabilities, and their performance on various language tasks has been remarkable. Despite their successes, LLMs face significant challenges, particularly in domain-specific tasks that require structured knowledge, often leading to issues such as hallucinations. To mitigate these challenges, we propose a novel system, SynaptiQA, which integrates LLMs with Knowledge Graphs (KGs) to answer more questions about knowledge. Our approach leverages the generative capabilities of LLMs to create and optimize KG queries, thereby improving the accuracy and contextual relevance of responses. Experimental results in an industrial data set demonstrate that SynaptiQA outperforms baseline models and naive retrieval-augmented generation (RAG) systems, demonstrating improved accuracy and reduced hallucinations. This integration of KGs with LLMs paves the way for more reliable and interpretable domain-specific question answering systems. © 2024 IEEE."
10.1109/IMSA61967.2024.10652751,,"Knowledge graphs (KGs), structured representations of entities and their relationships, are increasingly crucial for various Artificial Intelligence (AI) tasks. However, the complex structure and vast scale of KGs pose challenges for efficient reasoning and information retrieval. Knowledge graph embedding (KGE) is a powerful technique to bridge this gap by mapping entities and relations into low-dimensional vector spaces. This paper comprehensively surveys KGE methods, exploring diverse approaches, including point-wise embedding methods and complex vector spaces. We go deep into each method's underlying principles and strengths, highlighting their unique characteristics and providing insights into their effectiveness for various tasks. By exploring MuRP, AttH, and HypHKGE, we contribute to advancing graph embedding techniques and paving the way for more efficient knowledge graph analysis and reasoning.  © 2024 IEEE."
10.1109/MIPRO60963.2024.10569238,,"Large language models (LLM) are trained to understand and generate human-like language. While LLMs present a cutting-edge concept and their use is becoming widespread, hallucinations sometimes occur during their operation. Hallucinations refer to instances where the model generates inaccurate or fictitious information, deviating from factual knowledge and potentially providing responses that lack a basis in model's training data. In this paper, the ways in which LLMs generate text are examined to address the question of why hallucinations occur. The paper additional explores how existing LLM models can be leveraged to reduce the likelihood of hallucination. Alongside exploring hallucinations, this paper provides insights into the algorithms used for training LLMs, offering a clear picture of the text generation process and its effective utilization.  © 2024 IEEE."
10.1109/TASLP.2022.3199648,,"Recently, the attention mechanism boosts the performance of many neural network models in Natural Language Processing (NLP). Among the various attention mechanisms, Multi-Head Attention (MHA) is a powerful and popular variant. MHA helps the model to attend to different feature subspaces independently which is an essential component of Transformer. Despite its success, we conjecture that the different heads of the existing MHA may not collaborate properly. To validate this assumption and further improve the performance of Transformer, we study the collaboration problem for MHA in this paper. First, we propose the Single-Layer Collaboration (SLC) mechanism to help each attention head improve its attention distribution based on the feedback of other heads. Furthermore, we extend SLC to the cross-layer Multi-Head Dense Collaboration (MHDC) mechanism. MHDC helps each MHA layer learn the attention distributions considering the knowledge from the other MHA layers. Both SLC and MHDC are implemented as lightweight modules with very few additional parameters. When equipped with these modules, our new framework, i.e., Collaborative TransFormer (CollFormer), significantly outperforms the vanilla Transformer on a range of NLP tasks, including machine translation, sentence semantic relatedness, natural language inference, sentence classification, and reading comprehension. Besides, we also carry out extensive quantitative experiments to analyze the properties of the MHDC in different settings. The experimental results validate the effectiveness and universality of MHDC as well as CollFormer. © 2014 IEEE."
10.1145/3613904.3641904,,"Large Language Models (LLMs) are notorious for blending fact with fiction and generating non-factual content, known as hallucinations. To address this challenge, we propose an interactive system that helps users gain insight into the reliability of the generated text. Our approach is based on the idea that the self-consistency of multiple samples generated by the same LLM relates to its confidence in individual claims in the generated texts. Using this idea, we design RELIC, an interactive system that enables users to investigate and verify semantic-level variations in multiple long-form responses. This allows users to recognize potentially inaccurate information in the generated text and make necessary corrections. From a user study with ten participants, we demonstrate that our approach helps users better verify the reliability of the generated text. We further summarize the design implications and lessons learned from this research for future studies of reliable human-LLM interactions. © 2024 Copyright held by the owner/author(s)"
10.1145/3616855.3635744,,"Large Language Models (LLMs) have demonstrated remarkable capabilities in various language-related tasks enabling applications in various fields such as healthcare, education, financial services etc. However, they are prone to producing factually incorrect responses or ''hallucinations'' which can have detrimental consequences such as loss of credibility, diminished customer trust etc. In this presentation, we showcase a solution that addresses the challenge of minimizing hallucinations. Our solution provides accurate responses and generates detailed explanations, thereby enabling the users to know how the model arrived at the final response. Additionally, it verifies if the explanations are factually correct and offers insights into whether the generated explanations are directly derived from the provided context or if they are inferred from it. We also systematically assess the quality of generated responses using an LLM-based evaluation technique. We present empirical results on benchmark datasets to demonstrate the effectiveness of our approach. Our presentation also examines the impact of individual components in the solution, enhancing the factual correctness of the final response. This research is vital for industries utilizing LLMs, as it provides a means to enhance the reliability of responses and mitigate the risks associated with factual hallucinations. Researchers and practitioners seeking to enhance the reliability of LLM responses will find valuable insights in this presentation. © 2024 Owner/Author."
10.1145/3643806,,"Knowledge graph embedding (KGE) is an increasingly popular technique that aims to represent entities and relations of knowledge graphs into low-dimensional semantic spaces for a wide spectrum of applications such as link prediction, knowledge reasoning and knowledge completion. In this article, we provide a systematic review of existing KGE techniques based on representation spaces. Particularly, we build a fine-grained classification to categorise the models based on three mathematical perspectives of the representation spaces: (1) algebraic perspective, (2) geometric perspective and (3) analytical perspective. We introduce the rigorous definitions of fundamental mathematical spaces before diving into KGE models and their mathematical properties. We further discuss different KGE methods over the three categories, as well as summarise how spatial advantages work over different embedding needs. By collating the experimental results from downstream tasks, we also explore the advantages of mathematical space in different scenarios and the reasons behind them. We further state some promising research directions from a representation space perspective, with which we hope to inspire researchers to design their KGE models as well as their related applications with more consideration of their mathematical space properties. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM."
10.1145/3703155,,"The emergence of large language models (LLMs) has marked a significant breakthrough in natural language processing (NLP), fueling a paradigm shift in information acquisition. Nevertheless, LLMs are prone to hallucination, generating plausible yet nonfactual content. This phenomenon raises significant concerns over the reliability of LLMs in real-world information retrieval (IR) systems and has attracted intensive research to detect and mitigate such hallucinations. Given the open-ended general-purpose attributes inherent to LLMs, LLM hallucinations present distinct challenges that diverge from prior task-specific models. This divergence highlights the urgency for a nuanced understanding and comprehensive overview of recent advances in LLM hallucinations. In this survey, we begin with an innovative taxonomy of hallucination in the era of LLM and then delve into the factors contributing to hallucinations. Subsequently, we present a thorough overview of hallucination detection methods and benchmarks. Our discussion then transfers to representative methodologies for mitigating LLM hallucinations. Additionally, we delve into the current limitations faced by retrieval-augmented LLMs in combating hallucinations, offering insights for developing more robust IR systems. Finally, we highlight the promising research directions on LLM hallucinations, including hallucination in large vision-language models and understanding of knowledge boundaries in LLM hallucinations.  © 2025 Copyright held by the owner/author(s)."
10.1518/001872006777724417,,"Objective: This paper explores the development of a rigorous computational model of driver behavior in a cognitive architecture - a computational framework with underlying psychological theories that incorporate basic properties and limitations of the human system. Background: Computational modeling has emerged as a powerful tool for studying the complex task of driving, allowing researchers to simulate driver behavior and explore the parameters and constraints of this behavior. Method: An integrated driver model developed in the ACT-R (Adaptive Control of Thought-Rational) cognitive architecture is described that focuses on the component processes of control, monitoring, and decision making in a multilane highway environment. Results: This model accounts for the steering profiles, lateral position profiles, and gaze distributions of human drivers during lane keeping, curve negotiation, and lane changing. Conclusion: The model demonstrates how cognitive architectures facilitate understanding of driver behavior in the context of general human abilities and constraints and how the driving domain benefits cognitive architectures by pushing model development toward more complex, realistic tasks. Application: The model can also serve as a core computational engine for practical applications that predict and recognize driver behavior and distraction. Copyright © 2006, Human Factors and Ergonomics Society. All rights reserved."
10.3390/s24051687,,"Large language models have found utility in the domain of robot task planning and task decomposition. Nevertheless, the direct application of these models for instructing robots in task execution is not without its challenges. Limitations arise in handling more intricate tasks, encountering difficulties in effective interaction with the environment, and facing constraints in the practical executability of machine control instructions directly generated by such models. In response to these challenges, this research advocates for the implementation of a multi-layer large language model to augment a robot’s proficiency in handling complex tasks. The proposed model facilitates a meticulous layer-by-layer decomposition of tasks through the integration of multiple large language models, with the overarching goal of enhancing the accuracy of task planning. Within the task decomposition process, a visual language model is introduced as a sensor for environment perception. The outcomes of this perception process are subsequently assimilated into the large language model, thereby amalgamating the task objectives with environmental information. This integration, in turn, results in the generation of robot motion planning tailored to the specific characteristics of the current environment. Furthermore, to enhance the executability of task planning outputs from the large language model, a semantic alignment method is introduced. This method aligns task planning descriptions with the functional requirements of robot motion, thereby refining the overall compatibility and coherence of the generated instructions. To validate the efficacy of the proposed approach, an experimental platform is established utilizing an intelligent unmanned vehicle. This platform serves as a means to empirically verify the proficiency of the multi-layer large language model in addressing the intricate challenges associated with both robot task planning and execution. © 2024 by the authors."
