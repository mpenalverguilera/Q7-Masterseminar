DOI,Source title,Abstract
10.1007/s10462-025-11381-w,Artificial Intelligence Review,"Conventional treatment methods make even the most basic healthcare issues more complicated, which in turn increases the number of parties involved. Classical computing lacks the speed and accuracy needed for effective stakeholder collaboration in COVID-19 healthcare solutions, such as patients, insurance agents, healthcare practitioners, pharmaceutical suppliers, etc. The research uses organizational information processing theory (OIPT) to examine how quantum computing which is applications of artificial intelligence (AI) could transform the healthcare business, creating a more sustainable and less burdened system. The study of quantum computing (QC) has the potential to bring about “quantum leaps,” which might have unforeseen consequences for healthcare. The discovery of new medications, the personalization of medicinal treatments, and the acceleration of DNA sequencing are just a few of the many possible applications of this method. The potential of QC to transform compute-intensive healthcare tasks like drug-discovery, personalized-medicine, DNA-sequencing, medical-imaging, and operational-optimization is the primary focus of this survey paper, which offers the first comprehensive analysis of QCs diverse capabilities in improving healthcare systems. After a thorough literature study, we created taxonomies on the healthcare QC paradigm’s history and supporting technologies, applications, needs, architectures, security, outstanding questions, and future research prospects. We hope that by conducting this survey, researchers with varying levels of experience in quantum computing and healthcare will better understand the state of the art, assess opportunities and threats, and make informed decisions as they develop novel architectures and applications for this emerging field. © 2025 Elsevier B.V., All rights reserved."
10.1007/s10845-024-02494-0,Journal of Intelligent Manufacturing,"Self-organizing manufacturing network has emerged as a viable solution for adaptive manufacturing control within the mass personalization paradigm. This approach involves three critical elements: system modeling and control architecture, interoperable communication, and adaptive manufacturing control. However, current research often separates interoperable communication from adaptive manufacturing control as isolated areas of study. To address this gap, this paper introduces Knowledge Graph-enhanced Multi-Agent Reinforcement Learning (MARL) method that integrates interoperable communication via Knowledge Graphs with adaptive manufacturing control through Reinforcement Learning. We hypothesize that implicit domain knowledge obtained from historical production job allocation records can guide each agent to learn more effective scheduling policies with accelerated learning rates. This is based on the premise that machine assignment preferences effectively could reduce the Reinforcement Learning search space. Specifically, we redesign machine agents with new observation, action, reward, and cooperation mechanisms considering the preference of machines, building upon our previous MARL base model. The scheduling policies are trained under extensive simulation experiments that consider manufacturing requirements. During the training process, our approach demonstrates improved training speed compared with individual Reinforcement Learning methods under the same training hyperparameters. The obtained scheduling policies generated by our Knowledge Graph-enhanced MARL also outperform both individual Reinforcement Learning methods and heuristic rules under dynamic manufacturing settings. © 2025 Elsevier B.V., All rights reserved."
10.1007/s10916-025-02255-3,Journal of Medical Systems,"This paper presents a trust-aware architecture for personalized digital health that combines user modeling, symbolic reasoning, and adaptive trust mechanisms. The proposed system uses Blueprint Personas to capture detailed patient profiles, including clinical, behavioral, and emotional traits. These profiles guide an intelligent agent that interacts with patients and healthcare professionals to provide context-sensitive support. Personalization is achieved through an ontology-based reasoning layer that interprets user needs and integrates real-time data from electronic health records, wearable devices, and environmental sources. To promote transparency and foster long-term user engagement, the system includes a formal trust modeling component based on a Reference Ontology of Trust (ROT), allowing the system to flexibly tailor communication strategies in response to user feedback and evolving trust levels. A simulated scenario involving a patient with chronic obstructive pulmonary disease demonstrates how the system delivers proactive and personalized healthcare interventions, such as medication reminders and air quality alerts. While the architecture is modular and designed for scalability, it has not yet been deployed in real-world clinical settings. Empirical validation and integration with clinical platforms remain part of future work. Nevertheless, this ongoing work contributes to the development of explainable and ethically aligned AI systems that enhance autonomy, accessibility, and trust in digital health environments through explainable reasoning. © 2025 Elsevier B.V., All rights reserved."
10.1007/s43503-025-00072-8,AI in Civil Engineering,"The expansion of rail transport infrastructures necessitates accurate and efficient soil surveys to ensure long-term stability and performance, particularly in regions prone to soil heaving. This study aimed to demonstrate the potential of non-destructive spectral analysis combined with Agentic Artificial Intelligence for automating the identification of soil heaving potential, providing a transformative approach to soil assessment in railway construction. A robust AI-agent was developed to predict soil heaving potential across temperature regimes (ranging from 0°C to -5°C and back), enabling characterization of the relative acoustic compressibility coefficient (β) based on the physical and mechanical properties of the soil. The main objective was to develop a framework that integrated spectral reflectance data with machine learning algorithms to predict soil heaving potential and reduce the reliance on traditional invasive methods. The experimental setup employed digital techniques to process and record longitudinal and transverse acoustic pulse signals reflected from piezoelectric sensors mounted on soil specimens. The processed signals were automatically transferred via a USB adapter to a PC for further analysis by the AI-agent. Acoustic diagnostics of the soils were performed using Fast-Fourier Transform (FFT) Spectral Analysis, followed by correlation of waveform spectra with heaving deformation. The AI-agent utilized a hybrid architecture combining Convolutional Neural Network (CNN), Support Vector Machine (SVM), and Random Forest (RF) algorithms to address the complexities of heterogeneous soil data and multifaceted prediction tasks—including heaving classification and deformation regression—while mitigating overfitting. Soil heaving potential was accurately predicted by the AI agent, with minor variations attributed to equipment sensitivity. © 2025 Elsevier B.V., All rights reserved."
10.1016/j.atech.2025.101412,Smart Agricultural Technology,"Digital twins and artificial intelligence are increasingly explored to support decision-making. In this work, we introduce a modular and interoperable architecture that combines digital twins with reinforcement learning for adaptive decision-making in complex environmental systems. We apply this approach to smart farming, where efficient resource use is critical to balance productivity with environmental impact. Our contributions are threefold: (a) the augmentation of agricultural models as digital twins—specifically the crop growth model WOFOST and the plant disease model A-scab—that assimilate field data to reflect current crop conditions; (b) the integration of reinforcement learning agents that generate recommendations for pesticide and fertilizer application—the first to demonstrate interoperable reinforcement learning-integrated digital twins in operational agriculture; and (c) the development of a FIWARE-based interoperability layer that integrates a diverse set of (edge) components. We demonstrate our approach in two pilot studies—apple scab management and nitrogen application in winter wheat—showcasing its potential for real-world application in diverse agricultural contexts and its transferability to other domains. © 2025 Elsevier B.V., All rights reserved."
10.1016/j.comcom.2025.108342,Computer Communications,"Large-scale low earth orbit (LEO) satellite networks constitute a core component of future sixth-generation (6G) communication systems. To address the challenges of resource scarcity and highly dynamic topologies, the integration of software-defined networking (SDN) and network function virtualization (NFV) technologies into LEO satellite networks has become imperative. We proposes a hybrid centralized-distributed software-defined LEO satellite network architecture. Within this framework, This study focuses on the service function chain (SFC) deployment problem in LEO space-ground integrated networks. time-expanded graphs (TEGs) are employed to model satellite networks with dynamic topological variations, aiming to satisfy diverse user requirements while jointly optimizing resource consumption costs and service latency. The problem is formulated as a weighted sum minimization of resource consumption costs and service latency, and this problem is proven to be NP-complete. Subsequently, we integrate the twin delayed deep deterministic policy gradient method with multi-agent techniques to design a multi-agent deep reinforcement learning SFC deployment (MADRL-D) framework for optimizing our objectives. Experimental results demonstrate that the proposed MADRL-D framework outperforms existing alternatives in terms of resource utilization efficiency, resource consumption costs, and service latency. © 2025 Elsevier B.V., All rights reserved."
10.1016/j.commtr.2025.100165,Communications in Transportation Research,"Designing an optimal departure trajectory for an airport can minimize fuel emissions within the surrounding airspace and noise perceived by nearby populations, which brings positive sociological and economic implications in addition to environmental benefits. Yet, designing a trajectory that considers realistic operational constraints could be complex and, consequently, computationally expensive. Traditional trajectory optimization methods often simplify the problem to manage computational costs, which leads to compromised accuracy. To overcome this challenge, we propose a reinforcement learning (RL) approach that can satisfy multidisciplinary constraints by leveraging accurately modeled flight dynamics, high-fidelity population data, and topological data. This is achieved by establishing a comprehensive, physically-consistent simulated environment for the learning algorithm, while keeping the computational cost low. Instead of directly designing the trajectory itself, we train an RL agent to control the aircraft, whose trajectory is then considered as optimal. We model the RL problem as a continuous Markov decision process and employ the soft actor-critic architecture. By changing the relative importance of fuel consumption and noise in the optimization objective, we can obtain different optimum trajectories that are well-suited to the specific region of interest. Not surprisingly, a trade-off between fuel consumption and noise impact is observed in our results. This developed framework provides a more accurate and sophisticated approach for departure trajectory optimization, whose results are beneficial for future airspace design and can support sustainable aviation efforts. © 2025 Elsevier B.V., All rights reserved."
10.1016/j.comnet.2025.111749,Computer Networks,"Large Language Model (LLM)-based autonomous agents are expected to play a vital role in the evolution of 6G networks, by empowering real-time decision-making related to management and service provisioning to end-users. This shift facilitates the transition from a specialized intelligence approach, where artificial intelligence (AI) algorithms handle isolated tasks, to artificial general intelligence (AGI)-driven networks, where agents possess broader reasoning capabilities and can manage diverse network functions. In this paper, we introduce a novel agentic paradigm that combines LLMs with real-time optimization algorithms towards Trustworthy AI, defined as symbiotic agents. Optimizers at the LLM's input-level provide bounded uncertainty steering for numerically precise tasks, whereas output-level optimizers supervised by the LLM enable adaptive real-time control. We design and implement two novel agent types including: (i) Radio Access Network (RAN) optimizers, and (ii) multi-agent negotiators for Service-Level Agreements (SLAs). We further propose an end-to-end architecture for AGI-driven networks and evaluate it on a 5G testbed capturing channel fluctuations from moving vehicles. Results show that symbiotic agents reduce decision errors fivefold compared to standalone LLM-based agents, while smaller language models (SLM) achieve similar accuracy with a 99.9 % reduction in Graphical Processing Unit (GPU) resource overhead and in near-real-time (near-RT) loops of 82ms. A multi-agent demonstration for collaborative RAN on the real-world testbed highlights significant flexibility in service-level agreement and resource allocation, reducing RAN over-utilization by approximately 44 %. Drawing on our findings and open-source implementations, we introduce the symbiotic paradigm as the foundation for next-generation, AGI-driven networks-systems designed to remain adaptable, efficient, and trustworthy even as LLMs advance. A live demo is presented here https://www.youtube.com/watch?v=WQv61z1deXs&ab\_channel=BubbleRAN © 2025 Elsevier B.V., All rights reserved."
10.1016/j.engappai.2025.112222,Engineering Applications of Artificial Intelligence,"The degradation of fuel cell systems (FCS) affects the energy management performance of fuel cell hybrid electric vehicles (FCHEVs), especially in the case of severe degradation. This study develops a novel predictive energy management architecture, which consists of the Extended Long Short-Term Memory (xLSTM) and Soft Actor-Critic (SAC). Specifically, the speed predictor is built using xLSTM network and leverages the speed and position information of the preceding and following vehicles. In order to provide a reliable basis for energy management in degradation scenarios, an FCS degradation model is developed, which enables the dynamic mapping of output efficiency curves under varying state-of-health (SOH) conditions. Sequentially, a SAC-based agent is employed as the energy management strategy (EMS), which innovatively takes full account of the impact of the FCS SOH on energy allocation, achieving proactive degradation-aware energy allocation. Simulation results demonstrate that the developed xLSTM architecture achieves a 71 % improvement in speed prediction accuracy compared to Transformer-based models within the Next Generation Simulation validated scenario. Moreover, at SOH = 90 %, the newly designed EMS reduces operational costs by 8.7 % and 10.7 % compared to conventional methods under the New European Driving Cycle and Worldwide Harmonized Light Vehicles Test Procedure, while decreasing FCS degradation costs by 17 % and 51 %, respectively. The innovative approach not only elevates energy efficiency but also prolongs FCS operational longevity via intelligent SOH-aware, which establishes a new paradigm for lifecycle-optimized energy management in FCHEVs. © 2025 Elsevier B.V., All rights reserved."
10.1109/ACCESS.2020.3011670,A Novel Multi-Agent Parallel-Critic Network Architecture for Cooperative-Competitive Reinforcement Learning,"Multi-agent deep reinforcement learning (MDRL) is an emerging research hotspot and application direction in the field of machine learning and artificial intelligence. MDRL covers many algorithms, rules and frameworks, it is currently researched in swarm system, energy allocation optimization, stocking analysis, sequential social dilemma, and with extremely bright future. In this paper, a parallel-critic method based on classic MDRL algorithm MADDPG is proposed to alleviate the training instability problem in cooperative-competitive multi-agent environment. Furthermore, a policy smoothing technique is introduced to our proposed method to decrease the variance of learning policies. The suggested method is evaluated in three different scenarios of authoritative multi-agent particle environment (MPE). Multiple statistical data of experimental results show that our method significantly improves the training stability and performance compared to vanilla MADDPG."
10.1109/ACCESS.2021.3083087,Federated Reinforcement Learning Acceleration Method for Precise Control of Multiple Devices,"Nowadays, Reinforcement Learning (RL) is applied to various real-world tasks and attracts much attention in the fields of games, robotics, and autonomous driving. It is very challenging and devices overwhelming to directly apply RL to real-world environments. Due to the reality gap simulated environment does not match perfectly to the real-world scenario and additional learning cannot be performed. Therefore, an efficient approach is required for RL to find an optimal control policy and get better learning efficacy. In this paper, we propose federated reinforcement learning based on multi agent environment which applying a new federation policy. The new federation policy allows multi agents to perform learning and share their learning experiences with each other e.g., gradient and model parameters to increase their learning level. The Actor-Critic PPO algorithm is used with four types of RL simulation environments, OpenAI Gym's CartPole, MoutainCar, Acrobot, and Pendulum. In addition, we did real experiments with multiple Rotary Inverted Pendulum (RIP) to evaluate and compare the learning efficiency of the proposed scheme with both environments."
10.1109/ACCESS.2023.3309417,Rational Coordination in Cognitive Agents: A Decision-Theoretic Approach Using ERMM,"Over the years, research in multi-agent systems has become increasingly popular. Agents evolve by interacting with their environment and must communicate with other agents in order to do various cooperative tasks. The research aims to provide efficient coordination among cooperative cognitive agents in unpredictable multi-agent situations. Xiang’s rational agent model addresses scenarios when no social conventions or predefined communication protocols exist for the agents’ interaction and then makes decisions by recursive modeling. We address the deficiencies of the loosely coupled framework and the problem of mispredictions in Xiang’s architecture. The solution is based on Lawniczak’s Architecture for generic cognitive agents and an enhanced model of Xiang’s Recursive Modeling Method for coordinated decision-making in multi-agent situations. We instruct the cognitive agent to learn about other agents from past mispredictions and then consider its best choice. The feedback module is incorporated so agents can learn to maximize their joint expected reward. The model filters the mispredictions and evaluates the error rate. We compare the enhanced method with the Recursive Modeling Method. The results show that mispredictions are corrected from 33% to 10.9% and errors in perception are reduced from 22% to 0.097%, as the system progresses. Overall, the approach demonstrates superior performance. It significantly lowers the rate of mispredictions about other agents’ actions and takes 30% to 42% less time and 55.4 % fewer moves than RMM."
10.1109/ACCESS.2025.3573419,Strategic Implementation of Super-Agents in Heterogeneous Multi-Agent Training for Advanced Military Simulation Adaptability,"This study focuses on the application of reinforcement learning in tactical military simulation environments involving heterogeneous multi-agent systems. Optimizing Heterogeneous Multi-Agent Training (HMAT) through scenario-specific adjustments to the Proximal Policy Optimization (PPO) algorithm, we tackle the complexity of tactical simulations. Utilizing an advanced simulation platform, a diverse range of Reinforcement Learning (RL) agents are rigorously trained across various combat scenarios. A ‘super-agent’, an Artificial Intelligence (AI) orchestrator for multi-agent systems, marks a significant advancement in collaborative AI, enhancing operational performance. Comparative analysis highlights the strengths of both traditional RL approaches and HMAT in a unified computational framework. While independent learning agents excel in predictable environments with fast training capabilities, HMAT stands out in dynamic scenarios for its adaptability and superior performance. The integration of HMAT with ‘super-agents’ is shown to markedly improve the fidelity and adaptive capacity of military simulations. Experimental results demonstrate that our fine-tuned super-agent framework achieves up to 92% mission success rate, outperforming scenario-specific baselines by 15–20% in complex Suppression of Enemy Air Defenses (SEAD) and air-to-ground tasks.These enhancements have far-reaching implications, potentially revolutionizing strategic military training and operational planning and underscoring AI’s critical role in modern defense strategies."
10.1109/ACCESS.2025.3610526,"A Multi-Layered AI-Driven Cybersecurity Architecture: Integrating Entropy Analytics, Fuzzy Reasoning, Game Theory, and Multi-Agent Reinforcement Learning for Adaptive Threat Defense","In the face of increasingly sophisticated cyberattacks, including adaptive adversaries and stealthy anomalies, key features of defense mechanisms should be effective, interpretable, and theoretically rooted. Conventional intrusion detection systems are typically based on a single-paradigm machine learning model which can be effective (because it is optimized for conditions), but fail in generalizability and falling back on an explanation of its prediction. This paper outlines a multi-layered AI-enabled cyber defense framework that integrates entropy analytics, fuzzy inference, game-theoretic defense, and multi-agent reinforcement learning (MARL) inside a closed-loop adaptive architecture. In its simplest form, the novelty of the paper is that, four functional paradigms - uncertainty quantification, interpretability, strategic adversarial thinking, and live policy adaptation - are placed into a single coherent system. The framework operates as sequential and feedback salients - entropy analytics quantify the uncertainty in are states, fuzzy inference end maps the uncertainty into qualitative decision rules, game theory shapes defender - attacker towards equilibrium strategies, and MARL dynamically updates those strategies for convergence and long term adaptation. The empirical work on appropriate benchmark intrusion detection datasets consistently outperformed baseline systems including the DDN, Fed-ID, AG-IDS, DL-FL systems producing a 6-12% increase in detection accuracy, lower false positive rates from non-intrusions, and a faster convergence, with adversarial examples across multiple epochs. Also, practical case studies reveal a level of improved explainability in threat classification and anomaly detection, which equates to practical interpretability for security analysts from the framework. The major contributions of the work are threefold: 1) an integrated multi-layered AI-based cybersecurity framework, 2) theoretical robustness results in bounded adversarial models, and 3) performance and interpretability form the systematic empirical evaluations over multiple datasets."
10.1109/ACCESS.2025.3622382,Herbguard: An Ensemble Deep Learning Framework With Efficientnet and Vision Transformers for Fine-Grained Classification of Medicinal and Poisonous Plants,"Classifying whether a plant is herbal or poisonous is a significant challenge for trekkers, hikers, and nature enthusiasts, particularly in remote areas where several unfamiliar plant species are encountered. Consumption or even close contact with some poisonous plant species may lead to serious health risks, highlighting the need for an intelligent and real-time classification system. In this study, we propose an approach based on deep-learning to classify plants into several species under herbal and poisonous categories. The system employs Convolutional Neural Network (CNN) based EfficientNetV2-S, designed for local feature extraction, trained on segmented images, and transformer-based ViT-Tiny, capable of capturing global dependencies in images, fine-tuned on unsegmented raw images. Both models are trained using a two-stage fine-tuning strategy with label smoothing, MixUp, and CutMix augmentations. Preprocessing steps include CLAHE-based contrast enhancement, HSV masking and GrabCut segmentation, that are applied to training images to focus on relevant plant regions. The models are evaluated on 48 different plant species, consisting of 40 herbal and 8 poisonous species, ultimately achieving species-level accuracies of 95.86% (EfficientNet) and 96.69% (ViT) on the validation dataset. A soft-voting ensemble of the two models further improves species-level accuracy to 97.10% upon validation and 98.43% upon testing, while category-level accuracy remains consistently above 99.7% for all the models. These results demonstrate that combining convolutional and transformer-based approaches leads to a robust, highly accurate classification system that is capable of distinguishing varieties of medicinal and poisonous plants, offering a practical tool for safe trekking, biodiversity monitoring, and herbal medicine research."
10.1109/TLT.2014.2367493,A Self-Adaptive Multi-Agent System Approach for Collaborative Mobile Learning,"Mobile technologies have emerged as facilitators in the learning process, extending traditional classroom activities. However, engineering mobile learning applications for outdoor usage poses severe challenges. The requirements of these applications are challenging, as many different aspects need to be catered, such as resource access and sharing, communication between peers, group management, activity flow, etc. Robustness is particularly important for learning scenarios to guarantee undisturbed and smooth user experiences, pushing the technological aspects in the background. Despite significant research in the field of mobile learning, very few efforts have focused on collaborative mobile learning requirements from a software engineering perspective. This paper focuses on aspects of the software architecture, aiming to address the challenges related to resource sharing in collaborative mobile learning activities. This includes elements such as autonomy for personal interactive learning, richness for large group collaborative learning (indoor and outdoor), as well as robustness of the learning system. Additionally, we present self-adaptation as a solution to mitigate risks of resource unavailability and organization failures that arise from environment and system dynamism. Our evaluation provides indications regarding the system correctness with respect to resource sharing and collaboration concerns, and offers qualitative evidence of self-adaptation benefits for collaborative mobile learning applications."
10.1145/3649158.3657034,BlueSky: How to Raise a Robot - A Case for Neuro-Symbolic AI in Constrained Task Planning for Humanoid Assistive Robots,"Humanoid robots will be able to assist humans in their daily life, in particular due to their versatile action capabilities. However, while these robots need a certain degree of autonomy to learn and explore, they also should respect various constraints, for access control and beyond. We explore the novel field of incorporating privacy, security, and access control constraints with robot task planning approaches. We report preliminary results on the classical symbolic approach, deep-learned neural networks, and modern ideas using large language models as knowledge base. From analyzing their trade-offs, we conclude that a hybrid approach is necessary, and thereby present a new use case for the emerging field of neuro-symbolic artificial intelligence."
10.1145/3772077,LUMEN: Enhancing IoT System Observability with Multi-Agent Large Language Models and Knowledge Graphs,"The rapid expansion of Internet of Things (IoT) systems has transformed industries through real-time monitoring and automation, generating vast and heterogeneous data streams. As IoT networks expand, the increasing volume and diversity of data, spanning real-time telemetry, device logs, and historical records, complicate the management of IoT systems, including system monitoring, analysis, and reasoning. To address this challenge, we introduce LUMEN (Large Language Models as Unified Multi-Agent Systems for IoT ENhancement), a novel approach combining multi-agent Large Language Models (LLMs), knowledge graphs, and heterogeneous databases to enable cognitive digital twins for IoT observability. LUMEN models IoT systems as knowledge graphs, capturing device relationships and metadata while monitoring data is stored in time-series or object databases. Specialized LLM-based agents collaborate dynamically to analyze IoT systems and explain the findings in natural language, generating and executing analysis code when necessary. Integrated with off-the-shelf network monitoring tools, LUMEN facilitates semantic reasoning and human-in-the-loop collaboration, delivering adaptive insights across diverse data contexts. Two industrial case studies demonstrate the ability of LUMEN to automate analysis workflows, enhance system adaptability, and provide interpretable analytics. This work advances IoT observability by integrating LLMs, semantic intelligence, and explainable analytics into a scalable and adaptive solution using a multi-agent architecture for complex IoT systems."
10.23919/JSEE.2021.000121,UAV cooperative air combat maneuver decision based on multi-agent reinforcement learning,"In order to improve the autonomous ability of unmanned aerial vehicles (UAV) to implement air combat mission, many artificial intelligence-based autonomous air combat maneuver decision-making studies have been carried out, but these studies are often aimed at individual decision-making in 1v1 scenarios which rarely happen in actual air combat. Based on the research of the 1v1 autonomous air combat maneuver decision, this paper builds a multi-UAV cooperative air combat maneuver decision model based on multi-agent reinforcement learning. Firstly, a bidirectional recurrent neural network (BRNN) is used to achieve communication between UAV individuals, and the multi-UAV cooperative air combat maneuver decision model under the actor-critic architecture is established. Secondly, through combining with target allocation and air combat situation assessment, the tactical goal of the formation is merged with the reinforcement learning goal of every UAV, and a cooperative tactical maneuver policy is generated. The simulation results prove that the multi-UAV cooperative air combat maneuver decision model established in this paper can obtain the cooperative maneuver policy through reinforcement learning, the cooperative maneuver policy can guide UAVs to obtain the overall situational advantage and defeat the opponents under tactical cooperation."
10.26599/JICV.2023.9210039,Development of Deep-Learning-Based Autonomous Agents for Low-Speed Maneuvering in Unity,"This study provides a systematic analysis of the resource-consuming training of deep reinforcement-learning (DRL) agents for simulated low-speed automated driving (AD). In Unity, this study established two case studies: garage parking and navigating an obstacle-dense area. Our analysis involves training a path-planning agent with real-time-only sensor information. This study addresses research questions insufficiently covered in the literature, exploring curriculum learning (CL), agent generalization (knowledge transfer), computation distribution (CPU vs. GPU), and mapless navigation. CL proved necessary for the garage scenario and beneficial for obstacle avoidance. It involved adjustments at different stages, including terminal conditions, environment complexity, and reward function hyperparameters, guided by their evolution in multiple training attempts. Fine-tuning the simulation tick and decision period parameters was crucial for effective training. The abstraction of high-level concepts (e.g., obstacle avoidance) necessitates training the agent in sufficiently complex environments in terms of the number of obstacles. While blogs and forums discuss training machine learning models in Unity, a lack of scientific articles on DRL agents for AD persists. However, since agent development requires considerable training time and difficult procedures, there is a growing need to support such research through scientific means. In addition to our findings, we contribute to the R&D community by providing our environment with open sources."
